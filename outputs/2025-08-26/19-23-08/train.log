[2025-08-26 19:23:08,627][__main__][INFO] - Initializing training.
[2025-08-26 19:23:08,627][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-26 19:23:08,627][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-26 19:23:08,627][__main__][INFO] - CUDA version: 12.1
[2025-08-26 19:23:08,631][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_trainValid_split/train/*.parquet
valid_path: /data/48/wuqian/Proteometools/part1/parquet/1461_trainValid_split/valid/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 1461high_TrainValid_split_noLazy
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 1
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: false
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-26 19:23:08,635][__main__][INFO] - Starting transformer training
[2025-08-26 19:23:08,636][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-26 19:23:08,636][__main__][INFO] - Loading data
[2025-08-26 19:23:19,020][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-26 19:23:25,906][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-26 19:23:28,797][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-26 19:23:28,797][__main__][INFO] - New residues found: 
{'O'}
[2025-08-26 19:23:28,797][__main__][INFO] - Residues supported: 
{'Y', '[UNIMOD:5]', '[EOS]', 'W', '[SOS]', '[UNIMOD:1]', 'L', 'T[UNIMOD:21]', 'K', 'F', 'S[UNIMOD:21]', 'C[UNIMOD:4]', 'Q', '[PAD]', 'E', 'C', 'I', 'H', 'Q[UNIMOD:7]', 'M[UNIMOD:35]', 'P', 'S', 'M', 'Y[UNIMOD:21]', 'G', 'N[UNIMOD:7]', 'V', 'N', 'D', 'T', 'R', '[UNIMOD:385]', 'A'}
[2025-08-26 19:23:57,918][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-26 19:23:57,919][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-26 19:24:25,879][__main__][INFO] - Data loaded: 1,182,693 training samples; 79,338 validation samples
[2025-08-26 19:24:26,106][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-26 19:24:26,137][__main__][INFO] - No data leakage!
[2025-08-26 19:24:26,138][__main__][INFO] - Model checkpointing every 0.32 epochs.
[2025-08-26 19:24:26,138][__main__][INFO] - Updates per epoch: 6,160, step_scale=0.16666666666666666
[2025-08-26 19:24:32,367][__main__][INFO] - Sample batch:
[2025-08-26 19:24:32,367][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-26 19:24:32,367][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-26 19:24:32,367][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-26 19:24:32,367][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-26 19:24:32,367][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-26 19:24:32,497][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-26 19:24:32,497][__main__][INFO] - Test forward pass:
[2025-08-26 19:24:43,088][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-26 19:24:44,348][__main__][INFO] - Model saving enabled
[2025-08-26 19:24:44,349][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-26 19:24:44,349][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-26 19:24:44,360][__main__][INFO] - InstaNovo training started.
[2025-08-26 19:26:30,640][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 19:26:42,831][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00310] [00:00:12/00:07:40, 1.524s/it]
[2025-08-26 19:26:51,614][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/03080] [00:00:05/00:35:09, 0.687s/it]: train_loss_raw=3.4959, running_loss=3.5974, LR=0.000001
[2025-08-26 19:26:57,440][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/03080] [00:00:11/00:36:07, 0.707s/it]: train_loss_raw=3.2175, running_loss=3.5763, LR=0.000003
[2025-08-26 19:27:03,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/03080] [00:00:17/00:36:32, 0.717s/it]: train_loss_raw=3.0617, running_loss=3.5401, LR=0.000005
[2025-08-26 19:27:09,241][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/03080] [00:00:23/00:36:42, 0.723s/it]: train_loss_raw=2.9878, running_loss=3.5001, LR=0.000006
[2025-08-26 19:27:15,076][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/03080] [00:00:28/00:36:40, 0.724s/it]: train_loss_raw=2.9637, running_loss=3.4600, LR=0.000008
[2025-08-26 19:27:21,044][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/03080] [00:00:34/00:36:46, 0.728s/it]: train_loss_raw=2.9299, running_loss=3.4211, LR=0.000010
[2025-08-26 19:27:26,892][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/03080] [00:00:40/00:36:41, 0.728s/it]: train_loss_raw=2.9018, running_loss=3.3823, LR=0.000011
[2025-08-26 19:27:32,646][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/03080] [00:00:46/00:36:32, 0.727s/it]: train_loss_raw=2.8089, running_loss=3.3411, LR=0.000013
[2025-08-26 19:27:38,651][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/03080] [00:00:52/00:36:34, 0.730s/it]: train_loss_raw=2.7673, running_loss=3.2982, LR=0.000015
[2025-08-26 19:27:44,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/03080] [00:00:58/00:36:23, 0.728s/it]: train_loss_raw=2.7229, running_loss=3.2558, LR=0.000016
[2025-08-26 19:27:50,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/03080] [00:01:04/00:36:20, 0.729s/it]: train_loss_raw=2.7368, running_loss=3.2154, LR=0.000018
[2025-08-26 19:27:56,232][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/03080] [00:01:10/00:36:19, 0.730s/it]: train_loss_raw=2.7275, running_loss=3.1780, LR=0.000020
[2025-08-26 19:28:02,168][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/03080] [00:01:16/00:36:16, 0.731s/it]: train_loss_raw=2.7126, running_loss=3.1428, LR=0.000021
[2025-08-26 19:28:08,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/03080] [00:01:21/00:36:12, 0.732s/it]: train_loss_raw=2.7200, running_loss=3.1092, LR=0.000023
[2025-08-26 19:28:14,001][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/03080] [00:01:27/00:36:07, 0.732s/it]: train_loss_raw=2.7009, running_loss=3.0773, LR=0.000025
[2025-08-26 19:28:19,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/03080] [00:01:33/00:36:00, 0.732s/it]: train_loss_raw=2.6860, running_loss=3.0479, LR=0.000026
[2025-08-26 19:28:25,630][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/03080] [00:01:39/00:35:54, 0.732s/it]: train_loss_raw=2.6790, running_loss=3.0200, LR=0.000028
[2025-08-26 19:28:31,496][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/03080] [00:01:45/00:35:48, 0.732s/it]: train_loss_raw=2.6830, running_loss=2.9945, LR=0.000030
[2025-08-26 19:28:37,246][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/03080] [00:01:51/00:35:40, 0.731s/it]: train_loss_raw=2.6733, running_loss=2.9707, LR=0.000031
[2025-08-26 19:28:42,908][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/03080] [00:01:56/00:35:31, 0.730s/it]: train_loss_raw=2.6854, running_loss=2.9485, LR=0.000033
[2025-08-26 19:28:48,730][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/03080] [00:02:02/00:35:25, 0.730s/it]: train_loss_raw=2.7011, running_loss=2.9288, LR=0.000035
[2025-08-26 19:28:54,626][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/03080] [00:02:08/00:35:20, 0.730s/it]: train_loss_raw=2.6731, running_loss=2.9091, LR=0.000036
[2025-08-26 19:29:00,409][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/03080] [00:02:14/00:35:13, 0.730s/it]: train_loss_raw=2.6611, running_loss=2.8912, LR=0.000038
[2025-08-26 19:29:06,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/03080] [00:02:20/00:35:08, 0.730s/it]: train_loss_raw=2.6804, running_loss=2.8741, LR=0.000040
[2025-08-26 19:29:12,242][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/03080] [00:02:26/00:35:04, 0.731s/it]: train_loss_raw=2.6864, running_loss=2.8593, LR=0.000041
[2025-08-26 19:29:18,139][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/03080] [00:02:32/00:34:59, 0.731s/it]: train_loss_raw=2.6964, running_loss=2.8446, LR=0.000043
[2025-08-26 19:29:23,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/03080] [00:02:37/00:34:53, 0.731s/it]: train_loss_raw=2.6594, running_loss=2.8304, LR=0.000045
[2025-08-26 19:29:29,838][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/03080] [00:02:43/00:34:47, 0.731s/it]: train_loss_raw=2.6847, running_loss=2.8181, LR=0.000046
[2025-08-26 19:29:35,661][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/03080] [00:02:49/00:34:41, 0.731s/it]: train_loss_raw=2.6910, running_loss=2.8071, LR=0.000048
[2025-08-26 19:29:41,580][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/03080] [00:02:55/00:34:36, 0.731s/it]: train_loss_raw=2.6497, running_loss=2.7958, LR=0.000050
[2025-08-26 19:29:47,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/03080] [00:03:01/00:34:30, 0.731s/it]: train_loss_raw=2.6623, running_loss=2.7853, LR=0.000051
[2025-08-26 19:29:53,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/03080] [00:03:07/00:34:24, 0.731s/it]: train_loss_raw=2.6608, running_loss=2.7753, LR=0.000053
[2025-08-26 19:29:59,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/03080] [00:03:13/00:34:19, 0.731s/it]: train_loss_raw=2.6545, running_loss=2.7662, LR=0.000055
[2025-08-26 19:30:05,144][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/03080] [00:03:19/00:34:14, 0.732s/it]: train_loss_raw=2.6617, running_loss=2.7578, LR=0.000056
[2025-08-26 19:30:11,198][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/03080] [00:03:25/00:34:10, 0.732s/it]: train_loss_raw=2.6336, running_loss=2.7504, LR=0.000058
[2025-08-26 19:30:17,239][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/03080] [00:03:31/00:34:06, 0.733s/it]: train_loss_raw=2.6652, running_loss=2.7435, LR=0.000060
[2025-08-26 19:30:23,253][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/03080] [00:03:37/00:34:02, 0.734s/it]: train_loss_raw=2.6447, running_loss=2.7365, LR=0.000061
[2025-08-26 19:30:29,179][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/03080] [00:03:43/00:33:56, 0.734s/it]: train_loss_raw=2.6733, running_loss=2.7304, LR=0.000063
[2025-08-26 19:30:35,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/03080] [00:03:49/00:33:52, 0.734s/it]: train_loss_raw=2.6457, running_loss=2.7233, LR=0.000065
[2025-08-26 19:30:41,134][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/03080] [00:03:55/00:33:46, 0.734s/it]: train_loss_raw=2.6217, running_loss=2.7162, LR=0.000066
[2025-08-26 19:30:47,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/03080] [00:04:01/00:33:42, 0.735s/it]: train_loss_raw=2.6414, running_loss=2.7112, LR=0.000068
[2025-08-26 19:30:52,973][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/03080] [00:04:06/00:33:35, 0.735s/it]: train_loss_raw=2.6348, running_loss=2.7060, LR=0.000070
[2025-08-26 19:30:58,788][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/03080] [00:04:12/00:33:29, 0.734s/it]: train_loss_raw=2.6724, running_loss=2.7012, LR=0.000071
[2025-08-26 19:31:04,589][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/03080] [00:04:18/00:33:23, 0.734s/it]: train_loss_raw=2.6403, running_loss=2.6962, LR=0.000073
[2025-08-26 19:31:10,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/03080] [00:04:24/00:33:16, 0.734s/it]: train_loss_raw=2.6152, running_loss=2.6912, LR=0.000075
[2025-08-26 19:31:16,449][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/03080] [00:04:30/00:33:12, 0.735s/it]: train_loss_raw=2.6776, running_loss=2.6873, LR=0.000076
[2025-08-26 19:31:22,366][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/03080] [00:04:36/00:33:06, 0.735s/it]: train_loss_raw=2.6656, running_loss=2.6838, LR=0.000078
[2025-08-26 19:31:28,451][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/03080] [00:04:42/00:33:02, 0.735s/it]: train_loss_raw=2.6032, running_loss=2.6804, LR=0.000080
[2025-08-26 19:31:34,445][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/03080] [00:04:48/00:32:57, 0.736s/it]: train_loss_raw=2.6435, running_loss=2.6759, LR=0.000081
[2025-08-26 19:31:40,646][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/03080] [00:04:54/00:32:53, 0.736s/it]: train_loss_raw=2.6417, running_loss=2.6725, LR=0.000083
[2025-08-26 19:31:46,885][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/03080] [00:05:00/00:32:49, 0.737s/it]: train_loss_raw=2.6892, running_loss=2.6699, LR=0.000085
[2025-08-26 19:31:52,877][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/03080] [00:05:06/00:32:44, 0.737s/it]: train_loss_raw=2.6550, running_loss=2.6663, LR=0.000086
[2025-08-26 19:31:59,072][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/03080] [00:05:12/00:32:40, 0.738s/it]: train_loss_raw=2.6457, running_loss=2.6640, LR=0.000088
[2025-08-26 19:32:05,244][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/03080] [00:05:19/00:32:36, 0.739s/it]: train_loss_raw=2.5989, running_loss=2.6607, LR=0.000090
[2025-08-26 19:32:11,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/03080] [00:05:25/00:32:32, 0.739s/it]: train_loss_raw=2.6069, running_loss=2.6579, LR=0.000091
[2025-08-26 19:32:17,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/03080] [00:05:31/00:32:29, 0.741s/it]: train_loss_raw=2.6452, running_loss=2.6552, LR=0.000093
[2025-08-26 19:32:23,947][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/03080] [00:05:37/00:32:23, 0.741s/it]: train_loss_raw=2.5862, running_loss=2.6530, LR=0.000095
[2025-08-26 19:32:30,111][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/03080] [00:05:43/00:32:19, 0.741s/it]: train_loss_raw=2.6465, running_loss=2.6496, LR=0.000096
[2025-08-26 19:32:36,338][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/03080] [00:05:50/00:32:15, 0.742s/it]: train_loss_raw=2.6095, running_loss=2.6469, LR=0.000098
[2025-08-26 19:32:42,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/03080] [00:05:56/00:32:10, 0.743s/it]: train_loss_raw=2.5975, running_loss=2.6449, LR=0.000100
[2025-08-26 19:32:48,864][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/03080] [00:06:02/00:32:06, 0.743s/it]: train_loss_raw=2.6042, running_loss=2.6419, LR=0.000100
[2025-08-26 19:32:55,084][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/03080] [00:06:08/00:32:02, 0.744s/it]: train_loss_raw=2.5669, running_loss=2.6379, LR=0.000100
[2025-08-26 19:33:01,389][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/03080] [00:06:15/00:31:58, 0.745s/it]: train_loss_raw=2.5882, running_loss=2.6339, LR=0.000100
[2025-08-26 19:33:07,542][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/03080] [00:06:21/00:31:53, 0.745s/it]: train_loss_raw=2.5949, running_loss=2.6304, LR=0.000100
[2025-08-26 19:33:13,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/03080] [00:06:27/00:31:48, 0.745s/it]: train_loss_raw=2.6183, running_loss=2.6278, LR=0.000100
[2025-08-26 19:33:19,984][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/03080] [00:06:33/00:31:43, 0.746s/it]: train_loss_raw=2.6182, running_loss=2.6261, LR=0.000100
[2025-08-26 19:33:26,100][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/03080] [00:06:39/00:31:38, 0.746s/it]: train_loss_raw=2.5691, running_loss=2.6247, LR=0.000100
[2025-08-26 19:33:32,094][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/03080] [00:06:45/00:31:32, 0.746s/it]: train_loss_raw=2.6325, running_loss=2.6217, LR=0.000100
[2025-08-26 19:33:38,357][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/03080] [00:06:52/00:31:27, 0.747s/it]: train_loss_raw=2.5763, running_loss=2.6169, LR=0.000100
[2025-08-26 19:33:44,593][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/03080] [00:06:58/00:31:23, 0.747s/it]: train_loss_raw=2.5954, running_loss=2.6152, LR=0.000100
[2025-08-26 19:33:50,783][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/03080] [00:07:04/00:31:18, 0.748s/it]: train_loss_raw=2.6017, running_loss=2.6124, LR=0.000100
[2025-08-26 19:33:57,006][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/03080] [00:07:10/00:31:13, 0.748s/it]: train_loss_raw=2.5410, running_loss=2.6085, LR=0.000100
[2025-08-26 19:34:03,281][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/03080] [00:07:17/00:31:08, 0.749s/it]: train_loss_raw=2.5734, running_loss=2.6060, LR=0.000100
[2025-08-26 19:34:09,488][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/03080] [00:07:23/00:31:03, 0.749s/it]: train_loss_raw=2.5607, running_loss=2.6015, LR=0.000100
[2025-08-26 19:34:15,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/03080] [00:07:28/00:30:55, 0.748s/it]: train_loss_raw=2.5135, running_loss=2.5974, LR=0.000100
[2025-08-26 19:34:21,339][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/03080] [00:07:35/00:30:50, 0.749s/it]: train_loss_raw=2.6142, running_loss=2.5948, LR=0.000100
[2025-08-26 19:34:27,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/03080] [00:07:41/00:30:45, 0.749s/it]: train_loss_raw=2.5419, running_loss=2.5916, LR=0.000100
[2025-08-26 19:34:33,669][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/03080] [00:07:47/00:30:40, 0.749s/it]: train_loss_raw=2.4935, running_loss=2.5872, LR=0.000100
[2025-08-26 19:34:39,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/03080] [00:07:53/00:30:33, 0.749s/it]: train_loss_raw=2.5183, running_loss=2.5846, LR=0.000100
[2025-08-26 19:34:45,471][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/03080] [00:07:59/00:30:27, 0.749s/it]: train_loss_raw=2.5260, running_loss=2.5827, LR=0.000100
[2025-08-26 19:34:51,388][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/03080] [00:08:05/00:30:21, 0.749s/it]: train_loss_raw=2.4855, running_loss=2.5780, LR=0.000100
[2025-08-26 19:34:57,303][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/03080] [00:08:11/00:30:14, 0.749s/it]: train_loss_raw=2.5409, running_loss=2.5747, LR=0.000100
[2025-08-26 19:35:03,230][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/03080] [00:08:17/00:30:08, 0.749s/it]: train_loss_raw=2.5419, running_loss=2.5697, LR=0.000100
[2025-08-26 19:35:09,125][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/03080] [00:08:23/00:30:02, 0.749s/it]: train_loss_raw=2.5147, running_loss=2.5664, LR=0.000100
[2025-08-26 19:35:15,014][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/03080] [00:08:28/00:29:56, 0.748s/it]: train_loss_raw=2.4481, running_loss=2.5618, LR=0.000100
[2025-08-26 19:35:20,784][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/03080] [00:08:34/00:29:49, 0.748s/it]: train_loss_raw=2.5035, running_loss=2.5585, LR=0.000100
[2025-08-26 19:35:26,558][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/03080] [00:08:40/00:29:42, 0.748s/it]: train_loss_raw=2.4837, running_loss=2.5549, LR=0.000100
[2025-08-26 19:35:32,494][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/03080] [00:08:46/00:29:36, 0.748s/it]: train_loss_raw=2.5688, running_loss=2.5508, LR=0.000100
[2025-08-26 19:35:38,720][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/03080] [00:08:52/00:29:31, 0.748s/it]: train_loss_raw=2.5090, running_loss=2.5486, LR=0.000100
[2025-08-26 19:35:44,590][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/03080] [00:08:58/00:29:24, 0.748s/it]: train_loss_raw=2.5601, running_loss=2.5457, LR=0.000100
[2025-08-26 19:35:50,565][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/03080] [00:09:04/00:29:18, 0.748s/it]: train_loss_raw=2.4916, running_loss=2.5424, LR=0.000100
[2025-08-26 19:35:56,431][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/03080] [00:09:10/00:29:12, 0.748s/it]: train_loss_raw=2.4556, running_loss=2.5392, LR=0.000100
[2025-08-26 19:36:02,447][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/03080] [00:09:16/00:29:06, 0.748s/it]: train_loss_raw=2.5496, running_loss=2.5371, LR=0.000100
[2025-08-26 19:36:08,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/03080] [00:09:22/00:29:01, 0.748s/it]: train_loss_raw=2.4873, running_loss=2.5357, LR=0.000100
[2025-08-26 19:36:14,667][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/03080] [00:09:28/00:28:55, 0.748s/it]: train_loss_raw=2.5465, running_loss=2.5332, LR=0.000100
[2025-08-26 19:36:20,669][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/03080] [00:09:34/00:28:49, 0.748s/it]: train_loss_raw=2.5039, running_loss=2.5284, LR=0.000100
[2025-08-26 19:36:26,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/03080] [00:09:40/00:28:43, 0.748s/it]: train_loss_raw=2.4879, running_loss=2.5270, LR=0.000100
[2025-08-26 19:36:32,735][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/03080] [00:09:46/00:28:37, 0.748s/it]: train_loss_raw=2.5589, running_loss=2.5265, LR=0.000100
[2025-08-26 19:36:38,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/03080] [00:09:52/00:28:31, 0.748s/it]: train_loss_raw=2.4915, running_loss=2.5226, LR=0.000100
[2025-08-26 19:36:44,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/03080] [00:09:58/00:28:25, 0.748s/it]: train_loss_raw=2.4458, running_loss=2.5212, LR=0.000100
[2025-08-26 19:36:50,496][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/03080] [00:10:04/00:28:19, 0.748s/it]: train_loss_raw=2.4651, running_loss=2.5182, LR=0.000100
[2025-08-26 19:36:56,514][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/03080] [00:10:10/00:28:13, 0.748s/it]: train_loss_raw=2.4912, running_loss=2.5161, LR=0.000100
[2025-08-26 19:37:02,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000824] [Batch 00824/03080] [00:10:16/00:28:06, 0.748s/it]: train_loss_raw=2.4948, running_loss=2.5144, LR=0.000100
[2025-08-26 19:37:07,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000832] [Batch 00832/03080] [00:10:21/00:27:59, 0.747s/it]: train_loss_raw=2.4513, running_loss=2.5110, LR=0.000100
[2025-08-26 19:37:13,916][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/03080] [00:10:27/00:27:54, 0.747s/it]: train_loss_raw=2.4929, running_loss=2.5088, LR=0.000100
[2025-08-26 19:37:19,788][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000848] [Batch 00848/03080] [00:10:33/00:27:47, 0.747s/it]: train_loss_raw=2.4781, running_loss=2.5064, LR=0.000100
[2025-08-26 19:37:25,590][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000856] [Batch 00856/03080] [00:10:39/00:27:41, 0.747s/it]: train_loss_raw=2.4715, running_loss=2.5034, LR=0.000100
[2025-08-26 19:37:31,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/03080] [00:10:45/00:27:34, 0.747s/it]: train_loss_raw=2.4569, running_loss=2.4997, LR=0.000100
[2025-08-26 19:37:37,198][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000872] [Batch 00872/03080] [00:10:51/00:27:28, 0.747s/it]: train_loss_raw=2.4955, running_loss=2.4980, LR=0.000100
[2025-08-26 19:37:43,143][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000880] [Batch 00880/03080] [00:10:57/00:27:22, 0.747s/it]: train_loss_raw=2.5100, running_loss=2.4959, LR=0.000100
[2025-08-26 19:37:49,165][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/03080] [00:11:03/00:27:16, 0.747s/it]: train_loss_raw=2.4853, running_loss=2.4926, LR=0.000100
[2025-08-26 19:37:55,036][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000896] [Batch 00896/03080] [00:11:08/00:27:10, 0.747s/it]: train_loss_raw=2.4666, running_loss=2.4912, LR=0.000100
[2025-08-26 19:38:00,831][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000904] [Batch 00904/03080] [00:11:14/00:27:04, 0.746s/it]: train_loss_raw=2.4754, running_loss=2.4889, LR=0.000100
[2025-08-26 19:38:06,728][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/03080] [00:11:20/00:26:57, 0.746s/it]: train_loss_raw=2.4180, running_loss=2.4839, LR=0.000100
[2025-08-26 19:38:12,673][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000920] [Batch 00920/03080] [00:11:26/00:26:51, 0.746s/it]: train_loss_raw=2.4645, running_loss=2.4806, LR=0.000100
[2025-08-26 19:38:18,341][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000928] [Batch 00928/03080] [00:11:32/00:26:45, 0.746s/it]: train_loss_raw=2.4785, running_loss=2.4796, LR=0.000100
[2025-08-26 19:38:24,294][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/03080] [00:11:38/00:26:39, 0.746s/it]: train_loss_raw=2.3900, running_loss=2.4790, LR=0.000100
[2025-08-26 19:38:30,204][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000944] [Batch 00944/03080] [00:11:44/00:26:33, 0.746s/it]: train_loss_raw=2.4696, running_loss=2.4779, LR=0.000100
[2025-08-26 19:38:36,066][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000952] [Batch 00952/03080] [00:11:49/00:26:26, 0.746s/it]: train_loss_raw=2.4425, running_loss=2.4746, LR=0.000100
[2025-08-26 19:38:42,029][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/03080] [00:11:55/00:26:20, 0.746s/it]: train_loss_raw=2.4094, running_loss=2.4713, LR=0.000100
[2025-08-26 19:38:47,953][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000968] [Batch 00968/03080] [00:12:01/00:26:14, 0.746s/it]: train_loss_raw=2.4999, running_loss=2.4701, LR=0.000100
[2025-08-26 19:38:53,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000976] [Batch 00976/03080] [00:12:07/00:26:08, 0.746s/it]: train_loss_raw=2.4777, running_loss=2.4685, LR=0.000100
[2025-08-26 19:38:59,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/03080] [00:12:13/00:26:02, 0.746s/it]: train_loss_raw=2.4266, running_loss=2.4669, LR=0.000100
[2025-08-26 19:39:05,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000992] [Batch 00992/03080] [00:12:19/00:25:56, 0.746s/it]: train_loss_raw=2.4419, running_loss=2.4652, LR=0.000100
[2025-08-26 19:39:11,660][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001000] [Batch 01000/03080] [00:12:25/00:25:50, 0.746s/it]: train_loss_raw=2.4595, running_loss=2.4627, LR=0.000100
[2025-08-26 19:39:17,562][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/03080] [00:12:31/00:25:44, 0.745s/it]: train_loss_raw=2.4368, running_loss=2.4585, LR=0.000100
[2025-08-26 19:39:23,456][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001016] [Batch 01016/03080] [00:12:37/00:25:38, 0.745s/it]: train_loss_raw=2.3791, running_loss=2.4556, LR=0.000100
[2025-08-26 19:39:29,378][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001024] [Batch 01024/03080] [00:12:43/00:25:32, 0.745s/it]: train_loss_raw=2.4385, running_loss=2.4530, LR=0.000100
[2025-08-26 19:39:35,254][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/03080] [00:12:49/00:25:26, 0.745s/it]: train_loss_raw=2.4180, running_loss=2.4514, LR=0.000100
[2025-08-26 19:39:41,294][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001040] [Batch 01040/03080] [00:12:55/00:25:20, 0.745s/it]: train_loss_raw=2.3695, running_loss=2.4493, LR=0.000100
[2025-08-26 19:39:47,292][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001048] [Batch 01048/03080] [00:13:01/00:25:14, 0.745s/it]: train_loss_raw=2.4086, running_loss=2.4480, LR=0.000100
[2025-08-26 19:39:53,146][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/03080] [00:13:07/00:25:08, 0.745s/it]: train_loss_raw=2.4195, running_loss=2.4446, LR=0.000100
[2025-08-26 19:39:59,089][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001064] [Batch 01064/03080] [00:13:12/00:25:02, 0.745s/it]: train_loss_raw=2.4930, running_loss=2.4444, LR=0.000100
[2025-08-26 19:40:04,958][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001072] [Batch 01072/03080] [00:13:18/00:24:56, 0.745s/it]: train_loss_raw=2.3373, running_loss=2.4406, LR=0.000100
[2025-08-26 19:40:10,888][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/03080] [00:13:24/00:24:50, 0.745s/it]: train_loss_raw=2.3071, running_loss=2.4383, LR=0.000100
[2025-08-26 19:40:16,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001088] [Batch 01088/03080] [00:13:30/00:24:44, 0.745s/it]: train_loss_raw=2.4112, running_loss=2.4366, LR=0.000100
[2025-08-26 19:40:22,811][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001096] [Batch 01096/03080] [00:13:36/00:24:38, 0.745s/it]: train_loss_raw=2.3478, running_loss=2.4356, LR=0.000100
[2025-08-26 19:40:28,603][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/03080] [00:13:42/00:24:32, 0.745s/it]: train_loss_raw=2.4142, running_loss=2.4347, LR=0.000100
[2025-08-26 19:40:34,429][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001112] [Batch 01112/03080] [00:13:48/00:24:25, 0.745s/it]: train_loss_raw=2.3721, running_loss=2.4324, LR=0.000100
[2025-08-26 19:40:40,276][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001120] [Batch 01120/03080] [00:13:54/00:24:19, 0.745s/it]: train_loss_raw=2.4326, running_loss=2.4325, LR=0.000100
[2025-08-26 19:40:46,191][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/03080] [00:14:00/00:24:13, 0.745s/it]: train_loss_raw=2.4616, running_loss=2.4329, LR=0.000100
[2025-08-26 19:40:51,930][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001136] [Batch 01136/03080] [00:14:05/00:24:07, 0.745s/it]: train_loss_raw=2.4396, running_loss=2.4310, LR=0.000100
[2025-08-26 19:40:57,768][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001144] [Batch 01144/03080] [00:14:11/00:24:01, 0.744s/it]: train_loss_raw=2.4557, running_loss=2.4322, LR=0.000100
[2025-08-26 19:41:03,745][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/03080] [00:14:17/00:23:55, 0.744s/it]: train_loss_raw=2.3993, running_loss=2.4300, LR=0.000100
[2025-08-26 19:41:09,549][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001160] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=2.4837, running_loss=2.4292, LR=0.000100
[2025-08-26 19:41:15,428][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001168] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=2.4002, running_loss=2.4275, LR=0.000100
[2025-08-26 19:41:21,432][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/03080] [00:14:35/00:23:37, 0.744s/it]: train_loss_raw=2.4407, running_loss=2.4265, LR=0.000100
[2025-08-26 19:41:27,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001184] [Batch 01184/03080] [00:14:41/00:23:31, 0.744s/it]: train_loss_raw=2.4585, running_loss=2.4264, LR=0.000100
[2025-08-26 19:41:33,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001192] [Batch 01192/03080] [00:14:47/00:23:25, 0.744s/it]: train_loss_raw=2.4129, running_loss=2.4246, LR=0.000100
[2025-08-26 19:41:39,240][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/03080] [00:14:53/00:23:19, 0.744s/it]: train_loss_raw=2.4285, running_loss=2.4233, LR=0.000100
[2025-08-26 19:41:45,032][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001208] [Batch 01208/03080] [00:14:58/00:23:13, 0.744s/it]: train_loss_raw=2.4295, running_loss=2.4217, LR=0.000100
[2025-08-26 19:41:50,859][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001216] [Batch 01216/03080] [00:15:04/00:23:06, 0.744s/it]: train_loss_raw=2.3880, running_loss=2.4194, LR=0.000100
[2025-08-26 19:41:56,824][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/03080] [00:15:10/00:23:00, 0.744s/it]: train_loss_raw=2.3805, running_loss=2.4179, LR=0.000100
[2025-08-26 19:42:02,797][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001232] [Batch 01232/03080] [00:15:16/00:22:55, 0.744s/it]: train_loss_raw=2.4292, running_loss=2.4171, LR=0.000100
[2025-08-26 19:42:08,681][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001240] [Batch 01240/03080] [00:15:22/00:22:48, 0.744s/it]: train_loss_raw=2.4236, running_loss=2.4162, LR=0.000100
[2025-08-26 19:42:14,620][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/03080] [00:15:28/00:22:42, 0.744s/it]: train_loss_raw=2.3841, running_loss=2.4158, LR=0.000100
[2025-08-26 19:42:20,553][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001256] [Batch 01256/03080] [00:15:34/00:22:37, 0.744s/it]: train_loss_raw=2.4408, running_loss=2.4146, LR=0.000100
[2025-08-26 19:42:26,521][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001264] [Batch 01264/03080] [00:15:40/00:22:31, 0.744s/it]: train_loss_raw=2.3997, running_loss=2.4136, LR=0.000100
[2025-08-26 19:42:32,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/03080] [00:15:46/00:22:25, 0.744s/it]: train_loss_raw=2.4142, running_loss=2.4117, LR=0.000100
[2025-08-26 19:42:38,455][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001280] [Batch 01280/03080] [00:15:52/00:22:19, 0.744s/it]: train_loss_raw=2.3479, running_loss=2.4108, LR=0.000100
[2025-08-26 19:42:44,503][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001288] [Batch 01288/03080] [00:15:58/00:22:13, 0.744s/it]: train_loss_raw=2.3537, running_loss=2.4087, LR=0.000100
[2025-08-26 19:42:50,501][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=2.3887, running_loss=2.4060, LR=0.000100
[2025-08-26 19:42:56,377][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001304] [Batch 01304/03080] [00:16:10/00:22:01, 0.744s/it]: train_loss_raw=2.3218, running_loss=2.4049, LR=0.000100
[2025-08-26 19:43:02,027][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001312] [Batch 01312/03080] [00:16:15/00:21:55, 0.744s/it]: train_loss_raw=2.5046, running_loss=2.4062, LR=0.000100
[2025-08-26 19:43:07,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/03080] [00:16:21/00:21:49, 0.744s/it]: train_loss_raw=2.3842, running_loss=2.4034, LR=0.000100
[2025-08-26 19:43:13,995][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001328] [Batch 01328/03080] [00:16:27/00:21:43, 0.744s/it]: train_loss_raw=2.3003, running_loss=2.4006, LR=0.000100
[2025-08-26 19:43:19,919][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001336] [Batch 01336/03080] [00:16:33/00:21:37, 0.744s/it]: train_loss_raw=2.4233, running_loss=2.3992, LR=0.000100
[2025-08-26 19:43:25,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/03080] [00:16:39/00:21:31, 0.744s/it]: train_loss_raw=2.3082, running_loss=2.3968, LR=0.000100
[2025-08-26 19:43:31,799][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001352] [Batch 01352/03080] [00:16:45/00:21:25, 0.744s/it]: train_loss_raw=2.4474, running_loss=2.3959, LR=0.000100
[2025-08-26 19:43:37,782][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001360] [Batch 01360/03080] [00:16:51/00:21:19, 0.744s/it]: train_loss_raw=2.3886, running_loss=2.3946, LR=0.000100
[2025-08-26 19:43:43,833][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/03080] [00:16:57/00:21:13, 0.744s/it]: train_loss_raw=2.4026, running_loss=2.3942, LR=0.000100
[2025-08-26 19:43:49,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001376] [Batch 01376/03080] [00:17:03/00:21:07, 0.744s/it]: train_loss_raw=2.3559, running_loss=2.3945, LR=0.000100
[2025-08-26 19:43:55,317][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001384] [Batch 01384/03080] [00:17:09/00:21:01, 0.744s/it]: train_loss_raw=2.4134, running_loss=2.3943, LR=0.000100
[2025-08-26 19:44:01,272][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/03080] [00:17:15/00:20:55, 0.744s/it]: train_loss_raw=2.3325, running_loss=2.3926, LR=0.000100
[2025-08-26 19:44:07,131][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001400] [Batch 01400/03080] [00:17:21/00:20:49, 0.744s/it]: train_loss_raw=2.3650, running_loss=2.3909, LR=0.000100
[2025-08-26 19:44:12,749][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001408] [Batch 01408/03080] [00:17:26/00:20:42, 0.743s/it]: train_loss_raw=2.4810, running_loss=2.3905, LR=0.000100
[2025-08-26 19:44:18,713][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/03080] [00:17:32/00:20:36, 0.743s/it]: train_loss_raw=2.3777, running_loss=2.3897, LR=0.000100
[2025-08-26 19:44:24,290][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001424] [Batch 01424/03080] [00:17:38/00:20:30, 0.743s/it]: train_loss_raw=2.3208, running_loss=2.3870, LR=0.000100
[2025-08-26 19:44:30,061][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001432] [Batch 01432/03080] [00:17:43/00:20:24, 0.743s/it]: train_loss_raw=2.4016, running_loss=2.3850, LR=0.000100
[2025-08-26 19:44:35,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/03080] [00:17:49/00:20:18, 0.743s/it]: train_loss_raw=2.4090, running_loss=2.3820, LR=0.000100
[2025-08-26 19:44:41,978][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001448] [Batch 01448/03080] [00:17:55/00:20:12, 0.743s/it]: train_loss_raw=2.3868, running_loss=2.3814, LR=0.000100
[2025-08-26 19:44:47,795][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001456] [Batch 01456/03080] [00:18:01/00:20:06, 0.743s/it]: train_loss_raw=2.3744, running_loss=2.3800, LR=0.000100
[2025-08-26 19:44:53,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/03080] [00:18:07/00:20:00, 0.743s/it]: train_loss_raw=2.3745, running_loss=2.3817, LR=0.000100
[2025-08-26 19:44:59,654][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001472] [Batch 01472/03080] [00:18:13/00:19:54, 0.743s/it]: train_loss_raw=2.3542, running_loss=2.3798, LR=0.000100
[2025-08-26 19:45:05,770][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001480] [Batch 01480/03080] [00:18:19/00:19:48, 0.743s/it]: train_loss_raw=2.3437, running_loss=2.3780, LR=0.000100
[2025-08-26 19:45:12,003][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/03080] [00:18:25/00:19:43, 0.743s/it]: train_loss_raw=2.4457, running_loss=2.3771, LR=0.000100
[2025-08-26 19:45:18,073][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001496] [Batch 01496/03080] [00:18:31/00:19:37, 0.743s/it]: train_loss_raw=2.3521, running_loss=2.3746, LR=0.000100
[2025-08-26 19:45:24,159][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001504] [Batch 01504/03080] [00:18:38/00:19:31, 0.743s/it]: train_loss_raw=2.3287, running_loss=2.3728, LR=0.000100
[2025-08-26 19:45:30,270][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/03080] [00:18:44/00:19:25, 0.743s/it]: train_loss_raw=2.2895, running_loss=2.3719, LR=0.000100
[2025-08-26 19:45:36,551][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001520] [Batch 01520/03080] [00:18:50/00:19:20, 0.744s/it]: train_loss_raw=2.4225, running_loss=2.3720, LR=0.000100
[2025-08-26 19:45:42,780][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001528] [Batch 01528/03080] [00:18:56/00:19:14, 0.744s/it]: train_loss_raw=2.3513, running_loss=2.3700, LR=0.000100
[2025-08-26 19:45:48,986][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/03080] [00:19:02/00:19:08, 0.744s/it]: train_loss_raw=2.3297, running_loss=2.3697, LR=0.000100
[2025-08-26 19:45:55,209][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001544] [Batch 01544/03080] [00:19:09/00:19:03, 0.744s/it]: train_loss_raw=2.3531, running_loss=2.3674, LR=0.000100
[2025-08-26 19:46:01,430][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001552] [Batch 01552/03080] [00:19:15/00:18:57, 0.744s/it]: train_loss_raw=2.2794, running_loss=2.3658, LR=0.000100
[2025-08-26 19:46:07,658][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/03080] [00:19:21/00:18:51, 0.745s/it]: train_loss_raw=2.3390, running_loss=2.3652, LR=0.000100
[2025-08-26 19:46:13,887][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001568] [Batch 01568/03080] [00:19:27/00:18:46, 0.745s/it]: train_loss_raw=2.3094, running_loss=2.3649, LR=0.000100
[2025-08-26 19:46:20,088][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001576] [Batch 01576/03080] [00:19:33/00:18:40, 0.745s/it]: train_loss_raw=2.2913, running_loss=2.3610, LR=0.000100
[2025-08-26 19:46:26,345][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/03080] [00:19:40/00:18:34, 0.745s/it]: train_loss_raw=2.3398, running_loss=2.3604, LR=0.000100
[2025-08-26 19:46:32,538][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001592] [Batch 01592/03080] [00:19:46/00:18:28, 0.745s/it]: train_loss_raw=2.2742, running_loss=2.3604, LR=0.000100
[2025-08-26 19:46:38,504][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001600] [Batch 01600/03080] [00:19:52/00:18:22, 0.745s/it]: train_loss_raw=2.3490, running_loss=2.3591, LR=0.000100
[2025-08-26 19:46:44,240][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/03080] [00:19:58/00:18:16, 0.745s/it]: train_loss_raw=2.3737, running_loss=2.3592, LR=0.000100
[2025-08-26 19:46:50,089][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001616] [Batch 01616/03080] [00:20:03/00:18:10, 0.745s/it]: train_loss_raw=2.3691, running_loss=2.3577, LR=0.000100
[2025-08-26 19:46:56,145][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001624] [Batch 01624/03080] [00:20:10/00:18:04, 0.745s/it]: train_loss_raw=2.3778, running_loss=2.3556, LR=0.000100
[2025-08-26 19:47:02,273][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/03080] [00:20:16/00:17:59, 0.745s/it]: train_loss_raw=2.2703, running_loss=2.3541, LR=0.000100
[2025-08-26 19:47:08,431][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001640] [Batch 01640/03080] [00:20:22/00:17:53, 0.745s/it]: train_loss_raw=2.3433, running_loss=2.3525, LR=0.000100
[2025-08-26 19:47:14,656][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001648] [Batch 01648/03080] [00:20:28/00:17:47, 0.745s/it]: train_loss_raw=2.3478, running_loss=2.3511, LR=0.000100
[2025-08-26 19:47:20,184][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/03080] [00:20:34/00:17:41, 0.745s/it]: train_loss_raw=2.3235, running_loss=2.3506, LR=0.000100
[2025-08-26 19:47:26,091][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001664] [Batch 01664/03080] [00:20:39/00:17:35, 0.745s/it]: train_loss_raw=2.2663, running_loss=2.3507, LR=0.000100
[2025-08-26 19:47:31,932][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001672] [Batch 01672/03080] [00:20:45/00:17:29, 0.745s/it]: train_loss_raw=2.2889, running_loss=2.3475, LR=0.000100
[2025-08-26 19:47:38,024][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/03080] [00:20:51/00:17:23, 0.745s/it]: train_loss_raw=2.3208, running_loss=2.3456, LR=0.000100
[2025-08-26 19:47:44,235][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001688] [Batch 01688/03080] [00:20:58/00:17:17, 0.745s/it]: train_loss_raw=2.3205, running_loss=2.3458, LR=0.000100
[2025-08-26 19:47:50,491][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001696] [Batch 01696/03080] [00:21:04/00:17:11, 0.746s/it]: train_loss_raw=2.3145, running_loss=2.3447, LR=0.000100
[2025-08-26 19:47:56,702][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/03080] [00:21:10/00:17:06, 0.746s/it]: train_loss_raw=2.3749, running_loss=2.3425, LR=0.000100
[2025-08-26 19:48:02,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001712] [Batch 01712/03080] [00:21:16/00:17:00, 0.746s/it]: train_loss_raw=2.3027, running_loss=2.3427, LR=0.000100
[2025-08-26 19:48:09,138][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001720] [Batch 01720/03080] [00:21:23/00:16:54, 0.746s/it]: train_loss_raw=2.3669, running_loss=2.3423, LR=0.000100
[2025-08-26 19:48:15,311][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/03080] [00:21:29/00:16:48, 0.746s/it]: train_loss_raw=2.2957, running_loss=2.3410, LR=0.000100
[2025-08-26 19:48:21,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001736] [Batch 01736/03080] [00:21:35/00:16:42, 0.746s/it]: train_loss_raw=2.2708, running_loss=2.3377, LR=0.000100
[2025-08-26 19:48:27,317][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001744] [Batch 01744/03080] [00:21:41/00:16:36, 0.746s/it]: train_loss_raw=2.3057, running_loss=2.3367, LR=0.000100
[2025-08-26 19:48:33,508][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/03080] [00:21:47/00:16:30, 0.746s/it]: train_loss_raw=2.2896, running_loss=2.3371, LR=0.000100
[2025-08-26 19:48:39,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001760] [Batch 01760/03080] [00:21:53/00:16:25, 0.746s/it]: train_loss_raw=2.3672, running_loss=2.3379, LR=0.000100
[2025-08-26 19:48:45,921][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001768] [Batch 01768/03080] [00:21:59/00:16:19, 0.746s/it]: train_loss_raw=2.3176, running_loss=2.3372, LR=0.000100
[2025-08-26 19:48:52,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/03080] [00:22:06/00:16:13, 0.747s/it]: train_loss_raw=2.3365, running_loss=2.3370, LR=0.000100
[2025-08-26 19:48:58,369][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001784] [Batch 01784/03080] [00:22:12/00:16:07, 0.747s/it]: train_loss_raw=2.2977, running_loss=2.3357, LR=0.000100
[2025-08-26 19:49:04,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001792] [Batch 01792/03080] [00:22:18/00:16:02, 0.747s/it]: train_loss_raw=2.3620, running_loss=2.3345, LR=0.000100
[2025-08-26 19:49:10,788][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/03080] [00:22:24/00:15:56, 0.747s/it]: train_loss_raw=2.3446, running_loss=2.3346, LR=0.000100
[2025-08-26 19:49:17,009][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001808] [Batch 01808/03080] [00:22:30/00:15:50, 0.747s/it]: train_loss_raw=2.3574, running_loss=2.3320, LR=0.000100
[2025-08-26 19:49:22,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001816] [Batch 01816/03080] [00:22:36/00:15:44, 0.747s/it]: train_loss_raw=2.2392, running_loss=2.3318, LR=0.000100
[2025-08-26 19:49:28,709][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/03080] [00:22:42/00:15:38, 0.747s/it]: train_loss_raw=2.3184, running_loss=2.3294, LR=0.000100
[2025-08-26 19:49:34,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001832] [Batch 01832/03080] [00:22:48/00:15:32, 0.747s/it]: train_loss_raw=2.3386, running_loss=2.3303, LR=0.000100
[2025-08-26 19:49:40,908][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001840] [Batch 01840/03080] [00:22:54/00:15:26, 0.747s/it]: train_loss_raw=2.3410, running_loss=2.3297, LR=0.000100
[2025-08-26 19:49:47,152][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/03080] [00:23:01/00:15:20, 0.747s/it]: train_loss_raw=2.3354, running_loss=2.3284, LR=0.000100
[2025-08-26 19:49:53,308][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001856] [Batch 01856/03080] [00:23:07/00:15:14, 0.747s/it]: train_loss_raw=2.3452, running_loss=2.3270, LR=0.000100
[2025-08-26 19:49:59,442][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001864] [Batch 01864/03080] [00:23:13/00:15:08, 0.747s/it]: train_loss_raw=2.3250, running_loss=2.3256, LR=0.000100
[2025-08-26 19:50:05,654][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/03080] [00:23:19/00:15:03, 0.748s/it]: train_loss_raw=2.3041, running_loss=2.3252, LR=0.000100
[2025-08-26 19:50:11,866][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001880] [Batch 01880/03080] [00:23:25/00:14:57, 0.748s/it]: train_loss_raw=2.3591, running_loss=2.3242, LR=0.000100
[2025-08-26 19:50:18,035][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001888] [Batch 01888/03080] [00:23:31/00:14:51, 0.748s/it]: train_loss_raw=2.2534, running_loss=2.3223, LR=0.000100
[2025-08-26 19:50:24,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/03080] [00:23:38/00:14:45, 0.748s/it]: train_loss_raw=2.3678, running_loss=2.3208, LR=0.000100
[2025-08-26 19:50:30,474][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001904] [Batch 01904/03080] [00:23:44/00:14:39, 0.748s/it]: train_loss_raw=2.3255, running_loss=2.3196, LR=0.000100
[2025-08-26 19:50:36,701][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001912] [Batch 01912/03080] [00:23:50/00:14:33, 0.748s/it]: train_loss_raw=2.3474, running_loss=2.3180, LR=0.000100
[2025-08-26 19:50:42,824][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=2.3057, running_loss=2.3160, LR=0.000100
[2025-08-26 19:50:48,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001928] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=2.2670, running_loss=2.3148, LR=0.000100
[2025-08-26 19:50:54,589][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001936] [Batch 01936/03080] [00:24:08/00:14:15, 0.748s/it]: train_loss_raw=2.3693, running_loss=2.3152, LR=0.000100
[2025-08-26 19:51:00,802][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=2.3547, running_loss=2.3140, LR=0.000100
[2025-08-26 19:51:06,936][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001952] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=2.2813, running_loss=2.3119, LR=0.000100
[2025-08-26 19:51:13,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001960] [Batch 01960/03080] [00:24:27/00:13:58, 0.749s/it]: train_loss_raw=2.3456, running_loss=2.3105, LR=0.000100
[2025-08-26 19:51:19,427][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=2.3014, running_loss=2.3089, LR=0.000100
[2025-08-26 19:51:25,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001976] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=2.2944, running_loss=2.3083, LR=0.000100
[2025-08-26 19:51:31,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001984] [Batch 01984/03080] [00:24:45/00:13:40, 0.749s/it]: train_loss_raw=2.3364, running_loss=2.3085, LR=0.000100
[2025-08-26 19:51:38,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=2.2768, running_loss=2.3071, LR=0.000100
[2025-08-26 19:51:44,349][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002000] [Batch 02000/03080] [00:24:58/00:13:29, 0.749s/it]: train_loss_raw=2.2813, running_loss=2.3033, LR=0.000100
[2025-08-26 19:51:55,880][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002008] [Batch 02008/03080] [00:25:09/00:13:26, 0.752s/it]: train_loss_raw=2.2809, running_loss=2.3042, LR=0.000100
[2025-08-26 19:52:02,076][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/03080] [00:25:15/00:13:20, 0.752s/it]: train_loss_raw=2.2590, running_loss=2.3038, LR=0.000100
[2025-08-26 19:52:08,279][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002024] [Batch 02024/03080] [00:25:22/00:13:14, 0.752s/it]: train_loss_raw=2.3882, running_loss=2.3027, LR=0.000100
[2025-08-26 19:52:14,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002032] [Batch 02032/03080] [00:25:28/00:13:08, 0.752s/it]: train_loss_raw=2.3574, running_loss=2.3022, LR=0.000100
[2025-08-26 19:52:20,748][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/03080] [00:25:34/00:13:02, 0.752s/it]: train_loss_raw=2.2619, running_loss=2.3001, LR=0.000100
[2025-08-26 19:52:27,025][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002048] [Batch 02048/03080] [00:25:40/00:12:56, 0.752s/it]: train_loss_raw=2.3168, running_loss=2.2999, LR=0.000100
[2025-08-26 19:52:33,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002056] [Batch 02056/03080] [00:25:47/00:12:50, 0.753s/it]: train_loss_raw=2.2506, running_loss=2.2985, LR=0.000100
[2025-08-26 19:52:39,508][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/03080] [00:25:53/00:12:44, 0.753s/it]: train_loss_raw=2.2880, running_loss=2.2984, LR=0.000100
[2025-08-26 19:52:45,748][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002072] [Batch 02072/03080] [00:25:59/00:12:38, 0.753s/it]: train_loss_raw=2.3023, running_loss=2.2977, LR=0.000100
[2025-08-26 19:52:51,886][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002080] [Batch 02080/03080] [00:26:05/00:12:32, 0.753s/it]: train_loss_raw=2.3000, running_loss=2.2936, LR=0.000100
[2025-08-26 19:52:57,660][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/03080] [00:26:11/00:12:26, 0.753s/it]: train_loss_raw=2.2315, running_loss=2.2939, LR=0.000100
[2025-08-26 19:53:03,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002096] [Batch 02096/03080] [00:26:17/00:12:20, 0.753s/it]: train_loss_raw=2.2586, running_loss=2.2935, LR=0.000100
[2025-08-26 19:53:09,659][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002104] [Batch 02104/03080] [00:26:23/00:12:14, 0.753s/it]: train_loss_raw=2.2359, running_loss=2.2914, LR=0.000100
[2025-08-26 19:53:15,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/03080] [00:26:29/00:12:08, 0.753s/it]: train_loss_raw=2.2865, running_loss=2.2900, LR=0.000100
[2025-08-26 19:53:22,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002120] [Batch 02120/03080] [00:26:36/00:12:02, 0.753s/it]: train_loss_raw=2.1941, running_loss=2.2889, LR=0.000100
[2025-08-26 19:53:28,398][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002128] [Batch 02128/03080] [00:26:42/00:11:56, 0.753s/it]: train_loss_raw=2.2092, running_loss=2.2876, LR=0.000100
[2025-08-26 19:53:34,621][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/03080] [00:26:48/00:11:50, 0.753s/it]: train_loss_raw=2.3010, running_loss=2.2861, LR=0.000100
[2025-08-26 19:53:40,795][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002144] [Batch 02144/03080] [00:26:54/00:11:44, 0.753s/it]: train_loss_raw=2.2805, running_loss=2.2857, LR=0.000100
[2025-08-26 19:53:47,049][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002152] [Batch 02152/03080] [00:27:00/00:11:38, 0.753s/it]: train_loss_raw=2.3001, running_loss=2.2834, LR=0.000100
[2025-08-26 19:53:53,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/03080] [00:27:07/00:11:33, 0.753s/it]: train_loss_raw=2.1962, running_loss=2.2821, LR=0.000100
[2025-08-26 19:53:59,405][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002168] [Batch 02168/03080] [00:27:13/00:11:27, 0.753s/it]: train_loss_raw=2.2218, running_loss=2.2803, LR=0.000100
[2025-08-26 19:54:05,600][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002176] [Batch 02176/03080] [00:27:19/00:11:21, 0.753s/it]: train_loss_raw=2.2395, running_loss=2.2787, LR=0.000100
[2025-08-26 19:54:11,815][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/03080] [00:27:25/00:11:15, 0.754s/it]: train_loss_raw=2.2605, running_loss=2.2793, LR=0.000100
[2025-08-26 19:54:18,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002192] [Batch 02192/03080] [00:27:31/00:11:09, 0.754s/it]: train_loss_raw=2.3093, running_loss=2.2790, LR=0.000100
[2025-08-26 19:54:24,123][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002200] [Batch 02200/03080] [00:27:38/00:11:03, 0.754s/it]: train_loss_raw=2.3274, running_loss=2.2785, LR=0.000100
[2025-08-26 19:54:30,313][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/03080] [00:27:44/00:10:57, 0.754s/it]: train_loss_raw=2.2558, running_loss=2.2765, LR=0.000100
[2025-08-26 19:54:36,563][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002216] [Batch 02216/03080] [00:27:50/00:10:51, 0.754s/it]: train_loss_raw=2.2489, running_loss=2.2767, LR=0.000100
[2025-08-26 19:54:42,758][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002224] [Batch 02224/03080] [00:27:56/00:10:45, 0.754s/it]: train_loss_raw=2.2987, running_loss=2.2763, LR=0.000100
[2025-08-26 19:54:48,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/03080] [00:28:02/00:10:39, 0.754s/it]: train_loss_raw=2.2988, running_loss=2.2777, LR=0.000100
[2025-08-26 19:54:55,088][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002240] [Batch 02240/03080] [00:28:08/00:10:33, 0.754s/it]: train_loss_raw=2.2832, running_loss=2.2761, LR=0.000100
[2025-08-26 19:55:01,334][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002248] [Batch 02248/03080] [00:28:15/00:10:27, 0.754s/it]: train_loss_raw=2.3496, running_loss=2.2775, LR=0.000100
[2025-08-26 19:55:07,563][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/03080] [00:28:21/00:10:21, 0.754s/it]: train_loss_raw=2.2788, running_loss=2.2800, LR=0.000100
[2025-08-26 19:55:13,744][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002264] [Batch 02264/03080] [00:28:27/00:10:15, 0.754s/it]: train_loss_raw=2.3045, running_loss=2.2768, LR=0.000100
[2025-08-26 19:55:19,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002272] [Batch 02272/03080] [00:28:33/00:10:09, 0.754s/it]: train_loss_raw=2.2222, running_loss=2.2763, LR=0.000100
[2025-08-26 19:55:26,126][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/03080] [00:28:40/00:10:03, 0.754s/it]: train_loss_raw=2.3175, running_loss=2.2777, LR=0.000100
[2025-08-26 19:55:32,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002288] [Batch 02288/03080] [00:28:46/00:09:57, 0.754s/it]: train_loss_raw=2.1853, running_loss=2.2758, LR=0.000100
[2025-08-26 19:55:38,549][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002296] [Batch 02296/03080] [00:28:52/00:09:51, 0.755s/it]: train_loss_raw=2.2911, running_loss=2.2733, LR=0.000100
[2025-08-26 19:55:44,799][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/03080] [00:28:58/00:09:45, 0.755s/it]: train_loss_raw=2.3054, running_loss=2.2716, LR=0.000100
[2025-08-26 19:55:51,145][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002312] [Batch 02312/03080] [00:29:05/00:09:39, 0.755s/it]: train_loss_raw=2.2378, running_loss=2.2703, LR=0.000100
[2025-08-26 19:55:57,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002320] [Batch 02320/03080] [00:29:11/00:09:33, 0.755s/it]: train_loss_raw=2.2288, running_loss=2.2694, LR=0.000100
[2025-08-26 19:56:03,363][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/03080] [00:29:17/00:09:27, 0.755s/it]: train_loss_raw=2.2658, running_loss=2.2671, LR=0.000100
[2025-08-26 19:56:09,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002336] [Batch 02336/03080] [00:29:23/00:09:21, 0.755s/it]: train_loss_raw=2.2752, running_loss=2.2652, LR=0.000100
[2025-08-26 19:56:15,805][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002344] [Batch 02344/03080] [00:29:29/00:09:15, 0.755s/it]: train_loss_raw=2.3270, running_loss=2.2648, LR=0.000100
[2025-08-26 19:56:21,852][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/03080] [00:29:35/00:09:09, 0.755s/it]: train_loss_raw=2.2668, running_loss=2.2650, LR=0.000100
[2025-08-26 19:56:28,100][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002360] [Batch 02360/03080] [00:29:41/00:09:03, 0.755s/it]: train_loss_raw=2.2724, running_loss=2.2658, LR=0.000100
[2025-08-26 19:56:34,331][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002368] [Batch 02368/03080] [00:29:48/00:08:57, 0.755s/it]: train_loss_raw=2.3043, running_loss=2.2638, LR=0.000100
[2025-08-26 19:56:40,534][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/03080] [00:29:54/00:08:51, 0.755s/it]: train_loss_raw=2.1926, running_loss=2.2608, LR=0.000100
[2025-08-26 19:56:46,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002384] [Batch 02384/03080] [00:30:00/00:08:45, 0.755s/it]: train_loss_raw=2.3053, running_loss=2.2587, LR=0.000100
[2025-08-26 19:56:53,024][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002392] [Batch 02392/03080] [00:30:06/00:08:39, 0.755s/it]: train_loss_raw=2.1631, running_loss=2.2581, LR=0.000100
[2025-08-26 19:56:59,221][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/03080] [00:30:13/00:08:33, 0.755s/it]: train_loss_raw=2.3504, running_loss=2.2582, LR=0.000100
[2025-08-26 19:57:05,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002408] [Batch 02408/03080] [00:30:19/00:08:27, 0.756s/it]: train_loss_raw=2.2718, running_loss=2.2569, LR=0.000100
[2025-08-26 19:57:11,724][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002416] [Batch 02416/03080] [00:30:25/00:08:21, 0.756s/it]: train_loss_raw=2.2237, running_loss=2.2535, LR=0.000100
[2025-08-26 19:57:17,881][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/03080] [00:30:31/00:08:15, 0.756s/it]: train_loss_raw=2.2975, running_loss=2.2541, LR=0.000100
[2025-08-26 19:57:24,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002432] [Batch 02432/03080] [00:30:37/00:08:09, 0.756s/it]: train_loss_raw=2.2325, running_loss=2.2519, LR=0.000100
[2025-08-26 19:57:30,220][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002440] [Batch 02440/03080] [00:30:44/00:08:03, 0.756s/it]: train_loss_raw=2.2953, running_loss=2.2517, LR=0.000100
[2025-08-26 19:57:36,140][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/03080] [00:30:50/00:07:57, 0.756s/it]: train_loss_raw=2.2133, running_loss=2.2504, LR=0.000100
[2025-08-26 19:57:42,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002456] [Batch 02456/03080] [00:30:56/00:07:51, 0.756s/it]: train_loss_raw=2.3032, running_loss=2.2504, LR=0.000100
[2025-08-26 19:57:48,080][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002464] [Batch 02464/03080] [00:31:01/00:07:45, 0.756s/it]: train_loss_raw=2.1867, running_loss=2.2487, LR=0.000100
[2025-08-26 19:57:54,311][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/03080] [00:31:08/00:07:39, 0.756s/it]: train_loss_raw=2.1825, running_loss=2.2465, LR=0.000100
[2025-08-26 19:58:00,193][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002480] [Batch 02480/03080] [00:31:14/00:07:33, 0.756s/it]: train_loss_raw=2.2762, running_loss=2.2478, LR=0.000100
[2025-08-26 19:58:06,043][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002488] [Batch 02488/03080] [00:31:19/00:07:27, 0.756s/it]: train_loss_raw=2.2243, running_loss=2.2461, LR=0.000100
[2025-08-26 19:58:11,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/03080] [00:31:25/00:07:21, 0.756s/it]: train_loss_raw=2.2553, running_loss=2.2453, LR=0.000100
[2025-08-26 19:58:18,038][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002504] [Batch 02504/03080] [00:31:31/00:07:15, 0.756s/it]: train_loss_raw=2.2811, running_loss=2.2455, LR=0.000100
[2025-08-26 19:58:24,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002512] [Batch 02512/03080] [00:31:38/00:07:09, 0.756s/it]: train_loss_raw=2.2657, running_loss=2.2437, LR=0.000100
[2025-08-26 19:58:30,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/03080] [00:31:44/00:07:03, 0.756s/it]: train_loss_raw=2.2932, running_loss=2.2428, LR=0.000100
[2025-08-26 19:58:36,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002528] [Batch 02528/03080] [00:31:50/00:06:57, 0.756s/it]: train_loss_raw=2.2121, running_loss=2.2413, LR=0.000100
[2025-08-26 19:58:42,921][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002536] [Batch 02536/03080] [00:31:56/00:06:51, 0.756s/it]: train_loss_raw=2.1325, running_loss=2.2386, LR=0.000100
[2025-08-26 19:58:48,853][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/03080] [00:32:02/00:06:45, 0.756s/it]: train_loss_raw=2.1864, running_loss=2.2386, LR=0.000100
[2025-08-26 19:58:54,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002552] [Batch 02552/03080] [00:32:08/00:06:39, 0.756s/it]: train_loss_raw=2.2662, running_loss=2.2368, LR=0.000100
[2025-08-26 19:59:01,137][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002560] [Batch 02560/03080] [00:32:15/00:06:33, 0.756s/it]: train_loss_raw=2.1729, running_loss=2.2377, LR=0.000100
[2025-08-26 19:59:07,335][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/03080] [00:32:21/00:06:27, 0.756s/it]: train_loss_raw=2.1644, running_loss=2.2378, LR=0.000100
[2025-08-26 19:59:13,601][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002576] [Batch 02576/03080] [00:32:27/00:06:21, 0.756s/it]: train_loss_raw=2.2171, running_loss=2.2373, LR=0.000100
[2025-08-26 19:59:19,471][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002584] [Batch 02584/03080] [00:32:33/00:06:14, 0.756s/it]: train_loss_raw=2.1879, running_loss=2.2354, LR=0.000100
[2025-08-26 19:59:25,460][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/03080] [00:32:39/00:06:08, 0.756s/it]: train_loss_raw=2.3187, running_loss=2.2370, LR=0.000100
[2025-08-26 19:59:31,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002600] [Batch 02600/03080] [00:32:45/00:06:02, 0.756s/it]: train_loss_raw=2.2955, running_loss=2.2392, LR=0.000100
[2025-08-26 19:59:37,105][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002608] [Batch 02608/03080] [00:32:50/00:05:56, 0.756s/it]: train_loss_raw=2.1757, running_loss=2.2383, LR=0.000100
[2025-08-26 19:59:43,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/03080] [00:32:57/00:05:50, 0.756s/it]: train_loss_raw=2.2367, running_loss=2.2355, LR=0.000100
[2025-08-26 19:59:49,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002624] [Batch 02624/03080] [00:33:03/00:05:44, 0.756s/it]: train_loss_raw=2.1982, running_loss=2.2346, LR=0.000100
[2025-08-26 19:59:55,699][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002632] [Batch 02632/03080] [00:33:09/00:05:38, 0.756s/it]: train_loss_raw=2.1602, running_loss=2.2313, LR=0.000100
[2025-08-26 20:00:01,808][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/03080] [00:33:15/00:05:32, 0.756s/it]: train_loss_raw=2.2386, running_loss=2.2332, LR=0.000100
[2025-08-26 20:00:07,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002648] [Batch 02648/03080] [00:33:21/00:05:26, 0.756s/it]: train_loss_raw=2.1894, running_loss=2.2313, LR=0.000100
[2025-08-26 20:00:13,424][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002656] [Batch 02656/03080] [00:33:27/00:05:20, 0.756s/it]: train_loss_raw=2.1778, running_loss=2.2294, LR=0.000100
[2025-08-26 20:00:19,332][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/03080] [00:33:33/00:05:14, 0.756s/it]: train_loss_raw=2.2456, running_loss=2.2264, LR=0.000100
[2025-08-26 20:00:25,105][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002672] [Batch 02672/03080] [00:33:38/00:05:08, 0.756s/it]: train_loss_raw=2.2522, running_loss=2.2256, LR=0.000100
[2025-08-26 20:00:30,981][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002680] [Batch 02680/03080] [00:33:44/00:05:02, 0.756s/it]: train_loss_raw=2.2705, running_loss=2.2242, LR=0.000100
[2025-08-26 20:00:36,978][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/03080] [00:33:50/00:04:56, 0.756s/it]: train_loss_raw=2.1708, running_loss=2.2235, LR=0.000100
[2025-08-26 20:00:42,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002696] [Batch 02696/03080] [00:33:56/00:04:50, 0.755s/it]: train_loss_raw=2.2563, running_loss=2.2214, LR=0.000100
[2025-08-26 20:00:49,007][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002704] [Batch 02704/03080] [00:34:02/00:04:44, 0.756s/it]: train_loss_raw=2.1433, running_loss=2.2213, LR=0.000100
[2025-08-26 20:00:55,197][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/03080] [00:34:09/00:04:38, 0.756s/it]: train_loss_raw=2.1949, running_loss=2.2211, LR=0.000100
[2025-08-26 20:01:01,431][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002720] [Batch 02720/03080] [00:34:15/00:04:32, 0.756s/it]: train_loss_raw=2.2265, running_loss=2.2203, LR=0.000100
[2025-08-26 20:01:07,604][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002728] [Batch 02728/03080] [00:34:21/00:04:25, 0.756s/it]: train_loss_raw=2.1903, running_loss=2.2211, LR=0.000100
[2025-08-26 20:01:13,782][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/03080] [00:34:27/00:04:19, 0.756s/it]: train_loss_raw=2.2184, running_loss=2.2192, LR=0.000100
[2025-08-26 20:01:19,984][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002744] [Batch 02744/03080] [00:34:33/00:04:13, 0.756s/it]: train_loss_raw=2.2957, running_loss=2.2205, LR=0.000100
[2025-08-26 20:01:25,789][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002752] [Batch 02752/03080] [00:34:39/00:04:07, 0.756s/it]: train_loss_raw=2.2419, running_loss=2.2227, LR=0.000100
[2025-08-26 20:01:31,770][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/03080] [00:34:45/00:04:01, 0.756s/it]: train_loss_raw=2.2579, running_loss=2.2215, LR=0.000100
[2025-08-26 20:01:37,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002768] [Batch 02768/03080] [00:34:51/00:03:55, 0.756s/it]: train_loss_raw=2.1006, running_loss=2.2197, LR=0.000100
[2025-08-26 20:01:43,545][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002776] [Batch 02776/03080] [00:34:57/00:03:49, 0.756s/it]: train_loss_raw=2.2196, running_loss=2.2181, LR=0.000100
[2025-08-26 20:01:49,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/03080] [00:35:03/00:03:43, 0.756s/it]: train_loss_raw=2.1420, running_loss=2.2168, LR=0.000100
[2025-08-26 20:01:55,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002792] [Batch 02792/03080] [00:35:09/00:03:37, 0.755s/it]: train_loss_raw=2.2060, running_loss=2.2151, LR=0.000100
[2025-08-26 20:02:01,277][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002800] [Batch 02800/03080] [00:35:15/00:03:31, 0.755s/it]: train_loss_raw=2.2402, running_loss=2.2170, LR=0.000100
[2025-08-26 20:02:07,448][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/03080] [00:35:21/00:03:25, 0.755s/it]: train_loss_raw=2.1549, running_loss=2.2167, LR=0.000100
[2025-08-26 20:02:13,403][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002816] [Batch 02816/03080] [00:35:27/00:03:19, 0.755s/it]: train_loss_raw=2.1662, running_loss=2.2140, LR=0.000100
[2025-08-26 20:02:19,583][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002824] [Batch 02824/03080] [00:35:33/00:03:13, 0.755s/it]: train_loss_raw=2.2229, running_loss=2.2159, LR=0.000100
[2025-08-26 20:02:25,502][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/03080] [00:35:39/00:03:07, 0.755s/it]: train_loss_raw=2.2446, running_loss=2.2157, LR=0.000100
[2025-08-26 20:02:31,502][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002840] [Batch 02840/03080] [00:35:45/00:03:01, 0.755s/it]: train_loss_raw=2.1724, running_loss=2.2144, LR=0.000100
[2025-08-26 20:02:37,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002848] [Batch 02848/03080] [00:35:51/00:02:55, 0.755s/it]: train_loss_raw=2.1499, running_loss=2.2136, LR=0.000100
[2025-08-26 20:02:43,714][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/03080] [00:35:57/00:02:49, 0.755s/it]: train_loss_raw=2.2066, running_loss=2.2151, LR=0.000100
[2025-08-26 20:02:49,443][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002864] [Batch 02864/03080] [00:36:03/00:02:43, 0.755s/it]: train_loss_raw=2.1563, running_loss=2.2138, LR=0.000100
[2025-08-26 20:02:55,340][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002872] [Batch 02872/03080] [00:36:09/00:02:37, 0.755s/it]: train_loss_raw=2.2750, running_loss=2.2154, LR=0.000100
[2025-08-26 20:03:01,435][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/03080] [00:36:15/00:02:31, 0.755s/it]: train_loss_raw=2.1191, running_loss=2.2123, LR=0.000100
[2025-08-26 20:03:07,620][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002888] [Batch 02888/03080] [00:36:21/00:02:25, 0.755s/it]: train_loss_raw=2.2116, running_loss=2.2096, LR=0.000100
[2025-08-26 20:03:13,836][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002896] [Batch 02896/03080] [00:36:27/00:02:18, 0.755s/it]: train_loss_raw=2.1626, running_loss=2.2070, LR=0.000100
[2025-08-26 20:03:20,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/03080] [00:36:34/00:02:12, 0.756s/it]: train_loss_raw=2.2256, running_loss=2.2071, LR=0.000100
[2025-08-26 20:03:26,227][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002912] [Batch 02912/03080] [00:36:40/00:02:06, 0.756s/it]: train_loss_raw=2.2376, running_loss=2.2060, LR=0.000100
[2025-08-26 20:03:32,243][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002920] [Batch 02920/03080] [00:36:46/00:02:00, 0.756s/it]: train_loss_raw=2.1914, running_loss=2.2055, LR=0.000100
[2025-08-26 20:03:38,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/03080] [00:36:52/00:01:54, 0.756s/it]: train_loss_raw=2.1709, running_loss=2.2061, LR=0.000100
[2025-08-26 20:03:44,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002936] [Batch 02936/03080] [00:36:58/00:01:48, 0.756s/it]: train_loss_raw=2.1533, running_loss=2.2066, LR=0.000100
[2025-08-26 20:03:50,187][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002944] [Batch 02944/03080] [00:37:04/00:01:42, 0.755s/it]: train_loss_raw=2.2524, running_loss=2.2049, LR=0.000100
[2025-08-26 20:03:56,185][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/03080] [00:37:10/00:01:36, 0.755s/it]: train_loss_raw=2.2922, running_loss=2.2052, LR=0.000100
[2025-08-26 20:04:02,384][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002960] [Batch 02960/03080] [00:37:16/00:01:30, 0.755s/it]: train_loss_raw=2.1365, running_loss=2.2032, LR=0.000100
[2025-08-26 20:04:08,582][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002968] [Batch 02968/03080] [00:37:22/00:01:24, 0.756s/it]: train_loss_raw=2.2803, running_loss=2.2022, LR=0.000100
[2025-08-26 20:04:14,713][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/03080] [00:37:28/00:01:18, 0.756s/it]: train_loss_raw=2.1602, running_loss=2.2022, LR=0.000100
[2025-08-26 20:04:20,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002984] [Batch 02984/03080] [00:37:34/00:01:12, 0.756s/it]: train_loss_raw=2.1548, running_loss=2.2008, LR=0.000100
[2025-08-26 20:04:27,069][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002992] [Batch 02992/03080] [00:37:40/00:01:06, 0.756s/it]: train_loss_raw=2.1179, running_loss=2.1989, LR=0.000100
[2025-08-26 20:04:33,225][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/03080] [00:37:47/00:01:00, 0.756s/it]: train_loss_raw=2.1321, running_loss=2.1979, LR=0.000100
[2025-08-26 20:04:39,387][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003008] [Batch 03008/03080] [00:37:53/00:00:54, 0.756s/it]: train_loss_raw=2.2043, running_loss=2.1970, LR=0.000100
[2025-08-26 20:04:45,595][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003016] [Batch 03016/03080] [00:37:59/00:00:48, 0.756s/it]: train_loss_raw=2.2411, running_loss=2.1970, LR=0.000100
[2025-08-26 20:04:51,841][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/03080] [00:38:05/00:00:42, 0.756s/it]: train_loss_raw=2.2241, running_loss=2.1953, LR=0.000100
[2025-08-26 20:04:58,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003032] [Batch 03032/03080] [00:38:12/00:00:36, 0.756s/it]: train_loss_raw=2.1893, running_loss=2.1958, LR=0.000100
[2025-08-26 20:05:04,447][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003040] [Batch 03040/03080] [00:38:18/00:00:30, 0.756s/it]: train_loss_raw=2.1997, running_loss=2.1973, LR=0.000100
[2025-08-26 20:05:10,617][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/03080] [00:38:24/00:00:24, 0.756s/it]: train_loss_raw=2.2791, running_loss=2.1982, LR=0.000100
[2025-08-26 20:05:16,746][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003056] [Batch 03056/03080] [00:38:30/00:00:18, 0.756s/it]: train_loss_raw=2.2013, running_loss=2.1967, LR=0.000100
[2025-08-26 20:05:22,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003064] [Batch 03064/03080] [00:38:36/00:00:12, 0.756s/it]: train_loss_raw=2.2039, running_loss=2.1950, LR=0.000100
[2025-08-26 20:05:29,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/03080] [00:38:43/00:00:06, 0.756s/it]: train_loss_raw=2.1970, running_loss=2.1964, LR=0.000100
[2025-08-26 20:05:35,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003080] [Batch 03080/03080] [00:38:49/00:00:00, 0.756s/it]: train_loss_raw=2.2129, running_loss=2.1965, LR=0.000100
[2025-08-26 20:05:35,919][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 20:05:45,309][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00015/00310] [00:00:09/00:02:52, 0.587s/it]
[2025-08-26 20:05:57,645][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00023/00310] [00:00:21/00:04:18, 0.905s/it]
[2025-08-26 20:06:10,422][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00031/00310] [00:00:34/00:04:59, 1.078s/it]
[2025-08-26 20:06:22,871][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00039/00310] [00:00:46/00:05:16, 1.174s/it]
[2025-08-26 20:06:36,269][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00047/00310] [00:01:00/00:05:29, 1.257s/it]
[2025-08-26 20:06:48,959][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00055/00310] [00:01:13/00:05:31, 1.304s/it]
[2025-08-26 20:07:01,718][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00063/00310] [00:01:25/00:05:29, 1.341s/it]
[2025-08-26 20:07:14,684][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00071/00310] [00:01:38/00:05:26, 1.372s/it]
[2025-08-26 20:07:27,576][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00079/00310] [00:01:51/00:05:21, 1.396s/it]
[2025-08-26 20:07:40,536][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00087/00310] [00:02:04/00:05:14, 1.416s/it]
[2025-08-26 20:07:53,209][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00095/00310] [00:02:17/00:05:06, 1.430s/it]
[2025-08-26 20:08:06,254][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00103/00310] [00:02:30/00:04:57, 1.446s/it]
[2025-08-26 20:08:19,159][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00111/00310] [00:02:43/00:04:48, 1.457s/it]
[2025-08-26 20:08:32,091][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00119/00310] [00:02:56/00:04:38, 1.468s/it]
[2025-08-26 20:08:44,833][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00127/00310] [00:03:08/00:04:28, 1.476s/it]
[2025-08-26 20:08:57,682][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00135/00310] [00:03:21/00:04:18, 1.484s/it]
[2025-08-26 20:09:10,441][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00143/00310] [00:03:34/00:04:07, 1.490s/it]
[2025-08-26 20:09:23,244][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00151/00310] [00:03:47/00:03:56, 1.496s/it]
[2025-08-26 20:09:35,417][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00159/00310] [00:03:59/00:03:44, 1.497s/it]
[2025-08-26 20:09:47,256][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00167/00310] [00:04:11/00:03:32, 1.496s/it]
[2025-08-26 20:10:00,227][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00175/00310] [00:04:24/00:03:21, 1.502s/it]
[2025-08-26 20:10:12,018][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00183/00310] [00:04:36/00:03:09, 1.501s/it]
[2025-08-26 20:10:24,013][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00191/00310] [00:04:48/00:02:57, 1.500s/it]
[2025-08-26 20:10:36,473][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00199/00310] [00:05:00/00:02:45, 1.503s/it]
[2025-08-26 20:10:48,708][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00207/00310] [00:05:12/00:02:33, 1.504s/it]
[2025-08-26 20:11:00,978][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00215/00310] [00:05:25/00:02:21, 1.505s/it]
[2025-08-26 20:11:13,062][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00223/00310] [00:05:37/00:02:09, 1.505s/it]
[2025-08-26 20:11:25,532][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00231/00310] [00:05:49/00:01:57, 1.507s/it]
[2025-08-26 20:11:38,056][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00239/00310] [00:06:02/00:01:45, 1.509s/it]
[2025-08-26 20:11:50,269][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00247/00310] [00:06:14/00:01:33, 1.509s/it]
[2025-08-26 20:12:02,476][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00255/00310] [00:06:26/00:01:21, 1.510s/it]
[2025-08-26 20:12:14,984][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00263/00310] [00:06:39/00:01:09, 1.512s/it]
[2025-08-26 20:12:27,695][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00271/00310] [00:06:51/00:00:57, 1.514s/it]
[2025-08-26 20:12:40,031][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00279/00310] [00:07:04/00:00:45, 1.515s/it]
[2025-08-26 20:12:52,375][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00287/00310] [00:07:16/00:00:33, 1.515s/it]
[2025-08-26 20:13:05,178][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00295/00310] [00:07:29/00:00:21, 1.518s/it]
[2025-08-26 20:13:17,498][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00303/00310] [00:07:41/00:00:09, 1.518s/it]
[2025-08-26 20:13:30,208][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00001/00310] [00:07:54/20:17:20, 237.144s/it]
[2025-08-26 20:13:42,699][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00009/00310] [00:08:06/04:03:23, 48.678s/it]
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.19646, valid_loss=2.65461
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.949
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.008
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.009
[2025-08-26 20:13:42,701][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-26 20:13:42,714][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:46:56, remaining time 22:41:21, 00:46:56 per epoch
[2025-08-26 20:13:48,489][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003088] [Batch 00008/03080] [00:00:05/00:35:07, 0.686s/it]: train_loss_raw=2.2179, running_loss=2.1029, LR=0.000100
[2025-08-26 20:13:54,516][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003096] [Batch 00016/03080] [00:00:11/00:36:44, 0.720s/it]: train_loss_raw=2.1203, running_loss=2.1083, LR=0.000100
[2025-08-26 20:14:00,365][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003104] [Batch 00024/03080] [00:00:17/00:36:50, 0.723s/it]: train_loss_raw=2.1941, running_loss=2.1151, LR=0.000100
[2025-08-26 20:14:06,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003112] [Batch 00032/03080] [00:00:23/00:37:07, 0.731s/it]: train_loss_raw=2.0910, running_loss=2.1186, LR=0.000100
[2025-08-26 20:14:12,850][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003120] [Batch 00040/03080] [00:00:29/00:37:48, 0.746s/it]: train_loss_raw=2.1756, running_loss=2.1249, LR=0.000100
[2025-08-26 20:14:18,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003128] [Batch 00048/03080] [00:00:35/00:37:46, 0.747s/it]: train_loss_raw=2.2179, running_loss=2.1283, LR=0.000100
[2025-08-26 20:14:24,907][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003136] [Batch 00056/03080] [00:00:41/00:37:42, 0.748s/it]: train_loss_raw=2.2209, running_loss=2.1341, LR=0.000100
[2025-08-26 20:14:30,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003144] [Batch 00064/03080] [00:00:47/00:37:32, 0.747s/it]: train_loss_raw=2.1319, running_loss=2.1373, LR=0.000100
[2025-08-26 20:14:36,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003152] [Batch 00072/03080] [00:00:53/00:37:19, 0.744s/it]: train_loss_raw=2.2073, running_loss=2.1418, LR=0.000100
[2025-08-26 20:14:42,436][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003160] [Batch 00080/03080] [00:00:59/00:37:08, 0.743s/it]: train_loss_raw=2.2580, running_loss=2.1442, LR=0.000100
[2025-08-26 20:14:48,419][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003168] [Batch 00088/03080] [00:01:05/00:37:04, 0.743s/it]: train_loss_raw=2.2216, running_loss=2.1497, LR=0.000100
[2025-08-26 20:14:54,443][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003176] [Batch 00096/03080] [00:01:11/00:37:00, 0.744s/it]: train_loss_raw=2.1828, running_loss=2.1520, LR=0.000100
[2025-08-26 20:15:00,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003184] [Batch 00104/03080] [00:01:17/00:36:53, 0.744s/it]: train_loss_raw=2.1878, running_loss=2.1539, LR=0.000100
[2025-08-26 20:15:06,223][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003192] [Batch 00112/03080] [00:01:23/00:36:45, 0.743s/it]: train_loss_raw=2.1518, running_loss=2.1561, LR=0.000100
[2025-08-26 20:15:12,025][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003200] [Batch 00120/03080] [00:01:29/00:36:35, 0.742s/it]: train_loss_raw=2.1828, running_loss=2.1561, LR=0.000100
[2025-08-26 20:15:17,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003208] [Batch 00128/03080] [00:01:34/00:36:28, 0.741s/it]: train_loss_raw=2.2425, running_loss=2.1573, LR=0.000100
[2025-08-26 20:15:23,688][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003216] [Batch 00136/03080] [00:01:40/00:36:19, 0.740s/it]: train_loss_raw=2.2762, running_loss=2.1581, LR=0.000100
[2025-08-26 20:15:29,591][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003224] [Batch 00144/03080] [00:01:46/00:36:13, 0.740s/it]: train_loss_raw=2.0486, running_loss=2.1571, LR=0.000100
[2025-08-26 20:15:35,481][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003232] [Batch 00152/03080] [00:01:52/00:36:06, 0.740s/it]: train_loss_raw=2.2424, running_loss=2.1580, LR=0.000100
[2025-08-26 20:15:41,295][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003240] [Batch 00160/03080] [00:01:58/00:35:58, 0.739s/it]: train_loss_raw=2.1888, running_loss=2.1604, LR=0.000100
[2025-08-26 20:15:47,181][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003248] [Batch 00168/03080] [00:02:04/00:35:52, 0.739s/it]: train_loss_raw=2.2765, running_loss=2.1633, LR=0.000100
[2025-08-26 20:15:53,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003256] [Batch 00176/03080] [00:02:10/00:35:49, 0.740s/it]: train_loss_raw=2.1581, running_loss=2.1643, LR=0.000100
[2025-08-26 20:15:59,194][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003264] [Batch 00184/03080] [00:02:16/00:35:43, 0.740s/it]: train_loss_raw=2.1754, running_loss=2.1627, LR=0.000100
[2025-08-26 20:16:05,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003272] [Batch 00192/03080] [00:02:22/00:35:37, 0.740s/it]: train_loss_raw=2.1356, running_loss=2.1626, LR=0.000100
[2025-08-26 20:16:10,921][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003280] [Batch 00200/03080] [00:02:27/00:35:30, 0.740s/it]: train_loss_raw=2.1127, running_loss=2.1633, LR=0.000100
[2025-08-26 20:16:16,871][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003288] [Batch 00208/03080] [00:02:33/00:35:24, 0.740s/it]: train_loss_raw=2.2441, running_loss=2.1647, LR=0.000100
[2025-08-26 20:16:22,854][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003296] [Batch 00216/03080] [00:02:39/00:35:19, 0.740s/it]: train_loss_raw=2.1719, running_loss=2.1656, LR=0.000100
[2025-08-26 20:16:28,795][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003304] [Batch 00224/03080] [00:02:45/00:35:13, 0.740s/it]: train_loss_raw=2.2074, running_loss=2.1666, LR=0.000100
[2025-08-26 20:16:34,705][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003312] [Batch 00232/03080] [00:02:51/00:35:07, 0.740s/it]: train_loss_raw=2.1149, running_loss=2.1661, LR=0.000100
[2025-08-26 20:16:40,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003320] [Batch 00240/03080] [00:02:57/00:35:01, 0.740s/it]: train_loss_raw=2.1380, running_loss=2.1671, LR=0.000100
[2025-08-26 20:16:46,433][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003328] [Batch 00248/03080] [00:03:03/00:34:54, 0.740s/it]: train_loss_raw=2.1486, running_loss=2.1666, LR=0.000100
[2025-08-26 20:16:52,258][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003336] [Batch 00256/03080] [00:03:09/00:34:47, 0.739s/it]: train_loss_raw=2.1219, running_loss=2.1670, LR=0.000100
[2025-08-26 20:16:58,255][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003344] [Batch 00264/03080] [00:03:15/00:34:42, 0.740s/it]: train_loss_raw=2.1844, running_loss=2.1649, LR=0.000100
[2025-08-26 20:17:04,102][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003352] [Batch 00272/03080] [00:03:21/00:34:36, 0.739s/it]: train_loss_raw=2.1390, running_loss=2.1654, LR=0.000100
[2025-08-26 20:17:09,999][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003360] [Batch 00280/03080] [00:03:26/00:34:29, 0.739s/it]: train_loss_raw=2.1546, running_loss=2.1646, LR=0.000100
[2025-08-26 20:17:16,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003368] [Batch 00288/03080] [00:03:33/00:34:25, 0.740s/it]: train_loss_raw=2.1345, running_loss=2.1646, LR=0.000100
[2025-08-26 20:17:21,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003376] [Batch 00296/03080] [00:03:38/00:34:19, 0.740s/it]: train_loss_raw=2.2278, running_loss=2.1661, LR=0.000100
[2025-08-26 20:17:27,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003384] [Batch 00304/03080] [00:03:44/00:34:14, 0.740s/it]: train_loss_raw=2.1806, running_loss=2.1648, LR=0.000100
[2025-08-26 20:17:33,816][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003392] [Batch 00312/03080] [00:03:50/00:34:07, 0.740s/it]: train_loss_raw=2.1975, running_loss=2.1621, LR=0.000100
[2025-08-26 20:17:39,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003400] [Batch 00320/03080] [00:03:56/00:34:02, 0.740s/it]: train_loss_raw=2.1671, running_loss=2.1635, LR=0.000100
[2025-08-26 20:17:45,810][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003408] [Batch 00328/03080] [00:04:02/00:33:57, 0.740s/it]: train_loss_raw=2.1238, running_loss=2.1637, LR=0.000100
[2025-08-26 20:17:51,872][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003416] [Batch 00336/03080] [00:04:08/00:33:52, 0.741s/it]: train_loss_raw=2.2407, running_loss=2.1665, LR=0.000100
[2025-08-26 20:17:57,868][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003424] [Batch 00344/03080] [00:04:14/00:33:47, 0.741s/it]: train_loss_raw=2.1714, running_loss=2.1666, LR=0.000100
[2025-08-26 20:18:03,877][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003432] [Batch 00352/03080] [00:04:20/00:33:41, 0.741s/it]: train_loss_raw=2.1545, running_loss=2.1677, LR=0.000100
[2025-08-26 20:18:09,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003440] [Batch 00360/03080] [00:04:26/00:33:36, 0.741s/it]: train_loss_raw=2.1269, running_loss=2.1669, LR=0.000100
[2025-08-26 20:18:15,875][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003448] [Batch 00368/03080] [00:04:32/00:33:30, 0.742s/it]: train_loss_raw=2.2258, running_loss=2.1682, LR=0.000100
[2025-08-26 20:18:21,904][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003456] [Batch 00376/03080] [00:04:38/00:33:25, 0.742s/it]: train_loss_raw=2.2065, running_loss=2.1679, LR=0.000100
[2025-08-26 20:18:27,902][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003464] [Batch 00384/03080] [00:04:44/00:33:20, 0.742s/it]: train_loss_raw=2.1590, running_loss=2.1664, LR=0.000100
[2025-08-26 20:18:33,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003472] [Batch 00392/03080] [00:04:50/00:33:15, 0.742s/it]: train_loss_raw=2.1674, running_loss=2.1669, LR=0.000100
[2025-08-26 20:18:39,876][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003480] [Batch 00400/03080] [00:04:56/00:33:09, 0.742s/it]: train_loss_raw=2.1501, running_loss=2.1663, LR=0.000100
[2025-08-26 20:18:45,721][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003488] [Batch 00408/03080] [00:05:02/00:33:02, 0.742s/it]: train_loss_raw=2.0462, running_loss=2.1629, LR=0.000100
[2025-08-26 20:18:51,440][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003496] [Batch 00416/03080] [00:05:08/00:32:55, 0.741s/it]: train_loss_raw=2.1841, running_loss=2.1610, LR=0.000100
[2025-08-26 20:18:57,376][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003504] [Batch 00424/03080] [00:05:14/00:32:49, 0.741s/it]: train_loss_raw=2.1983, running_loss=2.1610, LR=0.000100
[2025-08-26 20:19:03,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003512] [Batch 00432/03080] [00:05:20/00:32:43, 0.741s/it]: train_loss_raw=2.1817, running_loss=2.1603, LR=0.000100
[2025-08-26 20:19:09,052][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003520] [Batch 00440/03080] [00:05:26/00:32:36, 0.741s/it]: train_loss_raw=2.1907, running_loss=2.1599, LR=0.000100
[2025-08-26 20:19:14,977][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003528] [Batch 00448/03080] [00:05:31/00:32:30, 0.741s/it]: train_loss_raw=2.1321, running_loss=2.1601, LR=0.000100
[2025-08-26 20:19:20,891][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003536] [Batch 00456/03080] [00:05:37/00:32:24, 0.741s/it]: train_loss_raw=2.1238, running_loss=2.1566, LR=0.000100
[2025-08-26 20:19:26,873][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003544] [Batch 00464/03080] [00:05:43/00:32:18, 0.741s/it]: train_loss_raw=2.0822, running_loss=2.1556, LR=0.000100
[2025-08-26 20:19:32,951][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003552] [Batch 00472/03080] [00:05:49/00:32:13, 0.741s/it]: train_loss_raw=2.1322, running_loss=2.1549, LR=0.000100
[2025-08-26 20:19:38,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003560] [Batch 00480/03080] [00:05:55/00:32:08, 0.742s/it]: train_loss_raw=2.1124, running_loss=2.1545, LR=0.000100
[2025-08-26 20:19:45,031][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003568] [Batch 00488/03080] [00:06:02/00:32:02, 0.742s/it]: train_loss_raw=2.1506, running_loss=2.1547, LR=0.000100
[2025-08-26 20:19:51,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003576] [Batch 00496/03080] [00:06:08/00:31:57, 0.742s/it]: train_loss_raw=2.1176, running_loss=2.1535, LR=0.000100
[2025-08-26 20:19:57,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003584] [Batch 00504/03080] [00:06:14/00:31:53, 0.743s/it]: train_loss_raw=2.0422, running_loss=2.1535, LR=0.000100
[2025-08-26 20:20:03,397][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003592] [Batch 00512/03080] [00:06:20/00:31:47, 0.743s/it]: train_loss_raw=2.0720, running_loss=2.1519, LR=0.000100
[2025-08-26 20:20:09,352][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003600] [Batch 00520/03080] [00:06:26/00:31:42, 0.743s/it]: train_loss_raw=2.1360, running_loss=2.1517, LR=0.000100
[2025-08-26 20:20:15,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003608] [Batch 00528/03080] [00:06:32/00:31:36, 0.743s/it]: train_loss_raw=2.1832, running_loss=2.1512, LR=0.000100
[2025-08-26 20:20:21,584][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003616] [Batch 00536/03080] [00:06:38/00:31:31, 0.744s/it]: train_loss_raw=2.1792, running_loss=2.1520, LR=0.000100
[2025-08-26 20:20:27,401][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003624] [Batch 00544/03080] [00:06:44/00:31:25, 0.743s/it]: train_loss_raw=2.1031, running_loss=2.1523, LR=0.000100
[2025-08-26 20:20:33,164][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003632] [Batch 00552/03080] [00:06:50/00:31:18, 0.743s/it]: train_loss_raw=2.1406, running_loss=2.1520, LR=0.000100
[2025-08-26 20:20:38,965][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003640] [Batch 00560/03080] [00:06:55/00:31:11, 0.743s/it]: train_loss_raw=2.1338, running_loss=2.1524, LR=0.000100
[2025-08-26 20:20:44,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003648] [Batch 00568/03080] [00:07:01/00:31:05, 0.743s/it]: train_loss_raw=2.1085, running_loss=2.1510, LR=0.000100
[2025-08-26 20:20:50,880][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003656] [Batch 00576/03080] [00:07:07/00:31:00, 0.743s/it]: train_loss_raw=2.1330, running_loss=2.1503, LR=0.000100
[2025-08-26 20:20:56,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003664] [Batch 00584/03080] [00:07:13/00:30:54, 0.743s/it]: train_loss_raw=2.1746, running_loss=2.1516, LR=0.000100
[2025-08-26 20:21:02,737][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003672] [Batch 00592/03080] [00:07:19/00:30:48, 0.743s/it]: train_loss_raw=2.1660, running_loss=2.1517, LR=0.000100
[2025-08-26 20:21:08,772][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003680] [Batch 00600/03080] [00:07:25/00:30:42, 0.743s/it]: train_loss_raw=2.0928, running_loss=2.1511, LR=0.000100
[2025-08-26 20:21:14,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003688] [Batch 00608/03080] [00:07:31/00:30:37, 0.743s/it]: train_loss_raw=2.1576, running_loss=2.1494, LR=0.000100
[2025-08-26 20:21:20,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003696] [Batch 00616/03080] [00:07:37/00:30:31, 0.743s/it]: train_loss_raw=2.0881, running_loss=2.1494, LR=0.000100
[2025-08-26 20:21:26,834][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003704] [Batch 00624/03080] [00:07:43/00:30:25, 0.743s/it]: train_loss_raw=2.1941, running_loss=2.1497, LR=0.000100
[2025-08-26 20:21:32,859][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003712] [Batch 00632/03080] [00:07:49/00:30:19, 0.743s/it]: train_loss_raw=2.1600, running_loss=2.1490, LR=0.000100
[2025-08-26 20:21:38,818][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003720] [Batch 00640/03080] [00:07:55/00:30:14, 0.743s/it]: train_loss_raw=2.1512, running_loss=2.1503, LR=0.000100
[2025-08-26 20:21:44,848][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003728] [Batch 00648/03080] [00:08:01/00:30:08, 0.744s/it]: train_loss_raw=2.1915, running_loss=2.1495, LR=0.000100
[2025-08-26 20:21:50,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003736] [Batch 00656/03080] [00:08:07/00:30:02, 0.744s/it]: train_loss_raw=2.1503, running_loss=2.1467, LR=0.000100
[2025-08-26 20:21:56,761][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003744] [Batch 00664/03080] [00:08:13/00:29:56, 0.744s/it]: train_loss_raw=2.1293, running_loss=2.1445, LR=0.000100
[2025-08-26 20:22:02,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003752] [Batch 00672/03080] [00:08:19/00:29:50, 0.744s/it]: train_loss_raw=2.1457, running_loss=2.1455, LR=0.000100
[2025-08-26 20:22:08,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003760] [Batch 00680/03080] [00:08:25/00:29:44, 0.744s/it]: train_loss_raw=2.1457, running_loss=2.1452, LR=0.000100
[2025-08-26 20:22:14,688][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003768] [Batch 00688/03080] [00:08:31/00:29:39, 0.744s/it]: train_loss_raw=2.0531, running_loss=2.1432, LR=0.000100
[2025-08-26 20:22:20,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003776] [Batch 00696/03080] [00:08:37/00:29:33, 0.744s/it]: train_loss_raw=2.2105, running_loss=2.1402, LR=0.000100
[2025-08-26 20:22:26,757][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003784] [Batch 00704/03080] [00:08:43/00:29:27, 0.744s/it]: train_loss_raw=2.2267, running_loss=2.1393, LR=0.000100
[2025-08-26 20:22:32,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003792] [Batch 00712/03080] [00:08:49/00:29:21, 0.744s/it]: train_loss_raw=2.1214, running_loss=2.1387, LR=0.000100
[2025-08-26 20:22:38,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003800] [Batch 00720/03080] [00:08:55/00:29:15, 0.744s/it]: train_loss_raw=2.1172, running_loss=2.1367, LR=0.000100
[2025-08-26 20:22:44,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003808] [Batch 00728/03080] [00:09:01/00:29:10, 0.744s/it]: train_loss_raw=2.0888, running_loss=2.1365, LR=0.000100
[2025-08-26 20:22:50,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003816] [Batch 00736/03080] [00:09:07/00:29:04, 0.744s/it]: train_loss_raw=2.1127, running_loss=2.1366, LR=0.000100
[2025-08-26 20:22:56,656][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003824] [Batch 00744/03080] [00:09:13/00:28:58, 0.744s/it]: train_loss_raw=2.1521, running_loss=2.1381, LR=0.000100
[2025-08-26 20:23:02,711][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003832] [Batch 00752/03080] [00:09:19/00:28:52, 0.744s/it]: train_loss_raw=2.1017, running_loss=2.1365, LR=0.000100
[2025-08-26 20:23:08,807][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003840] [Batch 00760/03080] [00:09:25/00:28:47, 0.744s/it]: train_loss_raw=2.1414, running_loss=2.1378, LR=0.000100
[2025-08-26 20:23:14,888][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003848] [Batch 00768/03080] [00:09:31/00:28:41, 0.745s/it]: train_loss_raw=2.0736, running_loss=2.1378, LR=0.000100
[2025-08-26 20:23:20,813][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003856] [Batch 00776/03080] [00:09:37/00:28:35, 0.745s/it]: train_loss_raw=2.2038, running_loss=2.1365, LR=0.000100
[2025-08-26 20:23:26,757][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003864] [Batch 00784/03080] [00:09:43/00:28:29, 0.745s/it]: train_loss_raw=2.1394, running_loss=2.1354, LR=0.000100
[2025-08-26 20:23:32,743][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003872] [Batch 00792/03080] [00:09:49/00:28:23, 0.745s/it]: train_loss_raw=2.1127, running_loss=2.1361, LR=0.000100
[2025-08-26 20:23:38,675][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003880] [Batch 00800/03080] [00:09:55/00:28:17, 0.745s/it]: train_loss_raw=2.1955, running_loss=2.1339, LR=0.000100
[2025-08-26 20:23:44,712][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003888] [Batch 00808/03080] [00:10:01/00:28:11, 0.745s/it]: train_loss_raw=2.1857, running_loss=2.1347, LR=0.000100
[2025-08-26 20:23:50,860][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003896] [Batch 00816/03080] [00:10:07/00:28:06, 0.745s/it]: train_loss_raw=2.1388, running_loss=2.1324, LR=0.000100
[2025-08-26 20:23:56,838][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003904] [Batch 00824/03080] [00:10:13/00:28:00, 0.745s/it]: train_loss_raw=2.1521, running_loss=2.1302, LR=0.000100
[2025-08-26 20:24:02,778][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003912] [Batch 00832/03080] [00:10:19/00:27:54, 0.745s/it]: train_loss_raw=2.1746, running_loss=2.1304, LR=0.000100
[2025-08-26 20:24:08,820][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003920] [Batch 00840/03080] [00:10:25/00:27:48, 0.745s/it]: train_loss_raw=2.1336, running_loss=2.1295, LR=0.000100
[2025-08-26 20:24:14,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003928] [Batch 00848/03080] [00:10:31/00:27:42, 0.745s/it]: train_loss_raw=2.0744, running_loss=2.1251, LR=0.000100
[2025-08-26 20:24:20,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003936] [Batch 00856/03080] [00:10:37/00:27:36, 0.745s/it]: train_loss_raw=2.1283, running_loss=2.1244, LR=0.000100
[2025-08-26 20:24:26,670][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003944] [Batch 00864/03080] [00:10:43/00:27:30, 0.745s/it]: train_loss_raw=2.1319, running_loss=2.1211, LR=0.000100
[2025-08-26 20:24:32,662][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003952] [Batch 00872/03080] [00:10:49/00:27:25, 0.745s/it]: train_loss_raw=2.1490, running_loss=2.1228, LR=0.000100
[2025-08-26 20:24:38,585][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003960] [Batch 00880/03080] [00:10:55/00:27:18, 0.745s/it]: train_loss_raw=2.0435, running_loss=2.1234, LR=0.000100
[2025-08-26 20:24:44,612][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003968] [Batch 00888/03080] [00:11:01/00:27:13, 0.745s/it]: train_loss_raw=2.2176, running_loss=2.1253, LR=0.000100
[2025-08-26 20:24:50,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003976] [Batch 00896/03080] [00:11:07/00:27:06, 0.745s/it]: train_loss_raw=2.1973, running_loss=2.1240, LR=0.000100
[2025-08-26 20:24:56,249][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003984] [Batch 00904/03080] [00:11:13/00:27:00, 0.745s/it]: train_loss_raw=2.0044, running_loss=2.1217, LR=0.000100
[2025-08-26 20:25:02,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003992] [Batch 00912/03080] [00:11:19/00:26:54, 0.745s/it]: train_loss_raw=2.1859, running_loss=2.1219, LR=0.000100
[2025-08-26 20:25:08,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004000] [Batch 00920/03080] [00:11:25/00:26:48, 0.745s/it]: train_loss_raw=2.1252, running_loss=2.1210, LR=0.000100
[2025-08-26 20:25:18,473][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004008] [Batch 00928/03080] [00:11:35/00:26:52, 0.749s/it]: train_loss_raw=2.1201, running_loss=2.1206, LR=0.000100
[2025-08-26 20:25:24,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004016] [Batch 00936/03080] [00:11:41/00:26:46, 0.749s/it]: train_loss_raw=2.0964, running_loss=2.1211, LR=0.000100
[2025-08-26 20:25:30,349][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004024] [Batch 00944/03080] [00:11:47/00:26:40, 0.749s/it]: train_loss_raw=2.0549, running_loss=2.1204, LR=0.000100
[2025-08-26 20:25:36,290][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004032] [Batch 00952/03080] [00:11:53/00:26:34, 0.749s/it]: train_loss_raw=2.1386, running_loss=2.1204, LR=0.000100
[2025-08-26 20:25:42,230][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004040] [Batch 00960/03080] [00:11:59/00:26:28, 0.749s/it]: train_loss_raw=2.0916, running_loss=2.1224, LR=0.000100
[2025-08-26 20:25:48,137][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004048] [Batch 00968/03080] [00:12:05/00:26:22, 0.749s/it]: train_loss_raw=2.0232, running_loss=2.1191, LR=0.000100
[2025-08-26 20:25:54,204][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004056] [Batch 00976/03080] [00:12:11/00:26:16, 0.749s/it]: train_loss_raw=2.1102, running_loss=2.1172, LR=0.000100
[2025-08-26 20:26:00,185][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004064] [Batch 00984/03080] [00:12:17/00:26:10, 0.749s/it]: train_loss_raw=2.1143, running_loss=2.1168, LR=0.000100
[2025-08-26 20:26:06,111][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004072] [Batch 00992/03080] [00:12:23/00:26:04, 0.749s/it]: train_loss_raw=2.1015, running_loss=2.1157, LR=0.000100
[2025-08-26 20:26:12,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004080] [Batch 01000/03080] [00:12:29/00:25:58, 0.749s/it]: train_loss_raw=2.1017, running_loss=2.1138, LR=0.000100
[2025-08-26 20:26:18,121][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004088] [Batch 01008/03080] [00:12:35/00:25:52, 0.749s/it]: train_loss_raw=2.0068, running_loss=2.1139, LR=0.000100
[2025-08-26 20:26:24,160][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004096] [Batch 01016/03080] [00:12:41/00:25:46, 0.749s/it]: train_loss_raw=2.0922, running_loss=2.1111, LR=0.000100
[2025-08-26 20:26:30,130][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004104] [Batch 01024/03080] [00:12:47/00:25:40, 0.749s/it]: train_loss_raw=2.0907, running_loss=2.1134, LR=0.000100
[2025-08-26 20:26:36,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004112] [Batch 01032/03080] [00:12:53/00:25:34, 0.749s/it]: train_loss_raw=2.0892, running_loss=2.1111, LR=0.000100
[2025-08-26 20:26:42,159][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004120] [Batch 01040/03080] [00:12:59/00:25:28, 0.749s/it]: train_loss_raw=1.9852, running_loss=2.1098, LR=0.000100
[2025-08-26 20:26:48,081][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004128] [Batch 01048/03080] [00:13:05/00:25:22, 0.749s/it]: train_loss_raw=2.1909, running_loss=2.1102, LR=0.000100
[2025-08-26 20:26:54,072][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004136] [Batch 01056/03080] [00:13:11/00:25:16, 0.749s/it]: train_loss_raw=2.1128, running_loss=2.1095, LR=0.000100
[2025-08-26 20:27:00,035][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004144] [Batch 01064/03080] [00:13:17/00:25:10, 0.749s/it]: train_loss_raw=2.0749, running_loss=2.1111, LR=0.000100
[2025-08-26 20:27:05,997][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004152] [Batch 01072/03080] [00:13:22/00:25:04, 0.749s/it]: train_loss_raw=2.1294, running_loss=2.1101, LR=0.000100
[2025-08-26 20:27:11,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004160] [Batch 01080/03080] [00:13:28/00:24:57, 0.749s/it]: train_loss_raw=2.1082, running_loss=2.1090, LR=0.000100
[2025-08-26 20:27:17,798][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004168] [Batch 01088/03080] [00:13:34/00:24:51, 0.749s/it]: train_loss_raw=2.2257, running_loss=2.1087, LR=0.000100
[2025-08-26 20:27:23,686][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004176] [Batch 01096/03080] [00:13:40/00:24:45, 0.749s/it]: train_loss_raw=2.1546, running_loss=2.1103, LR=0.000100
[2025-08-26 20:27:29,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004184] [Batch 01104/03080] [00:13:46/00:24:39, 0.749s/it]: train_loss_raw=2.0857, running_loss=2.1087, LR=0.000100
[2025-08-26 20:27:35,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004192] [Batch 01112/03080] [00:13:52/00:24:33, 0.749s/it]: train_loss_raw=2.0733, running_loss=2.1101, LR=0.000100
[2025-08-26 20:27:41,657][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004200] [Batch 01120/03080] [00:13:58/00:24:27, 0.749s/it]: train_loss_raw=2.1418, running_loss=2.1112, LR=0.000100
[2025-08-26 20:27:47,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004208] [Batch 01128/03080] [00:14:04/00:24:21, 0.749s/it]: train_loss_raw=2.0955, running_loss=2.1114, LR=0.000100
[2025-08-26 20:27:53,757][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004216] [Batch 01136/03080] [00:14:10/00:24:15, 0.749s/it]: train_loss_raw=2.0534, running_loss=2.1098, LR=0.000100
[2025-08-26 20:27:59,680][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004224] [Batch 01144/03080] [00:14:16/00:24:09, 0.749s/it]: train_loss_raw=2.0717, running_loss=2.1092, LR=0.000100
[2025-08-26 20:28:05,619][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004232] [Batch 01152/03080] [00:14:22/00:24:03, 0.749s/it]: train_loss_raw=2.0954, running_loss=2.1087, LR=0.000100
[2025-08-26 20:28:11,640][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004240] [Batch 01160/03080] [00:14:28/00:23:57, 0.749s/it]: train_loss_raw=2.0104, running_loss=2.1080, LR=0.000100
[2025-08-26 20:28:17,606][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004248] [Batch 01168/03080] [00:14:34/00:23:51, 0.749s/it]: train_loss_raw=2.1421, running_loss=2.1089, LR=0.000100
[2025-08-26 20:28:23,569][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004256] [Batch 01176/03080] [00:14:40/00:23:45, 0.749s/it]: train_loss_raw=2.1144, running_loss=2.1085, LR=0.000100
[2025-08-26 20:28:29,582][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004264] [Batch 01184/03080] [00:14:46/00:23:39, 0.749s/it]: train_loss_raw=2.1477, running_loss=2.1105, LR=0.000100
[2025-08-26 20:28:35,662][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004272] [Batch 01192/03080] [00:14:52/00:23:33, 0.749s/it]: train_loss_raw=2.0242, running_loss=2.1086, LR=0.000100
[2025-08-26 20:28:41,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004280] [Batch 01200/03080] [00:14:58/00:23:27, 0.749s/it]: train_loss_raw=2.1227, running_loss=2.1081, LR=0.000100
[2025-08-26 20:28:47,576][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004288] [Batch 01208/03080] [00:15:04/00:23:21, 0.749s/it]: train_loss_raw=2.0938, running_loss=2.1074, LR=0.000100
[2025-08-26 20:28:53,520][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004296] [Batch 01216/03080] [00:15:10/00:23:15, 0.749s/it]: train_loss_raw=2.1636, running_loss=2.1072, LR=0.000100
[2025-08-26 20:28:59,505][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004304] [Batch 01224/03080] [00:15:16/00:23:09, 0.749s/it]: train_loss_raw=2.0238, running_loss=2.1045, LR=0.000100
[2025-08-26 20:29:05,488][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004312] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=2.1111, running_loss=2.1032, LR=0.000100
[2025-08-26 20:29:11,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004320] [Batch 01240/03080] [00:15:28/00:22:57, 0.749s/it]: train_loss_raw=2.1029, running_loss=2.1025, LR=0.000100
[2025-08-26 20:29:17,339][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004328] [Batch 01248/03080] [00:15:34/00:22:51, 0.749s/it]: train_loss_raw=2.1267, running_loss=2.1004, LR=0.000100
[2025-08-26 20:29:23,440][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004336] [Batch 01256/03080] [00:15:40/00:22:45, 0.749s/it]: train_loss_raw=2.1363, running_loss=2.1016, LR=0.000100
[2025-08-26 20:29:29,412][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004344] [Batch 01264/03080] [00:15:46/00:22:39, 0.749s/it]: train_loss_raw=2.0274, running_loss=2.1005, LR=0.000100
[2025-08-26 20:29:35,420][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004352] [Batch 01272/03080] [00:15:52/00:22:33, 0.749s/it]: train_loss_raw=1.9550, running_loss=2.1004, LR=0.000100
[2025-08-26 20:29:41,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004360] [Batch 01280/03080] [00:15:58/00:22:27, 0.749s/it]: train_loss_raw=2.0692, running_loss=2.0979, LR=0.000100
[2025-08-26 20:29:47,224][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004368] [Batch 01288/03080] [00:16:04/00:22:21, 0.749s/it]: train_loss_raw=2.1267, running_loss=2.0969, LR=0.000100
[2025-08-26 20:29:53,148][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004376] [Batch 01296/03080] [00:16:10/00:22:15, 0.749s/it]: train_loss_raw=2.0746, running_loss=2.0962, LR=0.000100
[2025-08-26 20:29:59,125][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004384] [Batch 01304/03080] [00:16:16/00:22:09, 0.749s/it]: train_loss_raw=1.9546, running_loss=2.0932, LR=0.000100
[2025-08-26 20:30:05,111][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004392] [Batch 01312/03080] [00:16:22/00:22:03, 0.749s/it]: train_loss_raw=2.1237, running_loss=2.0928, LR=0.000100
[2025-08-26 20:30:11,120][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004400] [Batch 01320/03080] [00:16:28/00:21:57, 0.749s/it]: train_loss_raw=2.0232, running_loss=2.0921, LR=0.000100
[2025-08-26 20:30:17,054][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004408] [Batch 01328/03080] [00:16:34/00:21:51, 0.749s/it]: train_loss_raw=2.0477, running_loss=2.0927, LR=0.000100
[2025-08-26 20:30:22,976][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004416] [Batch 01336/03080] [00:16:39/00:21:45, 0.748s/it]: train_loss_raw=2.0888, running_loss=2.0941, LR=0.000100
[2025-08-26 20:30:29,033][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004424] [Batch 01344/03080] [00:16:46/00:21:39, 0.749s/it]: train_loss_raw=2.0711, running_loss=2.0950, LR=0.000100
[2025-08-26 20:30:34,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004432] [Batch 01352/03080] [00:16:51/00:21:33, 0.748s/it]: train_loss_raw=2.1830, running_loss=2.0942, LR=0.000100
[2025-08-26 20:30:40,888][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004440] [Batch 01360/03080] [00:16:57/00:21:27, 0.748s/it]: train_loss_raw=2.0362, running_loss=2.0945, LR=0.000100
[2025-08-26 20:30:46,853][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004448] [Batch 01368/03080] [00:17:03/00:21:21, 0.748s/it]: train_loss_raw=1.9851, running_loss=2.0929, LR=0.000100
[2025-08-26 20:30:52,802][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004456] [Batch 01376/03080] [00:17:09/00:21:15, 0.748s/it]: train_loss_raw=2.0279, running_loss=2.0913, LR=0.000100
[2025-08-26 20:30:58,935][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004464] [Batch 01384/03080] [00:17:15/00:21:09, 0.749s/it]: train_loss_raw=2.0561, running_loss=2.0938, LR=0.000100
[2025-08-26 20:31:05,008][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004472] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=2.0503, running_loss=2.0915, LR=0.000100
[2025-08-26 20:31:10,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004480] [Batch 01400/03080] [00:17:27/00:20:57, 0.749s/it]: train_loss_raw=2.0383, running_loss=2.0908, LR=0.000100
[2025-08-26 20:31:16,883][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004488] [Batch 01408/03080] [00:17:33/00:20:51, 0.748s/it]: train_loss_raw=2.0718, running_loss=2.0890, LR=0.000100
[2025-08-26 20:31:22,725][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004496] [Batch 01416/03080] [00:17:39/00:20:45, 0.748s/it]: train_loss_raw=2.0989, running_loss=2.0886, LR=0.000100
[2025-08-26 20:31:28,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004504] [Batch 01424/03080] [00:17:45/00:20:39, 0.748s/it]: train_loss_raw=2.1031, running_loss=2.0887, LR=0.000100
[2025-08-26 20:31:34,610][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004512] [Batch 01432/03080] [00:17:51/00:20:33, 0.748s/it]: train_loss_raw=2.1087, running_loss=2.0882, LR=0.000100
[2025-08-26 20:31:40,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004520] [Batch 01440/03080] [00:17:57/00:20:27, 0.748s/it]: train_loss_raw=2.1727, running_loss=2.0874, LR=0.000100
[2025-08-26 20:31:46,538][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004528] [Batch 01448/03080] [00:18:03/00:20:21, 0.748s/it]: train_loss_raw=2.1769, running_loss=2.0885, LR=0.000100
[2025-08-26 20:31:52,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004536] [Batch 01456/03080] [00:18:09/00:20:15, 0.748s/it]: train_loss_raw=2.0999, running_loss=2.0870, LR=0.000100
[2025-08-26 20:31:58,477][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004544] [Batch 01464/03080] [00:18:15/00:20:09, 0.748s/it]: train_loss_raw=2.0912, running_loss=2.0869, LR=0.000100
[2025-08-26 20:32:04,360][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004552] [Batch 01472/03080] [00:18:21/00:20:03, 0.748s/it]: train_loss_raw=2.0223, running_loss=2.0879, LR=0.000100
[2025-08-26 20:32:10,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004560] [Batch 01480/03080] [00:18:27/00:19:57, 0.748s/it]: train_loss_raw=2.1554, running_loss=2.0909, LR=0.000100
[2025-08-26 20:32:16,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004568] [Batch 01488/03080] [00:18:33/00:19:51, 0.748s/it]: train_loss_raw=2.1328, running_loss=2.0932, LR=0.000100
[2025-08-26 20:32:22,336][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004576] [Batch 01496/03080] [00:18:39/00:19:45, 0.748s/it]: train_loss_raw=2.2085, running_loss=2.0943, LR=0.000100
[2025-08-26 20:32:28,363][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004584] [Batch 01504/03080] [00:18:45/00:19:39, 0.748s/it]: train_loss_raw=1.9947, running_loss=2.0923, LR=0.000100
[2025-08-26 20:32:34,283][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004592] [Batch 01512/03080] [00:18:51/00:19:33, 0.748s/it]: train_loss_raw=2.0049, running_loss=2.0927, LR=0.000100
[2025-08-26 20:32:40,319][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004600] [Batch 01520/03080] [00:18:57/00:19:27, 0.748s/it]: train_loss_raw=2.0786, running_loss=2.0907, LR=0.000100
[2025-08-26 20:32:46,243][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004608] [Batch 01528/03080] [00:19:03/00:19:21, 0.748s/it]: train_loss_raw=2.0341, running_loss=2.0896, LR=0.000100
[2025-08-26 20:32:52,220][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004616] [Batch 01536/03080] [00:19:09/00:19:15, 0.748s/it]: train_loss_raw=2.0373, running_loss=2.0884, LR=0.000100
[2025-08-26 20:32:58,169][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004624] [Batch 01544/03080] [00:19:15/00:19:09, 0.748s/it]: train_loss_raw=2.0209, running_loss=2.0862, LR=0.000100
[2025-08-26 20:33:04,122][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004632] [Batch 01552/03080] [00:19:21/00:19:03, 0.748s/it]: train_loss_raw=2.0715, running_loss=2.0849, LR=0.000100
[2025-08-26 20:33:10,093][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004640] [Batch 01560/03080] [00:19:27/00:18:57, 0.748s/it]: train_loss_raw=2.0695, running_loss=2.0840, LR=0.000100
[2025-08-26 20:33:16,013][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004648] [Batch 01568/03080] [00:19:33/00:18:51, 0.748s/it]: train_loss_raw=2.0734, running_loss=2.0836, LR=0.000100
[2025-08-26 20:33:22,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004656] [Batch 01576/03080] [00:19:39/00:18:45, 0.748s/it]: train_loss_raw=2.0463, running_loss=2.0818, LR=0.000100
[2025-08-26 20:33:27,866][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004664] [Batch 01584/03080] [00:19:44/00:18:39, 0.748s/it]: train_loss_raw=2.1197, running_loss=2.0804, LR=0.000100
[2025-08-26 20:33:33,778][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004672] [Batch 01592/03080] [00:19:50/00:18:32, 0.748s/it]: train_loss_raw=2.0524, running_loss=2.0795, LR=0.000100
[2025-08-26 20:33:39,679][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004680] [Batch 01600/03080] [00:19:56/00:18:26, 0.748s/it]: train_loss_raw=2.0420, running_loss=2.0779, LR=0.000100
[2025-08-26 20:33:45,589][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004688] [Batch 01608/03080] [00:20:02/00:18:20, 0.748s/it]: train_loss_raw=2.0434, running_loss=2.0789, LR=0.000100
[2025-08-26 20:33:51,576][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004696] [Batch 01616/03080] [00:20:08/00:18:14, 0.748s/it]: train_loss_raw=2.0452, running_loss=2.0782, LR=0.000100
[2025-08-26 20:33:57,389][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004704] [Batch 01624/03080] [00:20:14/00:18:08, 0.748s/it]: train_loss_raw=2.0659, running_loss=2.0798, LR=0.000100
[2025-08-26 20:34:03,394][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004712] [Batch 01632/03080] [00:20:20/00:18:02, 0.748s/it]: train_loss_raw=2.0960, running_loss=2.0786, LR=0.000100
[2025-08-26 20:34:09,479][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004720] [Batch 01640/03080] [00:20:26/00:17:56, 0.748s/it]: train_loss_raw=2.1893, running_loss=2.0777, LR=0.000100
[2025-08-26 20:34:15,574][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004728] [Batch 01648/03080] [00:20:32/00:17:51, 0.748s/it]: train_loss_raw=1.9809, running_loss=2.0774, LR=0.000100
[2025-08-26 20:34:21,541][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004736] [Batch 01656/03080] [00:20:38/00:17:45, 0.748s/it]: train_loss_raw=2.0621, running_loss=2.0780, LR=0.000100
[2025-08-26 20:34:27,475][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004744] [Batch 01664/03080] [00:20:44/00:17:38, 0.748s/it]: train_loss_raw=2.0920, running_loss=2.0765, LR=0.000100
[2025-08-26 20:34:33,411][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004752] [Batch 01672/03080] [00:20:50/00:17:32, 0.748s/it]: train_loss_raw=1.9667, running_loss=2.0758, LR=0.000100
[2025-08-26 20:34:39,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004760] [Batch 01680/03080] [00:20:56/00:17:26, 0.748s/it]: train_loss_raw=2.0507, running_loss=2.0773, LR=0.000100
[2025-08-26 20:34:45,322][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004768] [Batch 01688/03080] [00:21:02/00:17:20, 0.748s/it]: train_loss_raw=2.0499, running_loss=2.0752, LR=0.000100
[2025-08-26 20:34:51,237][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004776] [Batch 01696/03080] [00:21:08/00:17:14, 0.748s/it]: train_loss_raw=2.1027, running_loss=2.0745, LR=0.000100
[2025-08-26 20:34:57,151][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004784] [Batch 01704/03080] [00:21:14/00:17:08, 0.748s/it]: train_loss_raw=2.1094, running_loss=2.0760, LR=0.000100
[2025-08-26 20:35:03,073][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004792] [Batch 01712/03080] [00:21:20/00:17:02, 0.748s/it]: train_loss_raw=1.9624, running_loss=2.0761, LR=0.000100
[2025-08-26 20:35:08,951][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004800] [Batch 01720/03080] [00:21:25/00:16:56, 0.748s/it]: train_loss_raw=2.1023, running_loss=2.0754, LR=0.000100
[2025-08-26 20:35:14,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004808] [Batch 01728/03080] [00:21:31/00:16:50, 0.748s/it]: train_loss_raw=2.0840, running_loss=2.0748, LR=0.000100
[2025-08-26 20:35:20,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004816] [Batch 01736/03080] [00:21:37/00:16:44, 0.748s/it]: train_loss_raw=2.0709, running_loss=2.0727, LR=0.000100
[2025-08-26 20:35:26,771][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004824] [Batch 01744/03080] [00:21:43/00:16:38, 0.748s/it]: train_loss_raw=2.0976, running_loss=2.0752, LR=0.000100
[2025-08-26 20:35:32,736][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004832] [Batch 01752/03080] [00:21:49/00:16:32, 0.748s/it]: train_loss_raw=2.0537, running_loss=2.0742, LR=0.000100
[2025-08-26 20:35:38,657][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004840] [Batch 01760/03080] [00:21:55/00:16:26, 0.748s/it]: train_loss_raw=1.9689, running_loss=2.0742, LR=0.000100
[2025-08-26 20:35:44,588][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004848] [Batch 01768/03080] [00:22:01/00:16:20, 0.748s/it]: train_loss_raw=2.0785, running_loss=2.0733, LR=0.000100
[2025-08-26 20:35:50,600][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004856] [Batch 01776/03080] [00:22:07/00:16:14, 0.748s/it]: train_loss_raw=1.9714, running_loss=2.0708, LR=0.000100
[2025-08-26 20:35:56,659][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004864] [Batch 01784/03080] [00:22:13/00:16:08, 0.748s/it]: train_loss_raw=2.0597, running_loss=2.0681, LR=0.000100
[2025-08-26 20:36:02,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 01792/03080] [00:22:19/00:16:02, 0.748s/it]: train_loss_raw=1.9658, running_loss=2.0687, LR=0.000100
[2025-08-26 20:36:09,015][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004880] [Batch 01800/03080] [00:22:26/00:15:57, 0.748s/it]: train_loss_raw=2.0493, running_loss=2.0682, LR=0.000100
[2025-08-26 20:36:15,286][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004888] [Batch 01808/03080] [00:22:32/00:15:51, 0.748s/it]: train_loss_raw=2.0863, running_loss=2.0681, LR=0.000100
[2025-08-26 20:36:21,432][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 01816/03080] [00:22:38/00:15:45, 0.748s/it]: train_loss_raw=2.0231, running_loss=2.0673, LR=0.000100
[2025-08-26 20:36:27,541][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004904] [Batch 01824/03080] [00:22:44/00:15:39, 0.748s/it]: train_loss_raw=2.0398, running_loss=2.0675, LR=0.000100
[2025-08-26 20:36:33,721][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004912] [Batch 01832/03080] [00:22:50/00:15:33, 0.748s/it]: train_loss_raw=1.9774, running_loss=2.0656, LR=0.000100
[2025-08-26 20:36:39,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 01840/03080] [00:22:56/00:15:27, 0.748s/it]: train_loss_raw=2.1108, running_loss=2.0634, LR=0.000100
[2025-08-26 20:36:46,065][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004928] [Batch 01848/03080] [00:23:03/00:15:22, 0.748s/it]: train_loss_raw=2.0551, running_loss=2.0620, LR=0.000100
[2025-08-26 20:36:52,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004936] [Batch 01856/03080] [00:23:09/00:15:16, 0.749s/it]: train_loss_raw=2.0722, running_loss=2.0605, LR=0.000100
[2025-08-26 20:36:58,331][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 01864/03080] [00:23:15/00:15:10, 0.749s/it]: train_loss_raw=2.0677, running_loss=2.0607, LR=0.000100
[2025-08-26 20:37:04,496][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004952] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=2.1171, running_loss=2.0576, LR=0.000100
[2025-08-26 20:37:10,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004960] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=2.0725, running_loss=2.0569, LR=0.000100
[2025-08-26 20:37:16,391][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 01888/03080] [00:23:33/00:14:52, 0.749s/it]: train_loss_raw=2.0107, running_loss=2.0582, LR=0.000100
[2025-08-26 20:37:22,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004976] [Batch 01896/03080] [00:23:39/00:14:46, 0.749s/it]: train_loss_raw=2.1129, running_loss=2.0594, LR=0.000100
[2025-08-26 20:37:28,217][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004984] [Batch 01904/03080] [00:23:45/00:14:40, 0.749s/it]: train_loss_raw=1.9811, running_loss=2.0578, LR=0.000100
[2025-08-26 20:37:34,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 01912/03080] [00:23:51/00:14:34, 0.749s/it]: train_loss_raw=2.0482, running_loss=2.0563, LR=0.000100
[2025-08-26 20:37:40,297][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005000] [Batch 01920/03080] [00:23:57/00:14:28, 0.749s/it]: train_loss_raw=2.0900, running_loss=2.0594, LR=0.000100
[2025-08-26 20:37:46,189][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005008] [Batch 01928/03080] [00:24:03/00:14:22, 0.749s/it]: train_loss_raw=1.9445, running_loss=2.0606, LR=0.000100
[2025-08-26 20:37:52,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 01936/03080] [00:24:09/00:14:16, 0.749s/it]: train_loss_raw=1.9954, running_loss=2.0591, LR=0.000100
[2025-08-26 20:37:58,138][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005024] [Batch 01944/03080] [00:24:15/00:14:10, 0.749s/it]: train_loss_raw=2.0901, running_loss=2.0610, LR=0.000100
[2025-08-26 20:38:04,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005032] [Batch 01952/03080] [00:24:21/00:14:04, 0.749s/it]: train_loss_raw=2.0437, running_loss=2.0589, LR=0.000100
[2025-08-26 20:38:10,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 01960/03080] [00:24:27/00:13:58, 0.749s/it]: train_loss_raw=2.0719, running_loss=2.0596, LR=0.000100
[2025-08-26 20:38:16,593][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005048] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=2.1272, running_loss=2.0577, LR=0.000100
[2025-08-26 20:38:22,799][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005056] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=2.1673, running_loss=2.0583, LR=0.000100
[2025-08-26 20:38:28,772][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 01984/03080] [00:24:45/00:13:40, 0.749s/it]: train_loss_raw=2.0604, running_loss=2.0576, LR=0.000100
[2025-08-26 20:38:34,792][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005072] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=2.0471, running_loss=2.0551, LR=0.000100
[2025-08-26 20:38:40,796][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005080] [Batch 02000/03080] [00:24:57/00:13:28, 0.749s/it]: train_loss_raw=2.0643, running_loss=2.0560, LR=0.000100
[2025-08-26 20:38:46,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 02008/03080] [00:25:03/00:13:22, 0.749s/it]: train_loss_raw=2.0289, running_loss=2.0547, LR=0.000100
[2025-08-26 20:38:52,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005096] [Batch 02016/03080] [00:25:09/00:13:16, 0.749s/it]: train_loss_raw=2.1028, running_loss=2.0564, LR=0.000100
[2025-08-26 20:38:59,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005104] [Batch 02024/03080] [00:25:16/00:13:10, 0.749s/it]: train_loss_raw=2.0493, running_loss=2.0561, LR=0.000100
[2025-08-26 20:39:05,017][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 02032/03080] [00:25:22/00:13:04, 0.749s/it]: train_loss_raw=2.0818, running_loss=2.0527, LR=0.000100
[2025-08-26 20:39:10,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005120] [Batch 02040/03080] [00:25:27/00:12:58, 0.749s/it]: train_loss_raw=2.0505, running_loss=2.0529, LR=0.000100
[2025-08-26 20:39:17,010][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005128] [Batch 02048/03080] [00:25:34/00:12:52, 0.749s/it]: train_loss_raw=1.9862, running_loss=2.0516, LR=0.000100
[2025-08-26 20:39:22,871][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 02056/03080] [00:25:39/00:12:46, 0.749s/it]: train_loss_raw=2.0630, running_loss=2.0519, LR=0.000100
[2025-08-26 20:39:28,803][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005144] [Batch 02064/03080] [00:25:45/00:12:40, 0.749s/it]: train_loss_raw=1.9578, running_loss=2.0517, LR=0.000100
[2025-08-26 20:39:34,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005152] [Batch 02072/03080] [00:25:51/00:12:34, 0.749s/it]: train_loss_raw=2.0577, running_loss=2.0497, LR=0.000100
[2025-08-26 20:39:40,664][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 02080/03080] [00:25:57/00:12:28, 0.749s/it]: train_loss_raw=2.1061, running_loss=2.0484, LR=0.000100
[2025-08-26 20:39:46,708][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005168] [Batch 02088/03080] [00:26:03/00:12:22, 0.749s/it]: train_loss_raw=2.0066, running_loss=2.0468, LR=0.000100
[2025-08-26 20:39:52,702][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005176] [Batch 02096/03080] [00:26:09/00:12:16, 0.749s/it]: train_loss_raw=2.0413, running_loss=2.0485, LR=0.000100
[2025-08-26 20:39:58,606][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 02104/03080] [00:26:15/00:12:10, 0.749s/it]: train_loss_raw=1.9873, running_loss=2.0501, LR=0.000100
[2025-08-26 20:40:04,637][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005192] [Batch 02112/03080] [00:26:21/00:12:04, 0.749s/it]: train_loss_raw=2.0552, running_loss=2.0479, LR=0.000100
[2025-08-26 20:40:10,673][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005200] [Batch 02120/03080] [00:26:27/00:11:58, 0.749s/it]: train_loss_raw=2.0368, running_loss=2.0468, LR=0.000100
[2025-08-26 20:40:16,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 02128/03080] [00:26:33/00:11:52, 0.749s/it]: train_loss_raw=1.9874, running_loss=2.0476, LR=0.000100
[2025-08-26 20:40:22,622][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005216] [Batch 02136/03080] [00:26:39/00:11:46, 0.749s/it]: train_loss_raw=2.0727, running_loss=2.0485, LR=0.000100
[2025-08-26 20:40:28,535][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005224] [Batch 02144/03080] [00:26:45/00:11:40, 0.749s/it]: train_loss_raw=2.1128, running_loss=2.0473, LR=0.000100
[2025-08-26 20:40:34,459][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 02152/03080] [00:26:51/00:11:34, 0.749s/it]: train_loss_raw=1.9630, running_loss=2.0445, LR=0.000100
[2025-08-26 20:40:40,376][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005240] [Batch 02160/03080] [00:26:57/00:11:28, 0.749s/it]: train_loss_raw=2.0045, running_loss=2.0443, LR=0.000100
[2025-08-26 20:40:46,468][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005248] [Batch 02168/03080] [00:27:03/00:11:22, 0.749s/it]: train_loss_raw=2.0128, running_loss=2.0447, LR=0.000100
[2025-08-26 20:40:52,530][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 02176/03080] [00:27:09/00:11:16, 0.749s/it]: train_loss_raw=2.1140, running_loss=2.0438, LR=0.000100
[2025-08-26 20:40:58,521][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005264] [Batch 02184/03080] [00:27:15/00:11:10, 0.749s/it]: train_loss_raw=2.1075, running_loss=2.0455, LR=0.000100
[2025-08-26 20:41:04,429][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005272] [Batch 02192/03080] [00:27:21/00:11:04, 0.749s/it]: train_loss_raw=2.0684, running_loss=2.0448, LR=0.000100
[2025-08-26 20:41:10,341][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 02200/03080] [00:27:27/00:10:58, 0.749s/it]: train_loss_raw=1.9355, running_loss=2.0433, LR=0.000100
[2025-08-26 20:41:16,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005288] [Batch 02208/03080] [00:27:33/00:10:52, 0.749s/it]: train_loss_raw=1.9933, running_loss=2.0441, LR=0.000100
[2025-08-26 20:41:22,344][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005296] [Batch 02216/03080] [00:27:39/00:10:46, 0.749s/it]: train_loss_raw=2.0717, running_loss=2.0425, LR=0.000100
[2025-08-26 20:41:28,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 02224/03080] [00:27:45/00:10:40, 0.749s/it]: train_loss_raw=2.0172, running_loss=2.0413, LR=0.000100
[2025-08-26 20:41:34,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005312] [Batch 02232/03080] [00:27:51/00:10:34, 0.749s/it]: train_loss_raw=1.9517, running_loss=2.0378, LR=0.000100
[2025-08-26 20:41:40,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005320] [Batch 02240/03080] [00:27:57/00:10:28, 0.749s/it]: train_loss_raw=2.0290, running_loss=2.0368, LR=0.000100
[2025-08-26 20:41:46,222][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 02248/03080] [00:28:03/00:10:22, 0.749s/it]: train_loss_raw=2.1344, running_loss=2.0374, LR=0.000100
[2025-08-26 20:41:52,164][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005336] [Batch 02256/03080] [00:28:09/00:10:16, 0.749s/it]: train_loss_raw=2.0527, running_loss=2.0358, LR=0.000100
[2025-08-26 20:41:58,149][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005344] [Batch 02264/03080] [00:28:15/00:10:10, 0.749s/it]: train_loss_raw=2.0339, running_loss=2.0368, LR=0.000100
[2025-08-26 20:42:04,205][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 02272/03080] [00:28:21/00:10:05, 0.749s/it]: train_loss_raw=2.0682, running_loss=2.0383, LR=0.000100
[2025-08-26 20:42:10,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005360] [Batch 02280/03080] [00:28:27/00:09:59, 0.749s/it]: train_loss_raw=1.9821, running_loss=2.0365, LR=0.000100
[2025-08-26 20:42:16,076][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005368] [Batch 02288/03080] [00:28:33/00:09:52, 0.749s/it]: train_loss_raw=1.9550, running_loss=2.0341, LR=0.000100
[2025-08-26 20:42:22,079][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 02296/03080] [00:28:39/00:09:47, 0.749s/it]: train_loss_raw=1.9915, running_loss=2.0341, LR=0.000100
[2025-08-26 20:42:28,049][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005384] [Batch 02304/03080] [00:28:45/00:09:41, 0.749s/it]: train_loss_raw=1.9786, running_loss=2.0344, LR=0.000100
[2025-08-26 20:42:33,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005392] [Batch 02312/03080] [00:28:50/00:09:34, 0.749s/it]: train_loss_raw=2.0449, running_loss=2.0355, LR=0.000100
[2025-08-26 20:42:39,919][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 02320/03080] [00:28:56/00:09:28, 0.749s/it]: train_loss_raw=2.0556, running_loss=2.0348, LR=0.000100
[2025-08-26 20:42:45,864][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005408] [Batch 02328/03080] [00:29:02/00:09:22, 0.749s/it]: train_loss_raw=2.0980, running_loss=2.0361, LR=0.000100
[2025-08-26 20:42:51,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005416] [Batch 02336/03080] [00:29:08/00:09:16, 0.749s/it]: train_loss_raw=2.0772, running_loss=2.0375, LR=0.000100
[2025-08-26 20:42:57,856][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 02344/03080] [00:29:14/00:09:11, 0.749s/it]: train_loss_raw=2.0568, running_loss=2.0372, LR=0.000100
[2025-08-26 20:43:03,814][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005432] [Batch 02352/03080] [00:29:20/00:09:05, 0.749s/it]: train_loss_raw=2.0836, running_loss=2.0385, LR=0.000100
[2025-08-26 20:43:09,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005440] [Batch 02360/03080] [00:29:26/00:08:59, 0.749s/it]: train_loss_raw=2.0354, running_loss=2.0383, LR=0.000100
[2025-08-26 20:43:15,723][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 02368/03080] [00:29:32/00:08:53, 0.749s/it]: train_loss_raw=2.0668, running_loss=2.0389, LR=0.000100
[2025-08-26 20:43:21,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005456] [Batch 02376/03080] [00:29:38/00:08:47, 0.749s/it]: train_loss_raw=1.9535, running_loss=2.0383, LR=0.000100
[2025-08-26 20:43:27,625][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005464] [Batch 02384/03080] [00:29:44/00:08:41, 0.749s/it]: train_loss_raw=2.0657, running_loss=2.0370, LR=0.000100
[2025-08-26 20:43:33,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 02392/03080] [00:29:50/00:08:35, 0.749s/it]: train_loss_raw=1.9934, running_loss=2.0361, LR=0.000100
[2025-08-26 20:43:39,498][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005480] [Batch 02400/03080] [00:29:56/00:08:29, 0.749s/it]: train_loss_raw=2.0174, running_loss=2.0359, LR=0.000100
[2025-08-26 20:43:45,447][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005488] [Batch 02408/03080] [00:30:02/00:08:23, 0.749s/it]: train_loss_raw=2.0277, running_loss=2.0371, LR=0.000100
[2025-08-26 20:43:51,468][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 02416/03080] [00:30:08/00:08:17, 0.749s/it]: train_loss_raw=1.9085, running_loss=2.0319, LR=0.000100
[2025-08-26 20:43:57,478][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005504] [Batch 02424/03080] [00:30:14/00:08:11, 0.749s/it]: train_loss_raw=2.1328, running_loss=2.0327, LR=0.000100
[2025-08-26 20:44:03,416][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005512] [Batch 02432/03080] [00:30:20/00:08:05, 0.749s/it]: train_loss_raw=2.0401, running_loss=2.0328, LR=0.000100
[2025-08-26 20:44:09,507][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 02440/03080] [00:30:26/00:07:59, 0.749s/it]: train_loss_raw=2.0749, running_loss=2.0335, LR=0.000100
[2025-08-26 20:44:15,428][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005528] [Batch 02448/03080] [00:30:32/00:07:53, 0.749s/it]: train_loss_raw=2.0633, running_loss=2.0322, LR=0.000100
[2025-08-26 20:44:21,344][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005536] [Batch 02456/03080] [00:30:38/00:07:47, 0.749s/it]: train_loss_raw=1.9803, running_loss=2.0331, LR=0.000100
[2025-08-26 20:44:27,264][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 02464/03080] [00:30:44/00:07:41, 0.748s/it]: train_loss_raw=2.0464, running_loss=2.0321, LR=0.000100
[2025-08-26 20:44:33,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005552] [Batch 02472/03080] [00:30:50/00:07:35, 0.748s/it]: train_loss_raw=1.9663, running_loss=2.0323, LR=0.000100
[2025-08-26 20:44:39,248][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005560] [Batch 02480/03080] [00:30:56/00:07:29, 0.748s/it]: train_loss_raw=1.9878, running_loss=2.0321, LR=0.000100
[2025-08-26 20:44:45,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 02488/03080] [00:31:02/00:07:23, 0.748s/it]: train_loss_raw=2.0354, running_loss=2.0314, LR=0.000100
[2025-08-26 20:44:51,178][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005576] [Batch 02496/03080] [00:31:08/00:07:17, 0.748s/it]: train_loss_raw=2.0408, running_loss=2.0301, LR=0.000100
[2025-08-26 20:44:57,133][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005584] [Batch 02504/03080] [00:31:14/00:07:11, 0.748s/it]: train_loss_raw=1.9918, running_loss=2.0280, LR=0.000100
[2025-08-26 20:45:03,124][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 02512/03080] [00:31:20/00:07:05, 0.748s/it]: train_loss_raw=1.9924, running_loss=2.0289, LR=0.000100
[2025-08-26 20:45:09,072][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005600] [Batch 02520/03080] [00:31:26/00:06:59, 0.748s/it]: train_loss_raw=2.0600, running_loss=2.0290, LR=0.000100
[2025-08-26 20:45:14,990][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005608] [Batch 02528/03080] [00:31:31/00:06:53, 0.748s/it]: train_loss_raw=2.0176, running_loss=2.0290, LR=0.000100
[2025-08-26 20:45:20,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 02536/03080] [00:31:37/00:06:47, 0.748s/it]: train_loss_raw=2.0069, running_loss=2.0296, LR=0.000100
[2025-08-26 20:45:26,896][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005624] [Batch 02544/03080] [00:31:43/00:06:41, 0.748s/it]: train_loss_raw=1.9877, running_loss=2.0275, LR=0.000100
[2025-08-26 20:45:32,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005632] [Batch 02552/03080] [00:31:49/00:06:35, 0.748s/it]: train_loss_raw=1.9652, running_loss=2.0253, LR=0.000100
[2025-08-26 20:45:38,825][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 02560/03080] [00:31:55/00:06:29, 0.748s/it]: train_loss_raw=2.0672, running_loss=2.0253, LR=0.000100
[2025-08-26 20:45:44,859][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005648] [Batch 02568/03080] [00:32:01/00:06:23, 0.748s/it]: train_loss_raw=1.9603, running_loss=2.0263, LR=0.000100
[2025-08-26 20:45:50,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005656] [Batch 02576/03080] [00:32:07/00:06:17, 0.748s/it]: train_loss_raw=2.0403, running_loss=2.0263, LR=0.000100
[2025-08-26 20:45:56,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 02584/03080] [00:32:13/00:06:11, 0.748s/it]: train_loss_raw=2.0414, running_loss=2.0254, LR=0.000100
[2025-08-26 20:46:02,792][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005672] [Batch 02592/03080] [00:32:19/00:06:05, 0.748s/it]: train_loss_raw=2.0381, running_loss=2.0236, LR=0.000100
[2025-08-26 20:46:08,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005680] [Batch 02600/03080] [00:32:25/00:05:59, 0.748s/it]: train_loss_raw=2.0655, running_loss=2.0229, LR=0.000100
[2025-08-26 20:46:14,759][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 02608/03080] [00:32:31/00:05:53, 0.748s/it]: train_loss_raw=2.1740, running_loss=2.0237, LR=0.000100
[2025-08-26 20:46:20,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005696] [Batch 02616/03080] [00:32:37/00:05:47, 0.748s/it]: train_loss_raw=2.0484, running_loss=2.0224, LR=0.000100
[2025-08-26 20:46:26,642][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005704] [Batch 02624/03080] [00:32:43/00:05:41, 0.748s/it]: train_loss_raw=1.9629, running_loss=2.0218, LR=0.000100
[2025-08-26 20:46:32,595][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=2.0255, running_loss=2.0229, LR=0.000100
[2025-08-26 20:46:38,516][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005720] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.9479, running_loss=2.0183, LR=0.000100
[2025-08-26 20:46:44,438][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005728] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=2.0199, running_loss=2.0180, LR=0.000100
[2025-08-26 20:46:50,428][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=1.9620, running_loss=2.0166, LR=0.000100
[2025-08-26 20:46:56,394][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005744] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=1.9558, running_loss=2.0180, LR=0.000100
[2025-08-26 20:47:02,326][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005752] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=1.9691, running_loss=2.0180, LR=0.000100
[2025-08-26 20:47:08,234][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 02680/03080] [00:33:25/00:04:59, 0.748s/it]: train_loss_raw=1.9937, running_loss=2.0186, LR=0.000100
[2025-08-26 20:47:14,153][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005768] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=2.0565, running_loss=2.0187, LR=0.000100
[2025-08-26 20:47:20,080][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005776] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=2.0566, running_loss=2.0193, LR=0.000100
[2025-08-26 20:47:26,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=1.9392, running_loss=2.0195, LR=0.000100
[2025-08-26 20:47:32,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005792] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=1.9479, running_loss=2.0163, LR=0.000100
[2025-08-26 20:47:38,449][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005800] [Batch 02720/03080] [00:33:55/00:04:29, 0.748s/it]: train_loss_raw=2.0157, running_loss=2.0166, LR=0.000100
[2025-08-26 20:47:44,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 02728/03080] [00:34:01/00:04:23, 0.748s/it]: train_loss_raw=2.0334, running_loss=2.0127, LR=0.000100
[2025-08-26 20:47:50,579][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005816] [Batch 02736/03080] [00:34:07/00:04:17, 0.748s/it]: train_loss_raw=2.0213, running_loss=2.0139, LR=0.000100
[2025-08-26 20:47:56,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005824] [Batch 02744/03080] [00:34:13/00:04:11, 0.748s/it]: train_loss_raw=1.9372, running_loss=2.0153, LR=0.000100
[2025-08-26 20:48:02,348][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 02752/03080] [00:34:19/00:04:05, 0.748s/it]: train_loss_raw=2.1114, running_loss=2.0163, LR=0.000100
[2025-08-26 20:48:08,303][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005840] [Batch 02760/03080] [00:34:25/00:03:59, 0.748s/it]: train_loss_raw=1.9843, running_loss=2.0166, LR=0.000100
[2025-08-26 20:48:14,279][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005848] [Batch 02768/03080] [00:34:31/00:03:53, 0.748s/it]: train_loss_raw=2.0715, running_loss=2.0147, LR=0.000100
[2025-08-26 20:48:20,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 02776/03080] [00:34:37/00:03:47, 0.748s/it]: train_loss_raw=2.1326, running_loss=2.0163, LR=0.000100
[2025-08-26 20:48:26,342][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005864] [Batch 02784/03080] [00:34:43/00:03:41, 0.748s/it]: train_loss_raw=2.0228, running_loss=2.0162, LR=0.000100
[2025-08-26 20:48:32,237][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005872] [Batch 02792/03080] [00:34:49/00:03:35, 0.748s/it]: train_loss_raw=2.0202, running_loss=2.0178, LR=0.000100
[2025-08-26 20:48:38,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 02800/03080] [00:34:55/00:03:29, 0.748s/it]: train_loss_raw=2.0186, running_loss=2.0175, LR=0.000100
[2025-08-26 20:48:44,028][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005888] [Batch 02808/03080] [00:35:01/00:03:23, 0.748s/it]: train_loss_raw=1.9225, running_loss=2.0191, LR=0.000100
[2025-08-26 20:48:49,940][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005896] [Batch 02816/03080] [00:35:06/00:03:17, 0.748s/it]: train_loss_raw=1.9812, running_loss=2.0176, LR=0.000100
[2025-08-26 20:48:55,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 02824/03080] [00:35:12/00:03:11, 0.748s/it]: train_loss_raw=1.9847, running_loss=2.0177, LR=0.000100
[2025-08-26 20:49:01,956][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005912] [Batch 02832/03080] [00:35:18/00:03:05, 0.748s/it]: train_loss_raw=2.0154, running_loss=2.0173, LR=0.000100
[2025-08-26 20:49:07,794][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005920] [Batch 02840/03080] [00:35:24/00:02:59, 0.748s/it]: train_loss_raw=2.0626, running_loss=2.0196, LR=0.000100
[2025-08-26 20:49:13,692][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=2.0810, running_loss=2.0179, LR=0.000100
[2025-08-26 20:49:19,670][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005936] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=2.0137, running_loss=2.0179, LR=0.000100
[2025-08-26 20:49:25,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005944] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=2.0654, running_loss=2.0178, LR=0.000100
[2025-08-26 20:49:31,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 02872/03080] [00:35:48/00:02:35, 0.748s/it]: train_loss_raw=2.0051, running_loss=2.0158, LR=0.000100
[2025-08-26 20:49:37,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005960] [Batch 02880/03080] [00:35:54/00:02:29, 0.748s/it]: train_loss_raw=1.9453, running_loss=2.0129, LR=0.000100
[2025-08-26 20:49:43,519][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005968] [Batch 02888/03080] [00:36:00/00:02:23, 0.748s/it]: train_loss_raw=1.9658, running_loss=2.0142, LR=0.000100
[2025-08-26 20:49:49,436][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 02896/03080] [00:36:06/00:02:17, 0.748s/it]: train_loss_raw=2.0304, running_loss=2.0129, LR=0.000100
[2025-08-26 20:49:55,324][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005984] [Batch 02904/03080] [00:36:12/00:02:11, 0.748s/it]: train_loss_raw=1.9732, running_loss=2.0148, LR=0.000100
[2025-08-26 20:50:01,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005992] [Batch 02912/03080] [00:36:18/00:02:05, 0.748s/it]: train_loss_raw=2.0697, running_loss=2.0138, LR=0.000100
[2025-08-26 20:50:07,114][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 02920/03080] [00:36:24/00:01:59, 0.748s/it]: train_loss_raw=1.9795, running_loss=2.0122, LR=0.000100
[2025-08-26 20:50:17,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006008] [Batch 02928/03080] [00:36:34/00:01:53, 0.750s/it]: train_loss_raw=2.0686, running_loss=2.0143, LR=0.000100
[2025-08-26 20:50:23,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006016] [Batch 02936/03080] [00:36:40/00:01:47, 0.750s/it]: train_loss_raw=2.0449, running_loss=2.0126, LR=0.000100
[2025-08-26 20:50:29,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 02944/03080] [00:36:46/00:01:41, 0.750s/it]: train_loss_raw=2.0399, running_loss=2.0116, LR=0.000100
[2025-08-26 20:50:35,652][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006032] [Batch 02952/03080] [00:36:52/00:01:35, 0.750s/it]: train_loss_raw=2.0586, running_loss=2.0131, LR=0.000100
[2025-08-26 20:50:41,634][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006040] [Batch 02960/03080] [00:36:58/00:01:29, 0.750s/it]: train_loss_raw=1.9953, running_loss=2.0119, LR=0.000100
[2025-08-26 20:50:47,646][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 02968/03080] [00:37:04/00:01:23, 0.750s/it]: train_loss_raw=1.9746, running_loss=2.0093, LR=0.000100
[2025-08-26 20:50:53,599][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006056] [Batch 02976/03080] [00:37:10/00:01:17, 0.750s/it]: train_loss_raw=1.9444, running_loss=2.0078, LR=0.000100
[2025-08-26 20:50:59,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006064] [Batch 02984/03080] [00:37:16/00:01:11, 0.750s/it]: train_loss_raw=1.9659, running_loss=2.0081, LR=0.000100
[2025-08-26 20:51:05,571][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 02992/03080] [00:37:22/00:01:05, 0.750s/it]: train_loss_raw=1.9578, running_loss=2.0065, LR=0.000100
[2025-08-26 20:51:11,579][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006080] [Batch 03000/03080] [00:37:28/00:00:59, 0.750s/it]: train_loss_raw=2.0147, running_loss=2.0035, LR=0.000100
[2025-08-26 20:51:17,490][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006088] [Batch 03008/03080] [00:37:34/00:00:53, 0.749s/it]: train_loss_raw=2.0975, running_loss=2.0028, LR=0.000100
[2025-08-26 20:51:23,462][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 03016/03080] [00:37:40/00:00:47, 0.749s/it]: train_loss_raw=2.1139, running_loss=2.0048, LR=0.000100
[2025-08-26 20:51:29,475][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006104] [Batch 03024/03080] [00:37:46/00:00:41, 0.749s/it]: train_loss_raw=1.9195, running_loss=2.0079, LR=0.000100
[2025-08-26 20:51:35,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006112] [Batch 03032/03080] [00:37:52/00:00:35, 0.749s/it]: train_loss_raw=1.9906, running_loss=2.0064, LR=0.000100
[2025-08-26 20:51:41,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 03040/03080] [00:37:58/00:00:29, 0.749s/it]: train_loss_raw=1.9550, running_loss=2.0081, LR=0.000100
[2025-08-26 20:51:47,340][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006128] [Batch 03048/03080] [00:38:04/00:00:23, 0.749s/it]: train_loss_raw=2.0060, running_loss=2.0066, LR=0.000100
[2025-08-26 20:51:53,337][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006136] [Batch 03056/03080] [00:38:10/00:00:17, 0.749s/it]: train_loss_raw=2.0871, running_loss=2.0075, LR=0.000100
[2025-08-26 20:51:59,291][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 03064/03080] [00:38:16/00:00:11, 0.749s/it]: train_loss_raw=2.0915, running_loss=2.0077, LR=0.000100
[2025-08-26 20:52:05,225][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006152] [Batch 03072/03080] [00:38:22/00:00:05, 0.749s/it]: train_loss_raw=2.0226, running_loss=2.0061, LR=0.000100
[2025-08-26 20:52:15,892][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006160] [Batch 03080/03080] [00:38:32/00:00:00, 0.751s/it]: train_loss_raw=2.0103, running_loss=2.0067, LR=0.000100
[2025-08-26 20:52:16,390][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-26 20:52:28,713][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00007/00310] [00:00:12/00:07:45, 1.540s/it]
[2025-08-26 20:52:41,139][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00015/00310] [00:00:24/00:07:34, 1.547s/it]
[2025-08-26 20:52:53,766][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00023/00310] [00:00:37/00:07:25, 1.557s/it]
[2025-08-26 20:53:07,061][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00031/00310] [00:00:50/00:07:20, 1.583s/it]
[2025-08-26 20:53:20,208][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00039/00310] [00:01:03/00:07:10, 1.595s/it]
[2025-08-26 20:53:33,355][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00047/00310] [00:01:16/00:07:00, 1.603s/it]
[2025-08-26 20:53:46,431][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00055/00310] [00:01:30/00:06:48, 1.608s/it]
[2025-08-26 20:53:59,442][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00063/00310] [00:01:43/00:06:36, 1.610s/it]
[2025-08-26 20:54:12,534][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00071/00310] [00:01:56/00:06:23, 1.613s/it]
[2025-08-26 20:54:25,730][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00079/00310] [00:02:09/00:06:11, 1.617s/it]
[2025-08-26 20:54:38,723][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00087/00310] [00:02:22/00:05:59, 1.617s/it]
[2025-08-26 20:54:51,948][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00095/00310] [00:02:35/00:05:46, 1.620s/it]
[2025-08-26 20:55:05,046][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00103/00310] [00:02:48/00:05:34, 1.622s/it]
[2025-08-26 20:55:18,097][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00111/00310] [00:03:01/00:05:21, 1.622s/it]
[2025-08-26 20:55:30,806][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00119/00310] [00:03:14/00:05:07, 1.620s/it]
[2025-08-26 20:55:43,675][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00127/00310] [00:03:27/00:04:54, 1.619s/it]
[2025-08-26 20:55:56,430][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00135/00310] [00:03:40/00:04:41, 1.618s/it]
[2025-08-26 20:56:09,271][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00143/00310] [00:03:52/00:04:28, 1.617s/it]
[2025-08-26 20:56:21,436][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00151/00310] [00:04:05/00:04:14, 1.612s/it]
[2025-08-26 20:56:33,426][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00159/00310] [00:04:17/00:04:00, 1.606s/it]
[2025-08-26 20:56:46,385][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00167/00310] [00:04:29/00:03:48, 1.607s/it]
[2025-08-26 20:56:58,334][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00175/00310] [00:04:41/00:03:34, 1.602s/it]
[2025-08-26 20:57:10,460][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00183/00310] [00:04:54/00:03:21, 1.598s/it]
[2025-08-26 20:57:23,146][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00191/00310] [00:05:06/00:03:08, 1.598s/it]
[2025-08-26 20:57:35,473][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00199/00310] [00:05:19/00:02:55, 1.595s/it]
[2025-08-26 20:57:47,660][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00207/00310] [00:05:31/00:02:42, 1.593s/it]
[2025-08-26 20:57:59,811][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00215/00310] [00:05:43/00:02:29, 1.590s/it]
[2025-08-26 20:58:12,339][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00223/00310] [00:05:55/00:02:16, 1.589s/it]
[2025-08-26 20:58:25,399][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00231/00310] [00:06:09/00:02:04, 1.591s/it]
[2025-08-26 20:58:37,245][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00239/00310] [00:06:20/00:01:51, 1.587s/it]
[2025-08-26 20:58:49,221][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00247/00310] [00:06:32/00:01:38, 1.584s/it]
[2025-08-26 20:59:01,725][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00255/00310] [00:06:45/00:01:25, 1.583s/it]
[2025-08-26 20:59:14,497][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00263/00310] [00:06:58/00:01:12, 1.584s/it]
[2025-08-26 20:59:26,790][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00271/00310] [00:07:10/00:01:00, 1.582s/it]
[2025-08-26 20:59:39,274][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00279/00310] [00:07:22/00:00:47, 1.582s/it]
[2025-08-26 20:59:51,885][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00287/00310] [00:07:35/00:00:34, 1.582s/it]
[2025-08-26 21:00:04,188][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00295/00310] [00:07:47/00:00:22, 1.580s/it]
[2025-08-26 21:00:16,932][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00303/00310] [00:08:00/00:00:09, 1.581s/it]
[2025-08-26 21:00:26,506][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.00666, valid_loss=2.52684
[2025-08-26 21:00:26,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-26 21:00:26,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.926
[2025-08-26 21:00:26,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.010
[2025-08-26 21:00:26,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.010
[2025-08-26 21:00:26,508][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-26 21:00:26,524][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:33:40, remaining time 21:51:25, 00:46:50 per epoch
[2025-08-26 21:00:32,194][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006168] [Batch 00008/03080] [00:00:05/00:34:34, 0.675s/it]: train_loss_raw=1.9730, running_loss=1.9837, LR=0.000100
[2025-08-26 21:00:38,115][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006176] [Batch 00016/03080] [00:00:11/00:36:08, 0.708s/it]: train_loss_raw=1.9906, running_loss=1.9820, LR=0.000100
[2025-08-26 21:00:44,082][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006184] [Batch 00024/03080] [00:00:17/00:36:41, 0.720s/it]: train_loss_raw=2.0670, running_loss=1.9849, LR=0.000100
[2025-08-26 21:00:50,068][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006192] [Batch 00032/03080] [00:00:23/00:36:57, 0.727s/it]: train_loss_raw=2.0160, running_loss=1.9842, LR=0.000100
[2025-08-26 21:00:56,036][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006200] [Batch 00040/03080] [00:00:29/00:37:02, 0.731s/it]: train_loss_raw=1.9491, running_loss=1.9859, LR=0.000100
[2025-08-26 21:01:01,994][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006208] [Batch 00048/03080] [00:00:35/00:37:03, 0.733s/it]: train_loss_raw=2.0357, running_loss=1.9861, LR=0.000100
[2025-08-26 21:01:07,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006216] [Batch 00056/03080] [00:00:41/00:36:56, 0.733s/it]: train_loss_raw=2.0622, running_loss=1.9899, LR=0.000100
[2025-08-26 21:01:13,798][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006224] [Batch 00064/03080] [00:00:47/00:36:55, 0.734s/it]: train_loss_raw=2.0150, running_loss=1.9917, LR=0.000100
[2025-08-26 21:01:19,758][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006232] [Batch 00072/03080] [00:00:52/00:36:52, 0.736s/it]: train_loss_raw=1.9774, running_loss=1.9930, LR=0.000100
[2025-08-26 21:01:25,682][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006240] [Batch 00080/03080] [00:00:58/00:36:48, 0.736s/it]: train_loss_raw=2.0267, running_loss=1.9947, LR=0.000100
[2025-08-26 21:01:31,692][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006248] [Batch 00088/03080] [00:01:04/00:36:46, 0.738s/it]: train_loss_raw=1.9210, running_loss=1.9957, LR=0.000100
[2025-08-26 21:01:37,609][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006256] [Batch 00096/03080] [00:01:10/00:36:41, 0.738s/it]: train_loss_raw=1.9610, running_loss=1.9970, LR=0.000100
[2025-08-26 21:01:43,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006264] [Batch 00104/03080] [00:01:16/00:36:37, 0.738s/it]: train_loss_raw=2.0342, running_loss=1.9983, LR=0.000100
[2025-08-26 21:01:49,563][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006272] [Batch 00112/03080] [00:01:22/00:36:33, 0.739s/it]: train_loss_raw=2.0533, running_loss=1.9993, LR=0.000100
[2025-08-26 21:01:55,633][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006280] [Batch 00120/03080] [00:01:28/00:36:31, 0.740s/it]: train_loss_raw=1.9746, running_loss=2.0001, LR=0.000100
[2025-08-26 21:02:01,563][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006288] [Batch 00128/03080] [00:01:34/00:36:25, 0.740s/it]: train_loss_raw=1.9220, running_loss=1.9980, LR=0.000100
[2025-08-26 21:02:07,496][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006296] [Batch 00136/03080] [00:01:40/00:36:19, 0.740s/it]: train_loss_raw=1.9067, running_loss=1.9954, LR=0.000100
[2025-08-26 21:02:13,404][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006304] [Batch 00144/03080] [00:01:46/00:36:13, 0.740s/it]: train_loss_raw=1.8480, running_loss=1.9928, LR=0.000100
[2025-08-26 21:02:19,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006312] [Batch 00152/03080] [00:01:52/00:36:07, 0.740s/it]: train_loss_raw=2.0168, running_loss=1.9944, LR=0.000100
[2025-08-26 21:02:25,392][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006320] [Batch 00160/03080] [00:01:58/00:36:04, 0.741s/it]: train_loss_raw=1.9546, running_loss=1.9920, LR=0.000100
[2025-08-26 21:02:31,341][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006328] [Batch 00168/03080] [00:02:04/00:35:58, 0.741s/it]: train_loss_raw=1.9787, running_loss=1.9918, LR=0.000100
[2025-08-26 21:02:37,357][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006336] [Batch 00176/03080] [00:02:10/00:35:54, 0.742s/it]: train_loss_raw=1.9756, running_loss=1.9899, LR=0.000100
[2025-08-26 21:02:43,317][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006344] [Batch 00184/03080] [00:02:16/00:35:48, 0.742s/it]: train_loss_raw=2.0039, running_loss=1.9885, LR=0.000100
[2025-08-26 21:02:49,309][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006352] [Batch 00192/03080] [00:02:22/00:35:43, 0.742s/it]: train_loss_raw=2.0525, running_loss=1.9891, LR=0.000100
[2025-08-26 21:02:55,312][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006360] [Batch 00200/03080] [00:02:28/00:35:38, 0.743s/it]: train_loss_raw=2.0137, running_loss=1.9894, LR=0.000100
[2025-08-26 21:03:01,341][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006368] [Batch 00208/03080] [00:02:34/00:35:33, 0.743s/it]: train_loss_raw=1.9321, running_loss=1.9889, LR=0.000100
[2025-08-26 21:03:07,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006376] [Batch 00216/03080] [00:02:40/00:35:28, 0.743s/it]: train_loss_raw=1.9672, running_loss=1.9894, LR=0.000100
[2025-08-26 21:03:13,291][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006384] [Batch 00224/03080] [00:02:46/00:35:22, 0.743s/it]: train_loss_raw=1.9668, running_loss=1.9876, LR=0.000100
[2025-08-26 21:03:19,318][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006392] [Batch 00232/03080] [00:02:52/00:35:17, 0.744s/it]: train_loss_raw=1.8960, running_loss=1.9862, LR=0.000100
[2025-08-26 21:03:25,337][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006400] [Batch 00240/03080] [00:02:58/00:35:12, 0.744s/it]: train_loss_raw=2.0418, running_loss=1.9869, LR=0.000100
[2025-08-26 21:03:31,285][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006408] [Batch 00248/03080] [00:03:04/00:35:06, 0.744s/it]: train_loss_raw=2.0066, running_loss=1.9862, LR=0.000100
[2025-08-26 21:03:37,296][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006416] [Batch 00256/03080] [00:03:10/00:35:01, 0.744s/it]: train_loss_raw=2.0309, running_loss=1.9859, LR=0.000100
[2025-08-26 21:03:43,329][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006424] [Batch 00264/03080] [00:03:16/00:34:56, 0.744s/it]: train_loss_raw=2.0131, running_loss=1.9872, LR=0.000100
[2025-08-26 21:03:49,354][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006432] [Batch 00272/03080] [00:03:22/00:34:51, 0.745s/it]: train_loss_raw=2.0197, running_loss=1.9861, LR=0.000100
[2025-08-26 21:03:55,284][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006440] [Batch 00280/03080] [00:03:28/00:34:44, 0.745s/it]: train_loss_raw=1.9826, running_loss=1.9868, LR=0.000100
[2025-08-26 21:04:01,330][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006448] [Batch 00288/03080] [00:03:34/00:34:39, 0.745s/it]: train_loss_raw=1.9483, running_loss=1.9867, LR=0.000100
[2025-08-26 21:04:07,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006456] [Batch 00296/03080] [00:03:40/00:34:34, 0.745s/it]: train_loss_raw=1.9828, running_loss=1.9868, LR=0.000100
[2025-08-26 21:04:13,333][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006464] [Batch 00304/03080] [00:03:46/00:34:28, 0.745s/it]: train_loss_raw=1.9804, running_loss=1.9877, LR=0.000100
[2025-08-26 21:04:19,312][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006472] [Batch 00312/03080] [00:03:52/00:34:22, 0.745s/it]: train_loss_raw=1.9245, running_loss=1.9876, LR=0.000100
[2025-08-26 21:04:25,329][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006480] [Batch 00320/03080] [00:03:58/00:34:17, 0.745s/it]: train_loss_raw=2.0187, running_loss=1.9875, LR=0.000100
[2025-08-26 21:04:31,232][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006488] [Batch 00328/03080] [00:04:04/00:34:10, 0.745s/it]: train_loss_raw=2.0199, running_loss=1.9892, LR=0.000100
[2025-08-26 21:04:37,226][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006496] [Batch 00336/03080] [00:04:10/00:34:05, 0.745s/it]: train_loss_raw=1.9935, running_loss=1.9893, LR=0.000100
[2025-08-26 21:04:43,157][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006504] [Batch 00344/03080] [00:04:16/00:33:59, 0.745s/it]: train_loss_raw=2.0354, running_loss=1.9893, LR=0.000100
[2025-08-26 21:04:49,085][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006512] [Batch 00352/03080] [00:04:22/00:33:52, 0.745s/it]: train_loss_raw=1.9484, running_loss=1.9883, LR=0.000100
[2025-08-26 21:04:55,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006520] [Batch 00360/03080] [00:04:28/00:33:47, 0.745s/it]: train_loss_raw=1.8888, running_loss=1.9850, LR=0.000100
[2025-08-26 21:05:01,089][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006528] [Batch 00368/03080] [00:04:34/00:33:41, 0.745s/it]: train_loss_raw=1.9008, running_loss=1.9824, LR=0.000100
[2025-08-26 21:05:07,170][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006536] [Batch 00376/03080] [00:04:40/00:33:36, 0.746s/it]: train_loss_raw=2.0434, running_loss=1.9823, LR=0.000100
[2025-08-26 21:05:12,993][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006544] [Batch 00384/03080] [00:04:46/00:33:29, 0.745s/it]: train_loss_raw=1.9639, running_loss=1.9803, LR=0.000100
[2025-08-26 21:05:18,846][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006552] [Batch 00392/03080] [00:04:52/00:33:22, 0.745s/it]: train_loss_raw=1.9342, running_loss=1.9799, LR=0.000100
[2025-08-26 21:05:24,736][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006560] [Batch 00400/03080] [00:04:57/00:33:16, 0.745s/it]: train_loss_raw=1.9554, running_loss=1.9789, LR=0.000100
[2025-08-26 21:05:30,774][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006568] [Batch 00408/03080] [00:05:03/00:33:10, 0.745s/it]: train_loss_raw=1.9413, running_loss=1.9796, LR=0.000100
[2025-08-26 21:05:36,756][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006576] [Batch 00416/03080] [00:05:09/00:33:04, 0.745s/it]: train_loss_raw=1.9113, running_loss=1.9774, LR=0.000100
[2025-08-26 21:05:42,733][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006584] [Batch 00424/03080] [00:05:15/00:32:59, 0.745s/it]: train_loss_raw=1.9407, running_loss=1.9774, LR=0.000100
[2025-08-26 21:05:48,578][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006592] [Batch 00432/03080] [00:05:21/00:32:52, 0.745s/it]: train_loss_raw=1.9806, running_loss=1.9771, LR=0.000100
[2025-08-26 21:05:54,684][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006600] [Batch 00440/03080] [00:05:27/00:32:47, 0.745s/it]: train_loss_raw=2.0343, running_loss=1.9777, LR=0.000100
[2025-08-26 21:06:00,652][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006608] [Batch 00448/03080] [00:05:33/00:32:41, 0.745s/it]: train_loss_raw=1.9872, running_loss=1.9799, LR=0.000100
[2025-08-26 21:06:06,662][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006616] [Batch 00456/03080] [00:05:39/00:32:35, 0.745s/it]: train_loss_raw=2.0314, running_loss=1.9787, LR=0.000100
[2025-08-26 21:06:12,674][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006624] [Batch 00464/03080] [00:05:45/00:32:30, 0.745s/it]: train_loss_raw=1.9706, running_loss=1.9769, LR=0.000100
[2025-08-26 21:06:18,541][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006632] [Batch 00472/03080] [00:05:51/00:32:23, 0.745s/it]: train_loss_raw=1.9812, running_loss=1.9778, LR=0.000100
[2025-08-26 21:06:24,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006640] [Batch 00480/03080] [00:05:57/00:32:18, 0.745s/it]: train_loss_raw=2.0053, running_loss=1.9779, LR=0.000100
[2025-08-26 21:06:30,596][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006648] [Batch 00488/03080] [00:06:03/00:32:12, 0.746s/it]: train_loss_raw=1.9758, running_loss=1.9764, LR=0.000100
[2025-08-26 21:06:36,593][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006656] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=1.9811, running_loss=1.9762, LR=0.000100
[2025-08-26 21:06:42,548][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006664] [Batch 00504/03080] [00:06:15/00:32:00, 0.746s/it]: train_loss_raw=1.9255, running_loss=1.9747, LR=0.000100
[2025-08-26 21:06:48,549][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006672] [Batch 00512/03080] [00:06:21/00:31:54, 0.746s/it]: train_loss_raw=1.9153, running_loss=1.9751, LR=0.000100
[2025-08-26 21:06:54,574][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006680] [Batch 00520/03080] [00:06:27/00:31:49, 0.746s/it]: train_loss_raw=1.9809, running_loss=1.9749, LR=0.000100
[2025-08-26 21:07:00,512][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006688] [Batch 00528/03080] [00:06:33/00:31:42, 0.746s/it]: train_loss_raw=1.9859, running_loss=1.9709, LR=0.000100
[2025-08-26 21:07:06,516][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006696] [Batch 00536/03080] [00:06:39/00:31:37, 0.746s/it]: train_loss_raw=1.9558, running_loss=1.9694, LR=0.000100
[2025-08-26 21:07:12,527][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006704] [Batch 00544/03080] [00:06:45/00:31:31, 0.746s/it]: train_loss_raw=1.9161, running_loss=1.9691, LR=0.000100
[2025-08-26 21:07:18,491][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006712] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=2.0102, running_loss=1.9706, LR=0.000100
[2025-08-26 21:07:24,591][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006720] [Batch 00560/03080] [00:06:57/00:31:20, 0.746s/it]: train_loss_raw=1.9848, running_loss=1.9710, LR=0.000100
[2025-08-26 21:07:30,577][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006728] [Batch 00568/03080] [00:07:03/00:31:14, 0.746s/it]: train_loss_raw=1.9394, running_loss=1.9692, LR=0.000100
[2025-08-26 21:07:36,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006736] [Batch 00576/03080] [00:07:09/00:31:08, 0.746s/it]: train_loss_raw=1.9640, running_loss=1.9680, LR=0.000100
[2025-08-26 21:07:42,522][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006744] [Batch 00584/03080] [00:07:15/00:31:02, 0.746s/it]: train_loss_raw=2.0343, running_loss=1.9688, LR=0.000100
[2025-08-26 21:07:48,498][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006752] [Batch 00592/03080] [00:07:21/00:30:56, 0.746s/it]: train_loss_raw=1.9500, running_loss=1.9686, LR=0.000100
[2025-08-26 21:07:54,470][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006760] [Batch 00600/03080] [00:07:27/00:30:50, 0.746s/it]: train_loss_raw=1.9407, running_loss=1.9665, LR=0.000100
[2025-08-26 21:08:00,435][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006768] [Batch 00608/03080] [00:07:33/00:30:44, 0.746s/it]: train_loss_raw=1.9027, running_loss=1.9656, LR=0.000100
[2025-08-26 21:08:06,438][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006776] [Batch 00616/03080] [00:07:39/00:30:38, 0.746s/it]: train_loss_raw=2.0005, running_loss=1.9660, LR=0.000100
[2025-08-26 21:08:12,399][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006784] [Batch 00624/03080] [00:07:45/00:30:32, 0.746s/it]: train_loss_raw=1.8853, running_loss=1.9654, LR=0.000100
[2025-08-26 21:08:18,508][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006792] [Batch 00632/03080] [00:07:51/00:30:27, 0.746s/it]: train_loss_raw=1.9665, running_loss=1.9663, LR=0.000100
[2025-08-26 21:08:24,425][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006800] [Batch 00640/03080] [00:07:57/00:30:20, 0.746s/it]: train_loss_raw=1.9830, running_loss=1.9672, LR=0.000100
[2025-08-26 21:08:30,362][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006808] [Batch 00648/03080] [00:08:03/00:30:14, 0.746s/it]: train_loss_raw=1.9461, running_loss=1.9651, LR=0.000100
[2025-08-26 21:08:36,358][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006816] [Batch 00656/03080] [00:08:09/00:30:09, 0.746s/it]: train_loss_raw=1.9834, running_loss=1.9659, LR=0.000100
[2025-08-26 21:08:42,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006824] [Batch 00664/03080] [00:08:15/00:30:02, 0.746s/it]: train_loss_raw=1.9492, running_loss=1.9647, LR=0.000100
[2025-08-26 21:08:48,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006832] [Batch 00672/03080] [00:08:21/00:29:56, 0.746s/it]: train_loss_raw=1.9392, running_loss=1.9658, LR=0.000100
[2025-08-26 21:08:54,178][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006840] [Batch 00680/03080] [00:08:27/00:29:50, 0.746s/it]: train_loss_raw=1.9457, running_loss=1.9671, LR=0.000100
[2025-08-26 21:09:00,151][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006848] [Batch 00688/03080] [00:08:33/00:29:44, 0.746s/it]: train_loss_raw=1.9833, running_loss=1.9667, LR=0.000100
[2025-08-26 21:09:05,942][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006856] [Batch 00696/03080] [00:08:39/00:29:38, 0.746s/it]: train_loss_raw=1.9693, running_loss=1.9675, LR=0.000100
[2025-08-26 21:09:11,902][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006864] [Batch 00704/03080] [00:08:45/00:29:32, 0.746s/it]: train_loss_raw=2.0668, running_loss=1.9681, LR=0.000100
[2025-08-26 21:09:17,942][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006872] [Batch 00712/03080] [00:08:51/00:29:26, 0.746s/it]: train_loss_raw=1.9574, running_loss=1.9687, LR=0.000100
[2025-08-26 21:09:23,934][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006880] [Batch 00720/03080] [00:08:57/00:29:20, 0.746s/it]: train_loss_raw=1.8916, running_loss=1.9653, LR=0.000100
[2025-08-26 21:09:30,054][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006888] [Batch 00728/03080] [00:09:03/00:29:15, 0.746s/it]: train_loss_raw=2.0133, running_loss=1.9638, LR=0.000100
[2025-08-26 21:09:36,089][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006896] [Batch 00736/03080] [00:09:09/00:29:09, 0.746s/it]: train_loss_raw=2.0182, running_loss=1.9640, LR=0.000100
[2025-08-26 21:09:42,013][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006904] [Batch 00744/03080] [00:09:15/00:29:03, 0.746s/it]: train_loss_raw=1.8986, running_loss=1.9628, LR=0.000100
[2025-08-26 21:09:47,977][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006912] [Batch 00752/03080] [00:09:21/00:28:57, 0.746s/it]: train_loss_raw=1.9355, running_loss=1.9621, LR=0.000100
[2025-08-26 21:09:53,950][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006920] [Batch 00760/03080] [00:09:27/00:28:51, 0.746s/it]: train_loss_raw=2.0256, running_loss=1.9635, LR=0.000100
[2025-08-26 21:09:59,882][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006928] [Batch 00768/03080] [00:09:33/00:28:45, 0.746s/it]: train_loss_raw=1.9225, running_loss=1.9634, LR=0.000100
[2025-08-26 21:10:05,870][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006936] [Batch 00776/03080] [00:09:39/00:28:39, 0.746s/it]: train_loss_raw=1.9658, running_loss=1.9646, LR=0.000100
[2025-08-26 21:10:11,814][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006944] [Batch 00784/03080] [00:09:45/00:28:33, 0.746s/it]: train_loss_raw=1.9801, running_loss=1.9628, LR=0.000100
[2025-08-26 21:10:17,828][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006952] [Batch 00792/03080] [00:09:51/00:28:27, 0.746s/it]: train_loss_raw=1.9880, running_loss=1.9632, LR=0.000100
[2025-08-26 21:10:23,784][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006960] [Batch 00800/03080] [00:09:56/00:28:21, 0.746s/it]: train_loss_raw=1.8995, running_loss=1.9625, LR=0.000100
[2025-08-26 21:10:29,679][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006968] [Batch 00808/03080] [00:10:02/00:28:15, 0.746s/it]: train_loss_raw=1.9122, running_loss=1.9630, LR=0.000100
[2025-08-26 21:10:35,618][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006976] [Batch 00816/03080] [00:10:08/00:28:09, 0.746s/it]: train_loss_raw=1.9949, running_loss=1.9631, LR=0.000100
[2025-08-26 21:10:41,541][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006984] [Batch 00824/03080] [00:10:14/00:28:03, 0.746s/it]: train_loss_raw=1.9444, running_loss=1.9641, LR=0.000100
[2025-08-26 21:10:47,374][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006992] [Batch 00832/03080] [00:10:20/00:27:56, 0.746s/it]: train_loss_raw=2.0606, running_loss=1.9629, LR=0.000100
[2025-08-26 21:10:53,315][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007000] [Batch 00840/03080] [00:10:26/00:27:50, 0.746s/it]: train_loss_raw=1.9561, running_loss=1.9623, LR=0.000100
[2025-08-26 21:10:59,209][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007008] [Batch 00848/03080] [00:10:32/00:27:44, 0.746s/it]: train_loss_raw=1.9183, running_loss=1.9628, LR=0.000100
[2025-08-26 21:11:05,127][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007016] [Batch 00856/03080] [00:10:38/00:27:38, 0.746s/it]: train_loss_raw=1.9303, running_loss=1.9619, LR=0.000100
[2025-08-26 21:11:11,068][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007024] [Batch 00864/03080] [00:10:44/00:27:32, 0.746s/it]: train_loss_raw=1.8857, running_loss=1.9642, LR=0.000100
[2025-08-26 21:11:16,948][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007032] [Batch 00872/03080] [00:10:50/00:27:26, 0.746s/it]: train_loss_raw=1.9630, running_loss=1.9650, LR=0.000100
[2025-08-26 21:11:22,769][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007040] [Batch 00880/03080] [00:10:55/00:27:19, 0.745s/it]: train_loss_raw=1.8691, running_loss=1.9622, LR=0.000100
[2025-08-26 21:11:28,551][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007048] [Batch 00888/03080] [00:11:01/00:27:13, 0.745s/it]: train_loss_raw=2.0169, running_loss=1.9630, LR=0.000100
[2025-08-26 21:11:34,564][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007056] [Batch 00896/03080] [00:11:07/00:27:07, 0.745s/it]: train_loss_raw=1.9414, running_loss=1.9623, LR=0.000100
[2025-08-26 21:11:40,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007064] [Batch 00904/03080] [00:11:13/00:27:01, 0.745s/it]: train_loss_raw=1.9677, running_loss=1.9603, LR=0.000100
[2025-08-26 21:11:46,470][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007072] [Batch 00912/03080] [00:11:19/00:26:55, 0.745s/it]: train_loss_raw=1.9328, running_loss=1.9565, LR=0.000100
[2025-08-26 21:11:52,404][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007080] [Batch 00920/03080] [00:11:25/00:26:49, 0.745s/it]: train_loss_raw=2.0225, running_loss=1.9556, LR=0.000100
[2025-08-26 21:11:58,380][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007088] [Batch 00928/03080] [00:11:31/00:26:43, 0.745s/it]: train_loss_raw=2.0425, running_loss=1.9576, LR=0.000100
[2025-08-26 21:12:04,345][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007096] [Batch 00936/03080] [00:11:37/00:26:37, 0.745s/it]: train_loss_raw=1.9029, running_loss=1.9542, LR=0.000100
[2025-08-26 21:12:10,189][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007104] [Batch 00944/03080] [00:11:43/00:26:31, 0.745s/it]: train_loss_raw=1.9536, running_loss=1.9522, LR=0.000100
[2025-08-26 21:12:16,338][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007112] [Batch 00952/03080] [00:11:49/00:26:26, 0.745s/it]: train_loss_raw=1.9790, running_loss=1.9520, LR=0.000100
[2025-08-26 21:12:22,495][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007120] [Batch 00960/03080] [00:11:55/00:26:20, 0.746s/it]: train_loss_raw=1.9727, running_loss=1.9499, LR=0.000100
[2025-08-26 21:12:28,506][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007128] [Batch 00968/03080] [00:12:01/00:26:14, 0.746s/it]: train_loss_raw=1.9174, running_loss=1.9515, LR=0.000100
[2025-08-26 21:12:34,853][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007136] [Batch 00976/03080] [00:12:08/00:26:09, 0.746s/it]: train_loss_raw=1.9968, running_loss=1.9493, LR=0.000100
[2025-08-26 21:12:41,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007144] [Batch 00984/03080] [00:12:14/00:26:04, 0.746s/it]: train_loss_raw=2.0120, running_loss=1.9467, LR=0.000100
[2025-08-26 21:12:47,321][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007152] [Batch 00992/03080] [00:12:20/00:25:58, 0.747s/it]: train_loss_raw=1.9238, running_loss=1.9472, LR=0.000100
[2025-08-26 21:12:53,570][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007160] [Batch 01000/03080] [00:12:26/00:25:53, 0.747s/it]: train_loss_raw=1.8791, running_loss=1.9463, LR=0.000100
[2025-08-26 21:12:59,919][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007168] [Batch 01008/03080] [00:12:33/00:25:48, 0.747s/it]: train_loss_raw=1.9584, running_loss=1.9486, LR=0.000100
[2025-08-26 21:13:06,092][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007176] [Batch 01016/03080] [00:12:39/00:25:42, 0.747s/it]: train_loss_raw=2.0028, running_loss=1.9482, LR=0.000100
[2025-08-26 21:13:12,509][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007184] [Batch 01024/03080] [00:12:45/00:25:37, 0.748s/it]: train_loss_raw=1.9064, running_loss=1.9472, LR=0.000100
[2025-08-26 21:13:18,515][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007192] [Batch 01032/03080] [00:12:51/00:25:31, 0.748s/it]: train_loss_raw=1.9713, running_loss=1.9462, LR=0.000100
[2025-08-26 21:13:24,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007200] [Batch 01040/03080] [00:12:57/00:25:25, 0.748s/it]: train_loss_raw=1.9791, running_loss=1.9469, LR=0.000100
[2025-08-26 21:13:30,453][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007208] [Batch 01048/03080] [00:13:03/00:25:19, 0.748s/it]: train_loss_raw=1.9667, running_loss=1.9489, LR=0.000100
[2025-08-26 21:13:36,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007216] [Batch 01056/03080] [00:13:09/00:25:14, 0.748s/it]: train_loss_raw=1.8744, running_loss=1.9485, LR=0.000100
[2025-08-26 21:13:42,749][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007224] [Batch 01064/03080] [00:13:15/00:25:08, 0.748s/it]: train_loss_raw=1.9281, running_loss=1.9493, LR=0.000100
[2025-08-26 21:13:49,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007232] [Batch 01072/03080] [00:13:22/00:25:02, 0.748s/it]: train_loss_raw=1.9236, running_loss=1.9484, LR=0.000100
[2025-08-26 21:13:55,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007240] [Batch 01080/03080] [00:13:28/00:24:57, 0.749s/it]: train_loss_raw=2.0020, running_loss=1.9457, LR=0.000100
[2025-08-26 21:14:01,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007248] [Batch 01088/03080] [00:13:34/00:24:51, 0.749s/it]: train_loss_raw=1.9871, running_loss=1.9480, LR=0.000100
[2025-08-26 21:14:07,838][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007256] [Batch 01096/03080] [00:13:41/00:24:46, 0.749s/it]: train_loss_raw=1.9327, running_loss=1.9462, LR=0.000100
[2025-08-26 21:14:13,986][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007264] [Batch 01104/03080] [00:13:47/00:24:40, 0.749s/it]: train_loss_raw=1.8339, running_loss=1.9448, LR=0.000100
[2025-08-26 21:14:19,980][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007272] [Batch 01112/03080] [00:13:53/00:24:34, 0.749s/it]: train_loss_raw=1.9204, running_loss=1.9453, LR=0.000100
[2025-08-26 21:14:26,217][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007280] [Batch 01120/03080] [00:13:59/00:24:28, 0.749s/it]: train_loss_raw=1.9730, running_loss=1.9475, LR=0.000100
[2025-08-26 21:14:32,103][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007288] [Batch 01128/03080] [00:14:05/00:24:22, 0.749s/it]: train_loss_raw=1.9894, running_loss=1.9469, LR=0.000100
[2025-08-26 21:14:38,056][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007296] [Batch 01136/03080] [00:14:11/00:24:16, 0.749s/it]: train_loss_raw=1.9553, running_loss=1.9470, LR=0.000100
[2025-08-26 21:14:43,923][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007304] [Batch 01144/03080] [00:14:17/00:24:10, 0.749s/it]: train_loss_raw=1.9058, running_loss=1.9451, LR=0.000100
[2025-08-26 21:14:49,890][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007312] [Batch 01152/03080] [00:14:23/00:24:04, 0.749s/it]: train_loss_raw=1.9159, running_loss=1.9424, LR=0.000100
[2025-08-26 21:14:55,752][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007320] [Batch 01160/03080] [00:14:28/00:23:58, 0.749s/it]: train_loss_raw=1.9338, running_loss=1.9398, LR=0.000100
[2025-08-26 21:15:01,673][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007328] [Batch 01168/03080] [00:14:34/00:23:52, 0.749s/it]: train_loss_raw=1.9885, running_loss=1.9399, LR=0.000100
[2025-08-26 21:15:07,608][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007336] [Batch 01176/03080] [00:14:40/00:23:46, 0.749s/it]: train_loss_raw=1.9602, running_loss=1.9420, LR=0.000100
[2025-08-26 21:15:13,473][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007344] [Batch 01184/03080] [00:14:46/00:23:39, 0.749s/it]: train_loss_raw=1.9535, running_loss=1.9391, LR=0.000100
[2025-08-26 21:15:19,314][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007352] [Batch 01192/03080] [00:14:52/00:23:33, 0.749s/it]: train_loss_raw=1.9669, running_loss=1.9373, LR=0.000100
[2025-08-26 21:15:25,275][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007360] [Batch 01200/03080] [00:14:58/00:23:27, 0.749s/it]: train_loss_raw=2.0349, running_loss=1.9369, LR=0.000100
[2025-08-26 21:15:31,261][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007368] [Batch 01208/03080] [00:15:04/00:23:21, 0.749s/it]: train_loss_raw=1.8724, running_loss=1.9395, LR=0.000100
[2025-08-26 21:15:37,391][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007376] [Batch 01216/03080] [00:15:10/00:23:15, 0.749s/it]: train_loss_raw=1.9215, running_loss=1.9396, LR=0.000100
[2025-08-26 21:15:43,340][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007384] [Batch 01224/03080] [00:15:16/00:23:09, 0.749s/it]: train_loss_raw=1.9534, running_loss=1.9388, LR=0.000100
[2025-08-26 21:15:49,263][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007392] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=1.9590, running_loss=1.9399, LR=0.000100
[2025-08-26 21:15:55,236][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007400] [Batch 01240/03080] [00:15:28/00:22:57, 0.749s/it]: train_loss_raw=1.9762, running_loss=1.9377, LR=0.000100
[2025-08-26 21:16:01,232][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007408] [Batch 01248/03080] [00:15:34/00:22:51, 0.749s/it]: train_loss_raw=1.8714, running_loss=1.9378, LR=0.000100
[2025-08-26 21:16:07,226][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007416] [Batch 01256/03080] [00:15:40/00:22:45, 0.749s/it]: train_loss_raw=1.9489, running_loss=1.9362, LR=0.000100
[2025-08-26 21:16:13,223][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007424] [Batch 01264/03080] [00:15:46/00:22:39, 0.749s/it]: train_loss_raw=1.9753, running_loss=1.9378, LR=0.000100
[2025-08-26 21:16:19,360][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007432] [Batch 01272/03080] [00:15:52/00:22:33, 0.749s/it]: train_loss_raw=1.9419, running_loss=1.9366, LR=0.000100
[2025-08-26 21:16:25,301][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007440] [Batch 01280/03080] [00:15:58/00:22:27, 0.749s/it]: train_loss_raw=1.9530, running_loss=1.9353, LR=0.000100
[2025-08-26 21:16:31,268][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007448] [Batch 01288/03080] [00:16:04/00:22:21, 0.749s/it]: train_loss_raw=1.9283, running_loss=1.9349, LR=0.000100
[2025-08-26 21:16:37,376][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007456] [Batch 01296/03080] [00:16:10/00:22:16, 0.749s/it]: train_loss_raw=1.7569, running_loss=1.9321, LR=0.000100
[2025-08-26 21:16:43,321][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007464] [Batch 01304/03080] [00:16:16/00:22:09, 0.749s/it]: train_loss_raw=1.8656, running_loss=1.9321, LR=0.000100
[2025-08-26 21:16:49,460][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007472] [Batch 01312/03080] [00:16:22/00:22:04, 0.749s/it]: train_loss_raw=1.9473, running_loss=1.9318, LR=0.000100
[2025-08-26 21:16:55,451][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007480] [Batch 01320/03080] [00:16:28/00:21:58, 0.749s/it]: train_loss_raw=1.7735, running_loss=1.9307, LR=0.000100
[2025-08-26 21:17:01,395][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007488] [Batch 01328/03080] [00:16:34/00:21:52, 0.749s/it]: train_loss_raw=1.7945, running_loss=1.9297, LR=0.000100
[2025-08-26 21:17:07,346][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007496] [Batch 01336/03080] [00:16:40/00:21:46, 0.749s/it]: train_loss_raw=1.9323, running_loss=1.9288, LR=0.000100
[2025-08-26 21:17:13,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007504] [Batch 01344/03080] [00:16:46/00:21:40, 0.749s/it]: train_loss_raw=1.8726, running_loss=1.9277, LR=0.000100
[2025-08-26 21:17:19,248][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007512] [Batch 01352/03080] [00:16:52/00:21:34, 0.749s/it]: train_loss_raw=1.9501, running_loss=1.9282, LR=0.000100
[2025-08-26 21:17:25,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007520] [Batch 01360/03080] [00:16:58/00:21:27, 0.749s/it]: train_loss_raw=1.9663, running_loss=1.9275, LR=0.000100
[2025-08-26 21:17:31,074][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007528] [Batch 01368/03080] [00:17:04/00:21:21, 0.749s/it]: train_loss_raw=1.8972, running_loss=1.9266, LR=0.000100
[2025-08-26 21:17:37,018][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007536] [Batch 01376/03080] [00:17:10/00:21:15, 0.749s/it]: train_loss_raw=1.9102, running_loss=1.9270, LR=0.000100
[2025-08-26 21:17:43,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007544] [Batch 01384/03080] [00:17:16/00:21:09, 0.749s/it]: train_loss_raw=1.8554, running_loss=1.9255, LR=0.000100
[2025-08-26 21:17:48,979][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007552] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=1.9886, running_loss=1.9258, LR=0.000100
[2025-08-26 21:17:54,943][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007560] [Batch 01400/03080] [00:17:28/00:20:57, 0.749s/it]: train_loss_raw=1.8007, running_loss=1.9252, LR=0.000100
[2025-08-26 21:18:01,060][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007568] [Batch 01408/03080] [00:17:34/00:20:51, 0.749s/it]: train_loss_raw=1.8709, running_loss=1.9236, LR=0.000100
[2025-08-26 21:18:07,049][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007576] [Batch 01416/03080] [00:17:40/00:20:45, 0.749s/it]: train_loss_raw=1.8956, running_loss=1.9231, LR=0.000100
[2025-08-26 21:18:12,904][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007584] [Batch 01424/03080] [00:17:46/00:20:39, 0.749s/it]: train_loss_raw=1.9058, running_loss=1.9207, LR=0.000100
[2025-08-26 21:18:18,867][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007592] [Batch 01432/03080] [00:17:52/00:20:33, 0.749s/it]: train_loss_raw=1.8798, running_loss=1.9198, LR=0.000100
[2025-08-26 21:18:24,840][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007600] [Batch 01440/03080] [00:17:58/00:20:27, 0.749s/it]: train_loss_raw=1.9810, running_loss=1.9201, LR=0.000100
[2025-08-26 21:18:30,863][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007608] [Batch 01448/03080] [00:18:04/00:20:21, 0.749s/it]: train_loss_raw=2.0230, running_loss=1.9225, LR=0.000100
[2025-08-26 21:18:36,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007616] [Batch 01456/03080] [00:18:10/00:20:15, 0.749s/it]: train_loss_raw=1.9675, running_loss=1.9238, LR=0.000100
[2025-08-26 21:18:42,829][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007624] [Batch 01464/03080] [00:18:16/00:20:09, 0.749s/it]: train_loss_raw=1.9234, running_loss=1.9263, LR=0.000100
[2025-08-26 21:18:48,950][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007632] [Batch 01472/03080] [00:18:22/00:20:03, 0.749s/it]: train_loss_raw=1.9251, running_loss=1.9259, LR=0.000100
[2025-08-26 21:18:54,943][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007640] [Batch 01480/03080] [00:18:28/00:19:58, 0.749s/it]: train_loss_raw=1.8555, running_loss=1.9249, LR=0.000100
[2025-08-26 21:19:00,926][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007648] [Batch 01488/03080] [00:18:34/00:19:52, 0.749s/it]: train_loss_raw=1.9822, running_loss=1.9256, LR=0.000100
[2025-08-26 21:19:06,813][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007656] [Batch 01496/03080] [00:18:40/00:19:45, 0.749s/it]: train_loss_raw=1.9055, running_loss=1.9228, LR=0.000100
[2025-08-26 21:19:12,723][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007664] [Batch 01504/03080] [00:18:45/00:19:39, 0.749s/it]: train_loss_raw=1.8780, running_loss=1.9212, LR=0.000100
[2025-08-26 21:19:18,668][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007672] [Batch 01512/03080] [00:18:51/00:19:33, 0.749s/it]: train_loss_raw=2.0138, running_loss=1.9225, LR=0.000100
[2025-08-26 21:19:24,636][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007680] [Batch 01520/03080] [00:18:57/00:19:27, 0.749s/it]: train_loss_raw=1.9491, running_loss=1.9220, LR=0.000100
[2025-08-26 21:19:30,569][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007688] [Batch 01528/03080] [00:19:03/00:19:21, 0.749s/it]: train_loss_raw=1.8585, running_loss=1.9217, LR=0.000100
[2025-08-26 21:19:36,533][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007696] [Batch 01536/03080] [00:19:09/00:19:15, 0.749s/it]: train_loss_raw=1.9090, running_loss=1.9211, LR=0.000100
[2025-08-26 21:19:42,556][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007704] [Batch 01544/03080] [00:19:15/00:19:09, 0.749s/it]: train_loss_raw=1.7952, running_loss=1.9188, LR=0.000100
[2025-08-26 21:19:48,522][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007712] [Batch 01552/03080] [00:19:21/00:19:03, 0.749s/it]: train_loss_raw=1.8870, running_loss=1.9173, LR=0.000100
[2025-08-26 21:19:54,525][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007720] [Batch 01560/03080] [00:19:27/00:18:57, 0.749s/it]: train_loss_raw=1.9386, running_loss=1.9149, LR=0.000100
[2025-08-26 21:20:00,456][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007728] [Batch 01568/03080] [00:19:33/00:18:51, 0.749s/it]: train_loss_raw=1.8318, running_loss=1.9159, LR=0.000100
[2025-08-26 21:20:06,422][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007736] [Batch 01576/03080] [00:19:39/00:18:45, 0.748s/it]: train_loss_raw=1.9565, running_loss=1.9158, LR=0.000100
[2025-08-26 21:20:12,323][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007744] [Batch 01584/03080] [00:19:45/00:18:39, 0.748s/it]: train_loss_raw=1.8499, running_loss=1.9155, LR=0.000100
[2025-08-26 21:20:18,317][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007752] [Batch 01592/03080] [00:19:51/00:18:33, 0.748s/it]: train_loss_raw=1.9972, running_loss=1.9181, LR=0.000100
[2025-08-26 21:20:24,289][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007760] [Batch 01600/03080] [00:19:57/00:18:27, 0.748s/it]: train_loss_raw=1.9805, running_loss=1.9164, LR=0.000100
[2025-08-26 21:20:30,267][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007768] [Batch 01608/03080] [00:20:03/00:18:21, 0.748s/it]: train_loss_raw=1.8141, running_loss=1.9138, LR=0.000100
[2025-08-26 21:20:36,162][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007776] [Batch 01616/03080] [00:20:09/00:18:15, 0.748s/it]: train_loss_raw=1.9311, running_loss=1.9133, LR=0.000100
[2025-08-26 21:20:42,067][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007784] [Batch 01624/03080] [00:20:15/00:18:09, 0.748s/it]: train_loss_raw=1.8805, running_loss=1.9119, LR=0.000100
[2025-08-26 21:20:47,956][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007792] [Batch 01632/03080] [00:20:21/00:18:03, 0.748s/it]: train_loss_raw=1.9400, running_loss=1.9108, LR=0.000100
[2025-08-26 21:20:54,051][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007800] [Batch 01640/03080] [00:20:27/00:17:57, 0.748s/it]: train_loss_raw=1.8563, running_loss=1.9093, LR=0.000100
[2025-08-26 21:20:59,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007808] [Batch 01648/03080] [00:20:33/00:17:51, 0.748s/it]: train_loss_raw=1.9197, running_loss=1.9088, LR=0.000100
[2025-08-26 21:21:05,968][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007816] [Batch 01656/03080] [00:20:39/00:17:45, 0.748s/it]: train_loss_raw=1.8857, running_loss=1.9099, LR=0.000100
[2025-08-26 21:21:12,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007824] [Batch 01664/03080] [00:20:45/00:17:39, 0.748s/it]: train_loss_raw=1.9584, running_loss=1.9108, LR=0.000100
[2025-08-26 21:21:17,964][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007832] [Batch 01672/03080] [00:20:51/00:17:33, 0.748s/it]: train_loss_raw=1.9313, running_loss=1.9106, LR=0.000100
[2025-08-26 21:21:23,951][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007840] [Batch 01680/03080] [00:20:57/00:17:27, 0.748s/it]: train_loss_raw=1.9735, running_loss=1.9086, LR=0.000100
[2025-08-26 21:21:29,821][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007848] [Batch 01688/03080] [00:21:03/00:17:21, 0.748s/it]: train_loss_raw=1.9512, running_loss=1.9075, LR=0.000100
[2025-08-26 21:21:35,771][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007856] [Batch 01696/03080] [00:21:08/00:17:15, 0.748s/it]: train_loss_raw=1.9454, running_loss=1.9098, LR=0.000100
[2025-08-26 21:21:41,731][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007864] [Batch 01704/03080] [00:21:14/00:17:09, 0.748s/it]: train_loss_raw=1.8712, running_loss=1.9089, LR=0.000100
[2025-08-26 21:21:47,724][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007872] [Batch 01712/03080] [00:21:20/00:17:03, 0.748s/it]: train_loss_raw=1.9465, running_loss=1.9076, LR=0.000100
[2025-08-26 21:21:53,636][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007880] [Batch 01720/03080] [00:21:26/00:16:57, 0.748s/it]: train_loss_raw=1.8797, running_loss=1.9067, LR=0.000100
[2025-08-26 21:21:59,570][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007888] [Batch 01728/03080] [00:21:32/00:16:51, 0.748s/it]: train_loss_raw=1.8696, running_loss=1.9051, LR=0.000100
[2025-08-26 21:22:05,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007896] [Batch 01736/03080] [00:21:38/00:16:45, 0.748s/it]: train_loss_raw=1.9425, running_loss=1.9069, LR=0.000100
[2025-08-26 21:22:11,468][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007904] [Batch 01744/03080] [00:21:44/00:16:39, 0.748s/it]: train_loss_raw=1.9123, running_loss=1.9051, LR=0.000100
[2025-08-26 21:22:17,499][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007912] [Batch 01752/03080] [00:21:50/00:16:33, 0.748s/it]: train_loss_raw=1.8847, running_loss=1.9030, LR=0.000100
[2025-08-26 21:22:23,599][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007920] [Batch 01760/03080] [00:21:56/00:16:27, 0.748s/it]: train_loss_raw=1.8438, running_loss=1.9021, LR=0.000100
[2025-08-26 21:22:29,501][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007928] [Batch 01768/03080] [00:22:02/00:16:21, 0.748s/it]: train_loss_raw=1.8857, running_loss=1.9012, LR=0.000100
[2025-08-26 21:22:35,496][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007936] [Batch 01776/03080] [00:22:08/00:16:15, 0.748s/it]: train_loss_raw=1.9457, running_loss=1.9002, LR=0.000100
[2025-08-26 21:22:41,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007944] [Batch 01784/03080] [00:22:14/00:16:09, 0.748s/it]: train_loss_raw=1.8975, running_loss=1.9010, LR=0.000100
[2025-08-26 21:22:47,373][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007952] [Batch 01792/03080] [00:22:20/00:16:03, 0.748s/it]: train_loss_raw=1.9106, running_loss=1.8991, LR=0.000100
[2025-08-26 21:22:53,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007960] [Batch 01800/03080] [00:22:26/00:15:57, 0.748s/it]: train_loss_raw=1.9009, running_loss=1.9017, LR=0.000100
[2025-08-26 21:22:59,232][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007968] [Batch 01808/03080] [00:22:32/00:15:51, 0.748s/it]: train_loss_raw=1.9488, running_loss=1.9033, LR=0.000100
[2025-08-26 21:23:05,131][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007976] [Batch 01816/03080] [00:22:38/00:15:45, 0.748s/it]: train_loss_raw=1.9111, running_loss=1.9024, LR=0.000100
[2025-08-26 21:23:10,901][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007984] [Batch 01824/03080] [00:22:44/00:15:39, 0.748s/it]: train_loss_raw=1.8762, running_loss=1.9022, LR=0.000100
[2025-08-26 21:23:16,684][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007992] [Batch 01832/03080] [00:22:49/00:15:33, 0.748s/it]: train_loss_raw=1.8759, running_loss=1.9013, LR=0.000100
[2025-08-26 21:23:22,704][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008000] [Batch 01840/03080] [00:22:55/00:15:27, 0.748s/it]: train_loss_raw=1.9640, running_loss=1.9002, LR=0.000100
[2025-08-26 21:23:33,159][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008008] [Batch 01848/03080] [00:23:06/00:15:24, 0.750s/it]: train_loss_raw=1.9785, running_loss=1.8991, LR=0.000100
[2025-08-26 21:23:39,171][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008016] [Batch 01856/03080] [00:23:12/00:15:18, 0.750s/it]: train_loss_raw=1.8998, running_loss=1.8987, LR=0.000100
[2025-08-26 21:23:45,003][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008024] [Batch 01864/03080] [00:23:18/00:15:12, 0.750s/it]: train_loss_raw=1.9021, running_loss=1.8986, LR=0.000100
[2025-08-26 21:23:50,952][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008032] [Batch 01872/03080] [00:23:24/00:15:06, 0.750s/it]: train_loss_raw=1.8654, running_loss=1.8986, LR=0.000100
[2025-08-26 21:23:57,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008040] [Batch 01880/03080] [00:23:30/00:15:00, 0.750s/it]: train_loss_raw=1.9391, running_loss=1.8984, LR=0.000100
[2025-08-26 21:24:03,014][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008048] [Batch 01888/03080] [00:23:36/00:14:54, 0.750s/it]: train_loss_raw=1.9324, running_loss=1.8989, LR=0.000100
[2025-08-26 21:24:09,006][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008056] [Batch 01896/03080] [00:23:42/00:14:48, 0.750s/it]: train_loss_raw=1.9974, running_loss=1.9011, LR=0.000100
[2025-08-26 21:24:14,989][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008064] [Batch 01904/03080] [00:23:48/00:14:42, 0.750s/it]: train_loss_raw=1.9284, running_loss=1.9024, LR=0.000100
[2025-08-26 21:24:20,910][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008072] [Batch 01912/03080] [00:23:54/00:14:36, 0.750s/it]: train_loss_raw=1.7998, running_loss=1.8996, LR=0.000100
[2025-08-26 21:24:26,854][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008080] [Batch 01920/03080] [00:24:00/00:14:30, 0.750s/it]: train_loss_raw=1.9393, running_loss=1.8993, LR=0.000100
[2025-08-26 21:24:32,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008088] [Batch 01928/03080] [00:24:06/00:14:24, 0.750s/it]: train_loss_raw=1.9386, running_loss=1.9006, LR=0.000100
[2025-08-26 21:24:38,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008096] [Batch 01936/03080] [00:24:11/00:14:17, 0.750s/it]: train_loss_raw=1.9665, running_loss=1.9007, LR=0.000100
[2025-08-26 21:24:44,677][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008104] [Batch 01944/03080] [00:24:17/00:14:11, 0.750s/it]: train_loss_raw=1.9377, running_loss=1.8995, LR=0.000100
[2025-08-26 21:24:50,560][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008112] [Batch 01952/03080] [00:24:23/00:14:05, 0.750s/it]: train_loss_raw=1.9131, running_loss=1.8997, LR=0.000100
[2025-08-26 21:24:56,512][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008120] [Batch 01960/03080] [00:24:29/00:13:59, 0.750s/it]: train_loss_raw=1.8864, running_loss=1.8987, LR=0.000100
[2025-08-26 21:25:02,512][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008128] [Batch 01968/03080] [00:24:35/00:13:53, 0.750s/it]: train_loss_raw=1.9288, running_loss=1.8951, LR=0.000100
[2025-08-26 21:25:08,496][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008136] [Batch 01976/03080] [00:24:41/00:13:47, 0.750s/it]: train_loss_raw=1.9547, running_loss=1.8973, LR=0.000100
[2025-08-26 21:25:14,457][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008144] [Batch 01984/03080] [00:24:47/00:13:41, 0.750s/it]: train_loss_raw=1.9237, running_loss=1.8953, LR=0.000100
[2025-08-26 21:25:20,463][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008152] [Batch 01992/03080] [00:24:53/00:13:35, 0.750s/it]: train_loss_raw=1.8819, running_loss=1.8951, LR=0.000100
[2025-08-26 21:25:26,426][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008160] [Batch 02000/03080] [00:24:59/00:13:29, 0.750s/it]: train_loss_raw=1.9168, running_loss=1.8961, LR=0.000100
[2025-08-26 21:25:32,430][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008168] [Batch 02008/03080] [00:25:05/00:13:23, 0.750s/it]: train_loss_raw=1.7811, running_loss=1.8930, LR=0.000100
[2025-08-26 21:25:38,424][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008176] [Batch 02016/03080] [00:25:11/00:13:17, 0.750s/it]: train_loss_raw=1.8961, running_loss=1.8917, LR=0.000100
[2025-08-26 21:25:44,411][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008184] [Batch 02024/03080] [00:25:17/00:13:11, 0.750s/it]: train_loss_raw=1.8236, running_loss=1.8898, LR=0.000100
[2025-08-26 21:25:50,390][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008192] [Batch 02032/03080] [00:25:23/00:13:05, 0.750s/it]: train_loss_raw=2.0076, running_loss=1.8935, LR=0.000100
[2025-08-26 21:25:56,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008200] [Batch 02040/03080] [00:25:29/00:12:59, 0.750s/it]: train_loss_raw=1.8229, running_loss=1.8908, LR=0.000100
[2025-08-26 21:26:02,187][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008208] [Batch 02048/03080] [00:25:35/00:12:53, 0.750s/it]: train_loss_raw=1.8894, running_loss=1.8907, LR=0.000100
[2025-08-26 21:26:08,215][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008216] [Batch 02056/03080] [00:25:41/00:12:47, 0.750s/it]: train_loss_raw=1.8367, running_loss=1.8887, LR=0.000100
[2025-08-26 21:26:14,093][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008224] [Batch 02064/03080] [00:25:47/00:12:41, 0.750s/it]: train_loss_raw=1.8491, running_loss=1.8888, LR=0.000100
[2025-08-26 21:26:20,039][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008232] [Batch 02072/03080] [00:25:53/00:12:35, 0.750s/it]: train_loss_raw=1.8787, running_loss=1.8889, LR=0.000100
[2025-08-26 21:26:25,949][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008240] [Batch 02080/03080] [00:25:59/00:12:29, 0.750s/it]: train_loss_raw=1.8271, running_loss=1.8881, LR=0.000100
[2025-08-26 21:26:31,967][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008248] [Batch 02088/03080] [00:26:05/00:12:23, 0.750s/it]: train_loss_raw=1.7931, running_loss=1.8861, LR=0.000100
[2025-08-26 21:26:37,927][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008256] [Batch 02096/03080] [00:26:11/00:12:17, 0.750s/it]: train_loss_raw=1.9068, running_loss=1.8827, LR=0.000100
[2025-08-26 21:26:43,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008264] [Batch 02104/03080] [00:26:17/00:12:11, 0.750s/it]: train_loss_raw=1.9276, running_loss=1.8808, LR=0.000100
[2025-08-26 21:26:49,680][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008272] [Batch 02112/03080] [00:26:22/00:12:05, 0.749s/it]: train_loss_raw=1.8883, running_loss=1.8822, LR=0.000100
[2025-08-26 21:26:55,655][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008280] [Batch 02120/03080] [00:26:28/00:11:59, 0.749s/it]: train_loss_raw=1.9111, running_loss=1.8818, LR=0.000100
[2025-08-26 21:27:01,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008288] [Batch 02128/03080] [00:26:34/00:11:53, 0.749s/it]: train_loss_raw=1.9229, running_loss=1.8825, LR=0.000100
[2025-08-26 21:27:07,825][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008296] [Batch 02136/03080] [00:26:41/00:11:47, 0.750s/it]: train_loss_raw=1.8725, running_loss=1.8817, LR=0.000100
[2025-08-26 21:27:13,783][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008304] [Batch 02144/03080] [00:26:46/00:11:41, 0.750s/it]: train_loss_raw=1.9619, running_loss=1.8838, LR=0.000100
[2025-08-26 21:27:19,742][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008312] [Batch 02152/03080] [00:26:52/00:11:35, 0.750s/it]: train_loss_raw=1.8973, running_loss=1.8836, LR=0.000100
[2025-08-26 21:27:25,625][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008320] [Batch 02160/03080] [00:26:58/00:11:29, 0.749s/it]: train_loss_raw=1.7733, running_loss=1.8824, LR=0.000100
[2025-08-26 21:27:31,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008328] [Batch 02168/03080] [00:27:04/00:11:23, 0.749s/it]: train_loss_raw=1.9341, running_loss=1.8831, LR=0.000100
[2025-08-26 21:27:37,919][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008336] [Batch 02176/03080] [00:27:11/00:11:17, 0.750s/it]: train_loss_raw=1.7816, running_loss=1.8797, LR=0.000100
[2025-08-26 21:27:43,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008344] [Batch 02184/03080] [00:27:17/00:11:11, 0.750s/it]: train_loss_raw=1.8734, running_loss=1.8797, LR=0.000100
[2025-08-26 21:27:49,775][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008352] [Batch 02192/03080] [00:27:22/00:11:05, 0.750s/it]: train_loss_raw=1.8738, running_loss=1.8824, LR=0.000100
[2025-08-26 21:27:55,937][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008360] [Batch 02200/03080] [00:27:29/00:10:59, 0.750s/it]: train_loss_raw=1.9257, running_loss=1.8813, LR=0.000100
[2025-08-26 21:28:01,846][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008368] [Batch 02208/03080] [00:27:35/00:10:53, 0.750s/it]: train_loss_raw=1.8758, running_loss=1.8824, LR=0.000100
[2025-08-26 21:28:07,714][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008376] [Batch 02216/03080] [00:27:40/00:10:47, 0.750s/it]: train_loss_raw=1.8935, running_loss=1.8836, LR=0.000100
[2025-08-26 21:28:13,447][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008384] [Batch 02224/03080] [00:27:46/00:10:41, 0.749s/it]: train_loss_raw=1.9949, running_loss=1.8852, LR=0.000100
[2025-08-26 21:28:19,411][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008392] [Batch 02232/03080] [00:27:52/00:10:35, 0.749s/it]: train_loss_raw=1.8302, running_loss=1.8870, LR=0.000100
[2025-08-26 21:28:25,361][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008400] [Batch 02240/03080] [00:27:58/00:10:29, 0.749s/it]: train_loss_raw=1.8342, running_loss=1.8842, LR=0.000100
[2025-08-26 21:28:31,367][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008408] [Batch 02248/03080] [00:28:04/00:10:23, 0.749s/it]: train_loss_raw=1.8319, running_loss=1.8827, LR=0.000100
[2025-08-26 21:28:37,190][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008416] [Batch 02256/03080] [00:28:10/00:10:17, 0.749s/it]: train_loss_raw=1.8001, running_loss=1.8804, LR=0.000100
[2025-08-26 21:28:43,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008424] [Batch 02264/03080] [00:28:16/00:10:11, 0.749s/it]: train_loss_raw=1.8841, running_loss=1.8792, LR=0.000100
[2025-08-26 21:28:49,058][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008432] [Batch 02272/03080] [00:28:22/00:10:05, 0.749s/it]: train_loss_raw=1.8370, running_loss=1.8782, LR=0.000100
[2025-08-26 21:28:54,918][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008440] [Batch 02280/03080] [00:28:28/00:09:59, 0.749s/it]: train_loss_raw=1.8741, running_loss=1.8772, LR=0.000100
[2025-08-26 21:29:00,957][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008448] [Batch 02288/03080] [00:28:34/00:09:53, 0.749s/it]: train_loss_raw=1.8347, running_loss=1.8748, LR=0.000100
[2025-08-26 21:29:06,845][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008456] [Batch 02296/03080] [00:28:40/00:09:47, 0.749s/it]: train_loss_raw=1.8599, running_loss=1.8760, LR=0.000100
[2025-08-26 21:29:12,800][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008464] [Batch 02304/03080] [00:28:46/00:09:41, 0.749s/it]: train_loss_raw=1.8360, running_loss=1.8766, LR=0.000100
[2025-08-26 21:29:18,758][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008472] [Batch 02312/03080] [00:28:51/00:09:35, 0.749s/it]: train_loss_raw=1.8517, running_loss=1.8771, LR=0.000100
[2025-08-26 21:29:24,574][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008480] [Batch 02320/03080] [00:28:57/00:09:29, 0.749s/it]: train_loss_raw=1.8106, running_loss=1.8770, LR=0.000100
[2025-08-26 21:29:30,532][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008488] [Batch 02328/03080] [00:29:03/00:09:23, 0.749s/it]: train_loss_raw=1.8394, running_loss=1.8768, LR=0.000100
[2025-08-26 21:29:36,394][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008496] [Batch 02336/03080] [00:29:09/00:09:17, 0.749s/it]: train_loss_raw=1.8298, running_loss=1.8754, LR=0.000100
[2025-08-26 21:29:42,311][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008504] [Batch 02344/03080] [00:29:15/00:09:11, 0.749s/it]: train_loss_raw=1.8821, running_loss=1.8767, LR=0.000100
[2025-08-26 21:29:48,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008512] [Batch 02352/03080] [00:29:21/00:09:05, 0.749s/it]: train_loss_raw=1.8672, running_loss=1.8768, LR=0.000100
[2025-08-26 21:29:54,142][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008520] [Batch 02360/03080] [00:29:27/00:08:59, 0.749s/it]: train_loss_raw=1.8645, running_loss=1.8736, LR=0.000100
[2025-08-26 21:30:00,045][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008528] [Batch 02368/03080] [00:29:33/00:08:53, 0.749s/it]: train_loss_raw=1.9316, running_loss=1.8751, LR=0.000100
[2025-08-26 21:30:05,968][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008536] [Batch 02376/03080] [00:29:39/00:08:47, 0.749s/it]: train_loss_raw=1.9121, running_loss=1.8751, LR=0.000100
[2025-08-26 21:30:11,812][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008544] [Batch 02384/03080] [00:29:45/00:08:41, 0.749s/it]: train_loss_raw=1.7664, running_loss=1.8701, LR=0.000100
[2025-08-26 21:30:17,721][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008552] [Batch 02392/03080] [00:29:50/00:08:35, 0.749s/it]: train_loss_raw=1.8408, running_loss=1.8698, LR=0.000100
[2025-08-26 21:30:23,686][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008560] [Batch 02400/03080] [00:29:56/00:08:29, 0.749s/it]: train_loss_raw=1.7633, running_loss=1.8690, LR=0.000100
[2025-08-26 21:30:29,748][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008568] [Batch 02408/03080] [00:30:02/00:08:23, 0.749s/it]: train_loss_raw=1.9711, running_loss=1.8694, LR=0.000100
[2025-08-26 21:30:35,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008576] [Batch 02416/03080] [00:30:08/00:08:17, 0.749s/it]: train_loss_raw=1.7412, running_loss=1.8660, LR=0.000100
[2025-08-26 21:30:41,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008584] [Batch 02424/03080] [00:30:14/00:08:11, 0.749s/it]: train_loss_raw=1.9245, running_loss=1.8654, LR=0.000100
[2025-08-26 21:30:47,471][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008592] [Batch 02432/03080] [00:30:20/00:08:05, 0.749s/it]: train_loss_raw=1.9192, running_loss=1.8641, LR=0.000100
[2025-08-26 21:30:53,754][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008600] [Batch 02440/03080] [00:30:26/00:07:59, 0.749s/it]: train_loss_raw=1.8770, running_loss=1.8646, LR=0.000100
[2025-08-26 21:30:59,805][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008608] [Batch 02448/03080] [00:30:33/00:07:53, 0.749s/it]: train_loss_raw=1.8215, running_loss=1.8634, LR=0.000100
[2025-08-26 21:31:06,126][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008616] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.9660, running_loss=1.8631, LR=0.000100
[2025-08-26 21:31:12,148][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008624] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.8115, running_loss=1.8600, LR=0.000100
[2025-08-26 21:31:18,284][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008632] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.8276, running_loss=1.8596, LR=0.000100
[2025-08-26 21:31:24,569][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008640] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.8781, running_loss=1.8594, LR=0.000100
[2025-08-26 21:31:30,698][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008648] [Batch 02488/03080] [00:31:03/00:07:23, 0.749s/it]: train_loss_raw=1.7764, running_loss=1.8586, LR=0.000100
[2025-08-26 21:31:36,908][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008656] [Batch 02496/03080] [00:31:10/00:07:17, 0.749s/it]: train_loss_raw=1.8855, running_loss=1.8579, LR=0.000100
[2025-08-26 21:31:42,859][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008664] [Batch 02504/03080] [00:31:16/00:07:11, 0.749s/it]: train_loss_raw=1.9162, running_loss=1.8571, LR=0.000100
[2025-08-26 21:31:48,945][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008672] [Batch 02512/03080] [00:31:22/00:07:05, 0.749s/it]: train_loss_raw=1.8497, running_loss=1.8572, LR=0.000100
[2025-08-26 21:31:55,330][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008680] [Batch 02520/03080] [00:31:28/00:06:59, 0.749s/it]: train_loss_raw=1.8577, running_loss=1.8567, LR=0.000100
[2025-08-26 21:32:01,398][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008688] [Batch 02528/03080] [00:31:34/00:06:53, 0.749s/it]: train_loss_raw=1.8631, running_loss=1.8541, LR=0.000100
[2025-08-26 21:32:07,529][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008696] [Batch 02536/03080] [00:31:40/00:06:47, 0.750s/it]: train_loss_raw=1.8719, running_loss=1.8543, LR=0.000100
[2025-08-26 21:32:13,509][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008704] [Batch 02544/03080] [00:31:46/00:06:41, 0.749s/it]: train_loss_raw=1.8981, running_loss=1.8542, LR=0.000100
[2025-08-26 21:32:19,228][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008712] [Batch 02552/03080] [00:31:52/00:06:35, 0.749s/it]: train_loss_raw=1.8252, running_loss=1.8543, LR=0.000100
[2025-08-26 21:32:24,838][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008720] [Batch 02560/03080] [00:31:58/00:06:29, 0.749s/it]: train_loss_raw=1.8049, running_loss=1.8526, LR=0.000100
[2025-08-26 21:32:30,590][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008728] [Batch 02568/03080] [00:32:03/00:06:23, 0.749s/it]: train_loss_raw=1.7581, running_loss=1.8515, LR=0.000100
[2025-08-26 21:32:36,479][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008736] [Batch 02576/03080] [00:32:09/00:06:17, 0.749s/it]: train_loss_raw=1.8273, running_loss=1.8532, LR=0.000100
[2025-08-26 21:32:42,293][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008744] [Batch 02584/03080] [00:32:15/00:06:11, 0.749s/it]: train_loss_raw=1.8630, running_loss=1.8534, LR=0.000100
[2025-08-26 21:32:47,858][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008752] [Batch 02592/03080] [00:32:21/00:06:05, 0.749s/it]: train_loss_raw=1.8787, running_loss=1.8527, LR=0.000100
[2025-08-26 21:32:53,400][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008760] [Batch 02600/03080] [00:32:26/00:05:59, 0.749s/it]: train_loss_raw=1.8742, running_loss=1.8543, LR=0.000100
[2025-08-26 21:32:58,896][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008768] [Batch 02608/03080] [00:32:32/00:05:53, 0.749s/it]: train_loss_raw=1.8382, running_loss=1.8548, LR=0.000100
[2025-08-26 21:33:04,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008776] [Batch 02616/03080] [00:32:37/00:05:47, 0.748s/it]: train_loss_raw=1.8822, running_loss=1.8552, LR=0.000100
[2025-08-26 21:33:10,410][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008784] [Batch 02624/03080] [00:32:43/00:05:41, 0.748s/it]: train_loss_raw=1.8482, running_loss=1.8540, LR=0.000100
[2025-08-26 21:33:16,196][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008792] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=1.9151, running_loss=1.8542, LR=0.000100
[2025-08-26 21:33:22,289][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008800] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.8804, running_loss=1.8527, LR=0.000100
[2025-08-26 21:33:28,204][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008808] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=1.8862, running_loss=1.8532, LR=0.000100
[2025-08-26 21:33:34,295][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008816] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=1.8488, running_loss=1.8522, LR=0.000100
[2025-08-26 21:33:40,259][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008824] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=1.9048, running_loss=1.8533, LR=0.000100
[2025-08-26 21:33:46,682][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008832] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=1.8803, running_loss=1.8538, LR=0.000100
[2025-08-26 21:33:53,423][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008840] [Batch 02680/03080] [00:33:26/00:04:59, 0.749s/it]: train_loss_raw=1.9378, running_loss=1.8548, LR=0.000100
[2025-08-26 21:34:00,044][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008848] [Batch 02688/03080] [00:33:33/00:04:53, 0.749s/it]: train_loss_raw=1.8381, running_loss=1.8543, LR=0.000100
[2025-08-26 21:34:06,592][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008856] [Batch 02696/03080] [00:33:39/00:04:47, 0.749s/it]: train_loss_raw=1.7894, running_loss=1.8514, LR=0.000100
[2025-08-26 21:34:13,236][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008864] [Batch 02704/03080] [00:33:46/00:04:41, 0.749s/it]: train_loss_raw=1.8752, running_loss=1.8520, LR=0.000100
[2025-08-26 21:34:19,857][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008872] [Batch 02712/03080] [00:33:53/00:04:35, 0.750s/it]: train_loss_raw=1.9101, running_loss=1.8532, LR=0.000100
[2025-08-26 21:34:26,433][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008880] [Batch 02720/03080] [00:33:59/00:04:29, 0.750s/it]: train_loss_raw=1.8245, running_loss=1.8491, LR=0.000100
[2025-08-26 21:34:33,040][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008888] [Batch 02728/03080] [00:34:06/00:04:24, 0.750s/it]: train_loss_raw=1.8817, running_loss=1.8476, LR=0.000100
[2025-08-26 21:34:39,635][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008896] [Batch 02736/03080] [00:34:12/00:04:18, 0.750s/it]: train_loss_raw=1.8839, running_loss=1.8458, LR=0.000100
[2025-08-26 21:34:46,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008904] [Batch 02744/03080] [00:34:19/00:04:12, 0.751s/it]: train_loss_raw=1.9271, running_loss=1.8429, LR=0.000100
[2025-08-26 21:34:52,925][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008912] [Batch 02752/03080] [00:34:26/00:04:06, 0.751s/it]: train_loss_raw=1.8540, running_loss=1.8413, LR=0.000100
[2025-08-26 21:34:59,566][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008920] [Batch 02760/03080] [00:34:32/00:04:00, 0.751s/it]: train_loss_raw=1.9087, running_loss=1.8419, LR=0.000100
[2025-08-26 21:35:06,184][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008928] [Batch 02768/03080] [00:34:39/00:03:54, 0.751s/it]: train_loss_raw=1.8887, running_loss=1.8427, LR=0.000100
[2025-08-26 21:35:12,830][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008936] [Batch 02776/03080] [00:34:46/00:03:48, 0.751s/it]: train_loss_raw=1.8624, running_loss=1.8414, LR=0.000100
[2025-08-26 21:35:19,423][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008944] [Batch 02784/03080] [00:34:52/00:03:42, 0.752s/it]: train_loss_raw=1.8125, running_loss=1.8386, LR=0.000100
[2025-08-26 21:35:26,046][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008952] [Batch 02792/03080] [00:34:59/00:03:36, 0.752s/it]: train_loss_raw=1.8592, running_loss=1.8366, LR=0.000100
[2025-08-26 21:35:32,686][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008960] [Batch 02800/03080] [00:35:05/00:03:30, 0.752s/it]: train_loss_raw=1.7996, running_loss=1.8380, LR=0.000100
[2025-08-26 21:35:39,330][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008968] [Batch 02808/03080] [00:35:12/00:03:24, 0.752s/it]: train_loss_raw=1.8593, running_loss=1.8377, LR=0.000100
[2025-08-26 21:35:45,816][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008976] [Batch 02816/03080] [00:35:19/00:03:18, 0.752s/it]: train_loss_raw=1.9379, running_loss=1.8377, LR=0.000100
[2025-08-26 21:35:52,439][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008984] [Batch 02824/03080] [00:35:25/00:03:12, 0.753s/it]: train_loss_raw=1.8598, running_loss=1.8369, LR=0.000100
[2025-08-26 21:35:58,957][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008992] [Batch 02832/03080] [00:35:32/00:03:06, 0.753s/it]: train_loss_raw=1.8733, running_loss=1.8345, LR=0.000100
[2025-08-26 21:36:05,440][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009000] [Batch 02840/03080] [00:35:38/00:03:00, 0.753s/it]: train_loss_raw=1.8101, running_loss=1.8362, LR=0.000100
[2025-08-26 21:36:11,523][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009008] [Batch 02848/03080] [00:35:44/00:02:54, 0.753s/it]: train_loss_raw=1.8516, running_loss=1.8350, LR=0.000100
[2025-08-26 21:36:18,035][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009016] [Batch 02856/03080] [00:35:51/00:02:48, 0.753s/it]: train_loss_raw=1.8310, running_loss=1.8328, LR=0.000100
[2025-08-26 21:36:24,625][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009024] [Batch 02864/03080] [00:35:57/00:02:42, 0.753s/it]: train_loss_raw=1.7635, running_loss=1.8313, LR=0.000100
[2025-08-26 21:36:31,143][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009032] [Batch 02872/03080] [00:36:04/00:02:36, 0.754s/it]: train_loss_raw=1.8230, running_loss=1.8279, LR=0.000100
[2025-08-26 21:36:37,727][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009040] [Batch 02880/03080] [00:36:10/00:02:30, 0.754s/it]: train_loss_raw=1.7696, running_loss=1.8283, LR=0.000100
[2025-08-26 21:36:44,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009048] [Batch 02888/03080] [00:36:17/00:02:24, 0.754s/it]: train_loss_raw=1.7845, running_loss=1.8251, LR=0.000100
[2025-08-26 21:36:50,336][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009056] [Batch 02896/03080] [00:36:23/00:02:18, 0.754s/it]: train_loss_raw=1.9017, running_loss=1.8249, LR=0.000100
[2025-08-26 21:36:56,910][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009064] [Batch 02904/03080] [00:36:30/00:02:12, 0.754s/it]: train_loss_raw=1.7687, running_loss=1.8263, LR=0.000100
[2025-08-26 21:37:03,628][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009072] [Batch 02912/03080] [00:36:36/00:02:06, 0.754s/it]: train_loss_raw=1.7428, running_loss=1.8305, LR=0.000100
[2025-08-26 21:37:10,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009080] [Batch 02920/03080] [00:36:43/00:02:00, 0.755s/it]: train_loss_raw=1.8927, running_loss=1.8322, LR=0.000100
[2025-08-26 21:37:16,710][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009088] [Batch 02928/03080] [00:36:49/00:01:54, 0.755s/it]: train_loss_raw=1.8784, running_loss=1.8327, LR=0.000100
[2025-08-26 21:37:23,162][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009096] [Batch 02936/03080] [00:36:56/00:01:48, 0.755s/it]: train_loss_raw=1.8319, running_loss=1.8292, LR=0.000100
[2025-08-26 21:37:29,752][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009104] [Batch 02944/03080] [00:37:02/00:01:42, 0.755s/it]: train_loss_raw=1.6977, running_loss=1.8272, LR=0.000100
[2025-08-26 21:37:36,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009112] [Batch 02952/03080] [00:37:09/00:01:36, 0.755s/it]: train_loss_raw=1.8015, running_loss=1.8261, LR=0.000100
[2025-08-26 21:37:42,593][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009120] [Batch 02960/03080] [00:37:15/00:01:30, 0.755s/it]: train_loss_raw=1.7912, running_loss=1.8257, LR=0.000100
[2025-08-26 21:37:48,987][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009128] [Batch 02968/03080] [00:37:22/00:01:24, 0.755s/it]: train_loss_raw=1.8604, running_loss=1.8267, LR=0.000100
[2025-08-26 21:37:55,578][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009136] [Batch 02976/03080] [00:37:28/00:01:18, 0.756s/it]: train_loss_raw=1.7243, running_loss=1.8248, LR=0.000100
[2025-08-26 21:38:02,209][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009144] [Batch 02984/03080] [00:37:35/00:01:12, 0.756s/it]: train_loss_raw=1.8637, running_loss=1.8250, LR=0.000100
[2025-08-26 21:38:08,748][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009152] [Batch 02992/03080] [00:37:41/00:01:06, 0.756s/it]: train_loss_raw=1.8745, running_loss=1.8247, LR=0.000100
[2025-08-26 21:38:15,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009160] [Batch 03000/03080] [00:37:48/00:01:00, 0.756s/it]: train_loss_raw=1.7549, running_loss=1.8245, LR=0.000100
[2025-08-26 21:38:21,922][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009168] [Batch 03008/03080] [00:37:55/00:00:54, 0.756s/it]: train_loss_raw=1.7866, running_loss=1.8226, LR=0.000100
[2025-08-26 21:38:28,567][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009176] [Batch 03016/03080] [00:38:01/00:00:48, 0.757s/it]: train_loss_raw=1.7587, running_loss=1.8215, LR=0.000100
[2025-08-26 21:38:35,272][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009184] [Batch 03024/03080] [00:38:08/00:00:42, 0.757s/it]: train_loss_raw=1.8068, running_loss=1.8211, LR=0.000100
[2025-08-26 21:38:42,066][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009192] [Batch 03032/03080] [00:38:15/00:00:36, 0.757s/it]: train_loss_raw=1.8214, running_loss=1.8195, LR=0.000100
[2025-08-26 21:38:48,599][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009200] [Batch 03040/03080] [00:38:21/00:00:30, 0.757s/it]: train_loss_raw=1.8373, running_loss=1.8221, LR=0.000100
[2025-08-26 21:38:55,273][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009208] [Batch 03048/03080] [00:38:28/00:00:24, 0.757s/it]: train_loss_raw=1.9165, running_loss=1.8230, LR=0.000100
[2025-08-26 21:39:02,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009216] [Batch 03056/03080] [00:38:35/00:00:18, 0.758s/it]: train_loss_raw=1.8702, running_loss=1.8225, LR=0.000100
[2025-08-26 21:39:08,668][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009224] [Batch 03064/03080] [00:38:41/00:00:12, 0.758s/it]: train_loss_raw=1.8061, running_loss=1.8223, LR=0.000100
[2025-08-26 21:39:15,286][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009232] [Batch 03072/03080] [00:38:48/00:00:06, 0.758s/it]: train_loss_raw=1.7340, running_loss=1.8217, LR=0.000100
[2025-08-26 21:39:21,629][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009240] [Batch 03080/03080] [00:38:54/00:00:00, 0.758s/it]: train_loss_raw=1.8050, running_loss=1.8221, LR=0.000100
[2025-08-26 21:39:22,166][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-26 21:39:34,637][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00007/00310] [00:00:12/00:07:50, 1.559s/it]
[2025-08-26 21:39:47,745][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00015/00310] [00:00:25/00:07:49, 1.599s/it]
[2025-08-26 21:40:01,194][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00023/00310] [00:00:39/00:07:45, 1.626s/it]
[2025-08-26 21:40:14,751][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00031/00310] [00:00:52/00:07:36, 1.643s/it]
[2025-08-26 21:40:28,609][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00039/00310] [00:01:06/00:07:28, 1.661s/it]
[2025-08-26 21:40:41,739][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00047/00310] [00:01:19/00:07:14, 1.658s/it]
[2025-08-26 21:40:55,280][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00055/00310] [00:01:33/00:07:02, 1.663s/it]
[2025-08-26 21:41:08,988][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00063/00310] [00:01:46/00:06:50, 1.669s/it]
[2025-08-26 21:41:22,646][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00071/00310] [00:02:00/00:06:38, 1.673s/it]
[2025-08-26 21:41:36,487][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00079/00310] [00:02:14/00:06:26, 1.679s/it]
[2025-08-26 21:41:49,897][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00087/00310] [00:02:27/00:06:12, 1.679s/it]
[2025-08-26 21:42:03,802][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00095/00310] [00:02:41/00:06:00, 1.684s/it]
[2025-08-26 21:42:17,557][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00103/00310] [00:02:55/00:05:47, 1.686s/it]
[2025-08-26 21:42:31,319][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00111/00310] [00:03:09/00:05:34, 1.689s/it]
[2025-08-26 21:42:45,078][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00119/00310] [00:03:22/00:05:21, 1.691s/it]
[2025-08-26 21:42:58,882][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00127/00310] [00:03:36/00:05:08, 1.693s/it]
[2025-08-26 21:43:12,243][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00135/00310] [00:03:50/00:04:54, 1.692s/it]
[2025-08-26 21:43:25,825][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00143/00310] [00:04:03/00:04:40, 1.692s/it]
[2025-08-26 21:43:38,686][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00151/00310] [00:04:16/00:04:26, 1.688s/it]
[2025-08-26 21:43:51,383][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00159/00310] [00:04:29/00:04:12, 1.683s/it]
[2025-08-26 21:44:04,664][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00167/00310] [00:04:42/00:03:58, 1.682s/it]
[2025-08-26 21:44:17,179][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00175/00310] [00:04:55/00:03:44, 1.676s/it]
[2025-08-26 21:44:30,016][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00183/00310] [00:05:07/00:03:30, 1.673s/it]
[2025-08-26 21:44:43,408][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00191/00310] [00:05:21/00:03:17, 1.673s/it]
[2025-08-26 21:44:56,758][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00199/00310] [00:05:34/00:03:04, 1.673s/it]
[2025-08-26 21:45:09,562][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00207/00310] [00:05:47/00:02:50, 1.670s/it]
[2025-08-26 21:45:22,435][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00215/00310] [00:06:00/00:02:36, 1.668s/it]
[2025-08-26 21:45:35,963][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00223/00310] [00:06:13/00:02:23, 1.669s/it]
[2025-08-26 21:45:49,514][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00231/00310] [00:06:27/00:02:10, 1.670s/it]
[2025-08-26 21:46:02,642][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00239/00310] [00:06:40/00:01:56, 1.669s/it]
[2025-08-26 21:46:15,078][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00247/00310] [00:06:52/00:01:43, 1.665s/it]
[2025-08-26 21:46:28,101][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00255/00310] [00:07:05/00:01:29, 1.664s/it]
[2025-08-26 21:46:41,826][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00263/00310] [00:07:19/00:01:16, 1.665s/it]
[2025-08-26 21:46:54,872][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00271/00310] [00:07:32/00:01:03, 1.664s/it]
[2025-08-26 21:47:08,517][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00279/00310] [00:07:46/00:00:49, 1.666s/it]
[2025-08-26 21:47:22,444][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00287/00310] [00:08:00/00:00:36, 1.668s/it]
[2025-08-26 21:47:35,509][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00295/00310] [00:08:13/00:00:23, 1.667s/it]
[2025-08-26 21:47:49,562][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00303/00310] [00:08:27/00:00:10, 1.669s/it]
[2025-08-26 21:47:59,737][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.82210, valid_loss=2.40113
[2025-08-26 21:47:59,738][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-26 21:47:59,738][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.934
[2025-08-26 21:47:59,738][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.012
[2025-08-26 21:47:59,738][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.014
[2025-08-26 21:47:59,738][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.000
[2025-08-26 21:47:59,756][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 02:21:13, remaining time 21:11:02, 00:47:04 per epoch
[2025-08-26 21:48:05,907][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009248] [Batch 00008/03080] [00:00:05/00:37:30, 0.732s/it]: train_loss_raw=1.8468, running_loss=1.7894, LR=0.000100
[2025-08-26 21:48:12,383][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009256] [Batch 00016/03080] [00:00:12/00:39:22, 0.771s/it]: train_loss_raw=1.7622, running_loss=1.7933, LR=0.000100
[2025-08-26 21:48:18,605][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009264] [Batch 00024/03080] [00:00:18/00:39:23, 0.773s/it]: train_loss_raw=1.7667, running_loss=1.7906, LR=0.000100
[2025-08-26 21:48:24,905][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009272] [Batch 00032/03080] [00:00:24/00:39:27, 0.777s/it]: train_loss_raw=1.8335, running_loss=1.7922, LR=0.000100
[2025-08-26 21:48:31,487][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009280] [Batch 00040/03080] [00:00:31/00:39:49, 0.786s/it]: train_loss_raw=1.8375, running_loss=1.7944, LR=0.000100
[2025-08-26 21:48:38,193][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009288] [Batch 00048/03080] [00:00:38/00:40:09, 0.795s/it]: train_loss_raw=1.7617, running_loss=1.7945, LR=0.000100
[2025-08-26 21:48:44,849][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009296] [Batch 00056/03080] [00:00:44/00:40:19, 0.800s/it]: train_loss_raw=1.8206, running_loss=1.7946, LR=0.000100
[2025-08-26 21:48:51,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009304] [Batch 00064/03080] [00:00:51/00:40:13, 0.800s/it]: train_loss_raw=1.7620, running_loss=1.7962, LR=0.000100
[2025-08-26 21:48:57,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009312] [Batch 00072/03080] [00:00:57/00:39:56, 0.797s/it]: train_loss_raw=1.8064, running_loss=1.7965, LR=0.000100
[2025-08-26 21:49:03,535][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009320] [Batch 00080/03080] [00:01:03/00:39:40, 0.794s/it]: train_loss_raw=1.8686, running_loss=1.7980, LR=0.000100
[2025-08-26 21:49:09,703][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009328] [Batch 00088/03080] [00:01:09/00:39:28, 0.792s/it]: train_loss_raw=1.7884, running_loss=1.7980, LR=0.000100
[2025-08-26 21:49:15,860][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009336] [Batch 00096/03080] [00:01:15/00:39:16, 0.790s/it]: train_loss_raw=1.7570, running_loss=1.7982, LR=0.000100
[2025-08-26 21:49:22,348][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009344] [Batch 00104/03080] [00:01:22/00:39:15, 0.791s/it]: train_loss_raw=1.8119, running_loss=1.7987, LR=0.000100
[2025-08-26 21:49:28,927][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009352] [Batch 00112/03080] [00:01:28/00:39:15, 0.794s/it]: train_loss_raw=1.9349, running_loss=1.8007, LR=0.000100
[2025-08-26 21:49:35,541][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009360] [Batch 00120/03080] [00:01:35/00:39:15, 0.796s/it]: train_loss_raw=1.8660, running_loss=1.8028, LR=0.000100
[2025-08-26 21:49:41,724][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009368] [Batch 00128/03080] [00:01:41/00:39:04, 0.794s/it]: train_loss_raw=1.7978, running_loss=1.8004, LR=0.000100
[2025-08-26 21:49:47,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009376] [Batch 00136/03080] [00:01:47/00:38:53, 0.793s/it]: train_loss_raw=1.8321, running_loss=1.8021, LR=0.000100
[2025-08-26 21:49:54,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009384] [Batch 00144/03080] [00:01:53/00:38:43, 0.791s/it]: train_loss_raw=1.7957, running_loss=1.8045, LR=0.000100
[2025-08-26 21:50:00,340][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009392] [Batch 00152/03080] [00:02:00/00:38:37, 0.791s/it]: train_loss_raw=1.7822, running_loss=1.8027, LR=0.000100
[2025-08-26 21:50:06,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009400] [Batch 00160/03080] [00:02:06/00:38:36, 0.793s/it]: train_loss_raw=1.7789, running_loss=1.8024, LR=0.000100
[2025-08-26 21:50:13,667][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009408] [Batch 00168/03080] [00:02:13/00:38:36, 0.795s/it]: train_loss_raw=1.8546, running_loss=1.8032, LR=0.000100
[2025-08-26 21:50:20,373][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009416] [Batch 00176/03080] [00:02:20/00:38:35, 0.797s/it]: train_loss_raw=1.7578, running_loss=1.8032, LR=0.000100
[2025-08-26 21:50:26,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009424] [Batch 00184/03080] [00:02:26/00:38:30, 0.798s/it]: train_loss_raw=1.6322, running_loss=1.8007, LR=0.000100
[2025-08-26 21:50:33,262][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009432] [Batch 00192/03080] [00:02:33/00:38:24, 0.798s/it]: train_loss_raw=1.7884, running_loss=1.7996, LR=0.000100
[2025-08-26 21:50:39,439][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009440] [Batch 00200/03080] [00:02:39/00:38:15, 0.797s/it]: train_loss_raw=1.8687, running_loss=1.8013, LR=0.000100
[2025-08-26 21:50:45,708][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009448] [Batch 00208/03080] [00:02:45/00:38:07, 0.796s/it]: train_loss_raw=1.8153, running_loss=1.8025, LR=0.000100
[2025-08-26 21:50:52,048][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009456] [Batch 00216/03080] [00:02:52/00:38:00, 0.796s/it]: train_loss_raw=1.8579, running_loss=1.8013, LR=0.000100
[2025-08-26 21:50:58,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009464] [Batch 00224/03080] [00:02:58/00:37:55, 0.797s/it]: train_loss_raw=1.8323, running_loss=1.8019, LR=0.000100
[2025-08-26 21:51:04,793][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009472] [Batch 00232/03080] [00:03:04/00:37:47, 0.796s/it]: train_loss_raw=1.8024, running_loss=1.8043, LR=0.000100
[2025-08-26 21:51:11,091][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009480] [Batch 00240/03080] [00:03:11/00:37:40, 0.796s/it]: train_loss_raw=1.8830, running_loss=1.8058, LR=0.000100
[2025-08-26 21:51:17,346][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009488] [Batch 00248/03080] [00:03:17/00:37:33, 0.796s/it]: train_loss_raw=1.7880, running_loss=1.8062, LR=0.000100
[2025-08-26 21:51:23,939][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009496] [Batch 00256/03080] [00:03:23/00:37:29, 0.796s/it]: train_loss_raw=1.7989, running_loss=1.8054, LR=0.000100
[2025-08-26 21:51:30,524][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009504] [Batch 00264/03080] [00:03:30/00:37:25, 0.797s/it]: train_loss_raw=1.8428, running_loss=1.8039, LR=0.000100
[2025-08-26 21:51:37,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009512] [Batch 00272/03080] [00:03:37/00:37:20, 0.798s/it]: train_loss_raw=1.7865, running_loss=1.8014, LR=0.000100
[2025-08-26 21:51:43,748][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009520] [Batch 00280/03080] [00:03:43/00:37:17, 0.799s/it]: train_loss_raw=1.8135, running_loss=1.8005, LR=0.000100
[2025-08-26 21:51:50,432][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009528] [Batch 00288/03080] [00:03:50/00:37:13, 0.800s/it]: train_loss_raw=1.8401, running_loss=1.8025, LR=0.000100
[2025-08-26 21:51:57,108][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009536] [Batch 00296/03080] [00:03:57/00:37:09, 0.801s/it]: train_loss_raw=1.7683, running_loss=1.8043, LR=0.000100
[2025-08-26 21:52:03,751][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009544] [Batch 00304/03080] [00:04:03/00:37:05, 0.802s/it]: train_loss_raw=1.8658, running_loss=1.8056, LR=0.000100
[2025-08-26 21:52:10,431][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009552] [Batch 00312/03080] [00:04:10/00:37:01, 0.803s/it]: train_loss_raw=1.8014, running_loss=1.8039, LR=0.000100
[2025-08-26 21:52:17,042][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009560] [Batch 00320/03080] [00:04:16/00:36:56, 0.803s/it]: train_loss_raw=1.7734, running_loss=1.8036, LR=0.000100
[2025-08-26 21:52:23,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009568] [Batch 00328/03080] [00:04:23/00:36:50, 0.803s/it]: train_loss_raw=1.8711, running_loss=1.8062, LR=0.000100
[2025-08-26 21:52:29,905][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009576] [Batch 00336/03080] [00:04:29/00:36:43, 0.803s/it]: train_loss_raw=1.7687, running_loss=1.8059, LR=0.000100
[2025-08-26 21:52:35,935][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009584] [Batch 00344/03080] [00:04:35/00:36:34, 0.802s/it]: train_loss_raw=1.7622, running_loss=1.8059, LR=0.000100
[2025-08-26 21:52:41,809][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009592] [Batch 00352/03080] [00:04:41/00:36:23, 0.800s/it]: train_loss_raw=1.8439, running_loss=1.8054, LR=0.000100
[2025-08-26 21:52:47,717][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009600] [Batch 00360/03080] [00:04:47/00:36:13, 0.799s/it]: train_loss_raw=1.8439, running_loss=1.8045, LR=0.000100
[2025-08-26 21:52:53,914][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009608] [Batch 00368/03080] [00:04:53/00:36:05, 0.799s/it]: train_loss_raw=1.8084, running_loss=1.8033, LR=0.000100
[2025-08-26 21:53:00,542][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009616] [Batch 00376/03080] [00:05:00/00:36:01, 0.799s/it]: train_loss_raw=1.7558, running_loss=1.8020, LR=0.000100
[2025-08-26 21:53:07,041][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009624] [Batch 00384/03080] [00:05:06/00:35:55, 0.799s/it]: train_loss_raw=1.7547, running_loss=1.8019, LR=0.000100
[2025-08-26 21:53:13,411][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009632] [Batch 00392/03080] [00:05:13/00:35:48, 0.799s/it]: train_loss_raw=1.7464, running_loss=1.8009, LR=0.000100
[2025-08-26 21:53:19,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009640] [Batch 00400/03080] [00:05:19/00:35:40, 0.799s/it]: train_loss_raw=1.7447, running_loss=1.7985, LR=0.000100
[2025-08-26 21:53:25,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009648] [Batch 00408/03080] [00:05:25/00:35:33, 0.798s/it]: train_loss_raw=1.7527, running_loss=1.7947, LR=0.000100
[2025-08-26 21:53:31,933][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009656] [Batch 00416/03080] [00:05:31/00:35:25, 0.798s/it]: train_loss_raw=1.8169, running_loss=1.7945, LR=0.000100
[2025-08-26 21:53:38,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009664] [Batch 00424/03080] [00:05:37/00:35:17, 0.797s/it]: train_loss_raw=1.7437, running_loss=1.7952, LR=0.000100
[2025-08-26 21:53:44,127][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009672] [Batch 00432/03080] [00:05:44/00:35:09, 0.796s/it]: train_loss_raw=1.7579, running_loss=1.7947, LR=0.000100
[2025-08-26 21:53:50,340][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009680] [Batch 00440/03080] [00:05:50/00:35:01, 0.796s/it]: train_loss_raw=1.8335, running_loss=1.7931, LR=0.000100
[2025-08-26 21:53:56,490][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009688] [Batch 00448/03080] [00:05:56/00:34:54, 0.796s/it]: train_loss_raw=1.7687, running_loss=1.7949, LR=0.000100
[2025-08-26 21:54:02,648][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009696] [Batch 00456/03080] [00:06:02/00:34:46, 0.795s/it]: train_loss_raw=1.8740, running_loss=1.7959, LR=0.000100
[2025-08-26 21:54:08,851][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009704] [Batch 00464/03080] [00:06:08/00:34:39, 0.795s/it]: train_loss_raw=1.8465, running_loss=1.7964, LR=0.000100
[2025-08-26 21:54:15,017][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009712] [Batch 00472/03080] [00:06:14/00:34:31, 0.794s/it]: train_loss_raw=1.7783, running_loss=1.7957, LR=0.000100
[2025-08-26 21:54:21,295][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009720] [Batch 00480/03080] [00:06:21/00:34:25, 0.794s/it]: train_loss_raw=1.7016, running_loss=1.7937, LR=0.000100
[2025-08-26 21:54:27,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009728] [Batch 00488/03080] [00:06:27/00:34:18, 0.794s/it]: train_loss_raw=1.8102, running_loss=1.7932, LR=0.000100
[2025-08-26 21:54:33,645][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009736] [Batch 00496/03080] [00:06:33/00:34:10, 0.794s/it]: train_loss_raw=1.8444, running_loss=1.7966, LR=0.000100
[2025-08-26 21:54:39,872][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009744] [Batch 00504/03080] [00:06:39/00:34:03, 0.793s/it]: train_loss_raw=1.7707, running_loss=1.7967, LR=0.000100
[2025-08-26 21:54:45,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009752] [Batch 00512/03080] [00:06:45/00:33:56, 0.793s/it]: train_loss_raw=1.7700, running_loss=1.7952, LR=0.000100
[2025-08-26 21:54:52,219][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009760] [Batch 00520/03080] [00:06:52/00:33:49, 0.793s/it]: train_loss_raw=1.7323, running_loss=1.7929, LR=0.000100
[2025-08-26 21:54:59,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009768] [Batch 00528/03080] [00:06:59/00:33:45, 0.794s/it]: train_loss_raw=1.8724, running_loss=1.7940, LR=0.000100
[2025-08-26 21:55:05,961][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009776] [Batch 00536/03080] [00:07:05/00:33:41, 0.795s/it]: train_loss_raw=1.7722, running_loss=1.7940, LR=0.000100
[2025-08-26 21:55:13,046][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009784] [Batch 00544/03080] [00:07:12/00:33:38, 0.796s/it]: train_loss_raw=1.7391, running_loss=1.7951, LR=0.000100
[2025-08-26 21:55:19,766][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009792] [Batch 00552/03080] [00:07:19/00:33:33, 0.797s/it]: train_loss_raw=1.8226, running_loss=1.7938, LR=0.000100
[2025-08-26 21:55:26,908][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009800] [Batch 00560/03080] [00:07:26/00:33:30, 0.798s/it]: train_loss_raw=1.8531, running_loss=1.7940, LR=0.000100
[2025-08-26 21:55:33,522][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009808] [Batch 00568/03080] [00:07:33/00:33:25, 0.798s/it]: train_loss_raw=1.8082, running_loss=1.7942, LR=0.000100
[2025-08-26 21:55:40,303][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009816] [Batch 00576/03080] [00:07:40/00:33:20, 0.799s/it]: train_loss_raw=1.8821, running_loss=1.7954, LR=0.000100
[2025-08-26 21:55:46,872][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009824] [Batch 00584/03080] [00:07:46/00:33:15, 0.799s/it]: train_loss_raw=1.7515, running_loss=1.7964, LR=0.000100
[2025-08-26 21:55:53,362][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009832] [Batch 00592/03080] [00:07:53/00:33:09, 0.800s/it]: train_loss_raw=1.7714, running_loss=1.7935, LR=0.000100
[2025-08-26 21:55:59,893][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009840] [Batch 00600/03080] [00:07:59/00:33:03, 0.800s/it]: train_loss_raw=1.8091, running_loss=1.7926, LR=0.000100
[2025-08-26 21:56:06,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009848] [Batch 00608/03080] [00:08:06/00:32:57, 0.800s/it]: train_loss_raw=1.8417, running_loss=1.7935, LR=0.000100
[2025-08-26 21:56:12,976][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009856] [Batch 00616/03080] [00:08:12/00:32:51, 0.800s/it]: train_loss_raw=1.8046, running_loss=1.7923, LR=0.000100
[2025-08-26 21:56:19,588][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009864] [Batch 00624/03080] [00:08:19/00:32:46, 0.801s/it]: train_loss_raw=1.8606, running_loss=1.7924, LR=0.000100
[2025-08-26 21:56:26,169][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009872] [Batch 00632/03080] [00:08:26/00:32:40, 0.801s/it]: train_loss_raw=1.7866, running_loss=1.7906, LR=0.000100
[2025-08-26 21:56:32,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009880] [Batch 00640/03080] [00:08:32/00:32:34, 0.801s/it]: train_loss_raw=1.7334, running_loss=1.7902, LR=0.000100
[2025-08-26 21:56:39,309][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009888] [Batch 00648/03080] [00:08:39/00:32:28, 0.801s/it]: train_loss_raw=1.8049, running_loss=1.7887, LR=0.000100
[2025-08-26 21:56:45,871][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009896] [Batch 00656/03080] [00:08:45/00:32:22, 0.802s/it]: train_loss_raw=1.7380, running_loss=1.7902, LR=0.000100
[2025-08-26 21:56:52,452][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009904] [Batch 00664/03080] [00:08:52/00:32:17, 0.802s/it]: train_loss_raw=1.7133, running_loss=1.7901, LR=0.000100
[2025-08-26 21:56:59,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009912] [Batch 00672/03080] [00:08:58/00:32:11, 0.802s/it]: train_loss_raw=1.7635, running_loss=1.7866, LR=0.000100
[2025-08-26 21:57:05,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009920] [Batch 00680/03080] [00:09:05/00:32:05, 0.802s/it]: train_loss_raw=1.7626, running_loss=1.7857, LR=0.000100
[2025-08-26 21:57:12,152][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009928] [Batch 00688/03080] [00:09:12/00:31:59, 0.802s/it]: train_loss_raw=1.7610, running_loss=1.7882, LR=0.000100
[2025-08-26 21:57:18,737][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009936] [Batch 00696/03080] [00:09:18/00:31:53, 0.803s/it]: train_loss_raw=1.7045, running_loss=1.7883, LR=0.000100
[2025-08-26 21:57:25,312][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009944] [Batch 00704/03080] [00:09:25/00:31:47, 0.803s/it]: train_loss_raw=1.7094, running_loss=1.7848, LR=0.000100
[2025-08-26 21:57:31,916][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009952] [Batch 00712/03080] [00:09:31/00:31:41, 0.803s/it]: train_loss_raw=1.7877, running_loss=1.7850, LR=0.000100
[2025-08-26 21:57:38,469][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009960] [Batch 00720/03080] [00:09:38/00:31:35, 0.803s/it]: train_loss_raw=1.7528, running_loss=1.7862, LR=0.000100
[2025-08-26 21:57:45,012][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009968] [Batch 00728/03080] [00:09:44/00:31:29, 0.804s/it]: train_loss_raw=1.9115, running_loss=1.7878, LR=0.000100
[2025-08-26 21:57:51,617][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009976] [Batch 00736/03080] [00:09:51/00:31:24, 0.804s/it]: train_loss_raw=1.8620, running_loss=1.7871, LR=0.000100
[2025-08-26 21:57:58,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009984] [Batch 00744/03080] [00:09:58/00:31:18, 0.804s/it]: train_loss_raw=1.8114, running_loss=1.7855, LR=0.000100
[2025-08-26 21:58:04,832][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009992] [Batch 00752/03080] [00:10:04/00:31:12, 0.804s/it]: train_loss_raw=1.7921, running_loss=1.7865, LR=0.000100
[2025-08-26 21:58:11,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010000] [Batch 00760/03080] [00:10:11/00:31:06, 0.804s/it]: train_loss_raw=1.7660, running_loss=1.7874, LR=0.000100
[2025-08-26 21:58:23,861][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010008] [Batch 00768/03080] [00:10:23/00:31:17, 0.812s/it]: train_loss_raw=1.7487, running_loss=1.7858, LR=0.000100
[2025-08-26 21:58:30,403][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010016] [Batch 00776/03080] [00:10:30/00:31:11, 0.812s/it]: train_loss_raw=1.8118, running_loss=1.7842, LR=0.000100
[2025-08-26 21:58:36,987][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010024] [Batch 00784/03080] [00:10:36/00:31:05, 0.812s/it]: train_loss_raw=1.7142, running_loss=1.7809, LR=0.000100
[2025-08-26 21:58:43,598][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010032] [Batch 00792/03080] [00:10:43/00:30:59, 0.813s/it]: train_loss_raw=1.8114, running_loss=1.7799, LR=0.000100
[2025-08-26 21:58:50,172][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010040] [Batch 00800/03080] [00:10:50/00:30:52, 0.813s/it]: train_loss_raw=1.8497, running_loss=1.7828, LR=0.000100
[2025-08-26 21:58:56,720][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010048] [Batch 00808/03080] [00:10:56/00:30:46, 0.813s/it]: train_loss_raw=1.7633, running_loss=1.7817, LR=0.000100
[2025-08-26 21:59:03,301][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010056] [Batch 00816/03080] [00:11:03/00:30:40, 0.813s/it]: train_loss_raw=1.7887, running_loss=1.7826, LR=0.000100
[2025-08-26 21:59:09,853][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010064] [Batch 00824/03080] [00:11:09/00:30:33, 0.813s/it]: train_loss_raw=1.7843, running_loss=1.7836, LR=0.000100
[2025-08-26 21:59:16,400][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010072] [Batch 00832/03080] [00:11:16/00:30:27, 0.813s/it]: train_loss_raw=1.8075, running_loss=1.7844, LR=0.000100
[2025-08-26 21:59:22,960][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010080] [Batch 00840/03080] [00:11:22/00:30:21, 0.813s/it]: train_loss_raw=1.7525, running_loss=1.7837, LR=0.000100
[2025-08-26 21:59:29,532][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010088] [Batch 00848/03080] [00:11:29/00:30:14, 0.813s/it]: train_loss_raw=1.7511, running_loss=1.7807, LR=0.000100
[2025-08-26 21:59:36,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010096] [Batch 00856/03080] [00:11:35/00:30:08, 0.813s/it]: train_loss_raw=1.7499, running_loss=1.7794, LR=0.000100
[2025-08-26 21:59:42,540][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010104] [Batch 00864/03080] [00:11:42/00:30:01, 0.813s/it]: train_loss_raw=1.6609, running_loss=1.7770, LR=0.000100
[2025-08-26 21:59:49,128][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010112] [Batch 00872/03080] [00:11:49/00:29:55, 0.813s/it]: train_loss_raw=1.8053, running_loss=1.7779, LR=0.000100
[2025-08-26 21:59:55,631][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010120] [Batch 00880/03080] [00:11:55/00:29:48, 0.813s/it]: train_loss_raw=1.7171, running_loss=1.7773, LR=0.000100
[2025-08-26 22:00:02,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010128] [Batch 00888/03080] [00:12:02/00:29:42, 0.813s/it]: train_loss_raw=1.7697, running_loss=1.7779, LR=0.000100
[2025-08-26 22:00:08,739][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010136] [Batch 00896/03080] [00:12:08/00:29:36, 0.813s/it]: train_loss_raw=1.7346, running_loss=1.7758, LR=0.000100
[2025-08-26 22:00:15,338][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010144] [Batch 00904/03080] [00:12:15/00:29:29, 0.813s/it]: train_loss_raw=1.7026, running_loss=1.7744, LR=0.000100
[2025-08-26 22:00:21,928][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010152] [Batch 00912/03080] [00:12:21/00:29:23, 0.813s/it]: train_loss_raw=1.7974, running_loss=1.7753, LR=0.000100
[2025-08-26 22:00:28,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010160] [Batch 00920/03080] [00:12:28/00:29:17, 0.814s/it]: train_loss_raw=1.8038, running_loss=1.7751, LR=0.000100
[2025-08-26 22:00:34,960][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010168] [Batch 00928/03080] [00:12:34/00:29:10, 0.813s/it]: train_loss_raw=1.7646, running_loss=1.7739, LR=0.000100
[2025-08-26 22:00:41,087][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010176] [Batch 00936/03080] [00:12:41/00:29:03, 0.813s/it]: train_loss_raw=1.7773, running_loss=1.7745, LR=0.000100
[2025-08-26 22:00:47,134][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010184] [Batch 00944/03080] [00:12:47/00:28:55, 0.813s/it]: train_loss_raw=1.8471, running_loss=1.7760, LR=0.000100
[2025-08-26 22:00:53,285][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010192] [Batch 00952/03080] [00:12:53/00:28:48, 0.812s/it]: train_loss_raw=1.7019, running_loss=1.7740, LR=0.000100
[2025-08-26 22:00:59,492][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010200] [Batch 00960/03080] [00:12:59/00:28:41, 0.812s/it]: train_loss_raw=1.7758, running_loss=1.7727, LR=0.000100
[2025-08-26 22:01:05,598][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010208] [Batch 00968/03080] [00:13:05/00:28:33, 0.812s/it]: train_loss_raw=1.7375, running_loss=1.7729, LR=0.000100
[2025-08-26 22:01:11,745][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010216] [Batch 00976/03080] [00:13:11/00:28:26, 0.811s/it]: train_loss_raw=1.7623, running_loss=1.7702, LR=0.000100
[2025-08-26 22:01:17,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010224] [Batch 00984/03080] [00:13:17/00:28:19, 0.811s/it]: train_loss_raw=1.7840, running_loss=1.7711, LR=0.000100
[2025-08-26 22:01:24,009][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010232] [Batch 00992/03080] [00:13:23/00:28:12, 0.810s/it]: train_loss_raw=1.7769, running_loss=1.7731, LR=0.000100
[2025-08-26 22:01:30,283][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010240] [Batch 01000/03080] [00:13:30/00:28:05, 0.810s/it]: train_loss_raw=1.7614, running_loss=1.7721, LR=0.000100
[2025-08-26 22:01:36,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010248] [Batch 01008/03080] [00:13:36/00:27:58, 0.810s/it]: train_loss_raw=1.6610, running_loss=1.7681, LR=0.000100
[2025-08-26 22:01:43,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010256] [Batch 01016/03080] [00:13:43/00:27:52, 0.810s/it]: train_loss_raw=1.7277, running_loss=1.7668, LR=0.000100
[2025-08-26 22:01:49,889][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010264] [Batch 01024/03080] [00:13:49/00:27:46, 0.810s/it]: train_loss_raw=1.7388, running_loss=1.7638, LR=0.000100
[2025-08-26 22:01:56,566][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010272] [Batch 01032/03080] [00:13:56/00:27:40, 0.811s/it]: train_loss_raw=1.7097, running_loss=1.7631, LR=0.000100
[2025-08-26 22:02:03,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010280] [Batch 01040/03080] [00:14:03/00:27:34, 0.811s/it]: train_loss_raw=1.7377, running_loss=1.7651, LR=0.000100
[2025-08-26 22:02:09,893][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010288] [Batch 01048/03080] [00:14:09/00:27:27, 0.811s/it]: train_loss_raw=1.7229, running_loss=1.7637, LR=0.000100
[2025-08-26 22:02:16,463][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010296] [Batch 01056/03080] [00:14:16/00:27:21, 0.811s/it]: train_loss_raw=1.8007, running_loss=1.7618, LR=0.000100
[2025-08-26 22:02:23,012][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010304] [Batch 01064/03080] [00:14:22/00:27:15, 0.811s/it]: train_loss_raw=1.7170, running_loss=1.7616, LR=0.000100
[2025-08-26 22:02:29,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010312] [Batch 01072/03080] [00:14:29/00:27:08, 0.811s/it]: train_loss_raw=1.7465, running_loss=1.7643, LR=0.000100
[2025-08-26 22:02:36,171][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010320] [Batch 01080/03080] [00:14:36/00:27:02, 0.811s/it]: train_loss_raw=1.8200, running_loss=1.7638, LR=0.000100
[2025-08-26 22:02:42,669][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010328] [Batch 01088/03080] [00:14:42/00:26:55, 0.811s/it]: train_loss_raw=1.7970, running_loss=1.7630, LR=0.000100
[2025-08-26 22:02:49,238][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010336] [Batch 01096/03080] [00:14:49/00:26:49, 0.811s/it]: train_loss_raw=1.8048, running_loss=1.7617, LR=0.000100
[2025-08-26 22:02:55,910][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010344] [Batch 01104/03080] [00:14:55/00:26:43, 0.811s/it]: train_loss_raw=1.7067, running_loss=1.7610, LR=0.000100
[2025-08-26 22:03:02,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010352] [Batch 01112/03080] [00:15:02/00:26:37, 0.812s/it]: train_loss_raw=1.7369, running_loss=1.7570, LR=0.000100
[2025-08-26 22:03:08,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010360] [Batch 01120/03080] [00:15:08/00:26:30, 0.811s/it]: train_loss_raw=1.7937, running_loss=1.7591, LR=0.000100
[2025-08-26 22:03:15,251][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010368] [Batch 01128/03080] [00:15:15/00:26:23, 0.811s/it]: train_loss_raw=1.7281, running_loss=1.7601, LR=0.000100
[2025-08-26 22:03:21,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010376] [Batch 01136/03080] [00:15:21/00:26:16, 0.811s/it]: train_loss_raw=1.8075, running_loss=1.7597, LR=0.000100
[2025-08-26 22:03:27,612][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010384] [Batch 01144/03080] [00:15:27/00:26:09, 0.811s/it]: train_loss_raw=1.8070, running_loss=1.7625, LR=0.000100
[2025-08-26 22:03:33,742][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010392] [Batch 01152/03080] [00:15:33/00:26:02, 0.810s/it]: train_loss_raw=1.7580, running_loss=1.7623, LR=0.000100
[2025-08-26 22:03:39,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010400] [Batch 01160/03080] [00:15:39/00:25:55, 0.810s/it]: train_loss_raw=1.7507, running_loss=1.7594, LR=0.000100
[2025-08-26 22:03:46,103][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010408] [Batch 01168/03080] [00:15:46/00:25:48, 0.810s/it]: train_loss_raw=1.8207, running_loss=1.7584, LR=0.000100
[2025-08-26 22:03:52,284][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010416] [Batch 01176/03080] [00:15:52/00:25:41, 0.810s/it]: train_loss_raw=1.7025, running_loss=1.7578, LR=0.000100
[2025-08-26 22:03:58,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010424] [Batch 01184/03080] [00:15:58/00:25:34, 0.809s/it]: train_loss_raw=1.8485, running_loss=1.7564, LR=0.000100
[2025-08-26 22:04:04,591][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010432] [Batch 01192/03080] [00:16:04/00:25:27, 0.809s/it]: train_loss_raw=1.7878, running_loss=1.7569, LR=0.000100
[2025-08-26 22:04:10,794][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010440] [Batch 01200/03080] [00:16:10/00:25:20, 0.809s/it]: train_loss_raw=1.7364, running_loss=1.7568, LR=0.000100
[2025-08-26 22:04:17,075][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010448] [Batch 01208/03080] [00:16:17/00:25:14, 0.809s/it]: train_loss_raw=1.7559, running_loss=1.7536, LR=0.000100
[2025-08-26 22:04:23,307][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010456] [Batch 01216/03080] [00:16:23/00:25:07, 0.809s/it]: train_loss_raw=1.7227, running_loss=1.7526, LR=0.000100
[2025-08-26 22:04:29,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010464] [Batch 01224/03080] [00:16:29/00:25:00, 0.808s/it]: train_loss_raw=1.7138, running_loss=1.7523, LR=0.000100
[2025-08-26 22:04:35,559][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010472] [Batch 01232/03080] [00:16:35/00:24:53, 0.808s/it]: train_loss_raw=1.7064, running_loss=1.7535, LR=0.000100
[2025-08-26 22:04:41,680][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010480] [Batch 01240/03080] [00:16:41/00:24:46, 0.808s/it]: train_loss_raw=1.7316, running_loss=1.7555, LR=0.000100
[2025-08-26 22:04:47,856][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010488] [Batch 01248/03080] [00:16:47/00:24:39, 0.808s/it]: train_loss_raw=1.8134, running_loss=1.7589, LR=0.000100
[2025-08-26 22:04:54,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010496] [Batch 01256/03080] [00:16:54/00:24:32, 0.807s/it]: train_loss_raw=1.6849, running_loss=1.7596, LR=0.000100
[2025-08-26 22:05:00,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010504] [Batch 01264/03080] [00:17:00/00:24:26, 0.807s/it]: train_loss_raw=1.7673, running_loss=1.7592, LR=0.000100
[2025-08-26 22:05:06,690][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010512] [Batch 01272/03080] [00:17:06/00:24:19, 0.807s/it]: train_loss_raw=1.7869, running_loss=1.7592, LR=0.000100
[2025-08-26 22:05:12,868][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010520] [Batch 01280/03080] [00:17:12/00:24:12, 0.807s/it]: train_loss_raw=1.8155, running_loss=1.7606, LR=0.000100
[2025-08-26 22:05:19,063][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010528] [Batch 01288/03080] [00:17:19/00:24:05, 0.807s/it]: train_loss_raw=1.7577, running_loss=1.7632, LR=0.000100
[2025-08-26 22:05:25,175][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010536] [Batch 01296/03080] [00:17:25/00:23:58, 0.806s/it]: train_loss_raw=1.7324, running_loss=1.7616, LR=0.000100
[2025-08-26 22:05:31,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010544] [Batch 01304/03080] [00:17:31/00:23:51, 0.806s/it]: train_loss_raw=1.6692, running_loss=1.7588, LR=0.000100
[2025-08-26 22:05:37,863][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010552] [Batch 01312/03080] [00:17:37/00:23:45, 0.806s/it]: train_loss_raw=1.7169, running_loss=1.7572, LR=0.000100
[2025-08-26 22:05:44,537][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010560] [Batch 01320/03080] [00:17:44/00:23:39, 0.806s/it]: train_loss_raw=1.7583, running_loss=1.7548, LR=0.000100
[2025-08-26 22:05:51,228][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010568] [Batch 01328/03080] [00:17:51/00:23:33, 0.807s/it]: train_loss_raw=1.7434, running_loss=1.7547, LR=0.000100
[2025-08-26 22:05:58,532][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010576] [Batch 01336/03080] [00:17:58/00:23:27, 0.807s/it]: train_loss_raw=1.6516, running_loss=1.7528, LR=0.000100
[2025-08-26 22:06:05,100][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010584] [Batch 01344/03080] [00:18:05/00:23:21, 0.807s/it]: train_loss_raw=1.8279, running_loss=1.7530, LR=0.000100
[2025-08-26 22:06:11,672][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010592] [Batch 01352/03080] [00:18:11/00:23:15, 0.807s/it]: train_loss_raw=1.7269, running_loss=1.7525, LR=0.000100
[2025-08-26 22:06:18,310][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010600] [Batch 01360/03080] [00:18:18/00:23:08, 0.808s/it]: train_loss_raw=1.7061, running_loss=1.7527, LR=0.000100
[2025-08-26 22:06:24,988][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010608] [Batch 01368/03080] [00:18:24/00:23:02, 0.808s/it]: train_loss_raw=1.6982, running_loss=1.7513, LR=0.000100
[2025-08-26 22:06:31,593][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010616] [Batch 01376/03080] [00:18:31/00:22:56, 0.808s/it]: train_loss_raw=1.6165, running_loss=1.7504, LR=0.000100
[2025-08-26 22:06:37,787][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010624] [Batch 01384/03080] [00:18:37/00:22:49, 0.808s/it]: train_loss_raw=1.7668, running_loss=1.7505, LR=0.000100
[2025-08-26 22:06:43,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010632] [Batch 01392/03080] [00:18:43/00:22:42, 0.807s/it]: train_loss_raw=1.8481, running_loss=1.7505, LR=0.000100
[2025-08-26 22:06:50,158][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010640] [Batch 01400/03080] [00:18:50/00:22:36, 0.807s/it]: train_loss_raw=1.8396, running_loss=1.7516, LR=0.000100
[2025-08-26 22:06:56,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010648] [Batch 01408/03080] [00:18:56/00:22:29, 0.807s/it]: train_loss_raw=1.7687, running_loss=1.7505, LR=0.000100
[2025-08-26 22:07:02,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010656] [Batch 01416/03080] [00:19:02/00:22:22, 0.807s/it]: train_loss_raw=1.6388, running_loss=1.7499, LR=0.000100
[2025-08-26 22:07:08,516][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010664] [Batch 01424/03080] [00:19:08/00:22:15, 0.807s/it]: train_loss_raw=1.7116, running_loss=1.7475, LR=0.000100
[2025-08-26 22:07:14,581][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010672] [Batch 01432/03080] [00:19:14/00:22:08, 0.806s/it]: train_loss_raw=1.6637, running_loss=1.7473, LR=0.000100
[2025-08-26 22:07:20,742][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010680] [Batch 01440/03080] [00:19:20/00:22:01, 0.806s/it]: train_loss_raw=1.7181, running_loss=1.7488, LR=0.000100
[2025-08-26 22:07:26,928][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010688] [Batch 01448/03080] [00:19:26/00:21:55, 0.806s/it]: train_loss_raw=1.7903, running_loss=1.7508, LR=0.000100
[2025-08-26 22:07:33,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010696] [Batch 01456/03080] [00:19:33/00:21:48, 0.806s/it]: train_loss_raw=1.6440, running_loss=1.7473, LR=0.000100
[2025-08-26 22:07:39,216][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010704] [Batch 01464/03080] [00:19:39/00:21:41, 0.805s/it]: train_loss_raw=1.6755, running_loss=1.7471, LR=0.000100
[2025-08-26 22:07:45,332][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010712] [Batch 01472/03080] [00:19:45/00:21:34, 0.805s/it]: train_loss_raw=1.7518, running_loss=1.7471, LR=0.000100
[2025-08-26 22:07:51,474][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010720] [Batch 01480/03080] [00:19:51/00:21:28, 0.805s/it]: train_loss_raw=1.7806, running_loss=1.7465, LR=0.000100
[2025-08-26 22:07:57,658][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010728] [Batch 01488/03080] [00:19:57/00:21:21, 0.805s/it]: train_loss_raw=1.7772, running_loss=1.7452, LR=0.000100
[2025-08-26 22:08:04,054][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010736] [Batch 01496/03080] [00:20:04/00:21:14, 0.805s/it]: train_loss_raw=1.6075, running_loss=1.7419, LR=0.000100
[2025-08-26 22:08:10,652][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010744] [Batch 01504/03080] [00:20:10/00:21:08, 0.805s/it]: train_loss_raw=1.7244, running_loss=1.7411, LR=0.000100
[2025-08-26 22:08:17,297][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010752] [Batch 01512/03080] [00:20:17/00:21:02, 0.805s/it]: train_loss_raw=1.7731, running_loss=1.7399, LR=0.000100
[2025-08-26 22:08:23,769][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010760] [Batch 01520/03080] [00:20:23/00:20:55, 0.805s/it]: train_loss_raw=1.7056, running_loss=1.7415, LR=0.000100
[2025-08-26 22:08:30,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010768] [Batch 01528/03080] [00:20:30/00:20:49, 0.805s/it]: train_loss_raw=1.7706, running_loss=1.7396, LR=0.000100
[2025-08-26 22:08:37,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010776] [Batch 01536/03080] [00:20:36/00:20:43, 0.805s/it]: train_loss_raw=1.6931, running_loss=1.7379, LR=0.000100
[2025-08-26 22:08:43,632][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010784] [Batch 01544/03080] [00:20:43/00:20:37, 0.805s/it]: train_loss_raw=1.5920, running_loss=1.7381, LR=0.000100
[2025-08-26 22:08:50,238][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010792] [Batch 01552/03080] [00:20:50/00:20:30, 0.806s/it]: train_loss_raw=1.7291, running_loss=1.7363, LR=0.000100
[2025-08-26 22:08:56,857][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010800] [Batch 01560/03080] [00:20:56/00:20:24, 0.806s/it]: train_loss_raw=1.7098, running_loss=1.7351, LR=0.000100
[2025-08-26 22:09:03,401][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010808] [Batch 01568/03080] [00:21:03/00:20:18, 0.806s/it]: train_loss_raw=1.7197, running_loss=1.7373, LR=0.000100
[2025-08-26 22:09:10,238][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010816] [Batch 01576/03080] [00:21:10/00:20:12, 0.806s/it]: train_loss_raw=1.7787, running_loss=1.7361, LR=0.000100
[2025-08-26 22:09:16,835][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010824] [Batch 01584/03080] [00:21:16/00:20:05, 0.806s/it]: train_loss_raw=1.7419, running_loss=1.7351, LR=0.000100
[2025-08-26 22:09:23,444][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010832] [Batch 01592/03080] [00:21:23/00:19:59, 0.806s/it]: train_loss_raw=1.7306, running_loss=1.7356, LR=0.000100
[2025-08-26 22:09:30,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010840] [Batch 01600/03080] [00:21:30/00:19:53, 0.806s/it]: train_loss_raw=1.7479, running_loss=1.7361, LR=0.000100
[2025-08-26 22:09:37,048][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010848] [Batch 01608/03080] [00:21:37/00:19:47, 0.807s/it]: train_loss_raw=1.7447, running_loss=1.7363, LR=0.000100
[2025-08-26 22:09:43,804][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010856] [Batch 01616/03080] [00:21:43/00:19:41, 0.807s/it]: train_loss_raw=1.7921, running_loss=1.7353, LR=0.000100
[2025-08-26 22:09:50,556][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010864] [Batch 01624/03080] [00:21:50/00:19:34, 0.807s/it]: train_loss_raw=1.6737, running_loss=1.7353, LR=0.000100
[2025-08-26 22:09:57,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010872] [Batch 01632/03080] [00:21:57/00:19:28, 0.807s/it]: train_loss_raw=1.7288, running_loss=1.7341, LR=0.000100
[2025-08-26 22:10:04,099][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010880] [Batch 01640/03080] [00:22:04/00:19:22, 0.807s/it]: train_loss_raw=1.6586, running_loss=1.7323, LR=0.000100
[2025-08-26 22:10:10,852][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010888] [Batch 01648/03080] [00:22:10/00:19:16, 0.808s/it]: train_loss_raw=1.6673, running_loss=1.7320, LR=0.000100
[2025-08-26 22:10:17,543][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010896] [Batch 01656/03080] [00:22:17/00:19:10, 0.808s/it]: train_loss_raw=1.7693, running_loss=1.7309, LR=0.000100
[2025-08-26 22:10:24,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010904] [Batch 01664/03080] [00:22:24/00:19:03, 0.808s/it]: train_loss_raw=1.7341, running_loss=1.7331, LR=0.000100
[2025-08-26 22:10:31,086][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010912] [Batch 01672/03080] [00:22:31/00:18:57, 0.808s/it]: train_loss_raw=1.7467, running_loss=1.7352, LR=0.000100
[2025-08-26 22:10:37,716][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010920] [Batch 01680/03080] [00:22:37/00:18:51, 0.808s/it]: train_loss_raw=1.7467, running_loss=1.7343, LR=0.000100
[2025-08-26 22:10:44,339][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010928] [Batch 01688/03080] [00:22:44/00:18:45, 0.808s/it]: train_loss_raw=1.7004, running_loss=1.7327, LR=0.000100
[2025-08-26 22:10:50,981][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010936] [Batch 01696/03080] [00:22:50/00:18:38, 0.808s/it]: train_loss_raw=1.7592, running_loss=1.7345, LR=0.000100
[2025-08-26 22:10:57,872][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010944] [Batch 01704/03080] [00:22:57/00:18:32, 0.809s/it]: train_loss_raw=1.7006, running_loss=1.7351, LR=0.000100
[2025-08-26 22:11:04,088][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010952] [Batch 01712/03080] [00:23:04/00:18:25, 0.808s/it]: train_loss_raw=1.7183, running_loss=1.7362, LR=0.000100
[2025-08-26 22:11:10,262][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010960] [Batch 01720/03080] [00:23:10/00:18:19, 0.808s/it]: train_loss_raw=1.6227, running_loss=1.7329, LR=0.000100
[2025-08-26 22:11:16,470][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010968] [Batch 01728/03080] [00:23:16/00:18:12, 0.808s/it]: train_loss_raw=1.6687, running_loss=1.7336, LR=0.000100
[2025-08-26 22:11:22,787][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010976] [Batch 01736/03080] [00:23:22/00:18:05, 0.808s/it]: train_loss_raw=1.7201, running_loss=1.7328, LR=0.000100
[2025-08-26 22:11:29,152][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010984] [Batch 01744/03080] [00:23:29/00:17:59, 0.808s/it]: train_loss_raw=1.7186, running_loss=1.7310, LR=0.000100
[2025-08-26 22:11:35,417][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010992] [Batch 01752/03080] [00:23:35/00:17:52, 0.808s/it]: train_loss_raw=1.7552, running_loss=1.7315, LR=0.000100
[2025-08-26 22:11:41,651][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011000] [Batch 01760/03080] [00:23:41/00:17:46, 0.808s/it]: train_loss_raw=1.6468, running_loss=1.7290, LR=0.000100
[2025-08-26 22:11:48,138][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011008] [Batch 01768/03080] [00:23:48/00:17:39, 0.808s/it]: train_loss_raw=1.5883, running_loss=1.7244, LR=0.000100
[2025-08-26 22:11:54,703][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011016] [Batch 01776/03080] [00:23:54/00:17:33, 0.808s/it]: train_loss_raw=1.6567, running_loss=1.7231, LR=0.000100
[2025-08-26 22:12:01,459][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011024] [Batch 01784/03080] [00:24:01/00:17:27, 0.808s/it]: train_loss_raw=1.6275, running_loss=1.7240, LR=0.000100
[2025-08-26 22:12:08,040][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011032] [Batch 01792/03080] [00:24:07/00:17:20, 0.808s/it]: train_loss_raw=1.8082, running_loss=1.7263, LR=0.000100
[2025-08-26 22:12:14,617][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011040] [Batch 01800/03080] [00:24:14/00:17:14, 0.808s/it]: train_loss_raw=1.7600, running_loss=1.7249, LR=0.000100
[2025-08-26 22:12:21,123][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011048] [Batch 01808/03080] [00:24:21/00:17:07, 0.808s/it]: train_loss_raw=1.6789, running_loss=1.7275, LR=0.000100
[2025-08-26 22:12:27,729][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011056] [Batch 01816/03080] [00:24:27/00:17:01, 0.808s/it]: train_loss_raw=1.7010, running_loss=1.7277, LR=0.000100
[2025-08-26 22:12:33,998][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011064] [Batch 01824/03080] [00:24:33/00:16:54, 0.808s/it]: train_loss_raw=1.6519, running_loss=1.7278, LR=0.000100
[2025-08-26 22:12:40,346][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011072] [Batch 01832/03080] [00:24:40/00:16:48, 0.808s/it]: train_loss_raw=1.6358, running_loss=1.7284, LR=0.000100
[2025-08-26 22:12:47,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011080] [Batch 01840/03080] [00:24:46/00:16:42, 0.808s/it]: train_loss_raw=1.6412, running_loss=1.7272, LR=0.000100
[2025-08-26 22:12:53,661][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011088] [Batch 01848/03080] [00:24:53/00:16:35, 0.808s/it]: train_loss_raw=1.7325, running_loss=1.7246, LR=0.000100
[2025-08-26 22:12:59,930][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011096] [Batch 01856/03080] [00:24:59/00:16:29, 0.808s/it]: train_loss_raw=1.6517, running_loss=1.7228, LR=0.000100
[2025-08-26 22:13:06,269][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011104] [Batch 01864/03080] [00:25:06/00:16:22, 0.808s/it]: train_loss_raw=1.6588, running_loss=1.7230, LR=0.000100
[2025-08-26 22:13:12,802][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011112] [Batch 01872/03080] [00:25:12/00:16:16, 0.808s/it]: train_loss_raw=1.6868, running_loss=1.7210, LR=0.000100
[2025-08-26 22:13:19,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011120] [Batch 01880/03080] [00:25:19/00:16:09, 0.808s/it]: train_loss_raw=1.7291, running_loss=1.7191, LR=0.000100
[2025-08-26 22:13:25,955][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011128] [Batch 01888/03080] [00:25:25/00:16:03, 0.808s/it]: train_loss_raw=1.7021, running_loss=1.7205, LR=0.000100
[2025-08-26 22:13:32,637][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011136] [Batch 01896/03080] [00:25:32/00:15:57, 0.808s/it]: train_loss_raw=1.7298, running_loss=1.7193, LR=0.000100
[2025-08-26 22:13:39,314][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011144] [Batch 01904/03080] [00:25:39/00:15:50, 0.808s/it]: train_loss_raw=1.6871, running_loss=1.7187, LR=0.000100
[2025-08-26 22:13:45,684][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011152] [Batch 01912/03080] [00:25:45/00:15:44, 0.808s/it]: train_loss_raw=1.7784, running_loss=1.7169, LR=0.000100
[2025-08-26 22:13:51,824][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011160] [Batch 01920/03080] [00:25:51/00:15:37, 0.808s/it]: train_loss_raw=1.7804, running_loss=1.7156, LR=0.000100
[2025-08-26 22:13:58,010][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011168] [Batch 01928/03080] [00:25:57/00:15:30, 0.808s/it]: train_loss_raw=1.7426, running_loss=1.7199, LR=0.000100
[2025-08-26 22:14:04,272][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011176] [Batch 01936/03080] [00:26:04/00:15:24, 0.808s/it]: train_loss_raw=1.6592, running_loss=1.7189, LR=0.000100
[2025-08-26 22:14:10,841][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011184] [Batch 01944/03080] [00:26:10/00:15:17, 0.808s/it]: train_loss_raw=1.6328, running_loss=1.7192, LR=0.000100
[2025-08-26 22:14:17,426][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011192] [Batch 01952/03080] [00:26:17/00:15:11, 0.808s/it]: train_loss_raw=1.6870, running_loss=1.7205, LR=0.000100
[2025-08-26 22:14:24,026][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011200] [Batch 01960/03080] [00:26:23/00:15:05, 0.808s/it]: train_loss_raw=1.6837, running_loss=1.7222, LR=0.000100
[2025-08-26 22:14:30,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011208] [Batch 01968/03080] [00:26:30/00:14:58, 0.808s/it]: train_loss_raw=1.6826, running_loss=1.7228, LR=0.000100
[2025-08-26 22:14:36,783][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011216] [Batch 01976/03080] [00:26:36/00:14:52, 0.808s/it]: train_loss_raw=1.5863, running_loss=1.7216, LR=0.000100
[2025-08-26 22:14:43,452][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011224] [Batch 01984/03080] [00:26:43/00:14:45, 0.808s/it]: train_loss_raw=1.6845, running_loss=1.7211, LR=0.000100
[2025-08-26 22:14:50,065][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011232] [Batch 01992/03080] [00:26:50/00:14:39, 0.808s/it]: train_loss_raw=1.7011, running_loss=1.7190, LR=0.000100
[2025-08-26 22:14:56,679][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011240] [Batch 02000/03080] [00:26:56/00:14:32, 0.808s/it]: train_loss_raw=1.7219, running_loss=1.7179, LR=0.000100
[2025-08-26 22:15:03,115][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011248] [Batch 02008/03080] [00:27:03/00:14:26, 0.808s/it]: train_loss_raw=1.7825, running_loss=1.7168, LR=0.000100
[2025-08-26 22:15:09,434][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011256] [Batch 02016/03080] [00:27:09/00:14:19, 0.808s/it]: train_loss_raw=1.6610, running_loss=1.7148, LR=0.000100
[2025-08-26 22:15:16,060][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011264] [Batch 02024/03080] [00:27:16/00:14:13, 0.808s/it]: train_loss_raw=1.6398, running_loss=1.7140, LR=0.000100
[2025-08-26 22:15:22,641][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011272] [Batch 02032/03080] [00:27:22/00:14:07, 0.808s/it]: train_loss_raw=1.7360, running_loss=1.7152, LR=0.000100
[2025-08-26 22:15:29,226][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011280] [Batch 02040/03080] [00:27:29/00:14:00, 0.808s/it]: train_loss_raw=1.6374, running_loss=1.7165, LR=0.000100
[2025-08-26 22:15:35,868][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011288] [Batch 02048/03080] [00:27:35/00:13:54, 0.809s/it]: train_loss_raw=1.7612, running_loss=1.7153, LR=0.000100
[2025-08-26 22:15:42,383][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011296] [Batch 02056/03080] [00:27:42/00:13:47, 0.809s/it]: train_loss_raw=1.6714, running_loss=1.7129, LR=0.000100
[2025-08-26 22:15:48,937][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011304] [Batch 02064/03080] [00:27:48/00:13:41, 0.809s/it]: train_loss_raw=1.6235, running_loss=1.7115, LR=0.000100
[2025-08-26 22:15:55,543][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011312] [Batch 02072/03080] [00:27:55/00:13:35, 0.809s/it]: train_loss_raw=1.7061, running_loss=1.7097, LR=0.000100
[2025-08-26 22:16:02,220][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011320] [Batch 02080/03080] [00:28:02/00:13:28, 0.809s/it]: train_loss_raw=1.6940, running_loss=1.7117, LR=0.000100
[2025-08-26 22:16:08,870][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011328] [Batch 02088/03080] [00:28:08/00:13:22, 0.809s/it]: train_loss_raw=1.6871, running_loss=1.7116, LR=0.000100
[2025-08-26 22:16:15,578][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011336] [Batch 02096/03080] [00:28:15/00:13:15, 0.809s/it]: train_loss_raw=1.6821, running_loss=1.7123, LR=0.000100
[2025-08-26 22:16:22,181][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011344] [Batch 02104/03080] [00:28:22/00:13:09, 0.809s/it]: train_loss_raw=1.7425, running_loss=1.7101, LR=0.000100
[2025-08-26 22:16:28,836][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011352] [Batch 02112/03080] [00:28:28/00:13:03, 0.809s/it]: train_loss_raw=1.6686, running_loss=1.7090, LR=0.000100
[2025-08-26 22:16:35,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011360] [Batch 02120/03080] [00:28:35/00:12:56, 0.809s/it]: train_loss_raw=1.6398, running_loss=1.7071, LR=0.000100
[2025-08-26 22:16:42,233][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011368] [Batch 02128/03080] [00:28:42/00:12:50, 0.809s/it]: train_loss_raw=1.8110, running_loss=1.7066, LR=0.000100
[2025-08-26 22:16:48,900][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011376] [Batch 02136/03080] [00:28:48/00:12:44, 0.809s/it]: train_loss_raw=1.6340, running_loss=1.7056, LR=0.000100
[2025-08-26 22:16:55,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011384] [Batch 02144/03080] [00:28:55/00:12:37, 0.809s/it]: train_loss_raw=1.5279, running_loss=1.7021, LR=0.000100
[2025-08-26 22:17:02,177][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011392] [Batch 02152/03080] [00:29:02/00:12:31, 0.810s/it]: train_loss_raw=1.7723, running_loss=1.7028, LR=0.000100
[2025-08-26 22:17:08,714][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011400] [Batch 02160/03080] [00:29:08/00:12:24, 0.810s/it]: train_loss_raw=1.6397, running_loss=1.7017, LR=0.000100
[2025-08-26 22:17:15,369][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011408] [Batch 02168/03080] [00:29:15/00:12:18, 0.810s/it]: train_loss_raw=1.6672, running_loss=1.7032, LR=0.000100
[2025-08-26 22:17:21,994][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011416] [Batch 02176/03080] [00:29:21/00:12:11, 0.810s/it]: train_loss_raw=1.6766, running_loss=1.7011, LR=0.000100
[2025-08-26 22:17:28,340][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011424] [Batch 02184/03080] [00:29:28/00:12:05, 0.810s/it]: train_loss_raw=1.8498, running_loss=1.7043, LR=0.000100
[2025-08-26 22:17:34,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011432] [Batch 02192/03080] [00:29:34/00:11:58, 0.810s/it]: train_loss_raw=1.7356, running_loss=1.7031, LR=0.000100
[2025-08-26 22:17:41,404][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011440] [Batch 02200/03080] [00:29:41/00:11:52, 0.810s/it]: train_loss_raw=1.6470, running_loss=1.7028, LR=0.000100
[2025-08-26 22:17:48,064][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011448] [Batch 02208/03080] [00:29:48/00:11:46, 0.810s/it]: train_loss_raw=1.6085, running_loss=1.7017, LR=0.000100
[2025-08-26 22:17:54,609][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011456] [Batch 02216/03080] [00:29:54/00:11:39, 0.810s/it]: train_loss_raw=1.7878, running_loss=1.7029, LR=0.000100
[2025-08-26 22:18:01,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011464] [Batch 02224/03080] [00:30:01/00:11:33, 0.810s/it]: train_loss_raw=1.8214, running_loss=1.7034, LR=0.000100
[2025-08-26 22:18:08,192][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011472] [Batch 02232/03080] [00:30:08/00:11:26, 0.810s/it]: train_loss_raw=1.7260, running_loss=1.7038, LR=0.000100
[2025-08-26 22:18:15,108][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011480] [Batch 02240/03080] [00:30:15/00:11:20, 0.810s/it]: train_loss_raw=1.8705, running_loss=1.7031, LR=0.000100
[2025-08-26 22:18:22,066][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011488] [Batch 02248/03080] [00:30:22/00:11:14, 0.811s/it]: train_loss_raw=1.7335, running_loss=1.7025, LR=0.000100
[2025-08-26 22:18:28,834][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011496] [Batch 02256/03080] [00:30:28/00:11:07, 0.811s/it]: train_loss_raw=1.7185, running_loss=1.7042, LR=0.000100
[2025-08-26 22:18:35,806][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011504] [Batch 02264/03080] [00:30:35/00:11:01, 0.811s/it]: train_loss_raw=1.7135, running_loss=1.7028, LR=0.000100
[2025-08-26 22:18:42,684][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011512] [Batch 02272/03080] [00:30:42/00:10:55, 0.811s/it]: train_loss_raw=1.7141, running_loss=1.7030, LR=0.000100
[2025-08-26 22:18:49,360][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011520] [Batch 02280/03080] [00:30:49/00:10:48, 0.811s/it]: train_loss_raw=1.7172, running_loss=1.7041, LR=0.000100
[2025-08-26 22:18:56,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011528] [Batch 02288/03080] [00:30:56/00:10:42, 0.811s/it]: train_loss_raw=1.6402, running_loss=1.7016, LR=0.000100
[2025-08-26 22:19:03,005][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011536] [Batch 02296/03080] [00:31:02/00:10:36, 0.811s/it]: train_loss_raw=1.7617, running_loss=1.7017, LR=0.000100
[2025-08-26 22:19:09,849][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011544] [Batch 02304/03080] [00:31:09/00:10:29, 0.812s/it]: train_loss_raw=1.7362, running_loss=1.7000, LR=0.000100
[2025-08-26 22:19:16,567][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011552] [Batch 02312/03080] [00:31:16/00:10:23, 0.812s/it]: train_loss_raw=1.7789, running_loss=1.7016, LR=0.000100
[2025-08-26 22:19:23,480][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011560] [Batch 02320/03080] [00:31:23/00:10:16, 0.812s/it]: train_loss_raw=1.7015, running_loss=1.7044, LR=0.000100
[2025-08-26 22:19:30,190][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011568] [Batch 02328/03080] [00:31:30/00:10:10, 0.812s/it]: train_loss_raw=1.8055, running_loss=1.7063, LR=0.000100
[2025-08-26 22:19:36,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011576] [Batch 02336/03080] [00:31:36/00:10:04, 0.812s/it]: train_loss_raw=1.7382, running_loss=1.7094, LR=0.000100
[2025-08-26 22:19:43,508][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011584] [Batch 02344/03080] [00:31:43/00:09:57, 0.812s/it]: train_loss_raw=1.6693, running_loss=1.7069, LR=0.000100
[2025-08-26 22:19:50,366][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011592] [Batch 02352/03080] [00:31:50/00:09:51, 0.812s/it]: train_loss_raw=1.8108, running_loss=1.7045, LR=0.000100
[2025-08-26 22:19:56,987][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011600] [Batch 02360/03080] [00:31:56/00:09:44, 0.812s/it]: train_loss_raw=1.7118, running_loss=1.7033, LR=0.000100
[2025-08-26 22:20:03,596][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011608] [Batch 02368/03080] [00:32:03/00:09:38, 0.812s/it]: train_loss_raw=1.5656, running_loss=1.6996, LR=0.000100
[2025-08-26 22:20:10,156][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011616] [Batch 02376/03080] [00:32:10/00:09:31, 0.812s/it]: train_loss_raw=1.7773, running_loss=1.6994, LR=0.000100
[2025-08-26 22:20:16,778][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011624] [Batch 02384/03080] [00:32:16/00:09:25, 0.812s/it]: train_loss_raw=1.7512, running_loss=1.6998, LR=0.000100
[2025-08-26 22:20:23,481][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011632] [Batch 02392/03080] [00:32:23/00:09:18, 0.812s/it]: train_loss_raw=1.7408, running_loss=1.6985, LR=0.000100
[2025-08-26 22:20:30,104][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011640] [Batch 02400/03080] [00:32:30/00:09:12, 0.813s/it]: train_loss_raw=1.7510, running_loss=1.6982, LR=0.000100
[2025-08-26 22:20:36,744][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011648] [Batch 02408/03080] [00:32:36/00:09:06, 0.813s/it]: train_loss_raw=1.6617, running_loss=1.6986, LR=0.000100
[2025-08-26 22:20:43,389][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011656] [Batch 02416/03080] [00:32:43/00:08:59, 0.813s/it]: train_loss_raw=1.5897, running_loss=1.6974, LR=0.000100
[2025-08-26 22:20:50,013][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011664] [Batch 02424/03080] [00:32:49/00:08:53, 0.813s/it]: train_loss_raw=1.5969, running_loss=1.6966, LR=0.000100
[2025-08-26 22:20:56,542][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011672] [Batch 02432/03080] [00:32:56/00:08:46, 0.813s/it]: train_loss_raw=1.6733, running_loss=1.6991, LR=0.000100
[2025-08-26 22:21:03,145][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011680] [Batch 02440/03080] [00:33:03/00:08:40, 0.813s/it]: train_loss_raw=1.6730, running_loss=1.6969, LR=0.000100
[2025-08-26 22:21:09,719][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011688] [Batch 02448/03080] [00:33:09/00:08:33, 0.813s/it]: train_loss_raw=1.5919, running_loss=1.6955, LR=0.000100
[2025-08-26 22:21:16,275][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011696] [Batch 02456/03080] [00:33:16/00:08:27, 0.813s/it]: train_loss_raw=1.6544, running_loss=1.6968, LR=0.000100
[2025-08-26 22:21:22,949][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011704] [Batch 02464/03080] [00:33:22/00:08:20, 0.813s/it]: train_loss_raw=1.7955, running_loss=1.6992, LR=0.000100
[2025-08-26 22:21:29,660][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011712] [Batch 02472/03080] [00:33:29/00:08:14, 0.813s/it]: train_loss_raw=1.7105, running_loss=1.6954, LR=0.000100
[2025-08-26 22:21:36,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011720] [Batch 02480/03080] [00:33:36/00:08:07, 0.813s/it]: train_loss_raw=1.7893, running_loss=1.6944, LR=0.000100
[2025-08-26 22:21:42,941][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011728] [Batch 02488/03080] [00:33:42/00:08:01, 0.813s/it]: train_loss_raw=1.7599, running_loss=1.6964, LR=0.000100
[2025-08-26 22:21:49,495][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011736] [Batch 02496/03080] [00:33:49/00:07:54, 0.813s/it]: train_loss_raw=1.6670, running_loss=1.6971, LR=0.000100
[2025-08-26 22:21:55,987][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011744] [Batch 02504/03080] [00:33:55/00:07:48, 0.813s/it]: train_loss_raw=1.7080, running_loss=1.6972, LR=0.000100
[2025-08-26 22:22:02,620][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011752] [Batch 02512/03080] [00:34:02/00:07:41, 0.813s/it]: train_loss_raw=1.6746, running_loss=1.6993, LR=0.000100
[2025-08-26 22:22:09,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011760] [Batch 02520/03080] [00:34:09/00:07:35, 0.813s/it]: train_loss_raw=1.7477, running_loss=1.7010, LR=0.000100
[2025-08-26 22:22:15,955][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011768] [Batch 02528/03080] [00:34:15/00:07:28, 0.813s/it]: train_loss_raw=1.6738, running_loss=1.6984, LR=0.000100
[2025-08-26 22:22:22,585][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011776] [Batch 02536/03080] [00:34:22/00:07:22, 0.813s/it]: train_loss_raw=1.6484, running_loss=1.6935, LR=0.000100
[2025-08-26 22:22:29,212][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011784] [Batch 02544/03080] [00:34:29/00:07:15, 0.813s/it]: train_loss_raw=1.6404, running_loss=1.6936, LR=0.000100
[2025-08-26 22:22:35,848][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011792] [Batch 02552/03080] [00:34:35/00:07:09, 0.813s/it]: train_loss_raw=1.6811, running_loss=1.6916, LR=0.000100
[2025-08-26 22:22:42,489][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011800] [Batch 02560/03080] [00:34:42/00:07:02, 0.813s/it]: train_loss_raw=1.7374, running_loss=1.6909, LR=0.000100
[2025-08-26 22:22:49,089][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011808] [Batch 02568/03080] [00:34:49/00:06:56, 0.813s/it]: train_loss_raw=1.6524, running_loss=1.6891, LR=0.000100
[2025-08-26 22:22:55,719][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011816] [Batch 02576/03080] [00:34:55/00:06:50, 0.814s/it]: train_loss_raw=1.6879, running_loss=1.6892, LR=0.000100
[2025-08-26 22:23:02,356][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011824] [Batch 02584/03080] [00:35:02/00:06:43, 0.814s/it]: train_loss_raw=1.8085, running_loss=1.6895, LR=0.000100
[2025-08-26 22:23:08,910][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011832] [Batch 02592/03080] [00:35:08/00:06:37, 0.814s/it]: train_loss_raw=1.6706, running_loss=1.6887, LR=0.000100
[2025-08-26 22:23:15,546][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011840] [Batch 02600/03080] [00:35:15/00:06:30, 0.814s/it]: train_loss_raw=1.7544, running_loss=1.6880, LR=0.000100
[2025-08-26 22:23:22,139][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011848] [Batch 02608/03080] [00:35:22/00:06:24, 0.814s/it]: train_loss_raw=1.6823, running_loss=1.6864, LR=0.000100
[2025-08-26 22:23:28,683][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011856] [Batch 02616/03080] [00:35:28/00:06:17, 0.814s/it]: train_loss_raw=1.6698, running_loss=1.6876, LR=0.000100
[2025-08-26 22:23:35,370][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011864] [Batch 02624/03080] [00:35:35/00:06:11, 0.814s/it]: train_loss_raw=1.7548, running_loss=1.6869, LR=0.000100
[2025-08-26 22:23:41,952][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011872] [Batch 02632/03080] [00:35:41/00:06:04, 0.814s/it]: train_loss_raw=1.6360, running_loss=1.6854, LR=0.000100
[2025-08-26 22:23:48,670][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011880] [Batch 02640/03080] [00:35:48/00:05:58, 0.814s/it]: train_loss_raw=1.6957, running_loss=1.6872, LR=0.000100
[2025-08-26 22:23:55,252][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011888] [Batch 02648/03080] [00:35:55/00:05:51, 0.814s/it]: train_loss_raw=1.5033, running_loss=1.6858, LR=0.000100
[2025-08-26 22:24:01,880][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011896] [Batch 02656/03080] [00:36:01/00:05:45, 0.814s/it]: train_loss_raw=1.6920, running_loss=1.6885, LR=0.000100
[2025-08-26 22:24:08,575][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011904] [Batch 02664/03080] [00:36:08/00:05:38, 0.814s/it]: train_loss_raw=1.6438, running_loss=1.6879, LR=0.000100
[2025-08-26 22:24:15,242][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011912] [Batch 02672/03080] [00:36:15/00:05:32, 0.814s/it]: train_loss_raw=1.7343, running_loss=1.6871, LR=0.000100
[2025-08-26 22:24:21,844][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011920] [Batch 02680/03080] [00:36:21/00:05:25, 0.814s/it]: train_loss_raw=1.7740, running_loss=1.6869, LR=0.000100
[2025-08-26 22:24:28,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011928] [Batch 02688/03080] [00:36:28/00:05:19, 0.814s/it]: train_loss_raw=1.7339, running_loss=1.6860, LR=0.000100
[2025-08-26 22:24:35,067][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011936] [Batch 02696/03080] [00:36:35/00:05:12, 0.814s/it]: train_loss_raw=1.6519, running_loss=1.6837, LR=0.000100
[2025-08-26 22:24:41,697][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011944] [Batch 02704/03080] [00:36:41/00:05:06, 0.814s/it]: train_loss_raw=1.5583, running_loss=1.6789, LR=0.000100
[2025-08-26 22:24:48,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011952] [Batch 02712/03080] [00:36:48/00:04:59, 0.814s/it]: train_loss_raw=1.6090, running_loss=1.6773, LR=0.000100
[2025-08-26 22:24:54,940][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011960] [Batch 02720/03080] [00:36:54/00:04:53, 0.814s/it]: train_loss_raw=1.6822, running_loss=1.6800, LR=0.000100
[2025-08-26 22:25:01,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011968] [Batch 02728/03080] [00:37:01/00:04:46, 0.814s/it]: train_loss_raw=1.7402, running_loss=1.6817, LR=0.000100
[2025-08-26 22:25:08,200][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011976] [Batch 02736/03080] [00:37:08/00:04:40, 0.814s/it]: train_loss_raw=1.7197, running_loss=1.6812, LR=0.000100
[2025-08-26 22:25:14,741][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011984] [Batch 02744/03080] [00:37:14/00:04:33, 0.814s/it]: train_loss_raw=1.6224, running_loss=1.6798, LR=0.000100
[2025-08-26 22:25:21,414][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011992] [Batch 02752/03080] [00:37:21/00:04:27, 0.814s/it]: train_loss_raw=1.7396, running_loss=1.6819, LR=0.000100
[2025-08-26 22:25:28,081][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012000] [Batch 02760/03080] [00:37:28/00:04:20, 0.815s/it]: train_loss_raw=1.7449, running_loss=1.6824, LR=0.000100
[2025-08-26 22:25:40,706][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012008] [Batch 02768/03080] [00:37:40/00:04:14, 0.817s/it]: train_loss_raw=1.6452, running_loss=1.6836, LR=0.000100
[2025-08-26 22:25:47,413][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012016] [Batch 02776/03080] [00:37:47/00:04:08, 0.817s/it]: train_loss_raw=1.6643, running_loss=1.6821, LR=0.000100
[2025-08-26 22:25:54,082][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012024] [Batch 02784/03080] [00:37:54/00:04:01, 0.817s/it]: train_loss_raw=1.6225, running_loss=1.6807, LR=0.000100
[2025-08-26 22:26:00,685][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012032] [Batch 02792/03080] [00:38:00/00:03:55, 0.817s/it]: train_loss_raw=1.6504, running_loss=1.6793, LR=0.000100
[2025-08-26 22:26:07,319][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012040] [Batch 02800/03080] [00:38:07/00:03:48, 0.817s/it]: train_loss_raw=1.6915, running_loss=1.6818, LR=0.000100
[2025-08-26 22:26:13,894][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012048] [Batch 02808/03080] [00:38:13/00:03:42, 0.817s/it]: train_loss_raw=1.6425, running_loss=1.6829, LR=0.000100
[2025-08-26 22:26:20,498][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012056] [Batch 02816/03080] [00:38:20/00:03:35, 0.817s/it]: train_loss_raw=1.7341, running_loss=1.6846, LR=0.000100
[2025-08-26 22:26:27,070][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012064] [Batch 02824/03080] [00:38:27/00:03:29, 0.817s/it]: train_loss_raw=1.6688, running_loss=1.6840, LR=0.000100
[2025-08-26 22:26:33,647][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012072] [Batch 02832/03080] [00:38:33/00:03:22, 0.817s/it]: train_loss_raw=1.6060, running_loss=1.6841, LR=0.000100
[2025-08-26 22:26:40,261][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012080] [Batch 02840/03080] [00:38:40/00:03:16, 0.817s/it]: train_loss_raw=1.6828, running_loss=1.6853, LR=0.000100
[2025-08-26 22:26:46,854][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012088] [Batch 02848/03080] [00:38:46/00:03:09, 0.817s/it]: train_loss_raw=1.7479, running_loss=1.6841, LR=0.000100
[2025-08-26 22:26:53,458][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012096] [Batch 02856/03080] [00:38:53/00:03:03, 0.817s/it]: train_loss_raw=1.6665, running_loss=1.6818, LR=0.000100
[2025-08-26 22:27:00,029][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012104] [Batch 02864/03080] [00:38:59/00:02:56, 0.817s/it]: train_loss_raw=1.6548, running_loss=1.6808, LR=0.000100
[2025-08-26 22:27:06,649][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012112] [Batch 02872/03080] [00:39:06/00:02:49, 0.817s/it]: train_loss_raw=1.7114, running_loss=1.6823, LR=0.000100
[2025-08-26 22:27:13,269][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012120] [Batch 02880/03080] [00:39:13/00:02:43, 0.817s/it]: train_loss_raw=1.6713, running_loss=1.6825, LR=0.000100
[2025-08-26 22:27:19,904][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012128] [Batch 02888/03080] [00:39:19/00:02:36, 0.817s/it]: train_loss_raw=1.6748, running_loss=1.6793, LR=0.000100
[2025-08-26 22:27:26,407][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012136] [Batch 02896/03080] [00:39:26/00:02:30, 0.817s/it]: train_loss_raw=1.7527, running_loss=1.6795, LR=0.000100
[2025-08-26 22:27:33,022][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012144] [Batch 02904/03080] [00:39:32/00:02:23, 0.817s/it]: train_loss_raw=1.7299, running_loss=1.6813, LR=0.000100
[2025-08-26 22:27:39,639][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012152] [Batch 02912/03080] [00:39:39/00:02:17, 0.817s/it]: train_loss_raw=1.6712, running_loss=1.6798, LR=0.000100
[2025-08-26 22:27:46,226][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012160] [Batch 02920/03080] [00:39:46/00:02:10, 0.817s/it]: train_loss_raw=1.6352, running_loss=1.6811, LR=0.000100
[2025-08-26 22:27:52,802][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012168] [Batch 02928/03080] [00:39:52/00:02:04, 0.817s/it]: train_loss_raw=1.7075, running_loss=1.6814, LR=0.000100
[2025-08-26 22:27:59,431][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012176] [Batch 02936/03080] [00:39:59/00:01:57, 0.817s/it]: train_loss_raw=1.6340, running_loss=1.6808, LR=0.000100
[2025-08-26 22:28:06,036][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012184] [Batch 02944/03080] [00:40:05/00:01:51, 0.817s/it]: train_loss_raw=1.7103, running_loss=1.6818, LR=0.000100
[2025-08-26 22:28:12,593][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012192] [Batch 02952/03080] [00:40:12/00:01:44, 0.817s/it]: train_loss_raw=1.6343, running_loss=1.6794, LR=0.000100
[2025-08-26 22:28:19,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012200] [Batch 02960/03080] [00:40:19/00:01:38, 0.817s/it]: train_loss_raw=1.7542, running_loss=1.6785, LR=0.000100
[2025-08-26 22:28:25,938][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012208] [Batch 02968/03080] [00:40:25/00:01:31, 0.817s/it]: train_loss_raw=1.6460, running_loss=1.6800, LR=0.000100
[2025-08-26 22:28:32,567][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012216] [Batch 02976/03080] [00:40:32/00:01:25, 0.817s/it]: train_loss_raw=1.5560, running_loss=1.6753, LR=0.000100
[2025-08-26 22:28:39,209][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012224] [Batch 02984/03080] [00:40:39/00:01:18, 0.817s/it]: train_loss_raw=1.6789, running_loss=1.6726, LR=0.000100
[2025-08-26 22:28:45,859][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012232] [Batch 02992/03080] [00:40:45/00:01:11, 0.817s/it]: train_loss_raw=1.7062, running_loss=1.6729, LR=0.000100
[2025-08-26 22:28:52,532][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012240] [Batch 03000/03080] [00:40:52/00:01:05, 0.817s/it]: train_loss_raw=1.5851, running_loss=1.6720, LR=0.000100
[2025-08-26 22:28:59,123][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012248] [Batch 03008/03080] [00:40:59/00:00:58, 0.818s/it]: train_loss_raw=1.6299, running_loss=1.6726, LR=0.000100
[2025-08-26 22:29:05,768][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012256] [Batch 03016/03080] [00:41:05/00:00:52, 0.818s/it]: train_loss_raw=1.6923, running_loss=1.6742, LR=0.000100
[2025-08-26 22:29:12,421][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012264] [Batch 03024/03080] [00:41:12/00:00:45, 0.818s/it]: train_loss_raw=1.6508, running_loss=1.6748, LR=0.000100
[2025-08-26 22:29:19,062][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012272] [Batch 03032/03080] [00:41:19/00:00:39, 0.818s/it]: train_loss_raw=1.6970, running_loss=1.6736, LR=0.000100
[2025-08-26 22:29:25,744][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012280] [Batch 03040/03080] [00:41:25/00:00:32, 0.818s/it]: train_loss_raw=1.6604, running_loss=1.6721, LR=0.000100
[2025-08-26 22:29:32,376][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012288] [Batch 03048/03080] [00:41:32/00:00:26, 0.818s/it]: train_loss_raw=1.6671, running_loss=1.6707, LR=0.000100
[2025-08-26 22:29:38,971][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012296] [Batch 03056/03080] [00:41:38/00:00:19, 0.818s/it]: train_loss_raw=1.6654, running_loss=1.6700, LR=0.000100
[2025-08-26 22:29:45,604][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012304] [Batch 03064/03080] [00:41:45/00:00:13, 0.818s/it]: train_loss_raw=1.8075, running_loss=1.6719, LR=0.000100
[2025-08-26 22:29:52,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012312] [Batch 03072/03080] [00:41:52/00:00:06, 0.818s/it]: train_loss_raw=1.6295, running_loss=1.6733, LR=0.000100
[2025-08-26 22:30:04,222][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012320] [Batch 03080/03080] [00:42:04/00:00:00, 0.820s/it]: train_loss_raw=1.6419, running_loss=1.6690, LR=0.000100
[2025-08-26 22:30:04,785][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-26 22:30:17,090][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00007/00310] [00:00:12/00:07:44, 1.538s/it]
[2025-08-26 22:30:30,016][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00015/00310] [00:00:25/00:07:43, 1.577s/it]
[2025-08-26 22:30:43,891][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00023/00310] [00:00:39/00:07:46, 1.629s/it]
[2025-08-26 22:30:57,493][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00031/00310] [00:00:52/00:07:37, 1.647s/it]
[2025-08-26 22:31:11,389][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00039/00310] [00:01:06/00:07:29, 1.665s/it]
[2025-08-26 22:31:24,901][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00047/00310] [00:01:20/00:07:17, 1.669s/it]
[2025-08-26 22:31:38,658][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00055/00310] [00:01:33/00:07:05, 1.676s/it]
[2025-08-26 22:31:52,107][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00063/00310] [00:01:47/00:06:52, 1.677s/it]
[2025-08-26 22:32:05,769][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00071/00310] [00:02:00/00:06:39, 1.680s/it]
[2025-08-26 22:32:19,854][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00079/00310] [00:02:15/00:06:28, 1.688s/it]
[2025-08-26 22:32:33,484][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00087/00310] [00:02:28/00:06:15, 1.690s/it]
[2025-08-26 22:32:46,934][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00095/00310] [00:02:42/00:06:01, 1.689s/it]
[2025-08-26 22:33:00,654][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00103/00310] [00:02:55/00:05:48, 1.691s/it]
[2025-08-26 22:33:14,424][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00111/00310] [00:03:09/00:05:35, 1.693s/it]
[2025-08-26 22:33:28,062][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00119/00310] [00:03:23/00:05:21, 1.694s/it]
[2025-08-26 22:33:41,728][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00127/00310] [00:03:36/00:05:08, 1.695s/it]
[2025-08-26 22:33:55,373][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00135/00310] [00:03:50/00:04:55, 1.695s/it]
[2025-08-26 22:34:09,108][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00143/00310] [00:04:04/00:04:41, 1.697s/it]
[2025-08-26 22:34:21,984][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00151/00310] [00:04:17/00:04:27, 1.692s/it]
[2025-08-26 22:34:34,756][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00159/00310] [00:04:29/00:04:13, 1.687s/it]
[2025-08-26 22:34:48,303][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00167/00310] [00:04:43/00:03:59, 1.688s/it]
[2025-08-26 22:35:01,009][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00175/00310] [00:04:56/00:03:45, 1.683s/it]
[2025-08-26 22:35:13,812][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00183/00310] [00:05:09/00:03:31, 1.679s/it]
[2025-08-26 22:35:27,237][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00191/00310] [00:05:22/00:03:18, 1.679s/it]
[2025-08-26 22:35:40,324][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00199/00310] [00:05:35/00:03:04, 1.678s/it]
[2025-08-26 22:35:53,290][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00207/00310] [00:05:48/00:02:50, 1.676s/it]
[2025-08-26 22:36:06,172][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00215/00310] [00:06:01/00:02:37, 1.673s/it]
[2025-08-26 22:36:19,634][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00223/00310] [00:06:14/00:02:23, 1.673s/it]
[2025-08-26 22:36:33,232][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00231/00310] [00:06:28/00:02:10, 1.674s/it]
[2025-08-26 22:36:46,463][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00239/00310] [00:06:41/00:01:57, 1.674s/it]
[2025-08-26 22:36:59,388][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00247/00310] [00:06:54/00:01:43, 1.672s/it]
[2025-08-26 22:37:13,136][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00255/00310] [00:07:08/00:01:30, 1.673s/it]
[2025-08-26 22:37:26,643][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00263/00310] [00:07:21/00:01:16, 1.674s/it]
[2025-08-26 22:37:39,991][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00271/00310] [00:07:35/00:01:03, 1.674s/it]
[2025-08-26 22:37:53,384][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00279/00310] [00:07:48/00:00:50, 1.674s/it]
[2025-08-26 22:38:07,115][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00287/00310] [00:08:02/00:00:36, 1.675s/it]
[2025-08-26 22:38:20,294][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00295/00310] [00:08:15/00:00:23, 1.674s/it]
[2025-08-26 22:38:33,689][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00303/00310] [00:08:28/00:00:10, 1.674s/it]
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.66903, valid_loss=2.31052
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.860
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.016
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.017
[2025-08-26 22:38:43,178][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.001
[2025-08-26 22:38:43,196][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 03:11:57, remaining time 20:47:40, 00:47:59 per epoch
[2025-08-26 22:38:49,077][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012328] [Batch 00008/03080] [00:00:05/00:35:38, 0.696s/it]: train_loss_raw=1.6048, running_loss=1.5844, LR=0.000100
[2025-08-26 22:38:55,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012336] [Batch 00016/03080] [00:00:12/00:38:29, 0.754s/it]: train_loss_raw=1.7062, running_loss=1.5905, LR=0.000100
[2025-08-26 22:39:02,063][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012344] [Batch 00024/03080] [00:00:18/00:39:22, 0.773s/it]: train_loss_raw=1.7200, running_loss=1.5968, LR=0.000100
[2025-08-26 22:39:08,642][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012352] [Batch 00032/03080] [00:00:25/00:39:54, 0.785s/it]: train_loss_raw=1.6649, running_loss=1.6017, LR=0.000100
[2025-08-26 22:39:15,231][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012360] [Batch 00040/03080] [00:00:31/00:40:10, 0.793s/it]: train_loss_raw=1.7610, running_loss=1.6089, LR=0.000100
[2025-08-26 22:39:21,767][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012368] [Batch 00048/03080] [00:00:38/00:40:16, 0.797s/it]: train_loss_raw=1.6847, running_loss=1.6121, LR=0.000100
[2025-08-26 22:39:28,339][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012376] [Batch 00056/03080] [00:00:44/00:40:20, 0.801s/it]: train_loss_raw=1.6675, running_loss=1.6146, LR=0.000100
[2025-08-26 22:39:34,923][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012384] [Batch 00064/03080] [00:00:51/00:40:22, 0.803s/it]: train_loss_raw=1.6247, running_loss=1.6171, LR=0.000100
[2025-08-26 22:39:41,501][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012392] [Batch 00072/03080] [00:00:57/00:40:22, 0.805s/it]: train_loss_raw=1.7495, running_loss=1.6264, LR=0.000100
[2025-08-26 22:39:48,139][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012400] [Batch 00080/03080] [00:01:04/00:40:23, 0.808s/it]: train_loss_raw=1.5975, running_loss=1.6283, LR=0.000100
[2025-08-26 22:39:54,706][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012408] [Batch 00088/03080] [00:01:11/00:40:20, 0.809s/it]: train_loss_raw=1.7307, running_loss=1.6278, LR=0.000100
[2025-08-26 22:40:01,448][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012416] [Batch 00096/03080] [00:01:17/00:40:22, 0.812s/it]: train_loss_raw=1.6985, running_loss=1.6276, LR=0.000100
[2025-08-26 22:40:08,055][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012424] [Batch 00104/03080] [00:01:24/00:40:19, 0.813s/it]: train_loss_raw=1.6745, running_loss=1.6295, LR=0.000100
[2025-08-26 22:40:14,733][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012432] [Batch 00112/03080] [00:01:31/00:40:17, 0.815s/it]: train_loss_raw=1.6193, running_loss=1.6323, LR=0.000100
[2025-08-26 22:40:21,377][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012440] [Batch 00120/03080] [00:01:37/00:40:14, 0.816s/it]: train_loss_raw=1.6217, running_loss=1.6321, LR=0.000100
[2025-08-26 22:40:28,044][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012448] [Batch 00128/03080] [00:01:44/00:40:10, 0.817s/it]: train_loss_raw=1.7028, running_loss=1.6360, LR=0.000100
[2025-08-26 22:40:34,561][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012456] [Batch 00136/03080] [00:01:51/00:40:03, 0.817s/it]: train_loss_raw=1.5995, running_loss=1.6347, LR=0.000100
[2025-08-26 22:40:41,120][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012464] [Batch 00144/03080] [00:01:57/00:39:57, 0.817s/it]: train_loss_raw=1.5667, running_loss=1.6351, LR=0.000100
[2025-08-26 22:40:47,552][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012472] [Batch 00152/03080] [00:02:04/00:39:49, 0.816s/it]: train_loss_raw=1.6397, running_loss=1.6378, LR=0.000100
[2025-08-26 22:40:54,134][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012480] [Batch 00160/03080] [00:02:10/00:39:43, 0.816s/it]: train_loss_raw=1.6007, running_loss=1.6378, LR=0.000100
[2025-08-26 22:41:00,714][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012488] [Batch 00168/03080] [00:02:17/00:39:38, 0.817s/it]: train_loss_raw=1.6044, running_loss=1.6387, LR=0.000100
[2025-08-26 22:41:07,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012496] [Batch 00176/03080] [00:02:23/00:39:31, 0.817s/it]: train_loss_raw=1.6757, running_loss=1.6391, LR=0.000100
[2025-08-26 22:41:13,812][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012504] [Batch 00184/03080] [00:02:30/00:39:25, 0.817s/it]: train_loss_raw=1.6903, running_loss=1.6405, LR=0.000100
[2025-08-26 22:41:20,366][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012512] [Batch 00192/03080] [00:02:36/00:39:19, 0.817s/it]: train_loss_raw=1.6864, running_loss=1.6411, LR=0.000100
[2025-08-26 22:41:26,459][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012520] [Batch 00200/03080] [00:02:42/00:39:06, 0.815s/it]: train_loss_raw=1.6522, running_loss=1.6446, LR=0.000100
[2025-08-26 22:41:32,695][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012528] [Batch 00208/03080] [00:02:49/00:38:56, 0.813s/it]: train_loss_raw=1.5989, running_loss=1.6458, LR=0.000100
[2025-08-26 22:41:39,177][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012536] [Batch 00216/03080] [00:02:55/00:38:49, 0.813s/it]: train_loss_raw=1.6823, running_loss=1.6458, LR=0.000100
[2025-08-26 22:41:45,692][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012544] [Batch 00224/03080] [00:03:02/00:38:42, 0.813s/it]: train_loss_raw=1.6213, running_loss=1.6441, LR=0.000100
[2025-08-26 22:41:51,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012552] [Batch 00232/03080] [00:03:08/00:38:33, 0.812s/it]: train_loss_raw=1.7227, running_loss=1.6436, LR=0.000100
[2025-08-26 22:41:57,988][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012560] [Batch 00240/03080] [00:03:14/00:38:21, 0.810s/it]: train_loss_raw=1.6712, running_loss=1.6422, LR=0.000100
[2025-08-26 22:42:04,168][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012568] [Batch 00248/03080] [00:03:20/00:38:11, 0.809s/it]: train_loss_raw=1.6677, running_loss=1.6451, LR=0.000100
[2025-08-26 22:42:10,389][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012576] [Batch 00256/03080] [00:03:26/00:38:02, 0.808s/it]: train_loss_raw=1.6152, running_loss=1.6434, LR=0.000100
[2025-08-26 22:42:16,524][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012584] [Batch 00264/03080] [00:03:33/00:37:52, 0.807s/it]: train_loss_raw=1.5868, running_loss=1.6426, LR=0.000100
[2025-08-26 22:42:22,670][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012592] [Batch 00272/03080] [00:03:39/00:37:42, 0.806s/it]: train_loss_raw=1.6391, running_loss=1.6414, LR=0.000100
[2025-08-26 22:42:28,740][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012600] [Batch 00280/03080] [00:03:45/00:37:32, 0.804s/it]: train_loss_raw=1.6761, running_loss=1.6411, LR=0.000100
[2025-08-26 22:42:35,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012608] [Batch 00288/03080] [00:03:51/00:37:25, 0.804s/it]: train_loss_raw=1.7067, running_loss=1.6441, LR=0.000100
[2025-08-26 22:42:41,888][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012616] [Batch 00296/03080] [00:03:58/00:37:22, 0.805s/it]: train_loss_raw=1.6927, running_loss=1.6418, LR=0.000100
[2025-08-26 22:42:48,460][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012624] [Batch 00304/03080] [00:04:04/00:37:16, 0.806s/it]: train_loss_raw=1.7237, running_loss=1.6428, LR=0.000100
[2025-08-26 22:42:55,046][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012632] [Batch 00312/03080] [00:04:11/00:37:11, 0.806s/it]: train_loss_raw=1.6525, running_loss=1.6441, LR=0.000100
[2025-08-26 22:43:01,668][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012640] [Batch 00320/03080] [00:04:18/00:37:06, 0.807s/it]: train_loss_raw=1.6402, running_loss=1.6451, LR=0.000100
[2025-08-26 22:43:07,975][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012648] [Batch 00328/03080] [00:04:24/00:36:58, 0.806s/it]: train_loss_raw=1.7724, running_loss=1.6471, LR=0.000100
[2025-08-26 22:43:14,198][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012656] [Batch 00336/03080] [00:04:30/00:36:50, 0.806s/it]: train_loss_raw=1.6729, running_loss=1.6480, LR=0.000100
[2025-08-26 22:43:20,552][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012664] [Batch 00344/03080] [00:04:37/00:36:43, 0.805s/it]: train_loss_raw=1.6942, running_loss=1.6495, LR=0.000100
[2025-08-26 22:43:26,738][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012672] [Batch 00352/03080] [00:04:43/00:36:35, 0.805s/it]: train_loss_raw=1.6565, running_loss=1.6502, LR=0.000100
[2025-08-26 22:43:32,825][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012680] [Batch 00360/03080] [00:04:49/00:36:25, 0.804s/it]: train_loss_raw=1.6057, running_loss=1.6469, LR=0.000100
[2025-08-26 22:43:38,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012688] [Batch 00368/03080] [00:04:55/00:36:17, 0.803s/it]: train_loss_raw=1.5560, running_loss=1.6474, LR=0.000100
[2025-08-26 22:43:45,012][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012696] [Batch 00376/03080] [00:05:01/00:36:08, 0.802s/it]: train_loss_raw=1.6054, running_loss=1.6458, LR=0.000100
[2025-08-26 22:43:51,147][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012704] [Batch 00384/03080] [00:05:07/00:35:59, 0.801s/it]: train_loss_raw=1.6224, running_loss=1.6448, LR=0.000100
[2025-08-26 22:43:57,298][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012712] [Batch 00392/03080] [00:05:13/00:35:51, 0.800s/it]: train_loss_raw=1.5963, running_loss=1.6444, LR=0.000100
[2025-08-26 22:44:03,806][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012720] [Batch 00400/03080] [00:05:20/00:35:45, 0.801s/it]: train_loss_raw=1.6827, running_loss=1.6441, LR=0.000100
[2025-08-26 22:44:10,339][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012728] [Batch 00408/03080] [00:05:26/00:35:40, 0.801s/it]: train_loss_raw=1.7131, running_loss=1.6448, LR=0.000100
[2025-08-26 22:44:16,870][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012736] [Batch 00416/03080] [00:05:33/00:35:34, 0.801s/it]: train_loss_raw=1.6863, running_loss=1.6427, LR=0.000100
[2025-08-26 22:44:23,024][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012744] [Batch 00424/03080] [00:05:39/00:35:26, 0.801s/it]: train_loss_raw=1.6407, running_loss=1.6417, LR=0.000100
[2025-08-26 22:44:29,376][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012752] [Batch 00432/03080] [00:05:45/00:35:20, 0.801s/it]: train_loss_raw=1.5990, running_loss=1.6405, LR=0.000100
[2025-08-26 22:44:35,969][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012760] [Batch 00440/03080] [00:05:52/00:35:14, 0.801s/it]: train_loss_raw=1.6901, running_loss=1.6427, LR=0.000100
[2025-08-26 22:44:42,602][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012768] [Batch 00448/03080] [00:05:59/00:35:09, 0.802s/it]: train_loss_raw=1.6481, running_loss=1.6395, LR=0.000100
[2025-08-26 22:44:49,115][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012776] [Batch 00456/03080] [00:06:05/00:35:03, 0.802s/it]: train_loss_raw=1.5576, running_loss=1.6369, LR=0.000100
[2025-08-26 22:44:55,981][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012784] [Batch 00464/03080] [00:06:12/00:34:59, 0.803s/it]: train_loss_raw=1.6918, running_loss=1.6381, LR=0.000100
[2025-08-26 22:45:02,840][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012792] [Batch 00472/03080] [00:06:19/00:34:55, 0.804s/it]: train_loss_raw=1.6958, running_loss=1.6380, LR=0.000100
[2025-08-26 22:45:09,784][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012800] [Batch 00480/03080] [00:06:26/00:34:52, 0.805s/it]: train_loss_raw=1.7216, running_loss=1.6379, LR=0.000100
[2025-08-26 22:45:16,433][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012808] [Batch 00488/03080] [00:06:32/00:34:47, 0.805s/it]: train_loss_raw=1.8109, running_loss=1.6378, LR=0.000100
[2025-08-26 22:45:22,976][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012816] [Batch 00496/03080] [00:06:39/00:34:41, 0.805s/it]: train_loss_raw=1.5417, running_loss=1.6347, LR=0.000100
[2025-08-26 22:45:29,886][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012824] [Batch 00504/03080] [00:06:46/00:34:37, 0.806s/it]: train_loss_raw=1.7399, running_loss=1.6347, LR=0.000100
[2025-08-26 22:45:36,850][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012832] [Batch 00512/03080] [00:06:53/00:34:33, 0.807s/it]: train_loss_raw=1.7528, running_loss=1.6339, LR=0.000100
[2025-08-26 22:45:43,329][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012840] [Batch 00520/03080] [00:06:59/00:34:26, 0.807s/it]: train_loss_raw=1.6219, running_loss=1.6324, LR=0.000100
[2025-08-26 22:45:50,144][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012848] [Batch 00528/03080] [00:07:06/00:34:22, 0.808s/it]: train_loss_raw=1.6955, running_loss=1.6365, LR=0.000100
[2025-08-26 22:45:57,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012856] [Batch 00536/03080] [00:07:13/00:34:17, 0.809s/it]: train_loss_raw=1.6804, running_loss=1.6375, LR=0.000100
[2025-08-26 22:46:04,007][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012864] [Batch 00544/03080] [00:07:20/00:34:13, 0.810s/it]: train_loss_raw=1.6463, running_loss=1.6367, LR=0.000100
[2025-08-26 22:46:10,603][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012872] [Batch 00552/03080] [00:07:27/00:34:07, 0.810s/it]: train_loss_raw=1.5775, running_loss=1.6361, LR=0.000100
[2025-08-26 22:46:17,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012880] [Batch 00560/03080] [00:07:33/00:34:02, 0.811s/it]: train_loss_raw=1.6211, running_loss=1.6372, LR=0.000100
[2025-08-26 22:46:24,152][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012888] [Batch 00568/03080] [00:07:40/00:33:57, 0.811s/it]: train_loss_raw=1.6292, running_loss=1.6389, LR=0.000100
[2025-08-26 22:46:30,813][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012896] [Batch 00576/03080] [00:07:47/00:33:51, 0.811s/it]: train_loss_raw=1.7491, running_loss=1.6400, LR=0.000100
[2025-08-26 22:46:37,565][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012904] [Batch 00584/03080] [00:07:54/00:33:46, 0.812s/it]: train_loss_raw=1.5850, running_loss=1.6389, LR=0.000100
[2025-08-26 22:46:45,053][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012912] [Batch 00592/03080] [00:08:01/00:33:43, 0.813s/it]: train_loss_raw=1.6560, running_loss=1.6378, LR=0.000100
[2025-08-26 22:46:51,787][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012920] [Batch 00600/03080] [00:08:08/00:33:38, 0.814s/it]: train_loss_raw=1.6150, running_loss=1.6390, LR=0.000100
[2025-08-26 22:46:59,005][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012928] [Batch 00608/03080] [00:08:15/00:33:34, 0.815s/it]: train_loss_raw=1.6215, running_loss=1.6403, LR=0.000100
[2025-08-26 22:47:05,641][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012936] [Batch 00616/03080] [00:08:22/00:33:28, 0.815s/it]: train_loss_raw=1.6439, running_loss=1.6418, LR=0.000100
[2025-08-26 22:47:12,161][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012944] [Batch 00624/03080] [00:08:28/00:33:22, 0.815s/it]: train_loss_raw=1.6632, running_loss=1.6435, LR=0.000100
[2025-08-26 22:47:18,738][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012952] [Batch 00632/03080] [00:08:35/00:33:15, 0.815s/it]: train_loss_raw=1.6308, running_loss=1.6426, LR=0.000100
[2025-08-26 22:47:25,259][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012960] [Batch 00640/03080] [00:08:41/00:33:09, 0.815s/it]: train_loss_raw=1.6262, running_loss=1.6419, LR=0.000100
[2025-08-26 22:47:31,806][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012968] [Batch 00648/03080] [00:08:48/00:33:02, 0.815s/it]: train_loss_raw=1.5874, running_loss=1.6404, LR=0.000100
[2025-08-26 22:47:38,297][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012976] [Batch 00656/03080] [00:08:54/00:32:56, 0.815s/it]: train_loss_raw=1.6154, running_loss=1.6393, LR=0.000100
[2025-08-26 22:47:44,773][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012984] [Batch 00664/03080] [00:09:01/00:32:49, 0.815s/it]: train_loss_raw=1.5627, running_loss=1.6380, LR=0.000100
[2025-08-26 22:47:51,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012992] [Batch 00672/03080] [00:09:07/00:32:42, 0.815s/it]: train_loss_raw=1.5512, running_loss=1.6376, LR=0.000100
[2025-08-26 22:47:57,917][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013000] [Batch 00680/03080] [00:09:14/00:32:36, 0.815s/it]: train_loss_raw=1.6555, running_loss=1.6397, LR=0.000100
[2025-08-26 22:48:04,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013008] [Batch 00688/03080] [00:09:20/00:32:30, 0.815s/it]: train_loss_raw=1.6084, running_loss=1.6384, LR=0.000100
[2025-08-26 22:48:10,921][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013016] [Batch 00696/03080] [00:09:27/00:32:23, 0.815s/it]: train_loss_raw=1.6019, running_loss=1.6377, LR=0.000100
[2025-08-26 22:48:17,380][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013024] [Batch 00704/03080] [00:09:33/00:32:16, 0.815s/it]: train_loss_raw=1.5730, running_loss=1.6348, LR=0.000100
[2025-08-26 22:48:23,841][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013032] [Batch 00712/03080] [00:09:40/00:32:10, 0.815s/it]: train_loss_raw=1.7129, running_loss=1.6360, LR=0.000100
[2025-08-26 22:48:30,428][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013040] [Batch 00720/03080] [00:09:46/00:32:03, 0.815s/it]: train_loss_raw=1.6071, running_loss=1.6357, LR=0.000100
[2025-08-26 22:48:36,955][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013048] [Batch 00728/03080] [00:09:53/00:31:57, 0.815s/it]: train_loss_raw=1.6091, running_loss=1.6358, LR=0.000100
[2025-08-26 22:48:43,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013056] [Batch 00736/03080] [00:10:00/00:31:51, 0.815s/it]: train_loss_raw=1.6594, running_loss=1.6343, LR=0.000100
[2025-08-26 22:48:50,091][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013064] [Batch 00744/03080] [00:10:06/00:31:44, 0.815s/it]: train_loss_raw=1.5716, running_loss=1.6302, LR=0.000100
[2025-08-26 22:48:56,632][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013072] [Batch 00752/03080] [00:10:13/00:31:38, 0.815s/it]: train_loss_raw=1.7666, running_loss=1.6279, LR=0.000100
[2025-08-26 22:49:03,121][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013080] [Batch 00760/03080] [00:10:19/00:31:31, 0.815s/it]: train_loss_raw=1.6379, running_loss=1.6273, LR=0.000100
[2025-08-26 22:49:09,605][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013088] [Batch 00768/03080] [00:10:26/00:31:24, 0.815s/it]: train_loss_raw=1.6768, running_loss=1.6287, LR=0.000100
[2025-08-26 22:49:16,158][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013096] [Batch 00776/03080] [00:10:32/00:31:18, 0.815s/it]: train_loss_raw=1.5597, running_loss=1.6289, LR=0.000100
[2025-08-26 22:49:22,754][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013104] [Batch 00784/03080] [00:10:39/00:31:12, 0.815s/it]: train_loss_raw=1.6643, running_loss=1.6290, LR=0.000100
[2025-08-26 22:49:29,268][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013112] [Batch 00792/03080] [00:10:45/00:31:05, 0.815s/it]: train_loss_raw=1.5922, running_loss=1.6255, LR=0.000100
[2025-08-26 22:49:35,896][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013120] [Batch 00800/03080] [00:10:52/00:30:59, 0.815s/it]: train_loss_raw=1.5372, running_loss=1.6272, LR=0.000100
[2025-08-26 22:49:42,433][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013128] [Batch 00808/03080] [00:10:58/00:30:52, 0.816s/it]: train_loss_raw=1.6985, running_loss=1.6297, LR=0.000100
[2025-08-26 22:49:48,917][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013136] [Batch 00816/03080] [00:11:05/00:30:46, 0.815s/it]: train_loss_raw=1.6414, running_loss=1.6320, LR=0.000100
[2025-08-26 22:49:55,389][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013144] [Batch 00824/03080] [00:11:11/00:30:39, 0.815s/it]: train_loss_raw=1.5034, running_loss=1.6278, LR=0.000100
[2025-08-26 22:50:01,931][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013152] [Batch 00832/03080] [00:11:18/00:30:33, 0.815s/it]: train_loss_raw=1.6860, running_loss=1.6309, LR=0.000100
[2025-08-26 22:50:08,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013160] [Batch 00840/03080] [00:11:24/00:30:26, 0.815s/it]: train_loss_raw=1.6432, running_loss=1.6318, LR=0.000100
[2025-08-26 22:50:15,005][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013168] [Batch 00848/03080] [00:11:31/00:30:20, 0.815s/it]: train_loss_raw=1.6208, running_loss=1.6288, LR=0.000100
[2025-08-26 22:50:21,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013176] [Batch 00856/03080] [00:11:37/00:30:13, 0.815s/it]: train_loss_raw=1.5571, running_loss=1.6281, LR=0.000100
[2025-08-26 22:50:28,028][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013184] [Batch 00864/03080] [00:11:44/00:30:06, 0.815s/it]: train_loss_raw=1.6281, running_loss=1.6269, LR=0.000100
[2025-08-26 22:50:34,501][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013192] [Batch 00872/03080] [00:11:50/00:30:00, 0.815s/it]: train_loss_raw=1.6907, running_loss=1.6287, LR=0.000100
[2025-08-26 22:50:41,134][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013200] [Batch 00880/03080] [00:11:57/00:29:54, 0.815s/it]: train_loss_raw=1.6268, running_loss=1.6311, LR=0.000100
[2025-08-26 22:50:47,722][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013208] [Batch 00888/03080] [00:12:04/00:29:47, 0.816s/it]: train_loss_raw=1.5737, running_loss=1.6308, LR=0.000100
[2025-08-26 22:50:54,234][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013216] [Batch 00896/03080] [00:12:10/00:29:41, 0.816s/it]: train_loss_raw=1.5765, running_loss=1.6302, LR=0.000100
[2025-08-26 22:51:00,800][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013224] [Batch 00904/03080] [00:12:17/00:29:34, 0.816s/it]: train_loss_raw=1.6608, running_loss=1.6308, LR=0.000100
[2025-08-26 22:51:07,322][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013232] [Batch 00912/03080] [00:12:23/00:29:28, 0.816s/it]: train_loss_raw=1.5789, running_loss=1.6298, LR=0.000100
[2025-08-26 22:51:13,879][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013240] [Batch 00920/03080] [00:12:30/00:29:21, 0.816s/it]: train_loss_raw=1.5646, running_loss=1.6278, LR=0.000100
[2025-08-26 22:51:20,421][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013248] [Batch 00928/03080] [00:12:36/00:29:15, 0.816s/it]: train_loss_raw=1.6123, running_loss=1.6270, LR=0.000100
[2025-08-26 22:51:26,956][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013256] [Batch 00936/03080] [00:12:43/00:29:08, 0.816s/it]: train_loss_raw=1.6030, running_loss=1.6267, LR=0.000100
[2025-08-26 22:51:33,510][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013264] [Batch 00944/03080] [00:12:50/00:29:02, 0.816s/it]: train_loss_raw=1.5999, running_loss=1.6274, LR=0.000100
[2025-08-26 22:51:40,023][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013272] [Batch 00952/03080] [00:12:56/00:28:55, 0.816s/it]: train_loss_raw=1.5723, running_loss=1.6265, LR=0.000100
[2025-08-26 22:51:46,603][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013280] [Batch 00960/03080] [00:13:03/00:28:49, 0.816s/it]: train_loss_raw=1.5898, running_loss=1.6270, LR=0.000100
[2025-08-26 22:51:53,143][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013288] [Batch 00968/03080] [00:13:09/00:28:42, 0.816s/it]: train_loss_raw=1.6812, running_loss=1.6248, LR=0.000100
[2025-08-26 22:51:59,753][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013296] [Batch 00976/03080] [00:13:16/00:28:36, 0.816s/it]: train_loss_raw=1.6037, running_loss=1.6244, LR=0.000100
[2025-08-26 22:52:06,217][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013304] [Batch 00984/03080] [00:13:22/00:28:29, 0.816s/it]: train_loss_raw=1.6716, running_loss=1.6220, LR=0.000100
[2025-08-26 22:52:12,753][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013312] [Batch 00992/03080] [00:13:29/00:28:23, 0.816s/it]: train_loss_raw=1.5296, running_loss=1.6214, LR=0.000100
[2025-08-26 22:52:19,319][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013320] [Batch 01000/03080] [00:13:35/00:28:16, 0.816s/it]: train_loss_raw=1.6032, running_loss=1.6185, LR=0.000100
[2025-08-26 22:52:25,896][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013328] [Batch 01008/03080] [00:13:42/00:28:10, 0.816s/it]: train_loss_raw=1.6749, running_loss=1.6161, LR=0.000100
[2025-08-26 22:52:32,457][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013336] [Batch 01016/03080] [00:13:48/00:28:04, 0.816s/it]: train_loss_raw=1.5830, running_loss=1.6171, LR=0.000100
[2025-08-26 22:52:38,971][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013344] [Batch 01024/03080] [00:13:55/00:27:57, 0.816s/it]: train_loss_raw=1.6313, running_loss=1.6165, LR=0.000100
[2025-08-26 22:52:45,555][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013352] [Batch 01032/03080] [00:14:02/00:27:51, 0.816s/it]: train_loss_raw=1.5286, running_loss=1.6152, LR=0.000100
[2025-08-26 22:52:52,151][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013360] [Batch 01040/03080] [00:14:08/00:27:44, 0.816s/it]: train_loss_raw=1.7319, running_loss=1.6170, LR=0.000100
[2025-08-26 22:52:58,690][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013368] [Batch 01048/03080] [00:14:15/00:27:38, 0.816s/it]: train_loss_raw=1.5300, running_loss=1.6141, LR=0.000100
[2025-08-26 22:53:05,212][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013376] [Batch 01056/03080] [00:14:21/00:27:31, 0.816s/it]: train_loss_raw=1.6494, running_loss=1.6158, LR=0.000100
[2025-08-26 22:53:11,746][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013384] [Batch 01064/03080] [00:14:28/00:27:25, 0.816s/it]: train_loss_raw=1.6392, running_loss=1.6186, LR=0.000100
[2025-08-26 22:53:18,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013392] [Batch 01072/03080] [00:14:34/00:27:18, 0.816s/it]: train_loss_raw=1.6428, running_loss=1.6180, LR=0.000100
[2025-08-26 22:53:24,915][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013400] [Batch 01080/03080] [00:14:41/00:27:12, 0.816s/it]: train_loss_raw=1.6808, running_loss=1.6160, LR=0.000100
[2025-08-26 22:53:31,474][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013408] [Batch 01088/03080] [00:14:47/00:27:05, 0.816s/it]: train_loss_raw=1.6647, running_loss=1.6157, LR=0.000100
[2025-08-26 22:53:37,984][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013416] [Batch 01096/03080] [00:14:54/00:26:59, 0.816s/it]: train_loss_raw=1.6209, running_loss=1.6151, LR=0.000100
[2025-08-26 22:53:44,593][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013424] [Batch 01104/03080] [00:15:01/00:26:52, 0.816s/it]: train_loss_raw=1.6215, running_loss=1.6146, LR=0.000100
[2025-08-26 22:53:51,111][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013432] [Batch 01112/03080] [00:15:07/00:26:46, 0.816s/it]: train_loss_raw=1.5448, running_loss=1.6173, LR=0.000100
[2025-08-26 22:53:57,672][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013440] [Batch 01120/03080] [00:15:14/00:26:39, 0.816s/it]: train_loss_raw=1.6805, running_loss=1.6161, LR=0.000100
[2025-08-26 22:54:04,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013448] [Batch 01128/03080] [00:15:20/00:26:33, 0.816s/it]: train_loss_raw=1.6317, running_loss=1.6163, LR=0.000100
[2025-08-26 22:54:10,803][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013456] [Batch 01136/03080] [00:15:27/00:26:26, 0.816s/it]: train_loss_raw=1.5840, running_loss=1.6148, LR=0.000100
[2025-08-26 22:54:17,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013464] [Batch 01144/03080] [00:15:33/00:26:20, 0.816s/it]: train_loss_raw=1.5501, running_loss=1.6144, LR=0.000100
[2025-08-26 22:54:23,845][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013472] [Batch 01152/03080] [00:15:40/00:26:13, 0.816s/it]: train_loss_raw=1.6159, running_loss=1.6151, LR=0.000100
[2025-08-26 22:54:30,357][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013480] [Batch 01160/03080] [00:15:46/00:26:07, 0.816s/it]: train_loss_raw=1.5464, running_loss=1.6129, LR=0.000100
[2025-08-26 22:54:36,906][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013488] [Batch 01168/03080] [00:15:53/00:26:00, 0.816s/it]: train_loss_raw=1.6489, running_loss=1.6125, LR=0.000100
[2025-08-26 22:54:43,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013496] [Batch 01176/03080] [00:15:59/00:25:54, 0.816s/it]: train_loss_raw=1.5290, running_loss=1.6129, LR=0.000100
[2025-08-26 22:54:49,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013504] [Batch 01184/03080] [00:16:06/00:25:47, 0.816s/it]: train_loss_raw=1.6585, running_loss=1.6125, LR=0.000100
[2025-08-26 22:54:56,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013512] [Batch 01192/03080] [00:16:13/00:25:41, 0.816s/it]: train_loss_raw=1.7564, running_loss=1.6142, LR=0.000100
[2025-08-26 22:55:03,127][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013520] [Batch 01200/03080] [00:16:19/00:25:34, 0.816s/it]: train_loss_raw=1.5733, running_loss=1.6158, LR=0.000100
[2025-08-26 22:55:09,674][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013528] [Batch 01208/03080] [00:16:26/00:25:28, 0.816s/it]: train_loss_raw=1.6380, running_loss=1.6154, LR=0.000100
[2025-08-26 22:55:16,220][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013536] [Batch 01216/03080] [00:16:32/00:25:21, 0.816s/it]: train_loss_raw=1.6280, running_loss=1.6158, LR=0.000100
[2025-08-26 22:55:22,785][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013544] [Batch 01224/03080] [00:16:39/00:25:15, 0.816s/it]: train_loss_raw=1.5329, running_loss=1.6132, LR=0.000100
[2025-08-26 22:55:29,313][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013552] [Batch 01232/03080] [00:16:45/00:25:08, 0.816s/it]: train_loss_raw=1.5960, running_loss=1.6127, LR=0.000100
[2025-08-26 22:55:35,845][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013560] [Batch 01240/03080] [00:16:52/00:25:02, 0.816s/it]: train_loss_raw=1.6280, running_loss=1.6116, LR=0.000100
[2025-08-26 22:55:42,355][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013568] [Batch 01248/03080] [00:16:58/00:24:55, 0.816s/it]: train_loss_raw=1.5497, running_loss=1.6117, LR=0.000100
[2025-08-26 22:55:48,925][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013576] [Batch 01256/03080] [00:17:05/00:24:49, 0.816s/it]: train_loss_raw=1.5083, running_loss=1.6112, LR=0.000100
[2025-08-26 22:55:55,488][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013584] [Batch 01264/03080] [00:17:11/00:24:42, 0.816s/it]: train_loss_raw=1.4887, running_loss=1.6119, LR=0.000100
[2025-08-26 22:56:02,003][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013592] [Batch 01272/03080] [00:17:18/00:24:36, 0.816s/it]: train_loss_raw=1.6498, running_loss=1.6108, LR=0.000100
[2025-08-26 22:56:08,580][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013600] [Batch 01280/03080] [00:17:25/00:24:29, 0.816s/it]: train_loss_raw=1.6111, running_loss=1.6119, LR=0.000100
[2025-08-26 22:56:15,188][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013608] [Batch 01288/03080] [00:17:31/00:24:23, 0.817s/it]: train_loss_raw=1.6199, running_loss=1.6144, LR=0.000100
[2025-08-26 22:56:21,748][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013616] [Batch 01296/03080] [00:17:38/00:24:16, 0.817s/it]: train_loss_raw=1.6213, running_loss=1.6119, LR=0.000100
[2025-08-26 22:56:28,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013624] [Batch 01304/03080] [00:17:44/00:24:10, 0.817s/it]: train_loss_raw=1.6643, running_loss=1.6127, LR=0.000100
[2025-08-26 22:56:34,846][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013632] [Batch 01312/03080] [00:17:51/00:24:03, 0.817s/it]: train_loss_raw=1.5380, running_loss=1.6112, LR=0.000100
[2025-08-26 22:56:41,333][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013640] [Batch 01320/03080] [00:17:57/00:23:57, 0.817s/it]: train_loss_raw=1.5974, running_loss=1.6089, LR=0.000100
[2025-08-26 22:56:47,953][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013648] [Batch 01328/03080] [00:18:04/00:23:50, 0.817s/it]: train_loss_raw=1.6061, running_loss=1.6092, LR=0.000100
[2025-08-26 22:56:54,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013656] [Batch 01336/03080] [00:18:10/00:23:44, 0.817s/it]: train_loss_raw=1.5832, running_loss=1.6090, LR=0.000100
[2025-08-26 22:57:01,094][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013664] [Batch 01344/03080] [00:18:17/00:23:37, 0.817s/it]: train_loss_raw=1.5905, running_loss=1.6074, LR=0.000100
[2025-08-26 22:57:07,698][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013672] [Batch 01352/03080] [00:18:24/00:23:31, 0.817s/it]: train_loss_raw=1.5586, running_loss=1.6069, LR=0.000100
[2025-08-26 22:57:14,246][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013680] [Batch 01360/03080] [00:18:30/00:23:24, 0.817s/it]: train_loss_raw=1.5180, running_loss=1.6030, LR=0.000100
[2025-08-26 22:57:20,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013688] [Batch 01368/03080] [00:18:37/00:23:18, 0.817s/it]: train_loss_raw=1.5964, running_loss=1.6038, LR=0.000100
[2025-08-26 22:57:27,412][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013696] [Batch 01376/03080] [00:18:43/00:23:11, 0.817s/it]: train_loss_raw=1.7995, running_loss=1.6060, LR=0.000100
[2025-08-26 22:57:33,993][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013704] [Batch 01384/03080] [00:18:50/00:23:05, 0.817s/it]: train_loss_raw=1.5532, running_loss=1.6039, LR=0.000100
[2025-08-26 22:57:40,607][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013712] [Batch 01392/03080] [00:18:57/00:22:58, 0.817s/it]: train_loss_raw=1.6600, running_loss=1.6057, LR=0.000100
[2025-08-26 22:57:47,207][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013720] [Batch 01400/03080] [00:19:03/00:22:52, 0.817s/it]: train_loss_raw=1.5662, running_loss=1.6077, LR=0.000100
[2025-08-26 22:57:53,782][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013728] [Batch 01408/03080] [00:19:10/00:22:45, 0.817s/it]: train_loss_raw=1.7324, running_loss=1.6083, LR=0.000100
[2025-08-26 22:58:00,405][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013736] [Batch 01416/03080] [00:19:16/00:22:39, 0.817s/it]: train_loss_raw=1.6191, running_loss=1.6067, LR=0.000100
[2025-08-26 22:58:06,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013744] [Batch 01424/03080] [00:19:23/00:22:33, 0.817s/it]: train_loss_raw=1.5131, running_loss=1.6048, LR=0.000100
[2025-08-26 22:58:13,665][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013752] [Batch 01432/03080] [00:19:30/00:22:26, 0.817s/it]: train_loss_raw=1.6171, running_loss=1.6067, LR=0.000100
[2025-08-26 22:58:20,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013760] [Batch 01440/03080] [00:19:36/00:22:20, 0.817s/it]: train_loss_raw=1.6068, running_loss=1.6065, LR=0.000100
[2025-08-26 22:58:26,841][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013768] [Batch 01448/03080] [00:19:43/00:22:13, 0.817s/it]: train_loss_raw=1.6291, running_loss=1.6089, LR=0.000100
[2025-08-26 22:58:33,453][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013776] [Batch 01456/03080] [00:19:49/00:22:07, 0.817s/it]: train_loss_raw=1.6199, running_loss=1.6068, LR=0.000100
[2025-08-26 22:58:40,097][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013784] [Batch 01464/03080] [00:19:56/00:22:00, 0.817s/it]: train_loss_raw=1.5402, running_loss=1.6034, LR=0.000100
[2025-08-26 22:58:46,710][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013792] [Batch 01472/03080] [00:20:03/00:21:54, 0.817s/it]: train_loss_raw=1.6466, running_loss=1.6035, LR=0.000100
[2025-08-26 22:58:53,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013800] [Batch 01480/03080] [00:20:09/00:21:47, 0.817s/it]: train_loss_raw=1.6811, running_loss=1.6017, LR=0.000100
[2025-08-26 22:58:59,887][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013808] [Batch 01488/03080] [00:20:16/00:21:41, 0.817s/it]: train_loss_raw=1.5963, running_loss=1.6007, LR=0.000100
[2025-08-26 22:59:06,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013816] [Batch 01496/03080] [00:20:22/00:21:34, 0.818s/it]: train_loss_raw=1.6057, running_loss=1.6003, LR=0.000100
[2025-08-26 22:59:13,122][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013824] [Batch 01504/03080] [00:20:29/00:21:28, 0.818s/it]: train_loss_raw=1.6069, running_loss=1.5988, LR=0.000100
[2025-08-26 22:59:19,692][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013832] [Batch 01512/03080] [00:20:36/00:21:21, 0.818s/it]: train_loss_raw=1.6819, running_loss=1.6008, LR=0.000100
[2025-08-26 22:59:26,316][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013840] [Batch 01520/03080] [00:20:42/00:21:15, 0.818s/it]: train_loss_raw=1.5246, running_loss=1.5991, LR=0.000100
[2025-08-26 22:59:33,026][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013848] [Batch 01528/03080] [00:20:49/00:21:09, 0.818s/it]: train_loss_raw=1.5410, running_loss=1.5987, LR=0.000100
[2025-08-26 22:59:39,553][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013856] [Batch 01536/03080] [00:20:56/00:21:02, 0.818s/it]: train_loss_raw=1.7137, running_loss=1.5988, LR=0.000100
[2025-08-26 22:59:46,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013864] [Batch 01544/03080] [00:21:02/00:20:56, 0.818s/it]: train_loss_raw=1.5364, running_loss=1.5979, LR=0.000100
[2025-08-26 22:59:52,752][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013872] [Batch 01552/03080] [00:21:09/00:20:49, 0.818s/it]: train_loss_raw=1.6909, running_loss=1.5954, LR=0.000100
[2025-08-26 22:59:59,331][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013880] [Batch 01560/03080] [00:21:15/00:20:43, 0.818s/it]: train_loss_raw=1.6580, running_loss=1.5981, LR=0.000100
[2025-08-26 23:00:06,002][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013888] [Batch 01568/03080] [00:21:22/00:20:36, 0.818s/it]: train_loss_raw=1.6026, running_loss=1.6008, LR=0.000100
[2025-08-26 23:00:12,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013896] [Batch 01576/03080] [00:21:29/00:20:30, 0.818s/it]: train_loss_raw=1.6065, running_loss=1.6015, LR=0.000100
[2025-08-26 23:00:19,304][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013904] [Batch 01584/03080] [00:21:35/00:20:23, 0.818s/it]: train_loss_raw=1.6436, running_loss=1.6014, LR=0.000100
[2025-08-26 23:00:25,965][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013912] [Batch 01592/03080] [00:21:42/00:20:17, 0.818s/it]: train_loss_raw=1.6784, running_loss=1.6031, LR=0.000100
[2025-08-26 23:00:32,627][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013920] [Batch 01600/03080] [00:21:49/00:20:10, 0.818s/it]: train_loss_raw=1.5801, running_loss=1.6036, LR=0.000100
[2025-08-26 23:00:39,210][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013928] [Batch 01608/03080] [00:21:55/00:20:04, 0.818s/it]: train_loss_raw=1.6271, running_loss=1.6054, LR=0.000100
[2025-08-26 23:00:45,850][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013936] [Batch 01616/03080] [00:22:02/00:19:57, 0.818s/it]: train_loss_raw=1.5898, running_loss=1.6030, LR=0.000100
[2025-08-26 23:00:52,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013944] [Batch 01624/03080] [00:22:09/00:19:51, 0.818s/it]: train_loss_raw=1.5352, running_loss=1.6015, LR=0.000100
[2025-08-26 23:00:59,142][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013952] [Batch 01632/03080] [00:22:15/00:19:45, 0.818s/it]: train_loss_raw=1.5828, running_loss=1.5997, LR=0.000100
[2025-08-26 23:01:05,712][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013960] [Batch 01640/03080] [00:22:22/00:19:38, 0.818s/it]: train_loss_raw=1.6241, running_loss=1.6021, LR=0.000100
[2025-08-26 23:01:12,394][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013968] [Batch 01648/03080] [00:22:28/00:19:32, 0.818s/it]: train_loss_raw=1.5624, running_loss=1.6019, LR=0.000100
[2025-08-26 23:01:18,981][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013976] [Batch 01656/03080] [00:22:35/00:19:25, 0.819s/it]: train_loss_raw=1.6614, running_loss=1.6023, LR=0.000100
[2025-08-26 23:01:25,613][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013984] [Batch 01664/03080] [00:22:42/00:19:19, 0.819s/it]: train_loss_raw=1.5817, running_loss=1.6019, LR=0.000100
[2025-08-26 23:01:32,144][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013992] [Batch 01672/03080] [00:22:48/00:19:12, 0.819s/it]: train_loss_raw=1.6339, running_loss=1.6016, LR=0.000100
[2025-08-26 23:01:38,715][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014000] [Batch 01680/03080] [00:22:55/00:19:06, 0.819s/it]: train_loss_raw=1.6099, running_loss=1.6010, LR=0.000100
[2025-08-26 23:01:50,987][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014008] [Batch 01688/03080] [00:23:07/00:19:04, 0.822s/it]: train_loss_raw=1.5821, running_loss=1.6025, LR=0.000100
[2025-08-26 23:01:57,558][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014016] [Batch 01696/03080] [00:23:14/00:18:57, 0.822s/it]: train_loss_raw=1.5724, running_loss=1.6017, LR=0.000100
[2025-08-26 23:02:04,154][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014024] [Batch 01704/03080] [00:23:20/00:18:51, 0.822s/it]: train_loss_raw=1.5876, running_loss=1.6009, LR=0.000100
[2025-08-26 23:02:10,779][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014032] [Batch 01712/03080] [00:23:27/00:18:44, 0.822s/it]: train_loss_raw=1.6475, running_loss=1.6003, LR=0.000100
[2025-08-26 23:02:17,326][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014040] [Batch 01720/03080] [00:23:33/00:18:37, 0.822s/it]: train_loss_raw=1.5595, running_loss=1.6008, LR=0.000100
[2025-08-26 23:02:23,961][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014048] [Batch 01728/03080] [00:23:40/00:18:31, 0.822s/it]: train_loss_raw=1.6173, running_loss=1.6010, LR=0.000100
[2025-08-26 23:02:30,637][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014056] [Batch 01736/03080] [00:23:47/00:18:24, 0.822s/it]: train_loss_raw=1.6468, running_loss=1.6020, LR=0.000100
[2025-08-26 23:02:37,221][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014064] [Batch 01744/03080] [00:23:53/00:18:18, 0.822s/it]: train_loss_raw=1.6155, running_loss=1.6026, LR=0.000100
[2025-08-26 23:02:43,823][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014072] [Batch 01752/03080] [00:24:00/00:18:11, 0.822s/it]: train_loss_raw=1.5958, running_loss=1.6016, LR=0.000100
[2025-08-26 23:02:50,382][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014080] [Batch 01760/03080] [00:24:06/00:18:05, 0.822s/it]: train_loss_raw=1.5653, running_loss=1.6021, LR=0.000100
[2025-08-26 23:02:56,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014088] [Batch 01768/03080] [00:24:13/00:17:58, 0.822s/it]: train_loss_raw=1.6405, running_loss=1.6031, LR=0.000100
[2025-08-26 23:03:03,628][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014096] [Batch 01776/03080] [00:24:20/00:17:52, 0.822s/it]: train_loss_raw=1.5498, running_loss=1.6019, LR=0.000100
[2025-08-26 23:03:10,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014104] [Batch 01784/03080] [00:24:26/00:17:45, 0.822s/it]: train_loss_raw=1.5946, running_loss=1.6013, LR=0.000100
[2025-08-26 23:03:16,925][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014112] [Batch 01792/03080] [00:24:33/00:17:39, 0.822s/it]: train_loss_raw=1.6182, running_loss=1.6030, LR=0.000100
[2025-08-26 23:03:23,540][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014120] [Batch 01800/03080] [00:24:40/00:17:32, 0.822s/it]: train_loss_raw=1.7012, running_loss=1.6046, LR=0.000100
[2025-08-26 23:03:30,215][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014128] [Batch 01808/03080] [00:24:46/00:17:25, 0.822s/it]: train_loss_raw=1.6019, running_loss=1.6044, LR=0.000100
[2025-08-26 23:03:36,762][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014136] [Batch 01816/03080] [00:24:53/00:17:19, 0.822s/it]: train_loss_raw=1.6463, running_loss=1.6032, LR=0.000100
[2025-08-26 23:03:43,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014144] [Batch 01824/03080] [00:24:59/00:17:12, 0.822s/it]: train_loss_raw=1.6245, running_loss=1.6059, LR=0.000100
[2025-08-26 23:03:49,947][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014152] [Batch 01832/03080] [00:25:06/00:17:06, 0.822s/it]: train_loss_raw=1.6402, running_loss=1.6042, LR=0.000100
[2025-08-26 23:03:56,586][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014160] [Batch 01840/03080] [00:25:13/00:16:59, 0.822s/it]: train_loss_raw=1.5686, running_loss=1.6056, LR=0.000100
[2025-08-26 23:04:03,257][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014168] [Batch 01848/03080] [00:25:19/00:16:53, 0.822s/it]: train_loss_raw=1.5577, running_loss=1.6052, LR=0.000100
[2025-08-26 23:04:09,822][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014176] [Batch 01856/03080] [00:25:26/00:16:46, 0.822s/it]: train_loss_raw=1.6116, running_loss=1.6061, LR=0.000100
[2025-08-26 23:04:16,478][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014184] [Batch 01864/03080] [00:25:32/00:16:40, 0.822s/it]: train_loss_raw=1.6167, running_loss=1.6039, LR=0.000100
[2025-08-26 23:04:23,126][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014192] [Batch 01872/03080] [00:25:39/00:16:33, 0.822s/it]: train_loss_raw=1.5926, running_loss=1.6038, LR=0.000100
[2025-08-26 23:04:29,747][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014200] [Batch 01880/03080] [00:25:46/00:16:26, 0.822s/it]: train_loss_raw=1.4804, running_loss=1.5991, LR=0.000100
[2025-08-26 23:04:36,405][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014208] [Batch 01888/03080] [00:25:52/00:16:20, 0.823s/it]: train_loss_raw=1.5674, running_loss=1.6009, LR=0.000100
[2025-08-26 23:04:43,071][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014216] [Batch 01896/03080] [00:25:59/00:16:13, 0.823s/it]: train_loss_raw=1.6608, running_loss=1.6020, LR=0.000100
[2025-08-26 23:04:49,618][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014224] [Batch 01904/03080] [00:26:06/00:16:07, 0.823s/it]: train_loss_raw=1.6353, running_loss=1.6010, LR=0.000100
[2025-08-26 23:04:56,212][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014232] [Batch 01912/03080] [00:26:12/00:16:00, 0.823s/it]: train_loss_raw=1.5317, running_loss=1.5979, LR=0.000100
[2025-08-26 23:05:02,863][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014240] [Batch 01920/03080] [00:26:19/00:15:54, 0.823s/it]: train_loss_raw=1.5616, running_loss=1.5979, LR=0.000100
[2025-08-26 23:05:09,470][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014248] [Batch 01928/03080] [00:26:25/00:15:47, 0.823s/it]: train_loss_raw=1.5978, running_loss=1.5954, LR=0.000100
[2025-08-26 23:05:16,104][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014256] [Batch 01936/03080] [00:26:32/00:15:41, 0.823s/it]: train_loss_raw=1.6158, running_loss=1.5943, LR=0.000100
[2025-08-26 23:05:22,732][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014264] [Batch 01944/03080] [00:26:39/00:15:34, 0.823s/it]: train_loss_raw=1.5771, running_loss=1.5957, LR=0.000100
[2025-08-26 23:05:29,389][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014272] [Batch 01952/03080] [00:26:45/00:15:27, 0.823s/it]: train_loss_raw=1.5178, running_loss=1.5921, LR=0.000100
[2025-08-26 23:05:35,992][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014280] [Batch 01960/03080] [00:26:52/00:15:21, 0.823s/it]: train_loss_raw=1.5855, running_loss=1.5912, LR=0.000100
[2025-08-26 23:05:42,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014288] [Batch 01968/03080] [00:26:59/00:15:14, 0.823s/it]: train_loss_raw=1.5528, running_loss=1.5901, LR=0.000100
[2025-08-26 23:05:49,178][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014296] [Batch 01976/03080] [00:27:05/00:15:08, 0.823s/it]: train_loss_raw=1.5428, running_loss=1.5869, LR=0.000100
[2025-08-26 23:05:55,713][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014304] [Batch 01984/03080] [00:27:12/00:15:01, 0.823s/it]: train_loss_raw=1.5531, running_loss=1.5875, LR=0.000100
[2025-08-26 23:06:02,297][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014312] [Batch 01992/03080] [00:27:18/00:14:55, 0.823s/it]: train_loss_raw=1.6216, running_loss=1.5881, LR=0.000100
[2025-08-26 23:06:08,956][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014320] [Batch 02000/03080] [00:27:25/00:14:48, 0.823s/it]: train_loss_raw=1.6137, running_loss=1.5884, LR=0.000100
[2025-08-26 23:06:15,525][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014328] [Batch 02008/03080] [00:27:32/00:14:41, 0.823s/it]: train_loss_raw=1.6924, running_loss=1.5859, LR=0.000100
[2025-08-26 23:06:22,182][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014336] [Batch 02016/03080] [00:27:38/00:14:35, 0.823s/it]: train_loss_raw=1.6161, running_loss=1.5853, LR=0.000100
[2025-08-26 23:06:28,746][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014344] [Batch 02024/03080] [00:27:45/00:14:28, 0.823s/it]: train_loss_raw=1.5473, running_loss=1.5866, LR=0.000100
[2025-08-26 23:06:35,323][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014352] [Batch 02032/03080] [00:27:51/00:14:22, 0.823s/it]: train_loss_raw=1.5676, running_loss=1.5856, LR=0.000100
[2025-08-26 23:06:42,013][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014360] [Batch 02040/03080] [00:27:58/00:14:15, 0.823s/it]: train_loss_raw=1.5534, running_loss=1.5828, LR=0.000100
[2025-08-26 23:06:48,615][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014368] [Batch 02048/03080] [00:28:05/00:14:09, 0.823s/it]: train_loss_raw=1.6143, running_loss=1.5815, LR=0.000100
[2025-08-26 23:06:55,232][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014376] [Batch 02056/03080] [00:28:11/00:14:02, 0.823s/it]: train_loss_raw=1.5049, running_loss=1.5808, LR=0.000100
[2025-08-26 23:07:01,885][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014384] [Batch 02064/03080] [00:28:18/00:13:56, 0.823s/it]: train_loss_raw=1.6533, running_loss=1.5829, LR=0.000100
[2025-08-26 23:07:08,550][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014392] [Batch 02072/03080] [00:28:25/00:13:49, 0.823s/it]: train_loss_raw=1.5672, running_loss=1.5838, LR=0.000100
[2025-08-26 23:07:15,133][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014400] [Batch 02080/03080] [00:28:31/00:13:42, 0.823s/it]: train_loss_raw=1.5757, running_loss=1.5829, LR=0.000100
[2025-08-26 23:07:21,712][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014408] [Batch 02088/03080] [00:28:38/00:13:36, 0.823s/it]: train_loss_raw=1.5603, running_loss=1.5830, LR=0.000100
[2025-08-26 23:07:28,361][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014416] [Batch 02096/03080] [00:28:44/00:13:29, 0.823s/it]: train_loss_raw=1.6549, running_loss=1.5850, LR=0.000100
[2025-08-26 23:07:34,958][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014424] [Batch 02104/03080] [00:28:51/00:13:23, 0.823s/it]: train_loss_raw=1.5644, running_loss=1.5831, LR=0.000100
[2025-08-26 23:07:41,481][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014432] [Batch 02112/03080] [00:28:57/00:13:16, 0.823s/it]: train_loss_raw=1.6107, running_loss=1.5852, LR=0.000100
[2025-08-26 23:07:47,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014440] [Batch 02120/03080] [00:29:04/00:13:09, 0.823s/it]: train_loss_raw=1.5716, running_loss=1.5850, LR=0.000100
[2025-08-26 23:07:54,239][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014448] [Batch 02128/03080] [00:29:10/00:13:03, 0.823s/it]: train_loss_raw=1.7039, running_loss=1.5871, LR=0.000100
[2025-08-26 23:08:00,475][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014456] [Batch 02136/03080] [00:29:16/00:12:56, 0.823s/it]: train_loss_raw=1.6979, running_loss=1.5884, LR=0.000100
[2025-08-26 23:08:06,442][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014464] [Batch 02144/03080] [00:29:22/00:12:49, 0.822s/it]: train_loss_raw=1.5223, running_loss=1.5867, LR=0.000100
[2025-08-26 23:08:12,557][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014472] [Batch 02152/03080] [00:29:29/00:12:42, 0.822s/it]: train_loss_raw=1.6578, running_loss=1.5883, LR=0.000100
[2025-08-26 23:08:18,717][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014480] [Batch 02160/03080] [00:29:35/00:12:36, 0.822s/it]: train_loss_raw=1.7033, running_loss=1.5838, LR=0.000100
[2025-08-26 23:08:24,822][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014488] [Batch 02168/03080] [00:29:41/00:12:29, 0.822s/it]: train_loss_raw=1.5228, running_loss=1.5851, LR=0.000100
[2025-08-26 23:08:30,959][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014496] [Batch 02176/03080] [00:29:47/00:12:22, 0.821s/it]: train_loss_raw=1.5539, running_loss=1.5835, LR=0.000100
[2025-08-26 23:08:36,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014504] [Batch 02184/03080] [00:29:53/00:12:15, 0.821s/it]: train_loss_raw=1.5481, running_loss=1.5822, LR=0.000100
[2025-08-26 23:08:42,897][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014512] [Batch 02192/03080] [00:29:59/00:12:08, 0.821s/it]: train_loss_raw=1.5208, running_loss=1.5812, LR=0.000100
[2025-08-26 23:08:48,922][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014520] [Batch 02200/03080] [00:30:05/00:12:02, 0.821s/it]: train_loss_raw=1.6122, running_loss=1.5783, LR=0.000100
[2025-08-26 23:08:54,819][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014528] [Batch 02208/03080] [00:30:11/00:11:55, 0.820s/it]: train_loss_raw=1.5204, running_loss=1.5769, LR=0.000100
[2025-08-26 23:09:00,952][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014536] [Batch 02216/03080] [00:30:17/00:11:48, 0.820s/it]: train_loss_raw=1.5830, running_loss=1.5781, LR=0.000100
[2025-08-26 23:09:07,159][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014544] [Batch 02224/03080] [00:30:23/00:11:41, 0.820s/it]: train_loss_raw=1.5181, running_loss=1.5771, LR=0.000100
[2025-08-26 23:09:13,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014552] [Batch 02232/03080] [00:30:29/00:11:35, 0.820s/it]: train_loss_raw=1.4917, running_loss=1.5754, LR=0.000100
[2025-08-26 23:09:19,248][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014560] [Batch 02240/03080] [00:30:35/00:11:28, 0.820s/it]: train_loss_raw=1.5427, running_loss=1.5736, LR=0.000100
[2025-08-26 23:09:25,390][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014568] [Batch 02248/03080] [00:30:41/00:11:21, 0.819s/it]: train_loss_raw=1.5401, running_loss=1.5754, LR=0.000100
[2025-08-26 23:09:31,332][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014576] [Batch 02256/03080] [00:30:47/00:11:14, 0.819s/it]: train_loss_raw=1.5525, running_loss=1.5771, LR=0.000100
[2025-08-26 23:09:37,140][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014584] [Batch 02264/03080] [00:30:53/00:11:08, 0.819s/it]: train_loss_raw=1.6014, running_loss=1.5776, LR=0.000100
[2025-08-26 23:09:43,214][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014592] [Batch 02272/03080] [00:30:59/00:11:01, 0.819s/it]: train_loss_raw=1.5992, running_loss=1.5764, LR=0.000100
[2025-08-26 23:09:49,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014600] [Batch 02280/03080] [00:31:05/00:10:54, 0.818s/it]: train_loss_raw=1.5379, running_loss=1.5762, LR=0.000100
[2025-08-26 23:09:55,409][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014608] [Batch 02288/03080] [00:31:11/00:10:47, 0.818s/it]: train_loss_raw=1.5653, running_loss=1.5764, LR=0.000100
[2025-08-26 23:10:01,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014616] [Batch 02296/03080] [00:31:17/00:10:41, 0.818s/it]: train_loss_raw=1.5758, running_loss=1.5767, LR=0.000100
[2025-08-26 23:10:07,282][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014624] [Batch 02304/03080] [00:31:23/00:10:34, 0.818s/it]: train_loss_raw=1.5825, running_loss=1.5754, LR=0.000100
[2025-08-26 23:10:13,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014632] [Batch 02312/03080] [00:31:29/00:10:27, 0.817s/it]: train_loss_raw=1.5896, running_loss=1.5740, LR=0.000100
[2025-08-26 23:10:19,370][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014640] [Batch 02320/03080] [00:31:35/00:10:21, 0.817s/it]: train_loss_raw=1.6730, running_loss=1.5734, LR=0.000100
[2025-08-26 23:10:25,268][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014648] [Batch 02328/03080] [00:31:41/00:10:14, 0.817s/it]: train_loss_raw=1.5345, running_loss=1.5716, LR=0.000100
[2025-08-26 23:10:31,060][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014656] [Batch 02336/03080] [00:31:47/00:10:07, 0.817s/it]: train_loss_raw=1.5656, running_loss=1.5725, LR=0.000100
[2025-08-26 23:10:36,825][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014664] [Batch 02344/03080] [00:31:53/00:10:00, 0.816s/it]: train_loss_raw=1.6260, running_loss=1.5717, LR=0.000100
[2025-08-26 23:10:42,729][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014672] [Batch 02352/03080] [00:31:59/00:09:54, 0.816s/it]: train_loss_raw=1.6287, running_loss=1.5711, LR=0.000100
[2025-08-26 23:10:48,654][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014680] [Batch 02360/03080] [00:32:05/00:09:47, 0.816s/it]: train_loss_raw=1.5029, running_loss=1.5696, LR=0.000100
[2025-08-26 23:10:54,606][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014688] [Batch 02368/03080] [00:32:11/00:09:40, 0.815s/it]: train_loss_raw=1.5031, running_loss=1.5713, LR=0.000100
[2025-08-26 23:11:00,701][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014696] [Batch 02376/03080] [00:32:17/00:09:33, 0.815s/it]: train_loss_raw=1.5073, running_loss=1.5706, LR=0.000100
[2025-08-26 23:11:06,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014704] [Batch 02384/03080] [00:32:23/00:09:27, 0.815s/it]: train_loss_raw=1.5189, running_loss=1.5678, LR=0.000100
[2025-08-26 23:11:12,725][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014712] [Batch 02392/03080] [00:32:29/00:09:20, 0.815s/it]: train_loss_raw=1.5591, running_loss=1.5682, LR=0.000100
[2025-08-26 23:11:18,391][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014720] [Batch 02400/03080] [00:32:34/00:09:13, 0.815s/it]: train_loss_raw=1.7172, running_loss=1.5713, LR=0.000100
[2025-08-26 23:11:24,120][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014728] [Batch 02408/03080] [00:32:40/00:09:07, 0.814s/it]: train_loss_raw=1.5615, running_loss=1.5713, LR=0.000100
[2025-08-26 23:11:30,028][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014736] [Batch 02416/03080] [00:32:46/00:09:00, 0.814s/it]: train_loss_raw=1.4400, running_loss=1.5688, LR=0.000100
[2025-08-26 23:11:35,710][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014744] [Batch 02424/03080] [00:32:52/00:08:53, 0.814s/it]: train_loss_raw=1.5151, running_loss=1.5694, LR=0.000100
[2025-08-26 23:11:41,479][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014752] [Batch 02432/03080] [00:32:57/00:08:47, 0.813s/it]: train_loss_raw=1.6119, running_loss=1.5698, LR=0.000100
[2025-08-26 23:11:47,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014760] [Batch 02440/03080] [00:33:03/00:08:40, 0.813s/it]: train_loss_raw=1.5069, running_loss=1.5694, LR=0.000100
[2025-08-26 23:11:53,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014768] [Batch 02448/03080] [00:33:09/00:08:33, 0.813s/it]: train_loss_raw=1.5608, running_loss=1.5709, LR=0.000100
[2025-08-26 23:11:59,014][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014776] [Batch 02456/03080] [00:33:15/00:08:27, 0.813s/it]: train_loss_raw=1.5600, running_loss=1.5717, LR=0.000100
[2025-08-26 23:12:04,750][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014784] [Batch 02464/03080] [00:33:21/00:08:20, 0.812s/it]: train_loss_raw=1.6410, running_loss=1.5733, LR=0.000100
[2025-08-26 23:12:10,474][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014792] [Batch 02472/03080] [00:33:26/00:08:13, 0.812s/it]: train_loss_raw=1.6453, running_loss=1.5712, LR=0.000100
[2025-08-26 23:12:16,329][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014800] [Batch 02480/03080] [00:33:32/00:08:06, 0.812s/it]: train_loss_raw=1.4897, running_loss=1.5696, LR=0.000100
[2025-08-26 23:12:22,145][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014808] [Batch 02488/03080] [00:33:38/00:08:00, 0.811s/it]: train_loss_raw=1.5288, running_loss=1.5689, LR=0.000100
[2025-08-26 23:12:27,933][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014816] [Batch 02496/03080] [00:33:44/00:07:53, 0.811s/it]: train_loss_raw=1.5716, running_loss=1.5691, LR=0.000100
[2025-08-26 23:12:34,033][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014824] [Batch 02504/03080] [00:33:50/00:07:47, 0.811s/it]: train_loss_raw=1.5516, running_loss=1.5706, LR=0.000100
[2025-08-26 23:12:39,900][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014832] [Batch 02512/03080] [00:33:56/00:07:40, 0.811s/it]: train_loss_raw=1.5523, running_loss=1.5673, LR=0.000100
[2025-08-26 23:12:45,862][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014840] [Batch 02520/03080] [00:34:02/00:07:33, 0.810s/it]: train_loss_raw=1.5783, running_loss=1.5663, LR=0.000100
[2025-08-26 23:12:51,510][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014848] [Batch 02528/03080] [00:34:08/00:07:27, 0.810s/it]: train_loss_raw=1.4936, running_loss=1.5654, LR=0.000100
[2025-08-26 23:12:57,502][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014856] [Batch 02536/03080] [00:34:13/00:07:20, 0.810s/it]: train_loss_raw=1.5653, running_loss=1.5656, LR=0.000100
[2025-08-26 23:13:03,512][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014864] [Batch 02544/03080] [00:34:20/00:07:14, 0.810s/it]: train_loss_raw=1.5812, running_loss=1.5653, LR=0.000100
[2025-08-26 23:13:09,506][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014872] [Batch 02552/03080] [00:34:25/00:07:07, 0.810s/it]: train_loss_raw=1.4675, running_loss=1.5650, LR=0.000100
[2025-08-26 23:13:15,114][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014880] [Batch 02560/03080] [00:34:31/00:07:00, 0.809s/it]: train_loss_raw=1.5535, running_loss=1.5635, LR=0.000100
[2025-08-26 23:13:20,819][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014888] [Batch 02568/03080] [00:34:37/00:06:54, 0.809s/it]: train_loss_raw=1.5987, running_loss=1.5648, LR=0.000100
[2025-08-26 23:13:26,515][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014896] [Batch 02576/03080] [00:34:43/00:06:47, 0.809s/it]: train_loss_raw=1.6017, running_loss=1.5659, LR=0.000100
[2025-08-26 23:13:32,490][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014904] [Batch 02584/03080] [00:34:48/00:06:40, 0.808s/it]: train_loss_raw=1.7486, running_loss=1.5667, LR=0.000100
[2025-08-26 23:13:38,690][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014912] [Batch 02592/03080] [00:34:55/00:06:34, 0.808s/it]: train_loss_raw=1.6580, running_loss=1.5683, LR=0.000100
[2025-08-26 23:13:44,479][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014920] [Batch 02600/03080] [00:35:00/00:06:27, 0.808s/it]: train_loss_raw=1.6166, running_loss=1.5671, LR=0.000100
[2025-08-26 23:13:50,455][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014928] [Batch 02608/03080] [00:35:06/00:06:21, 0.808s/it]: train_loss_raw=1.5021, running_loss=1.5663, LR=0.000100
[2025-08-26 23:13:56,355][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014936] [Batch 02616/03080] [00:35:12/00:06:14, 0.808s/it]: train_loss_raw=1.5357, running_loss=1.5663, LR=0.000100
[2025-08-26 23:14:02,356][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014944] [Batch 02624/03080] [00:35:18/00:06:08, 0.807s/it]: train_loss_raw=1.6629, running_loss=1.5667, LR=0.000100
[2025-08-26 23:14:08,392][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014952] [Batch 02632/03080] [00:35:24/00:06:01, 0.807s/it]: train_loss_raw=1.5715, running_loss=1.5661, LR=0.000100
[2025-08-26 23:14:14,263][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014960] [Batch 02640/03080] [00:35:30/00:05:55, 0.807s/it]: train_loss_raw=1.5296, running_loss=1.5672, LR=0.000100
[2025-08-26 23:14:20,000][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014968] [Batch 02648/03080] [00:35:36/00:05:48, 0.807s/it]: train_loss_raw=1.5763, running_loss=1.5667, LR=0.000100
[2025-08-26 23:14:25,794][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014976] [Batch 02656/03080] [00:35:42/00:05:41, 0.807s/it]: train_loss_raw=1.5012, running_loss=1.5650, LR=0.000100
[2025-08-26 23:14:31,897][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014984] [Batch 02664/03080] [00:35:48/00:05:35, 0.806s/it]: train_loss_raw=1.5242, running_loss=1.5631, LR=0.000100
[2025-08-26 23:14:37,815][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014992] [Batch 02672/03080] [00:35:54/00:05:28, 0.806s/it]: train_loss_raw=1.5095, running_loss=1.5645, LR=0.000100
[2025-08-26 23:14:43,647][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015000] [Batch 02680/03080] [00:36:00/00:05:22, 0.806s/it]: train_loss_raw=1.6215, running_loss=1.5674, LR=0.000100
[2025-08-26 23:14:49,491][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015008] [Batch 02688/03080] [00:36:05/00:05:15, 0.806s/it]: train_loss_raw=1.4352, running_loss=1.5634, LR=0.000100
[2025-08-26 23:14:55,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015016] [Batch 02696/03080] [00:36:12/00:05:09, 0.806s/it]: train_loss_raw=1.5412, running_loss=1.5597, LR=0.000100
[2025-08-26 23:15:01,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015024] [Batch 02704/03080] [00:36:17/00:05:02, 0.805s/it]: train_loss_raw=1.5926, running_loss=1.5611, LR=0.000100
[2025-08-26 23:15:07,372][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015032] [Batch 02712/03080] [00:36:23/00:04:56, 0.805s/it]: train_loss_raw=1.5741, running_loss=1.5621, LR=0.000100
[2025-08-26 23:15:13,264][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015040] [Batch 02720/03080] [00:36:29/00:04:49, 0.805s/it]: train_loss_raw=1.4739, running_loss=1.5651, LR=0.000100
[2025-08-26 23:15:19,074][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015048] [Batch 02728/03080] [00:36:35/00:04:43, 0.805s/it]: train_loss_raw=1.5790, running_loss=1.5630, LR=0.000100
[2025-08-26 23:15:25,036][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015056] [Batch 02736/03080] [00:36:41/00:04:36, 0.805s/it]: train_loss_raw=1.6112, running_loss=1.5632, LR=0.000100
[2025-08-26 23:15:30,832][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015064] [Batch 02744/03080] [00:36:47/00:04:30, 0.804s/it]: train_loss_raw=1.6465, running_loss=1.5627, LR=0.000100
[2025-08-26 23:15:36,442][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015072] [Batch 02752/03080] [00:36:52/00:04:23, 0.804s/it]: train_loss_raw=1.4643, running_loss=1.5599, LR=0.000100
[2025-08-26 23:15:42,477][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015080] [Batch 02760/03080] [00:36:58/00:04:17, 0.804s/it]: train_loss_raw=1.5384, running_loss=1.5609, LR=0.000100
[2025-08-26 23:15:48,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015088] [Batch 02768/03080] [00:37:04/00:04:10, 0.804s/it]: train_loss_raw=1.6527, running_loss=1.5634, LR=0.000100
[2025-08-26 23:15:54,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015096] [Batch 02776/03080] [00:37:11/00:04:04, 0.804s/it]: train_loss_raw=1.5097, running_loss=1.5606, LR=0.000100
[2025-08-26 23:16:00,502][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015104] [Batch 02784/03080] [00:37:16/00:03:57, 0.804s/it]: train_loss_raw=1.6076, running_loss=1.5607, LR=0.000100
[2025-08-26 23:16:06,376][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015112] [Batch 02792/03080] [00:37:22/00:03:51, 0.803s/it]: train_loss_raw=1.6054, running_loss=1.5596, LR=0.000100
[2025-08-26 23:16:12,160][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015120] [Batch 02800/03080] [00:37:28/00:03:44, 0.803s/it]: train_loss_raw=1.5073, running_loss=1.5578, LR=0.000100
[2025-08-26 23:16:18,027][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015128] [Batch 02808/03080] [00:37:34/00:03:38, 0.803s/it]: train_loss_raw=1.5233, running_loss=1.5560, LR=0.000100
[2025-08-26 23:16:23,912][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015136] [Batch 02816/03080] [00:37:40/00:03:31, 0.803s/it]: train_loss_raw=1.5340, running_loss=1.5561, LR=0.000100
[2025-08-26 23:16:29,859][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015144] [Batch 02824/03080] [00:37:46/00:03:25, 0.803s/it]: train_loss_raw=1.5190, running_loss=1.5572, LR=0.000100
[2025-08-26 23:16:35,734][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015152] [Batch 02832/03080] [00:37:52/00:03:18, 0.802s/it]: train_loss_raw=1.5180, running_loss=1.5559, LR=0.000100
[2025-08-26 23:16:41,522][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015160] [Batch 02840/03080] [00:37:58/00:03:12, 0.802s/it]: train_loss_raw=1.6150, running_loss=1.5556, LR=0.000100
[2025-08-26 23:16:47,398][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015168] [Batch 02848/03080] [00:38:03/00:03:06, 0.802s/it]: train_loss_raw=1.4622, running_loss=1.5554, LR=0.000100
[2025-08-26 23:16:53,434][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015176] [Batch 02856/03080] [00:38:09/00:02:59, 0.802s/it]: train_loss_raw=1.5973, running_loss=1.5563, LR=0.000100
[2025-08-26 23:16:59,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015184] [Batch 02864/03080] [00:38:16/00:02:53, 0.802s/it]: train_loss_raw=1.5496, running_loss=1.5550, LR=0.000100
[2025-08-26 23:17:05,406][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015192] [Batch 02872/03080] [00:38:21/00:02:46, 0.801s/it]: train_loss_raw=1.5386, running_loss=1.5522, LR=0.000100
[2025-08-26 23:17:11,298][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015200] [Batch 02880/03080] [00:38:27/00:02:40, 0.801s/it]: train_loss_raw=1.5155, running_loss=1.5502, LR=0.000100
[2025-08-26 23:17:17,254][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015208] [Batch 02888/03080] [00:38:33/00:02:33, 0.801s/it]: train_loss_raw=1.4896, running_loss=1.5512, LR=0.000100
[2025-08-26 23:17:23,182][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015216] [Batch 02896/03080] [00:38:39/00:02:27, 0.801s/it]: train_loss_raw=1.6011, running_loss=1.5511, LR=0.000100
[2025-08-26 23:17:29,129][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015224] [Batch 02904/03080] [00:38:45/00:02:20, 0.801s/it]: train_loss_raw=1.5176, running_loss=1.5514, LR=0.000100
[2025-08-26 23:17:35,120][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015232] [Batch 02912/03080] [00:38:51/00:02:14, 0.801s/it]: train_loss_raw=1.5194, running_loss=1.5485, LR=0.000100
[2025-08-26 23:17:40,922][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015240] [Batch 02920/03080] [00:38:57/00:02:08, 0.800s/it]: train_loss_raw=1.6149, running_loss=1.5470, LR=0.000100
[2025-08-26 23:17:46,862][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015248] [Batch 02928/03080] [00:39:03/00:02:01, 0.800s/it]: train_loss_raw=1.4491, running_loss=1.5497, LR=0.000100
[2025-08-26 23:17:53,166][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015256] [Batch 02936/03080] [00:39:09/00:01:55, 0.800s/it]: train_loss_raw=1.4560, running_loss=1.5474, LR=0.000100
[2025-08-26 23:17:59,114][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015264] [Batch 02944/03080] [00:39:15/00:01:48, 0.800s/it]: train_loss_raw=1.5601, running_loss=1.5473, LR=0.000100
[2025-08-26 23:18:05,093][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015272] [Batch 02952/03080] [00:39:21/00:01:42, 0.800s/it]: train_loss_raw=1.5488, running_loss=1.5461, LR=0.000100
[2025-08-26 23:18:10,865][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015280] [Batch 02960/03080] [00:39:27/00:01:35, 0.800s/it]: train_loss_raw=1.5098, running_loss=1.5458, LR=0.000100
[2025-08-26 23:18:16,529][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015288] [Batch 02968/03080] [00:39:33/00:01:29, 0.800s/it]: train_loss_raw=1.5402, running_loss=1.5457, LR=0.000100
[2025-08-26 23:18:22,202][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015296] [Batch 02976/03080] [00:39:38/00:01:23, 0.799s/it]: train_loss_raw=1.5980, running_loss=1.5464, LR=0.000100
[2025-08-26 23:18:28,014][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015304] [Batch 02984/03080] [00:39:44/00:01:16, 0.799s/it]: train_loss_raw=1.4661, running_loss=1.5457, LR=0.000100
[2025-08-26 23:18:34,159][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015312] [Batch 02992/03080] [00:39:50/00:01:10, 0.799s/it]: train_loss_raw=1.5450, running_loss=1.5476, LR=0.000100
[2025-08-26 23:18:40,172][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015320] [Batch 03000/03080] [00:39:56/00:01:03, 0.799s/it]: train_loss_raw=1.5621, running_loss=1.5502, LR=0.000100
[2025-08-26 23:18:46,263][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015328] [Batch 03008/03080] [00:40:02/00:00:57, 0.799s/it]: train_loss_raw=1.4920, running_loss=1.5484, LR=0.000100
[2025-08-26 23:18:52,062][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015336] [Batch 03016/03080] [00:40:08/00:00:51, 0.799s/it]: train_loss_raw=1.5329, running_loss=1.5486, LR=0.000100
[2025-08-26 23:18:57,904][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015344] [Batch 03024/03080] [00:40:14/00:00:44, 0.798s/it]: train_loss_raw=1.5628, running_loss=1.5481, LR=0.000100
[2025-08-26 23:19:04,006][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015352] [Batch 03032/03080] [00:40:20/00:00:38, 0.798s/it]: train_loss_raw=1.5830, running_loss=1.5471, LR=0.000100
[2025-08-26 23:19:09,767][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015360] [Batch 03040/03080] [00:40:26/00:00:31, 0.798s/it]: train_loss_raw=1.5449, running_loss=1.5463, LR=0.000100
[2025-08-26 23:19:15,696][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015368] [Batch 03048/03080] [00:40:32/00:00:25, 0.798s/it]: train_loss_raw=1.4733, running_loss=1.5470, LR=0.000100
[2025-08-26 23:19:21,877][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015376] [Batch 03056/03080] [00:40:38/00:00:19, 0.798s/it]: train_loss_raw=1.5184, running_loss=1.5478, LR=0.000100
[2025-08-26 23:19:27,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015384] [Batch 03064/03080] [00:40:44/00:00:12, 0.798s/it]: train_loss_raw=1.5572, running_loss=1.5462, LR=0.000100
[2025-08-26 23:19:33,852][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015392] [Batch 03072/03080] [00:40:50/00:00:06, 0.798s/it]: train_loss_raw=1.4678, running_loss=1.5444, LR=0.000100
[2025-08-26 23:19:39,830][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015400] [Batch 03080/03080] [00:40:56/00:00:00, 0.798s/it]: train_loss_raw=1.5831, running_loss=1.5442, LR=0.000100
[2025-08-26 23:19:40,328][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-26 23:19:52,250][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00007/00310] [00:00:11/00:07:30, 1.490s/it]
[2025-08-26 23:20:04,569][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00015/00310] [00:00:24/00:07:25, 1.515s/it]
[2025-08-26 23:20:17,185][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00023/00310] [00:00:36/00:07:19, 1.536s/it]
[2025-08-26 23:20:29,689][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00031/00310] [00:00:49/00:07:08, 1.543s/it]
[2025-08-26 23:20:41,862][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00039/00310] [00:01:01/00:06:55, 1.538s/it]
[2025-08-26 23:20:54,176][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00047/00310] [00:01:13/00:06:43, 1.539s/it]
[2025-08-26 23:21:06,925][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00055/00310] [00:01:26/00:06:32, 1.546s/it]
[2025-08-26 23:21:19,587][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00063/00310] [00:01:39/00:06:21, 1.551s/it]
[2025-08-26 23:21:32,059][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00071/00310] [00:01:51/00:06:09, 1.552s/it]
[2025-08-26 23:21:44,668][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00079/00310] [00:02:04/00:05:57, 1.554s/it]
[2025-08-26 23:21:57,310][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00087/00310] [00:02:16/00:05:45, 1.557s/it]
[2025-08-26 23:22:09,766][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00095/00310] [00:02:29/00:05:33, 1.557s/it]
[2025-08-26 23:22:22,233][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00103/00310] [00:02:41/00:05:20, 1.557s/it]
[2025-08-26 23:22:34,889][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00111/00310] [00:02:54/00:05:08, 1.559s/it]
[2025-08-26 23:22:47,398][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00119/00310] [00:03:07/00:04:56, 1.559s/it]
[2025-08-26 23:22:59,687][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00127/00310] [00:03:19/00:04:43, 1.557s/it]
[2025-08-26 23:23:12,251][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00135/00310] [00:03:31/00:04:31, 1.558s/it]
[2025-08-26 23:23:24,744][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00143/00310] [00:03:44/00:04:18, 1.558s/it]
[2025-08-26 23:23:36,682][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00151/00310] [00:03:56/00:04:05, 1.555s/it]
[2025-08-26 23:23:48,501][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00159/00310] [00:04:08/00:03:52, 1.551s/it]
[2025-08-26 23:24:01,087][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00167/00310] [00:04:20/00:03:40, 1.552s/it]
[2025-08-26 23:24:13,072][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00175/00310] [00:04:32/00:03:27, 1.550s/it]
[2025-08-26 23:24:24,696][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00183/00310] [00:04:44/00:03:14, 1.545s/it]
[2025-08-26 23:24:37,614][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00191/00310] [00:04:57/00:03:02, 1.548s/it]
[2025-08-26 23:24:49,412][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00199/00310] [00:05:09/00:02:49, 1.545s/it]
[2025-08-26 23:25:01,437][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00207/00310] [00:05:21/00:02:37, 1.544s/it]
[2025-08-26 23:25:13,641][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00215/00310] [00:05:33/00:02:25, 1.543s/it]
[2025-08-26 23:25:25,994][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00223/00310] [00:05:45/00:02:12, 1.543s/it]
[2025-08-26 23:25:38,680][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00231/00310] [00:05:58/00:02:00, 1.545s/it]
[2025-08-26 23:25:50,846][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00239/00310] [00:06:10/00:01:48, 1.544s/it]
[2025-08-26 23:26:02,632][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00247/00310] [00:06:22/00:01:35, 1.542s/it]
[2025-08-26 23:26:15,078][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00255/00310] [00:06:34/00:01:23, 1.542s/it]
[2025-08-26 23:26:27,412][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00263/00310] [00:06:47/00:01:10, 1.542s/it]
[2025-08-26 23:26:39,696][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00271/00310] [00:06:59/00:00:58, 1.542s/it]
[2025-08-26 23:26:51,666][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00279/00310] [00:07:11/00:00:46, 1.540s/it]
[2025-08-26 23:27:04,108][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00287/00310] [00:07:23/00:00:33, 1.541s/it]
[2025-08-26 23:27:16,198][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00295/00310] [00:07:35/00:00:21, 1.540s/it]
[2025-08-26 23:27:28,989][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00303/00310] [00:07:48/00:00:09, 1.542s/it]
[2025-08-26 23:27:38,170][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.54425, valid_loss=2.20011
[2025-08-26 23:27:38,170][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-26 23:27:38,171][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.822
[2025-08-26 23:27:38,171][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.020
[2025-08-26 23:27:38,171][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.022
[2025-08-26 23:27:38,171][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.002
[2025-08-26 23:27:38,186][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 04:00:52, remaining time 20:04:20, 00:48:10 per epoch
[2025-08-26 23:27:44,034][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015408] [Batch 00008/03080] [00:00:05/00:35:41, 0.697s/it]: train_loss_raw=1.5424, running_loss=1.5748, LR=0.000100
[2025-08-26 23:27:49,974][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015416] [Batch 00016/03080] [00:00:11/00:36:45, 0.720s/it]: train_loss_raw=1.5981, running_loss=1.5752, LR=0.000100
[2025-08-26 23:27:56,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015424] [Batch 00024/03080] [00:00:17/00:37:24, 0.735s/it]: train_loss_raw=1.4535, running_loss=1.5743, LR=0.000100
[2025-08-26 23:28:02,084][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015432] [Batch 00032/03080] [00:00:23/00:37:30, 0.738s/it]: train_loss_raw=1.5991, running_loss=1.5752, LR=0.000100
[2025-08-26 23:28:08,128][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015440] [Batch 00040/03080] [00:00:29/00:37:34, 0.742s/it]: train_loss_raw=1.5455, running_loss=1.5745, LR=0.000100
[2025-08-26 23:28:14,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015448] [Batch 00048/03080] [00:00:35/00:37:49, 0.748s/it]: train_loss_raw=1.5195, running_loss=1.5716, LR=0.000100
[2025-08-26 23:28:20,705][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015456] [Batch 00056/03080] [00:00:42/00:38:01, 0.754s/it]: train_loss_raw=1.5961, running_loss=1.5685, LR=0.000100
[2025-08-26 23:28:26,618][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015464] [Batch 00064/03080] [00:00:48/00:37:49, 0.752s/it]: train_loss_raw=1.5446, running_loss=1.5656, LR=0.000100
[2025-08-26 23:28:32,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015472] [Batch 00072/03080] [00:00:54/00:37:45, 0.753s/it]: train_loss_raw=1.6015, running_loss=1.5643, LR=0.000100
[2025-08-26 23:28:39,097][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015480] [Batch 00080/03080] [00:01:00/00:37:53, 0.758s/it]: train_loss_raw=1.5843, running_loss=1.5633, LR=0.000100
[2025-08-26 23:28:45,262][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015488] [Batch 00088/03080] [00:01:06/00:37:51, 0.759s/it]: train_loss_raw=1.6017, running_loss=1.5628, LR=0.000100
[2025-08-26 23:28:51,396][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015496] [Batch 00096/03080] [00:01:12/00:37:47, 0.760s/it]: train_loss_raw=1.5909, running_loss=1.5596, LR=0.000100
[2025-08-26 23:28:57,384][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015504] [Batch 00104/03080] [00:01:18/00:37:38, 0.759s/it]: train_loss_raw=1.5055, running_loss=1.5567, LR=0.000100
[2025-08-26 23:29:03,191][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015512] [Batch 00112/03080] [00:01:24/00:37:25, 0.757s/it]: train_loss_raw=1.5105, running_loss=1.5537, LR=0.000100
[2025-08-26 23:29:08,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015520] [Batch 00120/03080] [00:01:30/00:37:12, 0.754s/it]: train_loss_raw=1.5990, running_loss=1.5540, LR=0.000100
[2025-08-26 23:29:14,798][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015528] [Batch 00128/03080] [00:01:36/00:37:01, 0.753s/it]: train_loss_raw=1.5828, running_loss=1.5513, LR=0.000100
[2025-08-26 23:29:20,768][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015536] [Batch 00136/03080] [00:01:42/00:36:54, 0.752s/it]: train_loss_raw=1.5594, running_loss=1.5484, LR=0.000100
[2025-08-26 23:29:26,671][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015544] [Batch 00144/03080] [00:01:48/00:36:46, 0.751s/it]: train_loss_raw=1.5411, running_loss=1.5440, LR=0.000100
[2025-08-26 23:29:32,562][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015552] [Batch 00152/03080] [00:01:54/00:36:37, 0.751s/it]: train_loss_raw=1.5342, running_loss=1.5458, LR=0.000100
[2025-08-26 23:29:38,465][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015560] [Batch 00160/03080] [00:02:00/00:36:30, 0.750s/it]: train_loss_raw=1.5573, running_loss=1.5466, LR=0.000100
[2025-08-26 23:29:44,520][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015568] [Batch 00168/03080] [00:02:06/00:36:25, 0.750s/it]: train_loss_raw=1.4506, running_loss=1.5421, LR=0.000100
[2025-08-26 23:29:50,416][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015576] [Batch 00176/03080] [00:02:11/00:36:17, 0.750s/it]: train_loss_raw=1.4504, running_loss=1.5393, LR=0.000100
[2025-08-26 23:29:56,357][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015584] [Batch 00184/03080] [00:02:17/00:36:10, 0.749s/it]: train_loss_raw=1.5940, running_loss=1.5401, LR=0.000100
[2025-08-26 23:30:02,245][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015592] [Batch 00192/03080] [00:02:23/00:36:02, 0.749s/it]: train_loss_raw=1.5202, running_loss=1.5359, LR=0.000100
[2025-08-26 23:30:08,248][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015600] [Batch 00200/03080] [00:02:29/00:35:56, 0.749s/it]: train_loss_raw=1.6118, running_loss=1.5373, LR=0.000100
[2025-08-26 23:30:14,179][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015608] [Batch 00208/03080] [00:02:35/00:35:50, 0.749s/it]: train_loss_raw=1.5626, running_loss=1.5386, LR=0.000100
[2025-08-26 23:30:20,355][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015616] [Batch 00216/03080] [00:02:41/00:35:46, 0.750s/it]: train_loss_raw=1.5157, running_loss=1.5377, LR=0.000100
[2025-08-26 23:30:26,367][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015624] [Batch 00224/03080] [00:02:47/00:35:40, 0.750s/it]: train_loss_raw=1.4706, running_loss=1.5367, LR=0.000100
[2025-08-26 23:30:32,503][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015632] [Batch 00232/03080] [00:02:54/00:35:36, 0.750s/it]: train_loss_raw=1.6332, running_loss=1.5403, LR=0.000100
[2025-08-26 23:30:38,364][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015640] [Batch 00240/03080] [00:02:59/00:35:28, 0.750s/it]: train_loss_raw=1.5632, running_loss=1.5408, LR=0.000100
[2025-08-26 23:30:44,184][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015648] [Batch 00248/03080] [00:03:05/00:35:20, 0.749s/it]: train_loss_raw=1.4327, running_loss=1.5403, LR=0.000100
[2025-08-26 23:30:49,939][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015656] [Batch 00256/03080] [00:03:11/00:35:12, 0.748s/it]: train_loss_raw=1.4723, running_loss=1.5396, LR=0.000100
[2025-08-26 23:30:56,075][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015664] [Batch 00264/03080] [00:03:17/00:35:07, 0.749s/it]: train_loss_raw=1.6251, running_loss=1.5384, LR=0.000100
[2025-08-26 23:31:02,396][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015672] [Batch 00272/03080] [00:03:23/00:35:05, 0.750s/it]: train_loss_raw=1.5788, running_loss=1.5417, LR=0.000100
[2025-08-26 23:31:08,383][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015680] [Batch 00280/03080] [00:03:29/00:34:59, 0.750s/it]: train_loss_raw=1.5090, running_loss=1.5402, LR=0.000100
[2025-08-26 23:31:14,425][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015688] [Batch 00288/03080] [00:03:35/00:34:53, 0.750s/it]: train_loss_raw=1.5121, running_loss=1.5388, LR=0.000100
[2025-08-26 23:31:20,402][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015696] [Batch 00296/03080] [00:03:41/00:34:47, 0.750s/it]: train_loss_raw=1.5612, running_loss=1.5377, LR=0.000100
[2025-08-26 23:31:26,341][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015704] [Batch 00304/03080] [00:03:47/00:34:40, 0.750s/it]: train_loss_raw=1.5840, running_loss=1.5411, LR=0.000100
[2025-08-26 23:31:32,284][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015712] [Batch 00312/03080] [00:03:53/00:34:34, 0.749s/it]: train_loss_raw=1.5217, running_loss=1.5373, LR=0.000100
[2025-08-26 23:31:38,288][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015720] [Batch 00320/03080] [00:03:59/00:34:28, 0.749s/it]: train_loss_raw=1.5790, running_loss=1.5395, LR=0.000100
[2025-08-26 23:31:44,096][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015728] [Batch 00328/03080] [00:04:05/00:34:20, 0.749s/it]: train_loss_raw=1.5578, running_loss=1.5396, LR=0.000100
[2025-08-26 23:31:50,294][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015736] [Batch 00336/03080] [00:04:11/00:34:16, 0.750s/it]: train_loss_raw=1.4928, running_loss=1.5401, LR=0.000100
[2025-08-26 23:31:56,474][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015744] [Batch 00344/03080] [00:04:18/00:34:12, 0.750s/it]: train_loss_raw=1.4876, running_loss=1.5382, LR=0.000100
[2025-08-26 23:32:02,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015752] [Batch 00352/03080] [00:04:24/00:34:07, 0.751s/it]: train_loss_raw=1.5199, running_loss=1.5383, LR=0.000100
[2025-08-26 23:32:08,708][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015760] [Batch 00360/03080] [00:04:30/00:34:01, 0.751s/it]: train_loss_raw=1.5215, running_loss=1.5372, LR=0.000100
[2025-08-26 23:32:14,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015768] [Batch 00368/03080] [00:04:36/00:33:55, 0.751s/it]: train_loss_raw=1.5667, running_loss=1.5355, LR=0.000100
[2025-08-26 23:32:20,698][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015776] [Batch 00376/03080] [00:04:42/00:33:49, 0.751s/it]: train_loss_raw=1.6062, running_loss=1.5339, LR=0.000100
[2025-08-26 23:32:26,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015784] [Batch 00384/03080] [00:04:48/00:33:44, 0.751s/it]: train_loss_raw=1.5798, running_loss=1.5332, LR=0.000100
[2025-08-26 23:32:32,696][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015792] [Batch 00392/03080] [00:04:54/00:33:37, 0.751s/it]: train_loss_raw=1.4786, running_loss=1.5309, LR=0.000100
[2025-08-26 23:32:38,569][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015800] [Batch 00400/03080] [00:05:00/00:33:30, 0.750s/it]: train_loss_raw=1.4726, running_loss=1.5278, LR=0.000100
[2025-08-26 23:32:44,608][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015808] [Batch 00408/03080] [00:05:06/00:33:24, 0.750s/it]: train_loss_raw=1.5205, running_loss=1.5291, LR=0.000100
[2025-08-26 23:32:50,673][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015816] [Batch 00416/03080] [00:05:12/00:33:19, 0.751s/it]: train_loss_raw=1.5101, running_loss=1.5279, LR=0.000100
[2025-08-26 23:32:56,820][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015824] [Batch 00424/03080] [00:05:18/00:33:14, 0.751s/it]: train_loss_raw=1.5034, running_loss=1.5273, LR=0.000100
[2025-08-26 23:33:02,920][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015832] [Batch 00432/03080] [00:05:24/00:33:08, 0.751s/it]: train_loss_raw=1.5563, running_loss=1.5277, LR=0.000100
[2025-08-26 23:33:09,023][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015840] [Batch 00440/03080] [00:05:30/00:33:03, 0.751s/it]: train_loss_raw=1.3995, running_loss=1.5246, LR=0.000100
[2025-08-26 23:33:15,100][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015848] [Batch 00448/03080] [00:05:36/00:32:57, 0.751s/it]: train_loss_raw=1.5336, running_loss=1.5240, LR=0.000100
[2025-08-26 23:33:21,037][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015856] [Batch 00456/03080] [00:05:42/00:32:51, 0.751s/it]: train_loss_raw=1.5256, running_loss=1.5226, LR=0.000100
[2025-08-26 23:33:26,904][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015864] [Batch 00464/03080] [00:05:48/00:32:44, 0.751s/it]: train_loss_raw=1.4100, running_loss=1.5224, LR=0.000100
[2025-08-26 23:33:32,958][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015872] [Batch 00472/03080] [00:05:54/00:32:38, 0.751s/it]: train_loss_raw=1.4555, running_loss=1.5206, LR=0.000100
[2025-08-26 23:33:38,796][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015880] [Batch 00480/03080] [00:06:00/00:32:31, 0.751s/it]: train_loss_raw=1.4965, running_loss=1.5201, LR=0.000100
[2025-08-26 23:33:44,693][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015888] [Batch 00488/03080] [00:06:06/00:32:25, 0.750s/it]: train_loss_raw=1.5950, running_loss=1.5181, LR=0.000100
[2025-08-26 23:33:50,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015896] [Batch 00496/03080] [00:06:12/00:32:20, 0.751s/it]: train_loss_raw=1.5374, running_loss=1.5197, LR=0.000100
[2025-08-26 23:33:56,863][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015904] [Batch 00504/03080] [00:06:18/00:32:14, 0.751s/it]: train_loss_raw=1.5052, running_loss=1.5216, LR=0.000100
[2025-08-26 23:34:02,809][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015912] [Batch 00512/03080] [00:06:24/00:32:07, 0.751s/it]: train_loss_raw=1.5083, running_loss=1.5238, LR=0.000100
[2025-08-26 23:34:08,771][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015920] [Batch 00520/03080] [00:06:30/00:32:01, 0.751s/it]: train_loss_raw=1.4928, running_loss=1.5246, LR=0.000100
[2025-08-26 23:34:14,691][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015928] [Batch 00528/03080] [00:06:36/00:31:55, 0.750s/it]: train_loss_raw=1.6116, running_loss=1.5263, LR=0.000100
[2025-08-26 23:34:20,810][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015936] [Batch 00536/03080] [00:06:42/00:31:49, 0.751s/it]: train_loss_raw=1.5041, running_loss=1.5273, LR=0.000100
[2025-08-26 23:34:26,919][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015944] [Batch 00544/03080] [00:06:48/00:31:44, 0.751s/it]: train_loss_raw=1.5154, running_loss=1.5240, LR=0.000100
[2025-08-26 23:34:33,114][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015952] [Batch 00552/03080] [00:06:54/00:31:38, 0.751s/it]: train_loss_raw=1.4901, running_loss=1.5210, LR=0.000100
[2025-08-26 23:34:38,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015960] [Batch 00560/03080] [00:07:00/00:31:31, 0.751s/it]: train_loss_raw=1.4820, running_loss=1.5199, LR=0.000100
[2025-08-26 23:34:44,648][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015968] [Batch 00568/03080] [00:07:06/00:31:24, 0.750s/it]: train_loss_raw=1.7006, running_loss=1.5204, LR=0.000100
[2025-08-26 23:34:50,649][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015976] [Batch 00576/03080] [00:07:12/00:31:18, 0.750s/it]: train_loss_raw=1.5087, running_loss=1.5230, LR=0.000100
[2025-08-26 23:34:56,736][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015984] [Batch 00584/03080] [00:07:18/00:31:13, 0.750s/it]: train_loss_raw=1.4960, running_loss=1.5226, LR=0.000100
[2025-08-26 23:35:02,502][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015992] [Batch 00592/03080] [00:07:24/00:31:06, 0.750s/it]: train_loss_raw=1.5110, running_loss=1.5224, LR=0.000100
[2025-08-26 23:35:08,359][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016000] [Batch 00600/03080] [00:07:29/00:30:59, 0.750s/it]: train_loss_raw=1.4992, running_loss=1.5224, LR=0.000100
[2025-08-26 23:35:18,730][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016008] [Batch 00608/03080] [00:07:40/00:31:11, 0.757s/it]: train_loss_raw=1.4622, running_loss=1.5230, LR=0.000100
[2025-08-26 23:35:24,844][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016016] [Batch 00616/03080] [00:07:46/00:31:05, 0.757s/it]: train_loss_raw=1.6211, running_loss=1.5248, LR=0.000100
[2025-08-26 23:35:30,722][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016024] [Batch 00624/03080] [00:07:52/00:30:58, 0.757s/it]: train_loss_raw=1.4630, running_loss=1.5233, LR=0.000100
[2025-08-26 23:35:36,921][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016032] [Batch 00632/03080] [00:07:58/00:30:53, 0.757s/it]: train_loss_raw=1.5394, running_loss=1.5230, LR=0.000100
[2025-08-26 23:35:42,689][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016040] [Batch 00640/03080] [00:08:04/00:30:46, 0.757s/it]: train_loss_raw=1.4805, running_loss=1.5223, LR=0.000100
[2025-08-26 23:35:48,483][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016048] [Batch 00648/03080] [00:08:10/00:30:39, 0.756s/it]: train_loss_raw=1.4768, running_loss=1.5201, LR=0.000100
[2025-08-26 23:35:54,259][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016056] [Batch 00656/03080] [00:08:15/00:30:32, 0.756s/it]: train_loss_raw=1.5986, running_loss=1.5217, LR=0.000100
[2025-08-26 23:35:59,998][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016064] [Batch 00664/03080] [00:08:21/00:30:24, 0.755s/it]: train_loss_raw=1.5792, running_loss=1.5196, LR=0.000100
[2025-08-26 23:36:05,803][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016072] [Batch 00672/03080] [00:08:27/00:30:17, 0.755s/it]: train_loss_raw=1.4457, running_loss=1.5169, LR=0.000100
[2025-08-26 23:36:11,597][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016080] [Batch 00680/03080] [00:08:33/00:30:11, 0.755s/it]: train_loss_raw=1.5285, running_loss=1.5165, LR=0.000100
[2025-08-26 23:36:17,821][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016088] [Batch 00688/03080] [00:08:39/00:30:05, 0.755s/it]: train_loss_raw=1.6556, running_loss=1.5170, LR=0.000100
[2025-08-26 23:36:23,574][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016096] [Batch 00696/03080] [00:08:45/00:29:58, 0.754s/it]: train_loss_raw=1.5054, running_loss=1.5172, LR=0.000100
[2025-08-26 23:36:29,516][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016104] [Batch 00704/03080] [00:08:51/00:29:52, 0.754s/it]: train_loss_raw=1.5747, running_loss=1.5191, LR=0.000100
[2025-08-26 23:36:35,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016112] [Batch 00712/03080] [00:08:57/00:29:46, 0.754s/it]: train_loss_raw=1.4992, running_loss=1.5199, LR=0.000100
[2025-08-26 23:36:41,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016120] [Batch 00720/03080] [00:09:03/00:29:40, 0.754s/it]: train_loss_raw=1.4753, running_loss=1.5188, LR=0.000100
[2025-08-26 23:36:47,607][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016128] [Batch 00728/03080] [00:09:09/00:29:34, 0.754s/it]: train_loss_raw=1.5732, running_loss=1.5224, LR=0.000100
[2025-08-26 23:36:53,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016136] [Batch 00736/03080] [00:09:15/00:29:27, 0.754s/it]: train_loss_raw=1.5562, running_loss=1.5204, LR=0.000100
[2025-08-26 23:36:59,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016144] [Batch 00744/03080] [00:09:21/00:29:21, 0.754s/it]: train_loss_raw=1.4619, running_loss=1.5193, LR=0.000100
[2025-08-26 23:37:05,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016152] [Batch 00752/03080] [00:09:27/00:29:15, 0.754s/it]: train_loss_raw=1.4137, running_loss=1.5222, LR=0.000100
[2025-08-26 23:37:11,749][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016160] [Batch 00760/03080] [00:09:33/00:29:10, 0.754s/it]: train_loss_raw=1.5532, running_loss=1.5203, LR=0.000100
[2025-08-26 23:37:17,630][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016168] [Batch 00768/03080] [00:09:39/00:29:03, 0.754s/it]: train_loss_raw=1.5678, running_loss=1.5200, LR=0.000100
[2025-08-26 23:37:23,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016176] [Batch 00776/03080] [00:09:45/00:28:56, 0.754s/it]: train_loss_raw=1.4985, running_loss=1.5183, LR=0.000100
[2025-08-26 23:37:29,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016184] [Batch 00784/03080] [00:09:51/00:28:50, 0.754s/it]: train_loss_raw=1.6870, running_loss=1.5197, LR=0.000100
[2025-08-26 23:37:35,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016192] [Batch 00792/03080] [00:09:57/00:28:44, 0.754s/it]: train_loss_raw=1.5338, running_loss=1.5165, LR=0.000100
[2025-08-26 23:37:41,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016200] [Batch 00800/03080] [00:10:03/00:28:38, 0.754s/it]: train_loss_raw=1.5714, running_loss=1.5163, LR=0.000100
[2025-08-26 23:37:47,758][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016208] [Batch 00808/03080] [00:10:09/00:28:33, 0.754s/it]: train_loss_raw=1.5609, running_loss=1.5171, LR=0.000100
[2025-08-26 23:37:53,888][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016216] [Batch 00816/03080] [00:10:15/00:28:27, 0.754s/it]: train_loss_raw=1.5629, running_loss=1.5139, LR=0.000100
[2025-08-26 23:38:00,028][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016224] [Batch 00824/03080] [00:10:21/00:28:21, 0.754s/it]: train_loss_raw=1.5119, running_loss=1.5167, LR=0.000100
[2025-08-26 23:38:06,068][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016232] [Batch 00832/03080] [00:10:27/00:28:15, 0.754s/it]: train_loss_raw=1.5401, running_loss=1.5177, LR=0.000100
[2025-08-26 23:38:12,029][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016240] [Batch 00840/03080] [00:10:33/00:28:09, 0.754s/it]: train_loss_raw=1.5740, running_loss=1.5154, LR=0.000100
[2025-08-26 23:38:18,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016248] [Batch 00848/03080] [00:10:39/00:28:03, 0.754s/it]: train_loss_raw=1.4476, running_loss=1.5142, LR=0.000100
[2025-08-26 23:38:23,971][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016256] [Batch 00856/03080] [00:10:45/00:27:57, 0.754s/it]: train_loss_raw=1.5610, running_loss=1.5098, LR=0.000100
[2025-08-26 23:38:29,915][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016264] [Batch 00864/03080] [00:10:51/00:27:50, 0.754s/it]: train_loss_raw=1.5653, running_loss=1.5124, LR=0.000100
[2025-08-26 23:38:35,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016272] [Batch 00872/03080] [00:10:57/00:27:43, 0.754s/it]: train_loss_raw=1.4293, running_loss=1.5098, LR=0.000100
[2025-08-26 23:38:41,261][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016280] [Batch 00880/03080] [00:11:02/00:27:37, 0.753s/it]: train_loss_raw=1.5197, running_loss=1.5110, LR=0.000100
[2025-08-26 23:38:47,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016288] [Batch 00888/03080] [00:11:08/00:27:30, 0.753s/it]: train_loss_raw=1.5187, running_loss=1.5138, LR=0.000100
[2025-08-26 23:38:52,985][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016296] [Batch 00896/03080] [00:11:14/00:27:24, 0.753s/it]: train_loss_raw=1.4637, running_loss=1.5147, LR=0.000100
[2025-08-26 23:38:58,765][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016304] [Batch 00904/03080] [00:11:20/00:27:17, 0.753s/it]: train_loss_raw=1.5356, running_loss=1.5149, LR=0.000100
[2025-08-26 23:39:04,710][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016312] [Batch 00912/03080] [00:11:26/00:27:11, 0.752s/it]: train_loss_raw=1.4544, running_loss=1.5125, LR=0.000100
[2025-08-26 23:39:10,707][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016320] [Batch 00920/03080] [00:11:32/00:27:05, 0.752s/it]: train_loss_raw=1.5377, running_loss=1.5125, LR=0.000100
[2025-08-26 23:39:16,722][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016328] [Batch 00928/03080] [00:11:38/00:26:59, 0.752s/it]: train_loss_raw=1.4822, running_loss=1.5125, LR=0.000100
[2025-08-26 23:39:22,719][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016336] [Batch 00936/03080] [00:11:44/00:26:53, 0.752s/it]: train_loss_raw=1.5926, running_loss=1.5121, LR=0.000100
[2025-08-26 23:39:28,581][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016344] [Batch 00944/03080] [00:11:50/00:26:46, 0.752s/it]: train_loss_raw=1.4789, running_loss=1.5110, LR=0.000100
[2025-08-26 23:39:34,527][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016352] [Batch 00952/03080] [00:11:56/00:26:40, 0.752s/it]: train_loss_raw=1.5818, running_loss=1.5084, LR=0.000100
[2025-08-26 23:39:40,479][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016360] [Batch 00960/03080] [00:12:02/00:26:34, 0.752s/it]: train_loss_raw=1.3976, running_loss=1.5093, LR=0.000100
[2025-08-26 23:39:46,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016368] [Batch 00968/03080] [00:12:07/00:26:27, 0.752s/it]: train_loss_raw=1.5387, running_loss=1.5087, LR=0.000100
[2025-08-26 23:39:52,053][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016376] [Batch 00976/03080] [00:12:13/00:26:21, 0.752s/it]: train_loss_raw=1.5917, running_loss=1.5076, LR=0.000100
[2025-08-26 23:39:58,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016384] [Batch 00984/03080] [00:12:19/00:26:15, 0.752s/it]: train_loss_raw=1.4637, running_loss=1.5087, LR=0.000100
[2025-08-26 23:40:03,892][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016392] [Batch 00992/03080] [00:12:25/00:26:09, 0.751s/it]: train_loss_raw=1.5053, running_loss=1.5082, LR=0.000100
[2025-08-26 23:40:09,812][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016400] [Batch 01000/03080] [00:12:31/00:26:02, 0.751s/it]: train_loss_raw=1.5518, running_loss=1.5069, LR=0.000100
[2025-08-26 23:40:15,922][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016408] [Batch 01008/03080] [00:12:37/00:25:57, 0.751s/it]: train_loss_raw=1.4474, running_loss=1.5066, LR=0.000100
[2025-08-26 23:40:22,002][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016416] [Batch 01016/03080] [00:12:43/00:25:51, 0.752s/it]: train_loss_raw=1.5127, running_loss=1.5014, LR=0.000100
[2025-08-26 23:40:28,176][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016424] [Batch 01024/03080] [00:12:49/00:25:45, 0.752s/it]: train_loss_raw=1.5457, running_loss=1.5016, LR=0.000100
[2025-08-26 23:40:34,047][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016432] [Batch 01032/03080] [00:12:55/00:25:39, 0.752s/it]: train_loss_raw=1.4810, running_loss=1.5041, LR=0.000100
[2025-08-26 23:40:39,899][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016440] [Batch 01040/03080] [00:13:01/00:25:32, 0.751s/it]: train_loss_raw=1.4280, running_loss=1.5034, LR=0.000100
[2025-08-26 23:40:45,889][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016448] [Batch 01048/03080] [00:13:07/00:25:26, 0.751s/it]: train_loss_raw=1.4522, running_loss=1.5029, LR=0.000100
[2025-08-26 23:40:51,769][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016456] [Batch 01056/03080] [00:13:13/00:25:20, 0.751s/it]: train_loss_raw=1.5819, running_loss=1.5022, LR=0.000100
[2025-08-26 23:40:57,629][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016464] [Batch 01064/03080] [00:13:19/00:25:14, 0.751s/it]: train_loss_raw=1.5065, running_loss=1.4988, LR=0.000100
[2025-08-26 23:41:03,543][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016472] [Batch 01072/03080] [00:13:25/00:25:08, 0.751s/it]: train_loss_raw=1.5568, running_loss=1.4994, LR=0.000100
[2025-08-26 23:41:09,298][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016480] [Batch 01080/03080] [00:13:30/00:25:01, 0.751s/it]: train_loss_raw=1.6101, running_loss=1.5013, LR=0.000100
[2025-08-26 23:41:15,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016488] [Batch 01088/03080] [00:13:36/00:24:55, 0.751s/it]: train_loss_raw=1.4647, running_loss=1.5002, LR=0.000100
[2025-08-26 23:41:21,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016496] [Batch 01096/03080] [00:13:42/00:24:48, 0.750s/it]: train_loss_raw=1.4797, running_loss=1.5018, LR=0.000100
[2025-08-26 23:41:26,914][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016504] [Batch 01104/03080] [00:13:48/00:24:42, 0.750s/it]: train_loss_raw=1.3525, running_loss=1.5008, LR=0.000100
[2025-08-26 23:41:32,908][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016512] [Batch 01112/03080] [00:13:54/00:24:36, 0.750s/it]: train_loss_raw=1.5548, running_loss=1.5007, LR=0.000100
[2025-08-26 23:41:38,864][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016520] [Batch 01120/03080] [00:14:00/00:24:30, 0.750s/it]: train_loss_raw=1.5397, running_loss=1.5017, LR=0.000100
[2025-08-26 23:41:44,874][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016528] [Batch 01128/03080] [00:14:06/00:24:24, 0.750s/it]: train_loss_raw=1.5979, running_loss=1.5026, LR=0.000100
[2025-08-26 23:41:50,667][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016536] [Batch 01136/03080] [00:14:12/00:24:18, 0.750s/it]: train_loss_raw=1.4310, running_loss=1.5008, LR=0.000100
[2025-08-26 23:41:56,665][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016544] [Batch 01144/03080] [00:14:18/00:24:12, 0.750s/it]: train_loss_raw=1.4825, running_loss=1.4993, LR=0.000100
[2025-08-26 23:42:02,677][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016552] [Batch 01152/03080] [00:14:24/00:24:06, 0.750s/it]: train_loss_raw=1.5338, running_loss=1.5008, LR=0.000100
[2025-08-26 23:42:08,634][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016560] [Batch 01160/03080] [00:14:30/00:24:00, 0.750s/it]: train_loss_raw=1.4446, running_loss=1.4998, LR=0.000100
[2025-08-26 23:42:14,558][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016568] [Batch 01168/03080] [00:14:36/00:23:54, 0.750s/it]: train_loss_raw=1.3775, running_loss=1.4973, LR=0.000100
[2025-08-26 23:42:20,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016576] [Batch 01176/03080] [00:14:41/00:23:47, 0.750s/it]: train_loss_raw=1.4785, running_loss=1.4971, LR=0.000100
[2025-08-26 23:42:26,396][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016584] [Batch 01184/03080] [00:14:47/00:23:41, 0.750s/it]: train_loss_raw=1.4654, running_loss=1.4963, LR=0.000100
[2025-08-26 23:42:32,455][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016592] [Batch 01192/03080] [00:14:53/00:23:35, 0.750s/it]: train_loss_raw=1.3771, running_loss=1.4943, LR=0.000100
[2025-08-26 23:42:38,350][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016600] [Batch 01200/03080] [00:14:59/00:23:29, 0.750s/it]: train_loss_raw=1.4228, running_loss=1.4936, LR=0.000100
[2025-08-26 23:42:44,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016608] [Batch 01208/03080] [00:15:05/00:23:23, 0.750s/it]: train_loss_raw=1.4953, running_loss=1.4933, LR=0.000100
[2025-08-26 23:42:50,200][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016616] [Batch 01216/03080] [00:15:11/00:23:17, 0.750s/it]: train_loss_raw=1.5112, running_loss=1.4974, LR=0.000100
[2025-08-26 23:42:56,190][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016624] [Batch 01224/03080] [00:15:17/00:23:11, 0.750s/it]: train_loss_raw=1.5720, running_loss=1.4987, LR=0.000100
[2025-08-26 23:43:02,009][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016632] [Batch 01232/03080] [00:15:23/00:23:05, 0.750s/it]: train_loss_raw=1.4143, running_loss=1.4949, LR=0.000100
[2025-08-26 23:43:08,008][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016640] [Batch 01240/03080] [00:15:29/00:22:59, 0.750s/it]: train_loss_raw=1.5000, running_loss=1.4926, LR=0.000100
[2025-08-26 23:43:13,908][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016648] [Batch 01248/03080] [00:15:35/00:22:53, 0.750s/it]: train_loss_raw=1.4611, running_loss=1.4941, LR=0.000100
[2025-08-26 23:43:19,927][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016656] [Batch 01256/03080] [00:15:41/00:22:47, 0.750s/it]: train_loss_raw=1.5159, running_loss=1.4941, LR=0.000100
[2025-08-26 23:43:25,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016664] [Batch 01264/03080] [00:15:47/00:22:41, 0.749s/it]: train_loss_raw=1.5544, running_loss=1.4923, LR=0.000100
[2025-08-26 23:43:31,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016672] [Batch 01272/03080] [00:15:53/00:22:34, 0.749s/it]: train_loss_raw=1.4728, running_loss=1.4912, LR=0.000100
[2025-08-26 23:43:37,450][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016680] [Batch 01280/03080] [00:15:58/00:22:28, 0.749s/it]: train_loss_raw=1.4540, running_loss=1.4919, LR=0.000100
[2025-08-26 23:43:43,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016688] [Batch 01288/03080] [00:16:05/00:22:22, 0.749s/it]: train_loss_raw=1.4816, running_loss=1.4941, LR=0.000100
[2025-08-26 23:43:49,549][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016696] [Batch 01296/03080] [00:16:11/00:22:16, 0.749s/it]: train_loss_raw=1.4281, running_loss=1.4952, LR=0.000100
[2025-08-26 23:43:55,301][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016704] [Batch 01304/03080] [00:16:16/00:22:10, 0.749s/it]: train_loss_raw=1.5363, running_loss=1.4940, LR=0.000100
[2025-08-26 23:44:01,112][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016712] [Batch 01312/03080] [00:16:22/00:22:04, 0.749s/it]: train_loss_raw=1.4558, running_loss=1.4895, LR=0.000100
[2025-08-26 23:44:07,062][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016720] [Batch 01320/03080] [00:16:28/00:21:58, 0.749s/it]: train_loss_raw=1.5208, running_loss=1.4903, LR=0.000100
[2025-08-26 23:44:12,853][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016728] [Batch 01328/03080] [00:16:34/00:21:51, 0.749s/it]: train_loss_raw=1.4948, running_loss=1.4929, LR=0.000100
[2025-08-26 23:44:18,569][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016736] [Batch 01336/03080] [00:16:40/00:21:45, 0.749s/it]: train_loss_raw=1.5078, running_loss=1.4929, LR=0.000100
[2025-08-26 23:44:24,431][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016744] [Batch 01344/03080] [00:16:45/00:21:39, 0.748s/it]: train_loss_raw=1.4765, running_loss=1.4911, LR=0.000100
[2025-08-26 23:44:30,349][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016752] [Batch 01352/03080] [00:16:51/00:21:33, 0.748s/it]: train_loss_raw=1.4113, running_loss=1.4887, LR=0.000100
[2025-08-26 23:44:36,331][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016760] [Batch 01360/03080] [00:16:57/00:21:27, 0.748s/it]: train_loss_raw=1.4624, running_loss=1.4902, LR=0.000100
[2025-08-26 23:44:42,222][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016768] [Batch 01368/03080] [00:17:03/00:21:21, 0.748s/it]: train_loss_raw=1.4971, running_loss=1.4902, LR=0.000100
[2025-08-26 23:44:48,315][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016776] [Batch 01376/03080] [00:17:09/00:21:15, 0.748s/it]: train_loss_raw=1.4883, running_loss=1.4906, LR=0.000100
[2025-08-26 23:44:54,330][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016784] [Batch 01384/03080] [00:17:15/00:21:09, 0.748s/it]: train_loss_raw=1.4796, running_loss=1.4915, LR=0.000100
[2025-08-26 23:45:00,623][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016792] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=1.5462, running_loss=1.4905, LR=0.000100
[2025-08-26 23:45:06,765][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016800] [Batch 01400/03080] [00:17:28/00:20:57, 0.749s/it]: train_loss_raw=1.4727, running_loss=1.4879, LR=0.000100
[2025-08-26 23:45:13,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016808] [Batch 01408/03080] [00:17:34/00:20:52, 0.749s/it]: train_loss_raw=1.5307, running_loss=1.4881, LR=0.000100
[2025-08-26 23:45:19,028][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016816] [Batch 01416/03080] [00:17:40/00:20:46, 0.749s/it]: train_loss_raw=1.4831, running_loss=1.4868, LR=0.000100
[2025-08-26 23:45:24,979][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016824] [Batch 01424/03080] [00:17:46/00:20:40, 0.749s/it]: train_loss_raw=1.4952, running_loss=1.4909, LR=0.000100
[2025-08-26 23:45:30,907][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016832] [Batch 01432/03080] [00:17:52/00:20:34, 0.749s/it]: train_loss_raw=1.6009, running_loss=1.4909, LR=0.000100
[2025-08-26 23:45:36,948][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016840] [Batch 01440/03080] [00:17:58/00:20:28, 0.749s/it]: train_loss_raw=1.4211, running_loss=1.4903, LR=0.000100
[2025-08-26 23:45:42,858][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016848] [Batch 01448/03080] [00:18:04/00:20:22, 0.749s/it]: train_loss_raw=1.4436, running_loss=1.4898, LR=0.000100
[2025-08-26 23:45:48,917][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016856] [Batch 01456/03080] [00:18:10/00:20:16, 0.749s/it]: train_loss_raw=1.3983, running_loss=1.4873, LR=0.000100
[2025-08-26 23:45:55,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016864] [Batch 01464/03080] [00:18:16/00:20:10, 0.749s/it]: train_loss_raw=1.4108, running_loss=1.4867, LR=0.000100
[2025-08-26 23:46:01,243][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016872] [Batch 01472/03080] [00:18:22/00:20:04, 0.749s/it]: train_loss_raw=1.4890, running_loss=1.4855, LR=0.000100
[2025-08-26 23:46:07,456][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016880] [Batch 01480/03080] [00:18:28/00:19:58, 0.749s/it]: train_loss_raw=1.5280, running_loss=1.4839, LR=0.000100
[2025-08-26 23:46:13,430][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016888] [Batch 01488/03080] [00:18:34/00:19:52, 0.749s/it]: train_loss_raw=1.4557, running_loss=1.4819, LR=0.000100
[2025-08-26 23:46:19,195][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016896] [Batch 01496/03080] [00:18:40/00:19:46, 0.749s/it]: train_loss_raw=1.5267, running_loss=1.4817, LR=0.000100
[2025-08-26 23:46:25,055][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016904] [Batch 01504/03080] [00:18:46/00:19:40, 0.749s/it]: train_loss_raw=1.5547, running_loss=1.4839, LR=0.000100
[2025-08-26 23:46:31,163][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016912] [Batch 01512/03080] [00:18:52/00:19:34, 0.749s/it]: train_loss_raw=1.4641, running_loss=1.4840, LR=0.000100
[2025-08-26 23:46:37,355][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016920] [Batch 01520/03080] [00:18:58/00:19:28, 0.749s/it]: train_loss_raw=1.4293, running_loss=1.4830, LR=0.000100
[2025-08-26 23:46:43,258][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016928] [Batch 01528/03080] [00:19:04/00:19:22, 0.749s/it]: train_loss_raw=1.4461, running_loss=1.4831, LR=0.000100
[2025-08-26 23:46:49,056][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016936] [Batch 01536/03080] [00:19:10/00:19:16, 0.749s/it]: train_loss_raw=1.5941, running_loss=1.4828, LR=0.000100
[2025-08-26 23:46:54,822][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016944] [Batch 01544/03080] [00:19:16/00:19:10, 0.749s/it]: train_loss_raw=1.5063, running_loss=1.4831, LR=0.000100
[2025-08-26 23:47:00,676][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016952] [Batch 01552/03080] [00:19:22/00:19:04, 0.749s/it]: train_loss_raw=1.5776, running_loss=1.4820, LR=0.000100
[2025-08-26 23:47:06,670][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016960] [Batch 01560/03080] [00:19:28/00:18:58, 0.749s/it]: train_loss_raw=1.4974, running_loss=1.4858, LR=0.000100
[2025-08-26 23:47:12,660][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016968] [Batch 01568/03080] [00:19:34/00:18:52, 0.749s/it]: train_loss_raw=1.4888, running_loss=1.4895, LR=0.000100
[2025-08-26 23:47:18,919][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016976] [Batch 01576/03080] [00:19:40/00:18:46, 0.749s/it]: train_loss_raw=1.5552, running_loss=1.4898, LR=0.000100
[2025-08-26 23:47:24,930][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016984] [Batch 01584/03080] [00:19:46/00:18:40, 0.749s/it]: train_loss_raw=1.4533, running_loss=1.4871, LR=0.000100
[2025-08-26 23:47:31,033][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016992] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=1.5114, running_loss=1.4900, LR=0.000100
[2025-08-26 23:47:36,932][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017000] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=1.4417, running_loss=1.4927, LR=0.000100
[2025-08-26 23:47:43,157][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017008] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=1.5041, running_loss=1.4942, LR=0.000100
[2025-08-26 23:47:49,283][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017016] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=1.4683, running_loss=1.4896, LR=0.000100
[2025-08-26 23:47:55,534][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017024] [Batch 01624/03080] [00:20:17/00:18:11, 0.749s/it]: train_loss_raw=1.4586, running_loss=1.4912, LR=0.000100
[2025-08-26 23:48:01,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017032] [Batch 01632/03080] [00:20:23/00:18:05, 0.750s/it]: train_loss_raw=1.3715, running_loss=1.4904, LR=0.000100
[2025-08-26 23:48:07,658][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017040] [Batch 01640/03080] [00:20:29/00:17:59, 0.750s/it]: train_loss_raw=1.4054, running_loss=1.4884, LR=0.000100
[2025-08-26 23:48:13,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017048] [Batch 01648/03080] [00:20:35/00:17:53, 0.750s/it]: train_loss_raw=1.4032, running_loss=1.4873, LR=0.000100
[2025-08-26 23:48:19,692][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017056] [Batch 01656/03080] [00:20:41/00:17:47, 0.750s/it]: train_loss_raw=1.5209, running_loss=1.4839, LR=0.000100
[2025-08-26 23:48:25,618][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017064] [Batch 01664/03080] [00:20:47/00:17:41, 0.749s/it]: train_loss_raw=1.6379, running_loss=1.4837, LR=0.000100
[2025-08-26 23:48:31,541][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017072] [Batch 01672/03080] [00:20:53/00:17:35, 0.749s/it]: train_loss_raw=1.5859, running_loss=1.4845, LR=0.000100
[2025-08-26 23:48:37,533][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017080] [Batch 01680/03080] [00:20:59/00:17:29, 0.749s/it]: train_loss_raw=1.4758, running_loss=1.4851, LR=0.000100
[2025-08-26 23:48:43,488][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017088] [Batch 01688/03080] [00:21:05/00:17:23, 0.749s/it]: train_loss_raw=1.4663, running_loss=1.4857, LR=0.000100
[2025-08-26 23:48:49,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017096] [Batch 01696/03080] [00:21:11/00:17:17, 0.749s/it]: train_loss_raw=1.4573, running_loss=1.4870, LR=0.000100
[2025-08-26 23:48:55,501][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017104] [Batch 01704/03080] [00:21:17/00:17:11, 0.749s/it]: train_loss_raw=1.6064, running_loss=1.4858, LR=0.000100
[2025-08-26 23:49:01,399][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017112] [Batch 01712/03080] [00:21:22/00:17:05, 0.749s/it]: train_loss_raw=1.5192, running_loss=1.4872, LR=0.000100
[2025-08-26 23:49:07,189][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017120] [Batch 01720/03080] [00:21:28/00:16:58, 0.749s/it]: train_loss_raw=1.4642, running_loss=1.4863, LR=0.000100
[2025-08-26 23:49:12,974][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017128] [Batch 01728/03080] [00:21:34/00:16:52, 0.749s/it]: train_loss_raw=1.3863, running_loss=1.4861, LR=0.000100
[2025-08-26 23:49:18,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017136] [Batch 01736/03080] [00:21:40/00:16:46, 0.749s/it]: train_loss_raw=1.6009, running_loss=1.4851, LR=0.000100
[2025-08-26 23:49:24,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017144] [Batch 01744/03080] [00:21:46/00:16:40, 0.749s/it]: train_loss_raw=1.4932, running_loss=1.4853, LR=0.000100
[2025-08-26 23:49:30,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017152] [Batch 01752/03080] [00:21:51/00:16:34, 0.749s/it]: train_loss_raw=1.4038, running_loss=1.4850, LR=0.000100
[2025-08-26 23:49:36,218][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017160] [Batch 01760/03080] [00:21:57/00:16:28, 0.749s/it]: train_loss_raw=1.4817, running_loss=1.4839, LR=0.000100
[2025-08-26 23:49:42,261][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017168] [Batch 01768/03080] [00:22:03/00:16:22, 0.749s/it]: train_loss_raw=1.4496, running_loss=1.4841, LR=0.000100
[2025-08-26 23:49:48,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017176] [Batch 01776/03080] [00:22:09/00:16:16, 0.749s/it]: train_loss_raw=1.4595, running_loss=1.4831, LR=0.000100
[2025-08-26 23:49:54,298][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017184] [Batch 01784/03080] [00:22:15/00:16:10, 0.749s/it]: train_loss_raw=1.4657, running_loss=1.4821, LR=0.000100
[2025-08-26 23:50:00,336][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017192] [Batch 01792/03080] [00:22:21/00:16:04, 0.749s/it]: train_loss_raw=1.4247, running_loss=1.4852, LR=0.000100
[2025-08-26 23:50:06,384][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017200] [Batch 01800/03080] [00:22:27/00:15:58, 0.749s/it]: train_loss_raw=1.4652, running_loss=1.4871, LR=0.000100
[2025-08-26 23:50:12,277][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017208] [Batch 01808/03080] [00:22:33/00:15:52, 0.749s/it]: train_loss_raw=1.3926, running_loss=1.4868, LR=0.000100
[2025-08-26 23:50:17,987][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017216] [Batch 01816/03080] [00:22:39/00:15:46, 0.749s/it]: train_loss_raw=1.4418, running_loss=1.4842, LR=0.000100
[2025-08-26 23:50:23,820][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017224] [Batch 01824/03080] [00:22:45/00:15:40, 0.749s/it]: train_loss_raw=1.4590, running_loss=1.4844, LR=0.000100
[2025-08-26 23:50:29,685][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017232] [Batch 01832/03080] [00:22:51/00:15:34, 0.748s/it]: train_loss_raw=1.4031, running_loss=1.4830, LR=0.000100
[2025-08-26 23:50:35,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017240] [Batch 01840/03080] [00:22:57/00:15:28, 0.748s/it]: train_loss_raw=1.5444, running_loss=1.4838, LR=0.000100
[2025-08-26 23:50:41,524][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017248] [Batch 01848/03080] [00:23:03/00:15:22, 0.748s/it]: train_loss_raw=1.4653, running_loss=1.4815, LR=0.000100
[2025-08-26 23:50:47,295][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017256] [Batch 01856/03080] [00:23:08/00:15:15, 0.748s/it]: train_loss_raw=1.5632, running_loss=1.4821, LR=0.000100
[2025-08-26 23:50:53,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017264] [Batch 01864/03080] [00:23:15/00:15:10, 0.748s/it]: train_loss_raw=1.3581, running_loss=1.4794, LR=0.000100
[2025-08-26 23:50:59,833][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017272] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=1.4435, running_loss=1.4788, LR=0.000100
[2025-08-26 23:51:05,958][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017280] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=1.5638, running_loss=1.4817, LR=0.000100
[2025-08-26 23:51:11,652][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017288] [Batch 01888/03080] [00:23:33/00:14:52, 0.749s/it]: train_loss_raw=1.5235, running_loss=1.4817, LR=0.000100
[2025-08-26 23:51:17,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017296] [Batch 01896/03080] [00:23:38/00:14:46, 0.748s/it]: train_loss_raw=1.4588, running_loss=1.4796, LR=0.000100
[2025-08-26 23:51:23,376][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017304] [Batch 01904/03080] [00:23:44/00:14:40, 0.748s/it]: train_loss_raw=1.4079, running_loss=1.4754, LR=0.000100
[2025-08-26 23:51:29,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017312] [Batch 01912/03080] [00:23:51/00:14:34, 0.748s/it]: train_loss_raw=1.4234, running_loss=1.4740, LR=0.000100
[2025-08-26 23:51:35,245][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017320] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=1.3720, running_loss=1.4731, LR=0.000100
[2025-08-26 23:51:41,185][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017328] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=1.5397, running_loss=1.4748, LR=0.000100
[2025-08-26 23:51:47,171][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017336] [Batch 01936/03080] [00:24:08/00:14:16, 0.748s/it]: train_loss_raw=1.5697, running_loss=1.4752, LR=0.000100
[2025-08-26 23:51:53,084][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017344] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=1.4973, running_loss=1.4729, LR=0.000100
[2025-08-26 23:51:59,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017352] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=1.4423, running_loss=1.4715, LR=0.000100
[2025-08-26 23:52:05,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017360] [Batch 01960/03080] [00:24:26/00:13:58, 0.748s/it]: train_loss_raw=1.5147, running_loss=1.4697, LR=0.000100
[2025-08-26 23:52:11,383][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017368] [Batch 01968/03080] [00:24:32/00:13:52, 0.748s/it]: train_loss_raw=1.3685, running_loss=1.4653, LR=0.000100
[2025-08-26 23:52:17,377][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017376] [Batch 01976/03080] [00:24:38/00:13:46, 0.748s/it]: train_loss_raw=1.4124, running_loss=1.4670, LR=0.000100
[2025-08-26 23:52:23,391][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017384] [Batch 01984/03080] [00:24:44/00:13:40, 0.748s/it]: train_loss_raw=1.4431, running_loss=1.4691, LR=0.000100
[2025-08-26 23:52:29,421][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017392] [Batch 01992/03080] [00:24:50/00:13:34, 0.748s/it]: train_loss_raw=1.4680, running_loss=1.4704, LR=0.000100
[2025-08-26 23:52:35,220][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017400] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=1.4933, running_loss=1.4706, LR=0.000100
[2025-08-26 23:52:41,386][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017408] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=1.4448, running_loss=1.4711, LR=0.000100
[2025-08-26 23:52:47,479][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017416] [Batch 02016/03080] [00:25:09/00:13:16, 0.749s/it]: train_loss_raw=1.4247, running_loss=1.4690, LR=0.000100
[2025-08-26 23:52:53,511][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017424] [Batch 02024/03080] [00:25:15/00:13:10, 0.749s/it]: train_loss_raw=1.4047, running_loss=1.4675, LR=0.000100
[2025-08-26 23:52:59,595][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017432] [Batch 02032/03080] [00:25:21/00:13:04, 0.749s/it]: train_loss_raw=1.4018, running_loss=1.4652, LR=0.000100
[2025-08-26 23:53:05,498][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017440] [Batch 02040/03080] [00:25:27/00:12:58, 0.749s/it]: train_loss_raw=1.4487, running_loss=1.4663, LR=0.000100
[2025-08-26 23:53:11,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017448] [Batch 02048/03080] [00:25:32/00:12:52, 0.749s/it]: train_loss_raw=1.4700, running_loss=1.4665, LR=0.000100
[2025-08-26 23:53:17,754][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017456] [Batch 02056/03080] [00:25:39/00:12:46, 0.749s/it]: train_loss_raw=1.4994, running_loss=1.4664, LR=0.000100
[2025-08-26 23:53:23,761][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017464] [Batch 02064/03080] [00:25:45/00:12:40, 0.749s/it]: train_loss_raw=1.4436, running_loss=1.4662, LR=0.000100
[2025-08-26 23:53:29,762][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017472] [Batch 02072/03080] [00:25:51/00:12:34, 0.749s/it]: train_loss_raw=1.4917, running_loss=1.4674, LR=0.000100
[2025-08-26 23:53:35,842][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017480] [Batch 02080/03080] [00:25:57/00:12:28, 0.749s/it]: train_loss_raw=1.4747, running_loss=1.4666, LR=0.000100
[2025-08-26 23:53:41,873][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017488] [Batch 02088/03080] [00:26:03/00:12:22, 0.749s/it]: train_loss_raw=1.5200, running_loss=1.4660, LR=0.000100
[2025-08-26 23:53:47,760][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017496] [Batch 02096/03080] [00:26:09/00:12:16, 0.749s/it]: train_loss_raw=1.4997, running_loss=1.4648, LR=0.000100
[2025-08-26 23:53:53,587][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017504] [Batch 02104/03080] [00:26:15/00:12:10, 0.749s/it]: train_loss_raw=1.3615, running_loss=1.4662, LR=0.000100
[2025-08-26 23:53:59,667][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017512] [Batch 02112/03080] [00:26:21/00:12:04, 0.749s/it]: train_loss_raw=1.4308, running_loss=1.4680, LR=0.000100
[2025-08-26 23:54:05,489][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017520] [Batch 02120/03080] [00:26:27/00:11:58, 0.749s/it]: train_loss_raw=1.4340, running_loss=1.4673, LR=0.000100
[2025-08-26 23:54:11,583][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017528] [Batch 02128/03080] [00:26:33/00:11:52, 0.749s/it]: train_loss_raw=1.5045, running_loss=1.4692, LR=0.000100
[2025-08-26 23:54:17,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017536] [Batch 02136/03080] [00:26:39/00:11:46, 0.749s/it]: train_loss_raw=1.5037, running_loss=1.4682, LR=0.000100
[2025-08-26 23:54:23,759][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017544] [Batch 02144/03080] [00:26:45/00:11:40, 0.749s/it]: train_loss_raw=1.5306, running_loss=1.4687, LR=0.000100
[2025-08-26 23:54:29,948][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017552] [Batch 02152/03080] [00:26:51/00:11:34, 0.749s/it]: train_loss_raw=1.4689, running_loss=1.4656, LR=0.000100
[2025-08-26 23:54:35,985][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017560] [Batch 02160/03080] [00:26:57/00:11:28, 0.749s/it]: train_loss_raw=1.4686, running_loss=1.4629, LR=0.000100
[2025-08-26 23:54:41,890][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017568] [Batch 02168/03080] [00:27:03/00:11:22, 0.749s/it]: train_loss_raw=1.5417, running_loss=1.4643, LR=0.000100
[2025-08-26 23:54:47,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017576] [Batch 02176/03080] [00:27:09/00:11:16, 0.749s/it]: train_loss_raw=1.4917, running_loss=1.4623, LR=0.000100
[2025-08-26 23:54:53,648][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017584] [Batch 02184/03080] [00:27:15/00:11:10, 0.749s/it]: train_loss_raw=1.4566, running_loss=1.4621, LR=0.000100
[2025-08-26 23:54:59,875][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017592] [Batch 02192/03080] [00:27:21/00:11:04, 0.749s/it]: train_loss_raw=1.3643, running_loss=1.4598, LR=0.000100
[2025-08-26 23:55:06,252][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017600] [Batch 02200/03080] [00:27:27/00:10:59, 0.749s/it]: train_loss_raw=1.4931, running_loss=1.4609, LR=0.000100
[2025-08-26 23:55:12,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017608] [Batch 02208/03080] [00:27:33/00:10:53, 0.749s/it]: train_loss_raw=1.4540, running_loss=1.4598, LR=0.000100
[2025-08-26 23:55:18,562][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017616] [Batch 02216/03080] [00:27:40/00:10:47, 0.749s/it]: train_loss_raw=1.4239, running_loss=1.4601, LR=0.000100
[2025-08-26 23:55:24,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017624] [Batch 02224/03080] [00:27:46/00:10:41, 0.749s/it]: train_loss_raw=1.4004, running_loss=1.4626, LR=0.000100
[2025-08-26 23:55:30,333][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017632] [Batch 02232/03080] [00:27:51/00:10:35, 0.749s/it]: train_loss_raw=1.4111, running_loss=1.4622, LR=0.000100
[2025-08-26 23:55:36,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017640] [Batch 02240/03080] [00:27:58/00:10:29, 0.749s/it]: train_loss_raw=1.4619, running_loss=1.4622, LR=0.000100
[2025-08-26 23:55:42,381][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017648] [Batch 02248/03080] [00:28:03/00:10:23, 0.749s/it]: train_loss_raw=1.4796, running_loss=1.4624, LR=0.000100
[2025-08-26 23:55:48,299][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017656] [Batch 02256/03080] [00:28:09/00:10:17, 0.749s/it]: train_loss_raw=1.3678, running_loss=1.4623, LR=0.000100
[2025-08-26 23:55:54,334][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017664] [Batch 02264/03080] [00:28:15/00:10:11, 0.749s/it]: train_loss_raw=1.3979, running_loss=1.4608, LR=0.000100
[2025-08-26 23:56:00,097][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017672] [Batch 02272/03080] [00:28:21/00:10:05, 0.749s/it]: train_loss_raw=1.4757, running_loss=1.4583, LR=0.000100
[2025-08-26 23:56:06,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017680] [Batch 02280/03080] [00:28:27/00:09:59, 0.749s/it]: train_loss_raw=1.5327, running_loss=1.4596, LR=0.000100
[2025-08-26 23:56:12,080][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017688] [Batch 02288/03080] [00:28:33/00:09:53, 0.749s/it]: train_loss_raw=1.4947, running_loss=1.4609, LR=0.000100
[2025-08-26 23:56:18,152][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017696] [Batch 02296/03080] [00:28:39/00:09:47, 0.749s/it]: train_loss_raw=1.3639, running_loss=1.4587, LR=0.000100
[2025-08-26 23:56:24,190][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017704] [Batch 02304/03080] [00:28:45/00:09:41, 0.749s/it]: train_loss_raw=1.4582, running_loss=1.4588, LR=0.000100
[2025-08-26 23:56:30,113][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017712] [Batch 02312/03080] [00:28:51/00:09:35, 0.749s/it]: train_loss_raw=1.5318, running_loss=1.4597, LR=0.000100
[2025-08-26 23:56:36,116][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017720] [Batch 02320/03080] [00:28:57/00:09:29, 0.749s/it]: train_loss_raw=1.4266, running_loss=1.4584, LR=0.000100
[2025-08-26 23:56:42,800][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017728] [Batch 02328/03080] [00:29:04/00:09:23, 0.749s/it]: train_loss_raw=1.3068, running_loss=1.4571, LR=0.000100
[2025-08-26 23:56:48,555][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017736] [Batch 02336/03080] [00:29:10/00:09:17, 0.749s/it]: train_loss_raw=1.4758, running_loss=1.4559, LR=0.000100
[2025-08-26 23:56:54,274][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017744] [Batch 02344/03080] [00:29:15/00:09:11, 0.749s/it]: train_loss_raw=1.4863, running_loss=1.4603, LR=0.000100
[2025-08-26 23:57:00,117][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017752] [Batch 02352/03080] [00:29:21/00:09:05, 0.749s/it]: train_loss_raw=1.4617, running_loss=1.4601, LR=0.000100
[2025-08-26 23:57:06,216][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017760] [Batch 02360/03080] [00:29:27/00:08:59, 0.749s/it]: train_loss_raw=1.4221, running_loss=1.4611, LR=0.000100
[2025-08-26 23:57:12,548][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017768] [Batch 02368/03080] [00:29:34/00:08:53, 0.749s/it]: train_loss_raw=1.4876, running_loss=1.4630, LR=0.000100
[2025-08-26 23:57:18,406][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017776] [Batch 02376/03080] [00:29:39/00:08:47, 0.749s/it]: train_loss_raw=1.4192, running_loss=1.4606, LR=0.000100
[2025-08-26 23:57:24,257][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017784] [Batch 02384/03080] [00:29:45/00:08:41, 0.749s/it]: train_loss_raw=1.4183, running_loss=1.4617, LR=0.000100
[2025-08-26 23:57:30,086][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017792] [Batch 02392/03080] [00:29:51/00:08:35, 0.749s/it]: train_loss_raw=1.3698, running_loss=1.4571, LR=0.000100
[2025-08-26 23:57:36,208][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017800] [Batch 02400/03080] [00:29:57/00:08:29, 0.749s/it]: train_loss_raw=1.5089, running_loss=1.4569, LR=0.000100
[2025-08-26 23:57:42,144][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017808] [Batch 02408/03080] [00:30:03/00:08:23, 0.749s/it]: train_loss_raw=1.5184, running_loss=1.4557, LR=0.000100
[2025-08-26 23:57:47,988][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017816] [Batch 02416/03080] [00:30:09/00:08:17, 0.749s/it]: train_loss_raw=1.4540, running_loss=1.4531, LR=0.000100
[2025-08-26 23:57:53,832][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017824] [Batch 02424/03080] [00:30:15/00:08:11, 0.749s/it]: train_loss_raw=1.4857, running_loss=1.4523, LR=0.000100
[2025-08-26 23:57:59,696][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017832] [Batch 02432/03080] [00:30:21/00:08:05, 0.749s/it]: train_loss_raw=1.3802, running_loss=1.4518, LR=0.000100
[2025-08-26 23:58:05,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017840] [Batch 02440/03080] [00:30:27/00:07:59, 0.749s/it]: train_loss_raw=1.2957, running_loss=1.4495, LR=0.000100
[2025-08-26 23:58:11,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017848] [Batch 02448/03080] [00:30:33/00:07:53, 0.749s/it]: train_loss_raw=1.3812, running_loss=1.4485, LR=0.000100
[2025-08-26 23:58:17,868][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017856] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.5599, running_loss=1.4506, LR=0.000100
[2025-08-26 23:58:23,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017864] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.4667, running_loss=1.4532, LR=0.000100
[2025-08-26 23:58:29,958][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017872] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.5143, running_loss=1.4545, LR=0.000100
[2025-08-26 23:58:35,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017880] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.4561, running_loss=1.4527, LR=0.000100
[2025-08-26 23:58:41,185][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017888] [Batch 02488/03080] [00:31:02/00:07:23, 0.749s/it]: train_loss_raw=1.4981, running_loss=1.4518, LR=0.000100
[2025-08-26 23:58:47,022][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017896] [Batch 02496/03080] [00:31:08/00:07:17, 0.749s/it]: train_loss_raw=1.4332, running_loss=1.4517, LR=0.000100
[2025-08-26 23:58:52,882][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017904] [Batch 02504/03080] [00:31:14/00:07:11, 0.749s/it]: train_loss_raw=1.4906, running_loss=1.4526, LR=0.000100
[2025-08-26 23:58:58,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017912] [Batch 02512/03080] [00:31:20/00:07:05, 0.749s/it]: train_loss_raw=1.4941, running_loss=1.4516, LR=0.000100
[2025-08-26 23:59:04,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017920] [Batch 02520/03080] [00:31:26/00:06:59, 0.748s/it]: train_loss_raw=1.3516, running_loss=1.4522, LR=0.000100
[2025-08-26 23:59:10,295][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017928] [Batch 02528/03080] [00:31:31/00:06:53, 0.748s/it]: train_loss_raw=1.3852, running_loss=1.4523, LR=0.000100
[2025-08-26 23:59:16,027][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017936] [Batch 02536/03080] [00:31:37/00:06:47, 0.748s/it]: train_loss_raw=1.4713, running_loss=1.4506, LR=0.000100
[2025-08-26 23:59:21,960][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017944] [Batch 02544/03080] [00:31:43/00:06:41, 0.748s/it]: train_loss_raw=1.3985, running_loss=1.4500, LR=0.000100
[2025-08-26 23:59:28,219][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017952] [Batch 02552/03080] [00:31:49/00:06:35, 0.748s/it]: train_loss_raw=1.4710, running_loss=1.4535, LR=0.000100
[2025-08-26 23:59:33,884][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017960] [Batch 02560/03080] [00:31:55/00:06:29, 0.748s/it]: train_loss_raw=1.5124, running_loss=1.4525, LR=0.000100
[2025-08-26 23:59:39,759][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017968] [Batch 02568/03080] [00:32:01/00:06:23, 0.748s/it]: train_loss_raw=1.4128, running_loss=1.4536, LR=0.000100
[2025-08-26 23:59:45,412][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017976] [Batch 02576/03080] [00:32:06/00:06:17, 0.748s/it]: train_loss_raw=1.4074, running_loss=1.4544, LR=0.000100
[2025-08-26 23:59:50,931][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017984] [Batch 02584/03080] [00:32:12/00:06:10, 0.748s/it]: train_loss_raw=1.4949, running_loss=1.4523, LR=0.000100
[2025-08-26 23:59:56,830][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017992] [Batch 02592/03080] [00:32:18/00:06:04, 0.748s/it]: train_loss_raw=1.4635, running_loss=1.4518, LR=0.000100
[2025-08-27 00:00:02,854][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018000] [Batch 02600/03080] [00:32:24/00:05:58, 0.748s/it]: train_loss_raw=1.4478, running_loss=1.4526, LR=0.000100
[2025-08-27 00:00:12,531][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018008] [Batch 02608/03080] [00:32:34/00:05:53, 0.749s/it]: train_loss_raw=1.5345, running_loss=1.4529, LR=0.000100
[2025-08-27 00:00:18,319][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018016] [Batch 02616/03080] [00:32:39/00:05:47, 0.749s/it]: train_loss_raw=1.4069, running_loss=1.4530, LR=0.000100
[2025-08-27 00:00:24,060][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018024] [Batch 02624/03080] [00:32:45/00:05:41, 0.749s/it]: train_loss_raw=1.4070, running_loss=1.4515, LR=0.000100
[2025-08-27 00:00:29,780][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018032] [Batch 02632/03080] [00:32:51/00:05:35, 0.749s/it]: train_loss_raw=1.4823, running_loss=1.4514, LR=0.000100
[2025-08-27 00:00:35,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018040] [Batch 02640/03080] [00:32:57/00:05:29, 0.749s/it]: train_loss_raw=1.4216, running_loss=1.4498, LR=0.000100
[2025-08-27 00:00:41,571][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018048] [Batch 02648/03080] [00:33:03/00:05:23, 0.749s/it]: train_loss_raw=1.4005, running_loss=1.4480, LR=0.000100
[2025-08-27 00:00:47,271][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018056] [Batch 02656/03080] [00:33:08/00:05:17, 0.749s/it]: train_loss_raw=1.4428, running_loss=1.4468, LR=0.000100
[2025-08-27 00:00:53,068][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018064] [Batch 02664/03080] [00:33:14/00:05:11, 0.749s/it]: train_loss_raw=1.4366, running_loss=1.4476, LR=0.000100
[2025-08-27 00:00:58,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018072] [Batch 02672/03080] [00:33:20/00:05:05, 0.749s/it]: train_loss_raw=1.4252, running_loss=1.4452, LR=0.000100
[2025-08-27 00:01:04,609][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018080] [Batch 02680/03080] [00:33:26/00:04:59, 0.749s/it]: train_loss_raw=1.4592, running_loss=1.4451, LR=0.000100
[2025-08-27 00:01:10,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018088] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=1.5630, running_loss=1.4472, LR=0.000100
[2025-08-27 00:01:16,128][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018096] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=1.5186, running_loss=1.4476, LR=0.000100
[2025-08-27 00:01:21,856][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018104] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=1.4709, running_loss=1.4497, LR=0.000100
[2025-08-27 00:01:27,496][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018112] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=1.5054, running_loss=1.4498, LR=0.000100
[2025-08-27 00:01:33,245][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018120] [Batch 02720/03080] [00:33:54/00:04:29, 0.748s/it]: train_loss_raw=1.3988, running_loss=1.4475, LR=0.000100
[2025-08-27 00:01:38,953][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018128] [Batch 02728/03080] [00:34:00/00:04:23, 0.748s/it]: train_loss_raw=1.4965, running_loss=1.4482, LR=0.000100
[2025-08-27 00:01:44,868][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018136] [Batch 02736/03080] [00:34:06/00:04:17, 0.748s/it]: train_loss_raw=1.4393, running_loss=1.4480, LR=0.000100
[2025-08-27 00:01:50,792][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018144] [Batch 02744/03080] [00:34:12/00:04:11, 0.748s/it]: train_loss_raw=1.4962, running_loss=1.4488, LR=0.000100
[2025-08-27 00:01:56,702][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018152] [Batch 02752/03080] [00:34:18/00:04:05, 0.748s/it]: train_loss_raw=1.3985, running_loss=1.4447, LR=0.000100
[2025-08-27 00:02:02,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018160] [Batch 02760/03080] [00:34:24/00:03:59, 0.748s/it]: train_loss_raw=1.3229, running_loss=1.4447, LR=0.000100
[2025-08-27 00:02:08,546][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018168] [Batch 02768/03080] [00:34:30/00:03:53, 0.748s/it]: train_loss_raw=1.4018, running_loss=1.4448, LR=0.000100
[2025-08-27 00:02:14,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018176] [Batch 02776/03080] [00:34:36/00:03:47, 0.748s/it]: train_loss_raw=1.4675, running_loss=1.4442, LR=0.000100
[2025-08-27 00:02:20,180][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018184] [Batch 02784/03080] [00:34:41/00:03:41, 0.748s/it]: train_loss_raw=1.2897, running_loss=1.4403, LR=0.000100
[2025-08-27 00:02:25,941][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018192] [Batch 02792/03080] [00:34:47/00:03:35, 0.748s/it]: train_loss_raw=1.3738, running_loss=1.4405, LR=0.000100
[2025-08-27 00:02:31,633][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018200] [Batch 02800/03080] [00:34:53/00:03:29, 0.748s/it]: train_loss_raw=1.4499, running_loss=1.4397, LR=0.000100
[2025-08-27 00:02:37,215][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018208] [Batch 02808/03080] [00:34:58/00:03:23, 0.747s/it]: train_loss_raw=1.4194, running_loss=1.4383, LR=0.000100
[2025-08-27 00:02:43,021][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018216] [Batch 02816/03080] [00:35:04/00:03:17, 0.747s/it]: train_loss_raw=1.4453, running_loss=1.4388, LR=0.000100
[2025-08-27 00:02:48,653][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018224] [Batch 02824/03080] [00:35:10/00:03:11, 0.747s/it]: train_loss_raw=1.4846, running_loss=1.4411, LR=0.000100
[2025-08-27 00:02:54,402][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018232] [Batch 02832/03080] [00:35:15/00:03:05, 0.747s/it]: train_loss_raw=1.4290, running_loss=1.4430, LR=0.000100
[2025-08-27 00:03:00,102][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018240] [Batch 02840/03080] [00:35:21/00:02:59, 0.747s/it]: train_loss_raw=1.4712, running_loss=1.4416, LR=0.000100
[2025-08-27 00:03:05,891][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018248] [Batch 02848/03080] [00:35:27/00:02:53, 0.747s/it]: train_loss_raw=1.5457, running_loss=1.4429, LR=0.000100
[2025-08-27 00:03:11,648][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018256] [Batch 02856/03080] [00:35:33/00:02:47, 0.747s/it]: train_loss_raw=1.3255, running_loss=1.4424, LR=0.000100
[2025-08-27 00:03:17,356][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018264] [Batch 02864/03080] [00:35:38/00:02:41, 0.747s/it]: train_loss_raw=1.4064, running_loss=1.4431, LR=0.000100
[2025-08-27 00:03:23,201][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018272] [Batch 02872/03080] [00:35:44/00:02:35, 0.747s/it]: train_loss_raw=1.4096, running_loss=1.4410, LR=0.000100
[2025-08-27 00:03:29,119][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018280] [Batch 02880/03080] [00:35:50/00:02:29, 0.747s/it]: train_loss_raw=1.4864, running_loss=1.4419, LR=0.000100
[2025-08-27 00:03:35,110][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018288] [Batch 02888/03080] [00:35:56/00:02:23, 0.747s/it]: train_loss_raw=1.5434, running_loss=1.4437, LR=0.000100
[2025-08-27 00:03:41,148][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018296] [Batch 02896/03080] [00:36:02/00:02:17, 0.747s/it]: train_loss_raw=1.4293, running_loss=1.4450, LR=0.000100
[2025-08-27 00:03:47,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018304] [Batch 02904/03080] [00:36:08/00:02:11, 0.747s/it]: train_loss_raw=1.4315, running_loss=1.4459, LR=0.000100
[2025-08-27 00:03:53,061][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018312] [Batch 02912/03080] [00:36:14/00:02:05, 0.747s/it]: train_loss_raw=1.4806, running_loss=1.4440, LR=0.000100
[2025-08-27 00:03:58,833][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018320] [Batch 02920/03080] [00:36:20/00:01:59, 0.747s/it]: train_loss_raw=1.4025, running_loss=1.4435, LR=0.000100
[2025-08-27 00:04:04,723][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018328] [Batch 02928/03080] [00:36:26/00:01:53, 0.747s/it]: train_loss_raw=1.4149, running_loss=1.4457, LR=0.000100
[2025-08-27 00:04:10,848][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018336] [Batch 02936/03080] [00:36:32/00:01:47, 0.747s/it]: train_loss_raw=1.4583, running_loss=1.4438, LR=0.000100
[2025-08-27 00:04:16,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018344] [Batch 02944/03080] [00:36:38/00:01:41, 0.747s/it]: train_loss_raw=1.3273, running_loss=1.4432, LR=0.000100
[2025-08-27 00:04:22,845][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018352] [Batch 02952/03080] [00:36:44/00:01:35, 0.747s/it]: train_loss_raw=1.4243, running_loss=1.4432, LR=0.000100
[2025-08-27 00:04:28,878][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018360] [Batch 02960/03080] [00:36:50/00:01:29, 0.747s/it]: train_loss_raw=1.3759, running_loss=1.4374, LR=0.000100
[2025-08-27 00:04:35,061][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018368] [Batch 02968/03080] [00:36:56/00:01:23, 0.747s/it]: train_loss_raw=1.4639, running_loss=1.4381, LR=0.000100
[2025-08-27 00:04:41,047][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018376] [Batch 02976/03080] [00:37:02/00:01:17, 0.747s/it]: train_loss_raw=1.5011, running_loss=1.4379, LR=0.000100
[2025-08-27 00:04:46,874][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018384] [Batch 02984/03080] [00:37:08/00:01:11, 0.747s/it]: train_loss_raw=1.4659, running_loss=1.4395, LR=0.000100
[2025-08-27 00:04:52,700][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018392] [Batch 02992/03080] [00:37:14/00:01:05, 0.747s/it]: train_loss_raw=1.4573, running_loss=1.4405, LR=0.000100
[2025-08-27 00:04:58,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018400] [Batch 03000/03080] [00:37:19/00:00:59, 0.747s/it]: train_loss_raw=1.5201, running_loss=1.4426, LR=0.000100
[2025-08-27 00:05:04,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018408] [Batch 03008/03080] [00:37:26/00:00:53, 0.747s/it]: train_loss_raw=1.3940, running_loss=1.4449, LR=0.000100
[2025-08-27 00:05:11,008][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018416] [Batch 03016/03080] [00:37:32/00:00:47, 0.747s/it]: train_loss_raw=1.5132, running_loss=1.4451, LR=0.000100
[2025-08-27 00:05:17,553][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018424] [Batch 03024/03080] [00:37:39/00:00:41, 0.747s/it]: train_loss_raw=1.4201, running_loss=1.4454, LR=0.000100
[2025-08-27 00:05:23,995][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018432] [Batch 03032/03080] [00:37:45/00:00:35, 0.747s/it]: train_loss_raw=1.4524, running_loss=1.4438, LR=0.000100
[2025-08-27 00:05:30,187][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018440] [Batch 03040/03080] [00:37:51/00:00:29, 0.747s/it]: train_loss_raw=1.4435, running_loss=1.4438, LR=0.000100
[2025-08-27 00:05:36,158][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018448] [Batch 03048/03080] [00:37:57/00:00:23, 0.747s/it]: train_loss_raw=1.3618, running_loss=1.4411, LR=0.000100
[2025-08-27 00:05:42,230][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018456] [Batch 03056/03080] [00:38:03/00:00:17, 0.747s/it]: train_loss_raw=1.4411, running_loss=1.4404, LR=0.000100
[2025-08-27 00:05:48,337][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018464] [Batch 03064/03080] [00:38:09/00:00:11, 0.747s/it]: train_loss_raw=1.4537, running_loss=1.4423, LR=0.000100
[2025-08-27 00:05:54,315][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018472] [Batch 03072/03080] [00:38:15/00:00:05, 0.747s/it]: train_loss_raw=1.4054, running_loss=1.4440, LR=0.000100
[2025-08-27 00:06:04,761][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018480] [Batch 03080/03080] [00:38:26/00:00:00, 0.749s/it]: train_loss_raw=1.4602, running_loss=1.4453, LR=0.000100
[2025-08-27 00:06:05,266][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-27 00:06:17,292][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00007/00310] [00:00:12/00:07:33, 1.503s/it]
[2025-08-27 00:06:29,940][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00015/00310] [00:00:24/00:07:33, 1.542s/it]
[2025-08-27 00:06:42,739][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00023/00310] [00:00:37/00:07:26, 1.561s/it]
[2025-08-27 00:06:55,541][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00031/00310] [00:00:50/00:07:16, 1.571s/it]
[2025-08-27 00:07:08,059][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00039/00310] [00:01:02/00:07:03, 1.570s/it]
[2025-08-27 00:07:20,783][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00047/00310] [00:01:15/00:06:52, 1.573s/it]
[2025-08-27 00:07:33,673][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00055/00310] [00:01:28/00:06:40, 1.579s/it]
[2025-08-27 00:07:46,004][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00063/00310] [00:01:40/00:06:27, 1.574s/it]
[2025-08-27 00:07:58,507][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00071/00310] [00:01:53/00:06:14, 1.573s/it]
[2025-08-27 00:08:11,442][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00079/00310] [00:02:06/00:06:02, 1.577s/it]
[2025-08-27 00:08:24,003][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00087/00310] [00:02:18/00:05:49, 1.577s/it]
[2025-08-27 00:08:36,526][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00095/00310] [00:02:31/00:05:37, 1.576s/it]
[2025-08-27 00:08:49,043][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00103/00310] [00:02:43/00:05:24, 1.575s/it]
[2025-08-27 00:09:01,344][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00111/00310] [00:02:56/00:05:11, 1.572s/it]
[2025-08-27 00:09:14,479][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00119/00310] [00:03:09/00:04:59, 1.577s/it]
[2025-08-27 00:09:27,622][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00127/00310] [00:03:22/00:04:47, 1.581s/it]
[2025-08-27 00:09:40,035][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00135/00310] [00:03:34/00:04:34, 1.579s/it]
[2025-08-27 00:09:52,658][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00143/00310] [00:03:47/00:04:22, 1.579s/it]
[2025-08-27 00:10:04,714][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00151/00310] [00:03:59/00:04:08, 1.575s/it]
[2025-08-27 00:10:16,076][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00159/00310] [00:04:10/00:03:55, 1.568s/it]
[2025-08-27 00:10:28,544][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00167/00310] [00:04:23/00:03:42, 1.567s/it]
[2025-08-27 00:10:40,101][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00175/00310] [00:04:34/00:03:29, 1.562s/it]
[2025-08-27 00:10:51,489][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00183/00310] [00:04:46/00:03:16, 1.556s/it]
[2025-08-27 00:11:03,039][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00191/00310] [00:04:57/00:03:03, 1.551s/it]
[2025-08-27 00:11:14,814][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00199/00310] [00:05:09/00:02:50, 1.548s/it]
[2025-08-27 00:11:25,935][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00207/00310] [00:05:20/00:02:37, 1.542s/it]
[2025-08-27 00:11:37,805][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00215/00310] [00:05:32/00:02:24, 1.540s/it]
[2025-08-27 00:11:50,163][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00223/00310] [00:05:44/00:02:12, 1.540s/it]
[2025-08-27 00:12:02,331][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00231/00310] [00:05:57/00:02:00, 1.539s/it]
[2025-08-27 00:12:14,667][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00239/00310] [00:06:09/00:01:47, 1.539s/it]
[2025-08-27 00:12:26,567][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00247/00310] [00:06:21/00:01:35, 1.538s/it]
[2025-08-27 00:12:38,781][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00255/00310] [00:06:33/00:01:23, 1.537s/it]
[2025-08-27 00:12:50,773][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00263/00310] [00:06:45/00:01:10, 1.536s/it]
[2025-08-27 00:13:02,672][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00271/00310] [00:06:57/00:00:58, 1.535s/it]
[2025-08-27 00:13:14,929][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00279/00310] [00:07:09/00:00:46, 1.535s/it]
[2025-08-27 00:13:27,800][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00287/00310] [00:07:22/00:00:33, 1.537s/it]
[2025-08-27 00:13:39,520][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00295/00310] [00:07:34/00:00:21, 1.535s/it]
[2025-08-27 00:13:52,092][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00303/00310] [00:07:46/00:00:09, 1.536s/it]
[2025-08-27 00:14:01,219][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.44532, valid_loss=2.09892
[2025-08-27 00:14:01,219][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-27 00:14:01,220][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.788
[2025-08-27 00:14:01,220][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.025
[2025-08-27 00:14:01,220][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.027
[2025-08-27 00:14:01,220][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.004
[2025-08-27 00:14:01,234][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 04:47:15, remaining time 19:09:00, 00:47:52 per epoch
[2025-08-27 00:14:06,889][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018488] [Batch 00008/03080] [00:00:05/00:34:42, 0.678s/it]: train_loss_raw=1.3860, running_loss=1.4180, LR=0.000100
[2025-08-27 00:14:12,820][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018496] [Batch 00016/03080] [00:00:11/00:36:14, 0.710s/it]: train_loss_raw=1.4064, running_loss=1.4189, LR=0.000100
[2025-08-27 00:14:18,807][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018504] [Batch 00024/03080] [00:00:17/00:36:48, 0.723s/it]: train_loss_raw=1.4190, running_loss=1.4193, LR=0.000100
[2025-08-27 00:14:24,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018512] [Batch 00032/03080] [00:00:23/00:36:52, 0.726s/it]: train_loss_raw=1.3452, running_loss=1.4180, LR=0.000100
[2025-08-27 00:14:30,617][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018520] [Batch 00040/03080] [00:00:29/00:36:55, 0.729s/it]: train_loss_raw=1.4274, running_loss=1.4156, LR=0.000100
[2025-08-27 00:14:36,247][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018528] [Batch 00048/03080] [00:00:34/00:36:37, 0.725s/it]: train_loss_raw=1.3407, running_loss=1.4146, LR=0.000100
[2025-08-27 00:14:41,919][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018536] [Batch 00056/03080] [00:00:40/00:36:24, 0.722s/it]: train_loss_raw=1.3951, running_loss=1.4155, LR=0.000100
[2025-08-27 00:14:47,810][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018544] [Batch 00064/03080] [00:00:46/00:36:23, 0.724s/it]: train_loss_raw=1.4115, running_loss=1.4152, LR=0.000100
[2025-08-27 00:14:53,825][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018552] [Batch 00072/03080] [00:00:52/00:36:27, 0.727s/it]: train_loss_raw=1.4162, running_loss=1.4137, LR=0.000100
[2025-08-27 00:14:59,514][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018560] [Batch 00080/03080] [00:00:58/00:36:16, 0.726s/it]: train_loss_raw=1.4821, running_loss=1.4125, LR=0.000100
[2025-08-27 00:15:05,395][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018568] [Batch 00088/03080] [00:01:03/00:36:13, 0.726s/it]: train_loss_raw=1.3618, running_loss=1.4109, LR=0.000100
[2025-08-27 00:15:10,967][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018576] [Batch 00096/03080] [00:01:09/00:36:00, 0.724s/it]: train_loss_raw=1.3654, running_loss=1.4090, LR=0.000100
[2025-08-27 00:15:16,713][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018584] [Batch 00104/03080] [00:01:15/00:35:53, 0.724s/it]: train_loss_raw=1.4029, running_loss=1.4100, LR=0.000100
[2025-08-27 00:15:22,566][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018592] [Batch 00112/03080] [00:01:21/00:35:49, 0.724s/it]: train_loss_raw=1.5191, running_loss=1.4110, LR=0.000100
[2025-08-27 00:15:28,341][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018600] [Batch 00120/03080] [00:01:26/00:35:42, 0.724s/it]: train_loss_raw=1.5619, running_loss=1.4118, LR=0.000100
[2025-08-27 00:15:34,229][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018608] [Batch 00128/03080] [00:01:32/00:35:39, 0.725s/it]: train_loss_raw=1.3483, running_loss=1.4120, LR=0.000100
[2025-08-27 00:15:39,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018616] [Batch 00136/03080] [00:01:38/00:35:29, 0.723s/it]: train_loss_raw=1.3691, running_loss=1.4099, LR=0.000100
[2025-08-27 00:15:45,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018624] [Batch 00144/03080] [00:01:44/00:35:23, 0.723s/it]: train_loss_raw=1.3319, running_loss=1.4113, LR=0.000100
[2025-08-27 00:15:51,472][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018632] [Batch 00152/03080] [00:01:50/00:35:19, 0.724s/it]: train_loss_raw=1.3231, running_loss=1.4100, LR=0.000100
[2025-08-27 00:15:57,283][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018640] [Batch 00160/03080] [00:01:55/00:35:13, 0.724s/it]: train_loss_raw=1.4504, running_loss=1.4107, LR=0.000100
[2025-08-27 00:16:03,128][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018648] [Batch 00168/03080] [00:02:01/00:35:08, 0.724s/it]: train_loss_raw=1.4118, running_loss=1.4085, LR=0.000100
[2025-08-27 00:16:09,031][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018656] [Batch 00176/03080] [00:02:07/00:35:04, 0.725s/it]: train_loss_raw=1.5229, running_loss=1.4067, LR=0.000100
[2025-08-27 00:16:14,815][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018664] [Batch 00184/03080] [00:02:13/00:34:58, 0.725s/it]: train_loss_raw=1.4247, running_loss=1.4058, LR=0.000100
[2025-08-27 00:16:20,573][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018672] [Batch 00192/03080] [00:02:19/00:34:52, 0.725s/it]: train_loss_raw=1.4627, running_loss=1.4068, LR=0.000100
[2025-08-27 00:16:26,599][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018680] [Batch 00200/03080] [00:02:25/00:34:49, 0.726s/it]: train_loss_raw=1.4144, running_loss=1.4106, LR=0.000100
[2025-08-27 00:16:32,591][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018688] [Batch 00208/03080] [00:02:31/00:34:46, 0.727s/it]: train_loss_raw=1.3833, running_loss=1.4086, LR=0.000100
[2025-08-27 00:16:38,515][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018696] [Batch 00216/03080] [00:02:37/00:34:42, 0.727s/it]: train_loss_raw=1.3605, running_loss=1.4113, LR=0.000100
[2025-08-27 00:16:44,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018704] [Batch 00224/03080] [00:02:42/00:34:36, 0.727s/it]: train_loss_raw=1.3544, running_loss=1.4096, LR=0.000100
[2025-08-27 00:16:50,298][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018712] [Batch 00232/03080] [00:02:48/00:34:32, 0.728s/it]: train_loss_raw=1.5006, running_loss=1.4088, LR=0.000100
[2025-08-27 00:16:56,270][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018720] [Batch 00240/03080] [00:02:54/00:34:28, 0.728s/it]: train_loss_raw=1.2869, running_loss=1.4071, LR=0.000100
[2025-08-27 00:17:02,264][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018728] [Batch 00248/03080] [00:03:00/00:34:24, 0.729s/it]: train_loss_raw=1.4552, running_loss=1.4085, LR=0.000100
[2025-08-27 00:17:08,370][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018736] [Batch 00256/03080] [00:03:06/00:34:21, 0.730s/it]: train_loss_raw=1.3763, running_loss=1.4082, LR=0.000100
[2025-08-27 00:17:14,321][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018744] [Batch 00264/03080] [00:03:12/00:34:17, 0.731s/it]: train_loss_raw=1.3723, running_loss=1.4061, LR=0.000100
[2025-08-27 00:17:20,215][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018752] [Batch 00272/03080] [00:03:18/00:34:11, 0.731s/it]: train_loss_raw=1.5138, running_loss=1.4101, LR=0.000100
[2025-08-27 00:17:26,007][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018760] [Batch 00280/03080] [00:03:24/00:34:05, 0.731s/it]: train_loss_raw=1.4737, running_loss=1.4095, LR=0.000100
[2025-08-27 00:17:31,654][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018768] [Batch 00288/03080] [00:03:30/00:33:57, 0.730s/it]: train_loss_raw=1.2994, running_loss=1.4057, LR=0.000100
[2025-08-27 00:17:37,419][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018776] [Batch 00296/03080] [00:03:35/00:33:51, 0.730s/it]: train_loss_raw=1.3964, running_loss=1.4074, LR=0.000100
[2025-08-27 00:17:43,412][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018784] [Batch 00304/03080] [00:03:41/00:33:46, 0.730s/it]: train_loss_raw=1.4534, running_loss=1.4060, LR=0.000100
[2025-08-27 00:17:49,373][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018792] [Batch 00312/03080] [00:03:47/00:33:41, 0.730s/it]: train_loss_raw=1.4114, running_loss=1.4088, LR=0.000100
[2025-08-27 00:17:55,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018800] [Batch 00320/03080] [00:03:53/00:33:36, 0.731s/it]: train_loss_raw=1.4831, running_loss=1.4081, LR=0.000100
[2025-08-27 00:18:01,013][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018808] [Batch 00328/03080] [00:03:59/00:33:29, 0.730s/it]: train_loss_raw=1.3172, running_loss=1.4058, LR=0.000100
[2025-08-27 00:18:06,801][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018816] [Batch 00336/03080] [00:04:05/00:33:23, 0.730s/it]: train_loss_raw=1.4210, running_loss=1.4069, LR=0.000100
[2025-08-27 00:18:12,514][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018824] [Batch 00344/03080] [00:04:11/00:33:16, 0.730s/it]: train_loss_raw=1.3652, running_loss=1.4044, LR=0.000100
[2025-08-27 00:18:18,218][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018832] [Batch 00352/03080] [00:04:16/00:33:09, 0.729s/it]: train_loss_raw=1.4283, running_loss=1.4074, LR=0.000100
[2025-08-27 00:18:23,809][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018840] [Batch 00360/03080] [00:04:22/00:33:02, 0.729s/it]: train_loss_raw=1.4569, running_loss=1.4070, LR=0.000100
[2025-08-27 00:18:29,615][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018848] [Batch 00368/03080] [00:04:28/00:32:56, 0.729s/it]: train_loss_raw=1.3411, running_loss=1.4055, LR=0.000100
[2025-08-27 00:18:35,427][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018856] [Batch 00376/03080] [00:04:33/00:32:50, 0.729s/it]: train_loss_raw=1.4090, running_loss=1.4033, LR=0.000100
[2025-08-27 00:18:41,306][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018864] [Batch 00384/03080] [00:04:39/00:32:44, 0.729s/it]: train_loss_raw=1.4590, running_loss=1.4028, LR=0.000100
[2025-08-27 00:18:46,991][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018872] [Batch 00392/03080] [00:04:45/00:32:37, 0.728s/it]: train_loss_raw=1.4157, running_loss=1.4021, LR=0.000100
[2025-08-27 00:18:52,963][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018880] [Batch 00400/03080] [00:04:51/00:32:33, 0.729s/it]: train_loss_raw=1.3900, running_loss=1.4028, LR=0.000100
[2025-08-27 00:18:58,854][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018888] [Batch 00408/03080] [00:04:57/00:32:27, 0.729s/it]: train_loss_raw=1.3935, running_loss=1.4050, LR=0.000100
[2025-08-27 00:19:04,869][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018896] [Batch 00416/03080] [00:05:03/00:32:22, 0.729s/it]: train_loss_raw=1.3556, running_loss=1.4029, LR=0.000100
[2025-08-27 00:19:10,919][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018904] [Batch 00424/03080] [00:05:09/00:32:18, 0.730s/it]: train_loss_raw=1.4178, running_loss=1.4053, LR=0.000100
[2025-08-27 00:19:16,848][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018912] [Batch 00432/03080] [00:05:15/00:32:13, 0.730s/it]: train_loss_raw=1.3585, running_loss=1.4036, LR=0.000100
[2025-08-27 00:19:22,661][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018920] [Batch 00440/03080] [00:05:21/00:32:07, 0.730s/it]: train_loss_raw=1.3918, running_loss=1.4026, LR=0.000100
[2025-08-27 00:19:28,452][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018928] [Batch 00448/03080] [00:05:26/00:32:01, 0.730s/it]: train_loss_raw=1.4608, running_loss=1.4045, LR=0.000100
[2025-08-27 00:19:34,248][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018936] [Batch 00456/03080] [00:05:32/00:31:54, 0.730s/it]: train_loss_raw=1.3811, running_loss=1.4050, LR=0.000100
[2025-08-27 00:19:40,347][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018944] [Batch 00464/03080] [00:05:38/00:31:50, 0.730s/it]: train_loss_raw=1.5565, running_loss=1.4059, LR=0.000100
[2025-08-27 00:19:46,246][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018952] [Batch 00472/03080] [00:05:44/00:31:45, 0.730s/it]: train_loss_raw=1.5029, running_loss=1.4055, LR=0.000100
[2025-08-27 00:19:51,992][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018960] [Batch 00480/03080] [00:05:50/00:31:38, 0.730s/it]: train_loss_raw=1.4270, running_loss=1.4069, LR=0.000100
[2025-08-27 00:19:58,010][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018968] [Batch 00488/03080] [00:05:56/00:31:33, 0.731s/it]: train_loss_raw=1.4367, running_loss=1.4090, LR=0.000100
[2025-08-27 00:20:03,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018976] [Batch 00496/03080] [00:06:02/00:31:28, 0.731s/it]: train_loss_raw=1.4053, running_loss=1.4088, LR=0.000100
[2025-08-27 00:20:09,599][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018984] [Batch 00504/03080] [00:06:08/00:31:21, 0.730s/it]: train_loss_raw=1.3234, running_loss=1.4095, LR=0.000100
[2025-08-27 00:20:15,378][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018992] [Batch 00512/03080] [00:06:13/00:31:15, 0.730s/it]: train_loss_raw=1.3735, running_loss=1.4090, LR=0.000100
[2025-08-27 00:20:21,275][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019000] [Batch 00520/03080] [00:06:19/00:31:09, 0.730s/it]: train_loss_raw=1.3819, running_loss=1.4092, LR=0.000100
[2025-08-27 00:20:27,140][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019008] [Batch 00528/03080] [00:06:25/00:31:04, 0.730s/it]: train_loss_raw=1.3026, running_loss=1.4063, LR=0.000100
[2025-08-27 00:20:33,165][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019016] [Batch 00536/03080] [00:06:31/00:30:59, 0.731s/it]: train_loss_raw=1.3557, running_loss=1.4065, LR=0.000100
[2025-08-27 00:20:38,983][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019024] [Batch 00544/03080] [00:06:37/00:30:53, 0.731s/it]: train_loss_raw=1.4396, running_loss=1.4066, LR=0.000100
[2025-08-27 00:20:44,947][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019032] [Batch 00552/03080] [00:06:43/00:30:47, 0.731s/it]: train_loss_raw=1.4617, running_loss=1.4076, LR=0.000100
[2025-08-27 00:20:50,792][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019040] [Batch 00560/03080] [00:06:49/00:30:41, 0.731s/it]: train_loss_raw=1.3548, running_loss=1.4075, LR=0.000100
[2025-08-27 00:20:56,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019048] [Batch 00568/03080] [00:06:55/00:30:36, 0.731s/it]: train_loss_raw=1.4377, running_loss=1.4057, LR=0.000100
[2025-08-27 00:21:03,076][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019056] [Batch 00576/03080] [00:07:01/00:30:32, 0.732s/it]: train_loss_raw=1.2653, running_loss=1.3994, LR=0.000100
[2025-08-27 00:21:09,130][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019064] [Batch 00584/03080] [00:07:07/00:30:27, 0.732s/it]: train_loss_raw=1.3322, running_loss=1.3998, LR=0.000100
[2025-08-27 00:21:15,233][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019072] [Batch 00592/03080] [00:07:13/00:30:22, 0.733s/it]: train_loss_raw=1.3678, running_loss=1.3982, LR=0.000100
[2025-08-27 00:21:21,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019080] [Batch 00600/03080] [00:07:19/00:30:18, 0.733s/it]: train_loss_raw=1.3805, running_loss=1.3990, LR=0.000100
[2025-08-27 00:21:27,119][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019088] [Batch 00608/03080] [00:07:25/00:30:11, 0.733s/it]: train_loss_raw=1.4119, running_loss=1.3995, LR=0.000100
[2025-08-27 00:21:32,996][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019096] [Batch 00616/03080] [00:07:31/00:30:06, 0.733s/it]: train_loss_raw=1.5037, running_loss=1.4025, LR=0.000100
[2025-08-27 00:21:38,863][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019104] [Batch 00624/03080] [00:07:37/00:30:00, 0.733s/it]: train_loss_raw=1.4056, running_loss=1.4019, LR=0.000100
[2025-08-27 00:21:44,677][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019112] [Batch 00632/03080] [00:07:43/00:29:54, 0.733s/it]: train_loss_raw=1.3968, running_loss=1.4060, LR=0.000100
[2025-08-27 00:21:50,840][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019120] [Batch 00640/03080] [00:07:49/00:29:49, 0.733s/it]: train_loss_raw=1.3417, running_loss=1.4052, LR=0.000100
[2025-08-27 00:21:56,711][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019128] [Batch 00648/03080] [00:07:55/00:29:43, 0.733s/it]: train_loss_raw=1.4072, running_loss=1.4044, LR=0.000100
[2025-08-27 00:22:02,802][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019136] [Batch 00656/03080] [00:08:01/00:29:38, 0.734s/it]: train_loss_raw=1.4050, running_loss=1.4072, LR=0.000100
[2025-08-27 00:22:08,746][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019144] [Batch 00664/03080] [00:08:07/00:29:32, 0.734s/it]: train_loss_raw=1.3424, running_loss=1.4071, LR=0.000100
[2025-08-27 00:22:14,697][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019152] [Batch 00672/03080] [00:08:13/00:29:27, 0.734s/it]: train_loss_raw=1.3718, running_loss=1.4056, LR=0.000100
[2025-08-27 00:22:20,707][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019160] [Batch 00680/03080] [00:08:19/00:29:22, 0.734s/it]: train_loss_raw=1.3842, running_loss=1.4062, LR=0.000100
[2025-08-27 00:22:26,608][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019168] [Batch 00688/03080] [00:08:25/00:29:16, 0.734s/it]: train_loss_raw=1.3707, running_loss=1.4061, LR=0.000100
[2025-08-27 00:22:32,252][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019176] [Batch 00696/03080] [00:08:30/00:29:09, 0.734s/it]: train_loss_raw=1.3553, running_loss=1.4030, LR=0.000100
[2025-08-27 00:22:38,002][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019184] [Batch 00704/03080] [00:08:36/00:29:03, 0.734s/it]: train_loss_raw=1.4641, running_loss=1.4015, LR=0.000100
[2025-08-27 00:22:43,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019192] [Batch 00712/03080] [00:08:42/00:28:56, 0.734s/it]: train_loss_raw=1.3294, running_loss=1.4002, LR=0.000100
[2025-08-27 00:22:49,383][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019200] [Batch 00720/03080] [00:08:47/00:28:50, 0.733s/it]: train_loss_raw=1.3197, running_loss=1.3980, LR=0.000100
[2025-08-27 00:22:55,472][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019208] [Batch 00728/03080] [00:08:54/00:28:45, 0.734s/it]: train_loss_raw=1.3962, running_loss=1.3930, LR=0.000100
[2025-08-27 00:23:01,589][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019216] [Batch 00736/03080] [00:09:00/00:28:40, 0.734s/it]: train_loss_raw=1.4241, running_loss=1.3942, LR=0.000100
[2025-08-27 00:23:07,628][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019224] [Batch 00744/03080] [00:09:06/00:28:34, 0.734s/it]: train_loss_raw=1.4656, running_loss=1.3952, LR=0.000100
[2025-08-27 00:23:13,487][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019232] [Batch 00752/03080] [00:09:12/00:28:28, 0.734s/it]: train_loss_raw=1.3253, running_loss=1.3933, LR=0.000100
[2025-08-27 00:23:19,466][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019240] [Batch 00760/03080] [00:09:18/00:28:23, 0.734s/it]: train_loss_raw=1.5031, running_loss=1.3934, LR=0.000100
[2025-08-27 00:23:25,377][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019248] [Batch 00768/03080] [00:09:23/00:28:17, 0.734s/it]: train_loss_raw=1.3494, running_loss=1.3934, LR=0.000100
[2025-08-27 00:23:31,155][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019256] [Batch 00776/03080] [00:09:29/00:28:11, 0.734s/it]: train_loss_raw=1.3640, running_loss=1.3923, LR=0.000100
[2025-08-27 00:23:36,729][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019264] [Batch 00784/03080] [00:09:35/00:28:04, 0.734s/it]: train_loss_raw=1.3791, running_loss=1.3916, LR=0.000100
[2025-08-27 00:23:42,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019272] [Batch 00792/03080] [00:09:41/00:27:59, 0.734s/it]: train_loss_raw=1.4186, running_loss=1.3921, LR=0.000100
[2025-08-27 00:23:48,812][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019280] [Batch 00800/03080] [00:09:47/00:27:53, 0.734s/it]: train_loss_raw=1.4204, running_loss=1.3921, LR=0.000100
[2025-08-27 00:23:54,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019288] [Batch 00808/03080] [00:09:53/00:27:48, 0.734s/it]: train_loss_raw=1.3284, running_loss=1.3933, LR=0.000100
[2025-08-27 00:24:00,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019296] [Batch 00816/03080] [00:09:58/00:27:41, 0.734s/it]: train_loss_raw=1.4152, running_loss=1.3940, LR=0.000100
[2025-08-27 00:24:06,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019304] [Batch 00824/03080] [00:10:04/00:27:35, 0.734s/it]: train_loss_raw=1.4154, running_loss=1.3947, LR=0.000100
[2025-08-27 00:24:12,275][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019312] [Batch 00832/03080] [00:10:10/00:27:30, 0.734s/it]: train_loss_raw=1.4206, running_loss=1.3934, LR=0.000100
[2025-08-27 00:24:18,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019320] [Batch 00840/03080] [00:10:16/00:27:24, 0.734s/it]: train_loss_raw=1.3938, running_loss=1.3953, LR=0.000100
[2025-08-27 00:24:23,878][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019328] [Batch 00848/03080] [00:10:22/00:27:18, 0.734s/it]: train_loss_raw=1.2568, running_loss=1.3916, LR=0.000100
[2025-08-27 00:24:29,671][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019336] [Batch 00856/03080] [00:10:28/00:27:12, 0.734s/it]: train_loss_raw=1.3785, running_loss=1.3904, LR=0.000100
[2025-08-27 00:24:35,577][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019344] [Batch 00864/03080] [00:10:34/00:27:06, 0.734s/it]: train_loss_raw=1.3109, running_loss=1.3917, LR=0.000100
[2025-08-27 00:24:41,473][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019352] [Batch 00872/03080] [00:10:40/00:27:00, 0.734s/it]: train_loss_raw=1.2930, running_loss=1.3939, LR=0.000100
[2025-08-27 00:24:47,312][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019360] [Batch 00880/03080] [00:10:45/00:26:54, 0.734s/it]: train_loss_raw=1.3722, running_loss=1.3915, LR=0.000100
[2025-08-27 00:24:53,169][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019368] [Batch 00888/03080] [00:10:51/00:26:48, 0.734s/it]: train_loss_raw=1.3321, running_loss=1.3899, LR=0.000100
[2025-08-27 00:24:58,999][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019376] [Batch 00896/03080] [00:10:57/00:26:42, 0.734s/it]: train_loss_raw=1.3807, running_loss=1.3897, LR=0.000100
[2025-08-27 00:25:04,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019384] [Batch 00904/03080] [00:11:03/00:26:37, 0.734s/it]: train_loss_raw=1.2367, running_loss=1.3866, LR=0.000100
[2025-08-27 00:25:10,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019392] [Batch 00912/03080] [00:11:09/00:26:31, 0.734s/it]: train_loss_raw=1.2870, running_loss=1.3875, LR=0.000100
[2025-08-27 00:25:16,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019400] [Batch 00920/03080] [00:11:15/00:26:25, 0.734s/it]: train_loss_raw=1.3923, running_loss=1.3899, LR=0.000100
[2025-08-27 00:25:22,512][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019408] [Batch 00928/03080] [00:11:21/00:26:19, 0.734s/it]: train_loss_raw=1.4750, running_loss=1.3895, LR=0.000100
[2025-08-27 00:25:28,221][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019416] [Batch 00936/03080] [00:11:26/00:26:13, 0.734s/it]: train_loss_raw=1.3523, running_loss=1.3894, LR=0.000100
[2025-08-27 00:25:33,969][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019424] [Batch 00944/03080] [00:11:32/00:26:06, 0.734s/it]: train_loss_raw=1.4353, running_loss=1.3898, LR=0.000100
[2025-08-27 00:25:39,589][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019432] [Batch 00952/03080] [00:11:38/00:26:00, 0.733s/it]: train_loss_raw=1.3278, running_loss=1.3897, LR=0.000100
[2025-08-27 00:25:45,217][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019440] [Batch 00960/03080] [00:11:43/00:25:54, 0.733s/it]: train_loss_raw=1.3011, running_loss=1.3871, LR=0.000100
[2025-08-27 00:25:51,253][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019448] [Batch 00968/03080] [00:11:49/00:25:48, 0.733s/it]: train_loss_raw=1.4543, running_loss=1.3883, LR=0.000100
[2025-08-27 00:25:57,139][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019456] [Batch 00976/03080] [00:11:55/00:25:42, 0.733s/it]: train_loss_raw=1.3919, running_loss=1.3894, LR=0.000100
[2025-08-27 00:26:03,075][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019464] [Batch 00984/03080] [00:12:01/00:25:37, 0.733s/it]: train_loss_raw=1.4223, running_loss=1.3903, LR=0.000100
[2025-08-27 00:26:09,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019472] [Batch 00992/03080] [00:12:07/00:25:31, 0.733s/it]: train_loss_raw=1.4170, running_loss=1.3898, LR=0.000100
[2025-08-27 00:26:14,800][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019480] [Batch 01000/03080] [00:12:13/00:25:25, 0.733s/it]: train_loss_raw=1.4499, running_loss=1.3873, LR=0.000100
[2025-08-27 00:26:20,816][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019488] [Batch 01008/03080] [00:12:19/00:25:19, 0.733s/it]: train_loss_raw=1.4752, running_loss=1.3884, LR=0.000100
[2025-08-27 00:26:26,438][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019496] [Batch 01016/03080] [00:12:24/00:25:13, 0.733s/it]: train_loss_raw=1.4447, running_loss=1.3898, LR=0.000100
[2025-08-27 00:26:32,216][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019504] [Batch 01024/03080] [00:12:30/00:25:07, 0.733s/it]: train_loss_raw=1.4004, running_loss=1.3916, LR=0.000100
[2025-08-27 00:26:38,127][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019512] [Batch 01032/03080] [00:12:36/00:25:01, 0.733s/it]: train_loss_raw=1.4419, running_loss=1.3922, LR=0.000100
[2025-08-27 00:26:44,141][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019520] [Batch 01040/03080] [00:12:42/00:24:56, 0.733s/it]: train_loss_raw=1.5091, running_loss=1.3913, LR=0.000100
[2025-08-27 00:26:50,102][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019528] [Batch 01048/03080] [00:12:48/00:24:50, 0.733s/it]: train_loss_raw=1.3660, running_loss=1.3896, LR=0.000100
[2025-08-27 00:26:56,012][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019536] [Batch 01056/03080] [00:12:54/00:24:44, 0.733s/it]: train_loss_raw=1.3880, running_loss=1.3870, LR=0.000100
[2025-08-27 00:27:01,916][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019544] [Batch 01064/03080] [00:13:00/00:24:38, 0.734s/it]: train_loss_raw=1.3514, running_loss=1.3913, LR=0.000100
[2025-08-27 00:27:07,941][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019552] [Batch 01072/03080] [00:13:06/00:24:33, 0.734s/it]: train_loss_raw=1.4552, running_loss=1.3881, LR=0.000100
[2025-08-27 00:27:13,873][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019560] [Batch 01080/03080] [00:13:12/00:24:27, 0.734s/it]: train_loss_raw=1.3614, running_loss=1.3897, LR=0.000100
[2025-08-27 00:27:20,009][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019568] [Batch 01088/03080] [00:13:18/00:24:22, 0.734s/it]: train_loss_raw=1.3800, running_loss=1.3869, LR=0.000100
[2025-08-27 00:27:25,710][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019576] [Batch 01096/03080] [00:13:24/00:24:15, 0.734s/it]: train_loss_raw=1.2943, running_loss=1.3830, LR=0.000100
[2025-08-27 00:27:31,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019584] [Batch 01104/03080] [00:13:30/00:24:10, 0.734s/it]: train_loss_raw=1.4221, running_loss=1.3816, LR=0.000100
[2025-08-27 00:27:38,108][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019592] [Batch 01112/03080] [00:13:36/00:24:05, 0.734s/it]: train_loss_raw=1.4025, running_loss=1.3831, LR=0.000100
[2025-08-27 00:27:43,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019600] [Batch 01120/03080] [00:13:42/00:23:59, 0.734s/it]: train_loss_raw=1.3789, running_loss=1.3842, LR=0.000100
[2025-08-27 00:27:49,439][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019608] [Batch 01128/03080] [00:13:47/00:23:52, 0.734s/it]: train_loss_raw=1.3927, running_loss=1.3811, LR=0.000100
[2025-08-27 00:27:55,281][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019616] [Batch 01136/03080] [00:13:53/00:23:46, 0.734s/it]: train_loss_raw=1.2993, running_loss=1.3829, LR=0.000100
[2025-08-27 00:28:00,988][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019624] [Batch 01144/03080] [00:13:59/00:23:40, 0.734s/it]: train_loss_raw=1.3864, running_loss=1.3843, LR=0.000100
[2025-08-27 00:28:07,087][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019632] [Batch 01152/03080] [00:14:05/00:23:35, 0.734s/it]: train_loss_raw=1.3327, running_loss=1.3858, LR=0.000100
[2025-08-27 00:28:12,788][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019640] [Batch 01160/03080] [00:14:11/00:23:29, 0.734s/it]: train_loss_raw=1.3876, running_loss=1.3863, LR=0.000100
[2025-08-27 00:28:18,580][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019648] [Batch 01168/03080] [00:14:17/00:23:23, 0.734s/it]: train_loss_raw=1.3603, running_loss=1.3887, LR=0.000100
[2025-08-27 00:28:24,632][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019656] [Batch 01176/03080] [00:14:23/00:23:17, 0.734s/it]: train_loss_raw=1.3822, running_loss=1.3873, LR=0.000100
[2025-08-27 00:28:30,818][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019664] [Batch 01184/03080] [00:14:29/00:23:12, 0.734s/it]: train_loss_raw=1.3986, running_loss=1.3859, LR=0.000100
[2025-08-27 00:28:36,823][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019672] [Batch 01192/03080] [00:14:35/00:23:06, 0.734s/it]: train_loss_raw=1.2542, running_loss=1.3850, LR=0.000100
[2025-08-27 00:28:42,745][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019680] [Batch 01200/03080] [00:14:41/00:23:00, 0.734s/it]: train_loss_raw=1.4307, running_loss=1.3861, LR=0.000100
[2025-08-27 00:28:48,966][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019688] [Batch 01208/03080] [00:14:47/00:22:55, 0.735s/it]: train_loss_raw=1.3535, running_loss=1.3865, LR=0.000100
[2025-08-27 00:28:54,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019696] [Batch 01216/03080] [00:14:53/00:22:49, 0.735s/it]: train_loss_raw=1.3851, running_loss=1.3859, LR=0.000100
[2025-08-27 00:29:00,837][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019704] [Batch 01224/03080] [00:14:59/00:22:43, 0.735s/it]: train_loss_raw=1.3774, running_loss=1.3864, LR=0.000100
[2025-08-27 00:29:06,876][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019712] [Batch 01232/03080] [00:15:05/00:22:38, 0.735s/it]: train_loss_raw=1.4263, running_loss=1.3852, LR=0.000100
[2025-08-27 00:29:12,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019720] [Batch 01240/03080] [00:15:11/00:22:32, 0.735s/it]: train_loss_raw=1.3650, running_loss=1.3844, LR=0.000100
[2025-08-27 00:29:18,627][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019728] [Batch 01248/03080] [00:15:17/00:22:26, 0.735s/it]: train_loss_raw=1.3515, running_loss=1.3871, LR=0.000100
[2025-08-27 00:29:24,370][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019736] [Batch 01256/03080] [00:15:22/00:22:20, 0.735s/it]: train_loss_raw=1.5130, running_loss=1.3870, LR=0.000100
[2025-08-27 00:29:30,229][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019744] [Batch 01264/03080] [00:15:28/00:22:14, 0.735s/it]: train_loss_raw=1.4334, running_loss=1.3874, LR=0.000100
[2025-08-27 00:29:36,039][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019752] [Batch 01272/03080] [00:15:34/00:22:08, 0.735s/it]: train_loss_raw=1.3781, running_loss=1.3865, LR=0.000100
[2025-08-27 00:29:41,844][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019760] [Batch 01280/03080] [00:15:40/00:22:02, 0.735s/it]: train_loss_raw=1.4024, running_loss=1.3846, LR=0.000100
[2025-08-27 00:29:47,638][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019768] [Batch 01288/03080] [00:15:46/00:21:56, 0.735s/it]: train_loss_raw=1.2985, running_loss=1.3844, LR=0.000100
[2025-08-27 00:29:53,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019776] [Batch 01296/03080] [00:15:52/00:21:50, 0.735s/it]: train_loss_raw=1.4015, running_loss=1.3825, LR=0.000100
[2025-08-27 00:29:59,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019784] [Batch 01304/03080] [00:15:57/00:21:44, 0.735s/it]: train_loss_raw=1.4015, running_loss=1.3841, LR=0.000100
[2025-08-27 00:30:05,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019792] [Batch 01312/03080] [00:16:03/00:21:38, 0.735s/it]: train_loss_raw=1.4139, running_loss=1.3838, LR=0.000100
[2025-08-27 00:30:10,923][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019800] [Batch 01320/03080] [00:16:09/00:21:32, 0.734s/it]: train_loss_raw=1.4310, running_loss=1.3827, LR=0.000100
[2025-08-27 00:30:16,672][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019808] [Batch 01328/03080] [00:16:15/00:21:26, 0.734s/it]: train_loss_raw=1.2796, running_loss=1.3810, LR=0.000100
[2025-08-27 00:30:22,551][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019816] [Batch 01336/03080] [00:16:21/00:21:20, 0.734s/it]: train_loss_raw=1.2816, running_loss=1.3826, LR=0.000100
[2025-08-27 00:30:28,285][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019824] [Batch 01344/03080] [00:16:26/00:21:14, 0.734s/it]: train_loss_raw=1.4968, running_loss=1.3847, LR=0.000100
[2025-08-27 00:30:34,345][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019832] [Batch 01352/03080] [00:16:32/00:21:09, 0.734s/it]: train_loss_raw=1.2756, running_loss=1.3850, LR=0.000100
[2025-08-27 00:30:40,239][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019840] [Batch 01360/03080] [00:16:38/00:21:03, 0.734s/it]: train_loss_raw=1.3880, running_loss=1.3874, LR=0.000100
[2025-08-27 00:30:45,964][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019848] [Batch 01368/03080] [00:16:44/00:20:57, 0.734s/it]: train_loss_raw=1.3537, running_loss=1.3871, LR=0.000100
[2025-08-27 00:30:51,858][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019856] [Batch 01376/03080] [00:16:50/00:20:51, 0.734s/it]: train_loss_raw=1.3364, running_loss=1.3847, LR=0.000100
[2025-08-27 00:30:57,913][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019864] [Batch 01384/03080] [00:16:56/00:20:45, 0.734s/it]: train_loss_raw=1.3306, running_loss=1.3839, LR=0.000100
[2025-08-27 00:31:03,679][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019872] [Batch 01392/03080] [00:17:02/00:20:39, 0.734s/it]: train_loss_raw=1.2906, running_loss=1.3793, LR=0.000100
[2025-08-27 00:31:09,471][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019880] [Batch 01400/03080] [00:17:08/00:20:33, 0.734s/it]: train_loss_raw=1.3517, running_loss=1.3771, LR=0.000100
[2025-08-27 00:31:15,265][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019888] [Batch 01408/03080] [00:17:13/00:20:27, 0.734s/it]: train_loss_raw=1.4161, running_loss=1.3765, LR=0.000100
[2025-08-27 00:31:21,013][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019896] [Batch 01416/03080] [00:17:19/00:20:21, 0.734s/it]: train_loss_raw=1.3948, running_loss=1.3741, LR=0.000100
[2025-08-27 00:31:26,798][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019904] [Batch 01424/03080] [00:17:25/00:20:15, 0.734s/it]: train_loss_raw=1.3825, running_loss=1.3740, LR=0.000100
[2025-08-27 00:31:32,685][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019912] [Batch 01432/03080] [00:17:31/00:20:09, 0.734s/it]: train_loss_raw=1.3773, running_loss=1.3741, LR=0.000100
[2025-08-27 00:31:38,612][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019920] [Batch 01440/03080] [00:17:37/00:20:03, 0.734s/it]: train_loss_raw=1.4060, running_loss=1.3751, LR=0.000100
[2025-08-27 00:31:44,568][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019928] [Batch 01448/03080] [00:17:43/00:19:58, 0.734s/it]: train_loss_raw=1.3627, running_loss=1.3789, LR=0.000100
[2025-08-27 00:31:50,432][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019936] [Batch 01456/03080] [00:17:48/00:19:52, 0.734s/it]: train_loss_raw=1.3718, running_loss=1.3771, LR=0.000100
[2025-08-27 00:31:56,389][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019944] [Batch 01464/03080] [00:17:54/00:19:46, 0.734s/it]: train_loss_raw=1.3473, running_loss=1.3751, LR=0.000100
[2025-08-27 00:32:02,355][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019952] [Batch 01472/03080] [00:18:00/00:19:40, 0.734s/it]: train_loss_raw=1.4250, running_loss=1.3745, LR=0.000100
[2025-08-27 00:32:08,349][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019960] [Batch 01480/03080] [00:18:06/00:19:35, 0.734s/it]: train_loss_raw=1.3977, running_loss=1.3736, LR=0.000100
[2025-08-27 00:32:14,577][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019968] [Batch 01488/03080] [00:18:13/00:19:29, 0.735s/it]: train_loss_raw=1.4134, running_loss=1.3767, LR=0.000100
[2025-08-27 00:32:20,849][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019976] [Batch 01496/03080] [00:18:19/00:19:24, 0.735s/it]: train_loss_raw=1.2160, running_loss=1.3744, LR=0.000100
[2025-08-27 00:32:27,047][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019984] [Batch 01504/03080] [00:18:25/00:19:18, 0.735s/it]: train_loss_raw=1.3690, running_loss=1.3756, LR=0.000100
[2025-08-27 00:32:32,978][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019992] [Batch 01512/03080] [00:18:31/00:19:12, 0.735s/it]: train_loss_raw=1.3839, running_loss=1.3758, LR=0.000100
[2025-08-27 00:32:38,984][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020000] [Batch 01520/03080] [00:18:37/00:19:06, 0.735s/it]: train_loss_raw=1.3459, running_loss=1.3749, LR=0.000100
[2025-08-27 00:32:48,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020008] [Batch 01528/03080] [00:18:47/00:19:04, 0.738s/it]: train_loss_raw=1.3860, running_loss=1.3762, LR=0.000100
[2025-08-27 00:32:54,488][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020016] [Batch 01536/03080] [00:18:53/00:18:58, 0.738s/it]: train_loss_raw=1.4751, running_loss=1.3764, LR=0.000100
[2025-08-27 00:33:00,157][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020024] [Batch 01544/03080] [00:18:58/00:18:52, 0.737s/it]: train_loss_raw=1.3827, running_loss=1.3748, LR=0.000100
[2025-08-27 00:33:06,178][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020032] [Batch 01552/03080] [00:19:04/00:18:47, 0.738s/it]: train_loss_raw=1.4336, running_loss=1.3739, LR=0.000100
[2025-08-27 00:33:12,422][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020040] [Batch 01560/03080] [00:19:10/00:18:41, 0.738s/it]: train_loss_raw=1.3991, running_loss=1.3767, LR=0.000100
[2025-08-27 00:33:18,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020048] [Batch 01568/03080] [00:19:17/00:18:35, 0.738s/it]: train_loss_raw=1.2697, running_loss=1.3747, LR=0.000100
[2025-08-27 00:33:24,601][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020056] [Batch 01576/03080] [00:19:23/00:18:29, 0.738s/it]: train_loss_raw=1.3654, running_loss=1.3722, LR=0.000100
[2025-08-27 00:33:30,770][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020064] [Batch 01584/03080] [00:19:29/00:18:24, 0.738s/it]: train_loss_raw=1.3042, running_loss=1.3710, LR=0.000100
[2025-08-27 00:33:36,595][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020072] [Batch 01592/03080] [00:19:35/00:18:18, 0.738s/it]: train_loss_raw=1.3888, running_loss=1.3728, LR=0.000100
[2025-08-27 00:33:42,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020080] [Batch 01600/03080] [00:19:40/00:18:12, 0.738s/it]: train_loss_raw=1.2519, running_loss=1.3716, LR=0.000100
[2025-08-27 00:33:48,060][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020088] [Batch 01608/03080] [00:19:46/00:18:06, 0.738s/it]: train_loss_raw=1.4468, running_loss=1.3686, LR=0.000100
[2025-08-27 00:33:53,764][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020096] [Batch 01616/03080] [00:19:52/00:18:00, 0.738s/it]: train_loss_raw=1.2666, running_loss=1.3670, LR=0.000100
[2025-08-27 00:33:59,501][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020104] [Batch 01624/03080] [00:19:58/00:17:54, 0.738s/it]: train_loss_raw=1.3189, running_loss=1.3642, LR=0.000100
[2025-08-27 00:34:05,360][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020112] [Batch 01632/03080] [00:20:03/00:17:48, 0.738s/it]: train_loss_raw=1.2739, running_loss=1.3633, LR=0.000100
[2025-08-27 00:34:11,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020120] [Batch 01640/03080] [00:20:09/00:17:42, 0.738s/it]: train_loss_raw=1.3387, running_loss=1.3647, LR=0.000100
[2025-08-27 00:34:17,091][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020128] [Batch 01648/03080] [00:20:15/00:17:36, 0.738s/it]: train_loss_raw=1.3541, running_loss=1.3665, LR=0.000100
[2025-08-27 00:34:22,983][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020136] [Batch 01656/03080] [00:20:21/00:17:30, 0.738s/it]: train_loss_raw=1.3550, running_loss=1.3680, LR=0.000100
[2025-08-27 00:34:28,955][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020144] [Batch 01664/03080] [00:20:27/00:17:24, 0.738s/it]: train_loss_raw=1.4147, running_loss=1.3685, LR=0.000100
[2025-08-27 00:34:34,835][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020152] [Batch 01672/03080] [00:20:33/00:17:18, 0.738s/it]: train_loss_raw=1.3960, running_loss=1.3656, LR=0.000100
[2025-08-27 00:34:40,543][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020160] [Batch 01680/03080] [00:20:39/00:17:12, 0.738s/it]: train_loss_raw=1.3426, running_loss=1.3679, LR=0.000100
[2025-08-27 00:34:46,366][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020168] [Batch 01688/03080] [00:20:44/00:17:06, 0.738s/it]: train_loss_raw=1.4334, running_loss=1.3721, LR=0.000100
[2025-08-27 00:34:52,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020176] [Batch 01696/03080] [00:20:50/00:17:00, 0.738s/it]: train_loss_raw=1.4336, running_loss=1.3716, LR=0.000100
[2025-08-27 00:34:58,124][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020184] [Batch 01704/03080] [00:20:56/00:16:54, 0.737s/it]: train_loss_raw=1.3028, running_loss=1.3728, LR=0.000100
[2025-08-27 00:35:04,228][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020192] [Batch 01712/03080] [00:21:02/00:16:49, 0.738s/it]: train_loss_raw=1.4393, running_loss=1.3712, LR=0.000100
[2025-08-27 00:35:10,139][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020200] [Batch 01720/03080] [00:21:08/00:16:43, 0.738s/it]: train_loss_raw=1.3387, running_loss=1.3697, LR=0.000100
[2025-08-27 00:35:16,027][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020208] [Batch 01728/03080] [00:21:14/00:16:37, 0.738s/it]: train_loss_raw=1.4171, running_loss=1.3695, LR=0.000100
[2025-08-27 00:35:21,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020216] [Batch 01736/03080] [00:21:20/00:16:31, 0.738s/it]: train_loss_raw=1.3388, running_loss=1.3715, LR=0.000100
[2025-08-27 00:35:27,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020224] [Batch 01744/03080] [00:21:26/00:16:25, 0.738s/it]: train_loss_raw=1.3284, running_loss=1.3712, LR=0.000100
[2025-08-27 00:35:33,779][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020232] [Batch 01752/03080] [00:21:32/00:16:19, 0.738s/it]: train_loss_raw=1.3709, running_loss=1.3735, LR=0.000100
[2025-08-27 00:35:39,567][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020240] [Batch 01760/03080] [00:21:38/00:16:13, 0.738s/it]: train_loss_raw=1.1843, running_loss=1.3695, LR=0.000100
[2025-08-27 00:35:45,393][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020248] [Batch 01768/03080] [00:21:43/00:16:07, 0.738s/it]: train_loss_raw=1.4464, running_loss=1.3698, LR=0.000100
[2025-08-27 00:35:51,256][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020256] [Batch 01776/03080] [00:21:49/00:16:01, 0.737s/it]: train_loss_raw=1.2933, running_loss=1.3689, LR=0.000100
[2025-08-27 00:35:57,193][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020264] [Batch 01784/03080] [00:21:55/00:15:55, 0.738s/it]: train_loss_raw=1.2840, running_loss=1.3672, LR=0.000100
[2025-08-27 00:36:03,196][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020272] [Batch 01792/03080] [00:22:01/00:15:49, 0.738s/it]: train_loss_raw=1.4709, running_loss=1.3689, LR=0.000100
[2025-08-27 00:36:09,149][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020280] [Batch 01800/03080] [00:22:07/00:15:44, 0.738s/it]: train_loss_raw=1.3222, running_loss=1.3661, LR=0.000100
[2025-08-27 00:36:15,151][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020288] [Batch 01808/03080] [00:22:13/00:15:38, 0.738s/it]: train_loss_raw=1.2694, running_loss=1.3647, LR=0.000100
[2025-08-27 00:36:20,866][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020296] [Batch 01816/03080] [00:22:19/00:15:32, 0.738s/it]: train_loss_raw=1.4768, running_loss=1.3642, LR=0.000100
[2025-08-27 00:36:26,784][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020304] [Batch 01824/03080] [00:22:25/00:15:26, 0.738s/it]: train_loss_raw=1.2435, running_loss=1.3639, LR=0.000100
[2025-08-27 00:36:32,855][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020312] [Batch 01832/03080] [00:22:31/00:15:20, 0.738s/it]: train_loss_raw=1.3004, running_loss=1.3642, LR=0.000100
[2025-08-27 00:36:38,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020320] [Batch 01840/03080] [00:22:37/00:15:14, 0.738s/it]: train_loss_raw=1.3020, running_loss=1.3653, LR=0.000100
[2025-08-27 00:36:44,510][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020328] [Batch 01848/03080] [00:22:43/00:15:08, 0.738s/it]: train_loss_raw=1.2590, running_loss=1.3644, LR=0.000100
[2025-08-27 00:36:50,540][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020336] [Batch 01856/03080] [00:22:49/00:15:02, 0.738s/it]: train_loss_raw=1.4531, running_loss=1.3691, LR=0.000100
[2025-08-27 00:36:56,311][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020344] [Batch 01864/03080] [00:22:54/00:14:56, 0.738s/it]: train_loss_raw=1.4398, running_loss=1.3699, LR=0.000100
[2025-08-27 00:37:02,089][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020352] [Batch 01872/03080] [00:23:00/00:14:50, 0.738s/it]: train_loss_raw=1.3470, running_loss=1.3678, LR=0.000100
[2025-08-27 00:37:07,840][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020360] [Batch 01880/03080] [00:23:06/00:14:44, 0.737s/it]: train_loss_raw=1.4394, running_loss=1.3680, LR=0.000100
[2025-08-27 00:37:13,507][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020368] [Batch 01888/03080] [00:23:12/00:14:38, 0.737s/it]: train_loss_raw=1.3345, running_loss=1.3698, LR=0.000100
[2025-08-27 00:37:19,281][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020376] [Batch 01896/03080] [00:23:17/00:14:32, 0.737s/it]: train_loss_raw=1.3051, running_loss=1.3686, LR=0.000100
[2025-08-27 00:37:25,104][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020384] [Batch 01904/03080] [00:23:23/00:14:26, 0.737s/it]: train_loss_raw=1.3161, running_loss=1.3664, LR=0.000100
[2025-08-27 00:37:30,922][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020392] [Batch 01912/03080] [00:23:29/00:14:21, 0.737s/it]: train_loss_raw=1.3293, running_loss=1.3670, LR=0.000100
[2025-08-27 00:37:36,896][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020400] [Batch 01920/03080] [00:23:35/00:14:15, 0.737s/it]: train_loss_raw=1.3972, running_loss=1.3693, LR=0.000100
[2025-08-27 00:37:42,787][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020408] [Batch 01928/03080] [00:23:41/00:14:09, 0.737s/it]: train_loss_raw=1.3395, running_loss=1.3691, LR=0.000100
[2025-08-27 00:37:48,606][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020416] [Batch 01936/03080] [00:23:47/00:14:03, 0.737s/it]: train_loss_raw=1.3256, running_loss=1.3669, LR=0.000100
[2025-08-27 00:37:54,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020424] [Batch 01944/03080] [00:23:52/00:13:57, 0.737s/it]: train_loss_raw=1.3538, running_loss=1.3662, LR=0.000100
[2025-08-27 00:38:00,170][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020432] [Batch 01952/03080] [00:23:58/00:13:51, 0.737s/it]: train_loss_raw=1.2883, running_loss=1.3632, LR=0.000100
[2025-08-27 00:38:05,956][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020440] [Batch 01960/03080] [00:24:04/00:13:45, 0.737s/it]: train_loss_raw=1.3332, running_loss=1.3623, LR=0.000100
[2025-08-27 00:38:11,706][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020448] [Batch 01968/03080] [00:24:10/00:13:39, 0.737s/it]: train_loss_raw=1.5081, running_loss=1.3632, LR=0.000100
[2025-08-27 00:38:17,389][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020456] [Batch 01976/03080] [00:24:15/00:13:33, 0.737s/it]: train_loss_raw=1.2863, running_loss=1.3615, LR=0.000100
[2025-08-27 00:38:22,910][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020464] [Batch 01984/03080] [00:24:21/00:13:27, 0.737s/it]: train_loss_raw=1.3145, running_loss=1.3612, LR=0.000100
[2025-08-27 00:38:28,586][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020472] [Batch 01992/03080] [00:24:27/00:13:21, 0.737s/it]: train_loss_raw=1.3905, running_loss=1.3599, LR=0.000100
[2025-08-27 00:38:34,224][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020480] [Batch 02000/03080] [00:24:32/00:13:15, 0.736s/it]: train_loss_raw=1.3358, running_loss=1.3568, LR=0.000100
[2025-08-27 00:38:40,102][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020488] [Batch 02008/03080] [00:24:38/00:13:09, 0.736s/it]: train_loss_raw=1.3714, running_loss=1.3591, LR=0.000100
[2025-08-27 00:38:45,951][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020496] [Batch 02016/03080] [00:24:44/00:13:03, 0.736s/it]: train_loss_raw=1.4022, running_loss=1.3605, LR=0.000100
[2025-08-27 00:38:51,901][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020504] [Batch 02024/03080] [00:24:50/00:12:57, 0.736s/it]: train_loss_raw=1.3524, running_loss=1.3572, LR=0.000100
[2025-08-27 00:38:57,946][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020512] [Batch 02032/03080] [00:24:56/00:12:51, 0.736s/it]: train_loss_raw=1.3435, running_loss=1.3589, LR=0.000100
[2025-08-27 00:39:03,806][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020520] [Batch 02040/03080] [00:25:02/00:12:45, 0.736s/it]: train_loss_raw=1.3845, running_loss=1.3614, LR=0.000100
[2025-08-27 00:39:09,797][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020528] [Batch 02048/03080] [00:25:08/00:12:40, 0.736s/it]: train_loss_raw=1.4683, running_loss=1.3615, LR=0.000100
[2025-08-27 00:39:15,567][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020536] [Batch 02056/03080] [00:25:14/00:12:34, 0.736s/it]: train_loss_raw=1.3573, running_loss=1.3630, LR=0.000100
[2025-08-27 00:39:21,301][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020544] [Batch 02064/03080] [00:25:19/00:12:28, 0.736s/it]: train_loss_raw=1.4068, running_loss=1.3622, LR=0.000100
[2025-08-27 00:39:27,063][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020552] [Batch 02072/03080] [00:25:25/00:12:22, 0.736s/it]: train_loss_raw=1.2800, running_loss=1.3612, LR=0.000100
[2025-08-27 00:39:32,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020560] [Batch 02080/03080] [00:25:31/00:12:16, 0.736s/it]: train_loss_raw=1.2258, running_loss=1.3621, LR=0.000100
[2025-08-27 00:39:38,527][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020568] [Batch 02088/03080] [00:25:37/00:12:10, 0.736s/it]: train_loss_raw=1.3072, running_loss=1.3618, LR=0.000100
[2025-08-27 00:39:44,429][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020576] [Batch 02096/03080] [00:25:42/00:12:04, 0.736s/it]: train_loss_raw=1.2464, running_loss=1.3574, LR=0.000100
[2025-08-27 00:39:50,398][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020584] [Batch 02104/03080] [00:25:48/00:11:58, 0.736s/it]: train_loss_raw=1.3334, running_loss=1.3590, LR=0.000100
[2025-08-27 00:39:56,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020592] [Batch 02112/03080] [00:25:54/00:11:52, 0.736s/it]: train_loss_raw=1.3962, running_loss=1.3603, LR=0.000100
[2025-08-27 00:40:02,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020600] [Batch 02120/03080] [00:26:00/00:11:46, 0.736s/it]: train_loss_raw=1.3090, running_loss=1.3582, LR=0.000100
[2025-08-27 00:40:07,897][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020608] [Batch 02128/03080] [00:26:06/00:11:40, 0.736s/it]: train_loss_raw=1.3189, running_loss=1.3589, LR=0.000100
[2025-08-27 00:40:13,579][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020616] [Batch 02136/03080] [00:26:12/00:11:34, 0.736s/it]: train_loss_raw=1.3354, running_loss=1.3566, LR=0.000100
[2025-08-27 00:40:19,328][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020624] [Batch 02144/03080] [00:26:17/00:11:28, 0.736s/it]: train_loss_raw=1.3371, running_loss=1.3570, LR=0.000100
[2025-08-27 00:40:25,064][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020632] [Batch 02152/03080] [00:26:23/00:11:22, 0.736s/it]: train_loss_raw=1.2793, running_loss=1.3570, LR=0.000100
[2025-08-27 00:40:30,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020640] [Batch 02160/03080] [00:26:29/00:11:16, 0.736s/it]: train_loss_raw=1.4159, running_loss=1.3585, LR=0.000100
[2025-08-27 00:40:37,243][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020648] [Batch 02168/03080] [00:26:35/00:11:11, 0.736s/it]: train_loss_raw=1.3268, running_loss=1.3555, LR=0.000100
[2025-08-27 00:40:43,310][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020656] [Batch 02176/03080] [00:26:41/00:11:05, 0.736s/it]: train_loss_raw=1.3845, running_loss=1.3544, LR=0.000100
[2025-08-27 00:40:49,390][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020664] [Batch 02184/03080] [00:26:47/00:10:59, 0.736s/it]: train_loss_raw=1.2693, running_loss=1.3548, LR=0.000100
[2025-08-27 00:40:55,245][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020672] [Batch 02192/03080] [00:26:53/00:10:53, 0.736s/it]: train_loss_raw=1.4121, running_loss=1.3539, LR=0.000100
[2025-08-27 00:41:01,193][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020680] [Batch 02200/03080] [00:26:59/00:10:47, 0.736s/it]: train_loss_raw=1.3621, running_loss=1.3549, LR=0.000100
[2025-08-27 00:41:06,898][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020688] [Batch 02208/03080] [00:27:05/00:10:41, 0.736s/it]: train_loss_raw=1.3671, running_loss=1.3546, LR=0.000100
[2025-08-27 00:41:12,636][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020696] [Batch 02216/03080] [00:27:11/00:10:35, 0.736s/it]: train_loss_raw=1.3800, running_loss=1.3547, LR=0.000100
[2025-08-27 00:41:18,332][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020704] [Batch 02224/03080] [00:27:16/00:10:30, 0.736s/it]: train_loss_raw=1.3131, running_loss=1.3535, LR=0.000100
[2025-08-27 00:41:24,009][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020712] [Batch 02232/03080] [00:27:22/00:10:24, 0.736s/it]: train_loss_raw=1.3947, running_loss=1.3530, LR=0.000100
[2025-08-27 00:41:29,757][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020720] [Batch 02240/03080] [00:27:28/00:10:18, 0.736s/it]: train_loss_raw=1.5075, running_loss=1.3569, LR=0.000100
[2025-08-27 00:41:35,573][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020728] [Batch 02248/03080] [00:27:34/00:10:12, 0.736s/it]: train_loss_raw=1.2907, running_loss=1.3550, LR=0.000100
[2025-08-27 00:41:41,328][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020736] [Batch 02256/03080] [00:27:39/00:10:06, 0.736s/it]: train_loss_raw=1.4109, running_loss=1.3550, LR=0.000100
[2025-08-27 00:41:47,046][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020744] [Batch 02264/03080] [00:27:45/00:10:00, 0.736s/it]: train_loss_raw=1.3654, running_loss=1.3556, LR=0.000100
[2025-08-27 00:41:52,927][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020752] [Batch 02272/03080] [00:27:51/00:09:54, 0.736s/it]: train_loss_raw=1.2680, running_loss=1.3558, LR=0.000100
[2025-08-27 00:41:58,826][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020760] [Batch 02280/03080] [00:27:57/00:09:48, 0.736s/it]: train_loss_raw=1.3267, running_loss=1.3524, LR=0.000100
[2025-08-27 00:42:04,699][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020768] [Batch 02288/03080] [00:28:03/00:09:42, 0.736s/it]: train_loss_raw=1.3762, running_loss=1.3519, LR=0.000100
[2025-08-27 00:42:10,515][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020776] [Batch 02296/03080] [00:28:09/00:09:36, 0.736s/it]: train_loss_raw=1.3760, running_loss=1.3521, LR=0.000100
[2025-08-27 00:42:16,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020784] [Batch 02304/03080] [00:28:14/00:09:30, 0.736s/it]: train_loss_raw=1.3155, running_loss=1.3510, LR=0.000100
[2025-08-27 00:42:22,143][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020792] [Batch 02312/03080] [00:28:20/00:09:24, 0.736s/it]: train_loss_raw=1.3777, running_loss=1.3493, LR=0.000100
[2025-08-27 00:42:28,033][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020800] [Batch 02320/03080] [00:28:26/00:09:19, 0.736s/it]: train_loss_raw=1.4097, running_loss=1.3516, LR=0.000100
[2025-08-27 00:42:34,192][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020808] [Batch 02328/03080] [00:28:32/00:09:13, 0.736s/it]: train_loss_raw=1.3304, running_loss=1.3533, LR=0.000100
[2025-08-27 00:42:40,293][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020816] [Batch 02336/03080] [00:28:38/00:09:07, 0.736s/it]: train_loss_raw=1.3664, running_loss=1.3516, LR=0.000100
[2025-08-27 00:42:46,174][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020824] [Batch 02344/03080] [00:28:44/00:09:01, 0.736s/it]: train_loss_raw=1.4059, running_loss=1.3524, LR=0.000100
[2025-08-27 00:42:52,137][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020832] [Batch 02352/03080] [00:28:50/00:08:55, 0.736s/it]: train_loss_raw=1.3802, running_loss=1.3539, LR=0.000100
[2025-08-27 00:42:57,994][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020840] [Batch 02360/03080] [00:28:56/00:08:49, 0.736s/it]: train_loss_raw=1.3864, running_loss=1.3529, LR=0.000100
[2025-08-27 00:43:03,820][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020848] [Batch 02368/03080] [00:29:02/00:08:43, 0.736s/it]: train_loss_raw=1.3094, running_loss=1.3529, LR=0.000100
[2025-08-27 00:43:09,507][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020856] [Batch 02376/03080] [00:29:08/00:08:37, 0.736s/it]: train_loss_raw=1.2766, running_loss=1.3510, LR=0.000100
[2025-08-27 00:43:15,146][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020864] [Batch 02384/03080] [00:29:13/00:08:31, 0.736s/it]: train_loss_raw=1.3493, running_loss=1.3505, LR=0.000100
[2025-08-27 00:43:20,949][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020872] [Batch 02392/03080] [00:29:19/00:08:26, 0.736s/it]: train_loss_raw=1.3499, running_loss=1.3521, LR=0.000100
[2025-08-27 00:43:26,684][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020880] [Batch 02400/03080] [00:29:25/00:08:20, 0.736s/it]: train_loss_raw=1.4185, running_loss=1.3481, LR=0.000100
[2025-08-27 00:43:32,483][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020888] [Batch 02408/03080] [00:29:31/00:08:14, 0.735s/it]: train_loss_raw=1.2593, running_loss=1.3493, LR=0.000100
[2025-08-27 00:43:38,357][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020896] [Batch 02416/03080] [00:29:36/00:08:08, 0.735s/it]: train_loss_raw=1.2853, running_loss=1.3477, LR=0.000100
[2025-08-27 00:43:44,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020904] [Batch 02424/03080] [00:29:42/00:08:02, 0.736s/it]: train_loss_raw=1.3018, running_loss=1.3474, LR=0.000100
[2025-08-27 00:43:50,095][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020912] [Batch 02432/03080] [00:29:48/00:07:56, 0.735s/it]: train_loss_raw=1.4826, running_loss=1.3492, LR=0.000100
[2025-08-27 00:43:55,753][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020920] [Batch 02440/03080] [00:29:54/00:07:50, 0.735s/it]: train_loss_raw=1.2401, running_loss=1.3485, LR=0.000100
[2025-08-27 00:44:01,675][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020928] [Batch 02448/03080] [00:30:00/00:07:44, 0.735s/it]: train_loss_raw=1.4928, running_loss=1.3495, LR=0.000100
[2025-08-27 00:44:07,498][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020936] [Batch 02456/03080] [00:30:06/00:07:38, 0.735s/it]: train_loss_raw=1.4381, running_loss=1.3495, LR=0.000100
[2025-08-27 00:44:13,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020944] [Batch 02464/03080] [00:30:11/00:07:32, 0.735s/it]: train_loss_raw=1.3866, running_loss=1.3505, LR=0.000100
[2025-08-27 00:44:19,252][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020952] [Batch 02472/03080] [00:30:17/00:07:27, 0.735s/it]: train_loss_raw=1.4268, running_loss=1.3508, LR=0.000100
[2025-08-27 00:44:25,140][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020960] [Batch 02480/03080] [00:30:23/00:07:21, 0.735s/it]: train_loss_raw=1.3210, running_loss=1.3519, LR=0.000100
[2025-08-27 00:44:30,935][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020968] [Batch 02488/03080] [00:30:29/00:07:15, 0.735s/it]: train_loss_raw=1.3317, running_loss=1.3509, LR=0.000100
[2025-08-27 00:44:36,872][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020976] [Batch 02496/03080] [00:30:35/00:07:09, 0.735s/it]: train_loss_raw=1.2864, running_loss=1.3507, LR=0.000100
[2025-08-27 00:44:42,746][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020984] [Batch 02504/03080] [00:30:41/00:07:03, 0.735s/it]: train_loss_raw=1.4015, running_loss=1.3496, LR=0.000100
[2025-08-27 00:44:48,685][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020992] [Batch 02512/03080] [00:30:47/00:06:57, 0.735s/it]: train_loss_raw=1.3413, running_loss=1.3473, LR=0.000100
[2025-08-27 00:44:54,752][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021000] [Batch 02520/03080] [00:30:53/00:06:51, 0.735s/it]: train_loss_raw=1.3051, running_loss=1.3513, LR=0.000100
[2025-08-27 00:45:00,610][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021008] [Batch 02528/03080] [00:30:59/00:06:45, 0.735s/it]: train_loss_raw=1.3820, running_loss=1.3532, LR=0.000100
[2025-08-27 00:45:06,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021016] [Batch 02536/03080] [00:31:05/00:06:40, 0.735s/it]: train_loss_raw=1.4131, running_loss=1.3533, LR=0.000100
[2025-08-27 00:45:12,416][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021024] [Batch 02544/03080] [00:31:10/00:06:34, 0.735s/it]: train_loss_raw=1.3262, running_loss=1.3517, LR=0.000100
[2025-08-27 00:45:18,555][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021032] [Batch 02552/03080] [00:31:17/00:06:28, 0.736s/it]: train_loss_raw=1.3424, running_loss=1.3498, LR=0.000100
[2025-08-27 00:45:24,665][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021040] [Batch 02560/03080] [00:31:23/00:06:22, 0.736s/it]: train_loss_raw=1.3425, running_loss=1.3495, LR=0.000100
[2025-08-27 00:45:30,744][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021048] [Batch 02568/03080] [00:31:29/00:06:16, 0.736s/it]: train_loss_raw=1.3335, running_loss=1.3501, LR=0.000100
[2025-08-27 00:45:36,737][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021056] [Batch 02576/03080] [00:31:35/00:06:10, 0.736s/it]: train_loss_raw=1.4239, running_loss=1.3482, LR=0.000100
[2025-08-27 00:45:42,583][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021064] [Batch 02584/03080] [00:31:41/00:06:04, 0.736s/it]: train_loss_raw=1.3046, running_loss=1.3471, LR=0.000100
[2025-08-27 00:45:48,645][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021072] [Batch 02592/03080] [00:31:47/00:05:59, 0.736s/it]: train_loss_raw=1.3735, running_loss=1.3485, LR=0.000100
[2025-08-27 00:45:54,618][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021080] [Batch 02600/03080] [00:31:53/00:05:53, 0.736s/it]: train_loss_raw=1.3477, running_loss=1.3466, LR=0.000100
[2025-08-27 00:46:00,709][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021088] [Batch 02608/03080] [00:31:59/00:05:47, 0.736s/it]: train_loss_raw=1.3805, running_loss=1.3452, LR=0.000100
[2025-08-27 00:46:06,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021096] [Batch 02616/03080] [00:32:05/00:05:41, 0.736s/it]: train_loss_raw=1.3439, running_loss=1.3455, LR=0.000100
[2025-08-27 00:46:12,963][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021104] [Batch 02624/03080] [00:32:11/00:05:35, 0.736s/it]: train_loss_raw=1.4225, running_loss=1.3436, LR=0.000100
[2025-08-27 00:46:18,873][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021112] [Batch 02632/03080] [00:32:17/00:05:29, 0.736s/it]: train_loss_raw=1.4122, running_loss=1.3432, LR=0.000100
[2025-08-27 00:46:25,081][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021120] [Batch 02640/03080] [00:32:23/00:05:23, 0.736s/it]: train_loss_raw=1.3559, running_loss=1.3429, LR=0.000100
[2025-08-27 00:46:31,050][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021128] [Batch 02648/03080] [00:32:29/00:05:18, 0.736s/it]: train_loss_raw=1.1538, running_loss=1.3422, LR=0.000100
[2025-08-27 00:46:36,943][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021136] [Batch 02656/03080] [00:32:35/00:05:12, 0.736s/it]: train_loss_raw=1.3664, running_loss=1.3415, LR=0.000100
[2025-08-27 00:46:42,791][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021144] [Batch 02664/03080] [00:32:41/00:05:06, 0.736s/it]: train_loss_raw=1.2869, running_loss=1.3416, LR=0.000100
[2025-08-27 00:46:48,980][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021152] [Batch 02672/03080] [00:32:47/00:05:00, 0.736s/it]: train_loss_raw=1.3436, running_loss=1.3414, LR=0.000100
[2025-08-27 00:46:55,087][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021160] [Batch 02680/03080] [00:32:53/00:04:54, 0.736s/it]: train_loss_raw=1.3020, running_loss=1.3392, LR=0.000100
[2025-08-27 00:47:01,069][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021168] [Batch 02688/03080] [00:32:59/00:04:48, 0.736s/it]: train_loss_raw=1.3850, running_loss=1.3382, LR=0.000100
[2025-08-27 00:47:07,161][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021176] [Batch 02696/03080] [00:33:05/00:04:42, 0.737s/it]: train_loss_raw=1.3076, running_loss=1.3408, LR=0.000100
[2025-08-27 00:47:13,049][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021184] [Batch 02704/03080] [00:33:11/00:04:36, 0.737s/it]: train_loss_raw=1.3154, running_loss=1.3411, LR=0.000100
[2025-08-27 00:47:19,035][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021192] [Batch 02712/03080] [00:33:17/00:04:31, 0.737s/it]: train_loss_raw=1.4807, running_loss=1.3408, LR=0.000100
[2025-08-27 00:47:24,860][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021200] [Batch 02720/03080] [00:33:23/00:04:25, 0.737s/it]: train_loss_raw=1.3175, running_loss=1.3391, LR=0.000100
[2025-08-27 00:47:30,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021208] [Batch 02728/03080] [00:33:29/00:04:19, 0.737s/it]: train_loss_raw=1.3127, running_loss=1.3395, LR=0.000100
[2025-08-27 00:47:36,591][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021216] [Batch 02736/03080] [00:33:35/00:04:13, 0.737s/it]: train_loss_raw=1.2372, running_loss=1.3359, LR=0.000100
[2025-08-27 00:47:42,635][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021224] [Batch 02744/03080] [00:33:41/00:04:07, 0.737s/it]: train_loss_raw=1.3968, running_loss=1.3395, LR=0.000100
[2025-08-27 00:47:48,560][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021232] [Batch 02752/03080] [00:33:47/00:04:01, 0.737s/it]: train_loss_raw=1.2935, running_loss=1.3407, LR=0.000100
[2025-08-27 00:47:54,429][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021240] [Batch 02760/03080] [00:33:52/00:03:55, 0.737s/it]: train_loss_raw=1.4036, running_loss=1.3390, LR=0.000100
[2025-08-27 00:48:00,281][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021248] [Batch 02768/03080] [00:33:58/00:03:49, 0.737s/it]: train_loss_raw=1.3231, running_loss=1.3410, LR=0.000100
[2025-08-27 00:48:06,120][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021256] [Batch 02776/03080] [00:34:04/00:03:43, 0.737s/it]: train_loss_raw=1.2570, running_loss=1.3370, LR=0.000100
[2025-08-27 00:48:12,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021264] [Batch 02784/03080] [00:34:10/00:03:38, 0.737s/it]: train_loss_raw=1.3702, running_loss=1.3375, LR=0.000100
[2025-08-27 00:48:17,966][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021272] [Batch 02792/03080] [00:34:16/00:03:32, 0.737s/it]: train_loss_raw=1.3353, running_loss=1.3393, LR=0.000100
[2025-08-27 00:48:23,852][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021280] [Batch 02800/03080] [00:34:22/00:03:26, 0.737s/it]: train_loss_raw=1.2934, running_loss=1.3385, LR=0.000100
[2025-08-27 00:48:29,870][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021288] [Batch 02808/03080] [00:34:28/00:03:20, 0.737s/it]: train_loss_raw=1.3347, running_loss=1.3373, LR=0.000100
[2025-08-27 00:48:35,908][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021296] [Batch 02816/03080] [00:34:34/00:03:14, 0.737s/it]: train_loss_raw=1.3311, running_loss=1.3363, LR=0.000100
[2025-08-27 00:48:42,101][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021304] [Batch 02824/03080] [00:34:40/00:03:08, 0.737s/it]: train_loss_raw=1.2772, running_loss=1.3362, LR=0.000100
[2025-08-27 00:48:48,046][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021312] [Batch 02832/03080] [00:34:46/00:03:02, 0.737s/it]: train_loss_raw=1.2745, running_loss=1.3361, LR=0.000100
[2025-08-27 00:48:53,915][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021320] [Batch 02840/03080] [00:34:52/00:02:56, 0.737s/it]: train_loss_raw=1.2467, running_loss=1.3345, LR=0.000100
[2025-08-27 00:48:59,714][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021328] [Batch 02848/03080] [00:34:58/00:02:50, 0.737s/it]: train_loss_raw=1.2771, running_loss=1.3325, LR=0.000100
[2025-08-27 00:49:05,882][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021336] [Batch 02856/03080] [00:35:04/00:02:45, 0.737s/it]: train_loss_raw=1.3423, running_loss=1.3326, LR=0.000100
[2025-08-27 00:49:11,668][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021344] [Batch 02864/03080] [00:35:10/00:02:39, 0.737s/it]: train_loss_raw=1.4505, running_loss=1.3334, LR=0.000100
[2025-08-27 00:49:17,367][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021352] [Batch 02872/03080] [00:35:15/00:02:33, 0.737s/it]: train_loss_raw=1.3104, running_loss=1.3341, LR=0.000100
[2025-08-27 00:49:23,368][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021360] [Batch 02880/03080] [00:35:21/00:02:27, 0.737s/it]: train_loss_raw=1.4460, running_loss=1.3361, LR=0.000100
[2025-08-27 00:49:29,259][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021368] [Batch 02888/03080] [00:35:27/00:02:21, 0.737s/it]: train_loss_raw=1.3244, running_loss=1.3324, LR=0.000100
[2025-08-27 00:49:35,020][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021376] [Batch 02896/03080] [00:35:33/00:02:15, 0.737s/it]: train_loss_raw=1.3989, running_loss=1.3352, LR=0.000100
[2025-08-27 00:49:41,028][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021384] [Batch 02904/03080] [00:35:39/00:02:09, 0.737s/it]: train_loss_raw=1.3601, running_loss=1.3383, LR=0.000100
[2025-08-27 00:49:46,901][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021392] [Batch 02912/03080] [00:35:45/00:02:03, 0.737s/it]: train_loss_raw=1.2406, running_loss=1.3363, LR=0.000100
[2025-08-27 00:49:52,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021400] [Batch 02920/03080] [00:35:51/00:01:57, 0.737s/it]: train_loss_raw=1.3819, running_loss=1.3364, LR=0.000100
[2025-08-27 00:49:58,662][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021408] [Batch 02928/03080] [00:35:57/00:01:51, 0.737s/it]: train_loss_raw=1.3604, running_loss=1.3358, LR=0.000100
[2025-08-27 00:50:04,602][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021416] [Batch 02936/03080] [00:36:03/00:01:46, 0.737s/it]: train_loss_raw=1.4307, running_loss=1.3341, LR=0.000100
[2025-08-27 00:50:10,555][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021424] [Batch 02944/03080] [00:36:09/00:01:40, 0.737s/it]: train_loss_raw=1.3967, running_loss=1.3312, LR=0.000100
[2025-08-27 00:50:16,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021432] [Batch 02952/03080] [00:36:14/00:01:34, 0.737s/it]: train_loss_raw=1.3192, running_loss=1.3297, LR=0.000100
[2025-08-27 00:50:22,391][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021440] [Batch 02960/03080] [00:36:20/00:01:28, 0.737s/it]: train_loss_raw=1.3302, running_loss=1.3268, LR=0.000100
[2025-08-27 00:50:28,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021448] [Batch 02968/03080] [00:36:26/00:01:22, 0.737s/it]: train_loss_raw=1.3421, running_loss=1.3268, LR=0.000100
[2025-08-27 00:50:34,182][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021456] [Batch 02976/03080] [00:36:32/00:01:16, 0.737s/it]: train_loss_raw=1.3267, running_loss=1.3274, LR=0.000100
[2025-08-27 00:50:40,210][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021464] [Batch 02984/03080] [00:36:38/00:01:10, 0.737s/it]: train_loss_raw=1.4366, running_loss=1.3298, LR=0.000100
[2025-08-27 00:50:46,070][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021472] [Batch 02992/03080] [00:36:44/00:01:04, 0.737s/it]: train_loss_raw=1.3297, running_loss=1.3293, LR=0.000100
[2025-08-27 00:50:51,908][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021480] [Batch 03000/03080] [00:36:50/00:00:58, 0.737s/it]: train_loss_raw=1.2678, running_loss=1.3274, LR=0.000100
[2025-08-27 00:50:57,866][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021488] [Batch 03008/03080] [00:36:56/00:00:53, 0.737s/it]: train_loss_raw=1.3754, running_loss=1.3294, LR=0.000100
[2025-08-27 00:51:03,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021496] [Batch 03016/03080] [00:37:02/00:00:47, 0.737s/it]: train_loss_raw=1.3209, running_loss=1.3277, LR=0.000100
[2025-08-27 00:51:09,402][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021504] [Batch 03024/03080] [00:37:07/00:00:41, 0.737s/it]: train_loss_raw=1.2803, running_loss=1.3258, LR=0.000100
[2025-08-27 00:51:15,108][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021512] [Batch 03032/03080] [00:37:13/00:00:35, 0.737s/it]: train_loss_raw=1.3488, running_loss=1.3247, LR=0.000100
[2025-08-27 00:51:20,865][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021520] [Batch 03040/03080] [00:37:19/00:00:29, 0.737s/it]: train_loss_raw=1.3912, running_loss=1.3256, LR=0.000100
[2025-08-27 00:51:26,602][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021528] [Batch 03048/03080] [00:37:25/00:00:23, 0.737s/it]: train_loss_raw=1.3272, running_loss=1.3303, LR=0.000100
[2025-08-27 00:51:32,552][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021536] [Batch 03056/03080] [00:37:31/00:00:17, 0.737s/it]: train_loss_raw=1.3705, running_loss=1.3302, LR=0.000100
[2025-08-27 00:51:38,414][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021544] [Batch 03064/03080] [00:37:36/00:00:11, 0.737s/it]: train_loss_raw=1.3634, running_loss=1.3310, LR=0.000100
[2025-08-27 00:51:44,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021552] [Batch 03072/03080] [00:37:42/00:00:05, 0.737s/it]: train_loss_raw=1.3104, running_loss=1.3285, LR=0.000100
[2025-08-27 00:51:50,217][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021560] [Batch 03080/03080] [00:37:48/00:00:00, 0.737s/it]: train_loss_raw=1.3100, running_loss=1.3288, LR=0.000100
[2025-08-27 00:51:50,722][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-27 00:52:02,642][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00007/00310] [00:00:11/00:07:29, 1.490s/it]
[2025-08-27 00:52:15,130][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00015/00310] [00:00:24/00:07:28, 1.525s/it]
[2025-08-27 00:52:27,544][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00023/00310] [00:00:36/00:07:18, 1.534s/it]
[2025-08-27 00:52:40,601][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00031/00310] [00:00:49/00:07:13, 1.559s/it]
[2025-08-27 00:52:53,083][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00039/00310] [00:01:02/00:07:00, 1.559s/it]
[2025-08-27 00:53:05,814][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00047/00310] [00:01:15/00:06:49, 1.564s/it]
[2025-08-27 00:53:18,705][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00055/00310] [00:01:27/00:06:39, 1.571s/it]
[2025-08-27 00:53:32,041][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00063/00310] [00:01:41/00:06:29, 1.583s/it]
[2025-08-27 00:53:44,653][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00071/00310] [00:01:53/00:06:16, 1.582s/it]
[2025-08-27 00:53:57,359][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00079/00310] [00:02:06/00:06:04, 1.583s/it]
[2025-08-27 00:54:09,814][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00087/00310] [00:02:19/00:05:50, 1.581s/it]
[2025-08-27 00:54:22,495][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00095/00310] [00:02:31/00:05:38, 1.581s/it]
[2025-08-27 00:54:35,336][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00103/00310] [00:02:44/00:05:26, 1.583s/it]
[2025-08-27 00:54:47,992][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00111/00310] [00:02:57/00:05:13, 1.583s/it]
[2025-08-27 00:55:00,810][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00119/00310] [00:03:10/00:05:00, 1.584s/it]
[2025-08-27 00:55:13,768][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00127/00310] [00:03:23/00:04:48, 1.586s/it]
[2025-08-27 00:55:27,008][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00135/00310] [00:03:36/00:04:36, 1.590s/it]
[2025-08-27 00:55:40,335][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00143/00310] [00:03:49/00:04:24, 1.595s/it]
[2025-08-27 00:55:51,781][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00151/00310] [00:04:01/00:04:10, 1.586s/it]
[2025-08-27 00:56:03,729][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00159/00310] [00:04:13/00:03:57, 1.581s/it]
[2025-08-27 00:56:16,557][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00167/00310] [00:04:25/00:03:44, 1.582s/it]
[2025-08-27 00:56:28,215][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00175/00310] [00:04:37/00:03:31, 1.577s/it]
[2025-08-27 00:56:40,135][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00183/00310] [00:04:49/00:03:18, 1.573s/it]
[2025-08-27 00:56:52,580][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00191/00310] [00:05:01/00:03:05, 1.572s/it]
[2025-08-27 00:57:05,168][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00199/00310] [00:05:14/00:02:52, 1.572s/it]
[2025-08-27 00:57:17,528][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00207/00310] [00:05:26/00:02:40, 1.571s/it]
[2025-08-27 00:57:29,799][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00215/00310] [00:05:39/00:02:27, 1.570s/it]
[2025-08-27 00:57:42,642][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00223/00310] [00:05:51/00:02:15, 1.571s/it]
[2025-08-27 00:57:55,186][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00231/00310] [00:06:04/00:02:02, 1.571s/it]
[2025-08-27 00:58:07,875][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00239/00310] [00:06:17/00:01:50, 1.571s/it]
[2025-08-27 00:58:19,968][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00247/00310] [00:06:29/00:01:37, 1.570s/it]
[2025-08-27 00:58:32,401][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00255/00310] [00:06:41/00:01:24, 1.569s/it]
[2025-08-27 00:58:44,985][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00263/00310] [00:06:54/00:01:12, 1.569s/it]
[2025-08-27 00:58:57,362][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00271/00310] [00:07:06/00:00:59, 1.569s/it]
[2025-08-27 00:59:09,639][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00279/00310] [00:07:18/00:00:47, 1.568s/it]
[2025-08-27 00:59:22,290][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00287/00310] [00:07:31/00:00:34, 1.568s/it]
[2025-08-27 00:59:34,140][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00295/00310] [00:07:43/00:00:21, 1.566s/it]
[2025-08-27 00:59:47,447][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00303/00310] [00:07:56/00:00:09, 1.568s/it]
[2025-08-27 00:59:56,964][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.32880, valid_loss=2.02372
[2025-08-27 00:59:56,964][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-27 00:59:56,965][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.770
[2025-08-27 00:59:56,965][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.030
[2025-08-27 00:59:56,965][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.032
[2025-08-27 00:59:56,965][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.007
[2025-08-27 00:59:56,986][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 05:33:10, remaining time 18:14:44, 00:47:35 per epoch
[2025-08-27 01:00:02,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021568] [Batch 00008/03080] [00:00:05/00:36:04, 0.705s/it]: train_loss_raw=1.3370, running_loss=1.3431, LR=0.000100
[2025-08-27 01:00:09,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021576] [Batch 00016/03080] [00:00:11/00:37:48, 0.740s/it]: train_loss_raw=1.3118, running_loss=1.3418, LR=0.000100
[2025-08-27 01:00:15,264][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021584] [Batch 00024/03080] [00:00:17/00:38:07, 0.748s/it]: train_loss_raw=1.3408, running_loss=1.3407, LR=0.000100
[2025-08-27 01:00:20,943][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021592] [Batch 00032/03080] [00:00:23/00:37:31, 0.739s/it]: train_loss_raw=1.3274, running_loss=1.3376, LR=0.000100
[2025-08-27 01:00:26,991][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021600] [Batch 00040/03080] [00:00:29/00:37:36, 0.742s/it]: train_loss_raw=1.2885, running_loss=1.3332, LR=0.000100
[2025-08-27 01:00:32,815][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021608] [Batch 00048/03080] [00:00:35/00:37:23, 0.740s/it]: train_loss_raw=1.2509, running_loss=1.3292, LR=0.000100
[2025-08-27 01:00:38,666][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021616] [Batch 00056/03080] [00:00:41/00:37:13, 0.739s/it]: train_loss_raw=1.3150, running_loss=1.3280, LR=0.000100
[2025-08-27 01:00:44,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021624] [Batch 00064/03080] [00:00:47/00:37:05, 0.738s/it]: train_loss_raw=1.2471, running_loss=1.3274, LR=0.000100
[2025-08-27 01:00:50,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021632] [Batch 00072/03080] [00:00:53/00:37:09, 0.741s/it]: train_loss_raw=1.3820, running_loss=1.3284, LR=0.000100
[2025-08-27 01:00:56,456][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021640] [Batch 00080/03080] [00:00:59/00:36:58, 0.739s/it]: train_loss_raw=1.2213, running_loss=1.3248, LR=0.000100
[2025-08-27 01:01:02,482][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021648] [Batch 00088/03080] [00:01:05/00:36:56, 0.741s/it]: train_loss_raw=1.3503, running_loss=1.3250, LR=0.000100
[2025-08-27 01:01:08,249][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021656] [Batch 00096/03080] [00:01:10/00:36:45, 0.739s/it]: train_loss_raw=1.2340, running_loss=1.3238, LR=0.000100
[2025-08-27 01:01:14,206][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021664] [Batch 00104/03080] [00:01:16/00:36:40, 0.739s/it]: train_loss_raw=1.4070, running_loss=1.3248, LR=0.000100
[2025-08-27 01:01:20,080][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021672] [Batch 00112/03080] [00:01:22/00:36:33, 0.739s/it]: train_loss_raw=1.3216, running_loss=1.3238, LR=0.000100
[2025-08-27 01:01:26,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021680] [Batch 00120/03080] [00:01:29/00:36:35, 0.742s/it]: train_loss_raw=1.3089, running_loss=1.3231, LR=0.000100
[2025-08-27 01:01:32,241][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021688] [Batch 00128/03080] [00:01:34/00:36:29, 0.742s/it]: train_loss_raw=1.3608, running_loss=1.3242, LR=0.000100
[2025-08-27 01:01:38,237][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021696] [Batch 00136/03080] [00:01:40/00:36:24, 0.742s/it]: train_loss_raw=1.3252, running_loss=1.3241, LR=0.000100
[2025-08-27 01:01:43,968][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021704] [Batch 00144/03080] [00:01:46/00:36:14, 0.741s/it]: train_loss_raw=1.3526, running_loss=1.3254, LR=0.000100
[2025-08-27 01:01:49,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021712] [Batch 00152/03080] [00:01:52/00:36:06, 0.740s/it]: train_loss_raw=1.3793, running_loss=1.3246, LR=0.000100
[2025-08-27 01:01:55,586][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021720] [Batch 00160/03080] [00:01:58/00:35:58, 0.739s/it]: train_loss_raw=1.2701, running_loss=1.3236, LR=0.000100
[2025-08-27 01:02:01,422][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021728] [Batch 00168/03080] [00:02:04/00:35:51, 0.739s/it]: train_loss_raw=1.4317, running_loss=1.3218, LR=0.000100
[2025-08-27 01:02:07,510][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021736] [Batch 00176/03080] [00:02:10/00:35:48, 0.740s/it]: train_loss_raw=1.3473, running_loss=1.3240, LR=0.000100
[2025-08-27 01:02:13,694][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021744] [Batch 00184/03080] [00:02:16/00:35:46, 0.741s/it]: train_loss_raw=1.5120, running_loss=1.3274, LR=0.000100
[2025-08-27 01:02:19,865][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021752] [Batch 00192/03080] [00:02:22/00:35:44, 0.743s/it]: train_loss_raw=1.2472, running_loss=1.3239, LR=0.000100
[2025-08-27 01:02:25,862][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021760] [Batch 00200/03080] [00:02:28/00:35:39, 0.743s/it]: train_loss_raw=1.2634, running_loss=1.3201, LR=0.000100
[2025-08-27 01:02:31,711][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021768] [Batch 00208/03080] [00:02:34/00:35:32, 0.742s/it]: train_loss_raw=1.2350, running_loss=1.3211, LR=0.000100
[2025-08-27 01:02:37,473][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021776] [Batch 00216/03080] [00:02:40/00:35:23, 0.742s/it]: train_loss_raw=1.2929, running_loss=1.3202, LR=0.000100
[2025-08-27 01:02:43,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021784] [Batch 00224/03080] [00:02:45/00:35:16, 0.741s/it]: train_loss_raw=1.4414, running_loss=1.3230, LR=0.000100
[2025-08-27 01:02:49,079][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021792] [Batch 00232/03080] [00:02:51/00:35:08, 0.740s/it]: train_loss_raw=1.3267, running_loss=1.3213, LR=0.000100
[2025-08-27 01:02:54,972][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021800] [Batch 00240/03080] [00:02:57/00:35:02, 0.740s/it]: train_loss_raw=1.2953, running_loss=1.3208, LR=0.000100
[2025-08-27 01:03:00,958][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021808] [Batch 00248/03080] [00:03:03/00:34:57, 0.741s/it]: train_loss_raw=1.3668, running_loss=1.3194, LR=0.000100
[2025-08-27 01:03:06,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021816] [Batch 00256/03080] [00:03:09/00:34:49, 0.740s/it]: train_loss_raw=1.3691, running_loss=1.3206, LR=0.000100
[2025-08-27 01:03:12,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021824] [Batch 00264/03080] [00:03:15/00:34:43, 0.740s/it]: train_loss_raw=1.3020, running_loss=1.3216, LR=0.000100
[2025-08-27 01:03:18,591][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021832] [Batch 00272/03080] [00:03:21/00:34:38, 0.740s/it]: train_loss_raw=1.3737, running_loss=1.3217, LR=0.000100
[2025-08-27 01:03:24,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021840] [Batch 00280/03080] [00:03:27/00:34:30, 0.739s/it]: train_loss_raw=1.3867, running_loss=1.3209, LR=0.000100
[2025-08-27 01:03:30,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021848] [Batch 00288/03080] [00:03:32/00:34:24, 0.740s/it]: train_loss_raw=1.3031, running_loss=1.3182, LR=0.000100
[2025-08-27 01:03:36,258][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021856] [Batch 00296/03080] [00:03:38/00:34:19, 0.740s/it]: train_loss_raw=1.3769, running_loss=1.3210, LR=0.000100
[2025-08-27 01:03:42,074][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021864] [Batch 00304/03080] [00:03:44/00:34:12, 0.739s/it]: train_loss_raw=1.1610, running_loss=1.3176, LR=0.000100
[2025-08-27 01:03:47,975][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021872] [Batch 00312/03080] [00:03:50/00:34:06, 0.739s/it]: train_loss_raw=1.3813, running_loss=1.3189, LR=0.000100
[2025-08-27 01:03:53,923][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021880] [Batch 00320/03080] [00:03:56/00:34:00, 0.739s/it]: train_loss_raw=1.3999, running_loss=1.3191, LR=0.000100
[2025-08-27 01:03:59,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021888] [Batch 00328/03080] [00:04:02/00:33:54, 0.739s/it]: train_loss_raw=1.2982, running_loss=1.3225, LR=0.000100
[2025-08-27 01:04:05,524][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021896] [Batch 00336/03080] [00:04:08/00:33:47, 0.739s/it]: train_loss_raw=1.2274, running_loss=1.3210, LR=0.000100
[2025-08-27 01:04:11,377][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021904] [Batch 00344/03080] [00:04:14/00:33:40, 0.739s/it]: train_loss_raw=1.3146, running_loss=1.3225, LR=0.000100
[2025-08-27 01:04:17,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021912] [Batch 00352/03080] [00:04:19/00:33:33, 0.738s/it]: train_loss_raw=1.3037, running_loss=1.3246, LR=0.000100
[2025-08-27 01:04:22,960][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021920] [Batch 00360/03080] [00:04:25/00:33:27, 0.738s/it]: train_loss_raw=1.3540, running_loss=1.3243, LR=0.000100
[2025-08-27 01:04:28,686][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021928] [Batch 00368/03080] [00:04:31/00:33:19, 0.737s/it]: train_loss_raw=1.5210, running_loss=1.3230, LR=0.000100
[2025-08-27 01:04:34,787][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021936] [Batch 00376/03080] [00:04:37/00:33:15, 0.738s/it]: train_loss_raw=1.2799, running_loss=1.3250, LR=0.000100
[2025-08-27 01:04:40,730][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021944] [Batch 00384/03080] [00:04:43/00:33:09, 0.738s/it]: train_loss_raw=1.2878, running_loss=1.3238, LR=0.000100
[2025-08-27 01:04:46,623][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021952] [Batch 00392/03080] [00:04:49/00:33:03, 0.738s/it]: train_loss_raw=1.3185, running_loss=1.3241, LR=0.000100
[2025-08-27 01:04:52,257][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021960] [Batch 00400/03080] [00:04:54/00:32:56, 0.737s/it]: train_loss_raw=1.3815, running_loss=1.3237, LR=0.000100
[2025-08-27 01:04:58,113][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021968] [Batch 00408/03080] [00:05:00/00:32:50, 0.737s/it]: train_loss_raw=1.3264, running_loss=1.3220, LR=0.000100
[2025-08-27 01:05:03,877][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021976] [Batch 00416/03080] [00:05:06/00:32:43, 0.737s/it]: train_loss_raw=1.4008, running_loss=1.3201, LR=0.000100
[2025-08-27 01:05:09,649][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021984] [Batch 00424/03080] [00:05:12/00:32:36, 0.737s/it]: train_loss_raw=1.4177, running_loss=1.3211, LR=0.000100
[2025-08-27 01:05:15,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021992] [Batch 00432/03080] [00:05:18/00:32:29, 0.736s/it]: train_loss_raw=1.1650, running_loss=1.3197, LR=0.000100
[2025-08-27 01:05:21,319][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022000] [Batch 00440/03080] [00:05:24/00:32:24, 0.736s/it]: train_loss_raw=1.3443, running_loss=1.3178, LR=0.000100
[2025-08-27 01:05:31,232][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022008] [Batch 00448/03080] [00:05:33/00:32:41, 0.745s/it]: train_loss_raw=1.2346, running_loss=1.3179, LR=0.000100
[2025-08-27 01:05:37,075][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022016] [Batch 00456/03080] [00:05:39/00:32:35, 0.745s/it]: train_loss_raw=1.3761, running_loss=1.3166, LR=0.000100
[2025-08-27 01:05:43,111][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022024] [Batch 00464/03080] [00:05:45/00:32:29, 0.745s/it]: train_loss_raw=1.2464, running_loss=1.3161, LR=0.000100
[2025-08-27 01:05:48,993][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022032] [Batch 00472/03080] [00:05:51/00:32:23, 0.745s/it]: train_loss_raw=1.2885, running_loss=1.3133, LR=0.000100
[2025-08-27 01:05:54,819][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022040] [Batch 00480/03080] [00:05:57/00:32:16, 0.745s/it]: train_loss_raw=1.3028, running_loss=1.3147, LR=0.000100
[2025-08-27 01:06:01,131][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022048] [Batch 00488/03080] [00:06:03/00:32:12, 0.746s/it]: train_loss_raw=1.2412, running_loss=1.3134, LR=0.000100
[2025-08-27 01:06:07,123][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022056] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=1.2783, running_loss=1.3106, LR=0.000100
[2025-08-27 01:06:13,199][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022064] [Batch 00504/03080] [00:06:15/00:32:01, 0.746s/it]: train_loss_raw=1.2333, running_loss=1.3101, LR=0.000100
[2025-08-27 01:06:18,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022072] [Batch 00512/03080] [00:06:21/00:31:54, 0.745s/it]: train_loss_raw=1.2459, running_loss=1.3083, LR=0.000100
[2025-08-27 01:06:24,770][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022080] [Batch 00520/03080] [00:06:27/00:31:47, 0.745s/it]: train_loss_raw=1.2487, running_loss=1.3082, LR=0.000100
[2025-08-27 01:06:30,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022088] [Batch 00528/03080] [00:06:33/00:31:41, 0.745s/it]: train_loss_raw=1.3007, running_loss=1.3056, LR=0.000100
[2025-08-27 01:06:36,942][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022096] [Batch 00536/03080] [00:06:39/00:31:36, 0.746s/it]: train_loss_raw=1.2922, running_loss=1.3042, LR=0.000100
[2025-08-27 01:06:43,039][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022104] [Batch 00544/03080] [00:06:45/00:31:31, 0.746s/it]: train_loss_raw=1.3579, running_loss=1.3055, LR=0.000100
[2025-08-27 01:06:49,084][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022112] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=1.2862, running_loss=1.3067, LR=0.000100
[2025-08-27 01:06:55,186][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022120] [Batch 00560/03080] [00:06:57/00:31:20, 0.746s/it]: train_loss_raw=1.2157, running_loss=1.3052, LR=0.000100
[2025-08-27 01:07:01,013][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022128] [Batch 00568/03080] [00:07:03/00:31:13, 0.746s/it]: train_loss_raw=1.2490, running_loss=1.3062, LR=0.000100
[2025-08-27 01:07:07,012][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022136] [Batch 00576/03080] [00:07:09/00:31:08, 0.746s/it]: train_loss_raw=1.3635, running_loss=1.3076, LR=0.000100
[2025-08-27 01:07:13,142][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022144] [Batch 00584/03080] [00:07:15/00:31:02, 0.746s/it]: train_loss_raw=1.2464, running_loss=1.3075, LR=0.000100
[2025-08-27 01:07:19,452][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022152] [Batch 00592/03080] [00:07:22/00:30:58, 0.747s/it]: train_loss_raw=1.2262, running_loss=1.3080, LR=0.000100
[2025-08-27 01:07:25,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022160] [Batch 00600/03080] [00:07:28/00:30:52, 0.747s/it]: train_loss_raw=1.3073, running_loss=1.3085, LR=0.000100
[2025-08-27 01:07:31,196][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022168] [Batch 00608/03080] [00:07:33/00:30:45, 0.747s/it]: train_loss_raw=1.2983, running_loss=1.3080, LR=0.000100
[2025-08-27 01:07:37,118][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022176] [Batch 00616/03080] [00:07:39/00:30:39, 0.746s/it]: train_loss_raw=1.3190, running_loss=1.3067, LR=0.000100
[2025-08-27 01:07:43,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022184] [Batch 00624/03080] [00:07:46/00:30:34, 0.747s/it]: train_loss_raw=1.2997, running_loss=1.3041, LR=0.000100
[2025-08-27 01:07:48,970][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022192] [Batch 00632/03080] [00:07:51/00:30:26, 0.746s/it]: train_loss_raw=1.2616, running_loss=1.3005, LR=0.000100
[2025-08-27 01:07:54,638][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022200] [Batch 00640/03080] [00:07:57/00:30:19, 0.746s/it]: train_loss_raw=1.3584, running_loss=1.3038, LR=0.000100
[2025-08-27 01:08:00,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022208] [Batch 00648/03080] [00:08:03/00:30:12, 0.745s/it]: train_loss_raw=1.3636, running_loss=1.3035, LR=0.000100
[2025-08-27 01:08:06,021][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022216] [Batch 00656/03080] [00:08:08/00:30:05, 0.745s/it]: train_loss_raw=1.2951, running_loss=1.3019, LR=0.000100
[2025-08-27 01:08:11,666][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022224] [Batch 00664/03080] [00:08:14/00:29:58, 0.745s/it]: train_loss_raw=1.2776, running_loss=1.3035, LR=0.000100
[2025-08-27 01:08:17,416][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022232] [Batch 00672/03080] [00:08:20/00:29:52, 0.744s/it]: train_loss_raw=1.2962, running_loss=1.3020, LR=0.000100
[2025-08-27 01:08:23,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022240] [Batch 00680/03080] [00:08:25/00:29:45, 0.744s/it]: train_loss_raw=1.4240, running_loss=1.3066, LR=0.000100
[2025-08-27 01:08:29,160][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022248] [Batch 00688/03080] [00:08:31/00:29:39, 0.744s/it]: train_loss_raw=1.3640, running_loss=1.3040, LR=0.000100
[2025-08-27 01:08:34,910][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022256] [Batch 00696/03080] [00:08:37/00:29:32, 0.744s/it]: train_loss_raw=1.3765, running_loss=1.3063, LR=0.000100
[2025-08-27 01:08:40,770][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022264] [Batch 00704/03080] [00:08:43/00:29:26, 0.744s/it]: train_loss_raw=1.2199, running_loss=1.3032, LR=0.000100
[2025-08-27 01:08:46,667][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022272] [Batch 00712/03080] [00:08:49/00:29:20, 0.743s/it]: train_loss_raw=1.2875, running_loss=1.3039, LR=0.000100
[2025-08-27 01:08:52,610][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022280] [Batch 00720/03080] [00:08:55/00:29:14, 0.743s/it]: train_loss_raw=1.3412, running_loss=1.3045, LR=0.000100
[2025-08-27 01:08:58,725][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022288] [Batch 00728/03080] [00:09:01/00:29:09, 0.744s/it]: train_loss_raw=1.3004, running_loss=1.3054, LR=0.000100
[2025-08-27 01:09:04,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022296] [Batch 00736/03080] [00:09:07/00:29:03, 0.744s/it]: train_loss_raw=1.3250, running_loss=1.3050, LR=0.000100
[2025-08-27 01:09:10,598][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022304] [Batch 00744/03080] [00:09:13/00:28:57, 0.744s/it]: train_loss_raw=1.2661, running_loss=1.3055, LR=0.000100
[2025-08-27 01:09:16,269][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022312] [Batch 00752/03080] [00:09:18/00:28:50, 0.743s/it]: train_loss_raw=1.4080, running_loss=1.3063, LR=0.000100
[2025-08-27 01:09:22,029][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022320] [Batch 00760/03080] [00:09:24/00:28:43, 0.743s/it]: train_loss_raw=1.2666, running_loss=1.3071, LR=0.000100
[2025-08-27 01:09:28,033][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022328] [Batch 00768/03080] [00:09:30/00:28:38, 0.743s/it]: train_loss_raw=1.3243, running_loss=1.3107, LR=0.000100
[2025-08-27 01:09:34,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022336] [Batch 00776/03080] [00:09:36/00:28:32, 0.743s/it]: train_loss_raw=1.1608, running_loss=1.3110, LR=0.000100
[2025-08-27 01:09:39,821][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022344] [Batch 00784/03080] [00:09:42/00:28:25, 0.743s/it]: train_loss_raw=1.3081, running_loss=1.3128, LR=0.000100
[2025-08-27 01:09:45,922][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022352] [Batch 00792/03080] [00:09:48/00:28:20, 0.743s/it]: train_loss_raw=1.2249, running_loss=1.3102, LR=0.000100
[2025-08-27 01:09:51,993][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022360] [Batch 00800/03080] [00:09:54/00:28:14, 0.743s/it]: train_loss_raw=1.2158, running_loss=1.3094, LR=0.000100
[2025-08-27 01:09:58,006][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022368] [Batch 00808/03080] [00:10:00/00:28:09, 0.743s/it]: train_loss_raw=1.3757, running_loss=1.3080, LR=0.000100
[2025-08-27 01:10:03,906][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022376] [Batch 00816/03080] [00:10:06/00:28:03, 0.743s/it]: train_loss_raw=1.2491, running_loss=1.3086, LR=0.000100
[2025-08-27 01:10:09,687][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022384] [Batch 00824/03080] [00:10:12/00:27:56, 0.743s/it]: train_loss_raw=1.3410, running_loss=1.3088, LR=0.000100
[2025-08-27 01:10:15,545][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022392] [Batch 00832/03080] [00:10:18/00:27:50, 0.743s/it]: train_loss_raw=1.3613, running_loss=1.3121, LR=0.000100
[2025-08-27 01:10:21,437][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022400] [Batch 00840/03080] [00:10:24/00:27:44, 0.743s/it]: train_loss_raw=1.2633, running_loss=1.3121, LR=0.000100
[2025-08-27 01:10:27,397][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022408] [Batch 00848/03080] [00:10:30/00:27:38, 0.743s/it]: train_loss_raw=1.2168, running_loss=1.3097, LR=0.000100
[2025-08-27 01:10:33,374][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022416] [Batch 00856/03080] [00:10:36/00:27:32, 0.743s/it]: train_loss_raw=1.3428, running_loss=1.3111, LR=0.000100
[2025-08-27 01:10:39,255][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022424] [Batch 00864/03080] [00:10:41/00:27:26, 0.743s/it]: train_loss_raw=1.2194, running_loss=1.3109, LR=0.000100
[2025-08-27 01:10:45,108][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022432] [Batch 00872/03080] [00:10:47/00:27:20, 0.743s/it]: train_loss_raw=1.1956, running_loss=1.3112, LR=0.000100
[2025-08-27 01:10:50,933][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022440] [Batch 00880/03080] [00:10:53/00:27:14, 0.743s/it]: train_loss_raw=1.2456, running_loss=1.3106, LR=0.000100
[2025-08-27 01:10:56,651][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022448] [Batch 00888/03080] [00:10:59/00:27:07, 0.743s/it]: train_loss_raw=1.2449, running_loss=1.3092, LR=0.000100
[2025-08-27 01:11:02,542][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022456] [Batch 00896/03080] [00:11:05/00:27:01, 0.742s/it]: train_loss_raw=1.2756, running_loss=1.3077, LR=0.000100
[2025-08-27 01:11:08,647][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022464] [Batch 00904/03080] [00:11:11/00:26:55, 0.743s/it]: train_loss_raw=1.1418, running_loss=1.3059, LR=0.000100
[2025-08-27 01:11:14,439][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022472] [Batch 00912/03080] [00:11:17/00:26:49, 0.742s/it]: train_loss_raw=1.4106, running_loss=1.3083, LR=0.000100
[2025-08-27 01:11:20,297][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022480] [Batch 00920/03080] [00:11:22/00:26:43, 0.742s/it]: train_loss_raw=1.3151, running_loss=1.3093, LR=0.000100
[2025-08-27 01:11:26,241][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022488] [Batch 00928/03080] [00:11:28/00:26:37, 0.742s/it]: train_loss_raw=1.2274, running_loss=1.3114, LR=0.000100
[2025-08-27 01:11:32,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022496] [Batch 00936/03080] [00:11:34/00:26:31, 0.742s/it]: train_loss_raw=1.2788, running_loss=1.3090, LR=0.000100
[2025-08-27 01:11:38,045][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022504] [Batch 00944/03080] [00:11:40/00:26:25, 0.742s/it]: train_loss_raw=1.2372, running_loss=1.3102, LR=0.000100
[2025-08-27 01:11:43,955][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022512] [Batch 00952/03080] [00:11:46/00:26:19, 0.742s/it]: train_loss_raw=1.2160, running_loss=1.3070, LR=0.000100
[2025-08-27 01:11:49,721][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022520] [Batch 00960/03080] [00:11:52/00:26:13, 0.742s/it]: train_loss_raw=1.3305, running_loss=1.3066, LR=0.000100
[2025-08-27 01:11:56,029][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022528] [Batch 00968/03080] [00:11:58/00:26:08, 0.742s/it]: train_loss_raw=1.3329, running_loss=1.3082, LR=0.000100
[2025-08-27 01:12:01,978][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022536] [Batch 00976/03080] [00:12:04/00:26:02, 0.742s/it]: train_loss_raw=1.3874, running_loss=1.3094, LR=0.000100
[2025-08-27 01:12:07,862][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022544] [Batch 00984/03080] [00:12:10/00:25:56, 0.742s/it]: train_loss_raw=1.3400, running_loss=1.3114, LR=0.000100
[2025-08-27 01:12:13,882][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022552] [Batch 00992/03080] [00:12:16/00:25:50, 0.743s/it]: train_loss_raw=1.3101, running_loss=1.3097, LR=0.000100
[2025-08-27 01:12:19,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022560] [Batch 01000/03080] [00:12:22/00:25:44, 0.743s/it]: train_loss_raw=1.2710, running_loss=1.3098, LR=0.000100
[2025-08-27 01:12:25,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022568] [Batch 01008/03080] [00:12:28/00:25:38, 0.743s/it]: train_loss_raw=1.2592, running_loss=1.3072, LR=0.000100
[2025-08-27 01:12:31,850][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022576] [Batch 01016/03080] [00:12:34/00:25:32, 0.743s/it]: train_loss_raw=1.2831, running_loss=1.3043, LR=0.000100
[2025-08-27 01:12:37,768][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022584] [Batch 01024/03080] [00:12:40/00:25:26, 0.743s/it]: train_loss_raw=1.2699, running_loss=1.3035, LR=0.000100
[2025-08-27 01:12:43,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022592] [Batch 01032/03080] [00:12:46/00:25:20, 0.743s/it]: train_loss_raw=1.2417, running_loss=1.2986, LR=0.000100
[2025-08-27 01:12:49,564][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022600] [Batch 01040/03080] [00:12:52/00:25:14, 0.743s/it]: train_loss_raw=1.2692, running_loss=1.2958, LR=0.000100
[2025-08-27 01:12:55,250][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022608] [Batch 01048/03080] [00:12:57/00:25:08, 0.742s/it]: train_loss_raw=1.3123, running_loss=1.2966, LR=0.000100
[2025-08-27 01:13:01,067][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022616] [Batch 01056/03080] [00:13:03/00:25:02, 0.742s/it]: train_loss_raw=1.3453, running_loss=1.2972, LR=0.000100
[2025-08-27 01:13:06,882][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022624] [Batch 01064/03080] [00:13:09/00:24:56, 0.742s/it]: train_loss_raw=1.3293, running_loss=1.2962, LR=0.000100
[2025-08-27 01:13:12,877][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022632] [Batch 01072/03080] [00:13:15/00:24:50, 0.742s/it]: train_loss_raw=1.2637, running_loss=1.2959, LR=0.000100
[2025-08-27 01:13:18,700][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022640] [Batch 01080/03080] [00:13:21/00:24:44, 0.742s/it]: train_loss_raw=1.3740, running_loss=1.2943, LR=0.000100
[2025-08-27 01:13:24,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022648] [Batch 01088/03080] [00:13:27/00:24:38, 0.742s/it]: train_loss_raw=1.2356, running_loss=1.2964, LR=0.000100
[2025-08-27 01:13:30,461][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022656] [Batch 01096/03080] [00:13:33/00:24:31, 0.742s/it]: train_loss_raw=1.3688, running_loss=1.2963, LR=0.000100
[2025-08-27 01:13:36,183][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022664] [Batch 01104/03080] [00:13:38/00:24:25, 0.742s/it]: train_loss_raw=1.3285, running_loss=1.2967, LR=0.000100
[2025-08-27 01:13:42,087][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022672] [Batch 01112/03080] [00:13:44/00:24:19, 0.742s/it]: train_loss_raw=1.1633, running_loss=1.2960, LR=0.000100
[2025-08-27 01:13:48,036][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022680] [Batch 01120/03080] [00:13:50/00:24:13, 0.742s/it]: train_loss_raw=1.2037, running_loss=1.2949, LR=0.000100
[2025-08-27 01:13:53,890][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022688] [Batch 01128/03080] [00:13:56/00:24:07, 0.742s/it]: train_loss_raw=1.3727, running_loss=1.2946, LR=0.000100
[2025-08-27 01:13:59,824][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022696] [Batch 01136/03080] [00:14:02/00:24:01, 0.742s/it]: train_loss_raw=1.2946, running_loss=1.2973, LR=0.000100
[2025-08-27 01:14:05,652][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022704] [Batch 01144/03080] [00:14:08/00:23:55, 0.742s/it]: train_loss_raw=1.2220, running_loss=1.2965, LR=0.000100
[2025-08-27 01:14:11,547][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022712] [Batch 01152/03080] [00:14:14/00:23:49, 0.742s/it]: train_loss_raw=1.2606, running_loss=1.2958, LR=0.000100
[2025-08-27 01:14:17,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022720] [Batch 01160/03080] [00:14:20/00:23:43, 0.741s/it]: train_loss_raw=1.1848, running_loss=1.2934, LR=0.000100
[2025-08-27 01:14:23,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022728] [Batch 01168/03080] [00:14:25/00:23:37, 0.741s/it]: train_loss_raw=1.2764, running_loss=1.2937, LR=0.000100
[2025-08-27 01:14:29,491][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022736] [Batch 01176/03080] [00:14:32/00:23:32, 0.742s/it]: train_loss_raw=1.2546, running_loss=1.2956, LR=0.000100
[2025-08-27 01:14:35,448][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022744] [Batch 01184/03080] [00:14:38/00:23:26, 0.742s/it]: train_loss_raw=1.3562, running_loss=1.2982, LR=0.000100
[2025-08-27 01:14:41,576][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022752] [Batch 01192/03080] [00:14:44/00:23:20, 0.742s/it]: train_loss_raw=1.2974, running_loss=1.2996, LR=0.000100
[2025-08-27 01:14:47,499][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022760] [Batch 01200/03080] [00:14:50/00:23:14, 0.742s/it]: train_loss_raw=1.2688, running_loss=1.2962, LR=0.000100
[2025-08-27 01:14:53,379][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022768] [Batch 01208/03080] [00:14:56/00:23:08, 0.742s/it]: train_loss_raw=1.3981, running_loss=1.2948, LR=0.000100
[2025-08-27 01:14:59,377][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022776] [Batch 01216/03080] [00:15:02/00:23:02, 0.742s/it]: train_loss_raw=1.2409, running_loss=1.2940, LR=0.000100
[2025-08-27 01:15:05,494][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022784] [Batch 01224/03080] [00:15:08/00:22:57, 0.742s/it]: train_loss_raw=1.2435, running_loss=1.2914, LR=0.000100
[2025-08-27 01:15:11,356][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022792] [Batch 01232/03080] [00:15:14/00:22:51, 0.742s/it]: train_loss_raw=1.2675, running_loss=1.2918, LR=0.000100
[2025-08-27 01:15:17,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022800] [Batch 01240/03080] [00:15:20/00:22:45, 0.742s/it]: train_loss_raw=1.3422, running_loss=1.2938, LR=0.000100
[2025-08-27 01:15:23,478][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022808] [Batch 01248/03080] [00:15:26/00:22:39, 0.742s/it]: train_loss_raw=1.2435, running_loss=1.2937, LR=0.000100
[2025-08-27 01:15:29,226][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022816] [Batch 01256/03080] [00:15:31/00:22:33, 0.742s/it]: train_loss_raw=1.3725, running_loss=1.2936, LR=0.000100
[2025-08-27 01:15:34,798][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022824] [Batch 01264/03080] [00:15:37/00:22:26, 0.742s/it]: train_loss_raw=1.2584, running_loss=1.2910, LR=0.000100
[2025-08-27 01:15:40,565][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022832] [Batch 01272/03080] [00:15:43/00:22:20, 0.742s/it]: train_loss_raw=1.3730, running_loss=1.2927, LR=0.000100
[2025-08-27 01:15:46,469][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022840] [Batch 01280/03080] [00:15:49/00:22:14, 0.742s/it]: train_loss_raw=1.3128, running_loss=1.2942, LR=0.000100
[2025-08-27 01:15:52,499][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022848] [Batch 01288/03080] [00:15:55/00:22:08, 0.742s/it]: train_loss_raw=1.2911, running_loss=1.2955, LR=0.000100
[2025-08-27 01:15:58,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022856] [Batch 01296/03080] [00:16:01/00:22:02, 0.742s/it]: train_loss_raw=1.2314, running_loss=1.2930, LR=0.000100
[2025-08-27 01:16:04,313][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022864] [Batch 01304/03080] [00:16:07/00:21:57, 0.742s/it]: train_loss_raw=1.2761, running_loss=1.2922, LR=0.000100
[2025-08-27 01:16:10,255][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022872] [Batch 01312/03080] [00:16:12/00:21:51, 0.742s/it]: train_loss_raw=1.2932, running_loss=1.2939, LR=0.000100
[2025-08-27 01:16:16,336][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022880] [Batch 01320/03080] [00:16:19/00:21:45, 0.742s/it]: train_loss_raw=1.2798, running_loss=1.2946, LR=0.000100
[2025-08-27 01:16:22,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022888] [Batch 01328/03080] [00:16:25/00:21:39, 0.742s/it]: train_loss_raw=1.2526, running_loss=1.2941, LR=0.000100
[2025-08-27 01:16:28,296][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022896] [Batch 01336/03080] [00:16:30/00:21:33, 0.742s/it]: train_loss_raw=1.3692, running_loss=1.2924, LR=0.000100
[2025-08-27 01:16:34,245][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022904] [Batch 01344/03080] [00:16:36/00:21:27, 0.742s/it]: train_loss_raw=1.4881, running_loss=1.2921, LR=0.000100
[2025-08-27 01:16:40,117][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022912] [Batch 01352/03080] [00:16:42/00:21:21, 0.742s/it]: train_loss_raw=1.3611, running_loss=1.2926, LR=0.000100
[2025-08-27 01:16:46,152][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022920] [Batch 01360/03080] [00:16:48/00:21:15, 0.742s/it]: train_loss_raw=1.2386, running_loss=1.2914, LR=0.000100
[2025-08-27 01:16:52,021][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022928] [Batch 01368/03080] [00:16:54/00:21:09, 0.742s/it]: train_loss_raw=1.2138, running_loss=1.2880, LR=0.000100
[2025-08-27 01:16:58,025][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022936] [Batch 01376/03080] [00:17:00/00:21:04, 0.742s/it]: train_loss_raw=1.2930, running_loss=1.2887, LR=0.000100
[2025-08-27 01:17:03,908][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022944] [Batch 01384/03080] [00:17:06/00:20:58, 0.742s/it]: train_loss_raw=1.3578, running_loss=1.2886, LR=0.000100
[2025-08-27 01:17:09,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022952] [Batch 01392/03080] [00:17:12/00:20:52, 0.742s/it]: train_loss_raw=1.3884, running_loss=1.2887, LR=0.000100
[2025-08-27 01:17:15,699][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022960] [Batch 01400/03080] [00:17:18/00:20:46, 0.742s/it]: train_loss_raw=1.3665, running_loss=1.2901, LR=0.000100
[2025-08-27 01:17:21,577][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022968] [Batch 01408/03080] [00:17:24/00:20:40, 0.742s/it]: train_loss_raw=1.3520, running_loss=1.2902, LR=0.000100
[2025-08-27 01:17:27,609][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022976] [Batch 01416/03080] [00:17:30/00:20:34, 0.742s/it]: train_loss_raw=1.1152, running_loss=1.2893, LR=0.000100
[2025-08-27 01:17:33,820][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022984] [Batch 01424/03080] [00:17:36/00:20:28, 0.742s/it]: train_loss_raw=1.2875, running_loss=1.2892, LR=0.000100
[2025-08-27 01:17:40,125][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022992] [Batch 01432/03080] [00:17:42/00:20:23, 0.742s/it]: train_loss_raw=1.2546, running_loss=1.2885, LR=0.000100
[2025-08-27 01:17:46,239][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023000] [Batch 01440/03080] [00:17:48/00:20:17, 0.742s/it]: train_loss_raw=1.3625, running_loss=1.2874, LR=0.000100
[2025-08-27 01:17:52,245][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023008] [Batch 01448/03080] [00:17:54/00:20:11, 0.742s/it]: train_loss_raw=1.2286, running_loss=1.2863, LR=0.000100
[2025-08-27 01:17:58,224][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023016] [Batch 01456/03080] [00:18:00/00:20:05, 0.742s/it]: train_loss_raw=1.3728, running_loss=1.2898, LR=0.000100
[2025-08-27 01:18:04,166][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023024] [Batch 01464/03080] [00:18:06/00:19:59, 0.742s/it]: train_loss_raw=1.3433, running_loss=1.2860, LR=0.000100
[2025-08-27 01:18:10,100][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023032] [Batch 01472/03080] [00:18:12/00:19:53, 0.742s/it]: train_loss_raw=1.3607, running_loss=1.2848, LR=0.000100
[2025-08-27 01:18:16,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023040] [Batch 01480/03080] [00:18:18/00:19:47, 0.742s/it]: train_loss_raw=1.1431, running_loss=1.2838, LR=0.000100
[2025-08-27 01:18:22,151][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023048] [Batch 01488/03080] [00:18:24/00:19:42, 0.743s/it]: train_loss_raw=1.3263, running_loss=1.2845, LR=0.000100
[2025-08-27 01:18:27,800][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023056] [Batch 01496/03080] [00:18:30/00:19:35, 0.742s/it]: train_loss_raw=1.1823, running_loss=1.2856, LR=0.000100
[2025-08-27 01:18:33,775][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023064] [Batch 01504/03080] [00:18:36/00:19:29, 0.742s/it]: train_loss_raw=1.2394, running_loss=1.2845, LR=0.000100
[2025-08-27 01:18:39,876][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023072] [Batch 01512/03080] [00:18:42/00:19:24, 0.742s/it]: train_loss_raw=1.2456, running_loss=1.2838, LR=0.000100
[2025-08-27 01:18:45,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023080] [Batch 01520/03080] [00:18:48/00:19:18, 0.742s/it]: train_loss_raw=1.2600, running_loss=1.2860, LR=0.000100
[2025-08-27 01:18:51,912][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023088] [Batch 01528/03080] [00:18:54/00:19:12, 0.743s/it]: train_loss_raw=1.2043, running_loss=1.2868, LR=0.000100
[2025-08-27 01:18:57,781][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023096] [Batch 01536/03080] [00:19:00/00:19:06, 0.743s/it]: train_loss_raw=1.1717, running_loss=1.2842, LR=0.000100
[2025-08-27 01:19:03,879][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023104] [Batch 01544/03080] [00:19:06/00:19:00, 0.743s/it]: train_loss_raw=1.2029, running_loss=1.2873, LR=0.000100
[2025-08-27 01:19:09,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023112] [Batch 01552/03080] [00:19:12/00:18:54, 0.743s/it]: train_loss_raw=1.3129, running_loss=1.2880, LR=0.000100
[2025-08-27 01:19:15,890][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023120] [Batch 01560/03080] [00:19:18/00:18:48, 0.743s/it]: train_loss_raw=1.2828, running_loss=1.2877, LR=0.000100
[2025-08-27 01:19:21,987][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023128] [Batch 01568/03080] [00:19:24/00:18:43, 0.743s/it]: train_loss_raw=1.2741, running_loss=1.2871, LR=0.000100
[2025-08-27 01:19:27,671][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023136] [Batch 01576/03080] [00:19:30/00:18:36, 0.743s/it]: train_loss_raw=1.4386, running_loss=1.2858, LR=0.000100
[2025-08-27 01:19:33,332][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023144] [Batch 01584/03080] [00:19:36/00:18:30, 0.742s/it]: train_loss_raw=1.3022, running_loss=1.2897, LR=0.000100
[2025-08-27 01:19:39,186][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023152] [Batch 01592/03080] [00:19:41/00:18:24, 0.742s/it]: train_loss_raw=1.2578, running_loss=1.2879, LR=0.000100
[2025-08-27 01:19:45,083][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023160] [Batch 01600/03080] [00:19:47/00:18:18, 0.742s/it]: train_loss_raw=1.3765, running_loss=1.2893, LR=0.000100
[2025-08-27 01:19:50,898][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023168] [Batch 01608/03080] [00:19:53/00:18:12, 0.742s/it]: train_loss_raw=1.2635, running_loss=1.2888, LR=0.000100
[2025-08-27 01:19:56,771][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023176] [Batch 01616/03080] [00:19:59/00:18:06, 0.742s/it]: train_loss_raw=1.2624, running_loss=1.2874, LR=0.000100
[2025-08-27 01:20:02,521][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023184] [Batch 01624/03080] [00:20:05/00:18:00, 0.742s/it]: train_loss_raw=1.2780, running_loss=1.2849, LR=0.000100
[2025-08-27 01:20:08,324][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023192] [Batch 01632/03080] [00:20:11/00:17:54, 0.742s/it]: train_loss_raw=1.2729, running_loss=1.2851, LR=0.000100
[2025-08-27 01:20:14,080][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023200] [Batch 01640/03080] [00:20:16/00:17:48, 0.742s/it]: train_loss_raw=1.3073, running_loss=1.2844, LR=0.000100
[2025-08-27 01:20:19,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023208] [Batch 01648/03080] [00:20:22/00:17:42, 0.742s/it]: train_loss_raw=1.3033, running_loss=1.2825, LR=0.000100
[2025-08-27 01:20:25,691][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023216] [Batch 01656/03080] [00:20:28/00:17:36, 0.742s/it]: train_loss_raw=1.3862, running_loss=1.2814, LR=0.000100
[2025-08-27 01:20:31,552][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023224] [Batch 01664/03080] [00:20:34/00:17:30, 0.742s/it]: train_loss_raw=1.2884, running_loss=1.2806, LR=0.000100
[2025-08-27 01:20:37,482][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023232] [Batch 01672/03080] [00:20:40/00:17:24, 0.742s/it]: train_loss_raw=1.1931, running_loss=1.2801, LR=0.000100
[2025-08-27 01:20:43,507][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023240] [Batch 01680/03080] [00:20:46/00:17:18, 0.742s/it]: train_loss_raw=1.3092, running_loss=1.2831, LR=0.000100
[2025-08-27 01:20:49,611][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023248] [Batch 01688/03080] [00:20:52/00:17:12, 0.742s/it]: train_loss_raw=1.1496, running_loss=1.2811, LR=0.000100
[2025-08-27 01:20:55,539][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023256] [Batch 01696/03080] [00:20:58/00:17:06, 0.742s/it]: train_loss_raw=1.3830, running_loss=1.2801, LR=0.000100
[2025-08-27 01:21:01,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023264] [Batch 01704/03080] [00:21:04/00:17:00, 0.742s/it]: train_loss_raw=1.2073, running_loss=1.2804, LR=0.000100
[2025-08-27 01:21:07,480][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023272] [Batch 01712/03080] [00:21:10/00:16:54, 0.742s/it]: train_loss_raw=1.3381, running_loss=1.2824, LR=0.000100
[2025-08-27 01:21:13,543][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023280] [Batch 01720/03080] [00:21:16/00:16:49, 0.742s/it]: train_loss_raw=1.3461, running_loss=1.2822, LR=0.000100
[2025-08-27 01:21:19,529][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023288] [Batch 01728/03080] [00:21:22/00:16:43, 0.742s/it]: train_loss_raw=1.2165, running_loss=1.2788, LR=0.000100
[2025-08-27 01:21:25,446][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023296] [Batch 01736/03080] [00:21:28/00:16:37, 0.742s/it]: train_loss_raw=1.2274, running_loss=1.2779, LR=0.000100
[2025-08-27 01:21:31,325][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023304] [Batch 01744/03080] [00:21:34/00:16:31, 0.742s/it]: train_loss_raw=1.1634, running_loss=1.2775, LR=0.000100
[2025-08-27 01:21:37,143][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023312] [Batch 01752/03080] [00:21:39/00:16:25, 0.742s/it]: train_loss_raw=1.1965, running_loss=1.2787, LR=0.000100
[2025-08-27 01:21:42,957][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023320] [Batch 01760/03080] [00:21:45/00:16:19, 0.742s/it]: train_loss_raw=1.2959, running_loss=1.2790, LR=0.000100
[2025-08-27 01:21:49,096][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023328] [Batch 01768/03080] [00:21:51/00:16:13, 0.742s/it]: train_loss_raw=1.2370, running_loss=1.2772, LR=0.000100
[2025-08-27 01:21:55,048][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023336] [Batch 01776/03080] [00:21:57/00:16:07, 0.742s/it]: train_loss_raw=1.3265, running_loss=1.2770, LR=0.000100
[2025-08-27 01:22:00,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023344] [Batch 01784/03080] [00:22:03/00:16:01, 0.742s/it]: train_loss_raw=1.2790, running_loss=1.2760, LR=0.000100
[2025-08-27 01:22:06,703][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023352] [Batch 01792/03080] [00:22:09/00:15:55, 0.742s/it]: train_loss_raw=1.2756, running_loss=1.2753, LR=0.000100
[2025-08-27 01:22:12,703][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023360] [Batch 01800/03080] [00:22:15/00:15:49, 0.742s/it]: train_loss_raw=1.3440, running_loss=1.2780, LR=0.000100
[2025-08-27 01:22:18,546][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023368] [Batch 01808/03080] [00:22:21/00:15:43, 0.742s/it]: train_loss_raw=1.4139, running_loss=1.2801, LR=0.000100
[2025-08-27 01:22:24,285][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023376] [Batch 01816/03080] [00:22:26/00:15:37, 0.742s/it]: train_loss_raw=1.2036, running_loss=1.2801, LR=0.000100
[2025-08-27 01:22:30,206][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023384] [Batch 01824/03080] [00:22:32/00:15:31, 0.742s/it]: train_loss_raw=1.3625, running_loss=1.2804, LR=0.000100
[2025-08-27 01:22:36,064][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023392] [Batch 01832/03080] [00:22:38/00:15:25, 0.742s/it]: train_loss_raw=1.1665, running_loss=1.2785, LR=0.000100
[2025-08-27 01:22:41,960][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023400] [Batch 01840/03080] [00:22:44/00:15:19, 0.742s/it]: train_loss_raw=1.3047, running_loss=1.2778, LR=0.000100
[2025-08-27 01:22:47,720][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023408] [Batch 01848/03080] [00:22:50/00:15:13, 0.742s/it]: train_loss_raw=1.2347, running_loss=1.2774, LR=0.000100
[2025-08-27 01:22:53,503][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023416] [Batch 01856/03080] [00:22:56/00:15:07, 0.741s/it]: train_loss_raw=1.2257, running_loss=1.2753, LR=0.000100
[2025-08-27 01:22:59,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023424] [Batch 01864/03080] [00:23:01/00:15:01, 0.741s/it]: train_loss_raw=1.3060, running_loss=1.2767, LR=0.000100
[2025-08-27 01:23:05,111][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023432] [Batch 01872/03080] [00:23:07/00:14:55, 0.741s/it]: train_loss_raw=1.2692, running_loss=1.2758, LR=0.000100
[2025-08-27 01:23:10,841][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023440] [Batch 01880/03080] [00:23:13/00:14:49, 0.741s/it]: train_loss_raw=1.3153, running_loss=1.2769, LR=0.000100
[2025-08-27 01:23:16,971][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023448] [Batch 01888/03080] [00:23:19/00:14:43, 0.741s/it]: train_loss_raw=1.2303, running_loss=1.2775, LR=0.000100
[2025-08-27 01:23:23,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023456] [Batch 01896/03080] [00:23:25/00:14:37, 0.742s/it]: train_loss_raw=1.1917, running_loss=1.2770, LR=0.000100
[2025-08-27 01:23:28,989][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023464] [Batch 01904/03080] [00:23:31/00:14:31, 0.741s/it]: train_loss_raw=1.3035, running_loss=1.2791, LR=0.000100
[2025-08-27 01:23:34,937][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023472] [Batch 01912/03080] [00:23:37/00:14:26, 0.741s/it]: train_loss_raw=1.2664, running_loss=1.2780, LR=0.000100
[2025-08-27 01:23:40,644][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023480] [Batch 01920/03080] [00:23:43/00:14:19, 0.741s/it]: train_loss_raw=1.3113, running_loss=1.2794, LR=0.000100
[2025-08-27 01:23:46,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023488] [Batch 01928/03080] [00:23:49/00:14:13, 0.741s/it]: train_loss_raw=1.3505, running_loss=1.2795, LR=0.000100
[2025-08-27 01:23:52,222][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023496] [Batch 01936/03080] [00:23:54/00:14:07, 0.741s/it]: train_loss_raw=1.3434, running_loss=1.2808, LR=0.000100
[2025-08-27 01:23:58,477][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023504] [Batch 01944/03080] [00:24:01/00:14:02, 0.741s/it]: train_loss_raw=1.2797, running_loss=1.2805, LR=0.000100
[2025-08-27 01:24:04,401][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023512] [Batch 01952/03080] [00:24:07/00:13:56, 0.741s/it]: train_loss_raw=1.3540, running_loss=1.2825, LR=0.000100
[2025-08-27 01:24:10,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023520] [Batch 01960/03080] [00:24:12/00:13:50, 0.741s/it]: train_loss_raw=1.3022, running_loss=1.2813, LR=0.000100
[2025-08-27 01:24:15,948][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023528] [Batch 01968/03080] [00:24:18/00:13:44, 0.741s/it]: train_loss_raw=1.2273, running_loss=1.2817, LR=0.000100
[2025-08-27 01:24:22,194][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023536] [Batch 01976/03080] [00:24:24/00:13:38, 0.741s/it]: train_loss_raw=1.2627, running_loss=1.2858, LR=0.000100
[2025-08-27 01:24:28,223][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023544] [Batch 01984/03080] [00:24:30/00:13:32, 0.741s/it]: train_loss_raw=1.2027, running_loss=1.2821, LR=0.000100
[2025-08-27 01:24:34,273][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023552] [Batch 01992/03080] [00:24:36/00:13:26, 0.741s/it]: train_loss_raw=1.2650, running_loss=1.2815, LR=0.000100
[2025-08-27 01:24:40,200][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023560] [Batch 02000/03080] [00:24:42/00:13:20, 0.741s/it]: train_loss_raw=1.1690, running_loss=1.2813, LR=0.000100
[2025-08-27 01:24:46,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023568] [Batch 02008/03080] [00:24:48/00:13:14, 0.741s/it]: train_loss_raw=1.2713, running_loss=1.2809, LR=0.000100
[2025-08-27 01:24:52,168][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023576] [Batch 02016/03080] [00:24:54/00:13:08, 0.742s/it]: train_loss_raw=1.3265, running_loss=1.2786, LR=0.000100
[2025-08-27 01:24:57,984][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023584] [Batch 02024/03080] [00:25:00/00:13:02, 0.741s/it]: train_loss_raw=1.3411, running_loss=1.2792, LR=0.000100
[2025-08-27 01:25:03,820][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023592] [Batch 02032/03080] [00:25:06/00:12:56, 0.741s/it]: train_loss_raw=1.2282, running_loss=1.2777, LR=0.000100
[2025-08-27 01:25:09,762][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023600] [Batch 02040/03080] [00:25:12/00:12:51, 0.741s/it]: train_loss_raw=1.2595, running_loss=1.2771, LR=0.000100
[2025-08-27 01:25:15,663][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023608] [Batch 02048/03080] [00:25:18/00:12:45, 0.741s/it]: train_loss_raw=1.3713, running_loss=1.2780, LR=0.000100
[2025-08-27 01:25:21,354][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023616] [Batch 02056/03080] [00:25:24/00:12:39, 0.741s/it]: train_loss_raw=1.3650, running_loss=1.2772, LR=0.000100
[2025-08-27 01:25:27,257][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023624] [Batch 02064/03080] [00:25:29/00:12:33, 0.741s/it]: train_loss_raw=1.2069, running_loss=1.2756, LR=0.000100
[2025-08-27 01:25:33,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023632] [Batch 02072/03080] [00:25:35/00:12:27, 0.741s/it]: train_loss_raw=1.4183, running_loss=1.2800, LR=0.000100
[2025-08-27 01:25:38,913][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023640] [Batch 02080/03080] [00:25:41/00:12:21, 0.741s/it]: train_loss_raw=1.2418, running_loss=1.2795, LR=0.000100
[2025-08-27 01:25:45,035][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023648] [Batch 02088/03080] [00:25:47/00:12:15, 0.741s/it]: train_loss_raw=1.2385, running_loss=1.2799, LR=0.000100
[2025-08-27 01:25:50,864][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023656] [Batch 02096/03080] [00:25:53/00:12:09, 0.741s/it]: train_loss_raw=1.2099, running_loss=1.2770, LR=0.000100
[2025-08-27 01:25:56,685][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023664] [Batch 02104/03080] [00:25:59/00:12:03, 0.741s/it]: train_loss_raw=1.3101, running_loss=1.2763, LR=0.000100
[2025-08-27 01:26:02,411][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023672] [Batch 02112/03080] [00:26:05/00:11:57, 0.741s/it]: train_loss_raw=1.2523, running_loss=1.2733, LR=0.000100
[2025-08-27 01:26:08,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023680] [Batch 02120/03080] [00:26:11/00:11:51, 0.741s/it]: train_loss_raw=1.3072, running_loss=1.2726, LR=0.000100
[2025-08-27 01:26:14,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023688] [Batch 02128/03080] [00:26:17/00:11:45, 0.741s/it]: train_loss_raw=1.2945, running_loss=1.2725, LR=0.000100
[2025-08-27 01:26:20,044][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023696] [Batch 02136/03080] [00:26:22/00:11:39, 0.741s/it]: train_loss_raw=1.2466, running_loss=1.2714, LR=0.000100
[2025-08-27 01:26:25,819][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023704] [Batch 02144/03080] [00:26:28/00:11:33, 0.741s/it]: train_loss_raw=1.2678, running_loss=1.2705, LR=0.000100
[2025-08-27 01:26:31,686][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023712] [Batch 02152/03080] [00:26:34/00:11:27, 0.741s/it]: train_loss_raw=1.1987, running_loss=1.2702, LR=0.000100
[2025-08-27 01:26:37,514][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023720] [Batch 02160/03080] [00:26:40/00:11:21, 0.741s/it]: train_loss_raw=1.2637, running_loss=1.2701, LR=0.000100
[2025-08-27 01:26:43,453][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023728] [Batch 02168/03080] [00:26:46/00:11:15, 0.741s/it]: train_loss_raw=1.2508, running_loss=1.2701, LR=0.000100
[2025-08-27 01:26:49,366][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023736] [Batch 02176/03080] [00:26:52/00:11:09, 0.741s/it]: train_loss_raw=1.1665, running_loss=1.2665, LR=0.000100
[2025-08-27 01:26:55,224][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023744] [Batch 02184/03080] [00:26:57/00:11:03, 0.741s/it]: train_loss_raw=1.3719, running_loss=1.2688, LR=0.000100
[2025-08-27 01:27:01,147][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023752] [Batch 02192/03080] [00:27:03/00:10:57, 0.741s/it]: train_loss_raw=1.2848, running_loss=1.2689, LR=0.000100
[2025-08-27 01:27:07,158][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023760] [Batch 02200/03080] [00:27:09/00:10:51, 0.741s/it]: train_loss_raw=1.2173, running_loss=1.2684, LR=0.000100
[2025-08-27 01:27:13,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023768] [Batch 02208/03080] [00:27:16/00:10:46, 0.741s/it]: train_loss_raw=1.1900, running_loss=1.2669, LR=0.000100
[2025-08-27 01:27:19,545][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023776] [Batch 02216/03080] [00:27:22/00:10:40, 0.741s/it]: train_loss_raw=1.1574, running_loss=1.2667, LR=0.000100
[2025-08-27 01:27:25,554][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023784] [Batch 02224/03080] [00:27:28/00:10:34, 0.741s/it]: train_loss_raw=1.3093, running_loss=1.2660, LR=0.000100
[2025-08-27 01:27:31,652][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023792] [Batch 02232/03080] [00:27:34/00:10:28, 0.741s/it]: train_loss_raw=1.3688, running_loss=1.2667, LR=0.000100
[2025-08-27 01:27:37,632][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023800] [Batch 02240/03080] [00:27:40/00:10:22, 0.741s/it]: train_loss_raw=1.0650, running_loss=1.2609, LR=0.000100
[2025-08-27 01:27:43,542][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023808] [Batch 02248/03080] [00:27:46/00:10:16, 0.741s/it]: train_loss_raw=1.2927, running_loss=1.2614, LR=0.000100
[2025-08-27 01:27:49,605][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023816] [Batch 02256/03080] [00:27:52/00:10:10, 0.741s/it]: train_loss_raw=1.4198, running_loss=1.2639, LR=0.000100
[2025-08-27 01:27:55,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023824] [Batch 02264/03080] [00:27:58/00:10:04, 0.741s/it]: train_loss_raw=1.3307, running_loss=1.2635, LR=0.000100
[2025-08-27 01:28:01,203][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023832] [Batch 02272/03080] [00:28:03/00:09:58, 0.741s/it]: train_loss_raw=1.1989, running_loss=1.2636, LR=0.000100
[2025-08-27 01:28:07,049][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023840] [Batch 02280/03080] [00:28:09/00:09:52, 0.741s/it]: train_loss_raw=1.3319, running_loss=1.2627, LR=0.000100
[2025-08-27 01:28:12,816][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023848] [Batch 02288/03080] [00:28:15/00:09:46, 0.741s/it]: train_loss_raw=1.1882, running_loss=1.2651, LR=0.000100
[2025-08-27 01:28:18,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023856] [Batch 02296/03080] [00:28:21/00:09:40, 0.741s/it]: train_loss_raw=1.3351, running_loss=1.2675, LR=0.000100
[2025-08-27 01:28:24,659][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023864] [Batch 02304/03080] [00:28:27/00:09:35, 0.741s/it]: train_loss_raw=1.1710, running_loss=1.2666, LR=0.000100
[2025-08-27 01:28:30,617][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023872] [Batch 02312/03080] [00:28:33/00:09:29, 0.741s/it]: train_loss_raw=1.4103, running_loss=1.2686, LR=0.000100
[2025-08-27 01:28:36,767][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023880] [Batch 02320/03080] [00:28:39/00:09:23, 0.741s/it]: train_loss_raw=1.3091, running_loss=1.2676, LR=0.000100
[2025-08-27 01:28:42,650][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023888] [Batch 02328/03080] [00:28:45/00:09:17, 0.741s/it]: train_loss_raw=1.2002, running_loss=1.2657, LR=0.000100
[2025-08-27 01:28:48,474][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023896] [Batch 02336/03080] [00:28:51/00:09:11, 0.741s/it]: train_loss_raw=1.2056, running_loss=1.2675, LR=0.000100
[2025-08-27 01:28:54,458][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023904] [Batch 02344/03080] [00:28:57/00:09:05, 0.741s/it]: train_loss_raw=1.3353, running_loss=1.2670, LR=0.000100
[2025-08-27 01:29:00,173][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023912] [Batch 02352/03080] [00:29:02/00:08:59, 0.741s/it]: train_loss_raw=1.2800, running_loss=1.2698, LR=0.000100
[2025-08-27 01:29:06,030][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023920] [Batch 02360/03080] [00:29:08/00:08:53, 0.741s/it]: train_loss_raw=1.2364, running_loss=1.2676, LR=0.000100
[2025-08-27 01:29:12,133][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023928] [Batch 02368/03080] [00:29:14/00:08:47, 0.741s/it]: train_loss_raw=1.3671, running_loss=1.2704, LR=0.000100
[2025-08-27 01:29:18,439][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023936] [Batch 02376/03080] [00:29:21/00:08:41, 0.741s/it]: train_loss_raw=1.2797, running_loss=1.2722, LR=0.000100
[2025-08-27 01:29:24,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023944] [Batch 02384/03080] [00:29:26/00:08:35, 0.741s/it]: train_loss_raw=1.2817, running_loss=1.2724, LR=0.000100
[2025-08-27 01:29:30,014][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023952] [Batch 02392/03080] [00:29:32/00:08:29, 0.741s/it]: train_loss_raw=1.2386, running_loss=1.2730, LR=0.000100
[2025-08-27 01:29:35,839][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023960] [Batch 02400/03080] [00:29:38/00:08:23, 0.741s/it]: train_loss_raw=1.3338, running_loss=1.2703, LR=0.000100
[2025-08-27 01:29:41,548][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023968] [Batch 02408/03080] [00:29:44/00:08:17, 0.741s/it]: train_loss_raw=1.3032, running_loss=1.2695, LR=0.000100
[2025-08-27 01:29:47,191][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023976] [Batch 02416/03080] [00:29:49/00:08:11, 0.741s/it]: train_loss_raw=1.2982, running_loss=1.2679, LR=0.000100
[2025-08-27 01:29:52,898][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023984] [Batch 02424/03080] [00:29:55/00:08:05, 0.741s/it]: train_loss_raw=1.1813, running_loss=1.2651, LR=0.000100
[2025-08-27 01:29:58,654][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023992] [Batch 02432/03080] [00:30:01/00:07:59, 0.741s/it]: train_loss_raw=1.3206, running_loss=1.2689, LR=0.000100
[2025-08-27 01:30:04,394][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024000] [Batch 02440/03080] [00:30:07/00:07:53, 0.741s/it]: train_loss_raw=1.2686, running_loss=1.2683, LR=0.000100
[2025-08-27 01:30:15,172][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024008] [Batch 02448/03080] [00:30:17/00:07:49, 0.743s/it]: train_loss_raw=1.2418, running_loss=1.2627, LR=0.000100
[2025-08-27 01:30:21,161][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024016] [Batch 02456/03080] [00:30:23/00:07:43, 0.743s/it]: train_loss_raw=1.2203, running_loss=1.2611, LR=0.000100
[2025-08-27 01:30:27,036][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024024] [Batch 02464/03080] [00:30:29/00:07:37, 0.743s/it]: train_loss_raw=1.3549, running_loss=1.2621, LR=0.000100
[2025-08-27 01:30:32,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024032] [Batch 02472/03080] [00:30:35/00:07:31, 0.743s/it]: train_loss_raw=1.1495, running_loss=1.2614, LR=0.000100
[2025-08-27 01:30:38,754][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024040] [Batch 02480/03080] [00:30:41/00:07:25, 0.743s/it]: train_loss_raw=1.2697, running_loss=1.2630, LR=0.000100
[2025-08-27 01:30:44,753][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024048] [Batch 02488/03080] [00:30:47/00:07:19, 0.743s/it]: train_loss_raw=1.2644, running_loss=1.2637, LR=0.000100
[2025-08-27 01:30:50,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024056] [Batch 02496/03080] [00:30:53/00:07:13, 0.743s/it]: train_loss_raw=1.2893, running_loss=1.2629, LR=0.000100
[2025-08-27 01:30:57,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024064] [Batch 02504/03080] [00:30:59/00:07:07, 0.743s/it]: train_loss_raw=1.2837, running_loss=1.2641, LR=0.000100
[2025-08-27 01:31:03,172][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024072] [Batch 02512/03080] [00:31:05/00:07:01, 0.743s/it]: train_loss_raw=1.1867, running_loss=1.2599, LR=0.000100
[2025-08-27 01:31:08,914][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024080] [Batch 02520/03080] [00:31:11/00:06:55, 0.743s/it]: train_loss_raw=1.2143, running_loss=1.2574, LR=0.000100
[2025-08-27 01:31:14,844][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024088] [Batch 02528/03080] [00:31:17/00:06:49, 0.743s/it]: train_loss_raw=1.1389, running_loss=1.2562, LR=0.000100
[2025-08-27 01:31:20,934][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024096] [Batch 02536/03080] [00:31:23/00:06:44, 0.743s/it]: train_loss_raw=1.3556, running_loss=1.2545, LR=0.000100
[2025-08-27 01:31:26,951][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024104] [Batch 02544/03080] [00:31:29/00:06:38, 0.743s/it]: train_loss_raw=1.1823, running_loss=1.2540, LR=0.000100
[2025-08-27 01:31:32,935][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024112] [Batch 02552/03080] [00:31:35/00:06:32, 0.743s/it]: train_loss_raw=1.2337, running_loss=1.2559, LR=0.000100
[2025-08-27 01:31:38,740][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024120] [Batch 02560/03080] [00:31:41/00:06:26, 0.743s/it]: train_loss_raw=1.2056, running_loss=1.2543, LR=0.000100
[2025-08-27 01:31:44,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024128] [Batch 02568/03080] [00:31:47/00:06:20, 0.743s/it]: train_loss_raw=1.3571, running_loss=1.2541, LR=0.000100
[2025-08-27 01:31:50,472][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024136] [Batch 02576/03080] [00:31:53/00:06:14, 0.743s/it]: train_loss_raw=1.2675, running_loss=1.2535, LR=0.000100
[2025-08-27 01:31:56,482][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024144] [Batch 02584/03080] [00:31:59/00:06:08, 0.743s/it]: train_loss_raw=1.3060, running_loss=1.2548, LR=0.000100
[2025-08-27 01:32:02,626][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024152] [Batch 02592/03080] [00:32:05/00:06:02, 0.743s/it]: train_loss_raw=1.2105, running_loss=1.2540, LR=0.000100
[2025-08-27 01:32:08,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024160] [Batch 02600/03080] [00:32:11/00:05:56, 0.743s/it]: train_loss_raw=1.3301, running_loss=1.2598, LR=0.000100
[2025-08-27 01:32:14,171][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024168] [Batch 02608/03080] [00:32:16/00:05:50, 0.743s/it]: train_loss_raw=1.3236, running_loss=1.2599, LR=0.000100
[2025-08-27 01:32:19,878][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024176] [Batch 02616/03080] [00:32:22/00:05:44, 0.743s/it]: train_loss_raw=1.3361, running_loss=1.2606, LR=0.000100
[2025-08-27 01:32:25,543][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024184] [Batch 02624/03080] [00:32:28/00:05:38, 0.742s/it]: train_loss_raw=1.2253, running_loss=1.2596, LR=0.000100
[2025-08-27 01:32:31,349][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024192] [Batch 02632/03080] [00:32:34/00:05:32, 0.742s/it]: train_loss_raw=1.2120, running_loss=1.2584, LR=0.000100
[2025-08-27 01:32:37,151][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024200] [Batch 02640/03080] [00:32:39/00:05:26, 0.742s/it]: train_loss_raw=1.3301, running_loss=1.2594, LR=0.000100
[2025-08-27 01:32:43,132][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024208] [Batch 02648/03080] [00:32:45/00:05:20, 0.742s/it]: train_loss_raw=1.2286, running_loss=1.2594, LR=0.000100
[2025-08-27 01:32:49,297][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024216] [Batch 02656/03080] [00:32:51/00:05:14, 0.742s/it]: train_loss_raw=1.1742, running_loss=1.2591, LR=0.000100
[2025-08-27 01:32:55,467][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024224] [Batch 02664/03080] [00:32:58/00:05:08, 0.743s/it]: train_loss_raw=1.1309, running_loss=1.2589, LR=0.000100
[2025-08-27 01:33:01,182][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024232] [Batch 02672/03080] [00:33:03/00:05:02, 0.742s/it]: train_loss_raw=1.3017, running_loss=1.2625, LR=0.000100
[2025-08-27 01:33:07,310][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024240] [Batch 02680/03080] [00:33:10/00:04:57, 0.743s/it]: train_loss_raw=1.2593, running_loss=1.2616, LR=0.000100
[2025-08-27 01:33:13,211][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024248] [Batch 02688/03080] [00:33:15/00:04:51, 0.743s/it]: train_loss_raw=1.2277, running_loss=1.2592, LR=0.000100
[2025-08-27 01:33:19,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024256] [Batch 02696/03080] [00:33:22/00:04:45, 0.743s/it]: train_loss_raw=1.2113, running_loss=1.2596, LR=0.000100
[2025-08-27 01:33:25,379][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024264] [Batch 02704/03080] [00:33:28/00:04:39, 0.743s/it]: train_loss_raw=1.3790, running_loss=1.2625, LR=0.000100
[2025-08-27 01:33:31,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024272] [Batch 02712/03080] [00:33:34/00:04:33, 0.743s/it]: train_loss_raw=1.2606, running_loss=1.2625, LR=0.000100
[2025-08-27 01:33:37,302][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024280] [Batch 02720/03080] [00:33:40/00:04:27, 0.743s/it]: train_loss_raw=1.2941, running_loss=1.2631, LR=0.000100
[2025-08-27 01:33:43,503][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024288] [Batch 02728/03080] [00:33:46/00:04:21, 0.743s/it]: train_loss_raw=1.2472, running_loss=1.2632, LR=0.000100
[2025-08-27 01:33:49,362][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024296] [Batch 02736/03080] [00:33:52/00:04:15, 0.743s/it]: train_loss_raw=1.2862, running_loss=1.2636, LR=0.000100
[2025-08-27 01:33:55,244][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024304] [Batch 02744/03080] [00:33:57/00:04:09, 0.743s/it]: train_loss_raw=1.2730, running_loss=1.2633, LR=0.000100
[2025-08-27 01:34:01,331][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024312] [Batch 02752/03080] [00:34:04/00:04:03, 0.743s/it]: train_loss_raw=1.2282, running_loss=1.2632, LR=0.000100
[2025-08-27 01:34:07,496][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024320] [Batch 02760/03080] [00:34:10/00:03:57, 0.743s/it]: train_loss_raw=1.2867, running_loss=1.2629, LR=0.000100
[2025-08-27 01:34:13,621][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024328] [Batch 02768/03080] [00:34:16/00:03:51, 0.743s/it]: train_loss_raw=1.2493, running_loss=1.2596, LR=0.000100
[2025-08-27 01:34:19,563][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024336] [Batch 02776/03080] [00:34:22/00:03:45, 0.743s/it]: train_loss_raw=1.2147, running_loss=1.2605, LR=0.000100
[2025-08-27 01:34:25,368][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024344] [Batch 02784/03080] [00:34:28/00:03:39, 0.743s/it]: train_loss_raw=1.2291, running_loss=1.2580, LR=0.000100
[2025-08-27 01:34:31,262][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024352] [Batch 02792/03080] [00:34:33/00:03:33, 0.743s/it]: train_loss_raw=1.1775, running_loss=1.2560, LR=0.000100
[2025-08-27 01:34:37,325][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024360] [Batch 02800/03080] [00:34:40/00:03:28, 0.743s/it]: train_loss_raw=1.2156, running_loss=1.2552, LR=0.000100
[2025-08-27 01:34:43,349][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024368] [Batch 02808/03080] [00:34:46/00:03:22, 0.743s/it]: train_loss_raw=1.1119, running_loss=1.2510, LR=0.000100
[2025-08-27 01:34:48,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024376] [Batch 02816/03080] [00:34:51/00:03:16, 0.743s/it]: train_loss_raw=1.2349, running_loss=1.2509, LR=0.000100
[2025-08-27 01:34:54,822][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024384] [Batch 02824/03080] [00:34:57/00:03:10, 0.743s/it]: train_loss_raw=1.3395, running_loss=1.2524, LR=0.000100
[2025-08-27 01:35:00,589][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024392] [Batch 02832/03080] [00:35:03/00:03:04, 0.743s/it]: train_loss_raw=1.2767, running_loss=1.2517, LR=0.000100
[2025-08-27 01:35:06,564][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024400] [Batch 02840/03080] [00:35:09/00:02:58, 0.743s/it]: train_loss_raw=1.1071, running_loss=1.2485, LR=0.000100
[2025-08-27 01:35:12,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024408] [Batch 02848/03080] [00:35:15/00:02:52, 0.743s/it]: train_loss_raw=1.3077, running_loss=1.2500, LR=0.000100
[2025-08-27 01:35:18,400][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024416] [Batch 02856/03080] [00:35:21/00:02:46, 0.743s/it]: train_loss_raw=1.1393, running_loss=1.2490, LR=0.000100
[2025-08-27 01:35:24,607][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024424] [Batch 02864/03080] [00:35:27/00:02:40, 0.743s/it]: train_loss_raw=1.2400, running_loss=1.2519, LR=0.000100
[2025-08-27 01:35:30,598][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024432] [Batch 02872/03080] [00:35:33/00:02:34, 0.743s/it]: train_loss_raw=1.2974, running_loss=1.2524, LR=0.000100
[2025-08-27 01:35:36,838][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024440] [Batch 02880/03080] [00:35:39/00:02:28, 0.743s/it]: train_loss_raw=1.2577, running_loss=1.2523, LR=0.000100
[2025-08-27 01:35:42,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024448] [Batch 02888/03080] [00:35:45/00:02:22, 0.743s/it]: train_loss_raw=1.2210, running_loss=1.2515, LR=0.000100
[2025-08-27 01:35:48,818][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024456] [Batch 02896/03080] [00:35:51/00:02:16, 0.743s/it]: train_loss_raw=1.2561, running_loss=1.2511, LR=0.000100
[2025-08-27 01:35:54,955][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024464] [Batch 02904/03080] [00:35:57/00:02:10, 0.743s/it]: train_loss_raw=1.2018, running_loss=1.2497, LR=0.000100
[2025-08-27 01:36:00,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024472] [Batch 02912/03080] [00:36:03/00:02:04, 0.743s/it]: train_loss_raw=1.2366, running_loss=1.2496, LR=0.000100
[2025-08-27 01:36:06,685][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024480] [Batch 02920/03080] [00:36:09/00:01:58, 0.743s/it]: train_loss_raw=1.1934, running_loss=1.2489, LR=0.000100
[2025-08-27 01:36:12,591][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024488] [Batch 02928/03080] [00:36:15/00:01:52, 0.743s/it]: train_loss_raw=1.3108, running_loss=1.2496, LR=0.000100
[2025-08-27 01:36:18,374][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024496] [Batch 02936/03080] [00:36:21/00:01:46, 0.743s/it]: train_loss_raw=1.2434, running_loss=1.2512, LR=0.000100
[2025-08-27 01:36:24,080][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024504] [Batch 02944/03080] [00:36:26/00:01:41, 0.743s/it]: train_loss_raw=1.2400, running_loss=1.2532, LR=0.000100
[2025-08-27 01:36:29,910][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024512] [Batch 02952/03080] [00:36:32/00:01:35, 0.743s/it]: train_loss_raw=1.2866, running_loss=1.2527, LR=0.000100
[2025-08-27 01:36:35,785][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024520] [Batch 02960/03080] [00:36:38/00:01:29, 0.743s/it]: train_loss_raw=1.2870, running_loss=1.2514, LR=0.000100
[2025-08-27 01:36:41,642][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024528] [Batch 02968/03080] [00:36:44/00:01:23, 0.743s/it]: train_loss_raw=1.2846, running_loss=1.2475, LR=0.000100
[2025-08-27 01:36:47,796][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024536] [Batch 02976/03080] [00:36:50/00:01:17, 0.743s/it]: train_loss_raw=1.1543, running_loss=1.2472, LR=0.000100
[2025-08-27 01:36:53,882][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024544] [Batch 02984/03080] [00:36:56/00:01:11, 0.743s/it]: train_loss_raw=1.2247, running_loss=1.2470, LR=0.000100
[2025-08-27 01:36:59,844][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024552] [Batch 02992/03080] [00:37:02/00:01:05, 0.743s/it]: train_loss_raw=1.2993, running_loss=1.2469, LR=0.000100
[2025-08-27 01:37:05,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024560] [Batch 03000/03080] [00:37:08/00:00:59, 0.743s/it]: train_loss_raw=1.2046, running_loss=1.2467, LR=0.000100
[2025-08-27 01:37:11,504][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024568] [Batch 03008/03080] [00:37:14/00:00:53, 0.743s/it]: train_loss_raw=1.2711, running_loss=1.2474, LR=0.000100
[2025-08-27 01:37:17,528][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024576] [Batch 03016/03080] [00:37:20/00:00:47, 0.743s/it]: train_loss_raw=1.2234, running_loss=1.2441, LR=0.000100
[2025-08-27 01:37:23,462][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024584] [Batch 03024/03080] [00:37:26/00:00:41, 0.743s/it]: train_loss_raw=1.3009, running_loss=1.2454, LR=0.000100
[2025-08-27 01:37:29,555][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024592] [Batch 03032/03080] [00:37:32/00:00:35, 0.743s/it]: train_loss_raw=1.2543, running_loss=1.2473, LR=0.000100
[2025-08-27 01:37:35,627][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024600] [Batch 03040/03080] [00:37:38/00:00:29, 0.743s/it]: train_loss_raw=1.2756, running_loss=1.2491, LR=0.000100
[2025-08-27 01:37:41,508][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024608] [Batch 03048/03080] [00:37:44/00:00:23, 0.743s/it]: train_loss_raw=1.3503, running_loss=1.2486, LR=0.000100
[2025-08-27 01:37:47,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024616] [Batch 03056/03080] [00:37:49/00:00:17, 0.743s/it]: train_loss_raw=1.2428, running_loss=1.2470, LR=0.000100
[2025-08-27 01:37:53,107][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024624] [Batch 03064/03080] [00:37:55/00:00:11, 0.743s/it]: train_loss_raw=1.1768, running_loss=1.2453, LR=0.000100
[2025-08-27 01:37:58,859][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024632] [Batch 03072/03080] [00:38:01/00:00:05, 0.743s/it]: train_loss_raw=1.3286, running_loss=1.2489, LR=0.000100
[2025-08-27 01:38:10,113][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024640] [Batch 03080/03080] [00:38:12/00:00:00, 0.744s/it]: train_loss_raw=1.1947, running_loss=1.2461, LR=0.000100
[2025-08-27 01:38:10,609][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-27 01:38:21,797][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00007/00310] [00:00:11/00:07:02, 1.398s/it]
[2025-08-27 01:38:34,063][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00015/00310] [00:00:23/00:07:10, 1.466s/it]
[2025-08-27 01:38:46,510][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00023/00310] [00:00:35/00:07:07, 1.496s/it]
[2025-08-27 01:38:59,088][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00031/00310] [00:00:48/00:07:01, 1.515s/it]
[2025-08-27 01:39:11,934][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00039/00310] [00:01:01/00:06:53, 1.533s/it]
[2025-08-27 01:39:24,862][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00047/00310] [00:01:14/00:06:45, 1.547s/it]
[2025-08-27 01:39:37,769][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00055/00310] [00:01:27/00:06:35, 1.556s/it]
[2025-08-27 01:39:50,145][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00063/00310] [00:01:39/00:06:22, 1.555s/it]
[2025-08-27 01:40:02,878][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00071/00310] [00:01:52/00:06:11, 1.559s/it]
[2025-08-27 01:40:15,756][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00079/00310] [00:02:05/00:05:59, 1.564s/it]
[2025-08-27 01:40:28,037][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00087/00310] [00:02:17/00:05:46, 1.562s/it]
[2025-08-27 01:40:40,966][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00095/00310] [00:02:30/00:05:35, 1.566s/it]
[2025-08-27 01:40:53,539][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00103/00310] [00:02:42/00:05:22, 1.567s/it]
[2025-08-27 01:41:06,312][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00111/00310] [00:02:55/00:05:10, 1.569s/it]
[2025-08-27 01:41:19,132][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00119/00310] [00:03:08/00:04:58, 1.571s/it]
[2025-08-27 01:41:32,056][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00127/00310] [00:03:21/00:04:46, 1.574s/it]
[2025-08-27 01:41:44,971][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00135/00310] [00:03:34/00:04:34, 1.576s/it]
[2025-08-27 01:41:57,932][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00143/00310] [00:03:47/00:04:22, 1.579s/it]
[2025-08-27 01:42:09,379][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00151/00310] [00:03:58/00:04:08, 1.571s/it]
[2025-08-27 01:42:21,120][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00159/00310] [00:04:10/00:03:54, 1.566s/it]
[2025-08-27 01:42:33,994][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00167/00310] [00:04:23/00:03:42, 1.568s/it]
[2025-08-27 01:42:45,719][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00175/00310] [00:04:35/00:03:29, 1.563s/it]
[2025-08-27 01:42:57,385][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00183/00310] [00:04:46/00:03:16, 1.559s/it]
[2025-08-27 01:43:10,275][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00191/00310] [00:04:59/00:03:04, 1.561s/it]
[2025-08-27 01:43:22,658][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00199/00310] [00:05:12/00:02:51, 1.560s/it]
[2025-08-27 01:43:34,517][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00207/00310] [00:05:23/00:02:38, 1.557s/it]
[2025-08-27 01:43:46,543][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00215/00310] [00:05:35/00:02:26, 1.555s/it]
[2025-08-27 01:43:58,616][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00223/00310] [00:05:48/00:02:13, 1.554s/it]
[2025-08-27 01:44:11,094][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00231/00310] [00:06:00/00:02:01, 1.554s/it]
[2025-08-27 01:44:23,409][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00239/00310] [00:06:12/00:01:48, 1.553s/it]
[2025-08-27 01:44:35,193][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00247/00310] [00:06:24/00:01:36, 1.551s/it]
[2025-08-27 01:44:47,905][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00255/00310] [00:06:37/00:01:23, 1.552s/it]
[2025-08-27 01:45:01,002][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00263/00310] [00:06:50/00:01:11, 1.555s/it]
[2025-08-27 01:45:13,574][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00271/00310] [00:07:02/00:00:59, 1.555s/it]
[2025-08-27 01:45:25,744][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00279/00310] [00:07:15/00:00:46, 1.554s/it]
[2025-08-27 01:45:38,733][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00287/00310] [00:07:28/00:00:34, 1.556s/it]
[2025-08-27 01:45:50,618][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00295/00310] [00:07:40/00:00:21, 1.554s/it]
[2025-08-27 01:46:03,179][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00303/00310] [00:07:52/00:00:09, 1.555s/it]
[2025-08-27 01:46:12,246][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.24606, valid_loss=1.95749
[2025-08-27 01:46:12,246][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-27 01:46:12,246][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.744
[2025-08-27 01:46:12,247][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.035
[2025-08-27 01:46:12,247][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.037
[2025-08-27 01:46:12,247][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.009
[2025-08-27 01:46:12,263][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 06:19:26, remaining time 17:23:26, 00:47:25 per epoch
[2025-08-27 01:46:18,931][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024648] [Batch 00008/03080] [00:00:06/00:40:52, 0.798s/it]: train_loss_raw=1.2707, running_loss=1.2606, LR=0.000100
[2025-08-27 01:46:24,996][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024656] [Batch 00016/03080] [00:00:12/00:39:44, 0.778s/it]: train_loss_raw=1.2338, running_loss=1.2582, LR=0.000100
[2025-08-27 01:46:30,775][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024664] [Batch 00024/03080] [00:00:18/00:38:41, 0.760s/it]: train_loss_raw=1.2226, running_loss=1.2559, LR=0.000100
[2025-08-27 01:46:36,847][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024672] [Batch 00032/03080] [00:00:24/00:38:34, 0.759s/it]: train_loss_raw=1.2176, running_loss=1.2539, LR=0.000100
[2025-08-27 01:46:42,767][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024680] [Batch 00040/03080] [00:00:30/00:38:16, 0.756s/it]: train_loss_raw=1.2022, running_loss=1.2508, LR=0.000100
[2025-08-27 01:46:48,561][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024688] [Batch 00048/03080] [00:00:36/00:37:54, 0.750s/it]: train_loss_raw=1.2837, running_loss=1.2516, LR=0.000100
[2025-08-27 01:46:54,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024696] [Batch 00056/03080] [00:00:42/00:37:55, 0.752s/it]: train_loss_raw=1.3255, running_loss=1.2483, LR=0.000100
[2025-08-27 01:47:00,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024704] [Batch 00064/03080] [00:00:48/00:37:53, 0.754s/it]: train_loss_raw=1.1981, running_loss=1.2460, LR=0.000100
[2025-08-27 01:47:06,744][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024712] [Batch 00072/03080] [00:00:54/00:37:44, 0.753s/it]: train_loss_raw=1.3221, running_loss=1.2466, LR=0.000100
[2025-08-27 01:47:12,850][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024720] [Batch 00080/03080] [00:01:00/00:37:41, 0.754s/it]: train_loss_raw=1.2296, running_loss=1.2437, LR=0.000100
[2025-08-27 01:47:18,844][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024728] [Batch 00088/03080] [00:01:06/00:37:34, 0.753s/it]: train_loss_raw=1.1900, running_loss=1.2445, LR=0.000100
[2025-08-27 01:47:24,892][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024736] [Batch 00096/03080] [00:01:12/00:37:28, 0.754s/it]: train_loss_raw=1.1413, running_loss=1.2428, LR=0.000100
[2025-08-27 01:47:30,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024744] [Batch 00104/03080] [00:01:18/00:37:18, 0.752s/it]: train_loss_raw=1.1991, running_loss=1.2436, LR=0.000100
[2025-08-27 01:47:36,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024752] [Batch 00112/03080] [00:01:24/00:37:09, 0.751s/it]: train_loss_raw=1.3164, running_loss=1.2456, LR=0.000100
[2025-08-27 01:47:42,718][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024760] [Batch 00120/03080] [00:01:30/00:37:04, 0.751s/it]: train_loss_raw=1.2908, running_loss=1.2432, LR=0.000100
[2025-08-27 01:47:48,790][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024768] [Batch 00128/03080] [00:01:36/00:36:59, 0.752s/it]: train_loss_raw=1.1752, running_loss=1.2417, LR=0.000100
[2025-08-27 01:47:54,795][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024776] [Batch 00136/03080] [00:01:42/00:36:53, 0.752s/it]: train_loss_raw=1.1959, running_loss=1.2368, LR=0.000100
[2025-08-27 01:48:00,721][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024784] [Batch 00144/03080] [00:01:48/00:36:45, 0.751s/it]: train_loss_raw=1.2686, running_loss=1.2374, LR=0.000100
[2025-08-27 01:48:06,907][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024792] [Batch 00152/03080] [00:01:54/00:36:42, 0.752s/it]: train_loss_raw=1.1843, running_loss=1.2347, LR=0.000100
[2025-08-27 01:48:12,800][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024800] [Batch 00160/03080] [00:02:00/00:36:34, 0.752s/it]: train_loss_raw=1.0384, running_loss=1.2332, LR=0.000100
[2025-08-27 01:48:18,808][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024808] [Batch 00168/03080] [00:02:06/00:36:28, 0.752s/it]: train_loss_raw=1.2838, running_loss=1.2333, LR=0.000100
[2025-08-27 01:48:24,742][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024816] [Batch 00176/03080] [00:02:12/00:36:21, 0.751s/it]: train_loss_raw=1.2587, running_loss=1.2337, LR=0.000100
[2025-08-27 01:48:30,760][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024824] [Batch 00184/03080] [00:02:18/00:36:15, 0.751s/it]: train_loss_raw=1.2673, running_loss=1.2327, LR=0.000100
[2025-08-27 01:48:36,825][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024832] [Batch 00192/03080] [00:02:24/00:36:10, 0.751s/it]: train_loss_raw=1.1949, running_loss=1.2305, LR=0.000100
[2025-08-27 01:48:42,709][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024840] [Batch 00200/03080] [00:02:30/00:36:02, 0.751s/it]: train_loss_raw=1.3774, running_loss=1.2284, LR=0.000100
[2025-08-27 01:48:48,839][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024848] [Batch 00208/03080] [00:02:36/00:35:58, 0.751s/it]: train_loss_raw=1.2868, running_loss=1.2284, LR=0.000100
[2025-08-27 01:48:54,827][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024856] [Batch 00216/03080] [00:02:42/00:35:51, 0.751s/it]: train_loss_raw=1.2364, running_loss=1.2284, LR=0.000100
[2025-08-27 01:49:00,867][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024864] [Batch 00224/03080] [00:02:48/00:35:46, 0.751s/it]: train_loss_raw=1.2811, running_loss=1.2261, LR=0.000100
[2025-08-27 01:49:06,975][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024872] [Batch 00232/03080] [00:02:54/00:35:41, 0.752s/it]: train_loss_raw=1.2234, running_loss=1.2257, LR=0.000100
[2025-08-27 01:49:13,062][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024880] [Batch 00240/03080] [00:03:00/00:35:36, 0.752s/it]: train_loss_raw=1.2746, running_loss=1.2278, LR=0.000100
[2025-08-27 01:49:18,787][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024888] [Batch 00248/03080] [00:03:06/00:35:26, 0.751s/it]: train_loss_raw=1.2628, running_loss=1.2267, LR=0.000100
[2025-08-27 01:49:24,686][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024896] [Batch 00256/03080] [00:03:12/00:35:19, 0.751s/it]: train_loss_raw=1.2084, running_loss=1.2238, LR=0.000100
[2025-08-27 01:49:30,628][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024904] [Batch 00264/03080] [00:03:18/00:35:12, 0.750s/it]: train_loss_raw=1.2265, running_loss=1.2252, LR=0.000100
[2025-08-27 01:49:36,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024912] [Batch 00272/03080] [00:03:24/00:35:06, 0.750s/it]: train_loss_raw=1.2372, running_loss=1.2275, LR=0.000100
[2025-08-27 01:49:42,400][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024920] [Batch 00280/03080] [00:03:29/00:34:58, 0.749s/it]: train_loss_raw=1.2825, running_loss=1.2273, LR=0.000100
[2025-08-27 01:49:48,213][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024928] [Batch 00288/03080] [00:03:35/00:34:50, 0.749s/it]: train_loss_raw=1.1702, running_loss=1.2245, LR=0.000100
[2025-08-27 01:49:53,952][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024936] [Batch 00296/03080] [00:03:41/00:34:42, 0.748s/it]: train_loss_raw=1.2269, running_loss=1.2237, LR=0.000100
[2025-08-27 01:49:59,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024944] [Batch 00304/03080] [00:03:47/00:34:37, 0.748s/it]: train_loss_raw=1.2628, running_loss=1.2243, LR=0.000100
[2025-08-27 01:50:06,014][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024952] [Batch 00312/03080] [00:03:53/00:34:31, 0.748s/it]: train_loss_raw=1.3022, running_loss=1.2237, LR=0.000100
[2025-08-27 01:50:11,716][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024960] [Batch 00320/03080] [00:03:59/00:34:22, 0.747s/it]: train_loss_raw=1.2941, running_loss=1.2241, LR=0.000100
[2025-08-27 01:50:17,534][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024968] [Batch 00328/03080] [00:04:04/00:34:15, 0.747s/it]: train_loss_raw=1.3392, running_loss=1.2254, LR=0.000100
[2025-08-27 01:50:23,274][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024976] [Batch 00336/03080] [00:04:10/00:34:07, 0.746s/it]: train_loss_raw=1.3672, running_loss=1.2242, LR=0.000100
[2025-08-27 01:50:29,021][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024984] [Batch 00344/03080] [00:04:16/00:33:59, 0.746s/it]: train_loss_raw=1.3256, running_loss=1.2212, LR=0.000100
[2025-08-27 01:50:35,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024992] [Batch 00352/03080] [00:04:22/00:33:54, 0.746s/it]: train_loss_raw=1.1722, running_loss=1.2208, LR=0.000100
[2025-08-27 01:50:40,855][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025000] [Batch 00360/03080] [00:04:28/00:33:47, 0.745s/it]: train_loss_raw=1.1229, running_loss=1.2195, LR=0.000100
[2025-08-27 01:50:46,580][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025008] [Batch 00368/03080] [00:04:34/00:33:39, 0.745s/it]: train_loss_raw=1.2448, running_loss=1.2177, LR=0.000100
[2025-08-27 01:50:52,323][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025016] [Batch 00376/03080] [00:04:39/00:33:32, 0.744s/it]: train_loss_raw=1.2216, running_loss=1.2166, LR=0.000100
[2025-08-27 01:50:58,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025024] [Batch 00384/03080] [00:04:45/00:33:24, 0.744s/it]: train_loss_raw=1.2219, running_loss=1.2169, LR=0.000100
[2025-08-27 01:51:04,005][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025032] [Batch 00392/03080] [00:04:51/00:33:18, 0.744s/it]: train_loss_raw=1.1823, running_loss=1.2147, LR=0.000100
[2025-08-27 01:51:09,838][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025040] [Batch 00400/03080] [00:04:57/00:33:11, 0.743s/it]: train_loss_raw=1.1482, running_loss=1.2128, LR=0.000100
[2025-08-27 01:51:15,704][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025048] [Batch 00408/03080] [00:05:03/00:33:05, 0.743s/it]: train_loss_raw=1.3138, running_loss=1.2145, LR=0.000100
[2025-08-27 01:51:21,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025056] [Batch 00416/03080] [00:05:09/00:33:00, 0.743s/it]: train_loss_raw=1.1371, running_loss=1.2126, LR=0.000100
[2025-08-27 01:51:27,584][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025064] [Batch 00424/03080] [00:05:15/00:32:53, 0.743s/it]: train_loss_raw=1.1507, running_loss=1.2114, LR=0.000100
[2025-08-27 01:51:33,543][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025072] [Batch 00432/03080] [00:05:20/00:32:47, 0.743s/it]: train_loss_raw=1.2751, running_loss=1.2125, LR=0.000100
[2025-08-27 01:51:39,446][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025080] [Batch 00440/03080] [00:05:26/00:32:41, 0.743s/it]: train_loss_raw=1.2007, running_loss=1.2093, LR=0.000100
[2025-08-27 01:51:45,194][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025088] [Batch 00448/03080] [00:05:32/00:32:34, 0.743s/it]: train_loss_raw=1.2115, running_loss=1.2100, LR=0.000100
[2025-08-27 01:51:51,090][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025096] [Batch 00456/03080] [00:05:38/00:32:28, 0.742s/it]: train_loss_raw=1.2125, running_loss=1.2111, LR=0.000100
[2025-08-27 01:51:56,951][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025104] [Batch 00464/03080] [00:05:44/00:32:21, 0.742s/it]: train_loss_raw=1.2074, running_loss=1.2131, LR=0.000100
[2025-08-27 01:52:02,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025112] [Batch 00472/03080] [00:05:50/00:32:15, 0.742s/it]: train_loss_raw=1.2274, running_loss=1.2113, LR=0.000100
[2025-08-27 01:52:08,720][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025120] [Batch 00480/03080] [00:05:56/00:32:09, 0.742s/it]: train_loss_raw=1.1844, running_loss=1.2118, LR=0.000100
[2025-08-27 01:52:14,705][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025128] [Batch 00488/03080] [00:06:02/00:32:03, 0.742s/it]: train_loss_raw=1.2493, running_loss=1.2152, LR=0.000100
[2025-08-27 01:52:20,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025136] [Batch 00496/03080] [00:06:07/00:31:56, 0.742s/it]: train_loss_raw=1.2403, running_loss=1.2175, LR=0.000100
[2025-08-27 01:52:26,186][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025144] [Batch 00504/03080] [00:06:13/00:31:49, 0.741s/it]: train_loss_raw=1.2408, running_loss=1.2179, LR=0.000100
[2025-08-27 01:52:32,119][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025152] [Batch 00512/03080] [00:06:19/00:31:43, 0.741s/it]: train_loss_raw=1.1972, running_loss=1.2167, LR=0.000100
[2025-08-27 01:52:38,156][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025160] [Batch 00520/03080] [00:06:25/00:31:38, 0.742s/it]: train_loss_raw=1.2263, running_loss=1.2128, LR=0.000100
[2025-08-27 01:52:44,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025168] [Batch 00528/03080] [00:06:31/00:31:32, 0.742s/it]: train_loss_raw=1.1711, running_loss=1.2146, LR=0.000100
[2025-08-27 01:52:50,204][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025176] [Batch 00536/03080] [00:06:37/00:31:27, 0.742s/it]: train_loss_raw=1.2384, running_loss=1.2148, LR=0.000100
[2025-08-27 01:52:56,262][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025184] [Batch 00544/03080] [00:06:43/00:31:22, 0.742s/it]: train_loss_raw=1.2555, running_loss=1.2157, LR=0.000100
[2025-08-27 01:53:02,092][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025192] [Batch 00552/03080] [00:06:49/00:31:15, 0.742s/it]: train_loss_raw=1.2461, running_loss=1.2191, LR=0.000100
[2025-08-27 01:53:08,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025200] [Batch 00560/03080] [00:06:55/00:31:10, 0.742s/it]: train_loss_raw=1.1626, running_loss=1.2167, LR=0.000100
[2025-08-27 01:53:14,172][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025208] [Batch 00568/03080] [00:07:01/00:31:04, 0.742s/it]: train_loss_raw=1.2053, running_loss=1.2148, LR=0.000100
[2025-08-27 01:53:20,259][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025216] [Batch 00576/03080] [00:07:07/00:30:59, 0.743s/it]: train_loss_raw=1.1772, running_loss=1.2163, LR=0.000100
[2025-08-27 01:53:26,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025224] [Batch 00584/03080] [00:07:13/00:30:53, 0.742s/it]: train_loss_raw=1.2185, running_loss=1.2147, LR=0.000100
[2025-08-27 01:53:31,899][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025232] [Batch 00592/03080] [00:07:19/00:30:46, 0.742s/it]: train_loss_raw=1.2666, running_loss=1.2159, LR=0.000100
[2025-08-27 01:53:37,678][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025240] [Batch 00600/03080] [00:07:25/00:30:39, 0.742s/it]: train_loss_raw=1.1777, running_loss=1.2151, LR=0.000100
[2025-08-27 01:53:43,589][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025248] [Batch 00608/03080] [00:07:31/00:30:33, 0.742s/it]: train_loss_raw=1.1635, running_loss=1.2151, LR=0.000100
[2025-08-27 01:53:49,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025256] [Batch 00616/03080] [00:07:37/00:30:28, 0.742s/it]: train_loss_raw=1.2928, running_loss=1.2162, LR=0.000100
[2025-08-27 01:53:55,504][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025264] [Batch 00624/03080] [00:07:42/00:30:22, 0.742s/it]: train_loss_raw=1.1434, running_loss=1.2169, LR=0.000100
[2025-08-27 01:54:01,521][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025272] [Batch 00632/03080] [00:07:48/00:30:16, 0.742s/it]: train_loss_raw=1.2913, running_loss=1.2199, LR=0.000100
[2025-08-27 01:54:07,299][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025280] [Batch 00640/03080] [00:07:54/00:30:09, 0.742s/it]: train_loss_raw=1.3150, running_loss=1.2193, LR=0.000100
[2025-08-27 01:54:13,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025288] [Batch 00648/03080] [00:08:00/00:30:03, 0.742s/it]: train_loss_raw=1.1880, running_loss=1.2177, LR=0.000100
[2025-08-27 01:54:18,830][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025296] [Batch 00656/03080] [00:08:06/00:29:56, 0.741s/it]: train_loss_raw=1.2145, running_loss=1.2191, LR=0.000100
[2025-08-27 01:54:24,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025304] [Batch 00664/03080] [00:08:12/00:29:50, 0.741s/it]: train_loss_raw=1.3707, running_loss=1.2212, LR=0.000100
[2025-08-27 01:54:30,707][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025312] [Batch 00672/03080] [00:08:18/00:29:45, 0.741s/it]: train_loss_raw=1.1799, running_loss=1.2190, LR=0.000100
[2025-08-27 01:54:36,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025320] [Batch 00680/03080] [00:08:24/00:29:39, 0.742s/it]: train_loss_raw=1.1228, running_loss=1.2163, LR=0.000100
[2025-08-27 01:54:42,921][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025328] [Batch 00688/03080] [00:08:30/00:29:34, 0.742s/it]: train_loss_raw=1.3084, running_loss=1.2192, LR=0.000100
[2025-08-27 01:54:48,875][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025336] [Batch 00696/03080] [00:08:36/00:29:28, 0.742s/it]: train_loss_raw=1.3101, running_loss=1.2193, LR=0.000100
[2025-08-27 01:54:54,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025344] [Batch 00704/03080] [00:08:42/00:29:23, 0.742s/it]: train_loss_raw=1.1782, running_loss=1.2180, LR=0.000100
[2025-08-27 01:55:00,859][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025352] [Batch 00712/03080] [00:08:48/00:29:17, 0.742s/it]: train_loss_raw=1.2156, running_loss=1.2188, LR=0.000100
[2025-08-27 01:55:06,792][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025360] [Batch 00720/03080] [00:08:54/00:29:11, 0.742s/it]: train_loss_raw=1.1989, running_loss=1.2193, LR=0.000100
[2025-08-27 01:55:12,578][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025368] [Batch 00728/03080] [00:09:00/00:29:04, 0.742s/it]: train_loss_raw=1.1584, running_loss=1.2172, LR=0.000100
[2025-08-27 01:55:18,567][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025376] [Batch 00736/03080] [00:09:06/00:28:58, 0.742s/it]: train_loss_raw=1.3470, running_loss=1.2171, LR=0.000100
[2025-08-27 01:55:24,563][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025384] [Batch 00744/03080] [00:09:12/00:28:53, 0.742s/it]: train_loss_raw=1.1992, running_loss=1.2164, LR=0.000100
[2025-08-27 01:55:30,510][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025392] [Batch 00752/03080] [00:09:17/00:28:47, 0.742s/it]: train_loss_raw=1.2852, running_loss=1.2165, LR=0.000100
[2025-08-27 01:55:36,352][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025400] [Batch 00760/03080] [00:09:23/00:28:41, 0.742s/it]: train_loss_raw=1.1947, running_loss=1.2146, LR=0.000100
[2025-08-27 01:55:42,231][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025408] [Batch 00768/03080] [00:09:29/00:28:34, 0.742s/it]: train_loss_raw=1.2438, running_loss=1.2133, LR=0.000100
[2025-08-27 01:55:48,029][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025416] [Batch 00776/03080] [00:09:35/00:28:28, 0.742s/it]: train_loss_raw=1.1629, running_loss=1.2119, LR=0.000100
[2025-08-27 01:55:54,059][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025424] [Batch 00784/03080] [00:09:41/00:28:23, 0.742s/it]: train_loss_raw=1.1706, running_loss=1.2123, LR=0.000100
[2025-08-27 01:56:00,144][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025432] [Batch 00792/03080] [00:09:47/00:28:17, 0.742s/it]: train_loss_raw=1.1682, running_loss=1.2137, LR=0.000100
[2025-08-27 01:56:06,027][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025440] [Batch 00800/03080] [00:09:53/00:28:11, 0.742s/it]: train_loss_raw=1.1162, running_loss=1.2107, LR=0.000100
[2025-08-27 01:56:11,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025448] [Batch 00808/03080] [00:09:59/00:28:05, 0.742s/it]: train_loss_raw=1.2532, running_loss=1.2144, LR=0.000100
[2025-08-27 01:56:17,814][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025456] [Batch 00816/03080] [00:10:05/00:27:59, 0.742s/it]: train_loss_raw=1.2691, running_loss=1.2145, LR=0.000100
[2025-08-27 01:56:23,674][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025464] [Batch 00824/03080] [00:10:11/00:27:53, 0.742s/it]: train_loss_raw=1.0610, running_loss=1.2098, LR=0.000100
[2025-08-27 01:56:29,630][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025472] [Batch 00832/03080] [00:10:17/00:27:47, 0.742s/it]: train_loss_raw=1.2153, running_loss=1.2070, LR=0.000100
[2025-08-27 01:56:35,707][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025480] [Batch 00840/03080] [00:10:23/00:27:41, 0.742s/it]: train_loss_raw=1.1617, running_loss=1.2065, LR=0.000100
[2025-08-27 01:56:41,551][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025488] [Batch 00848/03080] [00:10:29/00:27:35, 0.742s/it]: train_loss_raw=1.3198, running_loss=1.2054, LR=0.000100
[2025-08-27 01:56:47,580][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025496] [Batch 00856/03080] [00:10:35/00:27:29, 0.742s/it]: train_loss_raw=1.3006, running_loss=1.2051, LR=0.000100
[2025-08-27 01:56:53,513][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025504] [Batch 00864/03080] [00:10:40/00:27:23, 0.742s/it]: train_loss_raw=1.2182, running_loss=1.2037, LR=0.000100
[2025-08-27 01:56:59,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025512] [Batch 00872/03080] [00:10:46/00:27:17, 0.742s/it]: train_loss_raw=1.0980, running_loss=1.2029, LR=0.000100
[2025-08-27 01:57:05,077][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025520] [Batch 00880/03080] [00:10:52/00:27:11, 0.742s/it]: train_loss_raw=1.2779, running_loss=1.2047, LR=0.000100
[2025-08-27 01:57:10,943][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025528] [Batch 00888/03080] [00:10:58/00:27:05, 0.741s/it]: train_loss_raw=1.2172, running_loss=1.2061, LR=0.000100
[2025-08-27 01:57:16,831][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025536] [Batch 00896/03080] [00:11:04/00:26:59, 0.741s/it]: train_loss_raw=1.2610, running_loss=1.2092, LR=0.000100
[2025-08-27 01:57:22,962][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025544] [Batch 00904/03080] [00:11:10/00:26:53, 0.742s/it]: train_loss_raw=1.3162, running_loss=1.2080, LR=0.000100
[2025-08-27 01:57:28,740][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025552] [Batch 00912/03080] [00:11:16/00:26:47, 0.741s/it]: train_loss_raw=1.1344, running_loss=1.2061, LR=0.000100
[2025-08-27 01:57:34,498][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025560] [Batch 00920/03080] [00:11:21/00:26:41, 0.741s/it]: train_loss_raw=1.3036, running_loss=1.2065, LR=0.000100
[2025-08-27 01:57:40,145][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025568] [Batch 00928/03080] [00:11:27/00:26:34, 0.741s/it]: train_loss_raw=1.1974, running_loss=1.2045, LR=0.000100
[2025-08-27 01:57:45,890][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025576] [Batch 00936/03080] [00:11:33/00:26:28, 0.741s/it]: train_loss_raw=1.2672, running_loss=1.2047, LR=0.000100
[2025-08-27 01:57:51,829][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025584] [Batch 00944/03080] [00:11:39/00:26:22, 0.741s/it]: train_loss_raw=1.3047, running_loss=1.2077, LR=0.000100
[2025-08-27 01:57:57,625][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025592] [Batch 00952/03080] [00:11:45/00:26:16, 0.741s/it]: train_loss_raw=1.3573, running_loss=1.2062, LR=0.000100
[2025-08-27 01:58:03,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025600] [Batch 00960/03080] [00:11:51/00:26:10, 0.741s/it]: train_loss_raw=1.2987, running_loss=1.2062, LR=0.000100
[2025-08-27 01:58:09,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025608] [Batch 00968/03080] [00:11:57/00:26:04, 0.741s/it]: train_loss_raw=1.3014, running_loss=1.2073, LR=0.000100
[2025-08-27 01:58:15,571][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025616] [Batch 00976/03080] [00:12:03/00:25:58, 0.741s/it]: train_loss_raw=1.2335, running_loss=1.2068, LR=0.000100
[2025-08-27 01:58:21,375][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025624] [Batch 00984/03080] [00:12:08/00:25:52, 0.741s/it]: train_loss_raw=1.2804, running_loss=1.2064, LR=0.000100
[2025-08-27 01:58:27,342][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025632] [Batch 00992/03080] [00:12:14/00:25:46, 0.741s/it]: train_loss_raw=1.1649, running_loss=1.2037, LR=0.000100
[2025-08-27 01:58:33,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025640] [Batch 01000/03080] [00:12:20/00:25:40, 0.741s/it]: train_loss_raw=1.1545, running_loss=1.2030, LR=0.000100
[2025-08-27 01:58:38,919][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025648] [Batch 01008/03080] [00:12:26/00:25:34, 0.740s/it]: train_loss_raw=1.1476, running_loss=1.2047, LR=0.000100
[2025-08-27 01:58:44,860][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025656] [Batch 01016/03080] [00:12:32/00:25:28, 0.740s/it]: train_loss_raw=1.2339, running_loss=1.2028, LR=0.000100
[2025-08-27 01:58:50,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025664] [Batch 01024/03080] [00:12:38/00:25:22, 0.741s/it]: train_loss_raw=1.2925, running_loss=1.2052, LR=0.000100
[2025-08-27 01:58:56,926][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025672] [Batch 01032/03080] [00:12:44/00:25:16, 0.741s/it]: train_loss_raw=1.2059, running_loss=1.2068, LR=0.000100
[2025-08-27 01:59:03,041][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025680] [Batch 01040/03080] [00:12:50/00:25:11, 0.741s/it]: train_loss_raw=1.2367, running_loss=1.2025, LR=0.000100
[2025-08-27 01:59:09,036][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025688] [Batch 01048/03080] [00:12:56/00:25:05, 0.741s/it]: train_loss_raw=1.2453, running_loss=1.2042, LR=0.000100
[2025-08-27 01:59:14,931][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025696] [Batch 01056/03080] [00:13:02/00:24:59, 0.741s/it]: train_loss_raw=1.3410, running_loss=1.2073, LR=0.000100
[2025-08-27 01:59:20,688][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025704] [Batch 01064/03080] [00:13:08/00:24:53, 0.741s/it]: train_loss_raw=1.1914, running_loss=1.2077, LR=0.000100
[2025-08-27 01:59:26,556][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025712] [Batch 01072/03080] [00:13:14/00:24:47, 0.741s/it]: train_loss_raw=1.1609, running_loss=1.2076, LR=0.000100
[2025-08-27 01:59:32,458][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025720] [Batch 01080/03080] [00:13:19/00:24:41, 0.741s/it]: train_loss_raw=1.2783, running_loss=1.2074, LR=0.000100
[2025-08-27 01:59:38,364][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025728] [Batch 01088/03080] [00:13:25/00:24:35, 0.741s/it]: train_loss_raw=1.1521, running_loss=1.2080, LR=0.000100
[2025-08-27 01:59:44,021][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025736] [Batch 01096/03080] [00:13:31/00:24:28, 0.740s/it]: train_loss_raw=1.2583, running_loss=1.2075, LR=0.000100
[2025-08-27 01:59:49,775][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025744] [Batch 01104/03080] [00:13:37/00:24:22, 0.740s/it]: train_loss_raw=1.2959, running_loss=1.2094, LR=0.000100
[2025-08-27 01:59:55,769][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025752] [Batch 01112/03080] [00:13:43/00:24:16, 0.740s/it]: train_loss_raw=1.2535, running_loss=1.2113, LR=0.000100
[2025-08-27 02:00:01,634][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025760] [Batch 01120/03080] [00:13:49/00:24:10, 0.740s/it]: train_loss_raw=1.2639, running_loss=1.2132, LR=0.000100
[2025-08-27 02:00:07,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025768] [Batch 01128/03080] [00:13:55/00:24:05, 0.740s/it]: train_loss_raw=1.2458, running_loss=1.2120, LR=0.000100
[2025-08-27 02:00:13,527][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025776] [Batch 01136/03080] [00:14:00/00:23:59, 0.740s/it]: train_loss_raw=1.2555, running_loss=1.2122, LR=0.000100
[2025-08-27 02:00:19,691][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025784] [Batch 01144/03080] [00:14:07/00:23:53, 0.741s/it]: train_loss_raw=1.1865, running_loss=1.2088, LR=0.000100
[2025-08-27 02:00:25,628][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025792] [Batch 01152/03080] [00:14:13/00:23:47, 0.741s/it]: train_loss_raw=1.2513, running_loss=1.2084, LR=0.000100
[2025-08-27 02:00:31,653][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025800] [Batch 01160/03080] [00:14:19/00:23:41, 0.741s/it]: train_loss_raw=1.2381, running_loss=1.2088, LR=0.000100
[2025-08-27 02:00:37,606][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025808] [Batch 01168/03080] [00:14:25/00:23:36, 0.741s/it]: train_loss_raw=1.2304, running_loss=1.2096, LR=0.000100
[2025-08-27 02:00:43,485][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025816] [Batch 01176/03080] [00:14:30/00:23:30, 0.741s/it]: train_loss_raw=1.0599, running_loss=1.2050, LR=0.000100
[2025-08-27 02:00:49,624][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025824] [Batch 01184/03080] [00:14:37/00:23:24, 0.741s/it]: train_loss_raw=1.2064, running_loss=1.2063, LR=0.000100
[2025-08-27 02:00:55,345][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025832] [Batch 01192/03080] [00:14:42/00:23:18, 0.741s/it]: train_loss_raw=1.1776, running_loss=1.2072, LR=0.000100
[2025-08-27 02:01:01,141][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025840] [Batch 01200/03080] [00:14:48/00:23:12, 0.740s/it]: train_loss_raw=1.2376, running_loss=1.2075, LR=0.000100
[2025-08-27 02:01:07,077][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025848] [Batch 01208/03080] [00:14:54/00:23:06, 0.741s/it]: train_loss_raw=1.2039, running_loss=1.2083, LR=0.000100
[2025-08-27 02:01:13,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025856] [Batch 01216/03080] [00:15:00/00:23:00, 0.741s/it]: train_loss_raw=1.2043, running_loss=1.2098, LR=0.000100
[2025-08-27 02:01:19,120][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025864] [Batch 01224/03080] [00:15:06/00:22:54, 0.741s/it]: train_loss_raw=1.2510, running_loss=1.2124, LR=0.000100
[2025-08-27 02:01:25,096][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025872] [Batch 01232/03080] [00:15:12/00:22:48, 0.741s/it]: train_loss_raw=1.2215, running_loss=1.2130, LR=0.000100
[2025-08-27 02:01:31,160][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025880] [Batch 01240/03080] [00:15:18/00:22:43, 0.741s/it]: train_loss_raw=1.1556, running_loss=1.2125, LR=0.000100
[2025-08-27 02:01:37,271][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025888] [Batch 01248/03080] [00:15:24/00:22:37, 0.741s/it]: train_loss_raw=1.2639, running_loss=1.2134, LR=0.000100
[2025-08-27 02:01:43,287][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025896] [Batch 01256/03080] [00:15:30/00:22:31, 0.741s/it]: train_loss_raw=1.1261, running_loss=1.2112, LR=0.000100
[2025-08-27 02:01:49,435][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025904] [Batch 01264/03080] [00:15:36/00:22:26, 0.741s/it]: train_loss_raw=1.2151, running_loss=1.2104, LR=0.000100
[2025-08-27 02:01:55,668][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025912] [Batch 01272/03080] [00:15:43/00:22:20, 0.741s/it]: train_loss_raw=1.1971, running_loss=1.2076, LR=0.000100
[2025-08-27 02:02:01,852][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025920] [Batch 01280/03080] [00:15:49/00:22:14, 0.742s/it]: train_loss_raw=1.1292, running_loss=1.2074, LR=0.000100
[2025-08-27 02:02:07,777][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025928] [Batch 01288/03080] [00:15:55/00:22:09, 0.742s/it]: train_loss_raw=1.2909, running_loss=1.2065, LR=0.000100
[2025-08-27 02:02:13,547][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025936] [Batch 01296/03080] [00:16:01/00:22:02, 0.742s/it]: train_loss_raw=1.2700, running_loss=1.2073, LR=0.000100
[2025-08-27 02:02:19,360][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025944] [Batch 01304/03080] [00:16:06/00:21:56, 0.741s/it]: train_loss_raw=1.1944, running_loss=1.2063, LR=0.000100
[2025-08-27 02:02:25,129][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025952] [Batch 01312/03080] [00:16:12/00:21:50, 0.741s/it]: train_loss_raw=1.1087, running_loss=1.2036, LR=0.000100
[2025-08-27 02:02:30,885][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025960] [Batch 01320/03080] [00:16:18/00:21:44, 0.741s/it]: train_loss_raw=1.2363, running_loss=1.2058, LR=0.000100
[2025-08-27 02:02:36,621][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025968] [Batch 01328/03080] [00:16:24/00:21:38, 0.741s/it]: train_loss_raw=1.2711, running_loss=1.2057, LR=0.000100
[2025-08-27 02:02:42,634][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025976] [Batch 01336/03080] [00:16:30/00:21:32, 0.741s/it]: train_loss_raw=1.2737, running_loss=1.2051, LR=0.000100
[2025-08-27 02:02:48,516][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025984] [Batch 01344/03080] [00:16:35/00:21:26, 0.741s/it]: train_loss_raw=1.2521, running_loss=1.2018, LR=0.000100
[2025-08-27 02:02:54,669][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025992] [Batch 01352/03080] [00:16:42/00:21:20, 0.741s/it]: train_loss_raw=1.1451, running_loss=1.2013, LR=0.000100
[2025-08-27 02:03:00,696][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026000] [Batch 01360/03080] [00:16:48/00:21:15, 0.741s/it]: train_loss_raw=1.1856, running_loss=1.1997, LR=0.000100
[2025-08-27 02:03:11,355][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026008] [Batch 01368/03080] [00:16:58/00:21:15, 0.745s/it]: train_loss_raw=1.1344, running_loss=1.1988, LR=0.000100
[2025-08-27 02:03:17,326][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026016] [Batch 01376/03080] [00:17:04/00:21:09, 0.745s/it]: train_loss_raw=1.2557, running_loss=1.1991, LR=0.000100
[2025-08-27 02:03:23,301][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026024] [Batch 01384/03080] [00:17:10/00:21:03, 0.745s/it]: train_loss_raw=1.2609, running_loss=1.1981, LR=0.000100
[2025-08-27 02:03:29,200][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026032] [Batch 01392/03080] [00:17:16/00:20:57, 0.745s/it]: train_loss_raw=1.1698, running_loss=1.1974, LR=0.000100
[2025-08-27 02:03:35,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026040] [Batch 01400/03080] [00:17:22/00:20:51, 0.745s/it]: train_loss_raw=1.2141, running_loss=1.1958, LR=0.000100
[2025-08-27 02:03:41,319][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026048] [Batch 01408/03080] [00:17:28/00:20:45, 0.745s/it]: train_loss_raw=1.2154, running_loss=1.1944, LR=0.000100
[2025-08-27 02:03:47,355][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026056] [Batch 01416/03080] [00:17:34/00:20:39, 0.745s/it]: train_loss_raw=1.1564, running_loss=1.1965, LR=0.000100
[2025-08-27 02:03:53,421][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026064] [Batch 01424/03080] [00:17:40/00:20:33, 0.745s/it]: train_loss_raw=1.2445, running_loss=1.1995, LR=0.000100
[2025-08-27 02:03:59,688][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026072] [Batch 01432/03080] [00:17:47/00:20:28, 0.745s/it]: train_loss_raw=1.1610, running_loss=1.2014, LR=0.000100
[2025-08-27 02:04:05,774][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026080] [Batch 01440/03080] [00:17:53/00:20:22, 0.745s/it]: train_loss_raw=1.1936, running_loss=1.2013, LR=0.000100
[2025-08-27 02:04:11,947][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026088] [Batch 01448/03080] [00:17:59/00:20:16, 0.745s/it]: train_loss_raw=1.2822, running_loss=1.2050, LR=0.000100
[2025-08-27 02:04:17,950][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026096] [Batch 01456/03080] [00:18:05/00:20:10, 0.745s/it]: train_loss_raw=1.0923, running_loss=1.2073, LR=0.000100
[2025-08-27 02:04:23,823][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026104] [Batch 01464/03080] [00:18:11/00:20:04, 0.745s/it]: train_loss_raw=1.1794, running_loss=1.2081, LR=0.000100
[2025-08-27 02:04:29,660][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026112] [Batch 01472/03080] [00:18:17/00:19:58, 0.745s/it]: train_loss_raw=1.1754, running_loss=1.2097, LR=0.000100
[2025-08-27 02:04:35,837][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026120] [Batch 01480/03080] [00:18:23/00:19:52, 0.745s/it]: train_loss_raw=1.2325, running_loss=1.2092, LR=0.000100
[2025-08-27 02:04:41,743][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026128] [Batch 01488/03080] [00:18:29/00:19:46, 0.745s/it]: train_loss_raw=1.1222, running_loss=1.2107, LR=0.000100
[2025-08-27 02:04:47,954][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026136] [Batch 01496/03080] [00:18:35/00:19:41, 0.746s/it]: train_loss_raw=1.2217, running_loss=1.2118, LR=0.000100
[2025-08-27 02:04:53,932][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026144] [Batch 01504/03080] [00:18:41/00:19:35, 0.746s/it]: train_loss_raw=1.2434, running_loss=1.2077, LR=0.000100
[2025-08-27 02:04:59,874][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026152] [Batch 01512/03080] [00:18:47/00:19:29, 0.746s/it]: train_loss_raw=1.1893, running_loss=1.2064, LR=0.000100
[2025-08-27 02:05:06,099][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026160] [Batch 01520/03080] [00:18:53/00:19:23, 0.746s/it]: train_loss_raw=1.0880, running_loss=1.2029, LR=0.000100
[2025-08-27 02:05:12,021][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026168] [Batch 01528/03080] [00:18:59/00:19:17, 0.746s/it]: train_loss_raw=1.1610, running_loss=1.2007, LR=0.000100
[2025-08-27 02:05:17,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026176] [Batch 01536/03080] [00:19:05/00:19:11, 0.746s/it]: train_loss_raw=1.1739, running_loss=1.2013, LR=0.000100
[2025-08-27 02:05:23,830][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026184] [Batch 01544/03080] [00:19:11/00:19:05, 0.746s/it]: train_loss_raw=1.2374, running_loss=1.2026, LR=0.000100
[2025-08-27 02:05:30,017][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026192] [Batch 01552/03080] [00:19:17/00:18:59, 0.746s/it]: train_loss_raw=1.1892, running_loss=1.2020, LR=0.000100
[2025-08-27 02:05:35,801][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026200] [Batch 01560/03080] [00:19:23/00:18:53, 0.746s/it]: train_loss_raw=1.2289, running_loss=1.2028, LR=0.000100
[2025-08-27 02:05:41,454][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026208] [Batch 01568/03080] [00:19:28/00:18:47, 0.745s/it]: train_loss_raw=1.1351, running_loss=1.2029, LR=0.000100
[2025-08-27 02:05:47,327][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026216] [Batch 01576/03080] [00:19:34/00:18:41, 0.745s/it]: train_loss_raw=1.1669, running_loss=1.2018, LR=0.000100
[2025-08-27 02:05:53,303][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026224] [Batch 01584/03080] [00:19:40/00:18:35, 0.745s/it]: train_loss_raw=1.2887, running_loss=1.2044, LR=0.000100
[2025-08-27 02:05:59,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026232] [Batch 01592/03080] [00:19:46/00:18:29, 0.745s/it]: train_loss_raw=1.2372, running_loss=1.2057, LR=0.000100
[2025-08-27 02:06:05,220][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026240] [Batch 01600/03080] [00:19:52/00:18:23, 0.745s/it]: train_loss_raw=1.1040, running_loss=1.2042, LR=0.000100
[2025-08-27 02:06:10,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026248] [Batch 01608/03080] [00:19:58/00:18:17, 0.745s/it]: train_loss_raw=1.1079, running_loss=1.2021, LR=0.000100
[2025-08-27 02:06:16,761][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026256] [Batch 01616/03080] [00:20:04/00:18:10, 0.745s/it]: train_loss_raw=1.1805, running_loss=1.2005, LR=0.000100
[2025-08-27 02:06:22,686][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026264] [Batch 01624/03080] [00:20:10/00:18:04, 0.745s/it]: train_loss_raw=1.2316, running_loss=1.1987, LR=0.000100
[2025-08-27 02:06:28,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026272] [Batch 01632/03080] [00:20:16/00:17:59, 0.745s/it]: train_loss_raw=1.1443, running_loss=1.2002, LR=0.000100
[2025-08-27 02:06:34,800][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026280] [Batch 01640/03080] [00:20:22/00:17:53, 0.745s/it]: train_loss_raw=1.1457, running_loss=1.1971, LR=0.000100
[2025-08-27 02:06:40,642][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026288] [Batch 01648/03080] [00:20:28/00:17:47, 0.745s/it]: train_loss_raw=1.1561, running_loss=1.1992, LR=0.000100
[2025-08-27 02:06:46,498][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026296] [Batch 01656/03080] [00:20:33/00:17:41, 0.745s/it]: train_loss_raw=1.1268, running_loss=1.1998, LR=0.000100
[2025-08-27 02:06:52,235][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026304] [Batch 01664/03080] [00:20:39/00:17:34, 0.745s/it]: train_loss_raw=1.2688, running_loss=1.2007, LR=0.000100
[2025-08-27 02:06:58,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026312] [Batch 01672/03080] [00:20:45/00:17:29, 0.745s/it]: train_loss_raw=1.2777, running_loss=1.2023, LR=0.000100
[2025-08-27 02:07:04,158][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026320] [Batch 01680/03080] [00:20:51/00:17:23, 0.745s/it]: train_loss_raw=1.2338, running_loss=1.2035, LR=0.000100
[2025-08-27 02:07:10,137][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026328] [Batch 01688/03080] [00:20:57/00:17:17, 0.745s/it]: train_loss_raw=1.2254, running_loss=1.2043, LR=0.000100
[2025-08-27 02:07:15,993][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026336] [Batch 01696/03080] [00:21:03/00:17:11, 0.745s/it]: train_loss_raw=1.1628, running_loss=1.2056, LR=0.000100
[2025-08-27 02:07:22,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026344] [Batch 01704/03080] [00:21:09/00:17:05, 0.745s/it]: train_loss_raw=1.1506, running_loss=1.2040, LR=0.000100
[2025-08-27 02:07:28,206][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026352] [Batch 01712/03080] [00:21:15/00:16:59, 0.745s/it]: train_loss_raw=1.2270, running_loss=1.2042, LR=0.000100
[2025-08-27 02:07:34,065][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026360] [Batch 01720/03080] [00:21:21/00:16:53, 0.745s/it]: train_loss_raw=1.2029, running_loss=1.2054, LR=0.000100
[2025-08-27 02:07:39,934][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026368] [Batch 01728/03080] [00:21:27/00:16:47, 0.745s/it]: train_loss_raw=1.1982, running_loss=1.2024, LR=0.000100
[2025-08-27 02:07:45,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026376] [Batch 01736/03080] [00:21:33/00:16:41, 0.745s/it]: train_loss_raw=1.1725, running_loss=1.2011, LR=0.000100
[2025-08-27 02:07:51,829][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026384] [Batch 01744/03080] [00:21:39/00:16:35, 0.745s/it]: train_loss_raw=1.1860, running_loss=1.2006, LR=0.000100
[2025-08-27 02:07:57,660][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026392] [Batch 01752/03080] [00:21:45/00:16:29, 0.745s/it]: train_loss_raw=1.1889, running_loss=1.2016, LR=0.000100
[2025-08-27 02:08:03,815][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026400] [Batch 01760/03080] [00:21:51/00:16:23, 0.745s/it]: train_loss_raw=1.1814, running_loss=1.2016, LR=0.000100
[2025-08-27 02:08:09,911][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026408] [Batch 01768/03080] [00:21:57/00:16:17, 0.745s/it]: train_loss_raw=1.0604, running_loss=1.1986, LR=0.000100
[2025-08-27 02:08:16,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026416] [Batch 01776/03080] [00:22:03/00:16:11, 0.745s/it]: train_loss_raw=1.2156, running_loss=1.1969, LR=0.000100
[2025-08-27 02:08:22,334][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026424] [Batch 01784/03080] [00:22:09/00:16:06, 0.745s/it]: train_loss_raw=1.1100, running_loss=1.1956, LR=0.000100
[2025-08-27 02:08:28,575][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026432] [Batch 01792/03080] [00:22:16/00:16:00, 0.746s/it]: train_loss_raw=1.1862, running_loss=1.1941, LR=0.000100
[2025-08-27 02:08:34,607][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026440] [Batch 01800/03080] [00:22:22/00:15:54, 0.746s/it]: train_loss_raw=1.2360, running_loss=1.1944, LR=0.000100
[2025-08-27 02:08:40,670][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026448] [Batch 01808/03080] [00:22:28/00:15:48, 0.746s/it]: train_loss_raw=1.2042, running_loss=1.1949, LR=0.000100
[2025-08-27 02:08:46,544][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026456] [Batch 01816/03080] [00:22:33/00:15:42, 0.746s/it]: train_loss_raw=1.2770, running_loss=1.1975, LR=0.000100
[2025-08-27 02:08:52,385][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026464] [Batch 01824/03080] [00:22:39/00:15:36, 0.746s/it]: train_loss_raw=1.1650, running_loss=1.1970, LR=0.000100
[2025-08-27 02:08:58,297][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026472] [Batch 01832/03080] [00:22:45/00:15:30, 0.745s/it]: train_loss_raw=1.1458, running_loss=1.1953, LR=0.000100
[2025-08-27 02:09:04,258][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026480] [Batch 01840/03080] [00:22:51/00:15:24, 0.745s/it]: train_loss_raw=1.1647, running_loss=1.1967, LR=0.000100
[2025-08-27 02:09:09,960][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026488] [Batch 01848/03080] [00:22:57/00:15:18, 0.745s/it]: train_loss_raw=1.2268, running_loss=1.1990, LR=0.000100
[2025-08-27 02:09:15,762][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026496] [Batch 01856/03080] [00:23:03/00:15:12, 0.745s/it]: train_loss_raw=1.1283, running_loss=1.1997, LR=0.000100
[2025-08-27 02:09:21,608][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026504] [Batch 01864/03080] [00:23:09/00:15:06, 0.745s/it]: train_loss_raw=1.1533, running_loss=1.1991, LR=0.000100
[2025-08-27 02:09:27,682][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026512] [Batch 01872/03080] [00:23:15/00:15:00, 0.745s/it]: train_loss_raw=1.1683, running_loss=1.1995, LR=0.000100
[2025-08-27 02:09:33,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026520] [Batch 01880/03080] [00:23:21/00:14:54, 0.745s/it]: train_loss_raw=1.2424, running_loss=1.1984, LR=0.000100
[2025-08-27 02:09:39,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026528] [Batch 01888/03080] [00:23:27/00:14:48, 0.745s/it]: train_loss_raw=1.1182, running_loss=1.1962, LR=0.000100
[2025-08-27 02:09:45,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026536] [Batch 01896/03080] [00:23:33/00:14:42, 0.745s/it]: train_loss_raw=1.1718, running_loss=1.1951, LR=0.000100
[2025-08-27 02:09:51,706][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026544] [Batch 01904/03080] [00:23:39/00:14:36, 0.745s/it]: train_loss_raw=1.2224, running_loss=1.1937, LR=0.000100
[2025-08-27 02:09:57,785][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026552] [Batch 01912/03080] [00:23:45/00:14:30, 0.745s/it]: train_loss_raw=1.2444, running_loss=1.1968, LR=0.000100
[2025-08-27 02:10:03,684][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026560] [Batch 01920/03080] [00:23:51/00:14:24, 0.745s/it]: train_loss_raw=1.2619, running_loss=1.1972, LR=0.000100
[2025-08-27 02:10:09,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026568] [Batch 01928/03080] [00:23:57/00:14:18, 0.745s/it]: train_loss_raw=1.2851, running_loss=1.1955, LR=0.000100
[2025-08-27 02:10:15,473][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026576] [Batch 01936/03080] [00:24:02/00:14:12, 0.745s/it]: train_loss_raw=1.3625, running_loss=1.1968, LR=0.000100
[2025-08-27 02:10:21,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026584] [Batch 01944/03080] [00:24:09/00:14:06, 0.745s/it]: train_loss_raw=1.2450, running_loss=1.1967, LR=0.000100
[2025-08-27 02:10:27,719][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026592] [Batch 01952/03080] [00:24:15/00:14:00, 0.745s/it]: train_loss_raw=1.2814, running_loss=1.1994, LR=0.000100
[2025-08-27 02:10:33,643][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026600] [Batch 01960/03080] [00:24:21/00:13:54, 0.745s/it]: train_loss_raw=1.1778, running_loss=1.1940, LR=0.000100
[2025-08-27 02:10:39,746][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026608] [Batch 01968/03080] [00:24:27/00:13:49, 0.746s/it]: train_loss_raw=1.2244, running_loss=1.1926, LR=0.000100
[2025-08-27 02:10:45,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026616] [Batch 01976/03080] [00:24:33/00:13:43, 0.746s/it]: train_loss_raw=1.2592, running_loss=1.1925, LR=0.000100
[2025-08-27 02:10:51,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026624] [Batch 01984/03080] [00:24:39/00:13:37, 0.746s/it]: train_loss_raw=1.1408, running_loss=1.1905, LR=0.000100
[2025-08-27 02:10:57,956][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026632] [Batch 01992/03080] [00:24:45/00:13:31, 0.746s/it]: train_loss_raw=1.1813, running_loss=1.1913, LR=0.000100
[2025-08-27 02:11:04,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026640] [Batch 02000/03080] [00:24:51/00:13:25, 0.746s/it]: train_loss_raw=1.2116, running_loss=1.1930, LR=0.000100
[2025-08-27 02:11:10,024][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026648] [Batch 02008/03080] [00:24:57/00:13:19, 0.746s/it]: train_loss_raw=1.2102, running_loss=1.1906, LR=0.000100
[2025-08-27 02:11:15,731][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026656] [Batch 02016/03080] [00:25:03/00:13:13, 0.746s/it]: train_loss_raw=1.1829, running_loss=1.1919, LR=0.000100
[2025-08-27 02:11:21,950][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026664] [Batch 02024/03080] [00:25:09/00:13:07, 0.746s/it]: train_loss_raw=1.0875, running_loss=1.1926, LR=0.000100
[2025-08-27 02:11:28,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026672] [Batch 02032/03080] [00:25:15/00:13:01, 0.746s/it]: train_loss_raw=1.2513, running_loss=1.1924, LR=0.000100
[2025-08-27 02:11:34,043][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026680] [Batch 02040/03080] [00:25:21/00:12:55, 0.746s/it]: train_loss_raw=1.1924, running_loss=1.1926, LR=0.000100
[2025-08-27 02:11:40,076][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026688] [Batch 02048/03080] [00:25:27/00:12:49, 0.746s/it]: train_loss_raw=1.1830, running_loss=1.1952, LR=0.000100
[2025-08-27 02:11:45,891][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026696] [Batch 02056/03080] [00:25:33/00:12:43, 0.746s/it]: train_loss_raw=1.2865, running_loss=1.1938, LR=0.000100
[2025-08-27 02:11:51,899][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026704] [Batch 02064/03080] [00:25:39/00:12:37, 0.746s/it]: train_loss_raw=1.0222, running_loss=1.1912, LR=0.000100
[2025-08-27 02:11:57,825][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026712] [Batch 02072/03080] [00:25:45/00:12:31, 0.746s/it]: train_loss_raw=1.1776, running_loss=1.1916, LR=0.000100
[2025-08-27 02:12:03,728][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026720] [Batch 02080/03080] [00:25:51/00:12:25, 0.746s/it]: train_loss_raw=1.2026, running_loss=1.1947, LR=0.000100
[2025-08-27 02:12:09,641][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026728] [Batch 02088/03080] [00:25:57/00:12:19, 0.746s/it]: train_loss_raw=1.1624, running_loss=1.1943, LR=0.000100
[2025-08-27 02:12:15,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026736] [Batch 02096/03080] [00:26:03/00:12:13, 0.746s/it]: train_loss_raw=1.1930, running_loss=1.1910, LR=0.000100
[2025-08-27 02:12:21,769][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026744] [Batch 02104/03080] [00:26:09/00:12:07, 0.746s/it]: train_loss_raw=1.1619, running_loss=1.1904, LR=0.000100
[2025-08-27 02:12:27,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026752] [Batch 02112/03080] [00:26:15/00:12:01, 0.746s/it]: train_loss_raw=1.1883, running_loss=1.1881, LR=0.000100
[2025-08-27 02:12:33,762][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026760] [Batch 02120/03080] [00:26:21/00:11:56, 0.746s/it]: train_loss_raw=1.1223, running_loss=1.1866, LR=0.000100
[2025-08-27 02:12:39,644][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026768] [Batch 02128/03080] [00:26:27/00:11:50, 0.746s/it]: train_loss_raw=1.2681, running_loss=1.1884, LR=0.000100
[2025-08-27 02:12:45,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026776] [Batch 02136/03080] [00:26:33/00:11:44, 0.746s/it]: train_loss_raw=1.3019, running_loss=1.1913, LR=0.000100
[2025-08-27 02:12:51,873][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026784] [Batch 02144/03080] [00:26:39/00:11:38, 0.746s/it]: train_loss_raw=1.1351, running_loss=1.1878, LR=0.000100
[2025-08-27 02:12:57,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026792] [Batch 02152/03080] [00:26:45/00:11:32, 0.746s/it]: train_loss_raw=1.2025, running_loss=1.1885, LR=0.000100
[2025-08-27 02:13:03,813][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026800] [Batch 02160/03080] [00:26:51/00:11:26, 0.746s/it]: train_loss_raw=1.2503, running_loss=1.1906, LR=0.000100
[2025-08-27 02:13:10,123][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026808] [Batch 02168/03080] [00:26:57/00:11:20, 0.746s/it]: train_loss_raw=1.1118, running_loss=1.1889, LR=0.000100
[2025-08-27 02:13:16,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026816] [Batch 02176/03080] [00:27:03/00:11:14, 0.746s/it]: train_loss_raw=1.1110, running_loss=1.1882, LR=0.000100
[2025-08-27 02:13:22,161][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026824] [Batch 02184/03080] [00:27:09/00:11:08, 0.746s/it]: train_loss_raw=1.1379, running_loss=1.1859, LR=0.000100
[2025-08-27 02:13:28,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026832] [Batch 02192/03080] [00:27:15/00:11:02, 0.746s/it]: train_loss_raw=1.0978, running_loss=1.1898, LR=0.000100
[2025-08-27 02:13:34,338][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026840] [Batch 02200/03080] [00:27:21/00:10:56, 0.746s/it]: train_loss_raw=1.1344, running_loss=1.1905, LR=0.000100
[2025-08-27 02:13:40,447][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026848] [Batch 02208/03080] [00:27:27/00:10:50, 0.746s/it]: train_loss_raw=1.2392, running_loss=1.1885, LR=0.000100
[2025-08-27 02:13:46,640][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026856] [Batch 02216/03080] [00:27:34/00:10:44, 0.746s/it]: train_loss_raw=1.1215, running_loss=1.1886, LR=0.000100
[2025-08-27 02:13:52,703][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026864] [Batch 02224/03080] [00:27:40/00:10:38, 0.746s/it]: train_loss_raw=1.1632, running_loss=1.1884, LR=0.000100
[2025-08-27 02:13:58,923][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026872] [Batch 02232/03080] [00:27:46/00:10:33, 0.747s/it]: train_loss_raw=1.1401, running_loss=1.1878, LR=0.000100
[2025-08-27 02:14:04,829][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026880] [Batch 02240/03080] [00:27:52/00:10:27, 0.747s/it]: train_loss_raw=1.1632, running_loss=1.1887, LR=0.000100
[2025-08-27 02:14:10,806][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026888] [Batch 02248/03080] [00:27:58/00:10:21, 0.747s/it]: train_loss_raw=1.0955, running_loss=1.1893, LR=0.000100
[2025-08-27 02:14:16,901][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026896] [Batch 02256/03080] [00:28:04/00:10:15, 0.747s/it]: train_loss_raw=1.3585, running_loss=1.1900, LR=0.000100
[2025-08-27 02:14:23,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026904] [Batch 02264/03080] [00:28:10/00:10:09, 0.747s/it]: train_loss_raw=1.2525, running_loss=1.1924, LR=0.000100
[2025-08-27 02:14:29,104][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026912] [Batch 02272/03080] [00:28:16/00:10:03, 0.747s/it]: train_loss_raw=1.1440, running_loss=1.1916, LR=0.000100
[2025-08-27 02:14:35,152][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026920] [Batch 02280/03080] [00:28:22/00:09:57, 0.747s/it]: train_loss_raw=1.2777, running_loss=1.1895, LR=0.000100
[2025-08-27 02:14:40,958][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026928] [Batch 02288/03080] [00:28:28/00:09:51, 0.747s/it]: train_loss_raw=1.2922, running_loss=1.1896, LR=0.000100
[2025-08-27 02:14:46,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026936] [Batch 02296/03080] [00:28:34/00:09:45, 0.747s/it]: train_loss_raw=1.1841, running_loss=1.1876, LR=0.000100
[2025-08-27 02:14:52,789][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026944] [Batch 02304/03080] [00:28:40/00:09:39, 0.747s/it]: train_loss_raw=1.2223, running_loss=1.1885, LR=0.000100
[2025-08-27 02:14:58,662][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026952] [Batch 02312/03080] [00:28:46/00:09:33, 0.747s/it]: train_loss_raw=1.3161, running_loss=1.1906, LR=0.000100
[2025-08-27 02:15:04,568][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026960] [Batch 02320/03080] [00:28:52/00:09:27, 0.747s/it]: train_loss_raw=1.1711, running_loss=1.1904, LR=0.000100
[2025-08-27 02:15:10,479][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026968] [Batch 02328/03080] [00:28:57/00:09:21, 0.747s/it]: train_loss_raw=1.1998, running_loss=1.1904, LR=0.000100
[2025-08-27 02:15:16,385][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026976] [Batch 02336/03080] [00:29:03/00:09:15, 0.747s/it]: train_loss_raw=1.3162, running_loss=1.1895, LR=0.000100
[2025-08-27 02:15:22,463][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026984] [Batch 02344/03080] [00:29:09/00:09:09, 0.747s/it]: train_loss_raw=1.2047, running_loss=1.1897, LR=0.000100
[2025-08-27 02:15:28,427][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026992] [Batch 02352/03080] [00:29:15/00:09:03, 0.747s/it]: train_loss_raw=1.2281, running_loss=1.1910, LR=0.000100
[2025-08-27 02:15:34,221][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027000] [Batch 02360/03080] [00:29:21/00:08:57, 0.746s/it]: train_loss_raw=1.1622, running_loss=1.1858, LR=0.000100
[2025-08-27 02:15:39,951][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027008] [Batch 02368/03080] [00:29:27/00:08:51, 0.746s/it]: train_loss_raw=1.1556, running_loss=1.1866, LR=0.000100
[2025-08-27 02:15:46,170][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027016] [Batch 02376/03080] [00:29:33/00:08:45, 0.746s/it]: train_loss_raw=1.1118, running_loss=1.1844, LR=0.000100
[2025-08-27 02:15:52,336][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027024] [Batch 02384/03080] [00:29:39/00:08:39, 0.747s/it]: train_loss_raw=1.1477, running_loss=1.1827, LR=0.000100
[2025-08-27 02:15:58,504][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027032] [Batch 02392/03080] [00:29:45/00:08:33, 0.747s/it]: train_loss_raw=1.0544, running_loss=1.1795, LR=0.000100
[2025-08-27 02:16:04,745][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027040] [Batch 02400/03080] [00:29:52/00:08:27, 0.747s/it]: train_loss_raw=1.1424, running_loss=1.1802, LR=0.000100
[2025-08-27 02:16:10,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027048] [Batch 02408/03080] [00:29:58/00:08:21, 0.747s/it]: train_loss_raw=1.1119, running_loss=1.1812, LR=0.000100
[2025-08-27 02:16:16,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027056] [Batch 02416/03080] [00:30:04/00:08:15, 0.747s/it]: train_loss_raw=1.1799, running_loss=1.1820, LR=0.000100
[2025-08-27 02:16:22,898][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027064] [Batch 02424/03080] [00:30:10/00:08:09, 0.747s/it]: train_loss_raw=1.1846, running_loss=1.1825, LR=0.000100
[2025-08-27 02:16:28,957][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027072] [Batch 02432/03080] [00:30:16/00:08:03, 0.747s/it]: train_loss_raw=1.2527, running_loss=1.1840, LR=0.000100
[2025-08-27 02:16:34,785][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027080] [Batch 02440/03080] [00:30:22/00:07:57, 0.747s/it]: train_loss_raw=1.1956, running_loss=1.1850, LR=0.000100
[2025-08-27 02:16:40,678][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027088] [Batch 02448/03080] [00:30:28/00:07:51, 0.747s/it]: train_loss_raw=1.2171, running_loss=1.1848, LR=0.000100
[2025-08-27 02:16:46,706][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027096] [Batch 02456/03080] [00:30:34/00:07:46, 0.747s/it]: train_loss_raw=1.2279, running_loss=1.1852, LR=0.000100
[2025-08-27 02:16:52,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027104] [Batch 02464/03080] [00:30:40/00:07:40, 0.747s/it]: train_loss_raw=1.0924, running_loss=1.1847, LR=0.000100
[2025-08-27 02:16:58,826][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027112] [Batch 02472/03080] [00:30:46/00:07:34, 0.747s/it]: train_loss_raw=1.0348, running_loss=1.1801, LR=0.000100
[2025-08-27 02:17:05,018][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027120] [Batch 02480/03080] [00:30:52/00:07:28, 0.747s/it]: train_loss_raw=1.0794, running_loss=1.1772, LR=0.000100
[2025-08-27 02:17:11,290][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027128] [Batch 02488/03080] [00:30:58/00:07:22, 0.747s/it]: train_loss_raw=1.2007, running_loss=1.1772, LR=0.000100
[2025-08-27 02:17:17,552][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027136] [Batch 02496/03080] [00:31:05/00:07:16, 0.747s/it]: train_loss_raw=1.1520, running_loss=1.1763, LR=0.000100
[2025-08-27 02:17:23,699][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027144] [Batch 02504/03080] [00:31:11/00:07:10, 0.747s/it]: train_loss_raw=1.1393, running_loss=1.1759, LR=0.000100
[2025-08-27 02:17:29,584][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027152] [Batch 02512/03080] [00:31:17/00:07:04, 0.747s/it]: train_loss_raw=1.2504, running_loss=1.1792, LR=0.000100
[2025-08-27 02:17:35,315][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027160] [Batch 02520/03080] [00:31:22/00:06:58, 0.747s/it]: train_loss_raw=1.1104, running_loss=1.1782, LR=0.000100
[2025-08-27 02:17:41,006][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027168] [Batch 02528/03080] [00:31:28/00:06:52, 0.747s/it]: train_loss_raw=1.2777, running_loss=1.1752, LR=0.000100
[2025-08-27 02:17:47,095][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027176] [Batch 02536/03080] [00:31:34/00:06:46, 0.747s/it]: train_loss_raw=1.2241, running_loss=1.1777, LR=0.000100
[2025-08-27 02:17:53,278][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027184] [Batch 02544/03080] [00:31:40/00:06:40, 0.747s/it]: train_loss_raw=1.1009, running_loss=1.1739, LR=0.000100
[2025-08-27 02:17:59,412][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027192] [Batch 02552/03080] [00:31:46/00:06:34, 0.747s/it]: train_loss_raw=1.1308, running_loss=1.1733, LR=0.000100
[2025-08-27 02:18:05,636][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027200] [Batch 02560/03080] [00:31:53/00:06:28, 0.747s/it]: train_loss_raw=1.2327, running_loss=1.1735, LR=0.000100
[2025-08-27 02:18:11,737][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027208] [Batch 02568/03080] [00:31:59/00:06:22, 0.747s/it]: train_loss_raw=1.1493, running_loss=1.1720, LR=0.000100
[2025-08-27 02:18:17,727][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027216] [Batch 02576/03080] [00:32:05/00:06:16, 0.747s/it]: train_loss_raw=1.2399, running_loss=1.1705, LR=0.000100
[2025-08-27 02:18:23,860][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027224] [Batch 02584/03080] [00:32:11/00:06:10, 0.747s/it]: train_loss_raw=1.1644, running_loss=1.1735, LR=0.000100
[2025-08-27 02:18:29,768][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027232] [Batch 02592/03080] [00:32:17/00:06:04, 0.747s/it]: train_loss_raw=1.0866, running_loss=1.1750, LR=0.000100
[2025-08-27 02:18:35,955][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027240] [Batch 02600/03080] [00:32:23/00:05:58, 0.747s/it]: train_loss_raw=1.2466, running_loss=1.1767, LR=0.000100
[2025-08-27 02:18:41,964][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027248] [Batch 02608/03080] [00:32:29/00:05:52, 0.747s/it]: train_loss_raw=1.0746, running_loss=1.1786, LR=0.000100
[2025-08-27 02:18:48,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027256] [Batch 02616/03080] [00:32:35/00:05:46, 0.748s/it]: train_loss_raw=1.1215, running_loss=1.1762, LR=0.000100
[2025-08-27 02:18:53,953][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027264] [Batch 02624/03080] [00:32:41/00:05:40, 0.747s/it]: train_loss_raw=1.1706, running_loss=1.1744, LR=0.000100
[2025-08-27 02:19:00,036][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027272] [Batch 02632/03080] [00:32:47/00:05:34, 0.748s/it]: train_loss_raw=1.1868, running_loss=1.1734, LR=0.000100
[2025-08-27 02:19:06,096][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027280] [Batch 02640/03080] [00:32:53/00:05:28, 0.748s/it]: train_loss_raw=1.2798, running_loss=1.1748, LR=0.000100
[2025-08-27 02:19:12,083][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027288] [Batch 02648/03080] [00:32:59/00:05:22, 0.748s/it]: train_loss_raw=1.2144, running_loss=1.1783, LR=0.000100
[2025-08-27 02:19:18,133][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027296] [Batch 02656/03080] [00:33:05/00:05:16, 0.748s/it]: train_loss_raw=1.0635, running_loss=1.1753, LR=0.000100
[2025-08-27 02:19:24,095][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027304] [Batch 02664/03080] [00:33:11/00:05:10, 0.748s/it]: train_loss_raw=1.2098, running_loss=1.1747, LR=0.000100
[2025-08-27 02:19:30,056][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027312] [Batch 02672/03080] [00:33:17/00:05:05, 0.748s/it]: train_loss_raw=1.3111, running_loss=1.1753, LR=0.000100
[2025-08-27 02:19:36,004][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027320] [Batch 02680/03080] [00:33:23/00:04:59, 0.748s/it]: train_loss_raw=1.2760, running_loss=1.1778, LR=0.000100
[2025-08-27 02:19:42,127][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027328] [Batch 02688/03080] [00:33:29/00:04:53, 0.748s/it]: train_loss_raw=1.1344, running_loss=1.1769, LR=0.000100
[2025-08-27 02:19:47,978][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027336] [Batch 02696/03080] [00:33:35/00:04:47, 0.748s/it]: train_loss_raw=1.1698, running_loss=1.1768, LR=0.000100
[2025-08-27 02:19:53,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027344] [Batch 02704/03080] [00:33:41/00:04:41, 0.748s/it]: train_loss_raw=1.1446, running_loss=1.1780, LR=0.000100
[2025-08-27 02:19:59,913][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027352] [Batch 02712/03080] [00:33:47/00:04:35, 0.748s/it]: train_loss_raw=1.1669, running_loss=1.1767, LR=0.000100
[2025-08-27 02:20:06,115][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027360] [Batch 02720/03080] [00:33:53/00:04:29, 0.748s/it]: train_loss_raw=1.2526, running_loss=1.1770, LR=0.000100
[2025-08-27 02:20:12,256][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027368] [Batch 02728/03080] [00:33:59/00:04:23, 0.748s/it]: train_loss_raw=1.2712, running_loss=1.1820, LR=0.000100
[2025-08-27 02:20:18,077][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027376] [Batch 02736/03080] [00:34:05/00:04:17, 0.748s/it]: train_loss_raw=1.1261, running_loss=1.1816, LR=0.000100
[2025-08-27 02:20:23,922][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027384] [Batch 02744/03080] [00:34:11/00:04:11, 0.748s/it]: train_loss_raw=1.1357, running_loss=1.1818, LR=0.000100
[2025-08-27 02:20:29,782][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027392] [Batch 02752/03080] [00:34:17/00:04:05, 0.748s/it]: train_loss_raw=1.1854, running_loss=1.1808, LR=0.000100
[2025-08-27 02:20:35,630][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027400] [Batch 02760/03080] [00:34:23/00:03:59, 0.747s/it]: train_loss_raw=1.2178, running_loss=1.1798, LR=0.000100
[2025-08-27 02:20:41,567][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027408] [Batch 02768/03080] [00:34:29/00:03:53, 0.747s/it]: train_loss_raw=1.1029, running_loss=1.1780, LR=0.000100
[2025-08-27 02:20:47,559][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027416] [Batch 02776/03080] [00:34:35/00:03:47, 0.747s/it]: train_loss_raw=1.1717, running_loss=1.1796, LR=0.000100
[2025-08-27 02:20:53,560][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027424] [Batch 02784/03080] [00:34:41/00:03:41, 0.747s/it]: train_loss_raw=1.2928, running_loss=1.1800, LR=0.000100
[2025-08-27 02:20:59,465][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027432] [Batch 02792/03080] [00:34:46/00:03:35, 0.747s/it]: train_loss_raw=1.2438, running_loss=1.1807, LR=0.000100
[2025-08-27 02:21:05,433][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027440] [Batch 02800/03080] [00:34:52/00:03:29, 0.747s/it]: train_loss_raw=1.2308, running_loss=1.1794, LR=0.000100
[2025-08-27 02:21:11,473][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027448] [Batch 02808/03080] [00:34:58/00:03:23, 0.747s/it]: train_loss_raw=1.1560, running_loss=1.1799, LR=0.000100
[2025-08-27 02:21:17,649][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027456] [Batch 02816/03080] [00:35:05/00:03:17, 0.748s/it]: train_loss_raw=1.0375, running_loss=1.1766, LR=0.000100
[2025-08-27 02:21:23,587][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027464] [Batch 02824/03080] [00:35:11/00:03:11, 0.748s/it]: train_loss_raw=1.1666, running_loss=1.1761, LR=0.000100
[2025-08-27 02:21:29,389][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027472] [Batch 02832/03080] [00:35:16/00:03:05, 0.747s/it]: train_loss_raw=1.1450, running_loss=1.1765, LR=0.000100
[2025-08-27 02:21:35,238][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027480] [Batch 02840/03080] [00:35:22/00:02:59, 0.747s/it]: train_loss_raw=1.2519, running_loss=1.1783, LR=0.000100
[2025-08-27 02:21:41,021][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027488] [Batch 02848/03080] [00:35:28/00:02:53, 0.747s/it]: train_loss_raw=1.1896, running_loss=1.1809, LR=0.000100
[2025-08-27 02:21:47,184][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027496] [Batch 02856/03080] [00:35:34/00:02:47, 0.747s/it]: train_loss_raw=1.2500, running_loss=1.1796, LR=0.000100
[2025-08-27 02:21:53,397][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027504] [Batch 02864/03080] [00:35:40/00:02:41, 0.748s/it]: train_loss_raw=1.2334, running_loss=1.1786, LR=0.000100
[2025-08-27 02:21:59,135][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027512] [Batch 02872/03080] [00:35:46/00:02:35, 0.747s/it]: train_loss_raw=1.1296, running_loss=1.1779, LR=0.000100
[2025-08-27 02:22:05,302][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027520] [Batch 02880/03080] [00:35:52/00:02:29, 0.747s/it]: train_loss_raw=1.2231, running_loss=1.1773, LR=0.000100
[2025-08-27 02:22:11,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027528] [Batch 02888/03080] [00:35:58/00:02:23, 0.748s/it]: train_loss_raw=1.1546, running_loss=1.1754, LR=0.000100
[2025-08-27 02:22:17,465][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027536] [Batch 02896/03080] [00:36:04/00:02:17, 0.748s/it]: train_loss_raw=1.1535, running_loss=1.1757, LR=0.000100
[2025-08-27 02:22:23,660][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027544] [Batch 02904/03080] [00:36:11/00:02:11, 0.748s/it]: train_loss_raw=1.1859, running_loss=1.1756, LR=0.000100
[2025-08-27 02:22:29,624][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027552] [Batch 02912/03080] [00:36:17/00:02:05, 0.748s/it]: train_loss_raw=1.2187, running_loss=1.1753, LR=0.000100
[2025-08-27 02:22:35,583][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027560] [Batch 02920/03080] [00:36:23/00:01:59, 0.748s/it]: train_loss_raw=1.2223, running_loss=1.1761, LR=0.000100
[2025-08-27 02:22:41,632][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027568] [Batch 02928/03080] [00:36:29/00:01:53, 0.748s/it]: train_loss_raw=1.2281, running_loss=1.1745, LR=0.000100
[2025-08-27 02:22:47,749][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027576] [Batch 02936/03080] [00:36:35/00:01:47, 0.748s/it]: train_loss_raw=1.2394, running_loss=1.1733, LR=0.000100
[2025-08-27 02:22:53,642][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027584] [Batch 02944/03080] [00:36:41/00:01:41, 0.748s/it]: train_loss_raw=1.1738, running_loss=1.1712, LR=0.000100
[2025-08-27 02:22:59,871][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027592] [Batch 02952/03080] [00:36:47/00:01:35, 0.748s/it]: train_loss_raw=1.0268, running_loss=1.1699, LR=0.000100
[2025-08-27 02:23:06,122][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027600] [Batch 02960/03080] [00:36:53/00:01:29, 0.748s/it]: train_loss_raw=1.1393, running_loss=1.1703, LR=0.000100
[2025-08-27 02:23:12,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027608] [Batch 02968/03080] [00:36:59/00:01:23, 0.748s/it]: train_loss_raw=1.1987, running_loss=1.1699, LR=0.000100
[2025-08-27 02:23:18,199][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027616] [Batch 02976/03080] [00:37:05/00:01:17, 0.748s/it]: train_loss_raw=1.1708, running_loss=1.1705, LR=0.000100
[2025-08-27 02:23:24,370][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027624] [Batch 02984/03080] [00:37:11/00:01:11, 0.748s/it]: train_loss_raw=1.2421, running_loss=1.1717, LR=0.000100
[2025-08-27 02:23:30,496][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027632] [Batch 02992/03080] [00:37:17/00:01:05, 0.748s/it]: train_loss_raw=1.1872, running_loss=1.1735, LR=0.000100
[2025-08-27 02:23:36,500][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027640] [Batch 03000/03080] [00:37:23/00:00:59, 0.748s/it]: train_loss_raw=1.0434, running_loss=1.1730, LR=0.000100
[2025-08-27 02:23:42,512][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027648] [Batch 03008/03080] [00:37:29/00:00:53, 0.748s/it]: train_loss_raw=1.1958, running_loss=1.1740, LR=0.000100
[2025-08-27 02:23:48,473][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027656] [Batch 03016/03080] [00:37:35/00:00:47, 0.748s/it]: train_loss_raw=1.1002, running_loss=1.1752, LR=0.000100
[2025-08-27 02:23:54,311][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027664] [Batch 03024/03080] [00:37:41/00:00:41, 0.748s/it]: train_loss_raw=1.2112, running_loss=1.1738, LR=0.000100
[2025-08-27 02:24:00,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027672] [Batch 03032/03080] [00:37:47/00:00:35, 0.748s/it]: train_loss_raw=1.1316, running_loss=1.1703, LR=0.000100
[2025-08-27 02:24:06,436][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027680] [Batch 03040/03080] [00:37:53/00:00:29, 0.748s/it]: train_loss_raw=1.2067, running_loss=1.1730, LR=0.000100
[2025-08-27 02:24:12,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027688] [Batch 03048/03080] [00:37:59/00:00:23, 0.748s/it]: train_loss_raw=1.1552, running_loss=1.1731, LR=0.000100
[2025-08-27 02:24:18,150][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027696] [Batch 03056/03080] [00:38:05/00:00:17, 0.748s/it]: train_loss_raw=1.0401, running_loss=1.1702, LR=0.000100
[2025-08-27 02:24:24,310][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027704] [Batch 03064/03080] [00:38:11/00:00:11, 0.748s/it]: train_loss_raw=1.2270, running_loss=1.1729, LR=0.000100
[2025-08-27 02:24:30,349][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027712] [Batch 03072/03080] [00:38:17/00:00:05, 0.748s/it]: train_loss_raw=1.2100, running_loss=1.1702, LR=0.000100
[2025-08-27 02:24:36,253][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027720] [Batch 03080/03080] [00:38:23/00:00:00, 0.748s/it]: train_loss_raw=1.1737, running_loss=1.1712, LR=0.000100
[2025-08-27 02:24:36,765][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-27 02:24:48,652][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00007/00310] [00:00:11/00:07:28, 1.486s/it]
[2025-08-27 02:25:01,085][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00015/00310] [00:00:24/00:07:26, 1.520s/it]
[2025-08-27 02:25:13,532][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00023/00310] [00:00:36/00:07:18, 1.532s/it]
[2025-08-27 02:25:25,887][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00031/00310] [00:00:49/00:07:06, 1.535s/it]
[2025-08-27 02:25:38,921][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00039/00310] [00:01:02/00:06:59, 1.554s/it]
[2025-08-27 02:25:51,879][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00047/00310] [00:01:15/00:06:49, 1.565s/it]
[2025-08-27 02:26:04,590][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00055/00310] [00:01:27/00:06:38, 1.568s/it]
[2025-08-27 02:26:16,925][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00063/00310] [00:01:40/00:06:24, 1.565s/it]
[2025-08-27 02:26:29,496][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00071/00310] [00:01:52/00:06:12, 1.566s/it]
[2025-08-27 02:26:42,046][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00079/00310] [00:02:05/00:06:00, 1.566s/it]
[2025-08-27 02:26:55,236][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00087/00310] [00:02:18/00:05:49, 1.574s/it]
[2025-08-27 02:27:08,143][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00095/00310] [00:02:31/00:05:37, 1.577s/it]
[2025-08-27 02:27:20,992][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00103/00310] [00:02:44/00:05:25, 1.579s/it]
[2025-08-27 02:27:33,674][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00111/00310] [00:02:56/00:05:12, 1.580s/it]
[2025-08-27 02:27:46,305][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00119/00310] [00:03:09/00:05:00, 1.579s/it]
[2025-08-27 02:27:58,892][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00127/00310] [00:03:22/00:04:47, 1.579s/it]
[2025-08-27 02:28:11,883][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00135/00310] [00:03:35/00:04:35, 1.582s/it]
[2025-08-27 02:28:24,365][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00143/00310] [00:03:47/00:04:22, 1.581s/it]
[2025-08-27 02:28:36,274][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00151/00310] [00:03:59/00:04:08, 1.576s/it]
[2025-08-27 02:28:47,891][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00159/00310] [00:04:11/00:03:55, 1.570s/it]
[2025-08-27 02:29:00,613][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00167/00310] [00:04:23/00:03:43, 1.571s/it]
[2025-08-27 02:29:12,502][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00175/00310] [00:04:35/00:03:29, 1.567s/it]
[2025-08-27 02:29:24,423][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00183/00310] [00:04:47/00:03:16, 1.563s/it]
[2025-08-27 02:29:36,835][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00191/00310] [00:05:00/00:03:04, 1.563s/it]
[2025-08-27 02:29:49,074][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00199/00310] [00:05:12/00:02:51, 1.562s/it]
[2025-08-27 02:30:00,901][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00207/00310] [00:05:24/00:02:38, 1.558s/it]
[2025-08-27 02:30:12,666][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00215/00310] [00:05:35/00:02:26, 1.555s/it]
[2025-08-27 02:30:25,483][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00223/00310] [00:05:48/00:02:13, 1.557s/it]
[2025-08-27 02:30:37,960][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00231/00310] [00:06:01/00:02:01, 1.557s/it]
[2025-08-27 02:30:50,122][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00239/00310] [00:06:13/00:01:48, 1.556s/it]
[2025-08-27 02:31:01,902][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00247/00310] [00:06:25/00:01:36, 1.553s/it]
[2025-08-27 02:31:14,524][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00255/00310] [00:06:37/00:01:23, 1.554s/it]
[2025-08-27 02:31:27,153][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00263/00310] [00:06:50/00:01:11, 1.555s/it]
[2025-08-27 02:31:39,444][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00271/00310] [00:07:02/00:00:59, 1.554s/it]
[2025-08-27 02:31:51,759][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00279/00310] [00:07:14/00:00:46, 1.554s/it]
[2025-08-27 02:32:04,896][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00287/00310] [00:07:28/00:00:34, 1.556s/it]
[2025-08-27 02:32:17,156][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00295/00310] [00:07:40/00:00:21, 1.555s/it]
[2025-08-27 02:32:30,442][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00303/00310] [00:07:53/00:00:09, 1.558s/it]
[2025-08-27 02:32:40,274][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.17120, valid_loss=1.92371
[2025-08-27 02:32:40,274][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-27 02:32:40,275][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.733
[2025-08-27 02:32:40,275][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.038
[2025-08-27 02:32:40,275][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.040
[2025-08-27 02:32:40,275][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.012
[2025-08-27 02:32:40,288][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 07:05:54, remaining time 16:33:46, 00:47:19 per epoch
[2025-08-27 02:32:46,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027728] [Batch 00008/03080] [00:00:05/00:35:18, 0.690s/it]: train_loss_raw=1.2282, running_loss=1.1589, LR=0.000100
[2025-08-27 02:32:52,150][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027736] [Batch 00016/03080] [00:00:11/00:37:08, 0.727s/it]: train_loss_raw=1.2505, running_loss=1.1594, LR=0.000100
[2025-08-27 02:32:58,367][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027744] [Batch 00024/03080] [00:00:17/00:37:53, 0.744s/it]: train_loss_raw=1.1422, running_loss=1.1608, LR=0.000100
[2025-08-27 02:33:04,308][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027752] [Batch 00032/03080] [00:00:23/00:37:46, 0.744s/it]: train_loss_raw=1.3049, running_loss=1.1629, LR=0.000100
[2025-08-27 02:33:10,389][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027760] [Batch 00040/03080] [00:00:29/00:37:50, 0.747s/it]: train_loss_raw=1.1630, running_loss=1.1604, LR=0.000100
[2025-08-27 02:33:16,465][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027768] [Batch 00048/03080] [00:00:35/00:37:51, 0.749s/it]: train_loss_raw=1.0987, running_loss=1.1618, LR=0.000100
[2025-08-27 02:33:22,535][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027776] [Batch 00056/03080] [00:00:42/00:37:49, 0.750s/it]: train_loss_raw=1.2928, running_loss=1.1591, LR=0.000100
[2025-08-27 02:33:28,684][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027784] [Batch 00064/03080] [00:00:48/00:37:50, 0.753s/it]: train_loss_raw=1.1275, running_loss=1.1615, LR=0.000100
[2025-08-27 02:33:34,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027792] [Batch 00072/03080] [00:00:54/00:37:51, 0.755s/it]: train_loss_raw=1.1249, running_loss=1.1598, LR=0.000100
[2025-08-27 02:33:40,893][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027800] [Batch 00080/03080] [00:01:00/00:37:44, 0.755s/it]: train_loss_raw=1.2339, running_loss=1.1601, LR=0.000100
[2025-08-27 02:33:46,999][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027808] [Batch 00088/03080] [00:01:06/00:37:40, 0.756s/it]: train_loss_raw=1.0754, running_loss=1.1586, LR=0.000100
[2025-08-27 02:33:53,055][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027816] [Batch 00096/03080] [00:01:12/00:37:34, 0.756s/it]: train_loss_raw=1.1119, running_loss=1.1592, LR=0.000100
[2025-08-27 02:33:59,132][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027824] [Batch 00104/03080] [00:01:18/00:37:29, 0.756s/it]: train_loss_raw=1.1998, running_loss=1.1580, LR=0.000100
[2025-08-27 02:34:05,310][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027832] [Batch 00112/03080] [00:01:24/00:37:27, 0.757s/it]: train_loss_raw=1.1157, running_loss=1.1562, LR=0.000100
[2025-08-27 02:34:11,070][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027840] [Batch 00120/03080] [00:01:30/00:37:13, 0.755s/it]: train_loss_raw=1.2410, running_loss=1.1571, LR=0.000100
[2025-08-27 02:34:16,898][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027848] [Batch 00128/03080] [00:01:36/00:37:02, 0.753s/it]: train_loss_raw=1.1366, running_loss=1.1577, LR=0.000100
[2025-08-27 02:34:22,774][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027856] [Batch 00136/03080] [00:01:42/00:36:53, 0.752s/it]: train_loss_raw=1.1409, running_loss=1.1586, LR=0.000100
[2025-08-27 02:34:28,769][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027864] [Batch 00144/03080] [00:01:48/00:36:47, 0.752s/it]: train_loss_raw=1.2901, running_loss=1.1598, LR=0.000100
[2025-08-27 02:34:34,910][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027872] [Batch 00152/03080] [00:01:54/00:36:43, 0.753s/it]: train_loss_raw=1.1253, running_loss=1.1590, LR=0.000100
[2025-08-27 02:34:40,883][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027880] [Batch 00160/03080] [00:02:00/00:36:36, 0.752s/it]: train_loss_raw=1.1647, running_loss=1.1568, LR=0.000100
[2025-08-27 02:34:46,788][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027888] [Batch 00168/03080] [00:02:06/00:36:28, 0.752s/it]: train_loss_raw=1.1544, running_loss=1.1571, LR=0.000100
[2025-08-27 02:34:52,652][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027896] [Batch 00176/03080] [00:02:12/00:36:20, 0.751s/it]: train_loss_raw=1.2155, running_loss=1.1599, LR=0.000100
[2025-08-27 02:34:58,679][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027904] [Batch 00184/03080] [00:02:18/00:36:14, 0.751s/it]: train_loss_raw=1.2259, running_loss=1.1622, LR=0.000100
[2025-08-27 02:35:04,596][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027912] [Batch 00192/03080] [00:02:24/00:36:07, 0.750s/it]: train_loss_raw=1.1982, running_loss=1.1620, LR=0.000100
[2025-08-27 02:35:10,573][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027920] [Batch 00200/03080] [00:02:30/00:36:00, 0.750s/it]: train_loss_raw=1.1046, running_loss=1.1611, LR=0.000100
[2025-08-27 02:35:16,445][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027928] [Batch 00208/03080] [00:02:35/00:35:53, 0.750s/it]: train_loss_raw=1.1576, running_loss=1.1626, LR=0.000100
[2025-08-27 02:35:22,369][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027936] [Batch 00216/03080] [00:02:41/00:35:46, 0.749s/it]: train_loss_raw=0.9891, running_loss=1.1606, LR=0.000100
[2025-08-27 02:35:28,354][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027944] [Batch 00224/03080] [00:02:47/00:35:39, 0.749s/it]: train_loss_raw=1.0986, running_loss=1.1591, LR=0.000100
[2025-08-27 02:35:34,452][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027952] [Batch 00232/03080] [00:02:53/00:35:35, 0.750s/it]: train_loss_raw=1.1256, running_loss=1.1586, LR=0.000100
[2025-08-27 02:35:40,395][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027960] [Batch 00240/03080] [00:02:59/00:35:28, 0.750s/it]: train_loss_raw=1.2528, running_loss=1.1583, LR=0.000100
[2025-08-27 02:35:46,430][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027968] [Batch 00248/03080] [00:03:05/00:35:23, 0.750s/it]: train_loss_raw=1.1933, running_loss=1.1626, LR=0.000100
[2025-08-27 02:35:52,401][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027976] [Batch 00256/03080] [00:03:11/00:35:16, 0.750s/it]: train_loss_raw=1.1011, running_loss=1.1590, LR=0.000100
[2025-08-27 02:35:58,112][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027984] [Batch 00264/03080] [00:03:17/00:35:07, 0.748s/it]: train_loss_raw=1.1628, running_loss=1.1596, LR=0.000100
[2025-08-27 02:36:04,233][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027992] [Batch 00272/03080] [00:03:23/00:35:03, 0.749s/it]: train_loss_raw=1.1509, running_loss=1.1607, LR=0.000100
[2025-08-27 02:36:10,243][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028000] [Batch 00280/03080] [00:03:29/00:34:57, 0.749s/it]: train_loss_raw=1.1649, running_loss=1.1607, LR=0.000100
[2025-08-27 02:36:21,103][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028008] [Batch 00288/03080] [00:03:40/00:35:38, 0.766s/it]: train_loss_raw=1.2140, running_loss=1.1604, LR=0.000100
[2025-08-27 02:36:27,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028016] [Batch 00296/03080] [00:03:46/00:35:32, 0.766s/it]: train_loss_raw=1.1139, running_loss=1.1607, LR=0.000100
[2025-08-27 02:36:33,436][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028024] [Batch 00304/03080] [00:03:52/00:35:26, 0.766s/it]: train_loss_raw=1.1740, running_loss=1.1615, LR=0.000100
[2025-08-27 02:36:39,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028032] [Batch 00312/03080] [00:03:59/00:35:20, 0.766s/it]: train_loss_raw=1.1935, running_loss=1.1634, LR=0.000100
[2025-08-27 02:36:45,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028040] [Batch 00320/03080] [00:04:05/00:35:13, 0.766s/it]: train_loss_raw=1.2464, running_loss=1.1651, LR=0.000100
[2025-08-27 02:36:51,507][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028048] [Batch 00328/03080] [00:04:10/00:35:05, 0.765s/it]: train_loss_raw=1.2605, running_loss=1.1668, LR=0.000100
[2025-08-27 02:36:57,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028056] [Batch 00336/03080] [00:04:16/00:34:55, 0.764s/it]: train_loss_raw=1.2675, running_loss=1.1682, LR=0.000100
[2025-08-27 02:37:02,875][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028064] [Batch 00344/03080] [00:04:22/00:34:46, 0.763s/it]: train_loss_raw=1.1705, running_loss=1.1675, LR=0.000100
[2025-08-27 02:37:08,917][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028072] [Batch 00352/03080] [00:04:28/00:34:40, 0.763s/it]: train_loss_raw=1.1087, running_loss=1.1667, LR=0.000100
[2025-08-27 02:37:14,838][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028080] [Batch 00360/03080] [00:04:34/00:34:32, 0.762s/it]: train_loss_raw=1.1594, running_loss=1.1618, LR=0.000100
[2025-08-27 02:37:21,001][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028088] [Batch 00368/03080] [00:04:40/00:34:27, 0.762s/it]: train_loss_raw=1.3055, running_loss=1.1651, LR=0.000100
[2025-08-27 02:37:27,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028096] [Batch 00376/03080] [00:04:46/00:34:21, 0.762s/it]: train_loss_raw=1.1565, running_loss=1.1636, LR=0.000100
[2025-08-27 02:37:33,434][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028104] [Batch 00384/03080] [00:04:52/00:34:16, 0.763s/it]: train_loss_raw=1.1581, running_loss=1.1641, LR=0.000100
[2025-08-27 02:37:39,647][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028112] [Batch 00392/03080] [00:04:59/00:34:11, 0.763s/it]: train_loss_raw=1.1597, running_loss=1.1643, LR=0.000100
[2025-08-27 02:37:45,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028120] [Batch 00400/03080] [00:05:05/00:34:05, 0.763s/it]: train_loss_raw=1.1795, running_loss=1.1629, LR=0.000100
[2025-08-27 02:37:51,682][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028128] [Batch 00408/03080] [00:05:11/00:33:57, 0.763s/it]: train_loss_raw=1.2053, running_loss=1.1625, LR=0.000100
[2025-08-27 02:37:57,817][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028136] [Batch 00416/03080] [00:05:17/00:33:51, 0.763s/it]: train_loss_raw=1.2244, running_loss=1.1631, LR=0.000100
[2025-08-27 02:38:04,078][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028144] [Batch 00424/03080] [00:05:23/00:33:46, 0.763s/it]: train_loss_raw=1.1408, running_loss=1.1650, LR=0.000100
[2025-08-27 02:38:10,230][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028152] [Batch 00432/03080] [00:05:29/00:33:41, 0.763s/it]: train_loss_raw=1.1259, running_loss=1.1638, LR=0.000100
[2025-08-27 02:38:16,075][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028160] [Batch 00440/03080] [00:05:35/00:33:33, 0.763s/it]: train_loss_raw=1.2069, running_loss=1.1666, LR=0.000100
[2025-08-27 02:38:22,147][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028168] [Batch 00448/03080] [00:05:41/00:33:27, 0.763s/it]: train_loss_raw=1.2036, running_loss=1.1649, LR=0.000100
[2025-08-27 02:38:28,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028176] [Batch 00456/03080] [00:05:47/00:33:20, 0.762s/it]: train_loss_raw=1.1798, running_loss=1.1634, LR=0.000100
[2025-08-27 02:38:34,430][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028184] [Batch 00464/03080] [00:05:53/00:33:15, 0.763s/it]: train_loss_raw=1.0340, running_loss=1.1609, LR=0.000100
[2025-08-27 02:38:40,652][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028192] [Batch 00472/03080] [00:06:00/00:33:09, 0.763s/it]: train_loss_raw=1.1806, running_loss=1.1611, LR=0.000100
[2025-08-27 02:38:46,745][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028200] [Batch 00480/03080] [00:06:06/00:33:03, 0.763s/it]: train_loss_raw=1.1639, running_loss=1.1582, LR=0.000100
[2025-08-27 02:38:52,814][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028208] [Batch 00488/03080] [00:06:12/00:32:57, 0.763s/it]: train_loss_raw=1.1941, running_loss=1.1585, LR=0.000100
[2025-08-27 02:38:58,971][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028216] [Batch 00496/03080] [00:06:18/00:32:51, 0.763s/it]: train_loss_raw=1.2150, running_loss=1.1604, LR=0.000100
[2025-08-27 02:39:05,190][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028224] [Batch 00504/03080] [00:06:24/00:32:46, 0.763s/it]: train_loss_raw=1.1586, running_loss=1.1597, LR=0.000100
[2025-08-27 02:39:11,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028232] [Batch 00512/03080] [00:06:30/00:32:39, 0.763s/it]: train_loss_raw=1.2091, running_loss=1.1607, LR=0.000100
[2025-08-27 02:39:17,371][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028240] [Batch 00520/03080] [00:06:36/00:32:33, 0.763s/it]: train_loss_raw=1.2194, running_loss=1.1574, LR=0.000100
[2025-08-27 02:39:23,488][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028248] [Batch 00528/03080] [00:06:42/00:32:27, 0.763s/it]: train_loss_raw=1.1365, running_loss=1.1564, LR=0.000100
[2025-08-27 02:39:29,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028256] [Batch 00536/03080] [00:06:48/00:32:21, 0.763s/it]: train_loss_raw=1.0771, running_loss=1.1578, LR=0.000100
[2025-08-27 02:39:35,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028264] [Batch 00544/03080] [00:06:55/00:32:15, 0.763s/it]: train_loss_raw=1.0819, running_loss=1.1569, LR=0.000100
[2025-08-27 02:39:41,738][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028272] [Batch 00552/03080] [00:07:01/00:32:09, 0.763s/it]: train_loss_raw=1.1813, running_loss=1.1571, LR=0.000100
[2025-08-27 02:39:47,555][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028280] [Batch 00560/03080] [00:07:07/00:32:01, 0.763s/it]: train_loss_raw=1.0881, running_loss=1.1585, LR=0.000100
[2025-08-27 02:39:53,456][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028288] [Batch 00568/03080] [00:07:12/00:31:54, 0.762s/it]: train_loss_raw=1.1461, running_loss=1.1560, LR=0.000100
[2025-08-27 02:39:59,358][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028296] [Batch 00576/03080] [00:07:18/00:31:47, 0.762s/it]: train_loss_raw=1.2303, running_loss=1.1563, LR=0.000100
[2025-08-27 02:40:05,149][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028304] [Batch 00584/03080] [00:07:24/00:31:40, 0.761s/it]: train_loss_raw=1.1384, running_loss=1.1576, LR=0.000100
[2025-08-27 02:40:11,062][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028312] [Batch 00592/03080] [00:07:30/00:31:33, 0.761s/it]: train_loss_raw=1.1140, running_loss=1.1603, LR=0.000100
[2025-08-27 02:40:16,979][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028320] [Batch 00600/03080] [00:07:36/00:31:26, 0.761s/it]: train_loss_raw=1.1190, running_loss=1.1565, LR=0.000100
[2025-08-27 02:40:22,854][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028328] [Batch 00608/03080] [00:07:42/00:31:19, 0.760s/it]: train_loss_raw=1.1613, running_loss=1.1576, LR=0.000100
[2025-08-27 02:40:28,872][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028336] [Batch 00616/03080] [00:07:48/00:31:13, 0.760s/it]: train_loss_raw=1.1414, running_loss=1.1574, LR=0.000100
[2025-08-27 02:40:34,784][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028344] [Batch 00624/03080] [00:07:54/00:31:06, 0.760s/it]: train_loss_raw=1.2096, running_loss=1.1564, LR=0.000100
[2025-08-27 02:40:40,767][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028352] [Batch 00632/03080] [00:08:00/00:31:00, 0.760s/it]: train_loss_raw=1.1814, running_loss=1.1578, LR=0.000100
[2025-08-27 02:40:46,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028360] [Batch 00640/03080] [00:08:06/00:30:53, 0.760s/it]: train_loss_raw=1.1110, running_loss=1.1595, LR=0.000100
[2025-08-27 02:40:52,741][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028368] [Batch 00648/03080] [00:08:12/00:30:47, 0.760s/it]: train_loss_raw=1.0445, running_loss=1.1594, LR=0.000100
[2025-08-27 02:40:58,684][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028376] [Batch 00656/03080] [00:08:18/00:30:40, 0.759s/it]: train_loss_raw=1.1293, running_loss=1.1603, LR=0.000100
[2025-08-27 02:41:04,814][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028384] [Batch 00664/03080] [00:08:24/00:30:34, 0.759s/it]: train_loss_raw=1.1736, running_loss=1.1616, LR=0.000100
[2025-08-27 02:41:10,836][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028392] [Batch 00672/03080] [00:08:30/00:30:28, 0.759s/it]: train_loss_raw=1.0614, running_loss=1.1636, LR=0.000100
[2025-08-27 02:41:17,067][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028400] [Batch 00680/03080] [00:08:36/00:30:23, 0.760s/it]: train_loss_raw=1.0814, running_loss=1.1632, LR=0.000100
[2025-08-27 02:41:22,916][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028408] [Batch 00688/03080] [00:08:42/00:30:16, 0.759s/it]: train_loss_raw=1.1310, running_loss=1.1609, LR=0.000100
[2025-08-27 02:41:28,680][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028416] [Batch 00696/03080] [00:08:48/00:30:09, 0.759s/it]: train_loss_raw=1.0833, running_loss=1.1616, LR=0.000100
[2025-08-27 02:41:34,631][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028424] [Batch 00704/03080] [00:08:54/00:30:02, 0.759s/it]: train_loss_raw=1.1215, running_loss=1.1582, LR=0.000100
[2025-08-27 02:41:40,646][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028432] [Batch 00712/03080] [00:09:00/00:29:56, 0.759s/it]: train_loss_raw=1.1970, running_loss=1.1594, LR=0.000100
[2025-08-27 02:41:46,891][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028440] [Batch 00720/03080] [00:09:06/00:29:50, 0.759s/it]: train_loss_raw=1.0518, running_loss=1.1593, LR=0.000100
[2025-08-27 02:41:52,898][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028448] [Batch 00728/03080] [00:09:12/00:29:44, 0.759s/it]: train_loss_raw=1.2163, running_loss=1.1591, LR=0.000100
[2025-08-27 02:41:58,724][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028456] [Batch 00736/03080] [00:09:18/00:29:37, 0.758s/it]: train_loss_raw=1.0735, running_loss=1.1578, LR=0.000100
[2025-08-27 02:42:04,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028464] [Batch 00744/03080] [00:09:24/00:29:31, 0.758s/it]: train_loss_raw=1.1490, running_loss=1.1546, LR=0.000100
[2025-08-27 02:42:10,818][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028472] [Batch 00752/03080] [00:09:30/00:29:25, 0.758s/it]: train_loss_raw=1.2379, running_loss=1.1565, LR=0.000100
[2025-08-27 02:42:16,671][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028480] [Batch 00760/03080] [00:09:36/00:29:18, 0.758s/it]: train_loss_raw=1.2313, running_loss=1.1564, LR=0.000100
[2025-08-27 02:42:22,385][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028488] [Batch 00768/03080] [00:09:41/00:29:11, 0.758s/it]: train_loss_raw=1.2082, running_loss=1.1592, LR=0.000100
[2025-08-27 02:42:28,129][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028496] [Batch 00776/03080] [00:09:47/00:29:04, 0.757s/it]: train_loss_raw=1.1696, running_loss=1.1590, LR=0.000100
[2025-08-27 02:42:34,167][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028504] [Batch 00784/03080] [00:09:53/00:28:58, 0.757s/it]: train_loss_raw=1.1811, running_loss=1.1603, LR=0.000100
[2025-08-27 02:42:40,099][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028512] [Batch 00792/03080] [00:09:59/00:28:52, 0.757s/it]: train_loss_raw=1.1287, running_loss=1.1585, LR=0.000100
[2025-08-27 02:42:46,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028520] [Batch 00800/03080] [00:10:05/00:28:45, 0.757s/it]: train_loss_raw=1.1771, running_loss=1.1597, LR=0.000100
[2025-08-27 02:42:51,916][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028528] [Batch 00808/03080] [00:10:11/00:28:39, 0.757s/it]: train_loss_raw=1.1238, running_loss=1.1568, LR=0.000100
[2025-08-27 02:42:58,125][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028536] [Batch 00816/03080] [00:10:17/00:28:33, 0.757s/it]: train_loss_raw=1.2305, running_loss=1.1581, LR=0.000100
[2025-08-27 02:43:04,190][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028544] [Batch 00824/03080] [00:10:23/00:28:27, 0.757s/it]: train_loss_raw=1.1557, running_loss=1.1574, LR=0.000100
[2025-08-27 02:43:10,147][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028552] [Batch 00832/03080] [00:10:29/00:28:21, 0.757s/it]: train_loss_raw=1.1848, running_loss=1.1566, LR=0.000100
[2025-08-27 02:43:15,913][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028560] [Batch 00840/03080] [00:10:35/00:28:14, 0.756s/it]: train_loss_raw=1.0934, running_loss=1.1541, LR=0.000100
[2025-08-27 02:43:21,863][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028568] [Batch 00848/03080] [00:10:41/00:28:08, 0.756s/it]: train_loss_raw=1.0921, running_loss=1.1531, LR=0.000100
[2025-08-27 02:43:27,707][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028576] [Batch 00856/03080] [00:10:47/00:28:01, 0.756s/it]: train_loss_raw=1.1720, running_loss=1.1551, LR=0.000100
[2025-08-27 02:43:33,626][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028584] [Batch 00864/03080] [00:10:53/00:27:55, 0.756s/it]: train_loss_raw=1.2361, running_loss=1.1567, LR=0.000100
[2025-08-27 02:43:39,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028592] [Batch 00872/03080] [00:10:58/00:27:48, 0.756s/it]: train_loss_raw=1.1426, running_loss=1.1566, LR=0.000100
[2025-08-27 02:43:45,381][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028600] [Batch 00880/03080] [00:11:04/00:27:42, 0.756s/it]: train_loss_raw=1.1837, running_loss=1.1548, LR=0.000100
[2025-08-27 02:43:51,429][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028608] [Batch 00888/03080] [00:11:10/00:27:36, 0.756s/it]: train_loss_raw=1.2652, running_loss=1.1554, LR=0.000100
[2025-08-27 02:43:57,432][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028616] [Batch 00896/03080] [00:11:16/00:27:29, 0.755s/it]: train_loss_raw=1.2785, running_loss=1.1569, LR=0.000100
[2025-08-27 02:44:03,270][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028624] [Batch 00904/03080] [00:11:22/00:27:23, 0.755s/it]: train_loss_raw=1.0621, running_loss=1.1584, LR=0.000100
[2025-08-27 02:44:09,100][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028632] [Batch 00912/03080] [00:11:28/00:27:16, 0.755s/it]: train_loss_raw=1.0704, running_loss=1.1557, LR=0.000100
[2025-08-27 02:44:15,000][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028640] [Batch 00920/03080] [00:11:34/00:27:10, 0.755s/it]: train_loss_raw=1.1800, running_loss=1.1589, LR=0.000100
[2025-08-27 02:44:20,740][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028648] [Batch 00928/03080] [00:11:40/00:27:03, 0.755s/it]: train_loss_raw=1.1707, running_loss=1.1590, LR=0.000100
[2025-08-27 02:44:26,520][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028656] [Batch 00936/03080] [00:11:46/00:26:57, 0.754s/it]: train_loss_raw=1.1475, running_loss=1.1613, LR=0.000100
[2025-08-27 02:44:32,372][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028664] [Batch 00944/03080] [00:11:51/00:26:50, 0.754s/it]: train_loss_raw=1.2060, running_loss=1.1614, LR=0.000100
[2025-08-27 02:44:38,319][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028672] [Batch 00952/03080] [00:11:57/00:26:44, 0.754s/it]: train_loss_raw=1.2299, running_loss=1.1612, LR=0.000100
[2025-08-27 02:44:44,293][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028680] [Batch 00960/03080] [00:12:03/00:26:38, 0.754s/it]: train_loss_raw=1.0698, running_loss=1.1610, LR=0.000100
[2025-08-27 02:44:50,164][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028688] [Batch 00968/03080] [00:12:09/00:26:31, 0.754s/it]: train_loss_raw=1.1349, running_loss=1.1568, LR=0.000100
[2025-08-27 02:44:56,068][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028696] [Batch 00976/03080] [00:12:15/00:26:25, 0.754s/it]: train_loss_raw=1.1470, running_loss=1.1546, LR=0.000100
[2025-08-27 02:45:01,896][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028704] [Batch 00984/03080] [00:12:21/00:26:19, 0.753s/it]: train_loss_raw=1.1231, running_loss=1.1532, LR=0.000100
[2025-08-27 02:45:07,848][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028712] [Batch 00992/03080] [00:12:27/00:26:13, 0.753s/it]: train_loss_raw=1.1585, running_loss=1.1506, LR=0.000100
[2025-08-27 02:45:13,762][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028720] [Batch 01000/03080] [00:12:33/00:26:06, 0.753s/it]: train_loss_raw=1.0749, running_loss=1.1486, LR=0.000100
[2025-08-27 02:45:19,617][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028728] [Batch 01008/03080] [00:12:39/00:26:00, 0.753s/it]: train_loss_raw=1.1168, running_loss=1.1482, LR=0.000100
[2025-08-27 02:45:25,585][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028736] [Batch 01016/03080] [00:12:45/00:25:54, 0.753s/it]: train_loss_raw=1.0471, running_loss=1.1467, LR=0.000100
[2025-08-27 02:45:31,481][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028744] [Batch 01024/03080] [00:12:50/00:25:47, 0.753s/it]: train_loss_raw=1.2136, running_loss=1.1470, LR=0.000100
[2025-08-27 02:45:37,372][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028752] [Batch 01032/03080] [00:12:56/00:25:41, 0.753s/it]: train_loss_raw=1.1188, running_loss=1.1490, LR=0.000100
[2025-08-27 02:45:43,271][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028760] [Batch 01040/03080] [00:13:02/00:25:35, 0.753s/it]: train_loss_raw=1.0527, running_loss=1.1461, LR=0.000100
[2025-08-27 02:45:49,186][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028768] [Batch 01048/03080] [00:13:08/00:25:29, 0.753s/it]: train_loss_raw=1.2499, running_loss=1.1483, LR=0.000100
[2025-08-27 02:45:55,066][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028776] [Batch 01056/03080] [00:13:14/00:25:22, 0.752s/it]: train_loss_raw=1.1453, running_loss=1.1486, LR=0.000100
[2025-08-27 02:46:00,836][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028784] [Batch 01064/03080] [00:13:20/00:25:16, 0.752s/it]: train_loss_raw=1.0812, running_loss=1.1467, LR=0.000100
[2025-08-27 02:46:06,744][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028792] [Batch 01072/03080] [00:13:26/00:25:10, 0.752s/it]: train_loss_raw=1.0695, running_loss=1.1440, LR=0.000100
[2025-08-27 02:46:12,588][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028800] [Batch 01080/03080] [00:13:32/00:25:03, 0.752s/it]: train_loss_raw=1.2412, running_loss=1.1424, LR=0.000100
[2025-08-27 02:46:18,566][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028808] [Batch 01088/03080] [00:13:38/00:24:57, 0.752s/it]: train_loss_raw=1.1565, running_loss=1.1443, LR=0.000100
[2025-08-27 02:46:24,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028816] [Batch 01096/03080] [00:13:43/00:24:51, 0.752s/it]: train_loss_raw=1.1361, running_loss=1.1459, LR=0.000100
[2025-08-27 02:46:30,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028824] [Batch 01104/03080] [00:13:49/00:24:45, 0.752s/it]: train_loss_raw=1.2973, running_loss=1.1461, LR=0.000100
[2025-08-27 02:46:36,098][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028832] [Batch 01112/03080] [00:13:55/00:24:38, 0.751s/it]: train_loss_raw=1.1047, running_loss=1.1455, LR=0.000100
[2025-08-27 02:46:42,005][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028840] [Batch 01120/03080] [00:14:01/00:24:32, 0.751s/it]: train_loss_raw=1.1080, running_loss=1.1482, LR=0.000100
[2025-08-27 02:46:47,734][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028848] [Batch 01128/03080] [00:14:07/00:24:26, 0.751s/it]: train_loss_raw=1.0882, running_loss=1.1466, LR=0.000100
[2025-08-27 02:46:53,608][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028856] [Batch 01136/03080] [00:14:13/00:24:19, 0.751s/it]: train_loss_raw=1.0895, running_loss=1.1496, LR=0.000100
[2025-08-27 02:46:59,286][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028864] [Batch 01144/03080] [00:14:18/00:24:13, 0.751s/it]: train_loss_raw=1.2083, running_loss=1.1495, LR=0.000100
[2025-08-27 02:47:05,376][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028872] [Batch 01152/03080] [00:14:24/00:24:07, 0.751s/it]: train_loss_raw=1.2029, running_loss=1.1494, LR=0.000100
[2025-08-27 02:47:11,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028880] [Batch 01160/03080] [00:14:30/00:24:01, 0.751s/it]: train_loss_raw=1.1787, running_loss=1.1476, LR=0.000100
[2025-08-27 02:47:17,306][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028888] [Batch 01168/03080] [00:14:36/00:23:55, 0.751s/it]: train_loss_raw=1.1615, running_loss=1.1502, LR=0.000100
[2025-08-27 02:47:23,231][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028896] [Batch 01176/03080] [00:14:42/00:23:49, 0.751s/it]: train_loss_raw=1.1660, running_loss=1.1493, LR=0.000100
[2025-08-27 02:47:29,108][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028904] [Batch 01184/03080] [00:14:48/00:23:42, 0.751s/it]: train_loss_raw=1.1870, running_loss=1.1477, LR=0.000100
[2025-08-27 02:47:35,217][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028912] [Batch 01192/03080] [00:14:54/00:23:37, 0.751s/it]: train_loss_raw=1.1139, running_loss=1.1490, LR=0.000100
[2025-08-27 02:47:41,303][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028920] [Batch 01200/03080] [00:15:00/00:23:31, 0.751s/it]: train_loss_raw=1.1969, running_loss=1.1504, LR=0.000100
[2025-08-27 02:47:47,354][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028928] [Batch 01208/03080] [00:15:06/00:23:25, 0.751s/it]: train_loss_raw=1.1531, running_loss=1.1537, LR=0.000100
[2025-08-27 02:47:53,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028936] [Batch 01216/03080] [00:15:12/00:23:19, 0.751s/it]: train_loss_raw=1.1816, running_loss=1.1547, LR=0.000100
[2025-08-27 02:47:59,387][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028944] [Batch 01224/03080] [00:15:18/00:23:13, 0.751s/it]: train_loss_raw=1.1788, running_loss=1.1560, LR=0.000100
[2025-08-27 02:48:05,376][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028952] [Batch 01232/03080] [00:15:24/00:23:07, 0.751s/it]: train_loss_raw=1.1857, running_loss=1.1536, LR=0.000100
[2025-08-27 02:48:11,232][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028960] [Batch 01240/03080] [00:15:30/00:23:01, 0.751s/it]: train_loss_raw=1.2576, running_loss=1.1537, LR=0.000100
[2025-08-27 02:48:17,204][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028968] [Batch 01248/03080] [00:15:36/00:22:55, 0.751s/it]: train_loss_raw=1.1053, running_loss=1.1533, LR=0.000100
[2025-08-27 02:48:23,169][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028976] [Batch 01256/03080] [00:15:42/00:22:48, 0.751s/it]: train_loss_raw=1.2072, running_loss=1.1529, LR=0.000100
[2025-08-27 02:48:29,178][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028984] [Batch 01264/03080] [00:15:48/00:22:42, 0.751s/it]: train_loss_raw=1.1600, running_loss=1.1528, LR=0.000100
[2025-08-27 02:48:35,296][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028992] [Batch 01272/03080] [00:15:54/00:22:37, 0.751s/it]: train_loss_raw=1.1219, running_loss=1.1531, LR=0.000100
[2025-08-27 02:48:41,357][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029000] [Batch 01280/03080] [00:16:00/00:22:31, 0.751s/it]: train_loss_raw=1.1113, running_loss=1.1512, LR=0.000100
[2025-08-27 02:48:47,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029008] [Batch 01288/03080] [00:16:06/00:22:25, 0.751s/it]: train_loss_raw=1.1799, running_loss=1.1516, LR=0.000100
[2025-08-27 02:48:53,196][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029016] [Batch 01296/03080] [00:16:12/00:22:18, 0.751s/it]: train_loss_raw=1.1508, running_loss=1.1533, LR=0.000100
[2025-08-27 02:48:59,107][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029024] [Batch 01304/03080] [00:16:18/00:22:12, 0.750s/it]: train_loss_raw=1.1563, running_loss=1.1573, LR=0.000100
[2025-08-27 02:49:05,115][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029032] [Batch 01312/03080] [00:16:24/00:22:06, 0.750s/it]: train_loss_raw=1.2232, running_loss=1.1575, LR=0.000100
[2025-08-27 02:49:11,228][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029040] [Batch 01320/03080] [00:16:30/00:22:00, 0.751s/it]: train_loss_raw=1.1983, running_loss=1.1576, LR=0.000100
[2025-08-27 02:49:17,112][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029048] [Batch 01328/03080] [00:16:36/00:21:54, 0.750s/it]: train_loss_raw=1.1071, running_loss=1.1556, LR=0.000100
[2025-08-27 02:49:23,249][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029056] [Batch 01336/03080] [00:16:42/00:21:48, 0.751s/it]: train_loss_raw=1.0574, running_loss=1.1531, LR=0.000100
[2025-08-27 02:49:29,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029064] [Batch 01344/03080] [00:16:48/00:21:43, 0.751s/it]: train_loss_raw=1.0066, running_loss=1.1514, LR=0.000100
[2025-08-27 02:49:35,342][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029072] [Batch 01352/03080] [00:16:54/00:21:37, 0.751s/it]: train_loss_raw=1.1759, running_loss=1.1522, LR=0.000100
[2025-08-27 02:49:41,154][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029080] [Batch 01360/03080] [00:17:00/00:21:30, 0.750s/it]: train_loss_raw=1.1358, running_loss=1.1524, LR=0.000100
[2025-08-27 02:49:46,909][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029088] [Batch 01368/03080] [00:17:06/00:21:24, 0.750s/it]: train_loss_raw=1.0944, running_loss=1.1519, LR=0.000100
[2025-08-27 02:49:52,677][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029096] [Batch 01376/03080] [00:17:12/00:21:18, 0.750s/it]: train_loss_raw=1.0654, running_loss=1.1512, LR=0.000100
[2025-08-27 02:49:58,521][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029104] [Batch 01384/03080] [00:17:18/00:21:12, 0.750s/it]: train_loss_raw=1.1448, running_loss=1.1496, LR=0.000100
[2025-08-27 02:50:04,555][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029112] [Batch 01392/03080] [00:17:24/00:21:06, 0.750s/it]: train_loss_raw=1.1315, running_loss=1.1457, LR=0.000100
[2025-08-27 02:50:10,527][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029120] [Batch 01400/03080] [00:17:30/00:21:00, 0.750s/it]: train_loss_raw=1.0786, running_loss=1.1462, LR=0.000100
[2025-08-27 02:50:16,332][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029128] [Batch 01408/03080] [00:17:35/00:20:53, 0.750s/it]: train_loss_raw=1.1635, running_loss=1.1446, LR=0.000100
[2025-08-27 02:50:22,444][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029136] [Batch 01416/03080] [00:17:41/00:20:47, 0.750s/it]: train_loss_raw=1.1678, running_loss=1.1454, LR=0.000100
[2025-08-27 02:50:28,370][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029144] [Batch 01424/03080] [00:17:47/00:20:41, 0.750s/it]: train_loss_raw=1.2110, running_loss=1.1466, LR=0.000100
[2025-08-27 02:50:34,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029152] [Batch 01432/03080] [00:17:53/00:20:35, 0.750s/it]: train_loss_raw=1.1736, running_loss=1.1429, LR=0.000100
[2025-08-27 02:50:40,213][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029160] [Batch 01440/03080] [00:17:59/00:20:29, 0.750s/it]: train_loss_raw=1.0997, running_loss=1.1436, LR=0.000100
[2025-08-27 02:50:46,164][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029168] [Batch 01448/03080] [00:18:05/00:20:23, 0.750s/it]: train_loss_raw=1.2008, running_loss=1.1423, LR=0.000100
[2025-08-27 02:50:52,178][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029176] [Batch 01456/03080] [00:18:11/00:20:17, 0.750s/it]: train_loss_raw=1.1233, running_loss=1.1418, LR=0.000100
[2025-08-27 02:50:58,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029184] [Batch 01464/03080] [00:18:17/00:20:11, 0.750s/it]: train_loss_raw=1.0939, running_loss=1.1432, LR=0.000100
[2025-08-27 02:51:04,072][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029192] [Batch 01472/03080] [00:18:23/00:20:05, 0.750s/it]: train_loss_raw=1.0890, running_loss=1.1410, LR=0.000100
[2025-08-27 02:51:10,055][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029200] [Batch 01480/03080] [00:18:29/00:19:59, 0.750s/it]: train_loss_raw=1.0982, running_loss=1.1410, LR=0.000100
[2025-08-27 02:51:15,977][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029208] [Batch 01488/03080] [00:18:35/00:19:53, 0.750s/it]: train_loss_raw=1.1144, running_loss=1.1408, LR=0.000100
[2025-08-27 02:51:22,039][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029216] [Batch 01496/03080] [00:18:41/00:19:47, 0.750s/it]: train_loss_raw=1.1686, running_loss=1.1375, LR=0.000100
[2025-08-27 02:51:28,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029224] [Batch 01504/03080] [00:18:47/00:19:41, 0.750s/it]: train_loss_raw=1.2401, running_loss=1.1399, LR=0.000100
[2025-08-27 02:51:33,951][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029232] [Batch 01512/03080] [00:18:53/00:19:35, 0.750s/it]: train_loss_raw=1.1829, running_loss=1.1425, LR=0.000100
[2025-08-27 02:51:39,888][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029240] [Batch 01520/03080] [00:18:59/00:19:29, 0.750s/it]: train_loss_raw=1.1173, running_loss=1.1399, LR=0.000100
[2025-08-27 02:51:45,811][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029248] [Batch 01528/03080] [00:19:05/00:19:23, 0.750s/it]: train_loss_raw=1.1131, running_loss=1.1392, LR=0.000100
[2025-08-27 02:51:51,794][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029256] [Batch 01536/03080] [00:19:11/00:19:17, 0.750s/it]: train_loss_raw=1.1790, running_loss=1.1365, LR=0.000100
[2025-08-27 02:51:57,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029264] [Batch 01544/03080] [00:19:17/00:19:11, 0.750s/it]: train_loss_raw=1.1489, running_loss=1.1358, LR=0.000100
[2025-08-27 02:52:03,638][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029272] [Batch 01552/03080] [00:19:23/00:19:05, 0.749s/it]: train_loss_raw=1.1591, running_loss=1.1333, LR=0.000100
[2025-08-27 02:52:09,410][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029280] [Batch 01560/03080] [00:19:28/00:18:58, 0.749s/it]: train_loss_raw=1.1936, running_loss=1.1343, LR=0.000100
[2025-08-27 02:52:15,519][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029288] [Batch 01568/03080] [00:19:35/00:18:53, 0.749s/it]: train_loss_raw=1.1764, running_loss=1.1347, LR=0.000100
[2025-08-27 02:52:21,490][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029296] [Batch 01576/03080] [00:19:40/00:18:47, 0.749s/it]: train_loss_raw=1.1746, running_loss=1.1352, LR=0.000100
[2025-08-27 02:52:27,396][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029304] [Batch 01584/03080] [00:19:46/00:18:40, 0.749s/it]: train_loss_raw=1.1863, running_loss=1.1337, LR=0.000100
[2025-08-27 02:52:33,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029312] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=1.0512, running_loss=1.1338, LR=0.000100
[2025-08-27 02:52:39,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029320] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=1.0529, running_loss=1.1357, LR=0.000100
[2025-08-27 02:52:45,214][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029328] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=1.1063, running_loss=1.1344, LR=0.000100
[2025-08-27 02:52:51,201][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029336] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=1.1487, running_loss=1.1349, LR=0.000100
[2025-08-27 02:52:57,161][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029344] [Batch 01624/03080] [00:20:16/00:18:10, 0.749s/it]: train_loss_raw=1.0779, running_loss=1.1336, LR=0.000100
[2025-08-27 02:53:03,090][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029352] [Batch 01632/03080] [00:20:22/00:18:04, 0.749s/it]: train_loss_raw=1.1569, running_loss=1.1354, LR=0.000100
[2025-08-27 02:53:08,959][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029360] [Batch 01640/03080] [00:20:28/00:17:58, 0.749s/it]: train_loss_raw=1.1234, running_loss=1.1362, LR=0.000100
[2025-08-27 02:53:15,014][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029368] [Batch 01648/03080] [00:20:34/00:17:52, 0.749s/it]: train_loss_raw=1.1732, running_loss=1.1356, LR=0.000100
[2025-08-27 02:53:21,047][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029376] [Batch 01656/03080] [00:20:40/00:17:46, 0.749s/it]: train_loss_raw=1.0761, running_loss=1.1357, LR=0.000100
[2025-08-27 02:53:27,047][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029384] [Batch 01664/03080] [00:20:46/00:17:40, 0.749s/it]: train_loss_raw=1.1317, running_loss=1.1347, LR=0.000100
[2025-08-27 02:53:33,079][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029392] [Batch 01672/03080] [00:20:52/00:17:34, 0.749s/it]: train_loss_raw=1.0371, running_loss=1.1334, LR=0.000100
[2025-08-27 02:53:38,912][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029400] [Batch 01680/03080] [00:20:58/00:17:28, 0.749s/it]: train_loss_raw=1.1448, running_loss=1.1323, LR=0.000100
[2025-08-27 02:53:44,901][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029408] [Batch 01688/03080] [00:21:04/00:17:22, 0.749s/it]: train_loss_raw=1.2705, running_loss=1.1319, LR=0.000100
[2025-08-27 02:53:51,148][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029416] [Batch 01696/03080] [00:21:10/00:17:16, 0.749s/it]: train_loss_raw=1.0694, running_loss=1.1329, LR=0.000100
[2025-08-27 02:53:56,886][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029424] [Batch 01704/03080] [00:21:16/00:17:10, 0.749s/it]: train_loss_raw=1.1594, running_loss=1.1344, LR=0.000100
[2025-08-27 02:54:02,856][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029432] [Batch 01712/03080] [00:21:22/00:17:04, 0.749s/it]: train_loss_raw=1.1390, running_loss=1.1349, LR=0.000100
[2025-08-27 02:54:08,931][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029440] [Batch 01720/03080] [00:21:28/00:16:58, 0.749s/it]: train_loss_raw=1.2412, running_loss=1.1339, LR=0.000100
[2025-08-27 02:54:14,986][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029448] [Batch 01728/03080] [00:21:34/00:16:52, 0.749s/it]: train_loss_raw=1.1845, running_loss=1.1350, LR=0.000100
[2025-08-27 02:54:21,022][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029456] [Batch 01736/03080] [00:21:40/00:16:46, 0.749s/it]: train_loss_raw=1.1449, running_loss=1.1351, LR=0.000100
[2025-08-27 02:54:27,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029464] [Batch 01744/03080] [00:21:46/00:16:40, 0.749s/it]: train_loss_raw=1.1656, running_loss=1.1350, LR=0.000100
[2025-08-27 02:54:33,200][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029472] [Batch 01752/03080] [00:21:52/00:16:35, 0.749s/it]: train_loss_raw=1.1916, running_loss=1.1375, LR=0.000100
[2025-08-27 02:54:39,150][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029480] [Batch 01760/03080] [00:21:58/00:16:28, 0.749s/it]: train_loss_raw=1.0994, running_loss=1.1365, LR=0.000100
[2025-08-27 02:54:45,027][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029488] [Batch 01768/03080] [00:22:04/00:16:22, 0.749s/it]: train_loss_raw=1.1100, running_loss=1.1365, LR=0.000100
[2025-08-27 02:54:50,873][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029496] [Batch 01776/03080] [00:22:10/00:16:16, 0.749s/it]: train_loss_raw=1.1074, running_loss=1.1375, LR=0.000100
[2025-08-27 02:54:56,729][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029504] [Batch 01784/03080] [00:22:16/00:16:10, 0.749s/it]: train_loss_raw=1.1499, running_loss=1.1401, LR=0.000100
[2025-08-27 02:55:02,632][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029512] [Batch 01792/03080] [00:22:22/00:16:04, 0.749s/it]: train_loss_raw=1.1934, running_loss=1.1399, LR=0.000100
[2025-08-27 02:55:08,446][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029520] [Batch 01800/03080] [00:22:27/00:15:58, 0.749s/it]: train_loss_raw=1.0513, running_loss=1.1373, LR=0.000100
[2025-08-27 02:55:14,690][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029528] [Batch 01808/03080] [00:22:34/00:15:52, 0.749s/it]: train_loss_raw=1.1761, running_loss=1.1362, LR=0.000100
[2025-08-27 02:55:20,659][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029536] [Batch 01816/03080] [00:22:40/00:15:46, 0.749s/it]: train_loss_raw=1.1036, running_loss=1.1370, LR=0.000100
[2025-08-27 02:55:26,507][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029544] [Batch 01824/03080] [00:22:45/00:15:40, 0.749s/it]: train_loss_raw=1.1269, running_loss=1.1364, LR=0.000100
[2025-08-27 02:55:32,336][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029552] [Batch 01832/03080] [00:22:51/00:15:34, 0.749s/it]: train_loss_raw=1.1659, running_loss=1.1399, LR=0.000100
[2025-08-27 02:55:38,254][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029560] [Batch 01840/03080] [00:22:57/00:15:28, 0.749s/it]: train_loss_raw=1.1964, running_loss=1.1426, LR=0.000100
[2025-08-27 02:55:44,186][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029568] [Batch 01848/03080] [00:23:03/00:15:22, 0.749s/it]: train_loss_raw=1.1836, running_loss=1.1438, LR=0.000100
[2025-08-27 02:55:50,135][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029576] [Batch 01856/03080] [00:23:09/00:15:16, 0.749s/it]: train_loss_raw=1.2115, running_loss=1.1452, LR=0.000100
[2025-08-27 02:55:55,997][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029584] [Batch 01864/03080] [00:23:15/00:15:10, 0.749s/it]: train_loss_raw=1.1337, running_loss=1.1458, LR=0.000100
[2025-08-27 02:56:01,867][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029592] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=1.1443, running_loss=1.1464, LR=0.000100
[2025-08-27 02:56:07,769][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029600] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=1.1596, running_loss=1.1451, LR=0.000100
[2025-08-27 02:56:13,664][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029608] [Batch 01888/03080] [00:23:33/00:14:52, 0.748s/it]: train_loss_raw=1.1129, running_loss=1.1451, LR=0.000100
[2025-08-27 02:56:19,613][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029616] [Batch 01896/03080] [00:23:39/00:14:46, 0.748s/it]: train_loss_raw=1.0508, running_loss=1.1440, LR=0.000100
[2025-08-27 02:56:25,534][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029624] [Batch 01904/03080] [00:23:45/00:14:40, 0.748s/it]: train_loss_raw=1.1525, running_loss=1.1458, LR=0.000100
[2025-08-27 02:56:31,563][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029632] [Batch 01912/03080] [00:23:51/00:14:34, 0.748s/it]: train_loss_raw=1.1080, running_loss=1.1462, LR=0.000100
[2025-08-27 02:56:37,467][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029640] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=1.1906, running_loss=1.1481, LR=0.000100
[2025-08-27 02:56:43,394][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029648] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=1.2345, running_loss=1.1480, LR=0.000100
[2025-08-27 02:56:49,389][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029656] [Batch 01936/03080] [00:24:08/00:14:16, 0.748s/it]: train_loss_raw=1.0553, running_loss=1.1493, LR=0.000100
[2025-08-27 02:56:55,386][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029664] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=1.1826, running_loss=1.1497, LR=0.000100
[2025-08-27 02:57:01,113][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029672] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=1.2054, running_loss=1.1484, LR=0.000100
[2025-08-27 02:57:07,188][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029680] [Batch 01960/03080] [00:24:26/00:13:58, 0.748s/it]: train_loss_raw=1.1246, running_loss=1.1485, LR=0.000100
[2025-08-27 02:57:13,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029688] [Batch 01968/03080] [00:24:32/00:13:52, 0.748s/it]: train_loss_raw=1.0882, running_loss=1.1435, LR=0.000100
[2025-08-27 02:57:19,326][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029696] [Batch 01976/03080] [00:24:38/00:13:46, 0.748s/it]: train_loss_raw=1.1490, running_loss=1.1456, LR=0.000100
[2025-08-27 02:57:25,401][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029704] [Batch 01984/03080] [00:24:44/00:13:40, 0.748s/it]: train_loss_raw=1.0989, running_loss=1.1418, LR=0.000100
[2025-08-27 02:57:31,300][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029712] [Batch 01992/03080] [00:24:50/00:13:34, 0.748s/it]: train_loss_raw=1.1612, running_loss=1.1406, LR=0.000100
[2025-08-27 02:57:37,304][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029720] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=1.0959, running_loss=1.1396, LR=0.000100
[2025-08-27 02:57:43,426][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029728] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=1.1113, running_loss=1.1372, LR=0.000100
[2025-08-27 02:57:49,308][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029736] [Batch 02016/03080] [00:25:08/00:13:16, 0.748s/it]: train_loss_raw=1.1286, running_loss=1.1348, LR=0.000100
[2025-08-27 02:57:55,202][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029744] [Batch 02024/03080] [00:25:14/00:13:10, 0.748s/it]: train_loss_raw=1.1174, running_loss=1.1331, LR=0.000100
[2025-08-27 02:58:01,104][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029752] [Batch 02032/03080] [00:25:20/00:13:04, 0.748s/it]: train_loss_raw=1.1759, running_loss=1.1334, LR=0.000100
[2025-08-27 02:58:07,035][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029760] [Batch 02040/03080] [00:25:26/00:12:58, 0.748s/it]: train_loss_raw=1.1931, running_loss=1.1332, LR=0.000100
[2025-08-27 02:58:12,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029768] [Batch 02048/03080] [00:25:32/00:12:52, 0.748s/it]: train_loss_raw=1.1511, running_loss=1.1352, LR=0.000100
[2025-08-27 02:58:18,728][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029776] [Batch 02056/03080] [00:25:38/00:12:46, 0.748s/it]: train_loss_raw=1.2160, running_loss=1.1320, LR=0.000100
[2025-08-27 02:58:24,665][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029784] [Batch 02064/03080] [00:25:44/00:12:40, 0.748s/it]: train_loss_raw=1.1244, running_loss=1.1349, LR=0.000100
[2025-08-27 02:58:30,708][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029792] [Batch 02072/03080] [00:25:50/00:12:34, 0.748s/it]: train_loss_raw=1.0620, running_loss=1.1345, LR=0.000100
[2025-08-27 02:58:36,639][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029800] [Batch 02080/03080] [00:25:56/00:12:28, 0.748s/it]: train_loss_raw=1.1192, running_loss=1.1361, LR=0.000100
[2025-08-27 02:58:42,635][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029808] [Batch 02088/03080] [00:26:02/00:12:22, 0.748s/it]: train_loss_raw=1.1629, running_loss=1.1379, LR=0.000100
[2025-08-27 02:58:48,491][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029816] [Batch 02096/03080] [00:26:07/00:12:16, 0.748s/it]: train_loss_raw=1.2010, running_loss=1.1391, LR=0.000100
[2025-08-27 02:58:54,582][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029824] [Batch 02104/03080] [00:26:14/00:12:10, 0.748s/it]: train_loss_raw=1.2228, running_loss=1.1370, LR=0.000100
[2025-08-27 02:59:00,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029832] [Batch 02112/03080] [00:26:20/00:12:04, 0.748s/it]: train_loss_raw=1.1304, running_loss=1.1371, LR=0.000100
[2025-08-27 02:59:06,663][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029840] [Batch 02120/03080] [00:26:26/00:11:58, 0.748s/it]: train_loss_raw=1.1275, running_loss=1.1388, LR=0.000100
[2025-08-27 02:59:12,581][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029848] [Batch 02128/03080] [00:26:32/00:11:52, 0.748s/it]: train_loss_raw=1.0179, running_loss=1.1371, LR=0.000100
[2025-08-27 02:59:18,508][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029856] [Batch 02136/03080] [00:26:37/00:11:46, 0.748s/it]: train_loss_raw=1.1259, running_loss=1.1384, LR=0.000100
[2025-08-27 02:59:24,526][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029864] [Batch 02144/03080] [00:26:44/00:11:40, 0.748s/it]: train_loss_raw=1.1536, running_loss=1.1376, LR=0.000100
[2025-08-27 02:59:30,283][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029872] [Batch 02152/03080] [00:26:49/00:11:34, 0.748s/it]: train_loss_raw=1.1097, running_loss=1.1357, LR=0.000100
[2025-08-27 02:59:36,292][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029880] [Batch 02160/03080] [00:26:55/00:11:28, 0.748s/it]: train_loss_raw=1.1617, running_loss=1.1355, LR=0.000100
[2025-08-27 02:59:42,156][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029888] [Batch 02168/03080] [00:27:01/00:11:22, 0.748s/it]: train_loss_raw=1.1237, running_loss=1.1334, LR=0.000100
[2025-08-27 02:59:48,049][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029896] [Batch 02176/03080] [00:27:07/00:11:16, 0.748s/it]: train_loss_raw=1.1550, running_loss=1.1322, LR=0.000100
[2025-08-27 02:59:53,980][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029904] [Batch 02184/03080] [00:27:13/00:11:10, 0.748s/it]: train_loss_raw=1.2508, running_loss=1.1351, LR=0.000100
[2025-08-27 02:59:59,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029912] [Batch 02192/03080] [00:27:19/00:11:04, 0.748s/it]: train_loss_raw=1.0945, running_loss=1.1318, LR=0.000100
[2025-08-27 03:00:05,822][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029920] [Batch 02200/03080] [00:27:25/00:10:58, 0.748s/it]: train_loss_raw=1.0688, running_loss=1.1269, LR=0.000100
[2025-08-27 03:00:11,734][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029928] [Batch 02208/03080] [00:27:31/00:10:52, 0.748s/it]: train_loss_raw=1.2215, running_loss=1.1275, LR=0.000100
[2025-08-27 03:00:17,798][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029936] [Batch 02216/03080] [00:27:37/00:10:46, 0.748s/it]: train_loss_raw=1.0604, running_loss=1.1258, LR=0.000100
[2025-08-27 03:00:23,678][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029944] [Batch 02224/03080] [00:27:43/00:10:40, 0.748s/it]: train_loss_raw=1.0941, running_loss=1.1247, LR=0.000100
[2025-08-27 03:00:29,582][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029952] [Batch 02232/03080] [00:27:49/00:10:34, 0.748s/it]: train_loss_raw=1.0527, running_loss=1.1242, LR=0.000100
[2025-08-27 03:00:35,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029960] [Batch 02240/03080] [00:27:55/00:10:28, 0.748s/it]: train_loss_raw=1.2085, running_loss=1.1297, LR=0.000100
[2025-08-27 03:00:41,544][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029968] [Batch 02248/03080] [00:28:01/00:10:22, 0.748s/it]: train_loss_raw=1.1255, running_loss=1.1305, LR=0.000100
[2025-08-27 03:00:47,619][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029976] [Batch 02256/03080] [00:28:07/00:10:16, 0.748s/it]: train_loss_raw=1.1148, running_loss=1.1287, LR=0.000100
[2025-08-27 03:00:53,592][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029984] [Batch 02264/03080] [00:28:13/00:10:10, 0.748s/it]: train_loss_raw=1.1865, running_loss=1.1270, LR=0.000100
[2025-08-27 03:00:59,690][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029992] [Batch 02272/03080] [00:28:19/00:10:04, 0.748s/it]: train_loss_raw=1.2224, running_loss=1.1288, LR=0.000100
[2025-08-27 03:01:05,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030000] [Batch 02280/03080] [00:28:25/00:09:58, 0.748s/it]: train_loss_raw=1.0149, running_loss=1.1278, LR=0.000100
[2025-08-27 03:01:15,599][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030008] [Batch 02288/03080] [00:28:35/00:09:53, 0.750s/it]: train_loss_raw=1.2523, running_loss=1.1296, LR=0.000100
[2025-08-27 03:01:21,553][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030016] [Batch 02296/03080] [00:28:41/00:09:47, 0.750s/it]: train_loss_raw=1.0774, running_loss=1.1276, LR=0.000100
[2025-08-27 03:01:27,484][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030024] [Batch 02304/03080] [00:28:46/00:09:41, 0.750s/it]: train_loss_raw=1.1918, running_loss=1.1299, LR=0.000100
[2025-08-27 03:01:33,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030032] [Batch 02312/03080] [00:28:52/00:09:35, 0.750s/it]: train_loss_raw=1.1870, running_loss=1.1265, LR=0.000100
[2025-08-27 03:01:39,406][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030040] [Batch 02320/03080] [00:28:58/00:09:29, 0.750s/it]: train_loss_raw=1.0789, running_loss=1.1265, LR=0.000100
[2025-08-27 03:01:45,334][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030048] [Batch 02328/03080] [00:29:04/00:09:23, 0.749s/it]: train_loss_raw=1.0495, running_loss=1.1251, LR=0.000100
[2025-08-27 03:01:51,272][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030056] [Batch 02336/03080] [00:29:10/00:09:17, 0.749s/it]: train_loss_raw=1.1098, running_loss=1.1209, LR=0.000100
[2025-08-27 03:01:57,156][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030064] [Batch 02344/03080] [00:29:16/00:09:11, 0.749s/it]: train_loss_raw=1.1131, running_loss=1.1196, LR=0.000100
[2025-08-27 03:02:03,170][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030072] [Batch 02352/03080] [00:29:22/00:09:05, 0.749s/it]: train_loss_raw=1.2448, running_loss=1.1231, LR=0.000100
[2025-08-27 03:02:09,138][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030080] [Batch 02360/03080] [00:29:28/00:08:59, 0.749s/it]: train_loss_raw=1.0612, running_loss=1.1237, LR=0.000100
[2025-08-27 03:02:14,900][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030088] [Batch 02368/03080] [00:29:34/00:08:53, 0.749s/it]: train_loss_raw=1.0510, running_loss=1.1247, LR=0.000100
[2025-08-27 03:02:20,823][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030096] [Batch 02376/03080] [00:29:40/00:08:47, 0.749s/it]: train_loss_raw=1.0327, running_loss=1.1223, LR=0.000100
[2025-08-27 03:02:26,710][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030104] [Batch 02384/03080] [00:29:46/00:08:41, 0.749s/it]: train_loss_raw=1.0930, running_loss=1.1219, LR=0.000100
[2025-08-27 03:02:32,773][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030112] [Batch 02392/03080] [00:29:52/00:08:35, 0.749s/it]: train_loss_raw=1.1270, running_loss=1.1217, LR=0.000100
[2025-08-27 03:02:38,730][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030120] [Batch 02400/03080] [00:29:58/00:08:29, 0.749s/it]: train_loss_raw=1.0815, running_loss=1.1209, LR=0.000100
[2025-08-27 03:02:44,655][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030128] [Batch 02408/03080] [00:30:04/00:08:23, 0.749s/it]: train_loss_raw=1.1563, running_loss=1.1195, LR=0.000100
[2025-08-27 03:02:50,776][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030136] [Batch 02416/03080] [00:30:10/00:08:17, 0.749s/it]: train_loss_raw=1.0655, running_loss=1.1194, LR=0.000100
[2025-08-27 03:02:56,762][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030144] [Batch 02424/03080] [00:30:16/00:08:11, 0.749s/it]: train_loss_raw=1.1796, running_loss=1.1203, LR=0.000100
[2025-08-27 03:03:02,641][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030152] [Batch 02432/03080] [00:30:22/00:08:05, 0.749s/it]: train_loss_raw=1.1382, running_loss=1.1185, LR=0.000100
[2025-08-27 03:03:08,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030160] [Batch 02440/03080] [00:30:28/00:07:59, 0.749s/it]: train_loss_raw=1.1978, running_loss=1.1188, LR=0.000100
[2025-08-27 03:03:14,547][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030168] [Batch 02448/03080] [00:30:34/00:07:53, 0.749s/it]: train_loss_raw=1.1417, running_loss=1.1188, LR=0.000100
[2025-08-27 03:03:20,400][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030176] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.2026, running_loss=1.1201, LR=0.000100
[2025-08-27 03:03:26,275][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030184] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.0821, running_loss=1.1228, LR=0.000100
[2025-08-27 03:03:32,307][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030192] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.1331, running_loss=1.1223, LR=0.000100
[2025-08-27 03:03:38,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030200] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.1300, running_loss=1.1199, LR=0.000100
[2025-08-27 03:03:44,184][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030208] [Batch 02488/03080] [00:31:03/00:07:23, 0.749s/it]: train_loss_raw=1.1926, running_loss=1.1218, LR=0.000100
[2025-08-27 03:03:50,009][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030216] [Batch 02496/03080] [00:31:09/00:07:17, 0.749s/it]: train_loss_raw=1.1846, running_loss=1.1211, LR=0.000100
[2025-08-27 03:03:55,806][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030224] [Batch 02504/03080] [00:31:15/00:07:11, 0.749s/it]: train_loss_raw=1.1089, running_loss=1.1233, LR=0.000100
[2025-08-27 03:04:01,720][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030232] [Batch 02512/03080] [00:31:21/00:07:05, 0.749s/it]: train_loss_raw=1.1660, running_loss=1.1235, LR=0.000100
[2025-08-27 03:04:07,656][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030240] [Batch 02520/03080] [00:31:27/00:06:59, 0.749s/it]: train_loss_raw=1.2337, running_loss=1.1228, LR=0.000100
[2025-08-27 03:04:13,690][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030248] [Batch 02528/03080] [00:31:33/00:06:53, 0.749s/it]: train_loss_raw=1.1694, running_loss=1.1228, LR=0.000100
[2025-08-27 03:04:19,575][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030256] [Batch 02536/03080] [00:31:39/00:06:47, 0.749s/it]: train_loss_raw=1.1624, running_loss=1.1261, LR=0.000100
[2025-08-27 03:04:25,416][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030264] [Batch 02544/03080] [00:31:44/00:06:41, 0.749s/it]: train_loss_raw=1.0787, running_loss=1.1247, LR=0.000100
[2025-08-27 03:04:31,328][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030272] [Batch 02552/03080] [00:31:50/00:06:35, 0.749s/it]: train_loss_raw=1.1663, running_loss=1.1255, LR=0.000100
[2025-08-27 03:04:37,171][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030280] [Batch 02560/03080] [00:31:56/00:06:29, 0.749s/it]: train_loss_raw=1.0723, running_loss=1.1231, LR=0.000100
[2025-08-27 03:04:43,090][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030288] [Batch 02568/03080] [00:32:02/00:06:23, 0.749s/it]: train_loss_raw=1.1682, running_loss=1.1213, LR=0.000100
[2025-08-27 03:04:49,060][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030296] [Batch 02576/03080] [00:32:08/00:06:17, 0.749s/it]: train_loss_raw=0.9643, running_loss=1.1217, LR=0.000100
[2025-08-27 03:04:54,927][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030304] [Batch 02584/03080] [00:32:14/00:06:11, 0.749s/it]: train_loss_raw=1.0929, running_loss=1.1198, LR=0.000100
[2025-08-27 03:05:00,892][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030312] [Batch 02592/03080] [00:32:20/00:06:05, 0.749s/it]: train_loss_raw=1.1601, running_loss=1.1197, LR=0.000100
[2025-08-27 03:05:06,829][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030320] [Batch 02600/03080] [00:32:26/00:05:59, 0.749s/it]: train_loss_raw=1.1761, running_loss=1.1197, LR=0.000100
[2025-08-27 03:05:12,801][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030328] [Batch 02608/03080] [00:32:32/00:05:53, 0.749s/it]: train_loss_raw=1.2567, running_loss=1.1214, LR=0.000100
[2025-08-27 03:05:18,706][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030336] [Batch 02616/03080] [00:32:38/00:05:47, 0.749s/it]: train_loss_raw=1.2406, running_loss=1.1245, LR=0.000100
[2025-08-27 03:05:24,521][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030344] [Batch 02624/03080] [00:32:44/00:05:41, 0.748s/it]: train_loss_raw=1.0798, running_loss=1.1268, LR=0.000100
[2025-08-27 03:05:30,338][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030352] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=1.0816, running_loss=1.1263, LR=0.000100
[2025-08-27 03:05:36,451][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030360] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.0610, running_loss=1.1263, LR=0.000100
[2025-08-27 03:05:42,270][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030368] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=0.9837, running_loss=1.1223, LR=0.000100
[2025-08-27 03:05:48,151][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030376] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=1.0554, running_loss=1.1204, LR=0.000100
[2025-08-27 03:05:54,012][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030384] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=1.2173, running_loss=1.1218, LR=0.000100
[2025-08-27 03:06:00,016][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030392] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=1.1243, running_loss=1.1215, LR=0.000100
[2025-08-27 03:06:06,048][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030400] [Batch 02680/03080] [00:33:25/00:04:59, 0.748s/it]: train_loss_raw=1.0946, running_loss=1.1201, LR=0.000100
[2025-08-27 03:06:12,073][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030408] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=1.1175, running_loss=1.1198, LR=0.000100
[2025-08-27 03:06:18,112][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030416] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=1.1318, running_loss=1.1203, LR=0.000100
[2025-08-27 03:06:24,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030424] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=1.2073, running_loss=1.1225, LR=0.000100
[2025-08-27 03:06:30,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030432] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=1.1196, running_loss=1.1212, LR=0.000100
[2025-08-27 03:06:36,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030440] [Batch 02720/03080] [00:33:55/00:04:29, 0.748s/it]: train_loss_raw=1.1089, running_loss=1.1218, LR=0.000100
[2025-08-27 03:06:42,060][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030448] [Batch 02728/03080] [00:34:01/00:04:23, 0.748s/it]: train_loss_raw=1.0563, running_loss=1.1181, LR=0.000100
[2025-08-27 03:06:48,009][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030456] [Batch 02736/03080] [00:34:07/00:04:17, 0.748s/it]: train_loss_raw=1.1506, running_loss=1.1156, LR=0.000100
[2025-08-27 03:06:53,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030464] [Batch 02744/03080] [00:34:13/00:04:11, 0.748s/it]: train_loss_raw=1.0977, running_loss=1.1131, LR=0.000100
[2025-08-27 03:06:59,642][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030472] [Batch 02752/03080] [00:34:19/00:04:05, 0.748s/it]: train_loss_raw=1.1611, running_loss=1.1144, LR=0.000100
[2025-08-27 03:07:05,492][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030480] [Batch 02760/03080] [00:34:24/00:03:59, 0.748s/it]: train_loss_raw=1.0667, running_loss=1.1143, LR=0.000100
[2025-08-27 03:07:11,331][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030488] [Batch 02768/03080] [00:34:30/00:03:53, 0.748s/it]: train_loss_raw=1.1700, running_loss=1.1133, LR=0.000100
[2025-08-27 03:07:17,228][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030496] [Batch 02776/03080] [00:34:36/00:03:47, 0.748s/it]: train_loss_raw=1.1279, running_loss=1.1174, LR=0.000100
[2025-08-27 03:07:23,341][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030504] [Batch 02784/03080] [00:34:42/00:03:41, 0.748s/it]: train_loss_raw=1.2461, running_loss=1.1194, LR=0.000100
[2025-08-27 03:07:29,300][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030512] [Batch 02792/03080] [00:34:48/00:03:35, 0.748s/it]: train_loss_raw=1.1306, running_loss=1.1178, LR=0.000100
[2025-08-27 03:07:35,368][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030520] [Batch 02800/03080] [00:34:54/00:03:29, 0.748s/it]: train_loss_raw=1.2202, running_loss=1.1206, LR=0.000100
[2025-08-27 03:07:41,368][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030528] [Batch 02808/03080] [00:35:00/00:03:23, 0.748s/it]: train_loss_raw=1.1473, running_loss=1.1174, LR=0.000100
[2025-08-27 03:07:47,140][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030536] [Batch 02816/03080] [00:35:06/00:03:17, 0.748s/it]: train_loss_raw=1.0802, running_loss=1.1159, LR=0.000100
[2025-08-27 03:07:52,932][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030544] [Batch 02824/03080] [00:35:12/00:03:11, 0.748s/it]: train_loss_raw=1.1775, running_loss=1.1188, LR=0.000100
[2025-08-27 03:07:58,918][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030552] [Batch 02832/03080] [00:35:18/00:03:05, 0.748s/it]: train_loss_raw=1.0052, running_loss=1.1156, LR=0.000100
[2025-08-27 03:08:04,708][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030560] [Batch 02840/03080] [00:35:24/00:02:59, 0.748s/it]: train_loss_raw=1.1064, running_loss=1.1160, LR=0.000100
[2025-08-27 03:08:10,705][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030568] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=1.0811, running_loss=1.1160, LR=0.000100
[2025-08-27 03:08:16,798][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030576] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=1.1424, running_loss=1.1164, LR=0.000100
[2025-08-27 03:08:22,616][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030584] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=1.1426, running_loss=1.1166, LR=0.000100
[2025-08-27 03:08:28,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030592] [Batch 02872/03080] [00:35:47/00:02:35, 0.748s/it]: train_loss_raw=1.0679, running_loss=1.1160, LR=0.000100
[2025-08-27 03:08:34,443][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030600] [Batch 02880/03080] [00:35:53/00:02:29, 0.748s/it]: train_loss_raw=1.1269, running_loss=1.1142, LR=0.000100
[2025-08-27 03:08:40,398][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030608] [Batch 02888/03080] [00:35:59/00:02:23, 0.748s/it]: train_loss_raw=1.1169, running_loss=1.1157, LR=0.000100
[2025-08-27 03:08:46,355][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030616] [Batch 02896/03080] [00:36:05/00:02:17, 0.748s/it]: train_loss_raw=1.0764, running_loss=1.1136, LR=0.000100
[2025-08-27 03:08:52,540][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030624] [Batch 02904/03080] [00:36:12/00:02:11, 0.748s/it]: train_loss_raw=1.1833, running_loss=1.1152, LR=0.000100
[2025-08-27 03:08:58,466][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030632] [Batch 02912/03080] [00:36:17/00:02:05, 0.748s/it]: train_loss_raw=1.2513, running_loss=1.1171, LR=0.000100
[2025-08-27 03:09:04,366][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030640] [Batch 02920/03080] [00:36:23/00:01:59, 0.748s/it]: train_loss_raw=1.1437, running_loss=1.1172, LR=0.000100
[2025-08-27 03:09:10,411][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030648] [Batch 02928/03080] [00:36:29/00:01:53, 0.748s/it]: train_loss_raw=1.0304, running_loss=1.1161, LR=0.000100
[2025-08-27 03:09:16,293][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030656] [Batch 02936/03080] [00:36:35/00:01:47, 0.748s/it]: train_loss_raw=1.1836, running_loss=1.1185, LR=0.000100
[2025-08-27 03:09:22,352][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030664] [Batch 02944/03080] [00:36:41/00:01:41, 0.748s/it]: train_loss_raw=1.1618, running_loss=1.1176, LR=0.000100
[2025-08-27 03:09:28,250][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030672] [Batch 02952/03080] [00:36:47/00:01:35, 0.748s/it]: train_loss_raw=1.1201, running_loss=1.1166, LR=0.000100
[2025-08-27 03:09:34,156][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030680] [Batch 02960/03080] [00:36:53/00:01:29, 0.748s/it]: train_loss_raw=1.1042, running_loss=1.1117, LR=0.000100
[2025-08-27 03:09:40,040][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030688] [Batch 02968/03080] [00:36:59/00:01:23, 0.748s/it]: train_loss_raw=1.1136, running_loss=1.1140, LR=0.000100
[2025-08-27 03:09:46,057][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030696] [Batch 02976/03080] [00:37:05/00:01:17, 0.748s/it]: train_loss_raw=1.0419, running_loss=1.1142, LR=0.000100
[2025-08-27 03:09:52,396][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030704] [Batch 02984/03080] [00:37:11/00:01:11, 0.748s/it]: train_loss_raw=1.1419, running_loss=1.1135, LR=0.000100
[2025-08-27 03:09:58,611][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030712] [Batch 02992/03080] [00:37:18/00:01:05, 0.748s/it]: train_loss_raw=1.1808, running_loss=1.1102, LR=0.000100
[2025-08-27 03:10:04,541][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030720] [Batch 03000/03080] [00:37:24/00:00:59, 0.748s/it]: train_loss_raw=1.0151, running_loss=1.1090, LR=0.000100
[2025-08-27 03:10:10,403][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030728] [Batch 03008/03080] [00:37:29/00:00:53, 0.748s/it]: train_loss_raw=1.0695, running_loss=1.1095, LR=0.000100
[2025-08-27 03:10:16,296][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030736] [Batch 03016/03080] [00:37:35/00:00:47, 0.748s/it]: train_loss_raw=1.0249, running_loss=1.1064, LR=0.000100
[2025-08-27 03:10:22,132][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030744] [Batch 03024/03080] [00:37:41/00:00:41, 0.748s/it]: train_loss_raw=1.1661, running_loss=1.1062, LR=0.000100
[2025-08-27 03:10:28,094][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030752] [Batch 03032/03080] [00:37:47/00:00:35, 0.748s/it]: train_loss_raw=1.1258, running_loss=1.1028, LR=0.000100
[2025-08-27 03:10:34,295][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030760] [Batch 03040/03080] [00:37:53/00:00:29, 0.748s/it]: train_loss_raw=1.0684, running_loss=1.1016, LR=0.000100
[2025-08-27 03:10:40,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030768] [Batch 03048/03080] [00:37:59/00:00:23, 0.748s/it]: train_loss_raw=1.2263, running_loss=1.1035, LR=0.000100
[2025-08-27 03:10:46,273][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030776] [Batch 03056/03080] [00:38:05/00:00:17, 0.748s/it]: train_loss_raw=1.0801, running_loss=1.1038, LR=0.000100
[2025-08-27 03:10:52,230][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030784] [Batch 03064/03080] [00:38:11/00:00:11, 0.748s/it]: train_loss_raw=1.2277, running_loss=1.1060, LR=0.000100
[2025-08-27 03:10:58,138][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030792] [Batch 03072/03080] [00:38:17/00:00:05, 0.748s/it]: train_loss_raw=1.1076, running_loss=1.1046, LR=0.000100
[2025-08-27 03:11:09,577][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030800] [Batch 03080/03080] [00:38:29/00:00:00, 0.750s/it]: train_loss_raw=1.0632, running_loss=1.1030, LR=0.000100
[2025-08-27 03:11:10,124][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-27 03:11:21,204][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00007/00310] [00:00:11/00:06:58, 1.385s/it]
[2025-08-27 03:11:32,646][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00015/00310] [00:00:22/00:06:53, 1.408s/it]
[2025-08-27 03:11:44,428][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00023/00310] [00:00:34/00:06:48, 1.429s/it]
[2025-08-27 03:11:56,279][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00031/00310] [00:00:46/00:06:40, 1.442s/it]
[2025-08-27 03:12:08,787][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00039/00310] [00:00:58/00:06:35, 1.467s/it]
[2025-08-27 03:12:21,460][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00047/00310] [00:01:11/00:06:29, 1.486s/it]
[2025-08-27 03:12:34,221][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00055/00310] [00:01:24/00:06:21, 1.502s/it]
[2025-08-27 03:12:46,723][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00063/00310] [00:01:36/00:06:11, 1.509s/it]
[2025-08-27 03:12:59,771][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00071/00310] [00:01:49/00:06:02, 1.523s/it]
[2025-08-27 03:13:12,097][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00079/00310] [00:02:01/00:05:50, 1.525s/it]
[2025-08-27 03:13:24,581][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00087/00310] [00:02:14/00:05:39, 1.528s/it]
[2025-08-27 03:13:36,966][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00095/00310] [00:02:26/00:05:27, 1.530s/it]
[2025-08-27 03:13:49,924][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00103/00310] [00:02:39/00:05:16, 1.537s/it]
[2025-08-27 03:14:02,897][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00111/00310] [00:02:52/00:05:05, 1.543s/it]
[2025-08-27 03:14:15,424][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00119/00310] [00:03:05/00:04:53, 1.544s/it]
[2025-08-27 03:14:27,854][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00127/00310] [00:03:17/00:04:41, 1.545s/it]
[2025-08-27 03:14:40,531][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00135/00310] [00:03:30/00:04:29, 1.547s/it]
[2025-08-27 03:14:53,162][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00143/00310] [00:03:43/00:04:17, 1.549s/it]
[2025-08-27 03:15:04,799][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00151/00310] [00:03:54/00:04:03, 1.544s/it]
[2025-08-27 03:15:16,723][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00159/00310] [00:04:06/00:03:51, 1.541s/it]
[2025-08-27 03:15:29,682][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00167/00310] [00:04:19/00:03:39, 1.545s/it]
[2025-08-27 03:15:41,097][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00175/00310] [00:04:30/00:03:26, 1.540s/it]
[2025-08-27 03:15:53,332][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00183/00310] [00:04:43/00:03:13, 1.539s/it]
[2025-08-27 03:16:05,964][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00191/00310] [00:04:55/00:03:01, 1.541s/it]
[2025-08-27 03:16:17,797][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00199/00310] [00:05:07/00:02:49, 1.538s/it]
[2025-08-27 03:16:29,866][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00207/00310] [00:05:19/00:02:36, 1.537s/it]
[2025-08-27 03:16:41,884][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00215/00310] [00:05:31/00:02:24, 1.536s/it]
[2025-08-27 03:16:53,805][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00223/00310] [00:05:43/00:02:11, 1.534s/it]
[2025-08-27 03:17:06,668][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00231/00310] [00:05:56/00:01:59, 1.537s/it]
[2025-08-27 03:17:19,057][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00239/00310] [00:06:08/00:01:47, 1.537s/it]
[2025-08-27 03:17:31,159][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00247/00310] [00:06:21/00:01:35, 1.536s/it]
[2025-08-27 03:17:43,482][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00255/00310] [00:06:33/00:01:22, 1.537s/it]
[2025-08-27 03:17:56,413][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00263/00310] [00:06:46/00:01:10, 1.539s/it]
[2025-08-27 03:18:08,811][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00271/00310] [00:06:58/00:00:58, 1.539s/it]
[2025-08-27 03:18:20,723][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00279/00310] [00:07:10/00:00:46, 1.538s/it]
[2025-08-27 03:18:33,025][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00287/00310] [00:07:22/00:00:33, 1.538s/it]
[2025-08-27 03:18:44,817][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00295/00310] [00:07:34/00:00:21, 1.536s/it]
[2025-08-27 03:18:57,103][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00303/00310] [00:07:46/00:00:09, 1.536s/it]
[2025-08-27 03:19:06,343][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.10304, valid_loss=1.89391
[2025-08-27 03:19:06,343][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-27 03:19:06,343][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.716
[2025-08-27 03:19:06,343][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.040
[2025-08-27 03:19:06,343][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.041
[2025-08-27 03:19:06,344][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.013
[2025-08-27 03:19:06,353][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 07:52:20, remaining time 15:44:40, 00:47:14 per epoch
[2025-08-27 03:19:12,790][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030808] [Batch 00008/03080] [00:00:06/00:39:30, 0.772s/it]: train_loss_raw=1.0566, running_loss=1.0646, LR=0.000100
[2025-08-27 03:19:18,988][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030816] [Batch 00016/03080] [00:00:12/00:39:29, 0.773s/it]: train_loss_raw=1.0541, running_loss=1.0647, LR=0.000100
[2025-08-27 03:19:24,953][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030824] [Batch 00024/03080] [00:00:18/00:38:54, 0.764s/it]: train_loss_raw=1.0150, running_loss=1.0661, LR=0.000100
[2025-08-27 03:19:30,879][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030832] [Batch 00032/03080] [00:00:24/00:38:31, 0.758s/it]: train_loss_raw=1.0575, running_loss=1.0651, LR=0.000100
[2025-08-27 03:19:36,798][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030840] [Batch 00040/03080] [00:00:30/00:38:13, 0.755s/it]: train_loss_raw=1.1474, running_loss=1.0671, LR=0.000100
[2025-08-27 03:19:42,748][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030848] [Batch 00048/03080] [00:00:36/00:38:02, 0.753s/it]: train_loss_raw=1.1406, running_loss=1.0656, LR=0.000100
[2025-08-27 03:19:48,879][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030856] [Batch 00056/03080] [00:00:42/00:38:02, 0.755s/it]: train_loss_raw=1.1662, running_loss=1.0681, LR=0.000100
[2025-08-27 03:19:54,953][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030864] [Batch 00064/03080] [00:00:48/00:37:57, 0.755s/it]: train_loss_raw=1.0543, running_loss=1.0698, LR=0.000100
[2025-08-27 03:20:00,849][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030872] [Batch 00072/03080] [00:00:54/00:37:45, 0.753s/it]: train_loss_raw=1.0874, running_loss=1.0715, LR=0.000100
[2025-08-27 03:20:06,687][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030880] [Batch 00080/03080] [00:01:00/00:37:32, 0.751s/it]: train_loss_raw=1.0043, running_loss=1.0727, LR=0.000100
[2025-08-27 03:20:12,426][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030888] [Batch 00088/03080] [00:01:05/00:37:17, 0.748s/it]: train_loss_raw=1.1696, running_loss=1.0736, LR=0.000100
[2025-08-27 03:20:18,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030896] [Batch 00096/03080] [00:01:11/00:37:05, 0.746s/it]: train_loss_raw=1.1355, running_loss=1.0773, LR=0.000100
[2025-08-27 03:20:23,995][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030904] [Batch 00104/03080] [00:01:17/00:36:54, 0.744s/it]: train_loss_raw=1.0545, running_loss=1.0790, LR=0.000100
[2025-08-27 03:20:29,982][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030912] [Batch 00112/03080] [00:01:23/00:36:49, 0.744s/it]: train_loss_raw=1.0904, running_loss=1.0824, LR=0.000100
[2025-08-27 03:20:36,003][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030920] [Batch 00120/03080] [00:01:29/00:36:44, 0.745s/it]: train_loss_raw=1.0113, running_loss=1.0849, LR=0.000100
[2025-08-27 03:20:41,598][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030928] [Batch 00128/03080] [00:01:34/00:36:30, 0.742s/it]: train_loss_raw=1.1352, running_loss=1.0872, LR=0.000100
[2025-08-27 03:20:47,462][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030936] [Batch 00136/03080] [00:01:40/00:36:23, 0.742s/it]: train_loss_raw=1.0508, running_loss=1.0887, LR=0.000100
[2025-08-27 03:20:53,347][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030944] [Batch 00144/03080] [00:01:46/00:36:16, 0.741s/it]: train_loss_raw=1.0898, running_loss=1.0870, LR=0.000100
[2025-08-27 03:20:59,233][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030952] [Batch 00152/03080] [00:01:52/00:36:09, 0.741s/it]: train_loss_raw=1.0725, running_loss=1.0872, LR=0.000100
[2025-08-27 03:21:05,312][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030960] [Batch 00160/03080] [00:01:58/00:36:06, 0.742s/it]: train_loss_raw=1.0498, running_loss=1.0865, LR=0.000100
[2025-08-27 03:21:11,283][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030968] [Batch 00168/03080] [00:02:04/00:36:00, 0.742s/it]: train_loss_raw=1.0899, running_loss=1.0849, LR=0.000100
[2025-08-27 03:21:17,280][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030976] [Batch 00176/03080] [00:02:10/00:35:55, 0.742s/it]: train_loss_raw=1.0789, running_loss=1.0848, LR=0.000100
[2025-08-27 03:21:23,265][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030984] [Batch 00184/03080] [00:02:16/00:35:50, 0.743s/it]: train_loss_raw=1.0507, running_loss=1.0873, LR=0.000100
[2025-08-27 03:21:29,206][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030992] [Batch 00192/03080] [00:02:22/00:35:44, 0.743s/it]: train_loss_raw=1.1551, running_loss=1.0871, LR=0.000100
[2025-08-27 03:21:35,275][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031000] [Batch 00200/03080] [00:02:28/00:35:40, 0.743s/it]: train_loss_raw=1.0266, running_loss=1.0869, LR=0.000100
[2025-08-27 03:21:41,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031008] [Batch 00208/03080] [00:02:34/00:35:34, 0.743s/it]: train_loss_raw=0.9755, running_loss=1.0888, LR=0.000100
[2025-08-27 03:21:46,928][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031016] [Batch 00216/03080] [00:02:40/00:35:25, 0.742s/it]: train_loss_raw=1.0315, running_loss=1.0885, LR=0.000100
[2025-08-27 03:21:52,970][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031024] [Batch 00224/03080] [00:02:46/00:35:21, 0.743s/it]: train_loss_raw=1.0604, running_loss=1.0880, LR=0.000100
[2025-08-27 03:21:58,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031032] [Batch 00232/03080] [00:02:52/00:35:14, 0.743s/it]: train_loss_raw=1.1215, running_loss=1.0892, LR=0.000100
[2025-08-27 03:22:04,995][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031040] [Batch 00240/03080] [00:02:58/00:35:10, 0.743s/it]: train_loss_raw=1.1388, running_loss=1.0909, LR=0.000100
[2025-08-27 03:22:10,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031048] [Batch 00248/03080] [00:03:04/00:35:02, 0.742s/it]: train_loss_raw=1.0939, running_loss=1.0899, LR=0.000100
[2025-08-27 03:22:16,583][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031056] [Batch 00256/03080] [00:03:09/00:34:55, 0.742s/it]: train_loss_raw=1.1255, running_loss=1.0874, LR=0.000100
[2025-08-27 03:22:22,561][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031064] [Batch 00264/03080] [00:03:15/00:34:50, 0.742s/it]: train_loss_raw=1.1493, running_loss=1.0879, LR=0.000100
[2025-08-27 03:22:28,539][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031072] [Batch 00272/03080] [00:03:21/00:34:44, 0.742s/it]: train_loss_raw=1.1116, running_loss=1.0902, LR=0.000100
[2025-08-27 03:22:34,483][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031080] [Batch 00280/03080] [00:03:27/00:34:38, 0.742s/it]: train_loss_raw=1.0705, running_loss=1.0900, LR=0.000100
[2025-08-27 03:22:40,580][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031088] [Batch 00288/03080] [00:03:33/00:34:34, 0.743s/it]: train_loss_raw=1.0553, running_loss=1.0903, LR=0.000100
[2025-08-27 03:22:46,608][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031096] [Batch 00296/03080] [00:03:39/00:34:29, 0.743s/it]: train_loss_raw=0.9268, running_loss=1.0879, LR=0.000100
[2025-08-27 03:22:52,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031104] [Batch 00304/03080] [00:03:45/00:34:21, 0.743s/it]: train_loss_raw=1.0768, running_loss=1.0868, LR=0.000100
[2025-08-27 03:22:58,404][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031112] [Batch 00312/03080] [00:03:51/00:34:16, 0.743s/it]: train_loss_raw=1.0026, running_loss=1.0824, LR=0.000100
[2025-08-27 03:23:04,365][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031120] [Batch 00320/03080] [00:03:57/00:34:10, 0.743s/it]: train_loss_raw=1.1985, running_loss=1.0815, LR=0.000100
[2025-08-27 03:23:10,351][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031128] [Batch 00328/03080] [00:04:03/00:34:04, 0.743s/it]: train_loss_raw=1.0615, running_loss=1.0831, LR=0.000100
[2025-08-27 03:23:16,477][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031136] [Batch 00336/03080] [00:04:09/00:34:00, 0.744s/it]: train_loss_raw=1.0980, running_loss=1.0828, LR=0.000100
[2025-08-27 03:23:22,585][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031144] [Batch 00344/03080] [00:04:15/00:33:55, 0.744s/it]: train_loss_raw=1.1036, running_loss=1.0822, LR=0.000100
[2025-08-27 03:23:28,709][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031152] [Batch 00352/03080] [00:04:22/00:33:51, 0.745s/it]: train_loss_raw=1.0921, running_loss=1.0800, LR=0.000100
[2025-08-27 03:23:34,813][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031160] [Batch 00360/03080] [00:04:28/00:33:46, 0.745s/it]: train_loss_raw=1.0220, running_loss=1.0809, LR=0.000100
[2025-08-27 03:23:40,957][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031168] [Batch 00368/03080] [00:04:34/00:33:41, 0.745s/it]: train_loss_raw=1.1038, running_loss=1.0828, LR=0.000100
[2025-08-27 03:23:46,959][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031176] [Batch 00376/03080] [00:04:40/00:33:36, 0.746s/it]: train_loss_raw=1.0779, running_loss=1.0833, LR=0.000100
[2025-08-27 03:23:52,897][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031184] [Batch 00384/03080] [00:04:46/00:33:29, 0.746s/it]: train_loss_raw=1.0522, running_loss=1.0833, LR=0.000100
[2025-08-27 03:23:58,849][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031192] [Batch 00392/03080] [00:04:52/00:33:23, 0.745s/it]: train_loss_raw=1.1266, running_loss=1.0839, LR=0.000100
[2025-08-27 03:24:04,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031200] [Batch 00400/03080] [00:04:58/00:33:18, 0.746s/it]: train_loss_raw=1.0041, running_loss=1.0817, LR=0.000100
[2025-08-27 03:24:10,851][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031208] [Batch 00408/03080] [00:05:04/00:33:12, 0.746s/it]: train_loss_raw=1.0213, running_loss=1.0812, LR=0.000100
[2025-08-27 03:24:16,800][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031216] [Batch 00416/03080] [00:05:10/00:33:06, 0.746s/it]: train_loss_raw=1.1363, running_loss=1.0801, LR=0.000100
[2025-08-27 03:24:22,821][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031224] [Batch 00424/03080] [00:05:16/00:33:00, 0.746s/it]: train_loss_raw=1.0859, running_loss=1.0809, LR=0.000100
[2025-08-27 03:24:28,994][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031232] [Batch 00432/03080] [00:05:22/00:32:56, 0.746s/it]: train_loss_raw=1.0108, running_loss=1.0808, LR=0.000100
[2025-08-27 03:24:35,091][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031240] [Batch 00440/03080] [00:05:28/00:32:50, 0.747s/it]: train_loss_raw=1.0728, running_loss=1.0820, LR=0.000100
[2025-08-27 03:24:40,844][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031248] [Batch 00448/03080] [00:05:34/00:32:43, 0.746s/it]: train_loss_raw=1.0977, running_loss=1.0809, LR=0.000100
[2025-08-27 03:24:46,792][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031256] [Batch 00456/03080] [00:05:40/00:32:37, 0.746s/it]: train_loss_raw=1.0217, running_loss=1.0794, LR=0.000100
[2025-08-27 03:24:52,600][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031264] [Batch 00464/03080] [00:05:45/00:32:30, 0.746s/it]: train_loss_raw=1.0537, running_loss=1.0786, LR=0.000100
[2025-08-27 03:24:58,443][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031272] [Batch 00472/03080] [00:05:51/00:32:23, 0.745s/it]: train_loss_raw=1.0056, running_loss=1.0750, LR=0.000100
[2025-08-27 03:25:04,556][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031280] [Batch 00480/03080] [00:05:57/00:32:18, 0.746s/it]: train_loss_raw=1.0696, running_loss=1.0756, LR=0.000100
[2025-08-27 03:25:10,602][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031288] [Batch 00488/03080] [00:06:03/00:32:13, 0.746s/it]: train_loss_raw=1.0539, running_loss=1.0749, LR=0.000100
[2025-08-27 03:25:16,571][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031296] [Batch 00496/03080] [00:06:09/00:32:07, 0.746s/it]: train_loss_raw=1.1052, running_loss=1.0758, LR=0.000100
[2025-08-27 03:25:22,539][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031304] [Batch 00504/03080] [00:06:15/00:32:01, 0.746s/it]: train_loss_raw=1.0421, running_loss=1.0758, LR=0.000100
[2025-08-27 03:25:28,491][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031312] [Batch 00512/03080] [00:06:21/00:31:55, 0.746s/it]: train_loss_raw=1.0421, running_loss=1.0760, LR=0.000100
[2025-08-27 03:25:34,443][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031320] [Batch 00520/03080] [00:06:27/00:31:49, 0.746s/it]: train_loss_raw=1.1727, running_loss=1.0767, LR=0.000100
[2025-08-27 03:25:40,565][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031328] [Batch 00528/03080] [00:06:33/00:31:44, 0.746s/it]: train_loss_raw=1.0937, running_loss=1.0763, LR=0.000100
[2025-08-27 03:25:46,553][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031336] [Batch 00536/03080] [00:06:39/00:31:38, 0.746s/it]: train_loss_raw=1.2418, running_loss=1.0780, LR=0.000100
[2025-08-27 03:25:52,440][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031344] [Batch 00544/03080] [00:06:45/00:31:31, 0.746s/it]: train_loss_raw=1.1017, running_loss=1.0798, LR=0.000100
[2025-08-27 03:25:58,331][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031352] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=1.1351, running_loss=1.0800, LR=0.000100
[2025-08-27 03:26:04,398][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031360] [Batch 00560/03080] [00:06:57/00:31:20, 0.746s/it]: train_loss_raw=1.1154, running_loss=1.0806, LR=0.000100
[2025-08-27 03:26:10,233][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031368] [Batch 00568/03080] [00:07:03/00:31:13, 0.746s/it]: train_loss_raw=0.9536, running_loss=1.0810, LR=0.000100
[2025-08-27 03:26:16,210][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031376] [Batch 00576/03080] [00:07:09/00:31:07, 0.746s/it]: train_loss_raw=1.0604, running_loss=1.0801, LR=0.000100
[2025-08-27 03:26:22,216][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031384] [Batch 00584/03080] [00:07:15/00:31:01, 0.746s/it]: train_loss_raw=1.1770, running_loss=1.0837, LR=0.000100
[2025-08-27 03:26:28,179][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031392] [Batch 00592/03080] [00:07:21/00:30:55, 0.746s/it]: train_loss_raw=1.1314, running_loss=1.0851, LR=0.000100
[2025-08-27 03:26:34,131][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031400] [Batch 00600/03080] [00:07:27/00:30:49, 0.746s/it]: train_loss_raw=1.1549, running_loss=1.0874, LR=0.000100
[2025-08-27 03:26:40,053][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031408] [Batch 00608/03080] [00:07:33/00:30:43, 0.746s/it]: train_loss_raw=1.0427, running_loss=1.0856, LR=0.000100
[2025-08-27 03:26:45,937][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031416] [Batch 00616/03080] [00:07:39/00:30:37, 0.746s/it]: train_loss_raw=1.2355, running_loss=1.0884, LR=0.000100
[2025-08-27 03:26:51,800][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031424] [Batch 00624/03080] [00:07:45/00:30:30, 0.745s/it]: train_loss_raw=1.0878, running_loss=1.0888, LR=0.000100
[2025-08-27 03:26:57,700][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031432] [Batch 00632/03080] [00:07:51/00:30:24, 0.745s/it]: train_loss_raw=1.1219, running_loss=1.0897, LR=0.000100
[2025-08-27 03:27:03,657][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031440] [Batch 00640/03080] [00:07:57/00:30:18, 0.745s/it]: train_loss_raw=1.0560, running_loss=1.0868, LR=0.000100
[2025-08-27 03:27:09,820][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031448] [Batch 00648/03080] [00:08:03/00:30:13, 0.746s/it]: train_loss_raw=1.0514, running_loss=1.0846, LR=0.000100
[2025-08-27 03:27:15,793][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031456] [Batch 00656/03080] [00:08:09/00:30:07, 0.746s/it]: train_loss_raw=1.0902, running_loss=1.0847, LR=0.000100
[2025-08-27 03:27:21,777][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031464] [Batch 00664/03080] [00:08:15/00:30:01, 0.746s/it]: train_loss_raw=1.1163, running_loss=1.0857, LR=0.000100
[2025-08-27 03:27:27,786][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031472] [Batch 00672/03080] [00:08:21/00:29:55, 0.746s/it]: train_loss_raw=1.0209, running_loss=1.0847, LR=0.000100
[2025-08-27 03:27:33,618][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031480] [Batch 00680/03080] [00:08:27/00:29:49, 0.746s/it]: train_loss_raw=1.1132, running_loss=1.0835, LR=0.000100
[2025-08-27 03:27:39,432][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031488] [Batch 00688/03080] [00:08:32/00:29:42, 0.745s/it]: train_loss_raw=1.0852, running_loss=1.0816, LR=0.000100
[2025-08-27 03:27:45,282][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031496] [Batch 00696/03080] [00:08:38/00:29:36, 0.745s/it]: train_loss_raw=1.0980, running_loss=1.0820, LR=0.000100
[2025-08-27 03:27:51,321][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031504] [Batch 00704/03080] [00:08:44/00:29:30, 0.745s/it]: train_loss_raw=1.0359, running_loss=1.0831, LR=0.000100
[2025-08-27 03:27:57,364][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031512] [Batch 00712/03080] [00:08:50/00:29:25, 0.745s/it]: train_loss_raw=1.0432, running_loss=1.0829, LR=0.000100
[2025-08-27 03:28:03,394][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031520] [Batch 00720/03080] [00:08:56/00:29:19, 0.746s/it]: train_loss_raw=1.0633, running_loss=1.0805, LR=0.000100
[2025-08-27 03:28:09,212][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031528] [Batch 00728/03080] [00:09:02/00:29:13, 0.745s/it]: train_loss_raw=1.0890, running_loss=1.0800, LR=0.000100
[2025-08-27 03:28:15,172][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031536] [Batch 00736/03080] [00:09:08/00:29:07, 0.745s/it]: train_loss_raw=1.1581, running_loss=1.0811, LR=0.000100
[2025-08-27 03:28:21,058][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031544] [Batch 00744/03080] [00:09:14/00:29:00, 0.745s/it]: train_loss_raw=1.1175, running_loss=1.0812, LR=0.000100
[2025-08-27 03:28:27,147][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031552] [Batch 00752/03080] [00:09:20/00:28:55, 0.745s/it]: train_loss_raw=1.0821, running_loss=1.0820, LR=0.000100
[2025-08-27 03:28:32,933][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031560] [Batch 00760/03080] [00:09:26/00:28:48, 0.745s/it]: train_loss_raw=1.1310, running_loss=1.0825, LR=0.000100
[2025-08-27 03:28:38,886][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031568] [Batch 00768/03080] [00:09:32/00:28:42, 0.745s/it]: train_loss_raw=0.9923, running_loss=1.0854, LR=0.000100
[2025-08-27 03:28:44,813][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031576] [Batch 00776/03080] [00:09:38/00:28:36, 0.745s/it]: train_loss_raw=1.0480, running_loss=1.0851, LR=0.000100
[2025-08-27 03:28:50,745][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031584] [Batch 00784/03080] [00:09:44/00:28:30, 0.745s/it]: train_loss_raw=1.1124, running_loss=1.0840, LR=0.000100
[2025-08-27 03:28:56,667][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031592] [Batch 00792/03080] [00:09:50/00:28:24, 0.745s/it]: train_loss_raw=1.0170, running_loss=1.0809, LR=0.000100
[2025-08-27 03:29:02,470][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031600] [Batch 00800/03080] [00:09:55/00:28:18, 0.745s/it]: train_loss_raw=1.0034, running_loss=1.0828, LR=0.000100
[2025-08-27 03:29:08,373][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031608] [Batch 00808/03080] [00:10:01/00:28:12, 0.745s/it]: train_loss_raw=1.0076, running_loss=1.0842, LR=0.000100
[2025-08-27 03:29:14,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031616] [Batch 00816/03080] [00:10:07/00:28:06, 0.745s/it]: train_loss_raw=0.9803, running_loss=1.0816, LR=0.000100
[2025-08-27 03:29:20,308][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031624] [Batch 00824/03080] [00:10:13/00:28:00, 0.745s/it]: train_loss_raw=1.0757, running_loss=1.0824, LR=0.000100
[2025-08-27 03:29:26,271][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031632] [Batch 00832/03080] [00:10:19/00:27:54, 0.745s/it]: train_loss_raw=1.1304, running_loss=1.0830, LR=0.000100
[2025-08-27 03:29:32,179][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031640] [Batch 00840/03080] [00:10:25/00:27:48, 0.745s/it]: train_loss_raw=1.0339, running_loss=1.0819, LR=0.000100
[2025-08-27 03:29:38,322][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031648] [Batch 00848/03080] [00:10:31/00:27:42, 0.745s/it]: train_loss_raw=1.1529, running_loss=1.0832, LR=0.000100
[2025-08-27 03:29:44,279][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031656] [Batch 00856/03080] [00:10:37/00:27:36, 0.745s/it]: train_loss_raw=1.0858, running_loss=1.0847, LR=0.000100
[2025-08-27 03:29:50,219][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031664] [Batch 00864/03080] [00:10:43/00:27:30, 0.745s/it]: train_loss_raw=1.1828, running_loss=1.0851, LR=0.000100
[2025-08-27 03:29:56,185][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031672] [Batch 00872/03080] [00:10:49/00:27:24, 0.745s/it]: train_loss_raw=0.9360, running_loss=1.0830, LR=0.000100
[2025-08-27 03:30:02,151][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031680] [Batch 00880/03080] [00:10:55/00:27:18, 0.745s/it]: train_loss_raw=1.0578, running_loss=1.0829, LR=0.000100
[2025-08-27 03:30:07,885][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031688] [Batch 00888/03080] [00:11:01/00:27:12, 0.745s/it]: train_loss_raw=1.0997, running_loss=1.0795, LR=0.000100
[2025-08-27 03:30:13,712][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031696] [Batch 00896/03080] [00:11:07/00:27:06, 0.745s/it]: train_loss_raw=1.0051, running_loss=1.0811, LR=0.000100
[2025-08-27 03:30:19,696][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031704] [Batch 00904/03080] [00:11:13/00:27:00, 0.745s/it]: train_loss_raw=1.0387, running_loss=1.0792, LR=0.000100
[2025-08-27 03:30:25,533][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031712] [Batch 00912/03080] [00:11:18/00:26:53, 0.744s/it]: train_loss_raw=1.2014, running_loss=1.0799, LR=0.000100
[2025-08-27 03:30:31,415][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031720] [Batch 00920/03080] [00:11:24/00:26:47, 0.744s/it]: train_loss_raw=1.1053, running_loss=1.0795, LR=0.000100
[2025-08-27 03:30:37,314][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031728] [Batch 00928/03080] [00:11:30/00:26:41, 0.744s/it]: train_loss_raw=1.0014, running_loss=1.0794, LR=0.000100
[2025-08-27 03:30:43,274][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031736] [Batch 00936/03080] [00:11:36/00:26:35, 0.744s/it]: train_loss_raw=1.0224, running_loss=1.0773, LR=0.000100
[2025-08-27 03:30:49,138][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031744] [Batch 00944/03080] [00:11:42/00:26:29, 0.744s/it]: train_loss_raw=1.0242, running_loss=1.0770, LR=0.000100
[2025-08-27 03:30:54,933][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031752] [Batch 00952/03080] [00:11:48/00:26:23, 0.744s/it]: train_loss_raw=1.1034, running_loss=1.0786, LR=0.000100
[2025-08-27 03:31:00,843][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031760] [Batch 00960/03080] [00:11:54/00:26:17, 0.744s/it]: train_loss_raw=0.9793, running_loss=1.0819, LR=0.000100
[2025-08-27 03:31:06,618][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031768] [Batch 00968/03080] [00:12:00/00:26:10, 0.744s/it]: train_loss_raw=1.1566, running_loss=1.0831, LR=0.000100
[2025-08-27 03:31:12,426][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031776] [Batch 00976/03080] [00:12:05/00:26:04, 0.744s/it]: train_loss_raw=1.0722, running_loss=1.0840, LR=0.000100
[2025-08-27 03:31:18,424][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031784] [Batch 00984/03080] [00:12:11/00:25:58, 0.744s/it]: train_loss_raw=1.1116, running_loss=1.0846, LR=0.000100
[2025-08-27 03:31:24,268][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031792] [Batch 00992/03080] [00:12:17/00:25:52, 0.744s/it]: train_loss_raw=1.1358, running_loss=1.0859, LR=0.000100
[2025-08-27 03:31:30,287][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031800] [Batch 01000/03080] [00:12:23/00:25:46, 0.744s/it]: train_loss_raw=1.0260, running_loss=1.0840, LR=0.000100
[2025-08-27 03:31:36,140][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031808] [Batch 01008/03080] [00:12:29/00:25:40, 0.744s/it]: train_loss_raw=1.0288, running_loss=1.0840, LR=0.000100
[2025-08-27 03:31:41,992][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031816] [Batch 01016/03080] [00:12:35/00:25:34, 0.743s/it]: train_loss_raw=1.0073, running_loss=1.0790, LR=0.000100
[2025-08-27 03:31:47,984][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031824] [Batch 01024/03080] [00:12:41/00:25:28, 0.744s/it]: train_loss_raw=1.1140, running_loss=1.0775, LR=0.000100
[2025-08-27 03:31:54,005][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031832] [Batch 01032/03080] [00:12:47/00:25:22, 0.744s/it]: train_loss_raw=1.0962, running_loss=1.0764, LR=0.000100
[2025-08-27 03:31:59,952][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031840] [Batch 01040/03080] [00:12:53/00:25:16, 0.744s/it]: train_loss_raw=1.0476, running_loss=1.0752, LR=0.000100
[2025-08-27 03:32:05,846][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031848] [Batch 01048/03080] [00:12:59/00:25:10, 0.744s/it]: train_loss_raw=1.0496, running_loss=1.0754, LR=0.000100
[2025-08-27 03:32:11,631][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031856] [Batch 01056/03080] [00:13:05/00:25:04, 0.743s/it]: train_loss_raw=1.1533, running_loss=1.0773, LR=0.000100
[2025-08-27 03:32:17,556][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031864] [Batch 01064/03080] [00:13:10/00:24:58, 0.743s/it]: train_loss_raw=1.1015, running_loss=1.0754, LR=0.000100
[2025-08-27 03:32:23,359][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031872] [Batch 01072/03080] [00:13:16/00:24:52, 0.743s/it]: train_loss_raw=0.9793, running_loss=1.0766, LR=0.000100
[2025-08-27 03:32:29,097][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031880] [Batch 01080/03080] [00:13:22/00:24:46, 0.743s/it]: train_loss_raw=1.1728, running_loss=1.0758, LR=0.000100
[2025-08-27 03:32:34,957][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031888] [Batch 01088/03080] [00:13:28/00:24:39, 0.743s/it]: train_loss_raw=1.0694, running_loss=1.0733, LR=0.000100
[2025-08-27 03:32:40,899][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031896] [Batch 01096/03080] [00:13:34/00:24:34, 0.743s/it]: train_loss_raw=1.0279, running_loss=1.0734, LR=0.000100
[2025-08-27 03:32:46,798][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031904] [Batch 01104/03080] [00:13:40/00:24:28, 0.743s/it]: train_loss_raw=1.1255, running_loss=1.0760, LR=0.000100
[2025-08-27 03:32:52,778][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031912] [Batch 01112/03080] [00:13:46/00:24:22, 0.743s/it]: train_loss_raw=1.0855, running_loss=1.0774, LR=0.000100
[2025-08-27 03:32:58,646][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031920] [Batch 01120/03080] [00:13:52/00:24:16, 0.743s/it]: train_loss_raw=1.1655, running_loss=1.0827, LR=0.000100
[2025-08-27 03:33:04,574][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031928] [Batch 01128/03080] [00:13:57/00:24:10, 0.743s/it]: train_loss_raw=1.0226, running_loss=1.0821, LR=0.000100
[2025-08-27 03:33:10,378][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031936] [Batch 01136/03080] [00:14:03/00:24:03, 0.743s/it]: train_loss_raw=1.1232, running_loss=1.0829, LR=0.000100
[2025-08-27 03:33:16,276][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031944] [Batch 01144/03080] [00:14:09/00:23:57, 0.743s/it]: train_loss_raw=1.1902, running_loss=1.0823, LR=0.000100
[2025-08-27 03:33:22,296][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031952] [Batch 01152/03080] [00:14:15/00:23:52, 0.743s/it]: train_loss_raw=1.1040, running_loss=1.0797, LR=0.000100
[2025-08-27 03:33:28,239][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031960] [Batch 01160/03080] [00:14:21/00:23:46, 0.743s/it]: train_loss_raw=0.8822, running_loss=1.0746, LR=0.000100
[2025-08-27 03:33:34,156][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031968] [Batch 01168/03080] [00:14:27/00:23:40, 0.743s/it]: train_loss_raw=1.1288, running_loss=1.0733, LR=0.000100
[2025-08-27 03:33:40,104][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031976] [Batch 01176/03080] [00:14:33/00:23:34, 0.743s/it]: train_loss_raw=1.1399, running_loss=1.0748, LR=0.000100
[2025-08-27 03:33:45,984][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031984] [Batch 01184/03080] [00:14:39/00:23:28, 0.743s/it]: train_loss_raw=1.0781, running_loss=1.0755, LR=0.000100
[2025-08-27 03:33:51,968][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031992] [Batch 01192/03080] [00:14:45/00:23:22, 0.743s/it]: train_loss_raw=1.0488, running_loss=1.0741, LR=0.000100
[2025-08-27 03:33:57,986][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032000] [Batch 01200/03080] [00:14:51/00:23:16, 0.743s/it]: train_loss_raw=1.1276, running_loss=1.0733, LR=0.000100
[2025-08-27 03:34:07,814][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032008] [Batch 01208/03080] [00:15:01/00:23:16, 0.746s/it]: train_loss_raw=1.1085, running_loss=1.0753, LR=0.000100
[2025-08-27 03:34:13,617][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032016] [Batch 01216/03080] [00:15:07/00:23:10, 0.746s/it]: train_loss_raw=1.1088, running_loss=1.0738, LR=0.000100
[2025-08-27 03:34:19,550][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032024] [Batch 01224/03080] [00:15:12/00:23:04, 0.746s/it]: train_loss_raw=1.0640, running_loss=1.0728, LR=0.000100
[2025-08-27 03:34:25,441][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032032] [Batch 01232/03080] [00:15:18/00:22:58, 0.746s/it]: train_loss_raw=1.0328, running_loss=1.0730, LR=0.000100
[2025-08-27 03:34:31,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032040] [Batch 01240/03080] [00:15:24/00:22:52, 0.746s/it]: train_loss_raw=1.0144, running_loss=1.0732, LR=0.000100
[2025-08-27 03:34:37,244][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032048] [Batch 01248/03080] [00:15:30/00:22:46, 0.746s/it]: train_loss_raw=1.1437, running_loss=1.0719, LR=0.000100
[2025-08-27 03:34:43,151][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032056] [Batch 01256/03080] [00:15:36/00:22:40, 0.746s/it]: train_loss_raw=1.0505, running_loss=1.0727, LR=0.000100
[2025-08-27 03:34:49,048][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032064] [Batch 01264/03080] [00:15:42/00:22:34, 0.746s/it]: train_loss_raw=1.0924, running_loss=1.0692, LR=0.000100
[2025-08-27 03:34:54,866][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032072] [Batch 01272/03080] [00:15:48/00:22:27, 0.745s/it]: train_loss_raw=1.1373, running_loss=1.0688, LR=0.000100
[2025-08-27 03:35:00,779][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032080] [Batch 01280/03080] [00:15:54/00:22:21, 0.745s/it]: train_loss_raw=1.1062, running_loss=1.0699, LR=0.000100
[2025-08-27 03:35:06,662][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032088] [Batch 01288/03080] [00:16:00/00:22:15, 0.745s/it]: train_loss_raw=0.9977, running_loss=1.0671, LR=0.000100
[2025-08-27 03:35:12,513][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032096] [Batch 01296/03080] [00:16:05/00:22:09, 0.745s/it]: train_loss_raw=1.0710, running_loss=1.0659, LR=0.000100
[2025-08-27 03:35:18,293][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032104] [Batch 01304/03080] [00:16:11/00:22:03, 0.745s/it]: train_loss_raw=0.8744, running_loss=1.0659, LR=0.000100
[2025-08-27 03:35:24,277][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032112] [Batch 01312/03080] [00:16:17/00:21:57, 0.745s/it]: train_loss_raw=1.0677, running_loss=1.0675, LR=0.000100
[2025-08-27 03:35:30,296][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032120] [Batch 01320/03080] [00:16:23/00:21:51, 0.745s/it]: train_loss_raw=1.0754, running_loss=1.0703, LR=0.000100
[2025-08-27 03:35:36,226][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032128] [Batch 01328/03080] [00:16:29/00:21:45, 0.745s/it]: train_loss_raw=1.1632, running_loss=1.0693, LR=0.000100
[2025-08-27 03:35:42,112][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032136] [Batch 01336/03080] [00:16:35/00:21:39, 0.745s/it]: train_loss_raw=1.0530, running_loss=1.0677, LR=0.000100
[2025-08-27 03:35:47,927][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032144] [Batch 01344/03080] [00:16:41/00:21:33, 0.745s/it]: train_loss_raw=1.0562, running_loss=1.0671, LR=0.000100
[2025-08-27 03:35:53,647][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032152] [Batch 01352/03080] [00:16:47/00:21:27, 0.745s/it]: train_loss_raw=1.1463, running_loss=1.0683, LR=0.000100
[2025-08-27 03:35:59,440][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032160] [Batch 01360/03080] [00:16:52/00:21:20, 0.745s/it]: train_loss_raw=1.0322, running_loss=1.0703, LR=0.000100
[2025-08-27 03:36:05,235][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032168] [Batch 01368/03080] [00:16:58/00:21:14, 0.745s/it]: train_loss_raw=1.0790, running_loss=1.0687, LR=0.000100
[2025-08-27 03:36:11,008][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032176] [Batch 01376/03080] [00:17:04/00:21:08, 0.744s/it]: train_loss_raw=1.2068, running_loss=1.0677, LR=0.000100
[2025-08-27 03:36:16,843][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032184] [Batch 01384/03080] [00:17:10/00:21:02, 0.744s/it]: train_loss_raw=1.0649, running_loss=1.0697, LR=0.000100
[2025-08-27 03:36:22,862][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032192] [Batch 01392/03080] [00:17:16/00:20:56, 0.744s/it]: train_loss_raw=1.1234, running_loss=1.0702, LR=0.000100
[2025-08-27 03:36:28,777][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032200] [Batch 01400/03080] [00:17:22/00:20:50, 0.744s/it]: train_loss_raw=1.1029, running_loss=1.0718, LR=0.000100
[2025-08-27 03:36:34,635][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032208] [Batch 01408/03080] [00:17:28/00:20:44, 0.744s/it]: train_loss_raw=1.0786, running_loss=1.0701, LR=0.000100
[2025-08-27 03:36:40,437][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032216] [Batch 01416/03080] [00:17:33/00:20:38, 0.744s/it]: train_loss_raw=1.0121, running_loss=1.0686, LR=0.000100
[2025-08-27 03:36:46,324][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032224] [Batch 01424/03080] [00:17:39/00:20:32, 0.744s/it]: train_loss_raw=1.1498, running_loss=1.0697, LR=0.000100
[2025-08-27 03:36:52,094][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032232] [Batch 01432/03080] [00:17:45/00:20:26, 0.744s/it]: train_loss_raw=1.0909, running_loss=1.0685, LR=0.000100
[2025-08-27 03:36:57,867][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032240] [Batch 01440/03080] [00:17:51/00:20:20, 0.744s/it]: train_loss_raw=1.0143, running_loss=1.0682, LR=0.000100
[2025-08-27 03:37:03,621][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032248] [Batch 01448/03080] [00:17:57/00:20:13, 0.744s/it]: train_loss_raw=0.9210, running_loss=1.0708, LR=0.000100
[2025-08-27 03:37:09,364][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032256] [Batch 01456/03080] [00:18:02/00:20:07, 0.744s/it]: train_loss_raw=1.1397, running_loss=1.0702, LR=0.000100
[2025-08-27 03:37:15,352][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032264] [Batch 01464/03080] [00:18:08/00:20:01, 0.744s/it]: train_loss_raw=0.9539, running_loss=1.0684, LR=0.000100
[2025-08-27 03:37:21,326][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032272] [Batch 01472/03080] [00:18:14/00:19:55, 0.744s/it]: train_loss_raw=1.1425, running_loss=1.0699, LR=0.000100
[2025-08-27 03:37:27,157][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032280] [Batch 01480/03080] [00:18:20/00:19:49, 0.744s/it]: train_loss_raw=1.1596, running_loss=1.0721, LR=0.000100
[2025-08-27 03:37:33,037][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032288] [Batch 01488/03080] [00:18:26/00:19:43, 0.744s/it]: train_loss_raw=1.0685, running_loss=1.0730, LR=0.000100
[2025-08-27 03:37:38,936][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032296] [Batch 01496/03080] [00:18:32/00:19:37, 0.744s/it]: train_loss_raw=1.1435, running_loss=1.0707, LR=0.000100
[2025-08-27 03:37:44,724][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032304] [Batch 01504/03080] [00:18:38/00:19:31, 0.743s/it]: train_loss_raw=1.1015, running_loss=1.0701, LR=0.000100
[2025-08-27 03:37:50,483][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032312] [Batch 01512/03080] [00:18:43/00:19:25, 0.743s/it]: train_loss_raw=1.0875, running_loss=1.0720, LR=0.000100
[2025-08-27 03:37:56,403][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032320] [Batch 01520/03080] [00:18:49/00:19:19, 0.743s/it]: train_loss_raw=1.0905, running_loss=1.0728, LR=0.000100
[2025-08-27 03:38:02,269][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032328] [Batch 01528/03080] [00:18:55/00:19:13, 0.743s/it]: train_loss_raw=1.0485, running_loss=1.0736, LR=0.000100
[2025-08-27 03:38:08,251][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032336] [Batch 01536/03080] [00:19:01/00:19:07, 0.743s/it]: train_loss_raw=1.1520, running_loss=1.0716, LR=0.000100
[2025-08-27 03:38:14,175][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032344] [Batch 01544/03080] [00:19:07/00:19:01, 0.743s/it]: train_loss_raw=1.0598, running_loss=1.0700, LR=0.000100
[2025-08-27 03:38:20,186][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032352] [Batch 01552/03080] [00:19:13/00:18:55, 0.743s/it]: train_loss_raw=1.0784, running_loss=1.0677, LR=0.000100
[2025-08-27 03:38:26,247][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032360] [Batch 01560/03080] [00:19:19/00:18:49, 0.743s/it]: train_loss_raw=1.0020, running_loss=1.0652, LR=0.000100
[2025-08-27 03:38:32,171][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032368] [Batch 01568/03080] [00:19:25/00:18:43, 0.743s/it]: train_loss_raw=1.0649, running_loss=1.0644, LR=0.000100
[2025-08-27 03:38:38,095][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032376] [Batch 01576/03080] [00:19:31/00:18:37, 0.743s/it]: train_loss_raw=1.0044, running_loss=1.0644, LR=0.000100
[2025-08-27 03:38:43,960][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032384] [Batch 01584/03080] [00:19:37/00:18:31, 0.743s/it]: train_loss_raw=0.9919, running_loss=1.0641, LR=0.000100
[2025-08-27 03:38:49,900][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032392] [Batch 01592/03080] [00:19:43/00:18:25, 0.743s/it]: train_loss_raw=1.0752, running_loss=1.0651, LR=0.000100
[2025-08-27 03:38:55,947][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032400] [Batch 01600/03080] [00:19:49/00:18:20, 0.743s/it]: train_loss_raw=1.0945, running_loss=1.0639, LR=0.000100
[2025-08-27 03:39:01,689][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032408] [Batch 01608/03080] [00:19:55/00:18:13, 0.743s/it]: train_loss_raw=1.1154, running_loss=1.0649, LR=0.000100
[2025-08-27 03:39:07,642][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032416] [Batch 01616/03080] [00:20:01/00:18:08, 0.743s/it]: train_loss_raw=0.9757, running_loss=1.0646, LR=0.000100
[2025-08-27 03:39:13,588][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032424] [Batch 01624/03080] [00:20:06/00:18:02, 0.743s/it]: train_loss_raw=1.1560, running_loss=1.0660, LR=0.000100
[2025-08-27 03:39:19,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032432] [Batch 01632/03080] [00:20:12/00:17:56, 0.743s/it]: train_loss_raw=1.1887, running_loss=1.0675, LR=0.000100
[2025-08-27 03:39:25,272][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032440] [Batch 01640/03080] [00:20:18/00:17:50, 0.743s/it]: train_loss_raw=1.1259, running_loss=1.0667, LR=0.000100
[2025-08-27 03:39:31,256][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032448] [Batch 01648/03080] [00:20:24/00:17:44, 0.743s/it]: train_loss_raw=1.1172, running_loss=1.0672, LR=0.000100
[2025-08-27 03:39:37,216][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032456] [Batch 01656/03080] [00:20:30/00:17:38, 0.743s/it]: train_loss_raw=0.9586, running_loss=1.0653, LR=0.000100
[2025-08-27 03:39:43,122][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032464] [Batch 01664/03080] [00:20:36/00:17:32, 0.743s/it]: train_loss_raw=1.1404, running_loss=1.0654, LR=0.000100
[2025-08-27 03:39:49,084][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032472] [Batch 01672/03080] [00:20:42/00:17:26, 0.743s/it]: train_loss_raw=1.0674, running_loss=1.0637, LR=0.000100
[2025-08-27 03:39:55,649][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032480] [Batch 01680/03080] [00:20:49/00:17:20, 0.743s/it]: train_loss_raw=1.0548, running_loss=1.0627, LR=0.000100
[2025-08-27 03:40:01,659][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032488] [Batch 01688/03080] [00:20:55/00:17:14, 0.744s/it]: train_loss_raw=1.0748, running_loss=1.0652, LR=0.000100
[2025-08-27 03:40:07,774][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032496] [Batch 01696/03080] [00:21:01/00:17:09, 0.744s/it]: train_loss_raw=1.0731, running_loss=1.0649, LR=0.000100
[2025-08-27 03:40:13,714][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032504] [Batch 01704/03080] [00:21:07/00:17:03, 0.744s/it]: train_loss_raw=0.9687, running_loss=1.0641, LR=0.000100
[2025-08-27 03:40:19,644][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032512] [Batch 01712/03080] [00:21:13/00:16:57, 0.744s/it]: train_loss_raw=1.1015, running_loss=1.0670, LR=0.000100
[2025-08-27 03:40:25,513][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032520] [Batch 01720/03080] [00:21:18/00:16:51, 0.744s/it]: train_loss_raw=1.1262, running_loss=1.0687, LR=0.000100
[2025-08-27 03:40:31,401][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032528] [Batch 01728/03080] [00:21:24/00:16:45, 0.744s/it]: train_loss_raw=1.0967, running_loss=1.0667, LR=0.000100
[2025-08-27 03:40:37,387][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032536] [Batch 01736/03080] [00:21:30/00:16:39, 0.744s/it]: train_loss_raw=1.1015, running_loss=1.0679, LR=0.000100
[2025-08-27 03:40:43,379][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032544] [Batch 01744/03080] [00:21:36/00:16:33, 0.744s/it]: train_loss_raw=1.0259, running_loss=1.0646, LR=0.000100
[2025-08-27 03:40:49,452][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032552] [Batch 01752/03080] [00:21:42/00:16:27, 0.744s/it]: train_loss_raw=1.0707, running_loss=1.0629, LR=0.000100
[2025-08-27 03:40:55,169][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032560] [Batch 01760/03080] [00:21:48/00:16:21, 0.743s/it]: train_loss_raw=1.0117, running_loss=1.0613, LR=0.000100
[2025-08-27 03:41:01,092][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032568] [Batch 01768/03080] [00:21:54/00:16:15, 0.743s/it]: train_loss_raw=1.0500, running_loss=1.0606, LR=0.000100
[2025-08-27 03:41:07,002][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032576] [Batch 01776/03080] [00:22:00/00:16:09, 0.743s/it]: train_loss_raw=1.1141, running_loss=1.0598, LR=0.000100
[2025-08-27 03:41:12,932][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032584] [Batch 01784/03080] [00:22:06/00:16:03, 0.743s/it]: train_loss_raw=1.0963, running_loss=1.0612, LR=0.000100
[2025-08-27 03:41:18,908][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032592] [Batch 01792/03080] [00:22:12/00:15:57, 0.743s/it]: train_loss_raw=1.0296, running_loss=1.0583, LR=0.000100
[2025-08-27 03:41:24,877][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032600] [Batch 01800/03080] [00:22:18/00:15:51, 0.743s/it]: train_loss_raw=1.1113, running_loss=1.0583, LR=0.000100
[2025-08-27 03:41:30,858][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032608] [Batch 01808/03080] [00:22:24/00:15:45, 0.743s/it]: train_loss_raw=0.8719, running_loss=1.0551, LR=0.000100
[2025-08-27 03:41:36,726][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032616] [Batch 01816/03080] [00:22:30/00:15:39, 0.743s/it]: train_loss_raw=1.0785, running_loss=1.0567, LR=0.000100
[2025-08-27 03:41:42,664][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032624] [Batch 01824/03080] [00:22:36/00:15:33, 0.743s/it]: train_loss_raw=1.0797, running_loss=1.0617, LR=0.000100
[2025-08-27 03:41:48,704][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032632] [Batch 01832/03080] [00:22:42/00:15:27, 0.743s/it]: train_loss_raw=1.0886, running_loss=1.0617, LR=0.000100
[2025-08-27 03:41:54,717][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032640] [Batch 01840/03080] [00:22:48/00:15:21, 0.744s/it]: train_loss_raw=1.1124, running_loss=1.0629, LR=0.000100
[2025-08-27 03:42:00,745][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032648] [Batch 01848/03080] [00:22:54/00:15:16, 0.744s/it]: train_loss_raw=1.0735, running_loss=1.0640, LR=0.000100
[2025-08-27 03:42:06,823][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032656] [Batch 01856/03080] [00:23:00/00:15:10, 0.744s/it]: train_loss_raw=1.1137, running_loss=1.0628, LR=0.000100
[2025-08-27 03:42:12,832][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032664] [Batch 01864/03080] [00:23:06/00:15:04, 0.744s/it]: train_loss_raw=1.0912, running_loss=1.0635, LR=0.000100
[2025-08-27 03:42:18,710][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032672] [Batch 01872/03080] [00:23:12/00:14:58, 0.744s/it]: train_loss_raw=1.0494, running_loss=1.0612, LR=0.000100
[2025-08-27 03:42:24,627][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032680] [Batch 01880/03080] [00:23:18/00:14:52, 0.744s/it]: train_loss_raw=1.0531, running_loss=1.0585, LR=0.000100
[2025-08-27 03:42:30,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032688] [Batch 01888/03080] [00:23:24/00:14:46, 0.744s/it]: train_loss_raw=1.0761, running_loss=1.0583, LR=0.000100
[2025-08-27 03:42:36,661][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032696] [Batch 01896/03080] [00:23:30/00:14:40, 0.744s/it]: train_loss_raw=1.0548, running_loss=1.0600, LR=0.000100
[2025-08-27 03:42:42,548][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032704] [Batch 01904/03080] [00:23:35/00:14:34, 0.744s/it]: train_loss_raw=1.1060, running_loss=1.0625, LR=0.000100
[2025-08-27 03:42:48,523][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032712] [Batch 01912/03080] [00:23:41/00:14:28, 0.744s/it]: train_loss_raw=1.1097, running_loss=1.0632, LR=0.000100
[2025-08-27 03:42:54,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032720] [Batch 01920/03080] [00:23:47/00:14:22, 0.744s/it]: train_loss_raw=1.0195, running_loss=1.0596, LR=0.000100
[2025-08-27 03:43:00,434][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032728] [Batch 01928/03080] [00:23:53/00:14:16, 0.744s/it]: train_loss_raw=1.0452, running_loss=1.0610, LR=0.000100
[2025-08-27 03:43:06,387][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032736] [Batch 01936/03080] [00:23:59/00:14:10, 0.744s/it]: train_loss_raw=1.0422, running_loss=1.0614, LR=0.000100
[2025-08-27 03:43:12,264][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032744] [Batch 01944/03080] [00:24:05/00:14:04, 0.744s/it]: train_loss_raw=1.0403, running_loss=1.0628, LR=0.000100
[2025-08-27 03:43:18,209][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032752] [Batch 01952/03080] [00:24:11/00:13:58, 0.744s/it]: train_loss_raw=1.0684, running_loss=1.0593, LR=0.000100
[2025-08-27 03:43:24,186][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032760] [Batch 01960/03080] [00:24:17/00:13:52, 0.744s/it]: train_loss_raw=1.0820, running_loss=1.0609, LR=0.000100
[2025-08-27 03:43:30,137][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032768] [Batch 01968/03080] [00:24:23/00:13:46, 0.744s/it]: train_loss_raw=1.0509, running_loss=1.0587, LR=0.000100
[2025-08-27 03:43:36,234][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032776] [Batch 01976/03080] [00:24:29/00:13:41, 0.744s/it]: train_loss_raw=0.9710, running_loss=1.0575, LR=0.000100
[2025-08-27 03:43:41,972][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032784] [Batch 01984/03080] [00:24:35/00:13:35, 0.744s/it]: train_loss_raw=1.0854, running_loss=1.0581, LR=0.000100
[2025-08-27 03:43:47,849][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032792] [Batch 01992/03080] [00:24:41/00:13:29, 0.744s/it]: train_loss_raw=1.0239, running_loss=1.0561, LR=0.000100
[2025-08-27 03:43:53,751][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032800] [Batch 02000/03080] [00:24:47/00:13:23, 0.744s/it]: train_loss_raw=1.2089, running_loss=1.0587, LR=0.000100
[2025-08-27 03:43:59,655][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032808] [Batch 02008/03080] [00:24:53/00:13:17, 0.744s/it]: train_loss_raw=1.0131, running_loss=1.0568, LR=0.000100
[2025-08-27 03:44:05,489][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032816] [Batch 02016/03080] [00:24:58/00:13:11, 0.743s/it]: train_loss_raw=1.0837, running_loss=1.0551, LR=0.000100
[2025-08-27 03:44:11,415][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032824] [Batch 02024/03080] [00:25:04/00:13:05, 0.743s/it]: train_loss_raw=0.9279, running_loss=1.0539, LR=0.000100
[2025-08-27 03:44:17,371][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032832] [Batch 02032/03080] [00:25:10/00:12:59, 0.743s/it]: train_loss_raw=0.9034, running_loss=1.0511, LR=0.000100
[2025-08-27 03:44:23,296][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032840] [Batch 02040/03080] [00:25:16/00:12:53, 0.743s/it]: train_loss_raw=1.0795, running_loss=1.0491, LR=0.000100
[2025-08-27 03:44:29,179][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032848] [Batch 02048/03080] [00:25:22/00:12:47, 0.743s/it]: train_loss_raw=0.9759, running_loss=1.0496, LR=0.000100
[2025-08-27 03:44:35,113][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032856] [Batch 02056/03080] [00:25:28/00:12:41, 0.743s/it]: train_loss_raw=1.1228, running_loss=1.0510, LR=0.000100
[2025-08-27 03:44:41,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032864] [Batch 02064/03080] [00:25:34/00:12:35, 0.743s/it]: train_loss_raw=0.9608, running_loss=1.0497, LR=0.000100
[2025-08-27 03:44:46,943][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032872] [Batch 02072/03080] [00:25:40/00:12:29, 0.743s/it]: train_loss_raw=1.0434, running_loss=1.0484, LR=0.000100
[2025-08-27 03:44:52,971][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032880] [Batch 02080/03080] [00:25:46/00:12:23, 0.743s/it]: train_loss_raw=1.0205, running_loss=1.0488, LR=0.000100
[2025-08-27 03:44:58,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032888] [Batch 02088/03080] [00:25:52/00:12:17, 0.743s/it]: train_loss_raw=0.9624, running_loss=1.0456, LR=0.000100
[2025-08-27 03:45:04,914][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032896] [Batch 02096/03080] [00:25:58/00:12:11, 0.743s/it]: train_loss_raw=1.0424, running_loss=1.0435, LR=0.000100
[2025-08-27 03:45:10,852][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032904] [Batch 02104/03080] [00:26:04/00:12:05, 0.743s/it]: train_loss_raw=1.0558, running_loss=1.0443, LR=0.000100
[2025-08-27 03:45:16,695][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032912] [Batch 02112/03080] [00:26:10/00:11:59, 0.743s/it]: train_loss_raw=1.0548, running_loss=1.0467, LR=0.000100
[2025-08-27 03:45:22,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032920] [Batch 02120/03080] [00:26:16/00:11:53, 0.743s/it]: train_loss_raw=1.0805, running_loss=1.0472, LR=0.000100
[2025-08-27 03:45:28,606][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032928] [Batch 02128/03080] [00:26:21/00:11:47, 0.743s/it]: train_loss_raw=1.0864, running_loss=1.0474, LR=0.000100
[2025-08-27 03:45:34,724][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032936] [Batch 02136/03080] [00:26:28/00:11:41, 0.743s/it]: train_loss_raw=1.1749, running_loss=1.0474, LR=0.000100
[2025-08-27 03:45:40,683][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032944] [Batch 02144/03080] [00:26:34/00:11:35, 0.744s/it]: train_loss_raw=0.9514, running_loss=1.0442, LR=0.000100
[2025-08-27 03:45:46,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032952] [Batch 02152/03080] [00:26:40/00:11:30, 0.744s/it]: train_loss_raw=1.1091, running_loss=1.0459, LR=0.000100
[2025-08-27 03:45:52,833][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032960] [Batch 02160/03080] [00:26:46/00:11:24, 0.744s/it]: train_loss_raw=1.1690, running_loss=1.0476, LR=0.000100
[2025-08-27 03:45:58,824][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032968] [Batch 02168/03080] [00:26:52/00:11:18, 0.744s/it]: train_loss_raw=1.0409, running_loss=1.0492, LR=0.000100
[2025-08-27 03:46:04,748][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032976] [Batch 02176/03080] [00:26:58/00:11:12, 0.744s/it]: train_loss_raw=0.9522, running_loss=1.0502, LR=0.000100
[2025-08-27 03:46:10,598][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032984] [Batch 02184/03080] [00:27:03/00:11:06, 0.744s/it]: train_loss_raw=1.0616, running_loss=1.0493, LR=0.000100
[2025-08-27 03:46:16,604][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032992] [Batch 02192/03080] [00:27:09/00:11:00, 0.744s/it]: train_loss_raw=1.0463, running_loss=1.0528, LR=0.000100
[2025-08-27 03:46:22,600][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033000] [Batch 02200/03080] [00:27:15/00:10:54, 0.744s/it]: train_loss_raw=1.0848, running_loss=1.0544, LR=0.000100
[2025-08-27 03:46:28,546][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033008] [Batch 02208/03080] [00:27:21/00:10:48, 0.744s/it]: train_loss_raw=1.1386, running_loss=1.0543, LR=0.000100
[2025-08-27 03:46:34,543][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033016] [Batch 02216/03080] [00:27:27/00:10:42, 0.744s/it]: train_loss_raw=1.0639, running_loss=1.0510, LR=0.000100
[2025-08-27 03:46:40,533][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033024] [Batch 02224/03080] [00:27:33/00:10:36, 0.744s/it]: train_loss_raw=1.0432, running_loss=1.0515, LR=0.000100
[2025-08-27 03:46:46,444][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033032] [Batch 02232/03080] [00:27:39/00:10:30, 0.744s/it]: train_loss_raw=1.0234, running_loss=1.0504, LR=0.000100
[2025-08-27 03:46:52,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033040] [Batch 02240/03080] [00:27:45/00:10:24, 0.744s/it]: train_loss_raw=1.1041, running_loss=1.0502, LR=0.000100
[2025-08-27 03:46:58,297][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033048] [Batch 02248/03080] [00:27:51/00:10:18, 0.744s/it]: train_loss_raw=0.9631, running_loss=1.0475, LR=0.000100
[2025-08-27 03:47:04,108][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033056] [Batch 02256/03080] [00:27:57/00:10:12, 0.744s/it]: train_loss_raw=1.0744, running_loss=1.0478, LR=0.000100
[2025-08-27 03:47:09,890][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033064] [Batch 02264/03080] [00:28:03/00:10:06, 0.743s/it]: train_loss_raw=1.0597, running_loss=1.0473, LR=0.000100
[2025-08-27 03:47:15,861][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033072] [Batch 02272/03080] [00:28:09/00:10:00, 0.744s/it]: train_loss_raw=1.0857, running_loss=1.0478, LR=0.000100
[2025-08-27 03:47:21,834][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033080] [Batch 02280/03080] [00:28:15/00:09:54, 0.744s/it]: train_loss_raw=1.0890, running_loss=1.0505, LR=0.000100
[2025-08-27 03:47:27,712][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033088] [Batch 02288/03080] [00:28:21/00:09:48, 0.743s/it]: train_loss_raw=1.0419, running_loss=1.0510, LR=0.000100
[2025-08-27 03:47:33,731][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033096] [Batch 02296/03080] [00:28:27/00:09:42, 0.744s/it]: train_loss_raw=1.0855, running_loss=1.0503, LR=0.000100
[2025-08-27 03:47:39,576][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033104] [Batch 02304/03080] [00:28:32/00:09:36, 0.743s/it]: train_loss_raw=1.1463, running_loss=1.0523, LR=0.000100
[2025-08-27 03:47:45,318][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033112] [Batch 02312/03080] [00:28:38/00:09:30, 0.743s/it]: train_loss_raw=1.1231, running_loss=1.0544, LR=0.000100
[2025-08-27 03:47:51,125][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033120] [Batch 02320/03080] [00:28:44/00:09:24, 0.743s/it]: train_loss_raw=0.9871, running_loss=1.0537, LR=0.000100
[2025-08-27 03:47:56,937][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033128] [Batch 02328/03080] [00:28:50/00:09:18, 0.743s/it]: train_loss_raw=1.0122, running_loss=1.0525, LR=0.000100
[2025-08-27 03:48:03,140][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033136] [Batch 02336/03080] [00:28:56/00:09:13, 0.743s/it]: train_loss_raw=1.1067, running_loss=1.0534, LR=0.000100
[2025-08-27 03:48:09,275][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033144] [Batch 02344/03080] [00:29:02/00:09:07, 0.743s/it]: train_loss_raw=1.0715, running_loss=1.0556, LR=0.000100
[2025-08-27 03:48:15,217][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033152] [Batch 02352/03080] [00:29:08/00:09:01, 0.743s/it]: train_loss_raw=1.0466, running_loss=1.0542, LR=0.000100
[2025-08-27 03:48:21,058][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033160] [Batch 02360/03080] [00:29:14/00:08:55, 0.743s/it]: train_loss_raw=1.1770, running_loss=1.0519, LR=0.000100
[2025-08-27 03:48:26,850][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033168] [Batch 02368/03080] [00:29:20/00:08:49, 0.743s/it]: train_loss_raw=1.0660, running_loss=1.0504, LR=0.000100
[2025-08-27 03:48:32,724][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033176] [Batch 02376/03080] [00:29:26/00:08:43, 0.743s/it]: train_loss_raw=1.0524, running_loss=1.0471, LR=0.000100
[2025-08-27 03:48:38,701][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033184] [Batch 02384/03080] [00:29:32/00:08:37, 0.743s/it]: train_loss_raw=0.9917, running_loss=1.0442, LR=0.000100
[2025-08-27 03:48:44,605][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033192] [Batch 02392/03080] [00:29:37/00:08:31, 0.743s/it]: train_loss_raw=1.0405, running_loss=1.0443, LR=0.000100
[2025-08-27 03:48:50,423][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033200] [Batch 02400/03080] [00:29:43/00:08:25, 0.743s/it]: train_loss_raw=0.9809, running_loss=1.0435, LR=0.000100
[2025-08-27 03:48:56,365][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033208] [Batch 02408/03080] [00:29:49/00:08:19, 0.743s/it]: train_loss_raw=1.0576, running_loss=1.0449, LR=0.000100
[2025-08-27 03:49:02,312][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033216] [Batch 02416/03080] [00:29:55/00:08:13, 0.743s/it]: train_loss_raw=1.1612, running_loss=1.0480, LR=0.000100
[2025-08-27 03:49:08,255][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033224] [Batch 02424/03080] [00:30:01/00:08:07, 0.743s/it]: train_loss_raw=1.0608, running_loss=1.0461, LR=0.000100
[2025-08-27 03:49:14,239][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033232] [Batch 02432/03080] [00:30:07/00:08:01, 0.743s/it]: train_loss_raw=0.9633, running_loss=1.0467, LR=0.000100
[2025-08-27 03:49:20,173][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033240] [Batch 02440/03080] [00:30:13/00:07:55, 0.743s/it]: train_loss_raw=1.0056, running_loss=1.0462, LR=0.000100
[2025-08-27 03:49:26,115][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033248] [Batch 02448/03080] [00:30:19/00:07:49, 0.743s/it]: train_loss_raw=1.0681, running_loss=1.0456, LR=0.000100
[2025-08-27 03:49:32,015][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033256] [Batch 02456/03080] [00:30:25/00:07:43, 0.743s/it]: train_loss_raw=1.0397, running_loss=1.0456, LR=0.000100
[2025-08-27 03:49:37,880][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033264] [Batch 02464/03080] [00:30:31/00:07:37, 0.743s/it]: train_loss_raw=1.0268, running_loss=1.0430, LR=0.000100
[2025-08-27 03:49:43,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033272] [Batch 02472/03080] [00:30:37/00:07:31, 0.743s/it]: train_loss_raw=1.1432, running_loss=1.0440, LR=0.000100
[2025-08-27 03:49:49,460][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033280] [Batch 02480/03080] [00:30:42/00:07:25, 0.743s/it]: train_loss_raw=1.0118, running_loss=1.0433, LR=0.000100
[2025-08-27 03:49:55,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033288] [Batch 02488/03080] [00:30:48/00:07:19, 0.743s/it]: train_loss_raw=1.0410, running_loss=1.0444, LR=0.000100
[2025-08-27 03:50:01,366][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033296] [Batch 02496/03080] [00:30:54/00:07:13, 0.743s/it]: train_loss_raw=1.0207, running_loss=1.0434, LR=0.000100
[2025-08-27 03:50:07,269][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033304] [Batch 02504/03080] [00:31:00/00:07:08, 0.743s/it]: train_loss_raw=0.9292, running_loss=1.0402, LR=0.000100
[2025-08-27 03:50:13,104][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033312] [Batch 02512/03080] [00:31:06/00:07:02, 0.743s/it]: train_loss_raw=1.1723, running_loss=1.0387, LR=0.000100
[2025-08-27 03:50:19,111][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033320] [Batch 02520/03080] [00:31:12/00:06:56, 0.743s/it]: train_loss_raw=0.9318, running_loss=1.0357, LR=0.000100
[2025-08-27 03:50:25,043][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033328] [Batch 02528/03080] [00:31:18/00:06:50, 0.743s/it]: train_loss_raw=1.1039, running_loss=1.0386, LR=0.000100
[2025-08-27 03:50:31,002][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033336] [Batch 02536/03080] [00:31:24/00:06:44, 0.743s/it]: train_loss_raw=0.9417, running_loss=1.0377, LR=0.000100
[2025-08-27 03:50:36,843][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033344] [Batch 02544/03080] [00:31:30/00:06:38, 0.743s/it]: train_loss_raw=1.0187, running_loss=1.0399, LR=0.000100
[2025-08-27 03:50:42,806][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033352] [Batch 02552/03080] [00:31:36/00:06:32, 0.743s/it]: train_loss_raw=1.0588, running_loss=1.0437, LR=0.000100
[2025-08-27 03:50:48,614][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033360] [Batch 02560/03080] [00:31:41/00:06:26, 0.743s/it]: train_loss_raw=1.0180, running_loss=1.0432, LR=0.000100
[2025-08-27 03:50:54,396][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033368] [Batch 02568/03080] [00:31:47/00:06:20, 0.743s/it]: train_loss_raw=1.1327, running_loss=1.0430, LR=0.000100
[2025-08-27 03:51:00,225][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033376] [Batch 02576/03080] [00:31:53/00:06:14, 0.743s/it]: train_loss_raw=1.0320, running_loss=1.0432, LR=0.000100
[2025-08-27 03:51:06,114][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033384] [Batch 02584/03080] [00:31:59/00:06:08, 0.743s/it]: train_loss_raw=1.0638, running_loss=1.0428, LR=0.000100
[2025-08-27 03:51:12,101][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033392] [Batch 02592/03080] [00:32:05/00:06:02, 0.743s/it]: train_loss_raw=0.9799, running_loss=1.0413, LR=0.000100
[2025-08-27 03:51:18,022][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033400] [Batch 02600/03080] [00:32:11/00:05:56, 0.743s/it]: train_loss_raw=1.0558, running_loss=1.0412, LR=0.000100
[2025-08-27 03:51:23,823][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033408] [Batch 02608/03080] [00:32:17/00:05:50, 0.743s/it]: train_loss_raw=1.1836, running_loss=1.0432, LR=0.000100
[2025-08-27 03:51:29,830][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033416] [Batch 02616/03080] [00:32:23/00:05:44, 0.743s/it]: train_loss_raw=1.0682, running_loss=1.0445, LR=0.000100
[2025-08-27 03:51:35,604][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033424] [Batch 02624/03080] [00:32:28/00:05:38, 0.743s/it]: train_loss_raw=1.0758, running_loss=1.0445, LR=0.000100
[2025-08-27 03:51:41,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033432] [Batch 02632/03080] [00:32:34/00:05:32, 0.743s/it]: train_loss_raw=1.0832, running_loss=1.0465, LR=0.000100
[2025-08-27 03:51:47,202][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033440] [Batch 02640/03080] [00:32:40/00:05:26, 0.743s/it]: train_loss_raw=0.9959, running_loss=1.0478, LR=0.000100
[2025-08-27 03:51:53,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033448] [Batch 02648/03080] [00:32:46/00:05:20, 0.743s/it]: train_loss_raw=0.9163, running_loss=1.0432, LR=0.000100
[2025-08-27 03:51:58,924][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033456] [Batch 02656/03080] [00:32:52/00:05:14, 0.743s/it]: train_loss_raw=0.9856, running_loss=1.0411, LR=0.000100
[2025-08-27 03:52:04,710][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033464] [Batch 02664/03080] [00:32:58/00:05:08, 0.743s/it]: train_loss_raw=1.0697, running_loss=1.0406, LR=0.000100
[2025-08-27 03:52:10,494][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033472] [Batch 02672/03080] [00:33:03/00:05:02, 0.742s/it]: train_loss_raw=1.0462, running_loss=1.0423, LR=0.000100
[2025-08-27 03:52:16,441][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033480] [Batch 02680/03080] [00:33:09/00:04:56, 0.742s/it]: train_loss_raw=0.9801, running_loss=1.0423, LR=0.000100
[2025-08-27 03:52:22,298][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033488] [Batch 02688/03080] [00:33:15/00:04:51, 0.742s/it]: train_loss_raw=1.0759, running_loss=1.0428, LR=0.000100
[2025-08-27 03:52:28,192][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033496] [Batch 02696/03080] [00:33:21/00:04:45, 0.742s/it]: train_loss_raw=1.0442, running_loss=1.0429, LR=0.000100
[2025-08-27 03:52:34,174][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033504] [Batch 02704/03080] [00:33:27/00:04:39, 0.742s/it]: train_loss_raw=1.0265, running_loss=1.0406, LR=0.000100
[2025-08-27 03:52:40,254][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033512] [Batch 02712/03080] [00:33:33/00:04:33, 0.742s/it]: train_loss_raw=1.0847, running_loss=1.0393, LR=0.000100
[2025-08-27 03:52:46,229][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033520] [Batch 02720/03080] [00:33:39/00:04:27, 0.743s/it]: train_loss_raw=1.0832, running_loss=1.0380, LR=0.000100
[2025-08-27 03:52:52,135][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033528] [Batch 02728/03080] [00:33:45/00:04:21, 0.742s/it]: train_loss_raw=0.9299, running_loss=1.0388, LR=0.000100
[2025-08-27 03:52:57,903][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033536] [Batch 02736/03080] [00:33:51/00:04:15, 0.742s/it]: train_loss_raw=1.0051, running_loss=1.0408, LR=0.000100
[2025-08-27 03:53:03,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033544] [Batch 02744/03080] [00:33:57/00:04:09, 0.742s/it]: train_loss_raw=0.9966, running_loss=1.0424, LR=0.000100
[2025-08-27 03:53:09,648][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033552] [Batch 02752/03080] [00:34:03/00:04:03, 0.742s/it]: train_loss_raw=0.9531, running_loss=1.0381, LR=0.000100
[2025-08-27 03:53:15,387][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033560] [Batch 02760/03080] [00:34:08/00:03:57, 0.742s/it]: train_loss_raw=1.1563, running_loss=1.0388, LR=0.000100
[2025-08-27 03:53:21,410][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033568] [Batch 02768/03080] [00:34:14/00:03:51, 0.742s/it]: train_loss_raw=1.0031, running_loss=1.0380, LR=0.000100
[2025-08-27 03:53:27,231][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033576] [Batch 02776/03080] [00:34:20/00:03:45, 0.742s/it]: train_loss_raw=1.0537, running_loss=1.0359, LR=0.000100
[2025-08-27 03:53:33,197][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033584] [Batch 02784/03080] [00:34:26/00:03:39, 0.742s/it]: train_loss_raw=0.9405, running_loss=1.0345, LR=0.000100
[2025-08-27 03:53:39,220][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033592] [Batch 02792/03080] [00:34:32/00:03:33, 0.742s/it]: train_loss_raw=0.9879, running_loss=1.0357, LR=0.000100
[2025-08-27 03:53:44,930][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033600] [Batch 02800/03080] [00:34:38/00:03:27, 0.742s/it]: train_loss_raw=1.1244, running_loss=1.0379, LR=0.000100
[2025-08-27 03:53:50,912][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033608] [Batch 02808/03080] [00:34:44/00:03:21, 0.742s/it]: train_loss_raw=0.9887, running_loss=1.0357, LR=0.000100
[2025-08-27 03:53:56,664][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033616] [Batch 02816/03080] [00:34:50/00:03:15, 0.742s/it]: train_loss_raw=1.1423, running_loss=1.0349, LR=0.000100
[2025-08-27 03:54:02,531][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033624] [Batch 02824/03080] [00:34:55/00:03:09, 0.742s/it]: train_loss_raw=1.0284, running_loss=1.0353, LR=0.000100
[2025-08-27 03:54:08,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033632] [Batch 02832/03080] [00:35:01/00:03:04, 0.742s/it]: train_loss_raw=1.0144, running_loss=1.0362, LR=0.000100
[2025-08-27 03:54:14,431][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033640] [Batch 02840/03080] [00:35:07/00:02:58, 0.742s/it]: train_loss_raw=1.1380, running_loss=1.0362, LR=0.000100
[2025-08-27 03:54:20,325][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033648] [Batch 02848/03080] [00:35:13/00:02:52, 0.742s/it]: train_loss_raw=1.1500, running_loss=1.0361, LR=0.000100
[2025-08-27 03:54:26,332][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033656] [Batch 02856/03080] [00:35:19/00:02:46, 0.742s/it]: train_loss_raw=1.0053, running_loss=1.0357, LR=0.000100
[2025-08-27 03:54:32,264][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033664] [Batch 02864/03080] [00:35:25/00:02:40, 0.742s/it]: train_loss_raw=1.1357, running_loss=1.0348, LR=0.000100
[2025-08-27 03:54:38,119][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033672] [Batch 02872/03080] [00:35:31/00:02:34, 0.742s/it]: train_loss_raw=1.1511, running_loss=1.0347, LR=0.000100
[2025-08-27 03:54:43,893][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033680] [Batch 02880/03080] [00:35:37/00:02:28, 0.742s/it]: train_loss_raw=0.9828, running_loss=1.0339, LR=0.000100
[2025-08-27 03:54:49,838][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033688] [Batch 02888/03080] [00:35:43/00:02:22, 0.742s/it]: train_loss_raw=0.9334, running_loss=1.0321, LR=0.000100
[2025-08-27 03:54:55,754][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033696] [Batch 02896/03080] [00:35:49/00:02:16, 0.742s/it]: train_loss_raw=1.0451, running_loss=1.0340, LR=0.000100
[2025-08-27 03:55:01,640][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033704] [Batch 02904/03080] [00:35:55/00:02:10, 0.742s/it]: train_loss_raw=1.0307, running_loss=1.0339, LR=0.000100
[2025-08-27 03:55:07,456][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033712] [Batch 02912/03080] [00:36:00/00:02:04, 0.742s/it]: train_loss_raw=1.0666, running_loss=1.0337, LR=0.000100
[2025-08-27 03:55:13,318][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033720] [Batch 02920/03080] [00:36:06/00:01:58, 0.742s/it]: train_loss_raw=0.9163, running_loss=1.0341, LR=0.000100
[2025-08-27 03:55:19,059][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033728] [Batch 02928/03080] [00:36:12/00:01:52, 0.742s/it]: train_loss_raw=0.9928, running_loss=1.0318, LR=0.000100
[2025-08-27 03:55:24,757][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033736] [Batch 02936/03080] [00:36:18/00:01:46, 0.742s/it]: train_loss_raw=1.0513, running_loss=1.0350, LR=0.000100
[2025-08-27 03:55:30,455][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033744] [Batch 02944/03080] [00:36:23/00:01:40, 0.742s/it]: train_loss_raw=0.9855, running_loss=1.0324, LR=0.000100
[2025-08-27 03:55:36,217][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033752] [Batch 02952/03080] [00:36:29/00:01:34, 0.742s/it]: train_loss_raw=1.0938, running_loss=1.0297, LR=0.000100
[2025-08-27 03:55:42,070][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033760] [Batch 02960/03080] [00:36:35/00:01:29, 0.742s/it]: train_loss_raw=1.0250, running_loss=1.0290, LR=0.000100
[2025-08-27 03:55:47,966][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033768] [Batch 02968/03080] [00:36:41/00:01:23, 0.742s/it]: train_loss_raw=1.0364, running_loss=1.0318, LR=0.000100
[2025-08-27 03:55:53,813][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033776] [Batch 02976/03080] [00:36:47/00:01:17, 0.742s/it]: train_loss_raw=1.1028, running_loss=1.0343, LR=0.000100
[2025-08-27 03:55:59,678][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033784] [Batch 02984/03080] [00:36:53/00:01:11, 0.742s/it]: train_loss_raw=0.9283, running_loss=1.0330, LR=0.000100
[2025-08-27 03:56:05,677][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033792] [Batch 02992/03080] [00:36:59/00:01:05, 0.742s/it]: train_loss_raw=1.0814, running_loss=1.0320, LR=0.000100
[2025-08-27 03:56:11,725][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033800] [Batch 03000/03080] [00:37:05/00:00:59, 0.742s/it]: train_loss_raw=0.9605, running_loss=1.0312, LR=0.000100
[2025-08-27 03:56:17,681][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033808] [Batch 03008/03080] [00:37:11/00:00:53, 0.742s/it]: train_loss_raw=1.1203, running_loss=1.0329, LR=0.000100
[2025-08-27 03:56:23,663][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033816] [Batch 03016/03080] [00:37:17/00:00:47, 0.742s/it]: train_loss_raw=0.9859, running_loss=1.0302, LR=0.000100
[2025-08-27 03:56:29,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033824] [Batch 03024/03080] [00:37:23/00:00:41, 0.742s/it]: train_loss_raw=1.0221, running_loss=1.0321, LR=0.000100
[2025-08-27 03:56:35,613][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033832] [Batch 03032/03080] [00:37:28/00:00:35, 0.742s/it]: train_loss_raw=0.9714, running_loss=1.0326, LR=0.000100
[2025-08-27 03:56:41,669][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033840] [Batch 03040/03080] [00:37:35/00:00:29, 0.742s/it]: train_loss_raw=0.9882, running_loss=1.0297, LR=0.000100
[2025-08-27 03:56:47,536][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033848] [Batch 03048/03080] [00:37:40/00:00:23, 0.742s/it]: train_loss_raw=1.1174, running_loss=1.0300, LR=0.000100
[2025-08-27 03:56:53,320][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033856] [Batch 03056/03080] [00:37:46/00:00:17, 0.742s/it]: train_loss_raw=1.0885, running_loss=1.0285, LR=0.000100
[2025-08-27 03:56:59,251][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033864] [Batch 03064/03080] [00:37:52/00:00:11, 0.742s/it]: train_loss_raw=1.0225, running_loss=1.0297, LR=0.000100
[2025-08-27 03:57:05,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033872] [Batch 03072/03080] [00:37:58/00:00:05, 0.742s/it]: train_loss_raw=1.0382, running_loss=1.0306, LR=0.000100
[2025-08-27 03:57:10,923][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033880] [Batch 03080/03080] [00:38:04/00:00:00, 0.742s/it]: train_loss_raw=1.0553, running_loss=1.0290, LR=0.000100
[2025-08-27 03:57:11,440][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-27 03:57:22,583][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00007/00310] [00:00:11/00:07:00, 1.393s/it]
[2025-08-27 03:57:34,294][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00015/00310] [00:00:22/00:06:59, 1.428s/it]
[2025-08-27 03:57:46,760][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00023/00310] [00:00:35/00:07:00, 1.472s/it]
[2025-08-27 03:57:59,491][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00031/00310] [00:00:48/00:06:57, 1.502s/it]
[2025-08-27 03:58:12,285][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00039/00310] [00:01:00/00:06:50, 1.521s/it]
[2025-08-27 03:58:24,984][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00047/00310] [00:01:13/00:06:41, 1.532s/it]
[2025-08-27 03:58:37,873][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00055/00310] [00:01:26/00:06:32, 1.543s/it]
[2025-08-27 03:58:50,513][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00063/00310] [00:01:39/00:06:20, 1.548s/it]
[2025-08-27 03:59:02,709][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00071/00310] [00:01:51/00:06:07, 1.545s/it]
[2025-08-27 03:59:15,338][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00079/00310] [00:02:03/00:05:56, 1.549s/it]
[2025-08-27 03:59:28,036][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00087/00310] [00:02:16/00:05:44, 1.552s/it]
[2025-08-27 03:59:41,200][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00095/00310] [00:02:29/00:05:33, 1.560s/it]
[2025-08-27 03:59:54,327][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00103/00310] [00:02:42/00:05:22, 1.566s/it]
[2025-08-27 04:00:06,522][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00111/00310] [00:02:55/00:05:09, 1.563s/it]
[2025-08-27 04:00:19,398][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00119/00310] [00:03:07/00:04:57, 1.566s/it]
[2025-08-27 04:00:32,164][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00127/00310] [00:03:20/00:04:45, 1.568s/it]
[2025-08-27 04:00:44,946][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00135/00310] [00:03:33/00:04:33, 1.570s/it]
[2025-08-27 04:00:57,937][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00143/00310] [00:03:46/00:04:21, 1.573s/it]
[2025-08-27 04:01:09,526][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00151/00310] [00:03:58/00:04:07, 1.566s/it]
[2025-08-27 04:01:21,359][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00159/00310] [00:04:09/00:03:54, 1.562s/it]
[2025-08-27 04:01:34,043][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00167/00310] [00:04:22/00:03:41, 1.563s/it]
[2025-08-27 04:01:45,388][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00175/00310] [00:04:33/00:03:28, 1.557s/it]
[2025-08-27 04:01:56,756][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00183/00310] [00:04:45/00:03:15, 1.551s/it]
[2025-08-27 04:02:09,086][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00191/00310] [00:04:57/00:03:02, 1.550s/it]
[2025-08-27 04:02:21,475][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00199/00310] [00:05:10/00:02:50, 1.550s/it]
[2025-08-27 04:02:33,506][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00207/00310] [00:05:22/00:02:37, 1.548s/it]
[2025-08-27 04:02:45,720][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00215/00310] [00:05:34/00:02:25, 1.548s/it]
[2025-08-27 04:02:58,696][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00223/00310] [00:05:47/00:02:13, 1.550s/it]
[2025-08-27 04:03:11,800][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00231/00310] [00:06:00/00:02:01, 1.553s/it]
[2025-08-27 04:03:23,799][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00239/00310] [00:06:12/00:01:48, 1.551s/it]
[2025-08-27 04:03:35,314][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00247/00310] [00:06:23/00:01:35, 1.548s/it]
[2025-08-27 04:03:47,725][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00255/00310] [00:06:36/00:01:23, 1.548s/it]
[2025-08-27 04:04:00,393][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00263/00310] [00:06:48/00:01:11, 1.549s/it]
[2025-08-27 04:04:12,843][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00271/00310] [00:07:01/00:00:58, 1.549s/it]
[2025-08-27 04:04:25,033][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00279/00310] [00:07:13/00:00:46, 1.549s/it]
[2025-08-27 04:04:37,915][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00287/00310] [00:07:26/00:00:34, 1.550s/it]
[2025-08-27 04:04:49,842][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00295/00310] [00:07:38/00:00:21, 1.549s/it]
[2025-08-27 04:05:02,230][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00303/00310] [00:07:50/00:00:09, 1.549s/it]
[2025-08-27 04:05:11,767][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.02900, valid_loss=1.86882
[2025-08-27 04:05:11,768][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-27 04:05:11,768][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.702
[2025-08-27 04:05:11,768][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.047
[2025-08-27 04:05:11,768][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.049
[2025-08-27 04:05:11,768][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.015
[2025-08-27 04:05:11,783][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 08:38:25, remaining time 14:55:27, 00:47:07 per epoch
[2025-08-27 04:05:18,127][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033888] [Batch 00008/03080] [00:00:06/00:38:47, 0.758s/it]: train_loss_raw=1.0140, running_loss=0.9873, LR=0.000100
[2025-08-27 04:05:24,067][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033896] [Batch 00016/03080] [00:00:12/00:38:18, 0.750s/it]: train_loss_raw=1.0426, running_loss=0.9890, LR=0.000100
[2025-08-27 04:05:29,951][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033904] [Batch 00024/03080] [00:00:17/00:37:57, 0.745s/it]: train_loss_raw=1.0213, running_loss=0.9912, LR=0.000100
[2025-08-27 04:05:35,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033912] [Batch 00032/03080] [00:00:23/00:37:55, 0.747s/it]: train_loss_raw=1.0090, running_loss=0.9950, LR=0.000100
[2025-08-27 04:05:41,920][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033920] [Batch 00040/03080] [00:00:29/00:37:48, 0.746s/it]: train_loss_raw=1.1053, running_loss=0.9996, LR=0.000100
[2025-08-27 04:05:47,822][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033928] [Batch 00048/03080] [00:00:35/00:37:38, 0.745s/it]: train_loss_raw=1.0857, running_loss=1.0013, LR=0.000100
[2025-08-27 04:05:53,770][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033936] [Batch 00056/03080] [00:00:41/00:37:32, 0.745s/it]: train_loss_raw=0.9218, running_loss=0.9992, LR=0.000100
[2025-08-27 04:05:59,771][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033944] [Batch 00064/03080] [00:00:47/00:37:28, 0.745s/it]: train_loss_raw=1.0215, running_loss=1.0001, LR=0.000100
[2025-08-27 04:06:05,687][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033952] [Batch 00072/03080] [00:00:53/00:37:20, 0.745s/it]: train_loss_raw=0.9064, running_loss=1.0001, LR=0.000100
[2025-08-27 04:06:11,563][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033960] [Batch 00080/03080] [00:00:59/00:37:11, 0.744s/it]: train_loss_raw=1.0529, running_loss=1.0019, LR=0.000100
[2025-08-27 04:06:17,437][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033968] [Batch 00088/03080] [00:01:05/00:37:02, 0.743s/it]: train_loss_raw=1.0473, running_loss=1.0011, LR=0.000100
[2025-08-27 04:06:23,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033976] [Batch 00096/03080] [00:01:11/00:36:56, 0.743s/it]: train_loss_raw=1.0382, running_loss=1.0022, LR=0.000100
[2025-08-27 04:06:29,451][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033984] [Batch 00104/03080] [00:01:17/00:36:54, 0.744s/it]: train_loss_raw=1.0187, running_loss=1.0052, LR=0.000100
[2025-08-27 04:06:35,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033992] [Batch 00112/03080] [00:01:23/00:36:47, 0.744s/it]: train_loss_raw=0.9957, running_loss=1.0039, LR=0.000100
[2025-08-27 04:06:41,244][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034000] [Batch 00120/03080] [00:01:29/00:36:39, 0.743s/it]: train_loss_raw=0.9592, running_loss=1.0048, LR=0.000100
[2025-08-27 04:06:51,167][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034008] [Batch 00128/03080] [00:01:39/00:38:05, 0.774s/it]: train_loss_raw=1.0794, running_loss=1.0054, LR=0.000100
[2025-08-27 04:06:57,114][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034016] [Batch 00136/03080] [00:01:45/00:37:54, 0.772s/it]: train_loss_raw=1.0269, running_loss=1.0074, LR=0.000100
[2025-08-27 04:07:03,174][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034024] [Batch 00144/03080] [00:01:51/00:37:45, 0.772s/it]: train_loss_raw=1.0565, running_loss=1.0090, LR=0.000100
[2025-08-27 04:07:09,204][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034032] [Batch 00152/03080] [00:01:57/00:37:36, 0.771s/it]: train_loss_raw=1.1652, running_loss=1.0124, LR=0.000100
[2025-08-27 04:07:15,102][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034040] [Batch 00160/03080] [00:02:03/00:37:25, 0.769s/it]: train_loss_raw=1.1096, running_loss=1.0142, LR=0.000100
[2025-08-27 04:07:21,169][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034048] [Batch 00168/03080] [00:02:09/00:37:17, 0.768s/it]: train_loss_raw=1.0528, running_loss=1.0155, LR=0.000100
[2025-08-27 04:07:27,228][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034056] [Batch 00176/03080] [00:02:15/00:37:10, 0.768s/it]: train_loss_raw=0.9986, running_loss=1.0134, LR=0.000100
[2025-08-27 04:07:33,071][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034064] [Batch 00184/03080] [00:02:21/00:36:59, 0.766s/it]: train_loss_raw=1.1262, running_loss=1.0166, LR=0.000100
[2025-08-27 04:07:38,926][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034072] [Batch 00192/03080] [00:02:26/00:36:49, 0.765s/it]: train_loss_raw=1.0955, running_loss=1.0177, LR=0.000100
[2025-08-27 04:07:44,845][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034080] [Batch 00200/03080] [00:02:32/00:36:40, 0.764s/it]: train_loss_raw=1.0229, running_loss=1.0171, LR=0.000100
[2025-08-27 04:07:50,793][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034088] [Batch 00208/03080] [00:02:38/00:36:31, 0.763s/it]: train_loss_raw=0.9575, running_loss=1.0171, LR=0.000100
[2025-08-27 04:07:56,766][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034096] [Batch 00216/03080] [00:02:44/00:36:23, 0.763s/it]: train_loss_raw=1.0163, running_loss=1.0212, LR=0.000100
[2025-08-27 04:08:02,784][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034104] [Batch 00224/03080] [00:02:50/00:36:16, 0.762s/it]: train_loss_raw=1.0607, running_loss=1.0210, LR=0.000100
[2025-08-27 04:08:08,772][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034112] [Batch 00232/03080] [00:02:56/00:36:09, 0.762s/it]: train_loss_raw=1.0472, running_loss=1.0190, LR=0.000100
[2025-08-27 04:08:14,738][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034120] [Batch 00240/03080] [00:03:02/00:36:01, 0.761s/it]: train_loss_raw=1.0836, running_loss=1.0176, LR=0.000100
[2025-08-27 04:08:20,711][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034128] [Batch 00248/03080] [00:03:08/00:35:54, 0.761s/it]: train_loss_raw=0.9398, running_loss=1.0132, LR=0.000100
[2025-08-27 04:08:27,165][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034136] [Batch 00256/03080] [00:03:15/00:35:52, 0.762s/it]: train_loss_raw=1.0519, running_loss=1.0134, LR=0.000100
[2025-08-27 04:08:33,040][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034144] [Batch 00264/03080] [00:03:20/00:35:43, 0.761s/it]: train_loss_raw=1.1364, running_loss=1.0138, LR=0.000100
[2025-08-27 04:08:38,981][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034152] [Batch 00272/03080] [00:03:26/00:35:36, 0.761s/it]: train_loss_raw=1.0604, running_loss=1.0154, LR=0.000100
[2025-08-27 04:08:44,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034160] [Batch 00280/03080] [00:03:32/00:35:27, 0.760s/it]: train_loss_raw=1.0304, running_loss=1.0169, LR=0.000100
[2025-08-27 04:08:50,750][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034168] [Batch 00288/03080] [00:03:38/00:35:20, 0.759s/it]: train_loss_raw=1.0305, running_loss=1.0172, LR=0.000100
[2025-08-27 04:08:56,741][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034176] [Batch 00296/03080] [00:03:44/00:35:13, 0.759s/it]: train_loss_raw=0.9502, running_loss=1.0205, LR=0.000100
[2025-08-27 04:09:02,660][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034184] [Batch 00304/03080] [00:03:50/00:35:05, 0.759s/it]: train_loss_raw=0.9907, running_loss=1.0183, LR=0.000100
[2025-08-27 04:09:08,563][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034192] [Batch 00312/03080] [00:03:56/00:34:58, 0.758s/it]: train_loss_raw=1.0527, running_loss=1.0195, LR=0.000100
[2025-08-27 04:09:14,398][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034200] [Batch 00320/03080] [00:04:02/00:34:50, 0.757s/it]: train_loss_raw=0.9847, running_loss=1.0193, LR=0.000100
[2025-08-27 04:09:20,301][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034208] [Batch 00328/03080] [00:04:08/00:34:42, 0.757s/it]: train_loss_raw=1.0155, running_loss=1.0183, LR=0.000100
[2025-08-27 04:09:26,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034216] [Batch 00336/03080] [00:04:14/00:34:35, 0.756s/it]: train_loss_raw=1.0013, running_loss=1.0177, LR=0.000100
[2025-08-27 04:09:32,121][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034224] [Batch 00344/03080] [00:04:20/00:34:28, 0.756s/it]: train_loss_raw=0.9754, running_loss=1.0177, LR=0.000100
[2025-08-27 04:09:38,037][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034232] [Batch 00352/03080] [00:04:25/00:34:21, 0.756s/it]: train_loss_raw=1.1444, running_loss=1.0193, LR=0.000100
[2025-08-27 04:09:43,942][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034240] [Batch 00360/03080] [00:04:31/00:34:14, 0.755s/it]: train_loss_raw=1.0656, running_loss=1.0192, LR=0.000100
[2025-08-27 04:09:49,826][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034248] [Batch 00368/03080] [00:04:37/00:34:06, 0.755s/it]: train_loss_raw=0.9376, running_loss=1.0212, LR=0.000100
[2025-08-27 04:09:55,645][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034256] [Batch 00376/03080] [00:04:43/00:33:59, 0.754s/it]: train_loss_raw=1.0137, running_loss=1.0186, LR=0.000100
[2025-08-27 04:10:01,552][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034264] [Batch 00384/03080] [00:04:49/00:33:52, 0.754s/it]: train_loss_raw=0.9604, running_loss=1.0120, LR=0.000100
[2025-08-27 04:10:07,524][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034272] [Batch 00392/03080] [00:04:55/00:33:46, 0.754s/it]: train_loss_raw=1.0162, running_loss=1.0116, LR=0.000100
[2025-08-27 04:10:13,352][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034280] [Batch 00400/03080] [00:05:01/00:33:38, 0.753s/it]: train_loss_raw=1.1009, running_loss=1.0115, LR=0.000100
[2025-08-27 04:10:19,324][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034288] [Batch 00408/03080] [00:05:07/00:33:32, 0.753s/it]: train_loss_raw=1.0394, running_loss=1.0132, LR=0.000100
[2025-08-27 04:10:25,339][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034296] [Batch 00416/03080] [00:05:13/00:33:26, 0.753s/it]: train_loss_raw=0.9180, running_loss=1.0113, LR=0.000100
[2025-08-27 04:10:31,390][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034304] [Batch 00424/03080] [00:05:19/00:33:20, 0.753s/it]: train_loss_raw=1.1050, running_loss=1.0132, LR=0.000100
[2025-08-27 04:10:37,199][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034312] [Batch 00432/03080] [00:05:25/00:33:12, 0.753s/it]: train_loss_raw=1.0359, running_loss=1.0144, LR=0.000100
[2025-08-27 04:10:43,072][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034320] [Batch 00440/03080] [00:05:31/00:33:06, 0.752s/it]: train_loss_raw=0.9523, running_loss=1.0168, LR=0.000100
[2025-08-27 04:10:49,012][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034328] [Batch 00448/03080] [00:05:36/00:32:59, 0.752s/it]: train_loss_raw=1.0982, running_loss=1.0174, LR=0.000100
[2025-08-27 04:10:54,807][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034336] [Batch 00456/03080] [00:05:42/00:32:52, 0.752s/it]: train_loss_raw=1.0096, running_loss=1.0151, LR=0.000100
[2025-08-27 04:11:00,658][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034344] [Batch 00464/03080] [00:05:48/00:32:45, 0.751s/it]: train_loss_raw=0.9939, running_loss=1.0116, LR=0.000100
[2025-08-27 04:11:06,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034352] [Batch 00472/03080] [00:05:54/00:32:38, 0.751s/it]: train_loss_raw=0.9912, running_loss=1.0147, LR=0.000100
[2025-08-27 04:11:12,511][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034360] [Batch 00480/03080] [00:06:00/00:32:32, 0.751s/it]: train_loss_raw=1.0648, running_loss=1.0158, LR=0.000100
[2025-08-27 04:11:18,438][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034368] [Batch 00488/03080] [00:06:06/00:32:25, 0.751s/it]: train_loss_raw=0.9483, running_loss=1.0108, LR=0.000100
[2025-08-27 04:11:24,396][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034376] [Batch 00496/03080] [00:06:12/00:32:19, 0.751s/it]: train_loss_raw=1.0509, running_loss=1.0132, LR=0.000100
[2025-08-27 04:11:30,331][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034384] [Batch 00504/03080] [00:06:18/00:32:13, 0.751s/it]: train_loss_raw=1.0498, running_loss=1.0128, LR=0.000100
[2025-08-27 04:11:36,210][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034392] [Batch 00512/03080] [00:06:24/00:32:06, 0.750s/it]: train_loss_raw=1.0378, running_loss=1.0126, LR=0.000100
[2025-08-27 04:11:42,079][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034400] [Batch 00520/03080] [00:06:30/00:32:00, 0.750s/it]: train_loss_raw=0.9209, running_loss=1.0114, LR=0.000100
[2025-08-27 04:11:48,064][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034408] [Batch 00528/03080] [00:06:35/00:31:53, 0.750s/it]: train_loss_raw=1.0270, running_loss=1.0125, LR=0.000100
[2025-08-27 04:11:53,911][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034416] [Batch 00536/03080] [00:06:41/00:31:47, 0.750s/it]: train_loss_raw=1.0471, running_loss=1.0123, LR=0.000100
[2025-08-27 04:11:59,716][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034424] [Batch 00544/03080] [00:06:47/00:31:40, 0.749s/it]: train_loss_raw=0.9879, running_loss=1.0146, LR=0.000100
[2025-08-27 04:12:05,589][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034432] [Batch 00552/03080] [00:06:53/00:31:33, 0.749s/it]: train_loss_raw=1.0125, running_loss=1.0163, LR=0.000100
[2025-08-27 04:12:11,535][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034440] [Batch 00560/03080] [00:06:59/00:31:27, 0.749s/it]: train_loss_raw=0.9697, running_loss=1.0132, LR=0.000100
[2025-08-27 04:12:17,563][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034448] [Batch 00568/03080] [00:07:05/00:31:21, 0.749s/it]: train_loss_raw=0.9277, running_loss=1.0150, LR=0.000100
[2025-08-27 04:12:23,449][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034456] [Batch 00576/03080] [00:07:11/00:31:15, 0.749s/it]: train_loss_raw=1.0348, running_loss=1.0158, LR=0.000100
[2025-08-27 04:12:29,338][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034464] [Batch 00584/03080] [00:07:17/00:31:08, 0.749s/it]: train_loss_raw=1.0748, running_loss=1.0134, LR=0.000100
[2025-08-27 04:12:35,287][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034472] [Batch 00592/03080] [00:07:23/00:31:02, 0.749s/it]: train_loss_raw=1.0323, running_loss=1.0146, LR=0.000100
[2025-08-27 04:12:41,296][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034480] [Batch 00600/03080] [00:07:29/00:30:56, 0.749s/it]: train_loss_raw=0.9969, running_loss=1.0145, LR=0.000100
[2025-08-27 04:12:47,207][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034488] [Batch 00608/03080] [00:07:35/00:30:50, 0.749s/it]: train_loss_raw=0.9053, running_loss=1.0129, LR=0.000100
[2025-08-27 04:12:53,179][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034496] [Batch 00616/03080] [00:07:41/00:30:44, 0.749s/it]: train_loss_raw=1.0779, running_loss=1.0147, LR=0.000100
[2025-08-27 04:12:59,114][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034504] [Batch 00624/03080] [00:07:47/00:30:38, 0.748s/it]: train_loss_raw=1.0804, running_loss=1.0137, LR=0.000100
[2025-08-27 04:13:04,953][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034512] [Batch 00632/03080] [00:07:52/00:30:31, 0.748s/it]: train_loss_raw=0.9584, running_loss=1.0150, LR=0.000100
[2025-08-27 04:13:10,944][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034520] [Batch 00640/03080] [00:07:58/00:30:25, 0.748s/it]: train_loss_raw=1.0126, running_loss=1.0182, LR=0.000100
[2025-08-27 04:13:16,870][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034528] [Batch 00648/03080] [00:08:04/00:30:19, 0.748s/it]: train_loss_raw=1.0110, running_loss=1.0172, LR=0.000100
[2025-08-27 04:13:22,721][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034536] [Batch 00656/03080] [00:08:10/00:30:13, 0.748s/it]: train_loss_raw=1.0094, running_loss=1.0150, LR=0.000100
[2025-08-27 04:13:28,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034544] [Batch 00664/03080] [00:08:16/00:30:06, 0.748s/it]: train_loss_raw=1.0213, running_loss=1.0168, LR=0.000100
[2025-08-27 04:13:34,460][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034552] [Batch 00672/03080] [00:08:22/00:30:00, 0.748s/it]: train_loss_raw=1.0275, running_loss=1.0163, LR=0.000100
[2025-08-27 04:13:40,366][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034560] [Batch 00680/03080] [00:08:28/00:29:54, 0.748s/it]: train_loss_raw=1.0394, running_loss=1.0177, LR=0.000100
[2025-08-27 04:13:46,193][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034568] [Batch 00688/03080] [00:08:34/00:29:47, 0.747s/it]: train_loss_raw=0.9791, running_loss=1.0173, LR=0.000100
[2025-08-27 04:13:52,027][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034576] [Batch 00696/03080] [00:08:39/00:29:41, 0.747s/it]: train_loss_raw=0.9258, running_loss=1.0156, LR=0.000100
[2025-08-27 04:13:58,008][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034584] [Batch 00704/03080] [00:08:45/00:29:35, 0.747s/it]: train_loss_raw=0.9335, running_loss=1.0144, LR=0.000100
[2025-08-27 04:14:03,822][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034592] [Batch 00712/03080] [00:08:51/00:29:28, 0.747s/it]: train_loss_raw=1.0993, running_loss=1.0136, LR=0.000100
[2025-08-27 04:14:09,939][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034600] [Batch 00720/03080] [00:08:57/00:29:23, 0.747s/it]: train_loss_raw=0.9868, running_loss=1.0086, LR=0.000100
[2025-08-27 04:14:16,030][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034608] [Batch 00728/03080] [00:09:03/00:29:17, 0.747s/it]: train_loss_raw=0.9479, running_loss=1.0099, LR=0.000100
[2025-08-27 04:14:21,898][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034616] [Batch 00736/03080] [00:09:09/00:29:11, 0.747s/it]: train_loss_raw=0.9942, running_loss=1.0092, LR=0.000100
[2025-08-27 04:14:27,791][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034624] [Batch 00744/03080] [00:09:15/00:29:04, 0.747s/it]: train_loss_raw=1.0518, running_loss=1.0085, LR=0.000100
[2025-08-27 04:14:33,737][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034632] [Batch 00752/03080] [00:09:21/00:28:58, 0.747s/it]: train_loss_raw=0.9883, running_loss=1.0071, LR=0.000100
[2025-08-27 04:14:39,593][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034640] [Batch 00760/03080] [00:09:27/00:28:52, 0.747s/it]: train_loss_raw=0.9773, running_loss=1.0056, LR=0.000100
[2025-08-27 04:14:45,594][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034648] [Batch 00768/03080] [00:09:33/00:28:46, 0.747s/it]: train_loss_raw=0.9868, running_loss=1.0055, LR=0.000100
[2025-08-27 04:14:51,817][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034656] [Batch 00776/03080] [00:09:39/00:28:41, 0.747s/it]: train_loss_raw=0.9793, running_loss=1.0053, LR=0.000100
[2025-08-27 04:14:57,699][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034664] [Batch 00784/03080] [00:09:45/00:28:35, 0.747s/it]: train_loss_raw=0.9237, running_loss=1.0063, LR=0.000100
[2025-08-27 04:15:03,585][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034672] [Batch 00792/03080] [00:09:51/00:28:28, 0.747s/it]: train_loss_raw=1.0054, running_loss=1.0042, LR=0.000100
[2025-08-27 04:15:09,500][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034680] [Batch 00800/03080] [00:09:57/00:28:22, 0.747s/it]: train_loss_raw=1.0419, running_loss=1.0039, LR=0.000100
[2025-08-27 04:15:15,277][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034688] [Batch 00808/03080] [00:10:03/00:28:16, 0.747s/it]: train_loss_raw=0.9513, running_loss=1.0006, LR=0.000100
[2025-08-27 04:15:21,098][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034696] [Batch 00816/03080] [00:10:09/00:28:09, 0.746s/it]: train_loss_raw=1.0019, running_loss=1.0012, LR=0.000100
[2025-08-27 04:15:27,052][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034704] [Batch 00824/03080] [00:10:14/00:28:03, 0.746s/it]: train_loss_raw=1.0785, running_loss=0.9999, LR=0.000100
[2025-08-27 04:15:33,285][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034712] [Batch 00832/03080] [00:10:21/00:27:58, 0.747s/it]: train_loss_raw=1.0024, running_loss=1.0014, LR=0.000100
[2025-08-27 04:15:39,235][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034720] [Batch 00840/03080] [00:10:27/00:27:52, 0.747s/it]: train_loss_raw=0.9353, running_loss=1.0008, LR=0.000100
[2025-08-27 04:15:45,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034728] [Batch 00848/03080] [00:10:33/00:27:46, 0.747s/it]: train_loss_raw=1.0978, running_loss=1.0008, LR=0.000100
[2025-08-27 04:15:51,392][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034736] [Batch 00856/03080] [00:10:39/00:27:41, 0.747s/it]: train_loss_raw=1.0611, running_loss=1.0035, LR=0.000100
[2025-08-27 04:15:57,605][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034744] [Batch 00864/03080] [00:10:45/00:27:35, 0.747s/it]: train_loss_raw=1.0429, running_loss=1.0044, LR=0.000100
[2025-08-27 04:16:03,788][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034752] [Batch 00872/03080] [00:10:51/00:27:30, 0.747s/it]: train_loss_raw=1.0430, running_loss=1.0051, LR=0.000100
[2025-08-27 04:16:09,684][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034760] [Batch 00880/03080] [00:10:57/00:27:24, 0.747s/it]: train_loss_raw=1.1347, running_loss=1.0067, LR=0.000100
[2025-08-27 04:16:15,648][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034768] [Batch 00888/03080] [00:11:03/00:27:18, 0.747s/it]: train_loss_raw=0.9422, running_loss=1.0057, LR=0.000100
[2025-08-27 04:16:21,603][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034776] [Batch 00896/03080] [00:11:09/00:27:11, 0.747s/it]: train_loss_raw=0.8493, running_loss=1.0054, LR=0.000100
[2025-08-27 04:16:27,504][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034784] [Batch 00904/03080] [00:11:15/00:27:05, 0.747s/it]: train_loss_raw=0.9426, running_loss=1.0033, LR=0.000100
[2025-08-27 04:16:33,375][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034792] [Batch 00912/03080] [00:11:21/00:26:59, 0.747s/it]: train_loss_raw=0.9876, running_loss=1.0034, LR=0.000100
[2025-08-27 04:16:39,293][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034800] [Batch 00920/03080] [00:11:27/00:26:53, 0.747s/it]: train_loss_raw=0.9859, running_loss=1.0031, LR=0.000100
[2025-08-27 04:16:45,228][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034808] [Batch 00928/03080] [00:11:33/00:26:47, 0.747s/it]: train_loss_raw=0.9278, running_loss=1.0020, LR=0.000100
[2025-08-27 04:16:51,193][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034816] [Batch 00936/03080] [00:11:39/00:26:41, 0.747s/it]: train_loss_raw=1.1257, running_loss=1.0034, LR=0.000100
[2025-08-27 04:16:57,221][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034824] [Batch 00944/03080] [00:11:45/00:26:35, 0.747s/it]: train_loss_raw=0.9709, running_loss=1.0015, LR=0.000100
[2025-08-27 04:17:03,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034832] [Batch 00952/03080] [00:11:51/00:26:29, 0.747s/it]: train_loss_raw=1.1013, running_loss=1.0009, LR=0.000100
[2025-08-27 04:17:09,313][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034840] [Batch 00960/03080] [00:11:57/00:26:23, 0.747s/it]: train_loss_raw=0.9924, running_loss=1.0026, LR=0.000100
[2025-08-27 04:17:15,209][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034848] [Batch 00968/03080] [00:12:03/00:26:17, 0.747s/it]: train_loss_raw=0.9982, running_loss=1.0010, LR=0.000100
[2025-08-27 04:17:21,173][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034856] [Batch 00976/03080] [00:12:09/00:26:11, 0.747s/it]: train_loss_raw=0.9673, running_loss=1.0025, LR=0.000100
[2025-08-27 04:17:27,100][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034864] [Batch 00984/03080] [00:12:15/00:26:05, 0.747s/it]: train_loss_raw=0.8615, running_loss=1.0002, LR=0.000100
[2025-08-27 04:17:32,928][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034872] [Batch 00992/03080] [00:12:20/00:25:59, 0.747s/it]: train_loss_raw=0.9176, running_loss=0.9982, LR=0.000100
[2025-08-27 04:17:38,876][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034880] [Batch 01000/03080] [00:12:26/00:25:53, 0.747s/it]: train_loss_raw=1.0083, running_loss=0.9976, LR=0.000100
[2025-08-27 04:17:44,736][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034888] [Batch 01008/03080] [00:12:32/00:25:47, 0.747s/it]: train_loss_raw=1.1029, running_loss=0.9966, LR=0.000100
[2025-08-27 04:17:50,633][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034896] [Batch 01016/03080] [00:12:38/00:25:41, 0.747s/it]: train_loss_raw=1.0480, running_loss=1.0020, LR=0.000100
[2025-08-27 04:17:56,575][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034904] [Batch 01024/03080] [00:12:44/00:25:34, 0.747s/it]: train_loss_raw=0.9356, running_loss=1.0045, LR=0.000100
[2025-08-27 04:18:02,416][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034912] [Batch 01032/03080] [00:12:50/00:25:28, 0.746s/it]: train_loss_raw=0.9990, running_loss=1.0031, LR=0.000100
[2025-08-27 04:18:08,185][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034920] [Batch 01040/03080] [00:12:56/00:25:22, 0.746s/it]: train_loss_raw=0.9950, running_loss=1.0018, LR=0.000100
[2025-08-27 04:18:14,069][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034928] [Batch 01048/03080] [00:13:02/00:25:16, 0.746s/it]: train_loss_raw=1.0639, running_loss=1.0029, LR=0.000100
[2025-08-27 04:18:19,896][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034936] [Batch 01056/03080] [00:13:07/00:25:10, 0.746s/it]: train_loss_raw=0.9520, running_loss=0.9995, LR=0.000100
[2025-08-27 04:18:25,784][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034944] [Batch 01064/03080] [00:13:13/00:25:03, 0.746s/it]: train_loss_raw=0.9746, running_loss=0.9964, LR=0.000100
[2025-08-27 04:18:31,578][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034952] [Batch 01072/03080] [00:13:19/00:24:57, 0.746s/it]: train_loss_raw=0.9737, running_loss=0.9958, LR=0.000100
[2025-08-27 04:18:37,462][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034960] [Batch 01080/03080] [00:13:25/00:24:51, 0.746s/it]: train_loss_raw=0.8288, running_loss=0.9951, LR=0.000100
[2025-08-27 04:18:43,281][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034968] [Batch 01088/03080] [00:13:31/00:24:45, 0.746s/it]: train_loss_raw=0.8950, running_loss=0.9930, LR=0.000100
[2025-08-27 04:18:49,161][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034976] [Batch 01096/03080] [00:13:37/00:24:39, 0.746s/it]: train_loss_raw=1.0807, running_loss=0.9920, LR=0.000100
[2025-08-27 04:18:55,028][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034984] [Batch 01104/03080] [00:13:42/00:24:32, 0.745s/it]: train_loss_raw=0.9728, running_loss=0.9937, LR=0.000100
[2025-08-27 04:19:00,904][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034992] [Batch 01112/03080] [00:13:48/00:24:26, 0.745s/it]: train_loss_raw=1.0093, running_loss=0.9924, LR=0.000100
[2025-08-27 04:19:06,892][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035000] [Batch 01120/03080] [00:13:54/00:24:20, 0.745s/it]: train_loss_raw=1.0481, running_loss=0.9922, LR=0.000100
[2025-08-27 04:19:12,759][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035008] [Batch 01128/03080] [00:14:00/00:24:14, 0.745s/it]: train_loss_raw=1.0180, running_loss=0.9922, LR=0.000100
[2025-08-27 04:19:18,651][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035016] [Batch 01136/03080] [00:14:06/00:24:08, 0.745s/it]: train_loss_raw=1.0508, running_loss=0.9954, LR=0.000100
[2025-08-27 04:19:24,556][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035024] [Batch 01144/03080] [00:14:12/00:24:02, 0.745s/it]: train_loss_raw=0.8915, running_loss=0.9947, LR=0.000100
[2025-08-27 04:19:30,479][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035032] [Batch 01152/03080] [00:14:18/00:23:56, 0.745s/it]: train_loss_raw=1.1127, running_loss=0.9938, LR=0.000100
[2025-08-27 04:19:36,517][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035040] [Batch 01160/03080] [00:14:24/00:23:50, 0.745s/it]: train_loss_raw=0.9788, running_loss=0.9941, LR=0.000100
[2025-08-27 04:19:42,451][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035048] [Batch 01168/03080] [00:14:30/00:23:44, 0.745s/it]: train_loss_raw=0.9476, running_loss=0.9945, LR=0.000100
[2025-08-27 04:19:48,347][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035056] [Batch 01176/03080] [00:14:36/00:23:38, 0.745s/it]: train_loss_raw=1.0614, running_loss=0.9955, LR=0.000100
[2025-08-27 04:19:54,223][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035064] [Batch 01184/03080] [00:14:42/00:23:32, 0.745s/it]: train_loss_raw=0.9030, running_loss=0.9962, LR=0.000100
[2025-08-27 04:20:00,105][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035072] [Batch 01192/03080] [00:14:48/00:23:26, 0.745s/it]: train_loss_raw=1.0676, running_loss=0.9970, LR=0.000100
[2025-08-27 04:20:05,975][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035080] [Batch 01200/03080] [00:14:53/00:23:20, 0.745s/it]: train_loss_raw=1.0358, running_loss=0.9952, LR=0.000100
[2025-08-27 04:20:11,998][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035088] [Batch 01208/03080] [00:14:59/00:23:14, 0.745s/it]: train_loss_raw=1.0731, running_loss=0.9954, LR=0.000100
[2025-08-27 04:20:18,245][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035096] [Batch 01216/03080] [00:15:06/00:23:09, 0.745s/it]: train_loss_raw=1.0995, running_loss=0.9948, LR=0.000100
[2025-08-27 04:20:24,229][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035104] [Batch 01224/03080] [00:15:12/00:23:03, 0.745s/it]: train_loss_raw=1.0020, running_loss=0.9959, LR=0.000100
[2025-08-27 04:20:30,009][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035112] [Batch 01232/03080] [00:15:17/00:22:56, 0.745s/it]: train_loss_raw=1.0672, running_loss=0.9979, LR=0.000100
[2025-08-27 04:20:35,973][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035120] [Batch 01240/03080] [00:15:23/00:22:50, 0.745s/it]: train_loss_raw=0.9773, running_loss=0.9966, LR=0.000100
[2025-08-27 04:20:41,920][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035128] [Batch 01248/03080] [00:15:29/00:22:44, 0.745s/it]: train_loss_raw=0.9429, running_loss=0.9916, LR=0.000100
[2025-08-27 04:20:47,816][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035136] [Batch 01256/03080] [00:15:35/00:22:38, 0.745s/it]: train_loss_raw=1.0610, running_loss=0.9929, LR=0.000100
[2025-08-27 04:20:53,732][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035144] [Batch 01264/03080] [00:15:41/00:22:32, 0.745s/it]: train_loss_raw=1.1119, running_loss=0.9938, LR=0.000100
[2025-08-27 04:20:59,575][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035152] [Batch 01272/03080] [00:15:47/00:22:26, 0.745s/it]: train_loss_raw=1.0528, running_loss=0.9963, LR=0.000100
[2025-08-27 04:21:05,432][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035160] [Batch 01280/03080] [00:15:53/00:22:20, 0.745s/it]: train_loss_raw=0.9302, running_loss=0.9962, LR=0.000100
[2025-08-27 04:21:11,274][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035168] [Batch 01288/03080] [00:15:59/00:22:14, 0.745s/it]: train_loss_raw=1.0054, running_loss=0.9965, LR=0.000100
[2025-08-27 04:21:17,354][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035176] [Batch 01296/03080] [00:16:05/00:22:08, 0.745s/it]: train_loss_raw=0.9517, running_loss=0.9998, LR=0.000100
[2025-08-27 04:21:23,364][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035184] [Batch 01304/03080] [00:16:11/00:22:02, 0.745s/it]: train_loss_raw=0.9998, running_loss=0.9990, LR=0.000100
[2025-08-27 04:21:29,349][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035192] [Batch 01312/03080] [00:16:17/00:21:56, 0.745s/it]: train_loss_raw=0.9133, running_loss=0.9972, LR=0.000100
[2025-08-27 04:21:35,263][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035200] [Batch 01320/03080] [00:16:23/00:21:50, 0.745s/it]: train_loss_raw=1.0062, running_loss=0.9970, LR=0.000100
[2025-08-27 04:21:41,118][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035208] [Batch 01328/03080] [00:16:29/00:21:44, 0.745s/it]: train_loss_raw=0.9651, running_loss=0.9959, LR=0.000100
[2025-08-27 04:21:47,044][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035216] [Batch 01336/03080] [00:16:34/00:21:38, 0.745s/it]: train_loss_raw=1.0252, running_loss=1.0003, LR=0.000100
[2025-08-27 04:21:53,063][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035224] [Batch 01344/03080] [00:16:40/00:21:32, 0.745s/it]: train_loss_raw=1.0118, running_loss=1.0001, LR=0.000100
[2025-08-27 04:21:58,937][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035232] [Batch 01352/03080] [00:16:46/00:21:26, 0.745s/it]: train_loss_raw=1.0431, running_loss=1.0007, LR=0.000100
[2025-08-27 04:22:04,876][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035240] [Batch 01360/03080] [00:16:52/00:21:20, 0.745s/it]: train_loss_raw=1.0172, running_loss=0.9997, LR=0.000100
[2025-08-27 04:22:10,785][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035248] [Batch 01368/03080] [00:16:58/00:21:14, 0.745s/it]: train_loss_raw=0.9711, running_loss=1.0004, LR=0.000100
[2025-08-27 04:22:16,698][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035256] [Batch 01376/03080] [00:17:04/00:21:08, 0.745s/it]: train_loss_raw=0.9900, running_loss=0.9978, LR=0.000100
[2025-08-27 04:22:22,633][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035264] [Batch 01384/03080] [00:17:10/00:21:02, 0.745s/it]: train_loss_raw=0.9732, running_loss=0.9985, LR=0.000100
[2025-08-27 04:22:28,564][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035272] [Batch 01392/03080] [00:17:16/00:20:56, 0.745s/it]: train_loss_raw=0.9887, running_loss=0.9967, LR=0.000100
[2025-08-27 04:22:34,689][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035280] [Batch 01400/03080] [00:17:22/00:20:51, 0.745s/it]: train_loss_raw=0.9250, running_loss=0.9957, LR=0.000100
[2025-08-27 04:22:40,579][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035288] [Batch 01408/03080] [00:17:28/00:20:45, 0.745s/it]: train_loss_raw=0.9194, running_loss=0.9974, LR=0.000100
[2025-08-27 04:22:46,490][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035296] [Batch 01416/03080] [00:17:34/00:20:39, 0.745s/it]: train_loss_raw=1.0919, running_loss=1.0004, LR=0.000100
[2025-08-27 04:22:52,454][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035304] [Batch 01424/03080] [00:17:40/00:20:33, 0.745s/it]: train_loss_raw=1.0620, running_loss=1.0007, LR=0.000100
[2025-08-27 04:22:58,389][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035312] [Batch 01432/03080] [00:17:46/00:20:27, 0.745s/it]: train_loss_raw=0.9777, running_loss=0.9980, LR=0.000100
[2025-08-27 04:23:04,333][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035320] [Batch 01440/03080] [00:17:52/00:20:21, 0.745s/it]: train_loss_raw=1.0567, running_loss=0.9983, LR=0.000100
[2025-08-27 04:23:10,265][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035328] [Batch 01448/03080] [00:17:58/00:20:15, 0.745s/it]: train_loss_raw=0.9669, running_loss=0.9946, LR=0.000100
[2025-08-27 04:23:16,115][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035336] [Batch 01456/03080] [00:18:04/00:20:09, 0.745s/it]: train_loss_raw=1.0237, running_loss=0.9966, LR=0.000100
[2025-08-27 04:23:22,250][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035344] [Batch 01464/03080] [00:18:10/00:20:03, 0.745s/it]: train_loss_raw=1.0528, running_loss=0.9939, LR=0.000100
[2025-08-27 04:23:28,214][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035352] [Batch 01472/03080] [00:18:16/00:19:57, 0.745s/it]: train_loss_raw=1.0045, running_loss=0.9936, LR=0.000100
[2025-08-27 04:23:34,270][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035360] [Batch 01480/03080] [00:18:22/00:19:51, 0.745s/it]: train_loss_raw=0.9891, running_loss=0.9951, LR=0.000100
[2025-08-27 04:23:40,232][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035368] [Batch 01488/03080] [00:18:28/00:19:45, 0.745s/it]: train_loss_raw=0.9989, running_loss=0.9952, LR=0.000100
[2025-08-27 04:23:46,047][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035376] [Batch 01496/03080] [00:18:33/00:19:39, 0.745s/it]: train_loss_raw=0.9453, running_loss=0.9963, LR=0.000100
[2025-08-27 04:23:51,970][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035384] [Batch 01504/03080] [00:18:39/00:19:33, 0.745s/it]: train_loss_raw=0.8906, running_loss=0.9953, LR=0.000100
[2025-08-27 04:23:57,852][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035392] [Batch 01512/03080] [00:18:45/00:19:27, 0.745s/it]: train_loss_raw=0.9643, running_loss=0.9951, LR=0.000100
[2025-08-27 04:24:03,713][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035400] [Batch 01520/03080] [00:18:51/00:19:21, 0.745s/it]: train_loss_raw=1.0263, running_loss=0.9941, LR=0.000100
[2025-08-27 04:24:09,638][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035408] [Batch 01528/03080] [00:18:57/00:19:15, 0.744s/it]: train_loss_raw=1.0557, running_loss=0.9960, LR=0.000100
[2025-08-27 04:24:15,576][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035416] [Batch 01536/03080] [00:19:03/00:19:09, 0.744s/it]: train_loss_raw=0.9663, running_loss=0.9953, LR=0.000100
[2025-08-27 04:24:21,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035424] [Batch 01544/03080] [00:19:09/00:19:03, 0.745s/it]: train_loss_raw=1.0038, running_loss=0.9939, LR=0.000100
[2025-08-27 04:24:27,662][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035432] [Batch 01552/03080] [00:19:15/00:18:57, 0.745s/it]: train_loss_raw=0.8975, running_loss=0.9932, LR=0.000100
[2025-08-27 04:24:33,488][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035440] [Batch 01560/03080] [00:19:21/00:18:51, 0.745s/it]: train_loss_raw=0.9517, running_loss=0.9936, LR=0.000100
[2025-08-27 04:24:39,528][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035448] [Batch 01568/03080] [00:19:27/00:18:45, 0.745s/it]: train_loss_raw=0.9503, running_loss=0.9941, LR=0.000100
[2025-08-27 04:24:45,496][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035456] [Batch 01576/03080] [00:19:33/00:18:39, 0.745s/it]: train_loss_raw=1.0021, running_loss=0.9907, LR=0.000100
[2025-08-27 04:24:51,506][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035464] [Batch 01584/03080] [00:19:39/00:18:33, 0.745s/it]: train_loss_raw=0.9001, running_loss=0.9874, LR=0.000100
[2025-08-27 04:24:57,558][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035472] [Batch 01592/03080] [00:19:45/00:18:28, 0.745s/it]: train_loss_raw=1.0511, running_loss=0.9860, LR=0.000100
[2025-08-27 04:25:03,480][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035480] [Batch 01600/03080] [00:19:51/00:18:22, 0.745s/it]: train_loss_raw=1.0359, running_loss=0.9896, LR=0.000100
[2025-08-27 04:25:09,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035488] [Batch 01608/03080] [00:19:57/00:18:16, 0.745s/it]: train_loss_raw=1.0320, running_loss=0.9894, LR=0.000100
[2025-08-27 04:25:15,418][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035496] [Batch 01616/03080] [00:20:03/00:18:10, 0.745s/it]: train_loss_raw=0.9816, running_loss=0.9891, LR=0.000100
[2025-08-27 04:25:21,292][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035504] [Batch 01624/03080] [00:20:09/00:18:04, 0.745s/it]: train_loss_raw=1.0530, running_loss=0.9890, LR=0.000100
[2025-08-27 04:25:27,189][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035512] [Batch 01632/03080] [00:20:15/00:17:58, 0.745s/it]: train_loss_raw=0.8963, running_loss=0.9879, LR=0.000100
[2025-08-27 04:25:33,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035520] [Batch 01640/03080] [00:20:21/00:17:52, 0.745s/it]: train_loss_raw=1.0173, running_loss=0.9893, LR=0.000100
[2025-08-27 04:25:39,207][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035528] [Batch 01648/03080] [00:20:27/00:17:46, 0.745s/it]: train_loss_raw=0.9940, running_loss=0.9885, LR=0.000100
[2025-08-27 04:25:45,263][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035536] [Batch 01656/03080] [00:20:33/00:17:40, 0.745s/it]: train_loss_raw=0.8965, running_loss=0.9884, LR=0.000100
[2025-08-27 04:25:51,293][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035544] [Batch 01664/03080] [00:20:39/00:17:34, 0.745s/it]: train_loss_raw=0.9871, running_loss=0.9867, LR=0.000100
[2025-08-27 04:25:57,203][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035552] [Batch 01672/03080] [00:20:45/00:17:28, 0.745s/it]: train_loss_raw=0.8739, running_loss=0.9854, LR=0.000100
[2025-08-27 04:26:03,133][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035560] [Batch 01680/03080] [00:20:51/00:17:22, 0.745s/it]: train_loss_raw=1.0400, running_loss=0.9858, LR=0.000100
[2025-08-27 04:26:09,040][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035568] [Batch 01688/03080] [00:20:56/00:17:16, 0.745s/it]: train_loss_raw=0.9505, running_loss=0.9877, LR=0.000100
[2025-08-27 04:26:15,069][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035576] [Batch 01696/03080] [00:21:03/00:17:10, 0.745s/it]: train_loss_raw=0.8958, running_loss=0.9872, LR=0.000100
[2025-08-27 04:26:21,068][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035584] [Batch 01704/03080] [00:21:09/00:17:04, 0.745s/it]: train_loss_raw=1.0148, running_loss=0.9887, LR=0.000100
[2025-08-27 04:26:27,023][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035592] [Batch 01712/03080] [00:21:14/00:16:58, 0.745s/it]: train_loss_raw=0.9735, running_loss=0.9879, LR=0.000100
[2025-08-27 04:26:32,978][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035600] [Batch 01720/03080] [00:21:20/00:16:52, 0.745s/it]: train_loss_raw=0.9668, running_loss=0.9868, LR=0.000100
[2025-08-27 04:26:38,895][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035608] [Batch 01728/03080] [00:21:26/00:16:46, 0.745s/it]: train_loss_raw=0.9656, running_loss=0.9859, LR=0.000100
[2025-08-27 04:26:45,142][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035616] [Batch 01736/03080] [00:21:33/00:16:41, 0.745s/it]: train_loss_raw=0.9164, running_loss=0.9832, LR=0.000100
[2025-08-27 04:26:51,096][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035624] [Batch 01744/03080] [00:21:39/00:16:35, 0.745s/it]: train_loss_raw=0.9612, running_loss=0.9838, LR=0.000100
[2025-08-27 04:26:57,062][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035632] [Batch 01752/03080] [00:21:44/00:16:29, 0.745s/it]: train_loss_raw=0.9522, running_loss=0.9815, LR=0.000100
[2025-08-27 04:27:02,893][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035640] [Batch 01760/03080] [00:21:50/00:16:23, 0.745s/it]: train_loss_raw=0.9539, running_loss=0.9795, LR=0.000100
[2025-08-27 04:27:08,756][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035648] [Batch 01768/03080] [00:21:56/00:16:17, 0.745s/it]: train_loss_raw=1.0275, running_loss=0.9806, LR=0.000100
[2025-08-27 04:27:14,646][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035656] [Batch 01776/03080] [00:22:02/00:16:11, 0.745s/it]: train_loss_raw=1.0246, running_loss=0.9801, LR=0.000100
[2025-08-27 04:27:20,611][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035664] [Batch 01784/03080] [00:22:08/00:16:05, 0.745s/it]: train_loss_raw=1.0537, running_loss=0.9845, LR=0.000100
[2025-08-27 04:27:26,492][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035672] [Batch 01792/03080] [00:22:14/00:15:59, 0.745s/it]: train_loss_raw=1.0232, running_loss=0.9875, LR=0.000100
[2025-08-27 04:27:32,423][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035680] [Batch 01800/03080] [00:22:20/00:15:53, 0.745s/it]: train_loss_raw=1.0315, running_loss=0.9872, LR=0.000100
[2025-08-27 04:27:38,420][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035688] [Batch 01808/03080] [00:22:26/00:15:47, 0.745s/it]: train_loss_raw=0.9723, running_loss=0.9857, LR=0.000100
[2025-08-27 04:27:44,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035696] [Batch 01816/03080] [00:22:32/00:15:41, 0.745s/it]: train_loss_raw=0.9275, running_loss=0.9870, LR=0.000100
[2025-08-27 04:27:50,277][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035704] [Batch 01824/03080] [00:22:38/00:15:35, 0.745s/it]: train_loss_raw=0.9948, running_loss=0.9878, LR=0.000100
[2025-08-27 04:27:56,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035712] [Batch 01832/03080] [00:22:44/00:15:29, 0.745s/it]: train_loss_raw=0.8662, running_loss=0.9852, LR=0.000100
[2025-08-27 04:28:02,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035720] [Batch 01840/03080] [00:22:50/00:15:23, 0.745s/it]: train_loss_raw=0.9600, running_loss=0.9875, LR=0.000100
[2025-08-27 04:28:08,120][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035728] [Batch 01848/03080] [00:22:56/00:15:17, 0.745s/it]: train_loss_raw=1.0302, running_loss=0.9875, LR=0.000100
[2025-08-27 04:28:14,103][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035736] [Batch 01856/03080] [00:23:02/00:15:11, 0.745s/it]: train_loss_raw=0.9889, running_loss=0.9844, LR=0.000100
[2025-08-27 04:28:20,084][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035744] [Batch 01864/03080] [00:23:08/00:15:05, 0.745s/it]: train_loss_raw=1.0651, running_loss=0.9860, LR=0.000100
[2025-08-27 04:28:26,054][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035752] [Batch 01872/03080] [00:23:13/00:14:59, 0.745s/it]: train_loss_raw=1.0001, running_loss=0.9867, LR=0.000100
[2025-08-27 04:28:32,013][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035760] [Batch 01880/03080] [00:23:19/00:14:53, 0.745s/it]: train_loss_raw=0.9842, running_loss=0.9870, LR=0.000100
[2025-08-27 04:28:37,970][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035768] [Batch 01888/03080] [00:23:25/00:14:47, 0.745s/it]: train_loss_raw=1.0295, running_loss=0.9858, LR=0.000100
[2025-08-27 04:28:44,078][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035776] [Batch 01896/03080] [00:23:32/00:14:41, 0.745s/it]: train_loss_raw=0.9309, running_loss=0.9868, LR=0.000100
[2025-08-27 04:28:50,120][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035784] [Batch 01904/03080] [00:23:38/00:14:35, 0.745s/it]: train_loss_raw=0.9097, running_loss=0.9867, LR=0.000100
[2025-08-27 04:28:56,072][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035792] [Batch 01912/03080] [00:23:44/00:14:29, 0.745s/it]: train_loss_raw=0.9017, running_loss=0.9855, LR=0.000100
[2025-08-27 04:29:02,154][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035800] [Batch 01920/03080] [00:23:50/00:14:24, 0.745s/it]: train_loss_raw=0.9930, running_loss=0.9834, LR=0.000100
[2025-08-27 04:29:08,160][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035808] [Batch 01928/03080] [00:23:56/00:14:18, 0.745s/it]: train_loss_raw=1.0079, running_loss=0.9830, LR=0.000100
[2025-08-27 04:29:14,251][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035816] [Batch 01936/03080] [00:24:02/00:14:12, 0.745s/it]: train_loss_raw=1.0286, running_loss=0.9813, LR=0.000100
[2025-08-27 04:29:20,255][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035824] [Batch 01944/03080] [00:24:08/00:14:06, 0.745s/it]: train_loss_raw=0.9197, running_loss=0.9818, LR=0.000100
[2025-08-27 04:29:26,237][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035832] [Batch 01952/03080] [00:24:14/00:14:00, 0.745s/it]: train_loss_raw=0.9284, running_loss=0.9790, LR=0.000100
[2025-08-27 04:29:32,227][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035840] [Batch 01960/03080] [00:24:20/00:13:54, 0.745s/it]: train_loss_raw=0.9268, running_loss=0.9778, LR=0.000100
[2025-08-27 04:29:38,158][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035848] [Batch 01968/03080] [00:24:26/00:13:48, 0.745s/it]: train_loss_raw=0.9922, running_loss=0.9765, LR=0.000100
[2025-08-27 04:29:44,154][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035856] [Batch 01976/03080] [00:24:32/00:13:42, 0.745s/it]: train_loss_raw=1.0708, running_loss=0.9776, LR=0.000100
[2025-08-27 04:29:50,117][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035864] [Batch 01984/03080] [00:24:38/00:13:36, 0.745s/it]: train_loss_raw=0.9371, running_loss=0.9771, LR=0.000100
[2025-08-27 04:29:56,259][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035872] [Batch 01992/03080] [00:24:44/00:13:30, 0.745s/it]: train_loss_raw=1.0152, running_loss=0.9776, LR=0.000100
[2025-08-27 04:30:02,174][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035880] [Batch 02000/03080] [00:24:50/00:13:24, 0.745s/it]: train_loss_raw=1.0482, running_loss=0.9783, LR=0.000100
[2025-08-27 04:30:08,126][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035888] [Batch 02008/03080] [00:24:56/00:13:18, 0.745s/it]: train_loss_raw=0.9025, running_loss=0.9773, LR=0.000100
[2025-08-27 04:30:14,401][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035896] [Batch 02016/03080] [00:25:02/00:13:12, 0.745s/it]: train_loss_raw=0.8754, running_loss=0.9763, LR=0.000100
[2025-08-27 04:30:20,364][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035904] [Batch 02024/03080] [00:25:08/00:13:06, 0.745s/it]: train_loss_raw=0.9494, running_loss=0.9768, LR=0.000100
[2025-08-27 04:30:26,342][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035912] [Batch 02032/03080] [00:25:14/00:13:00, 0.745s/it]: train_loss_raw=0.9218, running_loss=0.9767, LR=0.000100
[2025-08-27 04:30:32,135][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035920] [Batch 02040/03080] [00:25:20/00:12:54, 0.745s/it]: train_loss_raw=1.1106, running_loss=0.9774, LR=0.000100
[2025-08-27 04:30:38,066][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035928] [Batch 02048/03080] [00:25:26/00:12:48, 0.745s/it]: train_loss_raw=0.9445, running_loss=0.9784, LR=0.000100
[2025-08-27 04:30:44,094][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035936] [Batch 02056/03080] [00:25:32/00:12:43, 0.745s/it]: train_loss_raw=0.8883, running_loss=0.9750, LR=0.000100
[2025-08-27 04:30:49,914][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035944] [Batch 02064/03080] [00:25:37/00:12:37, 0.745s/it]: train_loss_raw=0.9888, running_loss=0.9755, LR=0.000100
[2025-08-27 04:30:55,750][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035952] [Batch 02072/03080] [00:25:43/00:12:30, 0.745s/it]: train_loss_raw=0.9743, running_loss=0.9755, LR=0.000100
[2025-08-27 04:31:01,715][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035960] [Batch 02080/03080] [00:25:49/00:12:25, 0.745s/it]: train_loss_raw=0.9106, running_loss=0.9740, LR=0.000100
[2025-08-27 04:31:07,490][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035968] [Batch 02088/03080] [00:25:55/00:12:18, 0.745s/it]: train_loss_raw=1.0001, running_loss=0.9771, LR=0.000100
[2025-08-27 04:31:13,536][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035976] [Batch 02096/03080] [00:26:01/00:12:13, 0.745s/it]: train_loss_raw=0.9138, running_loss=0.9759, LR=0.000100
[2025-08-27 04:31:19,364][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035984] [Batch 02104/03080] [00:26:07/00:12:07, 0.745s/it]: train_loss_raw=0.9739, running_loss=0.9752, LR=0.000100
[2025-08-27 04:31:25,317][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035992] [Batch 02112/03080] [00:26:13/00:12:01, 0.745s/it]: train_loss_raw=0.9978, running_loss=0.9753, LR=0.000100
[2025-08-27 04:31:31,122][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036000] [Batch 02120/03080] [00:26:19/00:11:55, 0.745s/it]: train_loss_raw=0.9230, running_loss=0.9726, LR=0.000100
[2025-08-27 04:31:41,169][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036008] [Batch 02128/03080] [00:26:29/00:11:50, 0.747s/it]: train_loss_raw=0.8831, running_loss=0.9729, LR=0.000100
[2025-08-27 04:31:47,031][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036016] [Batch 02136/03080] [00:26:34/00:11:44, 0.747s/it]: train_loss_raw=1.0844, running_loss=0.9712, LR=0.000100
[2025-08-27 04:31:52,839][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036024] [Batch 02144/03080] [00:26:40/00:11:38, 0.747s/it]: train_loss_raw=0.9196, running_loss=0.9703, LR=0.000100
[2025-08-27 04:31:58,805][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036032] [Batch 02152/03080] [00:26:46/00:11:32, 0.747s/it]: train_loss_raw=1.0061, running_loss=0.9716, LR=0.000100
[2025-08-27 04:32:04,380][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036040] [Batch 02160/03080] [00:26:52/00:11:26, 0.746s/it]: train_loss_raw=0.9070, running_loss=0.9702, LR=0.000100
[2025-08-27 04:32:10,264][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036048] [Batch 02168/03080] [00:26:58/00:11:20, 0.746s/it]: train_loss_raw=0.9284, running_loss=0.9679, LR=0.000100
[2025-08-27 04:32:16,178][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036056] [Batch 02176/03080] [00:27:04/00:11:14, 0.746s/it]: train_loss_raw=1.0971, running_loss=0.9692, LR=0.000100
[2025-08-27 04:32:22,058][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036064] [Batch 02184/03080] [00:27:09/00:11:08, 0.746s/it]: train_loss_raw=1.1176, running_loss=0.9705, LR=0.000100
[2025-08-27 04:32:27,948][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036072] [Batch 02192/03080] [00:27:15/00:11:02, 0.746s/it]: train_loss_raw=0.9869, running_loss=0.9727, LR=0.000100
[2025-08-27 04:32:33,784][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036080] [Batch 02200/03080] [00:27:21/00:10:56, 0.746s/it]: train_loss_raw=0.9786, running_loss=0.9728, LR=0.000100
[2025-08-27 04:32:39,696][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036088] [Batch 02208/03080] [00:27:27/00:10:50, 0.746s/it]: train_loss_raw=0.9532, running_loss=0.9717, LR=0.000100
[2025-08-27 04:32:45,473][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036096] [Batch 02216/03080] [00:27:33/00:10:44, 0.746s/it]: train_loss_raw=0.9154, running_loss=0.9731, LR=0.000100
[2025-08-27 04:32:51,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036104] [Batch 02224/03080] [00:27:39/00:10:38, 0.746s/it]: train_loss_raw=1.0185, running_loss=0.9733, LR=0.000100
[2025-08-27 04:32:57,155][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036112] [Batch 02232/03080] [00:27:45/00:10:32, 0.746s/it]: train_loss_raw=0.9472, running_loss=0.9728, LR=0.000100
[2025-08-27 04:33:02,986][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036120] [Batch 02240/03080] [00:27:50/00:10:26, 0.746s/it]: train_loss_raw=0.9222, running_loss=0.9714, LR=0.000100
[2025-08-27 04:33:08,929][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036128] [Batch 02248/03080] [00:27:56/00:10:20, 0.746s/it]: train_loss_raw=0.9007, running_loss=0.9682, LR=0.000100
[2025-08-27 04:33:14,852][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036136] [Batch 02256/03080] [00:28:02/00:10:14, 0.746s/it]: train_loss_raw=0.9806, running_loss=0.9656, LR=0.000100
[2025-08-27 04:33:20,784][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036144] [Batch 02264/03080] [00:28:08/00:10:08, 0.746s/it]: train_loss_raw=1.0613, running_loss=0.9654, LR=0.000100
[2025-08-27 04:33:26,615][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036152] [Batch 02272/03080] [00:28:14/00:10:02, 0.746s/it]: train_loss_raw=0.8782, running_loss=0.9665, LR=0.000100
[2025-08-27 04:33:32,554][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036160] [Batch 02280/03080] [00:28:20/00:09:56, 0.746s/it]: train_loss_raw=0.8644, running_loss=0.9648, LR=0.000100
[2025-08-27 04:33:38,440][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036168] [Batch 02288/03080] [00:28:26/00:09:50, 0.746s/it]: train_loss_raw=0.9964, running_loss=0.9663, LR=0.000100
[2025-08-27 04:33:44,543][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036176] [Batch 02296/03080] [00:28:32/00:09:44, 0.746s/it]: train_loss_raw=0.9672, running_loss=0.9671, LR=0.000100
[2025-08-27 04:33:50,381][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036184] [Batch 02304/03080] [00:28:38/00:09:38, 0.746s/it]: train_loss_raw=0.8210, running_loss=0.9657, LR=0.000100
[2025-08-27 04:33:56,253][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036192] [Batch 02312/03080] [00:28:44/00:09:32, 0.746s/it]: train_loss_raw=0.9904, running_loss=0.9671, LR=0.000100
[2025-08-27 04:34:02,119][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036200] [Batch 02320/03080] [00:28:50/00:09:26, 0.746s/it]: train_loss_raw=0.9900, running_loss=0.9694, LR=0.000100
[2025-08-27 04:34:07,994][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036208] [Batch 02328/03080] [00:28:55/00:09:20, 0.746s/it]: train_loss_raw=1.0227, running_loss=0.9658, LR=0.000100
[2025-08-27 04:34:13,820][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036216] [Batch 02336/03080] [00:29:01/00:09:14, 0.746s/it]: train_loss_raw=0.9684, running_loss=0.9625, LR=0.000100
[2025-08-27 04:34:19,705][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036224] [Batch 02344/03080] [00:29:07/00:09:08, 0.746s/it]: train_loss_raw=1.0301, running_loss=0.9622, LR=0.000100
[2025-08-27 04:34:25,722][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036232] [Batch 02352/03080] [00:29:13/00:09:02, 0.746s/it]: train_loss_raw=0.9959, running_loss=0.9612, LR=0.000100
[2025-08-27 04:34:31,674][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036240] [Batch 02360/03080] [00:29:19/00:08:56, 0.746s/it]: train_loss_raw=0.9614, running_loss=0.9616, LR=0.000100
[2025-08-27 04:34:37,641][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036248] [Batch 02368/03080] [00:29:25/00:08:50, 0.746s/it]: train_loss_raw=1.0084, running_loss=0.9623, LR=0.000100
[2025-08-27 04:34:43,531][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036256] [Batch 02376/03080] [00:29:31/00:08:44, 0.746s/it]: train_loss_raw=0.8857, running_loss=0.9582, LR=0.000100
[2025-08-27 04:34:49,442][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036264] [Batch 02384/03080] [00:29:37/00:08:38, 0.746s/it]: train_loss_raw=0.9634, running_loss=0.9601, LR=0.000100
[2025-08-27 04:34:55,281][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036272] [Batch 02392/03080] [00:29:43/00:08:32, 0.745s/it]: train_loss_raw=0.9391, running_loss=0.9574, LR=0.000100
[2025-08-27 04:35:01,221][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036280] [Batch 02400/03080] [00:29:49/00:08:26, 0.745s/it]: train_loss_raw=0.9525, running_loss=0.9598, LR=0.000100
[2025-08-27 04:35:07,144][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036288] [Batch 02408/03080] [00:29:55/00:08:20, 0.745s/it]: train_loss_raw=1.0030, running_loss=0.9576, LR=0.000100
[2025-08-27 04:35:12,996][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036296] [Batch 02416/03080] [00:30:00/00:08:14, 0.745s/it]: train_loss_raw=0.9092, running_loss=0.9579, LR=0.000100
[2025-08-27 04:35:18,768][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036304] [Batch 02424/03080] [00:30:06/00:08:08, 0.745s/it]: train_loss_raw=1.0012, running_loss=0.9573, LR=0.000100
[2025-08-27 04:35:24,629][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036312] [Batch 02432/03080] [00:30:12/00:08:02, 0.745s/it]: train_loss_raw=0.9947, running_loss=0.9568, LR=0.000100
[2025-08-27 04:35:30,538][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036320] [Batch 02440/03080] [00:30:18/00:07:56, 0.745s/it]: train_loss_raw=0.8791, running_loss=0.9539, LR=0.000100
[2025-08-27 04:35:36,460][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036328] [Batch 02448/03080] [00:30:24/00:07:51, 0.745s/it]: train_loss_raw=0.9844, running_loss=0.9549, LR=0.000100
[2025-08-27 04:35:42,365][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036336] [Batch 02456/03080] [00:30:30/00:07:45, 0.745s/it]: train_loss_raw=0.9821, running_loss=0.9555, LR=0.000100
[2025-08-27 04:35:48,477][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036344] [Batch 02464/03080] [00:30:36/00:07:39, 0.745s/it]: train_loss_raw=1.0732, running_loss=0.9567, LR=0.000100
[2025-08-27 04:35:54,508][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036352] [Batch 02472/03080] [00:30:42/00:07:33, 0.745s/it]: train_loss_raw=0.9372, running_loss=0.9588, LR=0.000100
[2025-08-27 04:36:00,416][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036360] [Batch 02480/03080] [00:30:48/00:07:27, 0.745s/it]: train_loss_raw=0.9287, running_loss=0.9601, LR=0.000100
[2025-08-27 04:36:06,288][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036368] [Batch 02488/03080] [00:30:54/00:07:21, 0.745s/it]: train_loss_raw=0.9146, running_loss=0.9611, LR=0.000100
[2025-08-27 04:36:12,200][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036376] [Batch 02496/03080] [00:31:00/00:07:15, 0.745s/it]: train_loss_raw=0.9293, running_loss=0.9628, LR=0.000100
[2025-08-27 04:36:18,101][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036384] [Batch 02504/03080] [00:31:06/00:07:09, 0.745s/it]: train_loss_raw=0.9621, running_loss=0.9629, LR=0.000100
[2025-08-27 04:36:24,030][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036392] [Batch 02512/03080] [00:31:11/00:07:03, 0.745s/it]: train_loss_raw=0.9621, running_loss=0.9633, LR=0.000100
[2025-08-27 04:36:29,719][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036400] [Batch 02520/03080] [00:31:17/00:06:57, 0.745s/it]: train_loss_raw=0.9594, running_loss=0.9661, LR=0.000100
[2025-08-27 04:36:35,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036408] [Batch 02528/03080] [00:31:23/00:06:51, 0.745s/it]: train_loss_raw=0.9191, running_loss=0.9662, LR=0.000100
[2025-08-27 04:36:41,169][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036416] [Batch 02536/03080] [00:31:29/00:06:45, 0.745s/it]: train_loss_raw=0.9610, running_loss=0.9691, LR=0.000100
[2025-08-27 04:36:47,104][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036424] [Batch 02544/03080] [00:31:35/00:06:39, 0.745s/it]: train_loss_raw=1.0328, running_loss=0.9668, LR=0.000100
[2025-08-27 04:36:53,111][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036432] [Batch 02552/03080] [00:31:41/00:06:33, 0.745s/it]: train_loss_raw=1.0135, running_loss=0.9669, LR=0.000100
[2025-08-27 04:36:58,980][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036440] [Batch 02560/03080] [00:31:46/00:06:27, 0.745s/it]: train_loss_raw=0.9488, running_loss=0.9654, LR=0.000100
[2025-08-27 04:37:04,752][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036448] [Batch 02568/03080] [00:31:52/00:06:21, 0.745s/it]: train_loss_raw=1.0672, running_loss=0.9662, LR=0.000100
[2025-08-27 04:37:10,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036456] [Batch 02576/03080] [00:31:58/00:06:15, 0.745s/it]: train_loss_raw=0.8830, running_loss=0.9658, LR=0.000100
[2025-08-27 04:37:16,509][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036464] [Batch 02584/03080] [00:32:04/00:06:09, 0.745s/it]: train_loss_raw=1.0166, running_loss=0.9659, LR=0.000100
[2025-08-27 04:37:21,999][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036472] [Batch 02592/03080] [00:32:09/00:06:03, 0.745s/it]: train_loss_raw=0.9894, running_loss=0.9675, LR=0.000100
[2025-08-27 04:37:27,814][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036480] [Batch 02600/03080] [00:32:15/00:05:57, 0.745s/it]: train_loss_raw=1.0511, running_loss=0.9691, LR=0.000100
[2025-08-27 04:37:33,700][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036488] [Batch 02608/03080] [00:32:21/00:05:51, 0.744s/it]: train_loss_raw=1.0429, running_loss=0.9675, LR=0.000100
[2025-08-27 04:37:39,505][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036496] [Batch 02616/03080] [00:32:27/00:05:45, 0.744s/it]: train_loss_raw=0.9159, running_loss=0.9679, LR=0.000100
[2025-08-27 04:37:45,361][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036504] [Batch 02624/03080] [00:32:33/00:05:39, 0.744s/it]: train_loss_raw=0.9830, running_loss=0.9657, LR=0.000100
[2025-08-27 04:37:51,235][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036512] [Batch 02632/03080] [00:32:39/00:05:33, 0.744s/it]: train_loss_raw=0.9923, running_loss=0.9651, LR=0.000100
[2025-08-27 04:37:57,099][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036520] [Batch 02640/03080] [00:32:45/00:05:27, 0.744s/it]: train_loss_raw=0.8980, running_loss=0.9657, LR=0.000100
[2025-08-27 04:38:02,936][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036528] [Batch 02648/03080] [00:32:50/00:05:21, 0.744s/it]: train_loss_raw=0.9176, running_loss=0.9650, LR=0.000100
[2025-08-27 04:38:08,816][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036536] [Batch 02656/03080] [00:32:56/00:05:15, 0.744s/it]: train_loss_raw=0.8502, running_loss=0.9633, LR=0.000100
[2025-08-27 04:38:14,717][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036544] [Batch 02664/03080] [00:33:02/00:05:09, 0.744s/it]: train_loss_raw=0.9907, running_loss=0.9630, LR=0.000100
[2025-08-27 04:38:20,603][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036552] [Batch 02672/03080] [00:33:08/00:05:03, 0.744s/it]: train_loss_raw=1.0761, running_loss=0.9609, LR=0.000100
[2025-08-27 04:38:26,539][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036560] [Batch 02680/03080] [00:33:14/00:04:57, 0.744s/it]: train_loss_raw=0.9023, running_loss=0.9605, LR=0.000100
[2025-08-27 04:38:32,489][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036568] [Batch 02688/03080] [00:33:20/00:04:51, 0.744s/it]: train_loss_raw=0.8749, running_loss=0.9604, LR=0.000100
[2025-08-27 04:38:38,411][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036576] [Batch 02696/03080] [00:33:26/00:04:45, 0.744s/it]: train_loss_raw=0.9645, running_loss=0.9607, LR=0.000100
[2025-08-27 04:38:44,259][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036584] [Batch 02704/03080] [00:33:32/00:04:39, 0.744s/it]: train_loss_raw=0.8820, running_loss=0.9591, LR=0.000100
[2025-08-27 04:38:50,037][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036592] [Batch 02712/03080] [00:33:37/00:04:33, 0.744s/it]: train_loss_raw=0.9902, running_loss=0.9622, LR=0.000100
[2025-08-27 04:38:55,781][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036600] [Batch 02720/03080] [00:33:43/00:04:27, 0.744s/it]: train_loss_raw=0.9735, running_loss=0.9639, LR=0.000100
[2025-08-27 04:39:01,744][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036608] [Batch 02728/03080] [00:33:49/00:04:21, 0.744s/it]: train_loss_raw=1.0095, running_loss=0.9633, LR=0.000100
[2025-08-27 04:39:07,643][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036616] [Batch 02736/03080] [00:33:55/00:04:15, 0.744s/it]: train_loss_raw=1.0508, running_loss=0.9636, LR=0.000100
[2025-08-27 04:39:13,439][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036624] [Batch 02744/03080] [00:34:01/00:04:09, 0.744s/it]: train_loss_raw=1.0495, running_loss=0.9620, LR=0.000100
[2025-08-27 04:39:19,286][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036632] [Batch 02752/03080] [00:34:07/00:04:04, 0.744s/it]: train_loss_raw=1.0298, running_loss=0.9633, LR=0.000100
[2025-08-27 04:39:25,140][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036640] [Batch 02760/03080] [00:34:13/00:03:58, 0.744s/it]: train_loss_raw=0.9162, running_loss=0.9628, LR=0.000100
[2025-08-27 04:39:31,165][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036648] [Batch 02768/03080] [00:34:19/00:03:52, 0.744s/it]: train_loss_raw=0.9427, running_loss=0.9615, LR=0.000100
[2025-08-27 04:39:37,073][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036656] [Batch 02776/03080] [00:34:25/00:03:46, 0.744s/it]: train_loss_raw=0.9945, running_loss=0.9599, LR=0.000100
[2025-08-27 04:39:42,975][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036664] [Batch 02784/03080] [00:34:30/00:03:40, 0.744s/it]: train_loss_raw=1.0047, running_loss=0.9605, LR=0.000100
[2025-08-27 04:39:48,780][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036672] [Batch 02792/03080] [00:34:36/00:03:34, 0.744s/it]: train_loss_raw=0.9118, running_loss=0.9603, LR=0.000100
[2025-08-27 04:39:54,771][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036680] [Batch 02800/03080] [00:34:42/00:03:28, 0.744s/it]: train_loss_raw=1.0120, running_loss=0.9609, LR=0.000100
[2025-08-27 04:40:00,849][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036688] [Batch 02808/03080] [00:34:48/00:03:22, 0.744s/it]: train_loss_raw=1.0330, running_loss=0.9610, LR=0.000100
[2025-08-27 04:40:06,787][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036696] [Batch 02816/03080] [00:34:54/00:03:16, 0.744s/it]: train_loss_raw=0.8493, running_loss=0.9586, LR=0.000100
[2025-08-27 04:40:12,664][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036704] [Batch 02824/03080] [00:35:00/00:03:10, 0.744s/it]: train_loss_raw=0.9668, running_loss=0.9607, LR=0.000100
[2025-08-27 04:40:18,543][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036712] [Batch 02832/03080] [00:35:06/00:03:04, 0.744s/it]: train_loss_raw=1.0158, running_loss=0.9612, LR=0.000100
[2025-08-27 04:40:24,360][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036720] [Batch 02840/03080] [00:35:12/00:02:58, 0.744s/it]: train_loss_raw=0.9873, running_loss=0.9583, LR=0.000100
[2025-08-27 04:40:30,272][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036728] [Batch 02848/03080] [00:35:18/00:02:52, 0.744s/it]: train_loss_raw=0.9189, running_loss=0.9577, LR=0.000100
[2025-08-27 04:40:36,294][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036736] [Batch 02856/03080] [00:35:24/00:02:46, 0.744s/it]: train_loss_raw=0.9558, running_loss=0.9590, LR=0.000100
[2025-08-27 04:40:42,179][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036744] [Batch 02864/03080] [00:35:30/00:02:40, 0.744s/it]: train_loss_raw=0.9680, running_loss=0.9562, LR=0.000100
[2025-08-27 04:40:48,080][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036752] [Batch 02872/03080] [00:35:36/00:02:34, 0.744s/it]: train_loss_raw=0.8809, running_loss=0.9536, LR=0.000100
[2025-08-27 04:40:54,031][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036760] [Batch 02880/03080] [00:35:41/00:02:28, 0.744s/it]: train_loss_raw=0.9164, running_loss=0.9528, LR=0.000100
[2025-08-27 04:40:59,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036768] [Batch 02888/03080] [00:35:47/00:02:22, 0.744s/it]: train_loss_raw=1.0776, running_loss=0.9542, LR=0.000100
[2025-08-27 04:41:05,795][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036776] [Batch 02896/03080] [00:35:53/00:02:16, 0.744s/it]: train_loss_raw=0.8764, running_loss=0.9507, LR=0.000100
[2025-08-27 04:41:11,808][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036784] [Batch 02904/03080] [00:35:59/00:02:10, 0.744s/it]: train_loss_raw=0.9268, running_loss=0.9488, LR=0.000100
[2025-08-27 04:41:17,653][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036792] [Batch 02912/03080] [00:36:05/00:02:04, 0.744s/it]: train_loss_raw=0.9457, running_loss=0.9479, LR=0.000100
[2025-08-27 04:41:23,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036800] [Batch 02920/03080] [00:36:11/00:01:58, 0.744s/it]: train_loss_raw=0.9098, running_loss=0.9493, LR=0.000100
[2025-08-27 04:41:29,872][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036808] [Batch 02928/03080] [00:36:17/00:01:53, 0.744s/it]: train_loss_raw=0.9621, running_loss=0.9477, LR=0.000100
[2025-08-27 04:41:35,845][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036816] [Batch 02936/03080] [00:36:23/00:01:47, 0.744s/it]: train_loss_raw=0.8559, running_loss=0.9454, LR=0.000100
[2025-08-27 04:41:41,669][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036824] [Batch 02944/03080] [00:36:29/00:01:41, 0.744s/it]: train_loss_raw=0.9444, running_loss=0.9459, LR=0.000100
[2025-08-27 04:41:47,504][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036832] [Batch 02952/03080] [00:36:35/00:01:35, 0.744s/it]: train_loss_raw=0.9647, running_loss=0.9471, LR=0.000100
[2025-08-27 04:41:53,306][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036840] [Batch 02960/03080] [00:36:41/00:01:29, 0.744s/it]: train_loss_raw=1.0529, running_loss=0.9491, LR=0.000100
[2025-08-27 04:41:59,094][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036848] [Batch 02968/03080] [00:36:47/00:01:23, 0.744s/it]: train_loss_raw=0.8497, running_loss=0.9480, LR=0.000100
[2025-08-27 04:42:04,847][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036856] [Batch 02976/03080] [00:36:52/00:01:17, 0.744s/it]: train_loss_raw=0.9841, running_loss=0.9472, LR=0.000100
[2025-08-27 04:42:10,631][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036864] [Batch 02984/03080] [00:36:58/00:01:11, 0.743s/it]: train_loss_raw=0.8537, running_loss=0.9457, LR=0.000100
[2025-08-27 04:42:16,511][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036872] [Batch 02992/03080] [00:37:04/00:01:05, 0.743s/it]: train_loss_raw=0.9293, running_loss=0.9455, LR=0.000100
[2025-08-27 04:42:22,538][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036880] [Batch 03000/03080] [00:37:10/00:00:59, 0.743s/it]: train_loss_raw=0.9615, running_loss=0.9486, LR=0.000100
[2025-08-27 04:42:28,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036888] [Batch 03008/03080] [00:37:16/00:00:53, 0.743s/it]: train_loss_raw=0.9802, running_loss=0.9512, LR=0.000100
[2025-08-27 04:42:34,349][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036896] [Batch 03016/03080] [00:37:22/00:00:47, 0.743s/it]: train_loss_raw=1.0280, running_loss=0.9509, LR=0.000100
[2025-08-27 04:42:40,270][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036904] [Batch 03024/03080] [00:37:28/00:00:41, 0.743s/it]: train_loss_raw=0.9612, running_loss=0.9511, LR=0.000100
[2025-08-27 04:42:46,263][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036912] [Batch 03032/03080] [00:37:34/00:00:35, 0.743s/it]: train_loss_raw=0.9996, running_loss=0.9508, LR=0.000100
[2025-08-27 04:42:52,311][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036920] [Batch 03040/03080] [00:37:40/00:00:29, 0.744s/it]: train_loss_raw=0.9222, running_loss=0.9504, LR=0.000100
[2025-08-27 04:42:58,247][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036928] [Batch 03048/03080] [00:37:46/00:00:23, 0.743s/it]: train_loss_raw=0.8861, running_loss=0.9496, LR=0.000100
[2025-08-27 04:43:04,155][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036936] [Batch 03056/03080] [00:37:52/00:00:17, 0.743s/it]: train_loss_raw=0.8609, running_loss=0.9482, LR=0.000100
[2025-08-27 04:43:09,970][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036944] [Batch 03064/03080] [00:37:57/00:00:11, 0.743s/it]: train_loss_raw=0.8623, running_loss=0.9481, LR=0.000100
[2025-08-27 04:43:15,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036952] [Batch 03072/03080] [00:38:03/00:00:05, 0.743s/it]: train_loss_raw=1.0090, running_loss=0.9495, LR=0.000100
[2025-08-27 04:43:26,743][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036960] [Batch 03080/03080] [00:38:14/00:00:00, 0.745s/it]: train_loss_raw=0.8544, running_loss=0.9489, LR=0.000100
[2025-08-27 04:43:27,269][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-27 04:43:38,560][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00007/00310] [00:00:11/00:07:06, 1.411s/it]
[2025-08-27 04:43:50,757][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00015/00310] [00:00:23/00:07:11, 1.468s/it]
[2025-08-27 04:44:03,457][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00023/00310] [00:00:36/00:07:11, 1.508s/it]
[2025-08-27 04:44:15,985][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00031/00310] [00:00:48/00:07:03, 1.522s/it]
[2025-08-27 04:44:29,200][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00039/00310] [00:01:01/00:06:58, 1.548s/it]
[2025-08-27 04:44:41,709][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00047/00310] [00:01:14/00:06:46, 1.551s/it]
[2025-08-27 04:44:53,976][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00055/00310] [00:01:26/00:06:33, 1.548s/it]
[2025-08-27 04:45:06,926][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00063/00310] [00:01:39/00:06:23, 1.557s/it]
[2025-08-27 04:45:20,064][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00071/00310] [00:01:52/00:06:12, 1.567s/it]
[2025-08-27 04:45:32,694][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00079/00310] [00:02:05/00:06:00, 1.568s/it]
[2025-08-27 04:45:45,367][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00087/00310] [00:02:18/00:05:48, 1.569s/it]
[2025-08-27 04:45:57,852][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00095/00310] [00:02:30/00:05:35, 1.569s/it]
[2025-08-27 04:46:10,408][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00103/00310] [00:02:43/00:05:23, 1.569s/it]
[2025-08-27 04:46:22,970][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00111/00310] [00:02:55/00:05:10, 1.569s/it]
[2025-08-27 04:46:35,416][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00119/00310] [00:03:08/00:04:57, 1.568s/it]
[2025-08-27 04:46:48,112][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00127/00310] [00:03:20/00:04:45, 1.569s/it]
[2025-08-27 04:47:00,878][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00135/00310] [00:03:33/00:04:33, 1.571s/it]
[2025-08-27 04:47:13,898][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00143/00310] [00:03:46/00:04:21, 1.574s/it]
[2025-08-27 04:47:25,225][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00151/00310] [00:03:57/00:04:07, 1.565s/it]
[2025-08-27 04:47:36,662][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00159/00310] [00:04:09/00:03:53, 1.559s/it]
[2025-08-27 04:47:48,848][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00167/00310] [00:04:21/00:03:41, 1.557s/it]
[2025-08-27 04:48:00,257][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00175/00310] [00:04:32/00:03:27, 1.551s/it]
[2025-08-27 04:48:12,137][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00183/00310] [00:04:44/00:03:15, 1.548s/it]
[2025-08-27 04:48:25,009][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00191/00310] [00:04:57/00:03:02, 1.551s/it]
[2025-08-27 04:48:36,786][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00199/00310] [00:05:09/00:02:50, 1.548s/it]
[2025-08-27 04:48:48,736][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00207/00310] [00:05:21/00:02:37, 1.546s/it]
[2025-08-27 04:49:01,131][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00215/00310] [00:05:33/00:02:25, 1.546s/it]
[2025-08-27 04:49:13,132][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00223/00310] [00:05:45/00:02:12, 1.544s/it]
[2025-08-27 04:49:25,483][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00231/00310] [00:05:58/00:02:00, 1.544s/it]
[2025-08-27 04:49:37,800][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00239/00310] [00:06:10/00:01:48, 1.544s/it]
[2025-08-27 04:49:49,791][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00247/00310] [00:06:22/00:01:35, 1.542s/it]
[2025-08-27 04:50:02,141][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00255/00310] [00:06:34/00:01:23, 1.542s/it]
[2025-08-27 04:50:14,438][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00263/00310] [00:06:47/00:01:10, 1.542s/it]
[2025-08-27 04:50:26,465][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00271/00310] [00:06:59/00:00:58, 1.541s/it]
[2025-08-27 04:50:39,158][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00279/00310] [00:07:11/00:00:46, 1.542s/it]
[2025-08-27 04:50:51,955][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00287/00310] [00:07:24/00:00:33, 1.544s/it]
[2025-08-27 04:51:03,750][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00295/00310] [00:07:36/00:00:21, 1.542s/it]
[2025-08-27 04:51:16,386][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00303/00310] [00:07:49/00:00:09, 1.543s/it]
[2025-08-27 04:51:26,191][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=0.94889, valid_loss=1.82671
[2025-08-27 04:51:26,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-27 04:51:26,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.692
[2025-08-27 04:51:26,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.050
[2025-08-27 04:51:26,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.052
[2025-08-27 04:51:26,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.017
[2025-08-27 04:51:26,215][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 09:24:40, remaining time 14:07:00, 00:47:03 per epoch
[2025-08-27 04:51:32,776][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036968] [Batch 00008/03080] [00:00:06/00:39:30, 0.772s/it]: train_loss_raw=0.8900, running_loss=0.9568, LR=0.000100
[2025-08-27 04:51:38,632][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036976] [Batch 00016/03080] [00:00:12/00:38:23, 0.752s/it]: train_loss_raw=0.8770, running_loss=0.9546, LR=0.000100
[2025-08-27 04:51:44,565][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036984] [Batch 00024/03080] [00:00:17/00:38:07, 0.748s/it]: train_loss_raw=0.9970, running_loss=0.9517, LR=0.000100
[2025-08-27 04:51:50,593][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036992] [Batch 00032/03080] [00:00:23/00:38:04, 0.750s/it]: train_loss_raw=0.9517, running_loss=0.9484, LR=0.000100
[2025-08-27 04:51:56,625][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037000] [Batch 00040/03080] [00:00:30/00:38:01, 0.751s/it]: train_loss_raw=0.8809, running_loss=0.9450, LR=0.000100
[2025-08-27 04:52:02,576][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037008] [Batch 00048/03080] [00:00:35/00:37:52, 0.749s/it]: train_loss_raw=0.8142, running_loss=0.9424, LR=0.000100
[2025-08-27 04:52:08,612][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037016] [Batch 00056/03080] [00:00:42/00:37:48, 0.750s/it]: train_loss_raw=0.9778, running_loss=0.9408, LR=0.000100
[2025-08-27 04:52:14,656][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037024] [Batch 00064/03080] [00:00:48/00:37:44, 0.751s/it]: train_loss_raw=1.0067, running_loss=0.9437, LR=0.000100
[2025-08-27 04:52:20,532][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037032] [Batch 00072/03080] [00:00:53/00:37:33, 0.749s/it]: train_loss_raw=0.9609, running_loss=0.9436, LR=0.000100
[2025-08-27 04:52:26,631][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037040] [Batch 00080/03080] [00:01:00/00:37:31, 0.750s/it]: train_loss_raw=0.7831, running_loss=0.9397, LR=0.000100
[2025-08-27 04:52:32,593][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037048] [Batch 00088/03080] [00:01:05/00:37:23, 0.750s/it]: train_loss_raw=0.8878, running_loss=0.9395, LR=0.000100
[2025-08-27 04:52:38,442][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037056] [Batch 00096/03080] [00:01:11/00:37:12, 0.748s/it]: train_loss_raw=0.9563, running_loss=0.9402, LR=0.000100
[2025-08-27 04:52:44,365][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037064] [Batch 00104/03080] [00:01:17/00:37:05, 0.748s/it]: train_loss_raw=0.9158, running_loss=0.9392, LR=0.000100
[2025-08-27 04:52:50,309][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037072] [Batch 00112/03080] [00:01:23/00:36:58, 0.747s/it]: train_loss_raw=0.7958, running_loss=0.9373, LR=0.000100
[2025-08-27 04:52:56,283][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037080] [Batch 00120/03080] [00:01:29/00:36:52, 0.747s/it]: train_loss_raw=0.8791, running_loss=0.9359, LR=0.000100
[2025-08-27 04:53:02,116][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037088] [Batch 00128/03080] [00:01:35/00:36:42, 0.746s/it]: train_loss_raw=0.9487, running_loss=0.9347, LR=0.000100
[2025-08-27 04:53:08,065][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037096] [Batch 00136/03080] [00:01:41/00:36:36, 0.746s/it]: train_loss_raw=0.8850, running_loss=0.9332, LR=0.000100
[2025-08-27 04:53:13,994][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037104] [Batch 00144/03080] [00:01:47/00:36:29, 0.746s/it]: train_loss_raw=0.8368, running_loss=0.9325, LR=0.000100
[2025-08-27 04:53:19,867][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037112] [Batch 00152/03080] [00:01:53/00:36:21, 0.745s/it]: train_loss_raw=0.9141, running_loss=0.9303, LR=0.000100
[2025-08-27 04:53:25,652][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037120] [Batch 00160/03080] [00:01:59/00:36:12, 0.744s/it]: train_loss_raw=0.9194, running_loss=0.9251, LR=0.000100
[2025-08-27 04:53:31,546][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037128] [Batch 00168/03080] [00:02:04/00:36:05, 0.744s/it]: train_loss_raw=0.8972, running_loss=0.9235, LR=0.000100
[2025-08-27 04:53:37,425][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037136] [Batch 00176/03080] [00:02:10/00:35:58, 0.743s/it]: train_loss_raw=0.9138, running_loss=0.9236, LR=0.000100
[2025-08-27 04:53:43,323][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037144] [Batch 00184/03080] [00:02:16/00:35:51, 0.743s/it]: train_loss_raw=0.8688, running_loss=0.9228, LR=0.000100
[2025-08-27 04:53:49,161][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037152] [Batch 00192/03080] [00:02:22/00:35:44, 0.742s/it]: train_loss_raw=1.0252, running_loss=0.9252, LR=0.000100
[2025-08-27 04:53:54,953][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037160] [Batch 00200/03080] [00:02:28/00:35:36, 0.742s/it]: train_loss_raw=0.8617, running_loss=0.9251, LR=0.000100
[2025-08-27 04:54:00,905][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037168] [Batch 00208/03080] [00:02:34/00:35:30, 0.742s/it]: train_loss_raw=0.9282, running_loss=0.9263, LR=0.000100
[2025-08-27 04:54:06,912][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037176] [Batch 00216/03080] [00:02:40/00:35:25, 0.742s/it]: train_loss_raw=0.9446, running_loss=0.9263, LR=0.000100
[2025-08-27 04:54:12,797][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037184] [Batch 00224/03080] [00:02:46/00:35:18, 0.742s/it]: train_loss_raw=0.8119, running_loss=0.9242, LR=0.000100
[2025-08-27 04:54:18,804][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037192] [Batch 00232/03080] [00:02:52/00:35:13, 0.742s/it]: train_loss_raw=0.8786, running_loss=0.9233, LR=0.000100
[2025-08-27 04:54:24,753][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037200] [Batch 00240/03080] [00:02:58/00:35:08, 0.742s/it]: train_loss_raw=0.8825, running_loss=0.9199, LR=0.000100
[2025-08-27 04:54:30,635][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037208] [Batch 00248/03080] [00:03:04/00:35:01, 0.742s/it]: train_loss_raw=0.8931, running_loss=0.9170, LR=0.000100
[2025-08-27 04:54:36,617][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037216] [Batch 00256/03080] [00:03:10/00:34:56, 0.742s/it]: train_loss_raw=0.9897, running_loss=0.9156, LR=0.000100
[2025-08-27 04:54:42,410][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037224] [Batch 00264/03080] [00:03:15/00:34:48, 0.742s/it]: train_loss_raw=1.0489, running_loss=0.9175, LR=0.000100
[2025-08-27 04:54:48,212][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037232] [Batch 00272/03080] [00:03:21/00:34:41, 0.741s/it]: train_loss_raw=0.9059, running_loss=0.9203, LR=0.000100
[2025-08-27 04:54:54,131][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037240] [Batch 00280/03080] [00:03:27/00:34:35, 0.741s/it]: train_loss_raw=0.9405, running_loss=0.9192, LR=0.000100
[2025-08-27 04:55:00,174][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037248] [Batch 00288/03080] [00:03:33/00:34:30, 0.742s/it]: train_loss_raw=0.9337, running_loss=0.9192, LR=0.000100
[2025-08-27 04:55:06,124][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037256] [Batch 00296/03080] [00:03:39/00:34:24, 0.742s/it]: train_loss_raw=0.9340, running_loss=0.9186, LR=0.000100
[2025-08-27 04:55:12,040][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037264] [Batch 00304/03080] [00:03:45/00:34:18, 0.742s/it]: train_loss_raw=0.9604, running_loss=0.9204, LR=0.000100
[2025-08-27 04:55:17,958][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037272] [Batch 00312/03080] [00:03:51/00:34:12, 0.742s/it]: train_loss_raw=0.8766, running_loss=0.9213, LR=0.000100
[2025-08-27 04:55:23,879][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037280] [Batch 00320/03080] [00:03:57/00:34:06, 0.741s/it]: train_loss_raw=0.8999, running_loss=0.9215, LR=0.000100
[2025-08-27 04:55:29,747][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037288] [Batch 00328/03080] [00:04:03/00:34:00, 0.741s/it]: train_loss_raw=0.8598, running_loss=0.9221, LR=0.000100
[2025-08-27 04:55:35,672][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037296] [Batch 00336/03080] [00:04:09/00:33:54, 0.741s/it]: train_loss_raw=1.0781, running_loss=0.9228, LR=0.000100
[2025-08-27 04:55:41,585][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037304] [Batch 00344/03080] [00:04:14/00:33:47, 0.741s/it]: train_loss_raw=0.9718, running_loss=0.9219, LR=0.000100
[2025-08-27 04:55:47,467][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037312] [Batch 00352/03080] [00:04:20/00:33:41, 0.741s/it]: train_loss_raw=0.9179, running_loss=0.9220, LR=0.000100
[2025-08-27 04:55:53,322][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037320] [Batch 00360/03080] [00:04:26/00:33:35, 0.741s/it]: train_loss_raw=0.9906, running_loss=0.9211, LR=0.000100
[2025-08-27 04:55:59,110][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037328] [Batch 00368/03080] [00:04:32/00:33:28, 0.741s/it]: train_loss_raw=0.9448, running_loss=0.9164, LR=0.000100
[2025-08-27 04:56:05,044][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037336] [Batch 00376/03080] [00:04:38/00:33:22, 0.741s/it]: train_loss_raw=0.8351, running_loss=0.9162, LR=0.000100
[2025-08-27 04:56:10,902][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037344] [Batch 00384/03080] [00:04:44/00:33:16, 0.740s/it]: train_loss_raw=0.9680, running_loss=0.9163, LR=0.000100
[2025-08-27 04:56:16,906][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037352] [Batch 00392/03080] [00:04:50/00:33:10, 0.741s/it]: train_loss_raw=0.8946, running_loss=0.9165, LR=0.000100
[2025-08-27 04:56:22,888][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037360] [Batch 00400/03080] [00:04:56/00:33:05, 0.741s/it]: train_loss_raw=0.8706, running_loss=0.9163, LR=0.000100
[2025-08-27 04:56:29,021][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037368] [Batch 00408/03080] [00:05:02/00:33:00, 0.741s/it]: train_loss_raw=0.9251, running_loss=0.9198, LR=0.000100
[2025-08-27 04:56:35,144][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037376] [Batch 00416/03080] [00:05:08/00:32:55, 0.742s/it]: train_loss_raw=0.9923, running_loss=0.9189, LR=0.000100
[2025-08-27 04:56:41,130][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037384] [Batch 00424/03080] [00:05:14/00:32:50, 0.742s/it]: train_loss_raw=0.9661, running_loss=0.9172, LR=0.000100
[2025-08-27 04:56:47,061][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037392] [Batch 00432/03080] [00:05:20/00:32:44, 0.742s/it]: train_loss_raw=0.9202, running_loss=0.9188, LR=0.000100
[2025-08-27 04:56:53,029][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037400] [Batch 00440/03080] [00:05:26/00:32:38, 0.742s/it]: train_loss_raw=0.8211, running_loss=0.9180, LR=0.000100
[2025-08-27 04:56:58,887][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037408] [Batch 00448/03080] [00:05:32/00:32:32, 0.742s/it]: train_loss_raw=0.9937, running_loss=0.9196, LR=0.000100
[2025-08-27 04:57:04,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037416] [Batch 00456/03080] [00:05:38/00:32:26, 0.742s/it]: train_loss_raw=0.8679, running_loss=0.9211, LR=0.000100
[2025-08-27 04:57:10,793][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037424] [Batch 00464/03080] [00:05:44/00:32:20, 0.742s/it]: train_loss_raw=0.8326, running_loss=0.9204, LR=0.000100
[2025-08-27 04:57:16,729][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037432] [Batch 00472/03080] [00:05:50/00:32:14, 0.742s/it]: train_loss_raw=0.9262, running_loss=0.9192, LR=0.000100
[2025-08-27 04:57:22,647][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037440] [Batch 00480/03080] [00:05:56/00:32:08, 0.742s/it]: train_loss_raw=0.8654, running_loss=0.9193, LR=0.000100
[2025-08-27 04:57:28,560][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037448] [Batch 00488/03080] [00:06:01/00:32:02, 0.742s/it]: train_loss_raw=0.9110, running_loss=0.9176, LR=0.000100
[2025-08-27 04:57:34,633][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037456] [Batch 00496/03080] [00:06:08/00:31:57, 0.742s/it]: train_loss_raw=0.9831, running_loss=0.9189, LR=0.000100
[2025-08-27 04:57:40,616][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037464] [Batch 00504/03080] [00:06:14/00:31:51, 0.742s/it]: train_loss_raw=0.8818, running_loss=0.9183, LR=0.000100
[2025-08-27 04:57:46,636][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037472] [Batch 00512/03080] [00:06:20/00:31:46, 0.742s/it]: train_loss_raw=0.8530, running_loss=0.9167, LR=0.000100
[2025-08-27 04:57:52,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037480] [Batch 00520/03080] [00:06:25/00:31:40, 0.742s/it]: train_loss_raw=0.9515, running_loss=0.9166, LR=0.000100
[2025-08-27 04:57:58,522][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037488] [Batch 00528/03080] [00:06:31/00:31:34, 0.742s/it]: train_loss_raw=0.9298, running_loss=0.9180, LR=0.000100
[2025-08-27 04:58:04,432][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037496] [Batch 00536/03080] [00:06:37/00:31:28, 0.742s/it]: train_loss_raw=0.8792, running_loss=0.9190, LR=0.000100
[2025-08-27 04:58:10,617][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037504] [Batch 00544/03080] [00:06:44/00:31:23, 0.743s/it]: train_loss_raw=0.9606, running_loss=0.9182, LR=0.000100
[2025-08-27 04:58:16,866][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037512] [Batch 00552/03080] [00:06:50/00:31:18, 0.743s/it]: train_loss_raw=0.8979, running_loss=0.9165, LR=0.000100
[2025-08-27 04:58:22,602][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037520] [Batch 00560/03080] [00:06:55/00:31:11, 0.743s/it]: train_loss_raw=0.8624, running_loss=0.9155, LR=0.000100
[2025-08-27 04:58:28,548][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037528] [Batch 00568/03080] [00:07:01/00:31:06, 0.743s/it]: train_loss_raw=0.8705, running_loss=0.9128, LR=0.000100
[2025-08-27 04:58:34,536][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037536] [Batch 00576/03080] [00:07:07/00:31:00, 0.743s/it]: train_loss_raw=0.8729, running_loss=0.9084, LR=0.000100
[2025-08-27 04:58:40,337][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037544] [Batch 00584/03080] [00:07:13/00:30:53, 0.743s/it]: train_loss_raw=1.0138, running_loss=0.9084, LR=0.000100
[2025-08-27 04:58:46,187][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037552] [Batch 00592/03080] [00:07:19/00:30:47, 0.743s/it]: train_loss_raw=0.8710, running_loss=0.9091, LR=0.000100
[2025-08-27 04:58:52,134][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037560] [Batch 00600/03080] [00:07:25/00:30:41, 0.743s/it]: train_loss_raw=0.9112, running_loss=0.9090, LR=0.000100
[2025-08-27 04:58:58,439][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037568] [Batch 00608/03080] [00:07:31/00:30:37, 0.743s/it]: train_loss_raw=0.9234, running_loss=0.9093, LR=0.000100
[2025-08-27 04:59:04,443][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037576] [Batch 00616/03080] [00:07:37/00:30:31, 0.743s/it]: train_loss_raw=0.9914, running_loss=0.9121, LR=0.000100
[2025-08-27 04:59:10,337][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037584] [Batch 00624/03080] [00:07:43/00:30:25, 0.743s/it]: train_loss_raw=0.9621, running_loss=0.9149, LR=0.000100
[2025-08-27 04:59:16,305][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037592] [Batch 00632/03080] [00:07:49/00:30:19, 0.743s/it]: train_loss_raw=0.9483, running_loss=0.9151, LR=0.000100
[2025-08-27 04:59:22,304][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037600] [Batch 00640/03080] [00:07:55/00:30:13, 0.743s/it]: train_loss_raw=0.8822, running_loss=0.9137, LR=0.000100
[2025-08-27 04:59:28,294][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037608] [Batch 00648/03080] [00:08:01/00:30:07, 0.743s/it]: train_loss_raw=0.8747, running_loss=0.9117, LR=0.000100
[2025-08-27 04:59:34,176][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037616] [Batch 00656/03080] [00:08:07/00:30:01, 0.743s/it]: train_loss_raw=0.9620, running_loss=0.9141, LR=0.000100
[2025-08-27 04:59:40,157][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037624] [Batch 00664/03080] [00:08:13/00:29:55, 0.743s/it]: train_loss_raw=0.8156, running_loss=0.9131, LR=0.000100
[2025-08-27 04:59:46,052][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037632] [Batch 00672/03080] [00:08:19/00:29:49, 0.743s/it]: train_loss_raw=0.9909, running_loss=0.9135, LR=0.000100
[2025-08-27 04:59:51,964][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037640] [Batch 00680/03080] [00:08:25/00:29:43, 0.743s/it]: train_loss_raw=0.8543, running_loss=0.9131, LR=0.000100
[2025-08-27 04:59:57,841][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037648] [Batch 00688/03080] [00:08:31/00:29:37, 0.743s/it]: train_loss_raw=0.9303, running_loss=0.9127, LR=0.000100
[2025-08-27 05:00:04,076][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037656] [Batch 00696/03080] [00:08:37/00:29:32, 0.743s/it]: train_loss_raw=0.9336, running_loss=0.9104, LR=0.000100
[2025-08-27 05:00:09,985][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037664] [Batch 00704/03080] [00:08:43/00:29:26, 0.743s/it]: train_loss_raw=0.8983, running_loss=0.9087, LR=0.000100
[2025-08-27 05:00:15,890][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037672] [Batch 00712/03080] [00:08:49/00:29:20, 0.743s/it]: train_loss_raw=0.8902, running_loss=0.9074, LR=0.000100
[2025-08-27 05:00:21,925][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037680] [Batch 00720/03080] [00:08:55/00:29:14, 0.744s/it]: train_loss_raw=0.9091, running_loss=0.9080, LR=0.000100
[2025-08-27 05:00:27,948][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037688] [Batch 00728/03080] [00:09:01/00:29:08, 0.744s/it]: train_loss_raw=0.9236, running_loss=0.9099, LR=0.000100
[2025-08-27 05:00:33,869][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037696] [Batch 00736/03080] [00:09:07/00:29:02, 0.744s/it]: train_loss_raw=0.8945, running_loss=0.9096, LR=0.000100
[2025-08-27 05:00:39,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037704] [Batch 00744/03080] [00:09:13/00:28:56, 0.743s/it]: train_loss_raw=0.9178, running_loss=0.9108, LR=0.000100
[2025-08-27 05:00:45,639][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037712] [Batch 00752/03080] [00:09:19/00:28:50, 0.743s/it]: train_loss_raw=0.9886, running_loss=0.9120, LR=0.000100
[2025-08-27 05:00:51,548][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037720] [Batch 00760/03080] [00:09:24/00:28:44, 0.743s/it]: train_loss_raw=0.9194, running_loss=0.9111, LR=0.000100
[2025-08-27 05:00:57,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037728] [Batch 00768/03080] [00:09:30/00:28:38, 0.743s/it]: train_loss_raw=0.9571, running_loss=0.9096, LR=0.000100
[2025-08-27 05:01:03,456][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037736] [Batch 00776/03080] [00:09:36/00:28:32, 0.743s/it]: train_loss_raw=0.9182, running_loss=0.9083, LR=0.000100
[2025-08-27 05:01:09,347][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037744] [Batch 00784/03080] [00:09:42/00:28:26, 0.743s/it]: train_loss_raw=0.8683, running_loss=0.9053, LR=0.000100
[2025-08-27 05:01:15,303][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037752] [Batch 00792/03080] [00:09:48/00:28:20, 0.743s/it]: train_loss_raw=0.8974, running_loss=0.9057, LR=0.000100
[2025-08-27 05:01:21,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037760] [Batch 00800/03080] [00:09:54/00:28:15, 0.743s/it]: train_loss_raw=0.9372, running_loss=0.9076, LR=0.000100
[2025-08-27 05:01:27,112][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037768] [Batch 00808/03080] [00:10:00/00:28:08, 0.743s/it]: train_loss_raw=0.8548, running_loss=0.9085, LR=0.000100
[2025-08-27 05:01:33,053][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037776] [Batch 00816/03080] [00:10:06/00:28:02, 0.743s/it]: train_loss_raw=0.9291, running_loss=0.9093, LR=0.000100
[2025-08-27 05:01:38,964][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037784] [Batch 00824/03080] [00:10:12/00:27:56, 0.743s/it]: train_loss_raw=0.8662, running_loss=0.9078, LR=0.000100
[2025-08-27 05:01:44,960][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037792] [Batch 00832/03080] [00:10:18/00:27:50, 0.743s/it]: train_loss_raw=0.9852, running_loss=0.9088, LR=0.000100
[2025-08-27 05:01:50,914][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037800] [Batch 00840/03080] [00:10:24/00:27:44, 0.743s/it]: train_loss_raw=0.9015, running_loss=0.9085, LR=0.000100
[2025-08-27 05:01:56,824][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037808] [Batch 00848/03080] [00:10:30/00:27:38, 0.743s/it]: train_loss_raw=0.8555, running_loss=0.9071, LR=0.000100
[2025-08-27 05:02:02,815][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037816] [Batch 00856/03080] [00:10:36/00:27:32, 0.743s/it]: train_loss_raw=0.8861, running_loss=0.9061, LR=0.000100
[2025-08-27 05:02:08,782][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037824] [Batch 00864/03080] [00:10:42/00:27:27, 0.743s/it]: train_loss_raw=0.9579, running_loss=0.9082, LR=0.000100
[2025-08-27 05:02:14,621][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037832] [Batch 00872/03080] [00:10:48/00:27:20, 0.743s/it]: train_loss_raw=0.9702, running_loss=0.9109, LR=0.000100
[2025-08-27 05:02:20,506][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037840] [Batch 00880/03080] [00:10:53/00:27:14, 0.743s/it]: train_loss_raw=0.9403, running_loss=0.9113, LR=0.000100
[2025-08-27 05:02:26,405][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037848] [Batch 00888/03080] [00:10:59/00:27:08, 0.743s/it]: train_loss_raw=0.9605, running_loss=0.9109, LR=0.000100
[2025-08-27 05:02:32,363][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037856] [Batch 00896/03080] [00:11:05/00:27:02, 0.743s/it]: train_loss_raw=0.8214, running_loss=0.9118, LR=0.000100
[2025-08-27 05:02:38,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037864] [Batch 00904/03080] [00:11:11/00:26:56, 0.743s/it]: train_loss_raw=0.9339, running_loss=0.9103, LR=0.000100
[2025-08-27 05:02:44,279][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037872] [Batch 00912/03080] [00:11:17/00:26:50, 0.743s/it]: train_loss_raw=0.9706, running_loss=0.9083, LR=0.000100
[2025-08-27 05:02:50,178][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037880] [Batch 00920/03080] [00:11:23/00:26:44, 0.743s/it]: train_loss_raw=0.8823, running_loss=0.9079, LR=0.000100
[2025-08-27 05:02:56,061][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037888] [Batch 00928/03080] [00:11:29/00:26:38, 0.743s/it]: train_loss_raw=0.8741, running_loss=0.9070, LR=0.000100
[2025-08-27 05:03:02,008][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037896] [Batch 00936/03080] [00:11:35/00:26:32, 0.743s/it]: train_loss_raw=0.9729, running_loss=0.9073, LR=0.000100
[2025-08-27 05:03:07,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037904] [Batch 00944/03080] [00:11:41/00:26:26, 0.743s/it]: train_loss_raw=0.8959, running_loss=0.9093, LR=0.000100
[2025-08-27 05:03:13,922][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037912] [Batch 00952/03080] [00:11:47/00:26:21, 0.743s/it]: train_loss_raw=0.8918, running_loss=0.9092, LR=0.000100
[2025-08-27 05:03:19,852][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037920] [Batch 00960/03080] [00:11:53/00:26:15, 0.743s/it]: train_loss_raw=0.7612, running_loss=0.9072, LR=0.000100
[2025-08-27 05:03:25,746][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037928] [Batch 00968/03080] [00:11:59/00:26:09, 0.743s/it]: train_loss_raw=0.9756, running_loss=0.9071, LR=0.000100
[2025-08-27 05:03:31,696][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037936] [Batch 00976/03080] [00:12:05/00:26:03, 0.743s/it]: train_loss_raw=0.8671, running_loss=0.9061, LR=0.000100
[2025-08-27 05:03:37,581][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037944] [Batch 00984/03080] [00:12:10/00:25:57, 0.743s/it]: train_loss_raw=1.0456, running_loss=0.9068, LR=0.000100
[2025-08-27 05:03:43,565][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037952] [Batch 00992/03080] [00:12:16/00:25:51, 0.743s/it]: train_loss_raw=0.9900, running_loss=0.9053, LR=0.000100
[2025-08-27 05:03:49,763][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037960] [Batch 01000/03080] [00:12:23/00:25:45, 0.743s/it]: train_loss_raw=0.8744, running_loss=0.9050, LR=0.000100
[2025-08-27 05:03:55,639][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037968] [Batch 01008/03080] [00:12:29/00:25:39, 0.743s/it]: train_loss_raw=0.8636, running_loss=0.9050, LR=0.000100
[2025-08-27 05:04:01,527][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037976] [Batch 01016/03080] [00:12:34/00:25:33, 0.743s/it]: train_loss_raw=0.9943, running_loss=0.9080, LR=0.000100
[2025-08-27 05:04:07,525][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037984] [Batch 01024/03080] [00:12:40/00:25:27, 0.743s/it]: train_loss_raw=0.9198, running_loss=0.9072, LR=0.000100
[2025-08-27 05:04:13,474][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037992] [Batch 01032/03080] [00:12:46/00:25:21, 0.743s/it]: train_loss_raw=0.9810, running_loss=0.9073, LR=0.000100
[2025-08-27 05:04:19,312][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038000] [Batch 01040/03080] [00:12:52/00:25:15, 0.743s/it]: train_loss_raw=0.9354, running_loss=0.9081, LR=0.000100
[2025-08-27 05:04:29,249][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038008] [Batch 01048/03080] [00:13:02/00:25:17, 0.747s/it]: train_loss_raw=0.9575, running_loss=0.9104, LR=0.000100
[2025-08-27 05:04:35,138][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038016] [Batch 01056/03080] [00:13:08/00:25:11, 0.747s/it]: train_loss_raw=1.0224, running_loss=0.9098, LR=0.000100
[2025-08-27 05:04:41,022][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038024] [Batch 01064/03080] [00:13:14/00:25:05, 0.747s/it]: train_loss_raw=0.8563, running_loss=0.9102, LR=0.000100
[2025-08-27 05:04:46,939][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038032] [Batch 01072/03080] [00:13:20/00:24:59, 0.747s/it]: train_loss_raw=0.9245, running_loss=0.9076, LR=0.000100
[2025-08-27 05:04:52,881][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038040] [Batch 01080/03080] [00:13:26/00:24:53, 0.747s/it]: train_loss_raw=0.9250, running_loss=0.9071, LR=0.000100
[2025-08-27 05:04:58,888][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038048] [Batch 01088/03080] [00:13:32/00:24:47, 0.747s/it]: train_loss_raw=0.9043, running_loss=0.9085, LR=0.000100
[2025-08-27 05:05:04,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038056] [Batch 01096/03080] [00:13:38/00:24:41, 0.747s/it]: train_loss_raw=0.9770, running_loss=0.9078, LR=0.000100
[2025-08-27 05:05:10,789][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038064] [Batch 01104/03080] [00:13:44/00:24:35, 0.747s/it]: train_loss_raw=0.9117, running_loss=0.9090, LR=0.000100
[2025-08-27 05:05:16,871][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038072] [Batch 01112/03080] [00:13:50/00:24:29, 0.747s/it]: train_loss_raw=0.9175, running_loss=0.9078, LR=0.000100
[2025-08-27 05:05:22,827][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038080] [Batch 01120/03080] [00:13:56/00:24:23, 0.747s/it]: train_loss_raw=0.8268, running_loss=0.9083, LR=0.000100
[2025-08-27 05:05:28,729][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038088] [Batch 01128/03080] [00:14:02/00:24:17, 0.747s/it]: train_loss_raw=1.0143, running_loss=0.9082, LR=0.000100
[2025-08-27 05:05:34,992][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038096] [Batch 01136/03080] [00:14:08/00:24:11, 0.747s/it]: train_loss_raw=0.8033, running_loss=0.9064, LR=0.000100
[2025-08-27 05:05:40,999][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038104] [Batch 01144/03080] [00:14:14/00:24:05, 0.747s/it]: train_loss_raw=0.9391, running_loss=0.9068, LR=0.000100
[2025-08-27 05:05:46,899][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038112] [Batch 01152/03080] [00:14:20/00:23:59, 0.747s/it]: train_loss_raw=0.7392, running_loss=0.9042, LR=0.000100
[2025-08-27 05:05:52,776][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038120] [Batch 01160/03080] [00:14:26/00:23:53, 0.747s/it]: train_loss_raw=1.0077, running_loss=0.9068, LR=0.000100
[2025-08-27 05:05:58,606][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038128] [Batch 01168/03080] [00:14:32/00:23:47, 0.747s/it]: train_loss_raw=0.9108, running_loss=0.9053, LR=0.000100
[2025-08-27 05:06:04,450][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038136] [Batch 01176/03080] [00:14:37/00:23:41, 0.746s/it]: train_loss_raw=0.9729, running_loss=0.9091, LR=0.000100
[2025-08-27 05:06:10,363][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038144] [Batch 01184/03080] [00:14:43/00:23:35, 0.746s/it]: train_loss_raw=0.9485, running_loss=0.9087, LR=0.000100
[2025-08-27 05:06:16,356][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038152] [Batch 01192/03080] [00:14:49/00:23:29, 0.746s/it]: train_loss_raw=0.9521, running_loss=0.9103, LR=0.000100
[2025-08-27 05:06:22,387][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038160] [Batch 01200/03080] [00:14:55/00:23:23, 0.746s/it]: train_loss_raw=0.9113, running_loss=0.9086, LR=0.000100
[2025-08-27 05:06:28,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038168] [Batch 01208/03080] [00:15:01/00:23:17, 0.746s/it]: train_loss_raw=0.9113, running_loss=0.9074, LR=0.000100
[2025-08-27 05:06:34,261][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038176] [Batch 01216/03080] [00:15:07/00:23:11, 0.746s/it]: train_loss_raw=0.9600, running_loss=0.9067, LR=0.000100
[2025-08-27 05:06:40,241][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038184] [Batch 01224/03080] [00:15:13/00:23:05, 0.746s/it]: train_loss_raw=0.9269, running_loss=0.9082, LR=0.000100
[2025-08-27 05:06:46,144][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038192] [Batch 01232/03080] [00:15:19/00:22:59, 0.746s/it]: train_loss_raw=0.9615, running_loss=0.9085, LR=0.000100
[2025-08-27 05:06:52,054][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038200] [Batch 01240/03080] [00:15:25/00:22:53, 0.746s/it]: train_loss_raw=0.9276, running_loss=0.9083, LR=0.000100
[2025-08-27 05:06:58,005][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038208] [Batch 01248/03080] [00:15:31/00:22:47, 0.746s/it]: train_loss_raw=0.7656, running_loss=0.9040, LR=0.000100
[2025-08-27 05:07:03,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038216] [Batch 01256/03080] [00:15:37/00:22:41, 0.746s/it]: train_loss_raw=0.9392, running_loss=0.9027, LR=0.000100
[2025-08-27 05:07:09,734][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038224] [Batch 01264/03080] [00:15:43/00:22:35, 0.746s/it]: train_loss_raw=0.8299, running_loss=0.9000, LR=0.000100
[2025-08-27 05:07:15,660][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038232] [Batch 01272/03080] [00:15:49/00:22:28, 0.746s/it]: train_loss_raw=0.8422, running_loss=0.9015, LR=0.000100
[2025-08-27 05:07:21,807][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038240] [Batch 01280/03080] [00:15:55/00:22:23, 0.746s/it]: train_loss_raw=0.9210, running_loss=0.9014, LR=0.000100
[2025-08-27 05:07:27,791][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038248] [Batch 01288/03080] [00:16:01/00:22:17, 0.746s/it]: train_loss_raw=0.9472, running_loss=0.9034, LR=0.000100
[2025-08-27 05:07:33,770][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038256] [Batch 01296/03080] [00:16:07/00:22:11, 0.746s/it]: train_loss_raw=0.9074, running_loss=0.9009, LR=0.000100
[2025-08-27 05:07:39,746][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038264] [Batch 01304/03080] [00:16:13/00:22:05, 0.746s/it]: train_loss_raw=0.8634, running_loss=0.9035, LR=0.000100
[2025-08-27 05:07:45,665][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038272] [Batch 01312/03080] [00:16:19/00:21:59, 0.746s/it]: train_loss_raw=0.9821, running_loss=0.8988, LR=0.000100
[2025-08-27 05:07:51,593][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038280] [Batch 01320/03080] [00:16:24/00:21:53, 0.746s/it]: train_loss_raw=0.7559, running_loss=0.8990, LR=0.000100
[2025-08-27 05:07:57,482][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038288] [Batch 01328/03080] [00:16:30/00:21:47, 0.746s/it]: train_loss_raw=0.9610, running_loss=0.8985, LR=0.000100
[2025-08-27 05:08:03,336][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038296] [Batch 01336/03080] [00:16:36/00:21:41, 0.746s/it]: train_loss_raw=0.9238, running_loss=0.8983, LR=0.000100
[2025-08-27 05:08:09,218][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038304] [Batch 01344/03080] [00:16:42/00:21:35, 0.746s/it]: train_loss_raw=0.9171, running_loss=0.8999, LR=0.000100
[2025-08-27 05:08:14,943][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038312] [Batch 01352/03080] [00:16:48/00:21:28, 0.746s/it]: train_loss_raw=0.8627, running_loss=0.9019, LR=0.000100
[2025-08-27 05:08:20,830][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038320] [Batch 01360/03080] [00:16:54/00:21:22, 0.746s/it]: train_loss_raw=0.9832, running_loss=0.9026, LR=0.000100
[2025-08-27 05:08:26,706][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038328] [Batch 01368/03080] [00:17:00/00:21:16, 0.746s/it]: train_loss_raw=0.9229, running_loss=0.9033, LR=0.000100
[2025-08-27 05:08:32,660][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038336] [Batch 01376/03080] [00:17:06/00:21:10, 0.746s/it]: train_loss_raw=0.9084, running_loss=0.9041, LR=0.000100
[2025-08-27 05:08:38,610][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038344] [Batch 01384/03080] [00:17:12/00:21:04, 0.746s/it]: train_loss_raw=0.9145, running_loss=0.9024, LR=0.000100
[2025-08-27 05:08:44,577][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038352] [Batch 01392/03080] [00:17:17/00:20:58, 0.746s/it]: train_loss_raw=0.9544, running_loss=0.9012, LR=0.000100
[2025-08-27 05:08:50,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038360] [Batch 01400/03080] [00:17:23/00:20:52, 0.746s/it]: train_loss_raw=0.9357, running_loss=0.9010, LR=0.000100
[2025-08-27 05:08:56,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038368] [Batch 01408/03080] [00:17:29/00:20:46, 0.746s/it]: train_loss_raw=0.8764, running_loss=0.9003, LR=0.000100
[2025-08-27 05:09:02,439][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038376] [Batch 01416/03080] [00:17:35/00:20:40, 0.746s/it]: train_loss_raw=0.8784, running_loss=0.8998, LR=0.000100
[2025-08-27 05:09:08,360][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038384] [Batch 01424/03080] [00:17:41/00:20:34, 0.746s/it]: train_loss_raw=0.9278, running_loss=0.9025, LR=0.000100
[2025-08-27 05:09:14,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038392] [Batch 01432/03080] [00:17:47/00:20:28, 0.746s/it]: train_loss_raw=0.7914, running_loss=0.9034, LR=0.000100
[2025-08-27 05:09:20,107][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038400] [Batch 01440/03080] [00:17:53/00:20:22, 0.745s/it]: train_loss_raw=0.9972, running_loss=0.9058, LR=0.000100
[2025-08-27 05:09:26,029][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038408] [Batch 01448/03080] [00:17:59/00:20:16, 0.745s/it]: train_loss_raw=0.9284, running_loss=0.9051, LR=0.000100
[2025-08-27 05:09:32,026][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038416] [Batch 01456/03080] [00:18:05/00:20:10, 0.745s/it]: train_loss_raw=0.8817, running_loss=0.9034, LR=0.000100
[2025-08-27 05:09:37,968][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038424] [Batch 01464/03080] [00:18:11/00:20:04, 0.745s/it]: train_loss_raw=0.7626, running_loss=0.8998, LR=0.000100
[2025-08-27 05:09:43,871][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038432] [Batch 01472/03080] [00:18:17/00:19:58, 0.745s/it]: train_loss_raw=0.9808, running_loss=0.8994, LR=0.000100
[2025-08-27 05:09:49,827][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038440] [Batch 01480/03080] [00:18:23/00:19:52, 0.745s/it]: train_loss_raw=0.9063, running_loss=0.9023, LR=0.000100
[2025-08-27 05:09:55,622][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038448] [Batch 01488/03080] [00:18:29/00:19:46, 0.745s/it]: train_loss_raw=0.9039, running_loss=0.9007, LR=0.000100
[2025-08-27 05:10:01,650][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038456] [Batch 01496/03080] [00:18:35/00:19:40, 0.745s/it]: train_loss_raw=0.9219, running_loss=0.9006, LR=0.000100
[2025-08-27 05:10:07,579][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038464] [Batch 01504/03080] [00:18:40/00:19:34, 0.745s/it]: train_loss_raw=0.9020, running_loss=0.9015, LR=0.000100
[2025-08-27 05:10:13,871][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038472] [Batch 01512/03080] [00:18:47/00:19:29, 0.746s/it]: train_loss_raw=0.8938, running_loss=0.8993, LR=0.000100
[2025-08-27 05:10:19,691][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038480] [Batch 01520/03080] [00:18:53/00:19:22, 0.745s/it]: train_loss_raw=0.8979, running_loss=0.8979, LR=0.000100
[2025-08-27 05:10:25,730][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038488] [Batch 01528/03080] [00:18:59/00:19:17, 0.746s/it]: train_loss_raw=0.9595, running_loss=0.8973, LR=0.000100
[2025-08-27 05:10:31,631][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038496] [Batch 01536/03080] [00:19:05/00:19:10, 0.745s/it]: train_loss_raw=0.9185, running_loss=0.8989, LR=0.000100
[2025-08-27 05:10:37,546][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038504] [Batch 01544/03080] [00:19:10/00:19:04, 0.745s/it]: train_loss_raw=0.9724, running_loss=0.8986, LR=0.000100
[2025-08-27 05:10:43,620][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038512] [Batch 01552/03080] [00:19:17/00:18:59, 0.746s/it]: train_loss_raw=0.8873, running_loss=0.9003, LR=0.000100
[2025-08-27 05:10:49,685][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038520] [Batch 01560/03080] [00:19:23/00:18:53, 0.746s/it]: train_loss_raw=0.9106, running_loss=0.9000, LR=0.000100
[2025-08-27 05:10:55,641][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038528] [Batch 01568/03080] [00:19:29/00:18:47, 0.746s/it]: train_loss_raw=1.0106, running_loss=0.8988, LR=0.000100
[2025-08-27 05:11:01,477][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038536] [Batch 01576/03080] [00:19:34/00:18:41, 0.745s/it]: train_loss_raw=0.8547, running_loss=0.8967, LR=0.000100
[2025-08-27 05:11:07,420][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038544] [Batch 01584/03080] [00:19:40/00:18:35, 0.745s/it]: train_loss_raw=0.9190, running_loss=0.8985, LR=0.000100
[2025-08-27 05:11:13,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038552] [Batch 01592/03080] [00:19:46/00:18:29, 0.745s/it]: train_loss_raw=0.8749, running_loss=0.8965, LR=0.000100
[2025-08-27 05:11:19,224][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038560] [Batch 01600/03080] [00:19:52/00:18:23, 0.745s/it]: train_loss_raw=0.9550, running_loss=0.8951, LR=0.000100
[2025-08-27 05:11:25,165][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038568] [Batch 01608/03080] [00:19:58/00:18:17, 0.745s/it]: train_loss_raw=0.8803, running_loss=0.8941, LR=0.000100
[2025-08-27 05:11:31,072][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038576] [Batch 01616/03080] [00:20:04/00:18:11, 0.745s/it]: train_loss_raw=0.9040, running_loss=0.8941, LR=0.000100
[2025-08-27 05:11:36,893][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038584] [Batch 01624/03080] [00:20:10/00:18:05, 0.745s/it]: train_loss_raw=0.8600, running_loss=0.8938, LR=0.000100
[2025-08-27 05:11:42,789][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038592] [Batch 01632/03080] [00:20:16/00:17:59, 0.745s/it]: train_loss_raw=0.7767, running_loss=0.8919, LR=0.000100
[2025-08-27 05:11:48,801][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038600] [Batch 01640/03080] [00:20:22/00:17:53, 0.745s/it]: train_loss_raw=0.7759, running_loss=0.8901, LR=0.000100
[2025-08-27 05:11:54,677][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038608] [Batch 01648/03080] [00:20:28/00:17:47, 0.745s/it]: train_loss_raw=0.8777, running_loss=0.8898, LR=0.000100
[2025-08-27 05:12:00,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038616] [Batch 01656/03080] [00:20:33/00:17:41, 0.745s/it]: train_loss_raw=0.9325, running_loss=0.8897, LR=0.000100
[2025-08-27 05:12:06,401][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038624] [Batch 01664/03080] [00:20:39/00:17:35, 0.745s/it]: train_loss_raw=0.9541, running_loss=0.8932, LR=0.000100
[2025-08-27 05:12:12,268][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038632] [Batch 01672/03080] [00:20:45/00:17:28, 0.745s/it]: train_loss_raw=0.8228, running_loss=0.8910, LR=0.000100
[2025-08-27 05:12:18,183][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038640] [Batch 01680/03080] [00:20:51/00:17:22, 0.745s/it]: train_loss_raw=0.9120, running_loss=0.8901, LR=0.000100
[2025-08-27 05:12:24,177][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038648] [Batch 01688/03080] [00:20:57/00:17:17, 0.745s/it]: train_loss_raw=0.9522, running_loss=0.8919, LR=0.000100
[2025-08-27 05:12:30,044][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038656] [Batch 01696/03080] [00:21:03/00:17:11, 0.745s/it]: train_loss_raw=0.8590, running_loss=0.8903, LR=0.000100
[2025-08-27 05:12:35,962][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038664] [Batch 01704/03080] [00:21:09/00:17:05, 0.745s/it]: train_loss_raw=0.9286, running_loss=0.8934, LR=0.000100
[2025-08-27 05:12:41,878][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038672] [Batch 01712/03080] [00:21:15/00:16:59, 0.745s/it]: train_loss_raw=0.9149, running_loss=0.8933, LR=0.000100
[2025-08-27 05:12:47,723][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038680] [Batch 01720/03080] [00:21:21/00:16:52, 0.745s/it]: train_loss_raw=0.9996, running_loss=0.8954, LR=0.000100
[2025-08-27 05:12:53,654][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038688] [Batch 01728/03080] [00:21:27/00:16:46, 0.745s/it]: train_loss_raw=0.9004, running_loss=0.8930, LR=0.000100
[2025-08-27 05:12:59,488][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038696] [Batch 01736/03080] [00:21:32/00:16:40, 0.745s/it]: train_loss_raw=0.8228, running_loss=0.8945, LR=0.000100
[2025-08-27 05:13:05,336][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038704] [Batch 01744/03080] [00:21:38/00:16:34, 0.745s/it]: train_loss_raw=0.9277, running_loss=0.8929, LR=0.000100
[2025-08-27 05:13:11,180][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038712] [Batch 01752/03080] [00:21:44/00:16:28, 0.745s/it]: train_loss_raw=0.9106, running_loss=0.8954, LR=0.000100
[2025-08-27 05:13:16,962][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038720] [Batch 01760/03080] [00:21:50/00:16:22, 0.745s/it]: train_loss_raw=0.9252, running_loss=0.8955, LR=0.000100
[2025-08-27 05:13:22,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038728] [Batch 01768/03080] [00:21:56/00:16:16, 0.744s/it]: train_loss_raw=0.8609, running_loss=0.8969, LR=0.000100
[2025-08-27 05:13:28,604][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038736] [Batch 01776/03080] [00:22:02/00:16:10, 0.744s/it]: train_loss_raw=0.8871, running_loss=0.8987, LR=0.000100
[2025-08-27 05:13:34,695][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038744] [Batch 01784/03080] [00:22:08/00:16:04, 0.744s/it]: train_loss_raw=1.0387, running_loss=0.9019, LR=0.000100
[2025-08-27 05:13:40,832][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038752] [Batch 01792/03080] [00:22:14/00:15:58, 0.745s/it]: train_loss_raw=0.8834, running_loss=0.8985, LR=0.000100
[2025-08-27 05:13:46,789][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038760] [Batch 01800/03080] [00:22:20/00:15:53, 0.745s/it]: train_loss_raw=0.9315, running_loss=0.8998, LR=0.000100
[2025-08-27 05:13:52,772][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038768] [Batch 01808/03080] [00:22:26/00:15:47, 0.745s/it]: train_loss_raw=0.9599, running_loss=0.8976, LR=0.000100
[2025-08-27 05:13:58,683][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038776] [Batch 01816/03080] [00:22:32/00:15:41, 0.745s/it]: train_loss_raw=0.8631, running_loss=0.8979, LR=0.000100
[2025-08-27 05:14:04,659][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038784] [Batch 01824/03080] [00:22:38/00:15:35, 0.745s/it]: train_loss_raw=0.9579, running_loss=0.8969, LR=0.000100
[2025-08-27 05:14:10,419][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038792] [Batch 01832/03080] [00:22:43/00:15:29, 0.744s/it]: train_loss_raw=0.9771, running_loss=0.8997, LR=0.000100
[2025-08-27 05:14:16,424][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038800] [Batch 01840/03080] [00:22:49/00:15:23, 0.744s/it]: train_loss_raw=0.8957, running_loss=0.8994, LR=0.000100
[2025-08-27 05:14:22,454][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038808] [Batch 01848/03080] [00:22:55/00:15:17, 0.745s/it]: train_loss_raw=0.8082, running_loss=0.8981, LR=0.000100
[2025-08-27 05:14:28,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038816] [Batch 01856/03080] [00:23:01/00:15:11, 0.745s/it]: train_loss_raw=0.9773, running_loss=0.9007, LR=0.000100
[2025-08-27 05:14:34,359][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038824] [Batch 01864/03080] [00:23:07/00:15:05, 0.745s/it]: train_loss_raw=1.0002, running_loss=0.9030, LR=0.000100
[2025-08-27 05:14:40,386][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038832] [Batch 01872/03080] [00:23:13/00:14:59, 0.745s/it]: train_loss_raw=0.9428, running_loss=0.9028, LR=0.000100
[2025-08-27 05:14:46,349][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038840] [Batch 01880/03080] [00:23:19/00:14:53, 0.745s/it]: train_loss_raw=0.8621, running_loss=0.9021, LR=0.000100
[2025-08-27 05:14:52,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038848] [Batch 01888/03080] [00:23:25/00:14:47, 0.745s/it]: train_loss_raw=0.8261, running_loss=0.8985, LR=0.000100
[2025-08-27 05:14:58,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038856] [Batch 01896/03080] [00:23:31/00:14:41, 0.745s/it]: train_loss_raw=0.8970, running_loss=0.8984, LR=0.000100
[2025-08-27 05:15:04,159][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038864] [Batch 01904/03080] [00:23:37/00:14:35, 0.745s/it]: train_loss_raw=0.8551, running_loss=0.8977, LR=0.000100
[2025-08-27 05:15:10,142][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038872] [Batch 01912/03080] [00:23:43/00:14:29, 0.745s/it]: train_loss_raw=0.9094, running_loss=0.8968, LR=0.000100
[2025-08-27 05:15:16,100][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038880] [Batch 01920/03080] [00:23:49/00:14:23, 0.745s/it]: train_loss_raw=0.8740, running_loss=0.8954, LR=0.000100
[2025-08-27 05:15:22,209][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038888] [Batch 01928/03080] [00:23:55/00:14:17, 0.745s/it]: train_loss_raw=1.0334, running_loss=0.8946, LR=0.000100
[2025-08-27 05:15:28,215][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038896] [Batch 01936/03080] [00:24:01/00:14:11, 0.745s/it]: train_loss_raw=0.9798, running_loss=0.8954, LR=0.000100
[2025-08-27 05:15:34,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038904] [Batch 01944/03080] [00:24:07/00:14:05, 0.745s/it]: train_loss_raw=0.9097, running_loss=0.8952, LR=0.000100
[2025-08-27 05:15:40,231][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038912] [Batch 01952/03080] [00:24:13/00:14:00, 0.745s/it]: train_loss_raw=0.8572, running_loss=0.8937, LR=0.000100
[2025-08-27 05:15:46,199][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038920] [Batch 01960/03080] [00:24:19/00:13:54, 0.745s/it]: train_loss_raw=0.8611, running_loss=0.8914, LR=0.000100
[2025-08-27 05:15:52,207][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038928] [Batch 01968/03080] [00:24:25/00:13:48, 0.745s/it]: train_loss_raw=0.8265, running_loss=0.8917, LR=0.000100
[2025-08-27 05:15:58,192][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038936] [Batch 01976/03080] [00:24:31/00:13:42, 0.745s/it]: train_loss_raw=0.8636, running_loss=0.8917, LR=0.000100
[2025-08-27 05:16:04,147][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038944] [Batch 01984/03080] [00:24:37/00:13:36, 0.745s/it]: train_loss_raw=0.8829, running_loss=0.8921, LR=0.000100
[2025-08-27 05:16:10,090][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038952] [Batch 01992/03080] [00:24:43/00:13:30, 0.745s/it]: train_loss_raw=0.8776, running_loss=0.8935, LR=0.000100
[2025-08-27 05:16:16,066][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038960] [Batch 02000/03080] [00:24:49/00:13:24, 0.745s/it]: train_loss_raw=0.8461, running_loss=0.8927, LR=0.000100
[2025-08-27 05:16:22,051][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038968] [Batch 02008/03080] [00:24:55/00:13:18, 0.745s/it]: train_loss_raw=0.9765, running_loss=0.8897, LR=0.000100
[2025-08-27 05:16:27,979][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038976] [Batch 02016/03080] [00:25:01/00:13:12, 0.745s/it]: train_loss_raw=0.9004, running_loss=0.8892, LR=0.000100
[2025-08-27 05:16:33,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038984] [Batch 02024/03080] [00:25:07/00:13:06, 0.745s/it]: train_loss_raw=0.8580, running_loss=0.8869, LR=0.000100
[2025-08-27 05:16:39,676][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038992] [Batch 02032/03080] [00:25:13/00:13:00, 0.745s/it]: train_loss_raw=0.8577, running_loss=0.8904, LR=0.000100
[2025-08-27 05:16:45,468][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039000] [Batch 02040/03080] [00:25:18/00:12:54, 0.745s/it]: train_loss_raw=0.8944, running_loss=0.8871, LR=0.000100
[2025-08-27 05:16:51,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039008] [Batch 02048/03080] [00:25:24/00:12:48, 0.745s/it]: train_loss_raw=0.9946, running_loss=0.8872, LR=0.000100
[2025-08-27 05:16:57,386][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039016] [Batch 02056/03080] [00:25:30/00:12:42, 0.745s/it]: train_loss_raw=0.8499, running_loss=0.8881, LR=0.000100
[2025-08-27 05:17:03,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039024] [Batch 02064/03080] [00:25:36/00:12:36, 0.744s/it]: train_loss_raw=0.9674, running_loss=0.8867, LR=0.000100
[2025-08-27 05:17:09,100][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039032] [Batch 02072/03080] [00:25:42/00:12:30, 0.744s/it]: train_loss_raw=0.9240, running_loss=0.8907, LR=0.000100
[2025-08-27 05:17:14,987][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039040] [Batch 02080/03080] [00:25:48/00:12:24, 0.744s/it]: train_loss_raw=0.8264, running_loss=0.8918, LR=0.000100
[2025-08-27 05:17:20,987][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039048] [Batch 02088/03080] [00:25:54/00:12:18, 0.744s/it]: train_loss_raw=0.8417, running_loss=0.8883, LR=0.000100
[2025-08-27 05:17:26,943][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039056] [Batch 02096/03080] [00:26:00/00:12:12, 0.744s/it]: train_loss_raw=0.8931, running_loss=0.8851, LR=0.000100
[2025-08-27 05:17:32,719][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039064] [Batch 02104/03080] [00:26:06/00:12:06, 0.744s/it]: train_loss_raw=0.8213, running_loss=0.8839, LR=0.000100
[2025-08-27 05:17:38,504][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039072] [Batch 02112/03080] [00:26:11/00:12:00, 0.744s/it]: train_loss_raw=0.9397, running_loss=0.8848, LR=0.000100
[2025-08-27 05:17:44,318][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039080] [Batch 02120/03080] [00:26:17/00:11:54, 0.744s/it]: train_loss_raw=0.8352, running_loss=0.8850, LR=0.000100
[2025-08-27 05:17:50,176][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039088] [Batch 02128/03080] [00:26:23/00:11:48, 0.744s/it]: train_loss_raw=0.8503, running_loss=0.8840, LR=0.000100
[2025-08-27 05:17:55,919][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039096] [Batch 02136/03080] [00:26:29/00:11:42, 0.744s/it]: train_loss_raw=0.7624, running_loss=0.8820, LR=0.000100
[2025-08-27 05:18:01,753][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039104] [Batch 02144/03080] [00:26:35/00:11:36, 0.744s/it]: train_loss_raw=0.8458, running_loss=0.8822, LR=0.000100
[2025-08-27 05:18:07,606][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039112] [Batch 02152/03080] [00:26:41/00:11:30, 0.744s/it]: train_loss_raw=0.9303, running_loss=0.8813, LR=0.000100
[2025-08-27 05:18:13,513][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039120] [Batch 02160/03080] [00:26:46/00:11:24, 0.744s/it]: train_loss_raw=0.9457, running_loss=0.8813, LR=0.000100
[2025-08-27 05:18:19,487][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039128] [Batch 02168/03080] [00:26:52/00:11:18, 0.744s/it]: train_loss_raw=0.8517, running_loss=0.8798, LR=0.000100
[2025-08-27 05:18:25,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039136] [Batch 02176/03080] [00:26:58/00:11:12, 0.744s/it]: train_loss_raw=0.9299, running_loss=0.8791, LR=0.000100
[2025-08-27 05:18:31,299][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039144] [Batch 02184/03080] [00:27:04/00:11:06, 0.744s/it]: train_loss_raw=0.8966, running_loss=0.8793, LR=0.000100
[2025-08-27 05:18:37,047][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039152] [Batch 02192/03080] [00:27:10/00:11:00, 0.744s/it]: train_loss_raw=0.7746, running_loss=0.8780, LR=0.000100
[2025-08-27 05:18:42,921][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039160] [Batch 02200/03080] [00:27:16/00:10:54, 0.744s/it]: train_loss_raw=0.7916, running_loss=0.8792, LR=0.000100
[2025-08-27 05:18:48,971][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039168] [Batch 02208/03080] [00:27:22/00:10:48, 0.744s/it]: train_loss_raw=0.8900, running_loss=0.8798, LR=0.000100
[2025-08-27 05:18:54,969][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039176] [Batch 02216/03080] [00:27:28/00:10:42, 0.744s/it]: train_loss_raw=0.8818, running_loss=0.8840, LR=0.000100
[2025-08-27 05:19:00,875][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039184] [Batch 02224/03080] [00:27:34/00:10:36, 0.744s/it]: train_loss_raw=0.9414, running_loss=0.8818, LR=0.000100
[2025-08-27 05:19:06,817][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039192] [Batch 02232/03080] [00:27:40/00:10:30, 0.744s/it]: train_loss_raw=0.8923, running_loss=0.8833, LR=0.000100
[2025-08-27 05:19:12,690][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039200] [Batch 02240/03080] [00:27:46/00:10:24, 0.744s/it]: train_loss_raw=0.8395, running_loss=0.8815, LR=0.000100
[2025-08-27 05:19:18,263][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039208] [Batch 02248/03080] [00:27:51/00:10:18, 0.744s/it]: train_loss_raw=0.9526, running_loss=0.8835, LR=0.000100
[2025-08-27 05:19:23,920][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039216] [Batch 02256/03080] [00:27:57/00:10:12, 0.743s/it]: train_loss_raw=0.8985, running_loss=0.8843, LR=0.000100
[2025-08-27 05:19:29,859][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039224] [Batch 02264/03080] [00:28:03/00:10:06, 0.743s/it]: train_loss_raw=0.9410, running_loss=0.8833, LR=0.000100
[2025-08-27 05:19:35,813][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039232] [Batch 02272/03080] [00:28:09/00:10:00, 0.743s/it]: train_loss_raw=0.8782, running_loss=0.8819, LR=0.000100
[2025-08-27 05:19:41,754][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039240] [Batch 02280/03080] [00:28:15/00:09:54, 0.743s/it]: train_loss_raw=0.7617, running_loss=0.8787, LR=0.000100
[2025-08-27 05:19:47,604][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039248] [Batch 02288/03080] [00:28:21/00:09:48, 0.743s/it]: train_loss_raw=0.9231, running_loss=0.8822, LR=0.000100
[2025-08-27 05:19:53,436][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039256] [Batch 02296/03080] [00:28:26/00:09:42, 0.743s/it]: train_loss_raw=0.8314, running_loss=0.8819, LR=0.000100
[2025-08-27 05:19:59,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039264] [Batch 02304/03080] [00:28:32/00:09:36, 0.743s/it]: train_loss_raw=0.9355, running_loss=0.8814, LR=0.000100
[2025-08-27 05:20:05,021][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039272] [Batch 02312/03080] [00:28:38/00:09:30, 0.743s/it]: train_loss_raw=0.7982, running_loss=0.8802, LR=0.000100
[2025-08-27 05:20:10,872][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039280] [Batch 02320/03080] [00:28:44/00:09:24, 0.743s/it]: train_loss_raw=0.9420, running_loss=0.8810, LR=0.000100
[2025-08-27 05:20:16,704][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039288] [Batch 02328/03080] [00:28:50/00:09:18, 0.743s/it]: train_loss_raw=0.8533, running_loss=0.8819, LR=0.000100
[2025-08-27 05:20:22,500][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039296] [Batch 02336/03080] [00:28:55/00:09:12, 0.743s/it]: train_loss_raw=0.8046, running_loss=0.8838, LR=0.000100
[2025-08-27 05:20:28,394][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039304] [Batch 02344/03080] [00:29:01/00:09:06, 0.743s/it]: train_loss_raw=0.9809, running_loss=0.8856, LR=0.000100
[2025-08-27 05:20:34,352][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039312] [Batch 02352/03080] [00:29:07/00:09:00, 0.743s/it]: train_loss_raw=0.8973, running_loss=0.8859, LR=0.000100
[2025-08-27 05:20:40,178][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039320] [Batch 02360/03080] [00:29:13/00:08:54, 0.743s/it]: train_loss_raw=0.8273, running_loss=0.8836, LR=0.000100
[2025-08-27 05:20:46,011][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039328] [Batch 02368/03080] [00:29:19/00:08:49, 0.743s/it]: train_loss_raw=0.7644, running_loss=0.8835, LR=0.000100
[2025-08-27 05:20:51,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039336] [Batch 02376/03080] [00:29:25/00:08:43, 0.743s/it]: train_loss_raw=0.8606, running_loss=0.8859, LR=0.000100
[2025-08-27 05:20:57,898][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039344] [Batch 02384/03080] [00:29:31/00:08:37, 0.743s/it]: train_loss_raw=0.8117, running_loss=0.8845, LR=0.000100
[2025-08-27 05:21:03,783][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039352] [Batch 02392/03080] [00:29:37/00:08:31, 0.743s/it]: train_loss_raw=0.8890, running_loss=0.8817, LR=0.000100
[2025-08-27 05:21:09,626][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039360] [Batch 02400/03080] [00:29:43/00:08:25, 0.743s/it]: train_loss_raw=0.8653, running_loss=0.8839, LR=0.000100
[2025-08-27 05:21:15,557][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039368] [Batch 02408/03080] [00:29:48/00:08:19, 0.743s/it]: train_loss_raw=0.8748, running_loss=0.8816, LR=0.000100
[2025-08-27 05:21:21,531][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039376] [Batch 02416/03080] [00:29:54/00:08:13, 0.743s/it]: train_loss_raw=0.8958, running_loss=0.8822, LR=0.000100
[2025-08-27 05:21:27,324][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039384] [Batch 02424/03080] [00:30:00/00:08:07, 0.743s/it]: train_loss_raw=0.7660, running_loss=0.8820, LR=0.000100
[2025-08-27 05:21:33,240][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039392] [Batch 02432/03080] [00:30:06/00:08:01, 0.743s/it]: train_loss_raw=0.9579, running_loss=0.8832, LR=0.000100
[2025-08-27 05:21:39,123][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039400] [Batch 02440/03080] [00:30:12/00:07:55, 0.743s/it]: train_loss_raw=0.8070, running_loss=0.8820, LR=0.000100
[2025-08-27 05:21:44,979][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039408] [Batch 02448/03080] [00:30:18/00:07:49, 0.743s/it]: train_loss_raw=0.9163, running_loss=0.8800, LR=0.000100
[2025-08-27 05:21:50,933][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039416] [Batch 02456/03080] [00:30:24/00:07:43, 0.743s/it]: train_loss_raw=0.9376, running_loss=0.8802, LR=0.000100
[2025-08-27 05:21:56,836][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039424] [Batch 02464/03080] [00:30:30/00:07:37, 0.743s/it]: train_loss_raw=0.8351, running_loss=0.8794, LR=0.000100
[2025-08-27 05:22:02,745][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039432] [Batch 02472/03080] [00:30:36/00:07:31, 0.743s/it]: train_loss_raw=0.8617, running_loss=0.8774, LR=0.000100
[2025-08-27 05:22:08,597][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039440] [Batch 02480/03080] [00:30:41/00:07:25, 0.743s/it]: train_loss_raw=0.9360, running_loss=0.8756, LR=0.000100
[2025-08-27 05:22:14,500][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039448] [Batch 02488/03080] [00:30:47/00:07:19, 0.743s/it]: train_loss_raw=0.7903, running_loss=0.8732, LR=0.000100
[2025-08-27 05:22:20,228][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039456] [Batch 02496/03080] [00:30:53/00:07:13, 0.743s/it]: train_loss_raw=0.9482, running_loss=0.8733, LR=0.000100
[2025-08-27 05:22:26,069][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039464] [Batch 02504/03080] [00:30:59/00:07:07, 0.743s/it]: train_loss_raw=1.0251, running_loss=0.8737, LR=0.000100
[2025-08-27 05:22:31,915][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039472] [Batch 02512/03080] [00:31:05/00:07:01, 0.743s/it]: train_loss_raw=0.7780, running_loss=0.8742, LR=0.000100
[2025-08-27 05:22:37,674][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039480] [Batch 02520/03080] [00:31:11/00:06:55, 0.742s/it]: train_loss_raw=0.9182, running_loss=0.8738, LR=0.000100
[2025-08-27 05:22:43,555][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039488] [Batch 02528/03080] [00:31:16/00:06:49, 0.742s/it]: train_loss_raw=0.9677, running_loss=0.8754, LR=0.000100
[2025-08-27 05:22:49,296][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039496] [Batch 02536/03080] [00:31:22/00:06:43, 0.742s/it]: train_loss_raw=0.8747, running_loss=0.8774, LR=0.000100
[2025-08-27 05:22:54,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039504] [Batch 02544/03080] [00:31:28/00:06:37, 0.742s/it]: train_loss_raw=0.8818, running_loss=0.8796, LR=0.000100
[2025-08-27 05:23:00,975][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039512] [Batch 02552/03080] [00:31:34/00:06:31, 0.742s/it]: train_loss_raw=0.8786, running_loss=0.8804, LR=0.000100
[2025-08-27 05:23:06,915][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039520] [Batch 02560/03080] [00:31:40/00:06:26, 0.742s/it]: train_loss_raw=0.8295, running_loss=0.8806, LR=0.000100
[2025-08-27 05:23:12,872][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039528] [Batch 02568/03080] [00:31:46/00:06:20, 0.742s/it]: train_loss_raw=0.8824, running_loss=0.8786, LR=0.000100
[2025-08-27 05:23:18,714][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039536] [Batch 02576/03080] [00:31:52/00:06:14, 0.742s/it]: train_loss_raw=0.9302, running_loss=0.8787, LR=0.000100
[2025-08-27 05:23:24,644][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039544] [Batch 02584/03080] [00:31:58/00:06:08, 0.742s/it]: train_loss_raw=0.8998, running_loss=0.8778, LR=0.000100
[2025-08-27 05:23:30,548][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039552] [Batch 02592/03080] [00:32:03/00:06:02, 0.742s/it]: train_loss_raw=0.8765, running_loss=0.8750, LR=0.000100
[2025-08-27 05:23:36,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039560] [Batch 02600/03080] [00:32:09/00:05:56, 0.742s/it]: train_loss_raw=0.8556, running_loss=0.8736, LR=0.000100
[2025-08-27 05:23:42,373][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039568] [Batch 02608/03080] [00:32:15/00:05:50, 0.742s/it]: train_loss_raw=0.8695, running_loss=0.8761, LR=0.000100
[2025-08-27 05:23:48,221][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039576] [Batch 02616/03080] [00:32:21/00:05:44, 0.742s/it]: train_loss_raw=0.8716, running_loss=0.8776, LR=0.000100
[2025-08-27 05:23:54,250][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039584] [Batch 02624/03080] [00:32:27/00:05:38, 0.742s/it]: train_loss_raw=0.8764, running_loss=0.8771, LR=0.000100
[2025-08-27 05:24:00,182][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039592] [Batch 02632/03080] [00:32:33/00:05:32, 0.742s/it]: train_loss_raw=0.9199, running_loss=0.8781, LR=0.000100
[2025-08-27 05:24:05,865][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039600] [Batch 02640/03080] [00:32:39/00:05:26, 0.742s/it]: train_loss_raw=0.7318, running_loss=0.8773, LR=0.000100
[2025-08-27 05:24:11,631][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039608] [Batch 02648/03080] [00:32:45/00:05:20, 0.742s/it]: train_loss_raw=0.8232, running_loss=0.8786, LR=0.000100
[2025-08-27 05:24:17,540][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039616] [Batch 02656/03080] [00:32:50/00:05:14, 0.742s/it]: train_loss_raw=0.7893, running_loss=0.8747, LR=0.000100
[2025-08-27 05:24:23,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039624] [Batch 02664/03080] [00:32:56/00:05:08, 0.742s/it]: train_loss_raw=0.8729, running_loss=0.8723, LR=0.000100
[2025-08-27 05:24:29,318][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039632] [Batch 02672/03080] [00:33:02/00:05:02, 0.742s/it]: train_loss_raw=0.9095, running_loss=0.8752, LR=0.000100
[2025-08-27 05:24:35,255][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039640] [Batch 02680/03080] [00:33:08/00:04:56, 0.742s/it]: train_loss_raw=0.8286, running_loss=0.8733, LR=0.000100
[2025-08-27 05:24:41,354][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039648] [Batch 02688/03080] [00:33:14/00:04:50, 0.742s/it]: train_loss_raw=0.8600, running_loss=0.8736, LR=0.000100
[2025-08-27 05:24:47,276][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039656] [Batch 02696/03080] [00:33:20/00:04:44, 0.742s/it]: train_loss_raw=0.7232, running_loss=0.8751, LR=0.000100
[2025-08-27 05:24:53,150][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039664] [Batch 02704/03080] [00:33:26/00:04:39, 0.742s/it]: train_loss_raw=0.8476, running_loss=0.8747, LR=0.000100
[2025-08-27 05:24:58,949][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039672] [Batch 02712/03080] [00:33:32/00:04:33, 0.742s/it]: train_loss_raw=0.8985, running_loss=0.8731, LR=0.000100
[2025-08-27 05:25:04,731][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039680] [Batch 02720/03080] [00:33:38/00:04:27, 0.742s/it]: train_loss_raw=0.7643, running_loss=0.8729, LR=0.000100
[2025-08-27 05:25:10,614][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039688] [Batch 02728/03080] [00:33:44/00:04:21, 0.742s/it]: train_loss_raw=0.9631, running_loss=0.8750, LR=0.000100
[2025-08-27 05:25:16,592][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039696] [Batch 02736/03080] [00:33:49/00:04:15, 0.742s/it]: train_loss_raw=0.8757, running_loss=0.8747, LR=0.000100
[2025-08-27 05:25:22,328][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039704] [Batch 02744/03080] [00:33:55/00:04:09, 0.742s/it]: train_loss_raw=0.9267, running_loss=0.8767, LR=0.000100
[2025-08-27 05:25:28,140][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039712] [Batch 02752/03080] [00:34:01/00:04:03, 0.742s/it]: train_loss_raw=0.8732, running_loss=0.8731, LR=0.000100
[2025-08-27 05:25:33,998][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039720] [Batch 02760/03080] [00:34:07/00:03:57, 0.742s/it]: train_loss_raw=0.9195, running_loss=0.8722, LR=0.000100
[2025-08-27 05:25:39,776][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039728] [Batch 02768/03080] [00:34:13/00:03:51, 0.742s/it]: train_loss_raw=0.8095, running_loss=0.8718, LR=0.000100
[2025-08-27 05:25:45,542][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039736] [Batch 02776/03080] [00:34:18/00:03:45, 0.742s/it]: train_loss_raw=0.9457, running_loss=0.8720, LR=0.000100
[2025-08-27 05:25:51,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039744] [Batch 02784/03080] [00:34:24/00:03:39, 0.742s/it]: train_loss_raw=0.8234, running_loss=0.8716, LR=0.000100
[2025-08-27 05:25:57,299][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039752] [Batch 02792/03080] [00:34:30/00:03:33, 0.742s/it]: train_loss_raw=0.9648, running_loss=0.8721, LR=0.000100
[2025-08-27 05:26:03,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039760] [Batch 02800/03080] [00:34:36/00:03:27, 0.742s/it]: train_loss_raw=0.8948, running_loss=0.8722, LR=0.000100
[2025-08-27 05:26:09,154][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039768] [Batch 02808/03080] [00:34:42/00:03:21, 0.742s/it]: train_loss_raw=0.8402, running_loss=0.8724, LR=0.000100
[2025-08-27 05:26:15,121][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039776] [Batch 02816/03080] [00:34:48/00:03:15, 0.742s/it]: train_loss_raw=0.8481, running_loss=0.8687, LR=0.000100
[2025-08-27 05:26:21,176][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039784] [Batch 02824/03080] [00:34:54/00:03:09, 0.742s/it]: train_loss_raw=0.7731, running_loss=0.8697, LR=0.000100
[2025-08-27 05:26:27,286][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039792] [Batch 02832/03080] [00:35:00/00:03:03, 0.742s/it]: train_loss_raw=0.8462, running_loss=0.8680, LR=0.000100
[2025-08-27 05:26:33,197][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039800] [Batch 02840/03080] [00:35:06/00:02:58, 0.742s/it]: train_loss_raw=0.7222, running_loss=0.8666, LR=0.000100
[2025-08-27 05:26:39,020][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039808] [Batch 02848/03080] [00:35:12/00:02:52, 0.742s/it]: train_loss_raw=0.8183, running_loss=0.8669, LR=0.000100
[2025-08-27 05:26:44,822][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039816] [Batch 02856/03080] [00:35:18/00:02:46, 0.742s/it]: train_loss_raw=0.8666, running_loss=0.8667, LR=0.000100
[2025-08-27 05:26:50,762][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039824] [Batch 02864/03080] [00:35:24/00:02:40, 0.742s/it]: train_loss_raw=0.7813, running_loss=0.8639, LR=0.000100
[2025-08-27 05:26:56,561][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039832] [Batch 02872/03080] [00:35:29/00:02:34, 0.742s/it]: train_loss_raw=0.8979, running_loss=0.8650, LR=0.000100
[2025-08-27 05:27:02,414][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039840] [Batch 02880/03080] [00:35:35/00:02:28, 0.742s/it]: train_loss_raw=0.9234, running_loss=0.8664, LR=0.000100
[2025-08-27 05:27:08,222][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039848] [Batch 02888/03080] [00:35:41/00:02:22, 0.742s/it]: train_loss_raw=0.8300, running_loss=0.8662, LR=0.000100
[2025-08-27 05:27:14,040][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039856] [Batch 02896/03080] [00:35:47/00:02:16, 0.742s/it]: train_loss_raw=0.9530, running_loss=0.8669, LR=0.000100
[2025-08-27 05:27:19,881][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039864] [Batch 02904/03080] [00:35:53/00:02:10, 0.741s/it]: train_loss_raw=0.8171, running_loss=0.8639, LR=0.000100
[2025-08-27 05:27:25,852][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039872] [Batch 02912/03080] [00:35:59/00:02:04, 0.742s/it]: train_loss_raw=0.8165, running_loss=0.8640, LR=0.000100
[2025-08-27 05:27:31,836][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039880] [Batch 02920/03080] [00:36:05/00:01:58, 0.742s/it]: train_loss_raw=0.8106, running_loss=0.8657, LR=0.000100
[2025-08-27 05:27:37,721][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039888] [Batch 02928/03080] [00:36:11/00:01:52, 0.742s/it]: train_loss_raw=0.7998, running_loss=0.8679, LR=0.000100
[2025-08-27 05:27:43,617][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039896] [Batch 02936/03080] [00:36:17/00:01:46, 0.741s/it]: train_loss_raw=0.9133, running_loss=0.8694, LR=0.000100
[2025-08-27 05:27:49,394][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039904] [Batch 02944/03080] [00:36:22/00:01:40, 0.741s/it]: train_loss_raw=0.8880, running_loss=0.8693, LR=0.000100
[2025-08-27 05:27:55,323][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039912] [Batch 02952/03080] [00:36:28/00:01:34, 0.741s/it]: train_loss_raw=0.9055, running_loss=0.8713, LR=0.000100
[2025-08-27 05:28:01,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039920] [Batch 02960/03080] [00:36:34/00:01:28, 0.741s/it]: train_loss_raw=0.9087, running_loss=0.8706, LR=0.000100
[2025-08-27 05:28:07,091][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039928] [Batch 02968/03080] [00:36:40/00:01:23, 0.741s/it]: train_loss_raw=0.7674, running_loss=0.8675, LR=0.000100
[2025-08-27 05:28:12,974][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039936] [Batch 02976/03080] [00:36:46/00:01:17, 0.741s/it]: train_loss_raw=0.8647, running_loss=0.8661, LR=0.000100
[2025-08-27 05:28:18,871][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039944] [Batch 02984/03080] [00:36:52/00:01:11, 0.741s/it]: train_loss_raw=0.8367, running_loss=0.8653, LR=0.000100
[2025-08-27 05:28:24,800][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039952] [Batch 02992/03080] [00:36:58/00:01:05, 0.741s/it]: train_loss_raw=0.9048, running_loss=0.8671, LR=0.000100
[2025-08-27 05:28:30,808][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039960] [Batch 03000/03080] [00:37:04/00:00:59, 0.741s/it]: train_loss_raw=0.7961, running_loss=0.8670, LR=0.000100
[2025-08-27 05:28:36,588][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039968] [Batch 03008/03080] [00:37:09/00:00:53, 0.741s/it]: train_loss_raw=0.8856, running_loss=0.8645, LR=0.000100
[2025-08-27 05:28:42,467][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039976] [Batch 03016/03080] [00:37:15/00:00:47, 0.741s/it]: train_loss_raw=0.7756, running_loss=0.8648, LR=0.000100
[2025-08-27 05:28:48,338][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039984] [Batch 03024/03080] [00:37:21/00:00:41, 0.741s/it]: train_loss_raw=0.8644, running_loss=0.8666, LR=0.000100
[2025-08-27 05:28:54,279][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039992] [Batch 03032/03080] [00:37:27/00:00:35, 0.741s/it]: train_loss_raw=0.8086, running_loss=0.8669, LR=0.000100
[2025-08-27 05:28:59,998][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040000] [Batch 03040/03080] [00:37:33/00:00:29, 0.741s/it]: train_loss_raw=0.8790, running_loss=0.8690, LR=0.000100
[2025-08-27 05:29:09,733][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040008] [Batch 03048/03080] [00:37:43/00:00:23, 0.742s/it]: train_loss_raw=0.7564, running_loss=0.8683, LR=0.000100
[2025-08-27 05:29:15,502][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040016] [Batch 03056/03080] [00:37:48/00:00:17, 0.742s/it]: train_loss_raw=0.8390, running_loss=0.8657, LR=0.000100
[2025-08-27 05:29:21,235][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040024] [Batch 03064/03080] [00:37:54/00:00:11, 0.742s/it]: train_loss_raw=0.9083, running_loss=0.8636, LR=0.000100
[2025-08-27 05:29:27,016][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040032] [Batch 03072/03080] [00:38:00/00:00:05, 0.742s/it]: train_loss_raw=0.8369, running_loss=0.8600, LR=0.000100
[2025-08-27 05:29:32,785][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040040] [Batch 03080/03080] [00:38:06/00:00:00, 0.742s/it]: train_loss_raw=0.8920, running_loss=0.8586, LR=0.000100
[2025-08-27 05:29:33,259][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-27 05:29:44,979][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00007/00310] [00:00:11/00:07:22, 1.465s/it]
[2025-08-27 05:29:56,912][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00015/00310] [00:00:23/00:07:14, 1.478s/it]
[2025-08-27 05:30:09,357][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00023/00310] [00:00:36/00:07:10, 1.504s/it]
[2025-08-27 05:30:22,211][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00031/00310] [00:00:48/00:07:05, 1.530s/it]
[2025-08-27 05:30:35,188][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00039/00310] [00:01:01/00:06:58, 1.548s/it]
[2025-08-27 05:30:47,627][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00047/00310] [00:01:14/00:06:45, 1.549s/it]
[2025-08-27 05:31:00,409][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00055/00310] [00:01:27/00:06:35, 1.556s/it]
[2025-08-27 05:31:12,928][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00063/00310] [00:01:39/00:06:23, 1.557s/it]
[2025-08-27 05:31:26,256][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00071/00310] [00:01:52/00:06:13, 1.569s/it]
[2025-08-27 05:31:39,322][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00079/00310] [00:02:06/00:06:02, 1.576s/it]
[2025-08-27 05:31:52,316][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00087/00310] [00:02:19/00:05:50, 1.580s/it]
[2025-08-27 05:32:04,873][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00095/00310] [00:02:31/00:05:37, 1.579s/it]
[2025-08-27 05:32:18,018][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00103/00310] [00:02:44/00:05:26, 1.584s/it]
[2025-08-27 05:32:30,535][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00111/00310] [00:02:57/00:05:13, 1.583s/it]
[2025-08-27 05:32:43,549][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00119/00310] [00:03:10/00:05:01, 1.586s/it]
[2025-08-27 05:32:56,870][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00127/00310] [00:03:23/00:04:49, 1.591s/it]
[2025-08-27 05:33:09,656][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00135/00310] [00:03:36/00:04:36, 1.591s/it]
[2025-08-27 05:33:22,257][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00143/00310] [00:03:48/00:04:23, 1.590s/it]
[2025-08-27 05:33:33,894][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00151/00310] [00:04:00/00:04:10, 1.583s/it]
[2025-08-27 05:33:45,310][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00159/00310] [00:04:12/00:03:56, 1.575s/it]
[2025-08-27 05:33:58,156][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00167/00310] [00:04:24/00:03:43, 1.577s/it]
[2025-08-27 05:34:09,190][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00175/00310] [00:04:35/00:03:30, 1.568s/it]
[2025-08-27 05:34:20,793][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00183/00310] [00:04:47/00:03:16, 1.563s/it]
[2025-08-27 05:34:33,731][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00191/00310] [00:05:00/00:03:04, 1.565s/it]
[2025-08-27 05:34:45,660][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00199/00310] [00:05:12/00:02:51, 1.562s/it]
[2025-08-27 05:34:57,314][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00207/00310] [00:05:24/00:02:38, 1.558s/it]
[2025-08-27 05:35:09,136][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00215/00310] [00:05:35/00:02:26, 1.555s/it]
[2025-08-27 05:35:21,465][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00223/00310] [00:05:48/00:02:13, 1.554s/it]
[2025-08-27 05:35:33,697][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00231/00310] [00:06:00/00:02:01, 1.554s/it]
[2025-08-27 05:35:46,041][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00239/00310] [00:06:12/00:01:48, 1.553s/it]
[2025-08-27 05:35:58,278][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00247/00310] [00:06:25/00:01:36, 1.552s/it]
[2025-08-27 05:36:10,824][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00255/00310] [00:06:37/00:01:23, 1.553s/it]
[2025-08-27 05:36:23,621][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00263/00310] [00:06:50/00:01:11, 1.554s/it]
[2025-08-27 05:36:35,896][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00271/00310] [00:07:02/00:00:59, 1.554s/it]
[2025-08-27 05:36:48,127][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00279/00310] [00:07:14/00:00:46, 1.553s/it]
[2025-08-27 05:37:00,558][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00287/00310] [00:07:27/00:00:34, 1.553s/it]
[2025-08-27 05:37:12,590][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00295/00310] [00:07:39/00:00:21, 1.552s/it]
[2025-08-27 05:37:25,295][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00303/00310] [00:07:52/00:00:09, 1.553s/it]
[2025-08-27 05:37:34,885][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=0.85857, valid_loss=1.81380
[2025-08-27 05:37:34,886][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-27 05:37:34,886][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.666
[2025-08-27 05:37:34,886][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.057
[2025-08-27 05:37:34,886][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.058
[2025-08-27 05:37:34,886][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.022
[2025-08-27 05:37:34,900][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 10:10:48, remaining time 13:18:45, 00:46:59 per epoch
[2025-08-27 05:37:40,623][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040048] [Batch 00008/03080] [00:00:05/00:34:12, 0.668s/it]: train_loss_raw=0.8241, running_loss=0.9012, LR=0.000100
[2025-08-27 05:37:46,569][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040056] [Batch 00016/03080] [00:00:11/00:36:02, 0.706s/it]: train_loss_raw=0.8451, running_loss=0.8989, LR=0.000100
[2025-08-27 05:37:52,488][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040064] [Batch 00024/03080] [00:00:17/00:36:31, 0.717s/it]: train_loss_raw=0.8083, running_loss=0.8931, LR=0.000100
[2025-08-27 05:37:58,379][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040072] [Batch 00032/03080] [00:00:23/00:36:40, 0.722s/it]: train_loss_raw=0.8093, running_loss=0.8883, LR=0.000100
[2025-08-27 05:38:04,272][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040080] [Batch 00040/03080] [00:00:28/00:36:43, 0.725s/it]: train_loss_raw=0.6913, running_loss=0.8840, LR=0.000100
[2025-08-27 05:38:10,127][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040088] [Batch 00048/03080] [00:00:34/00:36:41, 0.726s/it]: train_loss_raw=0.8099, running_loss=0.8810, LR=0.000100
[2025-08-27 05:38:16,169][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040096] [Batch 00056/03080] [00:00:40/00:36:48, 0.730s/it]: train_loss_raw=0.8709, running_loss=0.8796, LR=0.000100
[2025-08-27 05:38:22,235][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040104] [Batch 00064/03080] [00:00:46/00:36:52, 0.734s/it]: train_loss_raw=0.9038, running_loss=0.8799, LR=0.000100
[2025-08-27 05:38:28,150][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040112] [Batch 00072/03080] [00:00:52/00:36:48, 0.734s/it]: train_loss_raw=0.7943, running_loss=0.8759, LR=0.000100
[2025-08-27 05:38:34,049][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040120] [Batch 00080/03080] [00:00:58/00:36:43, 0.735s/it]: train_loss_raw=0.9561, running_loss=0.8739, LR=0.000100
[2025-08-27 05:38:39,998][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040128] [Batch 00088/03080] [00:01:04/00:36:40, 0.735s/it]: train_loss_raw=0.8459, running_loss=0.8731, LR=0.000100
[2025-08-27 05:38:45,944][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040136] [Batch 00096/03080] [00:01:10/00:36:36, 0.736s/it]: train_loss_raw=0.8922, running_loss=0.8690, LR=0.000100
[2025-08-27 05:38:51,913][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040144] [Batch 00104/03080] [00:01:16/00:36:32, 0.737s/it]: train_loss_raw=0.9390, running_loss=0.8682, LR=0.000100
[2025-08-27 05:38:57,864][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040152] [Batch 00112/03080] [00:01:22/00:36:28, 0.737s/it]: train_loss_raw=0.8279, running_loss=0.8682, LR=0.000100
[2025-08-27 05:39:03,923][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040160] [Batch 00120/03080] [00:01:28/00:36:26, 0.739s/it]: train_loss_raw=0.9207, running_loss=0.8671, LR=0.000100
[2025-08-27 05:39:09,889][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040168] [Batch 00128/03080] [00:01:34/00:36:21, 0.739s/it]: train_loss_raw=0.8684, running_loss=0.8628, LR=0.000100
[2025-08-27 05:39:15,812][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040176] [Batch 00136/03080] [00:01:40/00:36:16, 0.739s/it]: train_loss_raw=0.8167, running_loss=0.8609, LR=0.000100
[2025-08-27 05:39:22,003][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040184] [Batch 00144/03080] [00:01:46/00:36:15, 0.741s/it]: train_loss_raw=0.8062, running_loss=0.8598, LR=0.000100
[2025-08-27 05:39:27,883][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040192] [Batch 00152/03080] [00:01:52/00:36:09, 0.741s/it]: train_loss_raw=0.8444, running_loss=0.8586, LR=0.000100
[2025-08-27 05:39:34,034][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040200] [Batch 00160/03080] [00:01:58/00:36:07, 0.742s/it]: train_loss_raw=0.7386, running_loss=0.8581, LR=0.000100
[2025-08-27 05:39:39,876][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040208] [Batch 00168/03080] [00:02:04/00:35:59, 0.742s/it]: train_loss_raw=0.9740, running_loss=0.8599, LR=0.000100
[2025-08-27 05:39:46,063][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040216] [Batch 00176/03080] [00:02:10/00:35:57, 0.743s/it]: train_loss_raw=0.8632, running_loss=0.8595, LR=0.000100
[2025-08-27 05:39:51,979][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040224] [Batch 00184/03080] [00:02:16/00:35:51, 0.743s/it]: train_loss_raw=0.8773, running_loss=0.8602, LR=0.000100
[2025-08-27 05:39:58,044][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040232] [Batch 00192/03080] [00:02:22/00:35:47, 0.744s/it]: train_loss_raw=0.8574, running_loss=0.8602, LR=0.000100
[2025-08-27 05:40:04,134][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040240] [Batch 00200/03080] [00:02:28/00:35:43, 0.744s/it]: train_loss_raw=0.8829, running_loss=0.8608, LR=0.000100
[2025-08-27 05:40:09,877][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040248] [Batch 00208/03080] [00:02:34/00:35:34, 0.743s/it]: train_loss_raw=0.7959, running_loss=0.8576, LR=0.000100
[2025-08-27 05:40:15,686][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040256] [Batch 00216/03080] [00:02:40/00:35:26, 0.743s/it]: train_loss_raw=0.8864, running_loss=0.8593, LR=0.000100
[2025-08-27 05:40:21,743][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040264] [Batch 00224/03080] [00:02:46/00:35:22, 0.743s/it]: train_loss_raw=0.7787, running_loss=0.8577, LR=0.000100
[2025-08-27 05:40:27,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040272] [Batch 00232/03080] [00:02:52/00:35:18, 0.744s/it]: train_loss_raw=0.7340, running_loss=0.8567, LR=0.000100
[2025-08-27 05:40:33,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040280] [Batch 00240/03080] [00:02:58/00:35:11, 0.744s/it]: train_loss_raw=0.8296, running_loss=0.8552, LR=0.000100
[2025-08-27 05:40:39,601][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040288] [Batch 00248/03080] [00:03:04/00:35:04, 0.743s/it]: train_loss_raw=0.8588, running_loss=0.8528, LR=0.000100
[2025-08-27 05:40:45,552][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040296] [Batch 00256/03080] [00:03:10/00:34:58, 0.743s/it]: train_loss_raw=0.7528, running_loss=0.8507, LR=0.000100
[2025-08-27 05:40:51,703][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040304] [Batch 00264/03080] [00:03:16/00:34:55, 0.744s/it]: train_loss_raw=0.8638, running_loss=0.8474, LR=0.000100
[2025-08-27 05:40:57,944][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040312] [Batch 00272/03080] [00:03:22/00:34:52, 0.745s/it]: train_loss_raw=0.7828, running_loss=0.8443, LR=0.000100
[2025-08-27 05:41:04,098][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040320] [Batch 00280/03080] [00:03:28/00:34:48, 0.746s/it]: train_loss_raw=0.8265, running_loss=0.8447, LR=0.000100
[2025-08-27 05:41:10,264][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040328] [Batch 00288/03080] [00:03:34/00:34:44, 0.746s/it]: train_loss_raw=0.8577, running_loss=0.8461, LR=0.000100
[2025-08-27 05:41:16,595][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040336] [Batch 00296/03080] [00:03:41/00:34:41, 0.748s/it]: train_loss_raw=0.9065, running_loss=0.8455, LR=0.000100
[2025-08-27 05:41:22,539][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040344] [Batch 00304/03080] [00:03:47/00:34:35, 0.748s/it]: train_loss_raw=0.8059, running_loss=0.8439, LR=0.000100
[2025-08-27 05:41:28,471][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040352] [Batch 00312/03080] [00:03:53/00:34:28, 0.747s/it]: train_loss_raw=0.8156, running_loss=0.8445, LR=0.000100
[2025-08-27 05:41:34,540][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040360] [Batch 00320/03080] [00:03:59/00:34:23, 0.748s/it]: train_loss_raw=0.8658, running_loss=0.8460, LR=0.000100
[2025-08-27 05:41:40,510][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040368] [Batch 00328/03080] [00:04:05/00:34:17, 0.748s/it]: train_loss_raw=0.8415, running_loss=0.8462, LR=0.000100
[2025-08-27 05:41:46,416][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040376] [Batch 00336/03080] [00:04:11/00:34:10, 0.747s/it]: train_loss_raw=0.8575, running_loss=0.8475, LR=0.000100
[2025-08-27 05:41:52,334][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040384] [Batch 00344/03080] [00:04:17/00:34:04, 0.747s/it]: train_loss_raw=0.7632, running_loss=0.8493, LR=0.000100
[2025-08-27 05:41:58,179][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040392] [Batch 00352/03080] [00:04:22/00:33:57, 0.747s/it]: train_loss_raw=0.9149, running_loss=0.8494, LR=0.000100
[2025-08-27 05:42:04,365][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040400] [Batch 00360/03080] [00:04:29/00:33:53, 0.747s/it]: train_loss_raw=0.8213, running_loss=0.8488, LR=0.000100
[2025-08-27 05:42:10,562][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040408] [Batch 00368/03080] [00:04:35/00:33:48, 0.748s/it]: train_loss_raw=0.8121, running_loss=0.8472, LR=0.000100
[2025-08-27 05:42:16,495][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040416] [Batch 00376/03080] [00:04:41/00:33:42, 0.748s/it]: train_loss_raw=0.7977, running_loss=0.8481, LR=0.000100
[2025-08-27 05:42:22,535][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040424] [Batch 00384/03080] [00:04:47/00:33:36, 0.748s/it]: train_loss_raw=0.8897, running_loss=0.8473, LR=0.000100
[2025-08-27 05:42:28,459][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040432] [Batch 00392/03080] [00:04:53/00:33:30, 0.748s/it]: train_loss_raw=0.8653, running_loss=0.8487, LR=0.000100
[2025-08-27 05:42:34,390][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040440] [Batch 00400/03080] [00:04:59/00:33:24, 0.748s/it]: train_loss_raw=0.8612, running_loss=0.8485, LR=0.000100
[2025-08-27 05:42:40,369][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040448] [Batch 00408/03080] [00:05:05/00:33:18, 0.748s/it]: train_loss_raw=0.9342, running_loss=0.8489, LR=0.000100
[2025-08-27 05:42:46,235][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040456] [Batch 00416/03080] [00:05:10/00:33:11, 0.747s/it]: train_loss_raw=0.8049, running_loss=0.8468, LR=0.000100
[2025-08-27 05:42:52,195][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040464] [Batch 00424/03080] [00:05:16/00:33:05, 0.747s/it]: train_loss_raw=0.7531, running_loss=0.8458, LR=0.000100
[2025-08-27 05:42:58,001][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040472] [Batch 00432/03080] [00:05:22/00:32:58, 0.747s/it]: train_loss_raw=0.8917, running_loss=0.8459, LR=0.000100
[2025-08-27 05:43:03,832][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040480] [Batch 00440/03080] [00:05:28/00:32:51, 0.747s/it]: train_loss_raw=0.8279, running_loss=0.8479, LR=0.000100
[2025-08-27 05:43:09,760][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040488] [Batch 00448/03080] [00:05:34/00:32:45, 0.747s/it]: train_loss_raw=0.8913, running_loss=0.8469, LR=0.000100
[2025-08-27 05:43:15,707][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040496] [Batch 00456/03080] [00:05:40/00:32:38, 0.747s/it]: train_loss_raw=0.8870, running_loss=0.8447, LR=0.000100
[2025-08-27 05:43:21,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040504] [Batch 00464/03080] [00:05:46/00:32:32, 0.746s/it]: train_loss_raw=0.8726, running_loss=0.8436, LR=0.000100
[2025-08-27 05:43:27,572][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040512] [Batch 00472/03080] [00:05:52/00:32:26, 0.746s/it]: train_loss_raw=0.7504, running_loss=0.8403, LR=0.000100
[2025-08-27 05:43:33,418][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040520] [Batch 00480/03080] [00:05:58/00:32:19, 0.746s/it]: train_loss_raw=0.9253, running_loss=0.8430, LR=0.000100
[2025-08-27 05:43:39,239][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040528] [Batch 00488/03080] [00:06:03/00:32:13, 0.746s/it]: train_loss_raw=0.8681, running_loss=0.8442, LR=0.000100
[2025-08-27 05:43:45,129][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040536] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=0.7863, running_loss=0.8464, LR=0.000100
[2025-08-27 05:43:51,093][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040544] [Batch 00504/03080] [00:06:15/00:32:00, 0.746s/it]: train_loss_raw=0.9215, running_loss=0.8481, LR=0.000100
[2025-08-27 05:43:57,021][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040552] [Batch 00512/03080] [00:06:21/00:31:54, 0.746s/it]: train_loss_raw=0.8556, running_loss=0.8486, LR=0.000100
[2025-08-27 05:44:03,026][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040560] [Batch 00520/03080] [00:06:27/00:31:48, 0.746s/it]: train_loss_raw=0.7552, running_loss=0.8503, LR=0.000100
[2025-08-27 05:44:08,965][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040568] [Batch 00528/03080] [00:06:33/00:31:42, 0.746s/it]: train_loss_raw=0.7837, running_loss=0.8479, LR=0.000100
[2025-08-27 05:44:14,910][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040576] [Batch 00536/03080] [00:06:39/00:31:36, 0.746s/it]: train_loss_raw=0.6990, running_loss=0.8453, LR=0.000100
[2025-08-27 05:44:20,858][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040584] [Batch 00544/03080] [00:06:45/00:31:30, 0.746s/it]: train_loss_raw=0.8287, running_loss=0.8452, LR=0.000100
[2025-08-27 05:44:26,800][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040592] [Batch 00552/03080] [00:06:51/00:31:24, 0.746s/it]: train_loss_raw=0.7775, running_loss=0.8421, LR=0.000100
[2025-08-27 05:44:32,691][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040600] [Batch 00560/03080] [00:06:57/00:31:18, 0.745s/it]: train_loss_raw=0.8304, running_loss=0.8436, LR=0.000100
[2025-08-27 05:44:38,618][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040608] [Batch 00568/03080] [00:07:03/00:31:12, 0.745s/it]: train_loss_raw=0.8160, running_loss=0.8460, LR=0.000100
[2025-08-27 05:44:44,599][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040616] [Batch 00576/03080] [00:07:09/00:31:06, 0.745s/it]: train_loss_raw=0.7977, running_loss=0.8441, LR=0.000100
[2025-08-27 05:44:50,465][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040624] [Batch 00584/03080] [00:07:15/00:30:59, 0.745s/it]: train_loss_raw=0.8639, running_loss=0.8442, LR=0.000100
[2025-08-27 05:44:56,478][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040632] [Batch 00592/03080] [00:07:21/00:30:54, 0.745s/it]: train_loss_raw=0.9556, running_loss=0.8455, LR=0.000100
[2025-08-27 05:45:02,450][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040640] [Batch 00600/03080] [00:07:27/00:30:48, 0.745s/it]: train_loss_raw=0.8984, running_loss=0.8443, LR=0.000100
[2025-08-27 05:45:08,451][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040648] [Batch 00608/03080] [00:07:33/00:30:42, 0.745s/it]: train_loss_raw=0.8283, running_loss=0.8441, LR=0.000100
[2025-08-27 05:45:14,278][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040656] [Batch 00616/03080] [00:07:38/00:30:35, 0.745s/it]: train_loss_raw=0.9011, running_loss=0.8445, LR=0.000100
[2025-08-27 05:45:20,293][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040664] [Batch 00624/03080] [00:07:45/00:30:30, 0.745s/it]: train_loss_raw=0.9187, running_loss=0.8458, LR=0.000100
[2025-08-27 05:45:26,144][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040672] [Batch 00632/03080] [00:07:50/00:30:23, 0.745s/it]: train_loss_raw=0.7888, running_loss=0.8448, LR=0.000100
[2025-08-27 05:45:32,110][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040680] [Batch 00640/03080] [00:07:56/00:30:17, 0.745s/it]: train_loss_raw=0.9218, running_loss=0.8463, LR=0.000100
[2025-08-27 05:45:38,145][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040688] [Batch 00648/03080] [00:08:02/00:30:12, 0.745s/it]: train_loss_raw=0.9067, running_loss=0.8448, LR=0.000100
[2025-08-27 05:45:44,176][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040696] [Batch 00656/03080] [00:08:08/00:30:06, 0.745s/it]: train_loss_raw=0.8545, running_loss=0.8433, LR=0.000100
[2025-08-27 05:45:50,077][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040704] [Batch 00664/03080] [00:08:14/00:30:00, 0.745s/it]: train_loss_raw=0.8495, running_loss=0.8445, LR=0.000100
[2025-08-27 05:45:55,925][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040712] [Batch 00672/03080] [00:08:20/00:29:53, 0.745s/it]: train_loss_raw=0.8883, running_loss=0.8449, LR=0.000100
[2025-08-27 05:46:01,876][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040720] [Batch 00680/03080] [00:08:26/00:29:47, 0.745s/it]: train_loss_raw=0.8507, running_loss=0.8448, LR=0.000100
[2025-08-27 05:46:07,858][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040728] [Batch 00688/03080] [00:08:32/00:29:42, 0.745s/it]: train_loss_raw=0.8331, running_loss=0.8459, LR=0.000100
[2025-08-27 05:46:13,689][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040736] [Batch 00696/03080] [00:08:38/00:29:35, 0.745s/it]: train_loss_raw=0.8500, running_loss=0.8456, LR=0.000100
[2025-08-27 05:46:19,632][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040744] [Batch 00704/03080] [00:08:44/00:29:29, 0.745s/it]: train_loss_raw=0.8259, running_loss=0.8452, LR=0.000100
[2025-08-27 05:46:25,554][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040752] [Batch 00712/03080] [00:08:50/00:29:23, 0.745s/it]: train_loss_raw=0.6973, running_loss=0.8428, LR=0.000100
[2025-08-27 05:46:31,501][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040760] [Batch 00720/03080] [00:08:56/00:29:17, 0.745s/it]: train_loss_raw=0.8907, running_loss=0.8430, LR=0.000100
[2025-08-27 05:46:37,460][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040768] [Batch 00728/03080] [00:09:02/00:29:11, 0.745s/it]: train_loss_raw=0.7425, running_loss=0.8424, LR=0.000100
[2025-08-27 05:46:43,297][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040776] [Batch 00736/03080] [00:09:08/00:29:05, 0.745s/it]: train_loss_raw=0.8253, running_loss=0.8402, LR=0.000100
[2025-08-27 05:46:49,263][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040784] [Batch 00744/03080] [00:09:13/00:28:59, 0.745s/it]: train_loss_raw=0.8059, running_loss=0.8400, LR=0.000100
[2025-08-27 05:46:55,051][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040792] [Batch 00752/03080] [00:09:19/00:28:52, 0.744s/it]: train_loss_raw=0.7562, running_loss=0.8373, LR=0.000100
[2025-08-27 05:47:00,907][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040800] [Batch 00760/03080] [00:09:25/00:28:46, 0.744s/it]: train_loss_raw=0.8205, running_loss=0.8393, LR=0.000100
[2025-08-27 05:47:06,668][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040808] [Batch 00768/03080] [00:09:31/00:28:40, 0.744s/it]: train_loss_raw=0.8428, running_loss=0.8393, LR=0.000100
[2025-08-27 05:47:12,558][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040816] [Batch 00776/03080] [00:09:37/00:28:33, 0.744s/it]: train_loss_raw=0.7336, running_loss=0.8406, LR=0.000100
[2025-08-27 05:47:18,513][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040824] [Batch 00784/03080] [00:09:43/00:28:28, 0.744s/it]: train_loss_raw=0.8965, running_loss=0.8425, LR=0.000100
[2025-08-27 05:47:24,524][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040832] [Batch 00792/03080] [00:09:49/00:28:22, 0.744s/it]: train_loss_raw=0.9387, running_loss=0.8427, LR=0.000100
[2025-08-27 05:47:30,393][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040840] [Batch 00800/03080] [00:09:55/00:28:16, 0.744s/it]: train_loss_raw=0.8573, running_loss=0.8386, LR=0.000100
[2025-08-27 05:47:36,538][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040848] [Batch 00808/03080] [00:10:01/00:28:10, 0.744s/it]: train_loss_raw=0.8765, running_loss=0.8395, LR=0.000100
[2025-08-27 05:47:42,525][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040856] [Batch 00816/03080] [00:10:07/00:28:04, 0.744s/it]: train_loss_raw=0.8535, running_loss=0.8380, LR=0.000100
[2025-08-27 05:47:48,543][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040864] [Batch 00824/03080] [00:10:13/00:27:59, 0.744s/it]: train_loss_raw=0.8812, running_loss=0.8374, LR=0.000100
[2025-08-27 05:47:54,589][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040872] [Batch 00832/03080] [00:10:19/00:27:53, 0.744s/it]: train_loss_raw=0.8309, running_loss=0.8380, LR=0.000100
[2025-08-27 05:48:00,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040880] [Batch 00840/03080] [00:10:25/00:27:47, 0.744s/it]: train_loss_raw=0.9346, running_loss=0.8387, LR=0.000100
[2025-08-27 05:48:06,407][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040888] [Batch 00848/03080] [00:10:31/00:27:41, 0.744s/it]: train_loss_raw=0.9571, running_loss=0.8395, LR=0.000100
[2025-08-27 05:48:12,258][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040896] [Batch 00856/03080] [00:10:36/00:27:34, 0.744s/it]: train_loss_raw=0.8705, running_loss=0.8397, LR=0.000100
[2025-08-27 05:48:18,205][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040904] [Batch 00864/03080] [00:10:42/00:27:28, 0.744s/it]: train_loss_raw=0.8460, running_loss=0.8373, LR=0.000100
[2025-08-27 05:48:24,139][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040912] [Batch 00872/03080] [00:10:48/00:27:22, 0.744s/it]: train_loss_raw=0.8615, running_loss=0.8385, LR=0.000100
[2025-08-27 05:48:30,236][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040920] [Batch 00880/03080] [00:10:54/00:27:17, 0.744s/it]: train_loss_raw=0.6754, running_loss=0.8352, LR=0.000100
[2025-08-27 05:48:36,224][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040928] [Batch 00888/03080] [00:11:00/00:27:11, 0.744s/it]: train_loss_raw=0.9073, running_loss=0.8351, LR=0.000100
[2025-08-27 05:48:42,178][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040936] [Batch 00896/03080] [00:11:06/00:27:05, 0.744s/it]: train_loss_raw=0.7982, running_loss=0.8355, LR=0.000100
[2025-08-27 05:48:48,014][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040944] [Batch 00904/03080] [00:11:12/00:26:59, 0.744s/it]: train_loss_raw=0.8399, running_loss=0.8383, LR=0.000100
[2025-08-27 05:48:53,910][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040952] [Batch 00912/03080] [00:11:18/00:26:53, 0.744s/it]: train_loss_raw=0.8969, running_loss=0.8397, LR=0.000100
[2025-08-27 05:48:59,777][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040960] [Batch 00920/03080] [00:11:24/00:26:47, 0.744s/it]: train_loss_raw=0.8781, running_loss=0.8374, LR=0.000100
[2025-08-27 05:49:05,745][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040968] [Batch 00928/03080] [00:11:30/00:26:41, 0.744s/it]: train_loss_raw=0.8669, running_loss=0.8382, LR=0.000100
[2025-08-27 05:49:11,593][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040976] [Batch 00936/03080] [00:11:36/00:26:34, 0.744s/it]: train_loss_raw=0.8280, running_loss=0.8350, LR=0.000100
[2025-08-27 05:49:17,574][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040984] [Batch 00944/03080] [00:11:42/00:26:29, 0.744s/it]: train_loss_raw=0.9509, running_loss=0.8369, LR=0.000100
[2025-08-27 05:49:23,414][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040992] [Batch 00952/03080] [00:11:48/00:26:22, 0.744s/it]: train_loss_raw=0.8089, running_loss=0.8339, LR=0.000100
[2025-08-27 05:49:29,152][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041000] [Batch 00960/03080] [00:11:53/00:26:16, 0.744s/it]: train_loss_raw=0.8454, running_loss=0.8324, LR=0.000100
[2025-08-27 05:49:35,574][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041008] [Batch 00968/03080] [00:12:00/00:26:11, 0.744s/it]: train_loss_raw=0.8273, running_loss=0.8351, LR=0.000100
[2025-08-27 05:49:41,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041016] [Batch 00976/03080] [00:12:06/00:26:05, 0.744s/it]: train_loss_raw=0.8352, running_loss=0.8354, LR=0.000100
[2025-08-27 05:49:47,577][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041024] [Batch 00984/03080] [00:12:12/00:25:59, 0.744s/it]: train_loss_raw=0.8190, running_loss=0.8343, LR=0.000100
[2025-08-27 05:49:53,565][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041032] [Batch 00992/03080] [00:12:18/00:25:53, 0.744s/it]: train_loss_raw=0.7932, running_loss=0.8352, LR=0.000100
[2025-08-27 05:49:59,493][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041040] [Batch 01000/03080] [00:12:24/00:25:47, 0.744s/it]: train_loss_raw=0.7840, running_loss=0.8368, LR=0.000100
[2025-08-27 05:50:05,431][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041048] [Batch 01008/03080] [00:12:30/00:25:41, 0.744s/it]: train_loss_raw=0.8674, running_loss=0.8385, LR=0.000100
[2025-08-27 05:50:11,408][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041056] [Batch 01016/03080] [00:12:36/00:25:36, 0.744s/it]: train_loss_raw=0.9100, running_loss=0.8374, LR=0.000100
[2025-08-27 05:50:17,472][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041064] [Batch 01024/03080] [00:12:42/00:25:30, 0.744s/it]: train_loss_raw=0.8015, running_loss=0.8359, LR=0.000100
[2025-08-27 05:50:23,379][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041072] [Batch 01032/03080] [00:12:48/00:25:24, 0.744s/it]: train_loss_raw=0.7702, running_loss=0.8348, LR=0.000100
[2025-08-27 05:50:29,199][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041080] [Batch 01040/03080] [00:12:53/00:25:18, 0.744s/it]: train_loss_raw=0.7880, running_loss=0.8337, LR=0.000100
[2025-08-27 05:50:35,058][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041088] [Batch 01048/03080] [00:12:59/00:25:11, 0.744s/it]: train_loss_raw=0.8399, running_loss=0.8318, LR=0.000100
[2025-08-27 05:50:41,006][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041096] [Batch 01056/03080] [00:13:05/00:25:05, 0.744s/it]: train_loss_raw=0.9474, running_loss=0.8312, LR=0.000100
[2025-08-27 05:50:46,873][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041104] [Batch 01064/03080] [00:13:11/00:24:59, 0.744s/it]: train_loss_raw=0.8373, running_loss=0.8304, LR=0.000100
[2025-08-27 05:50:52,876][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041112] [Batch 01072/03080] [00:13:17/00:24:54, 0.744s/it]: train_loss_raw=0.8046, running_loss=0.8328, LR=0.000100
[2025-08-27 05:50:58,770][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041120] [Batch 01080/03080] [00:13:23/00:24:47, 0.744s/it]: train_loss_raw=0.7599, running_loss=0.8319, LR=0.000100
[2025-08-27 05:51:04,782][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041128] [Batch 01088/03080] [00:13:29/00:24:42, 0.744s/it]: train_loss_raw=0.9056, running_loss=0.8317, LR=0.000100
[2025-08-27 05:51:10,830][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041136] [Batch 01096/03080] [00:13:35/00:24:36, 0.744s/it]: train_loss_raw=0.8542, running_loss=0.8330, LR=0.000100
[2025-08-27 05:51:16,873][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041144] [Batch 01104/03080] [00:13:41/00:24:30, 0.744s/it]: train_loss_raw=0.8548, running_loss=0.8316, LR=0.000100
[2025-08-27 05:51:22,925][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041152] [Batch 01112/03080] [00:13:47/00:24:24, 0.744s/it]: train_loss_raw=0.8250, running_loss=0.8323, LR=0.000100
[2025-08-27 05:51:28,757][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041160] [Batch 01120/03080] [00:13:53/00:24:18, 0.744s/it]: train_loss_raw=0.9316, running_loss=0.8317, LR=0.000100
[2025-08-27 05:51:34,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041168] [Batch 01128/03080] [00:13:59/00:24:12, 0.744s/it]: train_loss_raw=0.8499, running_loss=0.8324, LR=0.000100
[2025-08-27 05:51:40,856][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041176] [Batch 01136/03080] [00:14:05/00:24:07, 0.744s/it]: train_loss_raw=0.8911, running_loss=0.8336, LR=0.000100
[2025-08-27 05:51:46,986][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041184] [Batch 01144/03080] [00:14:11/00:24:01, 0.744s/it]: train_loss_raw=0.7965, running_loss=0.8316, LR=0.000100
[2025-08-27 05:51:53,066][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041192] [Batch 01152/03080] [00:14:17/00:23:55, 0.745s/it]: train_loss_raw=0.7453, running_loss=0.8313, LR=0.000100
[2025-08-27 05:51:58,822][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041200] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=0.8281, running_loss=0.8314, LR=0.000100
[2025-08-27 05:52:04,776][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041208] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=0.9001, running_loss=0.8319, LR=0.000100
[2025-08-27 05:52:10,877][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041216] [Batch 01176/03080] [00:14:35/00:23:37, 0.745s/it]: train_loss_raw=0.8466, running_loss=0.8292, LR=0.000100
[2025-08-27 05:52:17,139][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041224] [Batch 01184/03080] [00:14:41/00:23:32, 0.745s/it]: train_loss_raw=0.7741, running_loss=0.8282, LR=0.000100
[2025-08-27 05:52:23,309][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041232] [Batch 01192/03080] [00:14:48/00:23:26, 0.745s/it]: train_loss_raw=0.8427, running_loss=0.8268, LR=0.000100
[2025-08-27 05:52:29,055][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041240] [Batch 01200/03080] [00:14:53/00:23:20, 0.745s/it]: train_loss_raw=0.8083, running_loss=0.8266, LR=0.000100
[2025-08-27 05:52:34,981][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041248] [Batch 01208/03080] [00:14:59/00:23:14, 0.745s/it]: train_loss_raw=0.8379, running_loss=0.8264, LR=0.000100
[2025-08-27 05:52:41,057][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041256] [Batch 01216/03080] [00:15:05/00:23:08, 0.745s/it]: train_loss_raw=0.7499, running_loss=0.8248, LR=0.000100
[2025-08-27 05:52:47,121][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041264] [Batch 01224/03080] [00:15:11/00:23:02, 0.745s/it]: train_loss_raw=0.8622, running_loss=0.8242, LR=0.000100
[2025-08-27 05:52:53,249][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041272] [Batch 01232/03080] [00:15:17/00:22:56, 0.745s/it]: train_loss_raw=0.8345, running_loss=0.8258, LR=0.000100
[2025-08-27 05:52:59,525][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041280] [Batch 01240/03080] [00:15:24/00:22:51, 0.745s/it]: train_loss_raw=0.9382, running_loss=0.8275, LR=0.000100
[2025-08-27 05:53:05,682][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041288] [Batch 01248/03080] [00:15:30/00:22:45, 0.746s/it]: train_loss_raw=0.7618, running_loss=0.8281, LR=0.000100
[2025-08-27 05:53:11,598][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041296] [Batch 01256/03080] [00:15:36/00:22:39, 0.745s/it]: train_loss_raw=0.8216, running_loss=0.8274, LR=0.000100
[2025-08-27 05:53:17,622][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041304] [Batch 01264/03080] [00:15:42/00:22:33, 0.746s/it]: train_loss_raw=0.7804, running_loss=0.8265, LR=0.000100
[2025-08-27 05:53:23,759][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041312] [Batch 01272/03080] [00:15:48/00:22:28, 0.746s/it]: train_loss_raw=0.8328, running_loss=0.8272, LR=0.000100
[2025-08-27 05:53:29,764][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041320] [Batch 01280/03080] [00:15:54/00:22:22, 0.746s/it]: train_loss_raw=0.8948, running_loss=0.8304, LR=0.000100
[2025-08-27 05:53:35,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041328] [Batch 01288/03080] [00:16:00/00:22:16, 0.746s/it]: train_loss_raw=0.8684, running_loss=0.8318, LR=0.000100
[2025-08-27 05:53:41,598][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041336] [Batch 01296/03080] [00:16:06/00:22:10, 0.746s/it]: train_loss_raw=0.8725, running_loss=0.8312, LR=0.000100
[2025-08-27 05:53:47,549][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041344] [Batch 01304/03080] [00:16:12/00:22:04, 0.746s/it]: train_loss_raw=0.7980, running_loss=0.8283, LR=0.000100
[2025-08-27 05:53:53,530][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041352] [Batch 01312/03080] [00:16:18/00:21:58, 0.746s/it]: train_loss_raw=0.8914, running_loss=0.8311, LR=0.000100
[2025-08-27 05:53:59,544][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041360] [Batch 01320/03080] [00:16:24/00:21:52, 0.746s/it]: train_loss_raw=0.8425, running_loss=0.8306, LR=0.000100
[2025-08-27 05:54:05,535][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041368] [Batch 01328/03080] [00:16:30/00:21:46, 0.746s/it]: train_loss_raw=0.6600, running_loss=0.8279, LR=0.000100
[2025-08-27 05:54:11,414][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041376] [Batch 01336/03080] [00:16:36/00:21:40, 0.746s/it]: train_loss_raw=0.8371, running_loss=0.8279, LR=0.000100
[2025-08-27 05:54:17,430][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041384] [Batch 01344/03080] [00:16:42/00:21:34, 0.746s/it]: train_loss_raw=0.9306, running_loss=0.8282, LR=0.000100
[2025-08-27 05:54:23,383][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041392] [Batch 01352/03080] [00:16:48/00:21:28, 0.746s/it]: train_loss_raw=0.8758, running_loss=0.8286, LR=0.000100
[2025-08-27 05:54:29,555][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041400] [Batch 01360/03080] [00:16:54/00:21:22, 0.746s/it]: train_loss_raw=0.8642, running_loss=0.8285, LR=0.000100
[2025-08-27 05:54:35,726][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041408] [Batch 01368/03080] [00:17:00/00:21:17, 0.746s/it]: train_loss_raw=0.7661, running_loss=0.8307, LR=0.000100
[2025-08-27 05:54:42,006][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041416] [Batch 01376/03080] [00:17:06/00:21:11, 0.746s/it]: train_loss_raw=0.8636, running_loss=0.8324, LR=0.000100
[2025-08-27 05:54:48,139][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041424] [Batch 01384/03080] [00:17:12/00:21:05, 0.746s/it]: train_loss_raw=0.8626, running_loss=0.8312, LR=0.000100
[2025-08-27 05:54:54,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041432] [Batch 01392/03080] [00:17:18/00:20:59, 0.746s/it]: train_loss_raw=0.7370, running_loss=0.8291, LR=0.000100
[2025-08-27 05:55:00,169][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041440] [Batch 01400/03080] [00:17:24/00:20:53, 0.746s/it]: train_loss_raw=0.8369, running_loss=0.8287, LR=0.000100
[2025-08-27 05:55:06,039][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041448] [Batch 01408/03080] [00:17:30/00:20:47, 0.746s/it]: train_loss_raw=0.8023, running_loss=0.8294, LR=0.000100
[2025-08-27 05:55:12,088][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041456] [Batch 01416/03080] [00:17:36/00:20:41, 0.746s/it]: train_loss_raw=0.7661, running_loss=0.8266, LR=0.000100
[2025-08-27 05:55:18,111][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041464] [Batch 01424/03080] [00:17:42/00:20:35, 0.746s/it]: train_loss_raw=0.8616, running_loss=0.8283, LR=0.000100
[2025-08-27 05:55:24,116][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041472] [Batch 01432/03080] [00:17:48/00:20:30, 0.746s/it]: train_loss_raw=0.8492, running_loss=0.8301, LR=0.000100
[2025-08-27 05:55:30,222][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041480] [Batch 01440/03080] [00:17:54/00:20:24, 0.746s/it]: train_loss_raw=0.8399, running_loss=0.8288, LR=0.000100
[2025-08-27 05:55:36,176][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041488] [Batch 01448/03080] [00:18:00/00:20:18, 0.746s/it]: train_loss_raw=0.8742, running_loss=0.8281, LR=0.000100
[2025-08-27 05:55:42,114][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041496] [Batch 01456/03080] [00:18:06/00:20:12, 0.746s/it]: train_loss_raw=0.8205, running_loss=0.8294, LR=0.000100
[2025-08-27 05:55:48,048][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041504] [Batch 01464/03080] [00:18:12/00:20:06, 0.746s/it]: train_loss_raw=0.8356, running_loss=0.8285, LR=0.000100
[2025-08-27 05:55:54,191][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041512] [Batch 01472/03080] [00:18:18/00:20:00, 0.747s/it]: train_loss_raw=0.7614, running_loss=0.8291, LR=0.000100
[2025-08-27 05:56:00,100][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041520] [Batch 01480/03080] [00:18:24/00:19:54, 0.747s/it]: train_loss_raw=0.8742, running_loss=0.8308, LR=0.000100
[2025-08-27 05:56:06,004][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041528] [Batch 01488/03080] [00:18:30/00:19:48, 0.746s/it]: train_loss_raw=0.8437, running_loss=0.8315, LR=0.000100
[2025-08-27 05:56:11,880][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041536] [Batch 01496/03080] [00:18:36/00:19:42, 0.746s/it]: train_loss_raw=0.9198, running_loss=0.8311, LR=0.000100
[2025-08-27 05:56:17,825][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041544] [Batch 01504/03080] [00:18:42/00:19:36, 0.746s/it]: train_loss_raw=0.9550, running_loss=0.8307, LR=0.000100
[2025-08-27 05:56:23,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041552] [Batch 01512/03080] [00:18:48/00:19:30, 0.746s/it]: train_loss_raw=0.8433, running_loss=0.8315, LR=0.000100
[2025-08-27 05:56:29,752][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041560] [Batch 01520/03080] [00:18:54/00:19:24, 0.746s/it]: train_loss_raw=0.7782, running_loss=0.8301, LR=0.000100
[2025-08-27 05:56:35,680][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041568] [Batch 01528/03080] [00:19:00/00:19:18, 0.746s/it]: train_loss_raw=0.7376, running_loss=0.8274, LR=0.000100
[2025-08-27 05:56:41,492][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041576] [Batch 01536/03080] [00:19:06/00:19:12, 0.746s/it]: train_loss_raw=0.8195, running_loss=0.8256, LR=0.000100
[2025-08-27 05:56:47,840][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041584] [Batch 01544/03080] [00:19:12/00:19:06, 0.746s/it]: train_loss_raw=0.7986, running_loss=0.8266, LR=0.000100
[2025-08-27 05:56:53,914][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041592] [Batch 01552/03080] [00:19:18/00:19:00, 0.747s/it]: train_loss_raw=0.8342, running_loss=0.8277, LR=0.000100
[2025-08-27 05:56:59,718][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041600] [Batch 01560/03080] [00:19:24/00:18:54, 0.746s/it]: train_loss_raw=0.8065, running_loss=0.8277, LR=0.000100
[2025-08-27 05:57:05,893][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041608] [Batch 01568/03080] [00:19:30/00:18:48, 0.747s/it]: train_loss_raw=0.8869, running_loss=0.8260, LR=0.000100
[2025-08-27 05:57:11,947][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041616] [Batch 01576/03080] [00:19:36/00:18:42, 0.747s/it]: train_loss_raw=0.8433, running_loss=0.8261, LR=0.000100
[2025-08-27 05:57:18,064][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041624] [Batch 01584/03080] [00:19:42/00:18:37, 0.747s/it]: train_loss_raw=0.8519, running_loss=0.8246, LR=0.000100
[2025-08-27 05:57:24,129][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041632] [Batch 01592/03080] [00:19:48/00:18:31, 0.747s/it]: train_loss_raw=0.7132, running_loss=0.8218, LR=0.000100
[2025-08-27 05:57:30,217][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041640] [Batch 01600/03080] [00:19:54/00:18:25, 0.747s/it]: train_loss_raw=0.8865, running_loss=0.8191, LR=0.000100
[2025-08-27 05:57:36,248][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041648] [Batch 01608/03080] [00:20:00/00:18:19, 0.747s/it]: train_loss_raw=0.7658, running_loss=0.8164, LR=0.000100
[2025-08-27 05:57:42,266][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041656] [Batch 01616/03080] [00:20:06/00:18:13, 0.747s/it]: train_loss_raw=0.8961, running_loss=0.8178, LR=0.000100
[2025-08-27 05:57:48,453][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041664] [Batch 01624/03080] [00:20:13/00:18:07, 0.747s/it]: train_loss_raw=0.7560, running_loss=0.8174, LR=0.000100
[2025-08-27 05:57:54,518][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041672] [Batch 01632/03080] [00:20:19/00:18:01, 0.747s/it]: train_loss_raw=0.8197, running_loss=0.8153, LR=0.000100
[2025-08-27 05:58:00,599][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041680] [Batch 01640/03080] [00:20:25/00:17:55, 0.747s/it]: train_loss_raw=0.7957, running_loss=0.8161, LR=0.000100
[2025-08-27 05:58:06,373][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041688] [Batch 01648/03080] [00:20:31/00:17:49, 0.747s/it]: train_loss_raw=0.7889, running_loss=0.8158, LR=0.000100
[2025-08-27 05:58:12,186][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041696] [Batch 01656/03080] [00:20:36/00:17:43, 0.747s/it]: train_loss_raw=0.8020, running_loss=0.8170, LR=0.000100
[2025-08-27 05:58:17,926][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041704] [Batch 01664/03080] [00:20:42/00:17:37, 0.747s/it]: train_loss_raw=0.7597, running_loss=0.8147, LR=0.000100
[2025-08-27 05:58:23,804][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041712] [Batch 01672/03080] [00:20:48/00:17:31, 0.747s/it]: train_loss_raw=0.8134, running_loss=0.8133, LR=0.000100
[2025-08-27 05:58:29,740][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041720] [Batch 01680/03080] [00:20:54/00:17:25, 0.747s/it]: train_loss_raw=0.8125, running_loss=0.8146, LR=0.000100
[2025-08-27 05:58:35,772][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041728] [Batch 01688/03080] [00:21:00/00:17:19, 0.747s/it]: train_loss_raw=0.9176, running_loss=0.8178, LR=0.000100
[2025-08-27 05:58:41,739][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041736] [Batch 01696/03080] [00:21:06/00:17:13, 0.747s/it]: train_loss_raw=0.9418, running_loss=0.8194, LR=0.000100
[2025-08-27 05:58:47,529][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041744] [Batch 01704/03080] [00:21:12/00:17:07, 0.747s/it]: train_loss_raw=0.8976, running_loss=0.8199, LR=0.000100
[2025-08-27 05:58:53,580][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041752] [Batch 01712/03080] [00:21:18/00:17:01, 0.747s/it]: train_loss_raw=0.8721, running_loss=0.8198, LR=0.000100
[2025-08-27 05:58:59,546][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041760] [Batch 01720/03080] [00:21:24/00:16:55, 0.747s/it]: train_loss_raw=0.7484, running_loss=0.8175, LR=0.000100
[2025-08-27 05:59:05,567][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041768] [Batch 01728/03080] [00:21:30/00:16:49, 0.747s/it]: train_loss_raw=0.8202, running_loss=0.8143, LR=0.000100
[2025-08-27 05:59:11,526][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041776] [Batch 01736/03080] [00:21:36/00:16:43, 0.747s/it]: train_loss_raw=0.8396, running_loss=0.8136, LR=0.000100
[2025-08-27 05:59:17,634][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041784] [Batch 01744/03080] [00:21:42/00:16:37, 0.747s/it]: train_loss_raw=0.8795, running_loss=0.8135, LR=0.000100
[2025-08-27 05:59:23,565][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041792] [Batch 01752/03080] [00:21:48/00:16:31, 0.747s/it]: train_loss_raw=0.8148, running_loss=0.8153, LR=0.000100
[2025-08-27 05:59:29,407][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041800] [Batch 01760/03080] [00:21:54/00:16:25, 0.747s/it]: train_loss_raw=0.8444, running_loss=0.8169, LR=0.000100
[2025-08-27 05:59:35,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041808] [Batch 01768/03080] [00:22:00/00:16:19, 0.747s/it]: train_loss_raw=0.9066, running_loss=0.8168, LR=0.000100
[2025-08-27 05:59:41,715][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041816] [Batch 01776/03080] [00:22:06/00:16:13, 0.747s/it]: train_loss_raw=0.8168, running_loss=0.8165, LR=0.000100
[2025-08-27 05:59:47,604][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041824] [Batch 01784/03080] [00:22:12/00:16:07, 0.747s/it]: train_loss_raw=0.7447, running_loss=0.8139, LR=0.000100
[2025-08-27 05:59:53,429][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041832] [Batch 01792/03080] [00:22:18/00:16:01, 0.747s/it]: train_loss_raw=0.9291, running_loss=0.8163, LR=0.000100
[2025-08-27 05:59:59,371][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041840] [Batch 01800/03080] [00:22:24/00:15:55, 0.747s/it]: train_loss_raw=0.8545, running_loss=0.8181, LR=0.000100
[2025-08-27 06:00:05,563][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041848] [Batch 01808/03080] [00:22:30/00:15:49, 0.747s/it]: train_loss_raw=0.8557, running_loss=0.8199, LR=0.000100
[2025-08-27 06:00:11,359][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041856] [Batch 01816/03080] [00:22:36/00:15:43, 0.747s/it]: train_loss_raw=0.7477, running_loss=0.8213, LR=0.000100
[2025-08-27 06:00:17,166][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041864] [Batch 01824/03080] [00:22:41/00:15:37, 0.747s/it]: train_loss_raw=0.8008, running_loss=0.8208, LR=0.000100
[2025-08-27 06:00:23,214][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041872] [Batch 01832/03080] [00:22:47/00:15:31, 0.747s/it]: train_loss_raw=0.8591, running_loss=0.8221, LR=0.000100
[2025-08-27 06:00:29,099][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041880] [Batch 01840/03080] [00:22:53/00:15:25, 0.747s/it]: train_loss_raw=0.8134, running_loss=0.8184, LR=0.000100
[2025-08-27 06:00:34,926][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041888] [Batch 01848/03080] [00:22:59/00:15:19, 0.747s/it]: train_loss_raw=0.6986, running_loss=0.8179, LR=0.000100
[2025-08-27 06:00:40,744][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041896] [Batch 01856/03080] [00:23:05/00:15:13, 0.746s/it]: train_loss_raw=0.6700, running_loss=0.8165, LR=0.000100
[2025-08-27 06:00:46,900][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041904] [Batch 01864/03080] [00:23:11/00:15:07, 0.747s/it]: train_loss_raw=0.8430, running_loss=0.8162, LR=0.000100
[2025-08-27 06:00:53,006][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041912] [Batch 01872/03080] [00:23:17/00:15:01, 0.747s/it]: train_loss_raw=0.9051, running_loss=0.8182, LR=0.000100
[2025-08-27 06:00:58,981][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041920] [Batch 01880/03080] [00:23:23/00:14:55, 0.747s/it]: train_loss_raw=0.7248, running_loss=0.8156, LR=0.000100
[2025-08-27 06:01:04,989][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041928] [Batch 01888/03080] [00:23:29/00:14:50, 0.747s/it]: train_loss_raw=0.7588, running_loss=0.8148, LR=0.000100
[2025-08-27 06:01:10,869][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041936] [Batch 01896/03080] [00:23:35/00:14:43, 0.747s/it]: train_loss_raw=0.8679, running_loss=0.8157, LR=0.000100
[2025-08-27 06:01:16,885][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041944] [Batch 01904/03080] [00:23:41/00:14:38, 0.747s/it]: train_loss_raw=0.7859, running_loss=0.8145, LR=0.000100
[2025-08-27 06:01:22,801][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041952] [Batch 01912/03080] [00:23:47/00:14:32, 0.747s/it]: train_loss_raw=0.7564, running_loss=0.8143, LR=0.000100
[2025-08-27 06:01:28,660][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041960] [Batch 01920/03080] [00:23:53/00:14:26, 0.747s/it]: train_loss_raw=0.7636, running_loss=0.8138, LR=0.000100
[2025-08-27 06:01:34,790][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041968] [Batch 01928/03080] [00:23:59/00:14:20, 0.747s/it]: train_loss_raw=0.7316, running_loss=0.8134, LR=0.000100
[2025-08-27 06:01:40,709][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041976] [Batch 01936/03080] [00:24:05/00:14:14, 0.747s/it]: train_loss_raw=0.8464, running_loss=0.8129, LR=0.000100
[2025-08-27 06:01:46,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041984] [Batch 01944/03080] [00:24:11/00:14:08, 0.747s/it]: train_loss_raw=0.8731, running_loss=0.8129, LR=0.000100
[2025-08-27 06:01:52,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041992] [Batch 01952/03080] [00:24:17/00:14:02, 0.747s/it]: train_loss_raw=0.7848, running_loss=0.8118, LR=0.000100
[2025-08-27 06:01:58,563][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042000] [Batch 01960/03080] [00:24:23/00:13:56, 0.747s/it]: train_loss_raw=0.8689, running_loss=0.8119, LR=0.000100
[2025-08-27 06:02:08,556][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042008] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=0.8297, running_loss=0.8127, LR=0.000100
[2025-08-27 06:02:14,464][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042016] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=0.8719, running_loss=0.8098, LR=0.000100
[2025-08-27 06:02:20,280][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042024] [Batch 01984/03080] [00:24:45/00:13:40, 0.748s/it]: train_loss_raw=0.8437, running_loss=0.8099, LR=0.000100
[2025-08-27 06:02:26,284][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042032] [Batch 01992/03080] [00:24:51/00:13:34, 0.748s/it]: train_loss_raw=0.9580, running_loss=0.8125, LR=0.000100
[2025-08-27 06:02:32,194][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042040] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=0.8041, running_loss=0.8122, LR=0.000100
[2025-08-27 06:02:37,996][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042048] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=0.8292, running_loss=0.8113, LR=0.000100
[2025-08-27 06:02:43,788][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042056] [Batch 02016/03080] [00:25:08/00:13:16, 0.748s/it]: train_loss_raw=0.7520, running_loss=0.8092, LR=0.000100
[2025-08-27 06:02:49,812][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042064] [Batch 02024/03080] [00:25:14/00:13:10, 0.748s/it]: train_loss_raw=0.8336, running_loss=0.8092, LR=0.000100
[2025-08-27 06:02:55,821][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042072] [Batch 02032/03080] [00:25:20/00:13:04, 0.748s/it]: train_loss_raw=0.8795, running_loss=0.8105, LR=0.000100
[2025-08-27 06:03:01,739][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042080] [Batch 02040/03080] [00:25:26/00:12:58, 0.748s/it]: train_loss_raw=0.8666, running_loss=0.8101, LR=0.000100
[2025-08-27 06:03:07,843][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042088] [Batch 02048/03080] [00:25:32/00:12:52, 0.748s/it]: train_loss_raw=0.8859, running_loss=0.8106, LR=0.000100
[2025-08-27 06:03:13,726][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042096] [Batch 02056/03080] [00:25:38/00:12:46, 0.748s/it]: train_loss_raw=0.7993, running_loss=0.8106, LR=0.000100
[2025-08-27 06:03:19,633][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042104] [Batch 02064/03080] [00:25:44/00:12:40, 0.748s/it]: train_loss_raw=0.7936, running_loss=0.8107, LR=0.000100
[2025-08-27 06:03:25,710][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042112] [Batch 02072/03080] [00:25:50/00:12:34, 0.748s/it]: train_loss_raw=0.8195, running_loss=0.8084, LR=0.000100
[2025-08-27 06:03:31,688][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042120] [Batch 02080/03080] [00:25:56/00:12:28, 0.748s/it]: train_loss_raw=0.8854, running_loss=0.8072, LR=0.000100
[2025-08-27 06:03:37,573][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042128] [Batch 02088/03080] [00:26:02/00:12:22, 0.748s/it]: train_loss_raw=0.8229, running_loss=0.8080, LR=0.000100
[2025-08-27 06:03:43,331][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042136] [Batch 02096/03080] [00:26:08/00:12:16, 0.748s/it]: train_loss_raw=0.8743, running_loss=0.8065, LR=0.000100
[2025-08-27 06:03:49,192][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042144] [Batch 02104/03080] [00:26:13/00:12:10, 0.748s/it]: train_loss_raw=0.8327, running_loss=0.8080, LR=0.000100
[2025-08-27 06:03:55,068][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042152] [Batch 02112/03080] [00:26:19/00:12:04, 0.748s/it]: train_loss_raw=0.7657, running_loss=0.8070, LR=0.000100
[2025-08-27 06:04:01,055][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042160] [Batch 02120/03080] [00:26:25/00:11:58, 0.748s/it]: train_loss_raw=0.8879, running_loss=0.8071, LR=0.000100
[2025-08-27 06:04:07,233][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042168] [Batch 02128/03080] [00:26:31/00:11:52, 0.748s/it]: train_loss_raw=0.7614, running_loss=0.8057, LR=0.000100
[2025-08-27 06:04:13,420][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042176] [Batch 02136/03080] [00:26:38/00:11:46, 0.748s/it]: train_loss_raw=0.7538, running_loss=0.8051, LR=0.000100
[2025-08-27 06:04:19,376][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042184] [Batch 02144/03080] [00:26:44/00:11:40, 0.748s/it]: train_loss_raw=0.7473, running_loss=0.8058, LR=0.000100
[2025-08-27 06:04:25,242][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042192] [Batch 02152/03080] [00:26:49/00:11:34, 0.748s/it]: train_loss_raw=0.7961, running_loss=0.8056, LR=0.000100
[2025-08-27 06:04:31,151][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042200] [Batch 02160/03080] [00:26:55/00:11:28, 0.748s/it]: train_loss_raw=0.7541, running_loss=0.8034, LR=0.000100
[2025-08-27 06:04:36,896][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042208] [Batch 02168/03080] [00:27:01/00:11:22, 0.748s/it]: train_loss_raw=0.7794, running_loss=0.8015, LR=0.000100
[2025-08-27 06:04:42,767][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042216] [Batch 02176/03080] [00:27:07/00:11:16, 0.748s/it]: train_loss_raw=0.8640, running_loss=0.8025, LR=0.000100
[2025-08-27 06:04:48,658][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042224] [Batch 02184/03080] [00:27:13/00:11:10, 0.748s/it]: train_loss_raw=0.7189, running_loss=0.7996, LR=0.000100
[2025-08-27 06:04:54,388][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042232] [Batch 02192/03080] [00:27:19/00:11:04, 0.748s/it]: train_loss_raw=0.6713, running_loss=0.7963, LR=0.000100
[2025-08-27 06:05:00,367][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042240] [Batch 02200/03080] [00:27:25/00:10:58, 0.748s/it]: train_loss_raw=0.8725, running_loss=0.7977, LR=0.000100
[2025-08-27 06:05:06,429][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042248] [Batch 02208/03080] [00:27:31/00:10:52, 0.748s/it]: train_loss_raw=0.8721, running_loss=0.8009, LR=0.000100
[2025-08-27 06:05:12,474][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042256] [Batch 02216/03080] [00:27:37/00:10:46, 0.748s/it]: train_loss_raw=0.7512, running_loss=0.7986, LR=0.000100
[2025-08-27 06:05:18,639][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042264] [Batch 02224/03080] [00:27:43/00:10:40, 0.748s/it]: train_loss_raw=0.8207, running_loss=0.7977, LR=0.000100
[2025-08-27 06:05:24,604][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042272] [Batch 02232/03080] [00:27:49/00:10:34, 0.748s/it]: train_loss_raw=0.8907, running_loss=0.8010, LR=0.000100
[2025-08-27 06:05:30,377][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042280] [Batch 02240/03080] [00:27:55/00:10:28, 0.748s/it]: train_loss_raw=0.8032, running_loss=0.8032, LR=0.000100
[2025-08-27 06:05:36,331][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042288] [Batch 02248/03080] [00:28:01/00:10:22, 0.748s/it]: train_loss_raw=0.8558, running_loss=0.8064, LR=0.000100
[2025-08-27 06:05:42,184][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042296] [Batch 02256/03080] [00:28:06/00:10:16, 0.748s/it]: train_loss_raw=0.7770, running_loss=0.8060, LR=0.000100
[2025-08-27 06:05:48,113][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042304] [Batch 02264/03080] [00:28:12/00:10:10, 0.748s/it]: train_loss_raw=0.7441, running_loss=0.8066, LR=0.000100
[2025-08-27 06:05:53,952][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042312] [Batch 02272/03080] [00:28:18/00:10:04, 0.748s/it]: train_loss_raw=0.7307, running_loss=0.8075, LR=0.000100
[2025-08-27 06:06:00,009][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042320] [Batch 02280/03080] [00:28:24/00:09:58, 0.748s/it]: train_loss_raw=0.7751, running_loss=0.8072, LR=0.000100
[2025-08-27 06:06:05,813][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042328] [Batch 02288/03080] [00:28:30/00:09:52, 0.748s/it]: train_loss_raw=0.8277, running_loss=0.8062, LR=0.000100
[2025-08-27 06:06:11,572][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042336] [Batch 02296/03080] [00:28:36/00:09:46, 0.748s/it]: train_loss_raw=0.7092, running_loss=0.8038, LR=0.000100
[2025-08-27 06:06:17,413][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042344] [Batch 02304/03080] [00:28:42/00:09:40, 0.747s/it]: train_loss_raw=0.8080, running_loss=0.8044, LR=0.000100
[2025-08-27 06:06:23,418][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042352] [Batch 02312/03080] [00:28:48/00:09:34, 0.747s/it]: train_loss_raw=0.9009, running_loss=0.8055, LR=0.000100
[2025-08-27 06:06:29,189][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042360] [Batch 02320/03080] [00:28:53/00:09:28, 0.747s/it]: train_loss_raw=0.8607, running_loss=0.8059, LR=0.000100
[2025-08-27 06:06:35,184][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042368] [Batch 02328/03080] [00:28:59/00:09:22, 0.747s/it]: train_loss_raw=0.7728, running_loss=0.8034, LR=0.000100
[2025-08-27 06:06:40,994][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042376] [Batch 02336/03080] [00:29:05/00:09:15, 0.747s/it]: train_loss_raw=0.6889, running_loss=0.8017, LR=0.000100
[2025-08-27 06:06:46,725][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042384] [Batch 02344/03080] [00:29:11/00:09:09, 0.747s/it]: train_loss_raw=0.8148, running_loss=0.8009, LR=0.000100
[2025-08-27 06:06:52,614][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042392] [Batch 02352/03080] [00:29:17/00:09:03, 0.747s/it]: train_loss_raw=0.7884, running_loss=0.8017, LR=0.000100
[2025-08-27 06:06:58,776][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042400] [Batch 02360/03080] [00:29:23/00:08:58, 0.747s/it]: train_loss_raw=0.8865, running_loss=0.8041, LR=0.000100
[2025-08-27 06:07:04,598][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042408] [Batch 02368/03080] [00:29:29/00:08:51, 0.747s/it]: train_loss_raw=0.7593, running_loss=0.8040, LR=0.000100
[2025-08-27 06:07:10,325][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042416] [Batch 02376/03080] [00:29:35/00:08:45, 0.747s/it]: train_loss_raw=0.8350, running_loss=0.8036, LR=0.000100
[2025-08-27 06:07:16,197][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042424] [Batch 02384/03080] [00:29:40/00:08:39, 0.747s/it]: train_loss_raw=0.7456, running_loss=0.8040, LR=0.000100
[2025-08-27 06:07:22,431][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042432] [Batch 02392/03080] [00:29:47/00:08:34, 0.747s/it]: train_loss_raw=0.8773, running_loss=0.8056, LR=0.000100
[2025-08-27 06:07:28,373][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042440] [Batch 02400/03080] [00:29:53/00:08:28, 0.747s/it]: train_loss_raw=0.7460, running_loss=0.8062, LR=0.000100
[2025-08-27 06:07:34,180][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042448] [Batch 02408/03080] [00:29:58/00:08:22, 0.747s/it]: train_loss_raw=0.7796, running_loss=0.8032, LR=0.000100
[2025-08-27 06:07:40,286][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042456] [Batch 02416/03080] [00:30:05/00:08:16, 0.747s/it]: train_loss_raw=0.7400, running_loss=0.8024, LR=0.000100
[2025-08-27 06:07:46,251][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042464] [Batch 02424/03080] [00:30:10/00:08:10, 0.747s/it]: train_loss_raw=0.7604, running_loss=0.8022, LR=0.000100
[2025-08-27 06:07:52,076][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042472] [Batch 02432/03080] [00:30:16/00:08:04, 0.747s/it]: train_loss_raw=0.8435, running_loss=0.8026, LR=0.000100
[2025-08-27 06:07:57,967][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042480] [Batch 02440/03080] [00:30:22/00:07:58, 0.747s/it]: train_loss_raw=0.8316, running_loss=0.8009, LR=0.000100
[2025-08-27 06:08:03,899][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042488] [Batch 02448/03080] [00:30:28/00:07:52, 0.747s/it]: train_loss_raw=0.8425, running_loss=0.8022, LR=0.000100
[2025-08-27 06:08:09,709][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042496] [Batch 02456/03080] [00:30:34/00:07:46, 0.747s/it]: train_loss_raw=0.8454, running_loss=0.8041, LR=0.000100
[2025-08-27 06:08:15,447][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042504] [Batch 02464/03080] [00:30:40/00:07:40, 0.747s/it]: train_loss_raw=0.8988, running_loss=0.8057, LR=0.000100
[2025-08-27 06:08:21,608][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042512] [Batch 02472/03080] [00:30:46/00:07:34, 0.747s/it]: train_loss_raw=0.7700, running_loss=0.8048, LR=0.000100
[2025-08-27 06:08:27,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042520] [Batch 02480/03080] [00:30:52/00:07:28, 0.747s/it]: train_loss_raw=0.7286, running_loss=0.8024, LR=0.000100
[2025-08-27 06:08:33,699][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042528] [Batch 02488/03080] [00:30:58/00:07:22, 0.747s/it]: train_loss_raw=0.8932, running_loss=0.8035, LR=0.000100
[2025-08-27 06:08:39,752][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042536] [Batch 02496/03080] [00:31:04/00:07:16, 0.747s/it]: train_loss_raw=0.8227, running_loss=0.8025, LR=0.000100
[2025-08-27 06:08:45,678][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042544] [Batch 02504/03080] [00:31:10/00:07:10, 0.747s/it]: train_loss_raw=0.7385, running_loss=0.8008, LR=0.000100
[2025-08-27 06:08:51,625][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042552] [Batch 02512/03080] [00:31:16/00:07:04, 0.747s/it]: train_loss_raw=0.8697, running_loss=0.8001, LR=0.000100
[2025-08-27 06:08:57,566][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042560] [Batch 02520/03080] [00:31:22/00:06:58, 0.747s/it]: train_loss_raw=0.8366, running_loss=0.8012, LR=0.000100
[2025-08-27 06:09:03,704][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042568] [Batch 02528/03080] [00:31:28/00:06:52, 0.747s/it]: train_loss_raw=0.8615, running_loss=0.7990, LR=0.000100
[2025-08-27 06:09:09,804][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042576] [Batch 02536/03080] [00:31:34/00:06:46, 0.747s/it]: train_loss_raw=0.9821, running_loss=0.7998, LR=0.000100
[2025-08-27 06:09:15,833][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042584] [Batch 02544/03080] [00:31:40/00:06:40, 0.747s/it]: train_loss_raw=0.9151, running_loss=0.7990, LR=0.000100
[2025-08-27 06:09:21,701][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042592] [Batch 02552/03080] [00:31:46/00:06:34, 0.747s/it]: train_loss_raw=0.7720, running_loss=0.7957, LR=0.000100
[2025-08-27 06:09:27,662][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042600] [Batch 02560/03080] [00:31:52/00:06:28, 0.747s/it]: train_loss_raw=0.7685, running_loss=0.7970, LR=0.000100
[2025-08-27 06:09:33,677][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042608] [Batch 02568/03080] [00:31:58/00:06:22, 0.747s/it]: train_loss_raw=0.8263, running_loss=0.7978, LR=0.000100
[2025-08-27 06:09:39,746][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042616] [Batch 02576/03080] [00:32:04/00:06:16, 0.747s/it]: train_loss_raw=0.9326, running_loss=0.8001, LR=0.000100
[2025-08-27 06:09:45,917][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042624] [Batch 02584/03080] [00:32:10/00:06:10, 0.747s/it]: train_loss_raw=0.7006, running_loss=0.7993, LR=0.000100
[2025-08-27 06:09:51,837][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042632] [Batch 02592/03080] [00:32:16/00:06:04, 0.747s/it]: train_loss_raw=0.8156, running_loss=0.7989, LR=0.000100
[2025-08-27 06:09:57,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042640] [Batch 02600/03080] [00:32:22/00:05:58, 0.747s/it]: train_loss_raw=0.7859, running_loss=0.7956, LR=0.000100
[2025-08-27 06:10:03,658][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042648] [Batch 02608/03080] [00:32:28/00:05:52, 0.747s/it]: train_loss_raw=0.8387, running_loss=0.7956, LR=0.000100
[2025-08-27 06:10:09,925][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042656] [Batch 02616/03080] [00:32:34/00:05:46, 0.747s/it]: train_loss_raw=0.8285, running_loss=0.7974, LR=0.000100
[2025-08-27 06:10:16,089][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042664] [Batch 02624/03080] [00:32:40/00:05:40, 0.747s/it]: train_loss_raw=0.7703, running_loss=0.7983, LR=0.000100
[2025-08-27 06:10:21,962][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042672] [Batch 02632/03080] [00:32:46/00:05:34, 0.747s/it]: train_loss_raw=0.6533, running_loss=0.7975, LR=0.000100
[2025-08-27 06:10:28,056][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042680] [Batch 02640/03080] [00:32:52/00:05:28, 0.747s/it]: train_loss_raw=0.8758, running_loss=0.7964, LR=0.000100
[2025-08-27 06:10:33,997][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042688] [Batch 02648/03080] [00:32:58/00:05:22, 0.747s/it]: train_loss_raw=0.6066, running_loss=0.7949, LR=0.000100
[2025-08-27 06:10:40,065][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042696] [Batch 02656/03080] [00:33:04/00:05:16, 0.747s/it]: train_loss_raw=0.7508, running_loss=0.7936, LR=0.000100
[2025-08-27 06:10:45,991][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042704] [Batch 02664/03080] [00:33:10/00:05:10, 0.747s/it]: train_loss_raw=0.8454, running_loss=0.7953, LR=0.000100
[2025-08-27 06:10:51,950][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042712] [Batch 02672/03080] [00:33:16/00:05:04, 0.747s/it]: train_loss_raw=0.8373, running_loss=0.7944, LR=0.000100
[2025-08-27 06:10:57,584][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042720] [Batch 02680/03080] [00:33:22/00:04:58, 0.747s/it]: train_loss_raw=0.8667, running_loss=0.7965, LR=0.000100
[2025-08-27 06:11:03,637][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042728] [Batch 02688/03080] [00:33:28/00:04:52, 0.747s/it]: train_loss_raw=0.7795, running_loss=0.7954, LR=0.000100
[2025-08-27 06:11:09,884][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042736] [Batch 02696/03080] [00:33:34/00:04:46, 0.747s/it]: train_loss_raw=0.8727, running_loss=0.7958, LR=0.000100
[2025-08-27 06:11:15,860][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042744] [Batch 02704/03080] [00:33:40/00:04:40, 0.747s/it]: train_loss_raw=0.7384, running_loss=0.7945, LR=0.000100
[2025-08-27 06:11:21,785][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042752] [Batch 02712/03080] [00:33:46/00:04:34, 0.747s/it]: train_loss_raw=0.8793, running_loss=0.7939, LR=0.000100
[2025-08-27 06:11:27,998][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042760] [Batch 02720/03080] [00:33:52/00:04:29, 0.747s/it]: train_loss_raw=0.7663, running_loss=0.7937, LR=0.000100
[2025-08-27 06:11:33,929][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042768] [Batch 02728/03080] [00:33:58/00:04:23, 0.747s/it]: train_loss_raw=0.8638, running_loss=0.7940, LR=0.000100
[2025-08-27 06:11:39,867][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042776] [Batch 02736/03080] [00:34:04/00:04:17, 0.747s/it]: train_loss_raw=0.7984, running_loss=0.7933, LR=0.000100
[2025-08-27 06:11:46,018][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042784] [Batch 02744/03080] [00:34:10/00:04:11, 0.747s/it]: train_loss_raw=0.7657, running_loss=0.7951, LR=0.000100
[2025-08-27 06:11:52,194][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042792] [Batch 02752/03080] [00:34:16/00:04:05, 0.747s/it]: train_loss_raw=0.7381, running_loss=0.7942, LR=0.000100
[2025-08-27 06:11:58,099][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042800] [Batch 02760/03080] [00:34:22/00:03:59, 0.747s/it]: train_loss_raw=0.7772, running_loss=0.7942, LR=0.000100
[2025-08-27 06:12:04,114][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042808] [Batch 02768/03080] [00:34:28/00:03:53, 0.747s/it]: train_loss_raw=0.7483, running_loss=0.7946, LR=0.000100
[2025-08-27 06:12:10,133][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042816] [Batch 02776/03080] [00:34:34/00:03:47, 0.747s/it]: train_loss_raw=0.8522, running_loss=0.7930, LR=0.000100
[2025-08-27 06:12:16,165][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042824] [Batch 02784/03080] [00:34:40/00:03:41, 0.747s/it]: train_loss_raw=0.7919, running_loss=0.7942, LR=0.000100
[2025-08-27 06:12:22,314][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042832] [Batch 02792/03080] [00:34:47/00:03:35, 0.748s/it]: train_loss_raw=0.6970, running_loss=0.7891, LR=0.000100
[2025-08-27 06:12:28,493][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042840] [Batch 02800/03080] [00:34:53/00:03:29, 0.748s/it]: train_loss_raw=0.8212, running_loss=0.7881, LR=0.000100
[2025-08-27 06:12:34,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042848] [Batch 02808/03080] [00:34:59/00:03:23, 0.748s/it]: train_loss_raw=0.7971, running_loss=0.7884, LR=0.000100
[2025-08-27 06:12:40,698][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042856] [Batch 02816/03080] [00:35:05/00:03:17, 0.748s/it]: train_loss_raw=0.7205, running_loss=0.7870, LR=0.000100
[2025-08-27 06:12:46,800][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042864] [Batch 02824/03080] [00:35:11/00:03:11, 0.748s/it]: train_loss_raw=0.8394, running_loss=0.7902, LR=0.000100
[2025-08-27 06:12:53,027][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042872] [Batch 02832/03080] [00:35:17/00:03:05, 0.748s/it]: train_loss_raw=0.8866, running_loss=0.7904, LR=0.000100
[2025-08-27 06:12:59,230][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042880] [Batch 02840/03080] [00:35:23/00:02:59, 0.748s/it]: train_loss_raw=0.8162, running_loss=0.7866, LR=0.000100
[2025-08-27 06:13:05,426][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042888] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=0.7521, running_loss=0.7864, LR=0.000100
[2025-08-27 06:13:11,656][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042896] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=0.8052, running_loss=0.7886, LR=0.000100
[2025-08-27 06:13:17,784][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042904] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=0.8611, running_loss=0.7923, LR=0.000100
[2025-08-27 06:13:23,874][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042912] [Batch 02872/03080] [00:35:48/00:02:35, 0.748s/it]: train_loss_raw=0.8178, running_loss=0.7932, LR=0.000100
[2025-08-27 06:13:29,739][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042920] [Batch 02880/03080] [00:35:54/00:02:29, 0.748s/it]: train_loss_raw=0.7040, running_loss=0.7929, LR=0.000100
[2025-08-27 06:13:35,824][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042928] [Batch 02888/03080] [00:36:00/00:02:23, 0.748s/it]: train_loss_raw=0.7942, running_loss=0.7910, LR=0.000100
[2025-08-27 06:13:41,743][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042936] [Batch 02896/03080] [00:36:06/00:02:17, 0.748s/it]: train_loss_raw=0.7965, running_loss=0.7918, LR=0.000100
[2025-08-27 06:13:47,658][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042944] [Batch 02904/03080] [00:36:12/00:02:11, 0.748s/it]: train_loss_raw=0.8734, running_loss=0.7923, LR=0.000100
[2025-08-27 06:13:53,759][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042952] [Batch 02912/03080] [00:36:18/00:02:05, 0.748s/it]: train_loss_raw=0.8274, running_loss=0.7911, LR=0.000100
[2025-08-27 06:13:59,726][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042960] [Batch 02920/03080] [00:36:24/00:01:59, 0.748s/it]: train_loss_raw=0.7223, running_loss=0.7891, LR=0.000100
[2025-08-27 06:14:05,744][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042968] [Batch 02928/03080] [00:36:30/00:01:53, 0.748s/it]: train_loss_raw=0.6686, running_loss=0.7869, LR=0.000100
[2025-08-27 06:14:11,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042976] [Batch 02936/03080] [00:36:36/00:01:47, 0.748s/it]: train_loss_raw=0.8836, running_loss=0.7870, LR=0.000100
[2025-08-27 06:14:17,832][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042984] [Batch 02944/03080] [00:36:42/00:01:41, 0.748s/it]: train_loss_raw=0.7543, running_loss=0.7885, LR=0.000100
[2025-08-27 06:14:23,829][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042992] [Batch 02952/03080] [00:36:48/00:01:35, 0.748s/it]: train_loss_raw=0.7457, running_loss=0.7872, LR=0.000100
[2025-08-27 06:14:30,100][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043000] [Batch 02960/03080] [00:36:54/00:01:29, 0.748s/it]: train_loss_raw=0.9193, running_loss=0.7876, LR=0.000100
[2025-08-27 06:14:36,135][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043008] [Batch 02968/03080] [00:37:00/00:01:23, 0.748s/it]: train_loss_raw=0.8650, running_loss=0.7881, LR=0.000100
[2025-08-27 06:14:42,475][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043016] [Batch 02976/03080] [00:37:07/00:01:17, 0.748s/it]: train_loss_raw=0.8713, running_loss=0.7896, LR=0.000100
[2025-08-27 06:14:48,275][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043024] [Batch 02984/03080] [00:37:12/00:01:11, 0.748s/it]: train_loss_raw=0.6939, running_loss=0.7872, LR=0.000100
[2025-08-27 06:14:54,143][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043032] [Batch 02992/03080] [00:37:18/00:01:05, 0.748s/it]: train_loss_raw=0.7613, running_loss=0.7863, LR=0.000100
[2025-08-27 06:15:00,374][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043040] [Batch 03000/03080] [00:37:25/00:00:59, 0.748s/it]: train_loss_raw=0.6432, running_loss=0.7848, LR=0.000100
[2025-08-27 06:15:06,378][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043048] [Batch 03008/03080] [00:37:31/00:00:53, 0.748s/it]: train_loss_raw=0.8672, running_loss=0.7844, LR=0.000100
[2025-08-27 06:15:12,326][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043056] [Batch 03016/03080] [00:37:37/00:00:47, 0.748s/it]: train_loss_raw=0.8277, running_loss=0.7824, LR=0.000100
[2025-08-27 06:15:18,192][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043064] [Batch 03024/03080] [00:37:42/00:00:41, 0.748s/it]: train_loss_raw=0.8425, running_loss=0.7846, LR=0.000100
[2025-08-27 06:15:24,000][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043072] [Batch 03032/03080] [00:37:48/00:00:35, 0.748s/it]: train_loss_raw=0.7334, running_loss=0.7850, LR=0.000100
[2025-08-27 06:15:29,861][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043080] [Batch 03040/03080] [00:37:54/00:00:29, 0.748s/it]: train_loss_raw=0.8180, running_loss=0.7862, LR=0.000100
[2025-08-27 06:15:35,788][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043088] [Batch 03048/03080] [00:38:00/00:00:23, 0.748s/it]: train_loss_raw=0.6786, running_loss=0.7842, LR=0.000100
[2025-08-27 06:15:41,683][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043096] [Batch 03056/03080] [00:38:06/00:00:17, 0.748s/it]: train_loss_raw=0.8322, running_loss=0.7828, LR=0.000100
[2025-08-27 06:15:47,819][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043104] [Batch 03064/03080] [00:38:12/00:00:11, 0.748s/it]: train_loss_raw=0.6784, running_loss=0.7823, LR=0.000100
[2025-08-27 06:15:53,835][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043112] [Batch 03072/03080] [00:38:18/00:00:05, 0.748s/it]: train_loss_raw=0.8142, running_loss=0.7853, LR=0.000100
[2025-08-27 06:16:04,004][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043120] [Batch 03080/03080] [00:38:28/00:00:00, 0.750s/it]: train_loss_raw=0.7654, running_loss=0.7859, LR=0.000100
[2025-08-27 06:16:04,531][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-27 06:16:15,341][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00007/00310] [00:00:10/00:06:48, 1.351s/it]
[2025-08-27 06:16:27,528][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00015/00310] [00:00:22/00:07:02, 1.437s/it]
[2025-08-27 06:16:40,230][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00023/00310] [00:00:35/00:07:05, 1.487s/it]
[2025-08-27 06:16:52,615][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00031/00310] [00:00:48/00:06:57, 1.503s/it]
[2025-08-27 06:17:05,457][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00039/00310] [00:01:00/00:06:51, 1.523s/it]
[2025-08-27 06:17:18,561][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00047/00310] [00:01:14/00:06:44, 1.542s/it]
[2025-08-27 06:17:31,652][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00055/00310] [00:01:27/00:06:35, 1.556s/it]
[2025-08-27 06:17:44,235][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00063/00310] [00:01:39/00:06:23, 1.558s/it]
[2025-08-27 06:17:56,524][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00071/00310] [00:01:51/00:06:10, 1.555s/it]
[2025-08-27 06:18:09,399][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00079/00310] [00:02:04/00:05:58, 1.561s/it]
[2025-08-27 06:18:22,574][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00087/00310] [00:02:18/00:05:48, 1.569s/it]
[2025-08-27 06:18:35,200][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00095/00310] [00:02:30/00:05:35, 1.569s/it]
[2025-08-27 06:18:48,028][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00103/00310] [00:02:43/00:05:23, 1.572s/it]
[2025-08-27 06:19:00,487][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00111/00310] [00:02:55/00:05:11, 1.571s/it]
[2025-08-27 06:19:13,195][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00119/00310] [00:03:08/00:04:58, 1.572s/it]
[2025-08-27 06:19:26,185][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00127/00310] [00:03:21/00:04:46, 1.575s/it]
[2025-08-27 06:19:38,656][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00135/00310] [00:03:34/00:04:33, 1.574s/it]
[2025-08-27 06:19:51,241][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00143/00310] [00:03:46/00:04:21, 1.574s/it]
[2025-08-27 06:20:03,247][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00151/00310] [00:03:58/00:04:08, 1.570s/it]
[2025-08-27 06:20:14,829][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00159/00310] [00:04:10/00:03:54, 1.564s/it]
[2025-08-27 06:20:27,282][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00167/00310] [00:04:22/00:03:42, 1.564s/it]
[2025-08-27 06:20:39,051][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00175/00310] [00:04:34/00:03:29, 1.560s/it]
[2025-08-27 06:20:50,962][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00183/00310] [00:04:46/00:03:16, 1.557s/it]
[2025-08-27 06:21:03,360][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00191/00310] [00:04:58/00:03:03, 1.556s/it]
[2025-08-27 06:21:15,041][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00199/00310] [00:05:10/00:02:50, 1.553s/it]
[2025-08-27 06:21:26,698][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00207/00310] [00:05:22/00:02:37, 1.549s/it]
[2025-08-27 06:21:38,807][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00215/00310] [00:05:34/00:02:25, 1.548s/it]
[2025-08-27 06:21:50,697][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00223/00310] [00:05:46/00:02:12, 1.545s/it]
[2025-08-27 06:22:03,806][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00231/00310] [00:05:59/00:02:00, 1.549s/it]
[2025-08-27 06:22:16,736][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00239/00310] [00:06:12/00:01:48, 1.551s/it]
[2025-08-27 06:22:28,307][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00247/00310] [00:06:23/00:01:35, 1.547s/it]
[2025-08-27 06:22:40,513][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00255/00310] [00:06:35/00:01:23, 1.547s/it]
[2025-08-27 06:22:52,603][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00263/00310] [00:06:48/00:01:11, 1.546s/it]
[2025-08-27 06:23:05,059][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00271/00310] [00:07:00/00:00:58, 1.546s/it]
[2025-08-27 06:23:17,525][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00279/00310] [00:07:12/00:00:46, 1.546s/it]
[2025-08-27 06:23:29,827][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00287/00310] [00:07:25/00:00:34, 1.546s/it]
[2025-08-27 06:23:42,261][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00295/00310] [00:07:37/00:00:21, 1.546s/it]
[2025-08-27 06:23:54,977][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00303/00310] [00:07:50/00:00:09, 1.548s/it]
[2025-08-27 06:24:04,403][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=0.78589, valid_loss=1.74884
[2025-08-27 06:24:04,403][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-27 06:24:04,403][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.654
[2025-08-27 06:24:04,403][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.062
[2025-08-27 06:24:04,403][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.064
[2025-08-27 06:24:04,404][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.024
[2025-08-27 06:24:04,416][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 10:57:18, remaining time 12:31:12, 00:46:57 per epoch
[2025-08-27 06:24:11,195][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043128] [Batch 00008/03080] [00:00:06/00:41:04, 0.802s/it]: train_loss_raw=0.5956, running_loss=0.7686, LR=0.000100
[2025-08-27 06:24:17,439][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043136] [Batch 00016/03080] [00:00:12/00:40:24, 0.791s/it]: train_loss_raw=0.7629, running_loss=0.7682, LR=0.000100
[2025-08-27 06:24:23,631][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043144] [Batch 00024/03080] [00:00:18/00:40:00, 0.786s/it]: train_loss_raw=0.7005, running_loss=0.7652, LR=0.000100
[2025-08-27 06:24:29,548][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043152] [Batch 00032/03080] [00:00:24/00:39:19, 0.774s/it]: train_loss_raw=0.6563, running_loss=0.7616, LR=0.000100
[2025-08-27 06:24:35,651][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043160] [Batch 00040/03080] [00:00:30/00:39:06, 0.772s/it]: train_loss_raw=0.7409, running_loss=0.7609, LR=0.000100
[2025-08-27 06:24:41,820][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043168] [Batch 00048/03080] [00:00:37/00:38:59, 0.772s/it]: train_loss_raw=0.7287, running_loss=0.7586, LR=0.000100
[2025-08-27 06:24:47,947][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043176] [Batch 00056/03080] [00:00:43/00:38:51, 0.771s/it]: train_loss_raw=0.7165, running_loss=0.7581, LR=0.000100
[2025-08-27 06:24:54,057][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043184] [Batch 00064/03080] [00:00:49/00:38:42, 0.770s/it]: train_loss_raw=0.7806, running_loss=0.7586, LR=0.000100
[2025-08-27 06:25:00,141][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043192] [Batch 00072/03080] [00:00:55/00:38:32, 0.769s/it]: train_loss_raw=0.6875, running_loss=0.7570, LR=0.000100
[2025-08-27 06:25:06,211][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043200] [Batch 00080/03080] [00:01:01/00:38:23, 0.768s/it]: train_loss_raw=0.7379, running_loss=0.7584, LR=0.000100
[2025-08-27 06:25:12,035][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043208] [Batch 00088/03080] [00:01:07/00:38:06, 0.764s/it]: train_loss_raw=0.6504, running_loss=0.7581, LR=0.000100
[2025-08-27 06:25:17,787][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043216] [Batch 00096/03080] [00:01:13/00:37:49, 0.761s/it]: train_loss_raw=0.6789, running_loss=0.7570, LR=0.000100
[2025-08-27 06:25:23,711][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043224] [Batch 00104/03080] [00:01:18/00:37:38, 0.759s/it]: train_loss_raw=0.7563, running_loss=0.7574, LR=0.000100
[2025-08-27 06:25:29,793][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043232] [Batch 00112/03080] [00:01:25/00:37:32, 0.759s/it]: train_loss_raw=0.8229, running_loss=0.7573, LR=0.000100
[2025-08-27 06:25:35,787][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043240] [Batch 00120/03080] [00:01:31/00:37:24, 0.758s/it]: train_loss_raw=0.7394, running_loss=0.7565, LR=0.000100
[2025-08-27 06:25:42,057][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043248] [Batch 00128/03080] [00:01:37/00:37:23, 0.760s/it]: train_loss_raw=0.7267, running_loss=0.7577, LR=0.000100
[2025-08-27 06:25:48,283][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043256] [Batch 00136/03080] [00:01:43/00:37:20, 0.761s/it]: train_loss_raw=0.7548, running_loss=0.7581, LR=0.000100
[2025-08-27 06:25:54,027][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043264] [Batch 00144/03080] [00:01:49/00:37:07, 0.759s/it]: train_loss_raw=0.7745, running_loss=0.7593, LR=0.000100
[2025-08-27 06:26:00,161][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043272] [Batch 00152/03080] [00:01:55/00:37:02, 0.759s/it]: train_loss_raw=0.6629, running_loss=0.7553, LR=0.000100
[2025-08-27 06:26:05,922][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043280] [Batch 00160/03080] [00:02:01/00:36:50, 0.757s/it]: train_loss_raw=0.7095, running_loss=0.7571, LR=0.000100
[2025-08-27 06:26:11,710][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043288] [Batch 00168/03080] [00:02:06/00:36:40, 0.756s/it]: train_loss_raw=0.7542, running_loss=0.7573, LR=0.000100
[2025-08-27 06:26:17,662][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043296] [Batch 00176/03080] [00:02:12/00:36:32, 0.755s/it]: train_loss_raw=0.7911, running_loss=0.7560, LR=0.000100
[2025-08-27 06:26:23,710][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043304] [Batch 00184/03080] [00:02:18/00:36:26, 0.755s/it]: train_loss_raw=0.7266, running_loss=0.7540, LR=0.000100
[2025-08-27 06:26:29,827][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043312] [Batch 00192/03080] [00:02:25/00:36:21, 0.755s/it]: train_loss_raw=0.8498, running_loss=0.7563, LR=0.000100
[2025-08-27 06:26:35,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043320] [Batch 00200/03080] [00:02:31/00:36:17, 0.756s/it]: train_loss_raw=0.6033, running_loss=0.7579, LR=0.000100
[2025-08-27 06:26:41,926][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043328] [Batch 00208/03080] [00:02:37/00:36:09, 0.756s/it]: train_loss_raw=0.7698, running_loss=0.7589, LR=0.000100
[2025-08-27 06:26:47,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043336] [Batch 00216/03080] [00:02:43/00:36:03, 0.756s/it]: train_loss_raw=0.7854, running_loss=0.7588, LR=0.000100
[2025-08-27 06:26:54,020][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043344] [Batch 00224/03080] [00:02:49/00:35:57, 0.756s/it]: train_loss_raw=0.6658, running_loss=0.7568, LR=0.000100
[2025-08-27 06:26:59,940][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043352] [Batch 00232/03080] [00:02:55/00:35:50, 0.755s/it]: train_loss_raw=0.7296, running_loss=0.7570, LR=0.000100
[2025-08-27 06:27:05,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043360] [Batch 00240/03080] [00:03:01/00:35:42, 0.754s/it]: train_loss_raw=0.8652, running_loss=0.7584, LR=0.000100
[2025-08-27 06:27:12,045][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043368] [Batch 00248/03080] [00:03:07/00:35:38, 0.755s/it]: train_loss_raw=0.7086, running_loss=0.7593, LR=0.000100
[2025-08-27 06:27:18,012][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043376] [Batch 00256/03080] [00:03:13/00:35:31, 0.755s/it]: train_loss_raw=0.7302, running_loss=0.7571, LR=0.000100
[2025-08-27 06:27:24,026][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043384] [Batch 00264/03080] [00:03:19/00:35:25, 0.755s/it]: train_loss_raw=0.8512, running_loss=0.7568, LR=0.000100
[2025-08-27 06:27:30,239][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043392] [Batch 00272/03080] [00:03:25/00:35:21, 0.755s/it]: train_loss_raw=0.7034, running_loss=0.7573, LR=0.000100
[2025-08-27 06:27:36,279][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043400] [Batch 00280/03080] [00:03:31/00:35:15, 0.755s/it]: train_loss_raw=0.6722, running_loss=0.7578, LR=0.000100
[2025-08-27 06:27:42,368][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043408] [Batch 00288/03080] [00:03:37/00:35:09, 0.756s/it]: train_loss_raw=0.7599, running_loss=0.7562, LR=0.000100
[2025-08-27 06:27:48,525][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043416] [Batch 00296/03080] [00:03:43/00:35:04, 0.756s/it]: train_loss_raw=0.8028, running_loss=0.7519, LR=0.000100
[2025-08-27 06:27:54,480][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043424] [Batch 00304/03080] [00:03:49/00:34:57, 0.756s/it]: train_loss_raw=0.8881, running_loss=0.7536, LR=0.000100
[2025-08-27 06:28:00,582][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043432] [Batch 00312/03080] [00:03:55/00:34:52, 0.756s/it]: train_loss_raw=0.7233, running_loss=0.7562, LR=0.000100
[2025-08-27 06:28:06,549][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043440] [Batch 00320/03080] [00:04:01/00:34:45, 0.756s/it]: train_loss_raw=0.6909, running_loss=0.7541, LR=0.000100
[2025-08-27 06:28:12,318][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043448] [Batch 00328/03080] [00:04:07/00:34:36, 0.755s/it]: train_loss_raw=0.6595, running_loss=0.7516, LR=0.000100
[2025-08-27 06:28:18,077][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043456] [Batch 00336/03080] [00:04:13/00:34:28, 0.754s/it]: train_loss_raw=0.6773, running_loss=0.7526, LR=0.000100
[2025-08-27 06:28:23,923][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043464] [Batch 00344/03080] [00:04:19/00:34:21, 0.753s/it]: train_loss_raw=0.7565, running_loss=0.7518, LR=0.000100
[2025-08-27 06:28:29,760][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043472] [Batch 00352/03080] [00:04:24/00:34:13, 0.753s/it]: train_loss_raw=0.6815, running_loss=0.7518, LR=0.000100
[2025-08-27 06:28:35,679][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043480] [Batch 00360/03080] [00:04:30/00:34:06, 0.753s/it]: train_loss_raw=0.6878, running_loss=0.7498, LR=0.000100
[2025-08-27 06:28:41,735][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043488] [Batch 00368/03080] [00:04:36/00:34:01, 0.753s/it]: train_loss_raw=0.7192, running_loss=0.7475, LR=0.000100
[2025-08-27 06:28:47,648][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043496] [Batch 00376/03080] [00:04:42/00:33:54, 0.752s/it]: train_loss_raw=0.8060, running_loss=0.7468, LR=0.000100
[2025-08-27 06:28:53,876][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043504] [Batch 00384/03080] [00:04:49/00:33:49, 0.753s/it]: train_loss_raw=0.6970, running_loss=0.7448, LR=0.000100
[2025-08-27 06:28:59,870][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043512] [Batch 00392/03080] [00:04:55/00:33:43, 0.753s/it]: train_loss_raw=0.7749, running_loss=0.7463, LR=0.000100
[2025-08-27 06:29:05,622][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043520] [Batch 00400/03080] [00:05:00/00:33:35, 0.752s/it]: train_loss_raw=0.7802, running_loss=0.7489, LR=0.000100
[2025-08-27 06:29:11,557][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043528] [Batch 00408/03080] [00:05:06/00:33:29, 0.752s/it]: train_loss_raw=0.7521, running_loss=0.7493, LR=0.000100
[2025-08-27 06:29:17,723][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043536] [Batch 00416/03080] [00:05:12/00:33:24, 0.752s/it]: train_loss_raw=0.7438, running_loss=0.7475, LR=0.000100
[2025-08-27 06:29:23,881][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043544] [Batch 00424/03080] [00:05:19/00:33:18, 0.753s/it]: train_loss_raw=0.8039, running_loss=0.7462, LR=0.000100
[2025-08-27 06:29:29,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043552] [Batch 00432/03080] [00:05:25/00:33:13, 0.753s/it]: train_loss_raw=0.7165, running_loss=0.7469, LR=0.000100
[2025-08-27 06:29:36,177][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043560] [Batch 00440/03080] [00:05:31/00:33:08, 0.753s/it]: train_loss_raw=0.7857, running_loss=0.7459, LR=0.000100
[2025-08-27 06:29:42,522][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043568] [Batch 00448/03080] [00:05:37/00:33:04, 0.754s/it]: train_loss_raw=0.7630, running_loss=0.7454, LR=0.000100
[2025-08-27 06:29:48,553][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043576] [Batch 00456/03080] [00:05:43/00:32:58, 0.754s/it]: train_loss_raw=0.7799, running_loss=0.7476, LR=0.000100
[2025-08-27 06:29:54,537][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043584] [Batch 00464/03080] [00:05:49/00:32:51, 0.754s/it]: train_loss_raw=0.7554, running_loss=0.7518, LR=0.000100
[2025-08-27 06:30:00,405][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043592] [Batch 00472/03080] [00:05:55/00:32:44, 0.753s/it]: train_loss_raw=0.6901, running_loss=0.7518, LR=0.000100
[2025-08-27 06:30:06,316][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043600] [Batch 00480/03080] [00:06:01/00:32:38, 0.753s/it]: train_loss_raw=0.8324, running_loss=0.7526, LR=0.000100
[2025-08-27 06:30:12,305][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043608] [Batch 00488/03080] [00:06:07/00:32:32, 0.753s/it]: train_loss_raw=0.7374, running_loss=0.7511, LR=0.000100
[2025-08-27 06:30:18,149][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043616] [Batch 00496/03080] [00:06:13/00:32:25, 0.753s/it]: train_loss_raw=0.7487, running_loss=0.7507, LR=0.000100
[2025-08-27 06:30:24,216][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043624] [Batch 00504/03080] [00:06:19/00:32:19, 0.753s/it]: train_loss_raw=0.7829, running_loss=0.7494, LR=0.000100
[2025-08-27 06:30:30,197][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043632] [Batch 00512/03080] [00:06:25/00:32:13, 0.753s/it]: train_loss_raw=0.7932, running_loss=0.7520, LR=0.000100
[2025-08-27 06:30:36,253][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043640] [Batch 00520/03080] [00:06:31/00:32:07, 0.753s/it]: train_loss_raw=0.8053, running_loss=0.7532, LR=0.000100
[2025-08-27 06:30:42,134][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043648] [Batch 00528/03080] [00:06:37/00:32:00, 0.753s/it]: train_loss_raw=0.7717, running_loss=0.7536, LR=0.000100
[2025-08-27 06:30:48,227][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043656] [Batch 00536/03080] [00:06:43/00:31:54, 0.753s/it]: train_loss_raw=0.7516, running_loss=0.7565, LR=0.000100
[2025-08-27 06:30:54,196][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043664] [Batch 00544/03080] [00:06:49/00:31:48, 0.753s/it]: train_loss_raw=0.7648, running_loss=0.7560, LR=0.000100
[2025-08-27 06:30:59,999][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043672] [Batch 00552/03080] [00:06:55/00:31:41, 0.752s/it]: train_loss_raw=0.7737, running_loss=0.7570, LR=0.000100
[2025-08-27 06:31:05,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043680] [Batch 00560/03080] [00:07:00/00:31:34, 0.752s/it]: train_loss_raw=0.7258, running_loss=0.7576, LR=0.000100
[2025-08-27 06:31:11,621][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043688] [Batch 00568/03080] [00:07:06/00:31:27, 0.751s/it]: train_loss_raw=0.8461, running_loss=0.7595, LR=0.000100
[2025-08-27 06:31:17,621][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043696] [Batch 00576/03080] [00:07:12/00:31:21, 0.751s/it]: train_loss_raw=0.7848, running_loss=0.7613, LR=0.000100
[2025-08-27 06:31:23,460][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043704] [Batch 00584/03080] [00:07:18/00:31:14, 0.751s/it]: train_loss_raw=0.7373, running_loss=0.7590, LR=0.000100
[2025-08-27 06:31:29,299][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043712] [Batch 00592/03080] [00:07:24/00:31:08, 0.751s/it]: train_loss_raw=0.8575, running_loss=0.7569, LR=0.000100
[2025-08-27 06:31:35,077][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043720] [Batch 00600/03080] [00:07:30/00:31:01, 0.750s/it]: train_loss_raw=0.6828, running_loss=0.7586, LR=0.000100
[2025-08-27 06:31:40,969][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043728] [Batch 00608/03080] [00:07:36/00:30:54, 0.750s/it]: train_loss_raw=0.8034, running_loss=0.7590, LR=0.000100
[2025-08-27 06:31:46,871][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043736] [Batch 00616/03080] [00:07:42/00:30:48, 0.750s/it]: train_loss_raw=0.7264, running_loss=0.7574, LR=0.000100
[2025-08-27 06:31:52,860][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043744] [Batch 00624/03080] [00:07:48/00:30:42, 0.750s/it]: train_loss_raw=0.7825, running_loss=0.7554, LR=0.000100
[2025-08-27 06:31:58,760][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043752] [Batch 00632/03080] [00:07:53/00:30:35, 0.750s/it]: train_loss_raw=0.7361, running_loss=0.7513, LR=0.000100
[2025-08-27 06:32:04,666][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043760] [Batch 00640/03080] [00:07:59/00:30:29, 0.750s/it]: train_loss_raw=0.7916, running_loss=0.7537, LR=0.000100
[2025-08-27 06:32:10,541][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043768] [Batch 00648/03080] [00:08:05/00:30:23, 0.750s/it]: train_loss_raw=0.6661, running_loss=0.7517, LR=0.000100
[2025-08-27 06:32:16,367][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043776] [Batch 00656/03080] [00:08:11/00:30:16, 0.749s/it]: train_loss_raw=0.6481, running_loss=0.7506, LR=0.000100
[2025-08-27 06:32:22,228][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043784] [Batch 00664/03080] [00:08:17/00:30:09, 0.749s/it]: train_loss_raw=0.7792, running_loss=0.7497, LR=0.000100
[2025-08-27 06:32:28,135][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043792] [Batch 00672/03080] [00:08:23/00:30:03, 0.749s/it]: train_loss_raw=0.7213, running_loss=0.7510, LR=0.000100
[2025-08-27 06:32:34,029][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043800] [Batch 00680/03080] [00:08:29/00:29:57, 0.749s/it]: train_loss_raw=0.7202, running_loss=0.7492, LR=0.000100
[2025-08-27 06:32:39,849][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043808] [Batch 00688/03080] [00:08:35/00:29:50, 0.749s/it]: train_loss_raw=0.7071, running_loss=0.7493, LR=0.000100
[2025-08-27 06:32:45,639][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043816] [Batch 00696/03080] [00:08:40/00:29:44, 0.748s/it]: train_loss_raw=0.7262, running_loss=0.7500, LR=0.000100
[2025-08-27 06:32:51,546][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043824] [Batch 00704/03080] [00:08:46/00:29:37, 0.748s/it]: train_loss_raw=0.7159, running_loss=0.7503, LR=0.000100
[2025-08-27 06:32:57,360][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043832] [Batch 00712/03080] [00:08:52/00:29:31, 0.748s/it]: train_loss_raw=0.7655, running_loss=0.7492, LR=0.000100
[2025-08-27 06:33:03,220][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043840] [Batch 00720/03080] [00:08:58/00:29:24, 0.748s/it]: train_loss_raw=0.7889, running_loss=0.7508, LR=0.000100
[2025-08-27 06:33:09,008][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043848] [Batch 00728/03080] [00:09:04/00:29:18, 0.748s/it]: train_loss_raw=0.7499, running_loss=0.7497, LR=0.000100
[2025-08-27 06:33:14,875][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043856] [Batch 00736/03080] [00:09:10/00:29:11, 0.747s/it]: train_loss_raw=0.8323, running_loss=0.7483, LR=0.000100
[2025-08-27 06:33:20,872][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043864] [Batch 00744/03080] [00:09:16/00:29:06, 0.747s/it]: train_loss_raw=0.7136, running_loss=0.7469, LR=0.000100
[2025-08-27 06:33:26,925][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043872] [Batch 00752/03080] [00:09:22/00:29:00, 0.748s/it]: train_loss_raw=0.7190, running_loss=0.7454, LR=0.000100
[2025-08-27 06:33:32,585][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043880] [Batch 00760/03080] [00:09:27/00:28:53, 0.747s/it]: train_loss_raw=0.6440, running_loss=0.7420, LR=0.000100
[2025-08-27 06:33:38,206][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043888] [Batch 00768/03080] [00:09:33/00:28:46, 0.747s/it]: train_loss_raw=0.7136, running_loss=0.7396, LR=0.000100
[2025-08-27 06:33:44,020][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043896] [Batch 00776/03080] [00:09:39/00:28:39, 0.746s/it]: train_loss_raw=0.7043, running_loss=0.7383, LR=0.000100
[2025-08-27 06:33:49,912][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043904] [Batch 00784/03080] [00:09:45/00:28:33, 0.746s/it]: train_loss_raw=0.7393, running_loss=0.7392, LR=0.000100
[2025-08-27 06:33:55,729][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043912] [Batch 00792/03080] [00:09:50/00:28:27, 0.746s/it]: train_loss_raw=0.7942, running_loss=0.7418, LR=0.000100
[2025-08-27 06:34:01,584][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043920] [Batch 00800/03080] [00:09:56/00:28:20, 0.746s/it]: train_loss_raw=0.5550, running_loss=0.7386, LR=0.000100
[2025-08-27 06:34:07,494][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043928] [Batch 00808/03080] [00:10:02/00:28:14, 0.746s/it]: train_loss_raw=0.8472, running_loss=0.7394, LR=0.000100
[2025-08-27 06:34:13,428][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043936] [Batch 00816/03080] [00:10:08/00:28:08, 0.746s/it]: train_loss_raw=0.6478, running_loss=0.7374, LR=0.000100
[2025-08-27 06:34:19,341][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043944] [Batch 00824/03080] [00:10:14/00:28:02, 0.746s/it]: train_loss_raw=0.7338, running_loss=0.7411, LR=0.000100
[2025-08-27 06:34:25,258][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043952] [Batch 00832/03080] [00:10:20/00:27:56, 0.746s/it]: train_loss_raw=0.8241, running_loss=0.7427, LR=0.000100
[2025-08-27 06:34:31,084][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043960] [Batch 00840/03080] [00:10:26/00:27:50, 0.746s/it]: train_loss_raw=0.6565, running_loss=0.7417, LR=0.000100
[2025-08-27 06:34:36,920][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043968] [Batch 00848/03080] [00:10:32/00:27:43, 0.745s/it]: train_loss_raw=0.7027, running_loss=0.7421, LR=0.000100
[2025-08-27 06:34:42,811][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043976] [Batch 00856/03080] [00:10:38/00:27:37, 0.745s/it]: train_loss_raw=0.7413, running_loss=0.7430, LR=0.000100
[2025-08-27 06:34:48,715][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043984] [Batch 00864/03080] [00:10:43/00:27:31, 0.745s/it]: train_loss_raw=0.6624, running_loss=0.7442, LR=0.000100
[2025-08-27 06:34:54,541][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043992] [Batch 00872/03080] [00:10:49/00:27:25, 0.745s/it]: train_loss_raw=0.7682, running_loss=0.7431, LR=0.000100
[2025-08-27 06:35:00,400][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044000] [Batch 00880/03080] [00:10:55/00:27:19, 0.745s/it]: train_loss_raw=0.7255, running_loss=0.7418, LR=0.000100
[2025-08-27 06:35:10,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044008] [Batch 00888/03080] [00:11:05/00:27:22, 0.749s/it]: train_loss_raw=0.7558, running_loss=0.7414, LR=0.000100
[2025-08-27 06:35:16,124][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044016] [Batch 00896/03080] [00:11:11/00:27:16, 0.749s/it]: train_loss_raw=0.7524, running_loss=0.7411, LR=0.000100
[2025-08-27 06:35:21,895][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044024] [Batch 00904/03080] [00:11:17/00:27:09, 0.749s/it]: train_loss_raw=0.7249, running_loss=0.7410, LR=0.000100
[2025-08-27 06:35:27,639][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044032] [Batch 00912/03080] [00:11:22/00:27:03, 0.749s/it]: train_loss_raw=0.7169, running_loss=0.7410, LR=0.000100
[2025-08-27 06:35:33,498][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044040] [Batch 00920/03080] [00:11:28/00:26:56, 0.749s/it]: train_loss_raw=0.8048, running_loss=0.7435, LR=0.000100
[2025-08-27 06:35:39,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044048] [Batch 00928/03080] [00:11:34/00:26:50, 0.748s/it]: train_loss_raw=0.7228, running_loss=0.7456, LR=0.000100
[2025-08-27 06:35:45,175][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044056] [Batch 00936/03080] [00:11:40/00:26:44, 0.748s/it]: train_loss_raw=0.6678, running_loss=0.7444, LR=0.000100
[2025-08-27 06:35:50,912][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044064] [Batch 00944/03080] [00:11:46/00:26:37, 0.748s/it]: train_loss_raw=0.7808, running_loss=0.7455, LR=0.000100
[2025-08-27 06:35:56,574][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044072] [Batch 00952/03080] [00:11:51/00:26:31, 0.748s/it]: train_loss_raw=0.7613, running_loss=0.7484, LR=0.000100
[2025-08-27 06:36:02,550][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044080] [Batch 00960/03080] [00:11:57/00:26:25, 0.748s/it]: train_loss_raw=0.7858, running_loss=0.7473, LR=0.000100
[2025-08-27 06:36:08,489][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044088] [Batch 00968/03080] [00:12:03/00:26:19, 0.748s/it]: train_loss_raw=0.7598, running_loss=0.7493, LR=0.000100
[2025-08-27 06:36:14,317][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044096] [Batch 00976/03080] [00:12:09/00:26:12, 0.747s/it]: train_loss_raw=0.7161, running_loss=0.7467, LR=0.000100
[2025-08-27 06:36:20,152][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044104] [Batch 00984/03080] [00:12:15/00:26:06, 0.747s/it]: train_loss_raw=0.7954, running_loss=0.7459, LR=0.000100
[2025-08-27 06:36:25,631][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044112] [Batch 00992/03080] [00:12:20/00:25:59, 0.747s/it]: train_loss_raw=0.7896, running_loss=0.7459, LR=0.000100
[2025-08-27 06:36:31,269][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044120] [Batch 01000/03080] [00:12:26/00:25:52, 0.746s/it]: train_loss_raw=0.7013, running_loss=0.7432, LR=0.000100
[2025-08-27 06:36:36,923][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044128] [Batch 01008/03080] [00:12:32/00:25:46, 0.746s/it]: train_loss_raw=0.6650, running_loss=0.7398, LR=0.000100
[2025-08-27 06:36:42,814][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044136] [Batch 01016/03080] [00:12:38/00:25:39, 0.746s/it]: train_loss_raw=0.7252, running_loss=0.7391, LR=0.000100
[2025-08-27 06:36:48,723][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044144] [Batch 01024/03080] [00:12:43/00:25:33, 0.746s/it]: train_loss_raw=0.7313, running_loss=0.7402, LR=0.000100
[2025-08-27 06:36:54,543][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044152] [Batch 01032/03080] [00:12:49/00:25:27, 0.746s/it]: train_loss_raw=0.7490, running_loss=0.7395, LR=0.000100
[2025-08-27 06:37:00,415][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044160] [Batch 01040/03080] [00:12:55/00:25:21, 0.746s/it]: train_loss_raw=0.7991, running_loss=0.7400, LR=0.000100
[2025-08-27 06:37:06,313][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044168] [Batch 01048/03080] [00:13:01/00:25:15, 0.746s/it]: train_loss_raw=0.8736, running_loss=0.7420, LR=0.000100
[2025-08-27 06:37:12,236][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044176] [Batch 01056/03080] [00:13:07/00:25:09, 0.746s/it]: train_loss_raw=0.7492, running_loss=0.7413, LR=0.000100
[2025-08-27 06:37:18,082][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044184] [Batch 01064/03080] [00:13:13/00:25:03, 0.746s/it]: train_loss_raw=0.6997, running_loss=0.7447, LR=0.000100
[2025-08-27 06:37:23,893][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044192] [Batch 01072/03080] [00:13:19/00:24:56, 0.745s/it]: train_loss_raw=0.8354, running_loss=0.7437, LR=0.000100
[2025-08-27 06:37:29,727][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044200] [Batch 01080/03080] [00:13:24/00:24:50, 0.745s/it]: train_loss_raw=0.6887, running_loss=0.7442, LR=0.000100
[2025-08-27 06:37:35,642][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044208] [Batch 01088/03080] [00:13:30/00:24:44, 0.745s/it]: train_loss_raw=0.6729, running_loss=0.7412, LR=0.000100
[2025-08-27 06:37:41,470][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044216] [Batch 01096/03080] [00:13:36/00:24:38, 0.745s/it]: train_loss_raw=0.7562, running_loss=0.7419, LR=0.000100
[2025-08-27 06:37:47,299][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044224] [Batch 01104/03080] [00:13:42/00:24:32, 0.745s/it]: train_loss_raw=0.8438, running_loss=0.7439, LR=0.000100
[2025-08-27 06:37:53,208][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044232] [Batch 01112/03080] [00:13:48/00:24:26, 0.745s/it]: train_loss_raw=0.7618, running_loss=0.7443, LR=0.000100
[2025-08-27 06:37:59,234][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044240] [Batch 01120/03080] [00:13:54/00:24:20, 0.745s/it]: train_loss_raw=0.7564, running_loss=0.7458, LR=0.000100
[2025-08-27 06:38:05,262][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044248] [Batch 01128/03080] [00:14:00/00:24:14, 0.745s/it]: train_loss_raw=0.7485, running_loss=0.7438, LR=0.000100
[2025-08-27 06:38:11,090][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044256] [Batch 01136/03080] [00:14:06/00:24:08, 0.745s/it]: train_loss_raw=0.6551, running_loss=0.7416, LR=0.000100
[2025-08-27 06:38:16,897][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044264] [Batch 01144/03080] [00:14:12/00:24:02, 0.745s/it]: train_loss_raw=0.7436, running_loss=0.7414, LR=0.000100
[2025-08-27 06:38:22,801][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044272] [Batch 01152/03080] [00:14:18/00:23:55, 0.745s/it]: train_loss_raw=0.7275, running_loss=0.7380, LR=0.000100
[2025-08-27 06:38:28,742][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044280] [Batch 01160/03080] [00:14:23/00:23:50, 0.745s/it]: train_loss_raw=0.8154, running_loss=0.7369, LR=0.000100
[2025-08-27 06:38:34,603][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044288] [Batch 01168/03080] [00:14:29/00:23:43, 0.745s/it]: train_loss_raw=0.7372, running_loss=0.7366, LR=0.000100
[2025-08-27 06:38:40,487][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044296] [Batch 01176/03080] [00:14:35/00:23:37, 0.745s/it]: train_loss_raw=0.7465, running_loss=0.7362, LR=0.000100
[2025-08-27 06:38:46,317][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044304] [Batch 01184/03080] [00:14:41/00:23:31, 0.745s/it]: train_loss_raw=0.8502, running_loss=0.7364, LR=0.000100
[2025-08-27 06:38:52,370][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044312] [Batch 01192/03080] [00:14:47/00:23:25, 0.745s/it]: train_loss_raw=0.7705, running_loss=0.7380, LR=0.000100
[2025-08-27 06:38:58,323][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044320] [Batch 01200/03080] [00:14:53/00:23:19, 0.745s/it]: train_loss_raw=0.7800, running_loss=0.7380, LR=0.000100
[2025-08-27 06:39:04,260][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044328] [Batch 01208/03080] [00:14:59/00:23:13, 0.745s/it]: train_loss_raw=0.6934, running_loss=0.7387, LR=0.000100
[2025-08-27 06:39:10,144][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044336] [Batch 01216/03080] [00:15:05/00:23:07, 0.745s/it]: train_loss_raw=0.7292, running_loss=0.7397, LR=0.000100
[2025-08-27 06:39:16,064][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044344] [Batch 01224/03080] [00:15:11/00:23:01, 0.745s/it]: train_loss_raw=0.7047, running_loss=0.7400, LR=0.000100
[2025-08-27 06:39:21,967][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044352] [Batch 01232/03080] [00:15:17/00:22:55, 0.744s/it]: train_loss_raw=0.6805, running_loss=0.7387, LR=0.000100
[2025-08-27 06:39:27,824][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044360] [Batch 01240/03080] [00:15:23/00:22:49, 0.744s/it]: train_loss_raw=0.7886, running_loss=0.7386, LR=0.000100
[2025-08-27 06:39:33,608][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044368] [Batch 01248/03080] [00:15:28/00:22:43, 0.744s/it]: train_loss_raw=0.8492, running_loss=0.7400, LR=0.000100
[2025-08-27 06:39:39,572][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044376] [Batch 01256/03080] [00:15:34/00:22:37, 0.744s/it]: train_loss_raw=0.7846, running_loss=0.7431, LR=0.000100
[2025-08-27 06:39:45,394][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044384] [Batch 01264/03080] [00:15:40/00:22:31, 0.744s/it]: train_loss_raw=0.6967, running_loss=0.7444, LR=0.000100
[2025-08-27 06:39:51,193][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044392] [Batch 01272/03080] [00:15:46/00:22:25, 0.744s/it]: train_loss_raw=0.6530, running_loss=0.7436, LR=0.000100
[2025-08-27 06:39:57,028][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044400] [Batch 01280/03080] [00:15:52/00:22:19, 0.744s/it]: train_loss_raw=0.6980, running_loss=0.7426, LR=0.000100
[2025-08-27 06:40:02,999][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044408] [Batch 01288/03080] [00:15:58/00:22:13, 0.744s/it]: train_loss_raw=0.7889, running_loss=0.7427, LR=0.000100
[2025-08-27 06:40:08,883][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044416] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=0.8162, running_loss=0.7396, LR=0.000100
[2025-08-27 06:40:14,673][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044424] [Batch 01304/03080] [00:16:09/00:22:00, 0.744s/it]: train_loss_raw=0.7603, running_loss=0.7415, LR=0.000100
[2025-08-27 06:40:20,524][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044432] [Batch 01312/03080] [00:16:15/00:21:54, 0.744s/it]: train_loss_raw=0.6714, running_loss=0.7390, LR=0.000100
[2025-08-27 06:40:26,495][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044440] [Batch 01320/03080] [00:16:21/00:21:48, 0.744s/it]: train_loss_raw=0.7171, running_loss=0.7388, LR=0.000100
[2025-08-27 06:40:32,315][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044448] [Batch 01328/03080] [00:16:27/00:21:42, 0.744s/it]: train_loss_raw=0.7419, running_loss=0.7360, LR=0.000100
[2025-08-27 06:40:38,119][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044456] [Batch 01336/03080] [00:16:33/00:21:36, 0.744s/it]: train_loss_raw=0.6904, running_loss=0.7332, LR=0.000100
[2025-08-27 06:40:44,006][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044464] [Batch 01344/03080] [00:16:39/00:21:30, 0.743s/it]: train_loss_raw=0.8154, running_loss=0.7346, LR=0.000100
[2025-08-27 06:40:50,078][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044472] [Batch 01352/03080] [00:16:45/00:21:24, 0.744s/it]: train_loss_raw=0.6448, running_loss=0.7343, LR=0.000100
[2025-08-27 06:40:56,089][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044480] [Batch 01360/03080] [00:16:51/00:21:19, 0.744s/it]: train_loss_raw=0.7062, running_loss=0.7355, LR=0.000100
[2025-08-27 06:41:01,969][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044488] [Batch 01368/03080] [00:16:57/00:21:12, 0.744s/it]: train_loss_raw=0.7608, running_loss=0.7351, LR=0.000100
[2025-08-27 06:41:07,921][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044496] [Batch 01376/03080] [00:17:03/00:21:07, 0.744s/it]: train_loss_raw=0.7165, running_loss=0.7353, LR=0.000100
[2025-08-27 06:41:13,961][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044504] [Batch 01384/03080] [00:17:09/00:21:01, 0.744s/it]: train_loss_raw=0.7256, running_loss=0.7340, LR=0.000100
[2025-08-27 06:41:19,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044512] [Batch 01392/03080] [00:17:14/00:20:55, 0.744s/it]: train_loss_raw=0.7287, running_loss=0.7340, LR=0.000100
[2025-08-27 06:41:25,820][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044520] [Batch 01400/03080] [00:17:21/00:20:49, 0.744s/it]: train_loss_raw=0.7485, running_loss=0.7342, LR=0.000100
[2025-08-27 06:41:32,037][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044528] [Batch 01408/03080] [00:17:27/00:20:43, 0.744s/it]: train_loss_raw=0.7698, running_loss=0.7348, LR=0.000100
[2025-08-27 06:41:37,967][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044536] [Batch 01416/03080] [00:17:33/00:20:37, 0.744s/it]: train_loss_raw=0.8084, running_loss=0.7337, LR=0.000100
[2025-08-27 06:41:43,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044544] [Batch 01424/03080] [00:17:39/00:20:31, 0.744s/it]: train_loss_raw=0.7870, running_loss=0.7343, LR=0.000100
[2025-08-27 06:41:50,044][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044552] [Batch 01432/03080] [00:17:45/00:20:25, 0.744s/it]: train_loss_raw=0.7048, running_loss=0.7364, LR=0.000100
[2025-08-27 06:41:55,861][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044560] [Batch 01440/03080] [00:17:51/00:20:19, 0.744s/it]: train_loss_raw=0.7264, running_loss=0.7379, LR=0.000100
[2025-08-27 06:42:01,781][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044568] [Batch 01448/03080] [00:17:57/00:20:13, 0.744s/it]: train_loss_raw=0.7400, running_loss=0.7373, LR=0.000100
[2025-08-27 06:42:07,619][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044576] [Batch 01456/03080] [00:18:02/00:20:07, 0.744s/it]: train_loss_raw=0.7819, running_loss=0.7402, LR=0.000100
[2025-08-27 06:42:13,494][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044584] [Batch 01464/03080] [00:18:08/00:20:01, 0.744s/it]: train_loss_raw=0.7047, running_loss=0.7379, LR=0.000100
[2025-08-27 06:42:19,437][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044592] [Batch 01472/03080] [00:18:14/00:19:55, 0.744s/it]: train_loss_raw=0.6816, running_loss=0.7346, LR=0.000100
[2025-08-27 06:42:25,231][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044600] [Batch 01480/03080] [00:18:20/00:19:49, 0.744s/it]: train_loss_raw=0.7630, running_loss=0.7332, LR=0.000100
[2025-08-27 06:42:31,008][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044608] [Batch 01488/03080] [00:18:26/00:19:43, 0.743s/it]: train_loss_raw=0.8659, running_loss=0.7359, LR=0.000100
[2025-08-27 06:42:36,832][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044616] [Batch 01496/03080] [00:18:32/00:19:37, 0.743s/it]: train_loss_raw=0.6430, running_loss=0.7343, LR=0.000100
[2025-08-27 06:42:42,708][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044624] [Batch 01504/03080] [00:18:37/00:19:31, 0.743s/it]: train_loss_raw=0.7833, running_loss=0.7336, LR=0.000100
[2025-08-27 06:42:48,602][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044632] [Batch 01512/03080] [00:18:43/00:19:25, 0.743s/it]: train_loss_raw=0.6698, running_loss=0.7339, LR=0.000100
[2025-08-27 06:42:54,425][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044640] [Batch 01520/03080] [00:18:49/00:19:19, 0.743s/it]: train_loss_raw=0.6825, running_loss=0.7336, LR=0.000100
[2025-08-27 06:43:00,482][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044648] [Batch 01528/03080] [00:18:55/00:19:13, 0.743s/it]: train_loss_raw=0.7355, running_loss=0.7325, LR=0.000100
[2025-08-27 06:43:06,529][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044656] [Batch 01536/03080] [00:19:01/00:19:07, 0.743s/it]: train_loss_raw=0.6785, running_loss=0.7343, LR=0.000100
[2025-08-27 06:43:12,330][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044664] [Batch 01544/03080] [00:19:07/00:19:01, 0.743s/it]: train_loss_raw=0.6985, running_loss=0.7322, LR=0.000100
[2025-08-27 06:43:18,360][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044672] [Batch 01552/03080] [00:19:13/00:18:55, 0.743s/it]: train_loss_raw=0.7446, running_loss=0.7311, LR=0.000100
[2025-08-27 06:43:24,488][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044680] [Batch 01560/03080] [00:19:19/00:18:49, 0.743s/it]: train_loss_raw=0.7059, running_loss=0.7299, LR=0.000100
[2025-08-27 06:43:30,281][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044688] [Batch 01568/03080] [00:19:25/00:18:43, 0.743s/it]: train_loss_raw=0.7572, running_loss=0.7301, LR=0.000100
[2025-08-27 06:43:36,343][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044696] [Batch 01576/03080] [00:19:31/00:18:38, 0.743s/it]: train_loss_raw=0.7680, running_loss=0.7316, LR=0.000100
[2025-08-27 06:43:41,993][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044704] [Batch 01584/03080] [00:19:37/00:18:31, 0.743s/it]: train_loss_raw=0.8344, running_loss=0.7338, LR=0.000100
[2025-08-27 06:43:47,786][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044712] [Batch 01592/03080] [00:19:43/00:18:25, 0.743s/it]: train_loss_raw=0.7508, running_loss=0.7347, LR=0.000100
[2025-08-27 06:43:53,607][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044720] [Batch 01600/03080] [00:19:48/00:18:19, 0.743s/it]: train_loss_raw=0.7033, running_loss=0.7347, LR=0.000100
[2025-08-27 06:43:59,520][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044728] [Batch 01608/03080] [00:19:54/00:18:13, 0.743s/it]: train_loss_raw=0.8070, running_loss=0.7346, LR=0.000100
[2025-08-27 06:44:05,363][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044736] [Batch 01616/03080] [00:20:00/00:18:07, 0.743s/it]: train_loss_raw=0.6895, running_loss=0.7318, LR=0.000100
[2025-08-27 06:44:11,156][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044744] [Batch 01624/03080] [00:20:06/00:18:01, 0.743s/it]: train_loss_raw=0.7691, running_loss=0.7315, LR=0.000100
[2025-08-27 06:44:17,036][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044752] [Batch 01632/03080] [00:20:12/00:17:55, 0.743s/it]: train_loss_raw=0.8051, running_loss=0.7333, LR=0.000100
[2025-08-27 06:44:22,896][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044760] [Batch 01640/03080] [00:20:18/00:17:49, 0.743s/it]: train_loss_raw=0.6986, running_loss=0.7329, LR=0.000100
[2025-08-27 06:44:28,784][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044768] [Batch 01648/03080] [00:20:24/00:17:43, 0.743s/it]: train_loss_raw=0.7832, running_loss=0.7327, LR=0.000100
[2025-08-27 06:44:34,601][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044776] [Batch 01656/03080] [00:20:29/00:17:37, 0.743s/it]: train_loss_raw=0.8759, running_loss=0.7340, LR=0.000100
[2025-08-27 06:44:40,347][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044784] [Batch 01664/03080] [00:20:35/00:17:31, 0.743s/it]: train_loss_raw=0.8544, running_loss=0.7347, LR=0.000100
[2025-08-27 06:44:46,338][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044792] [Batch 01672/03080] [00:20:41/00:17:25, 0.743s/it]: train_loss_raw=0.7954, running_loss=0.7361, LR=0.000100
[2025-08-27 06:44:52,180][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044800] [Batch 01680/03080] [00:20:47/00:17:19, 0.743s/it]: train_loss_raw=0.7614, running_loss=0.7357, LR=0.000100
[2025-08-27 06:44:57,816][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044808] [Batch 01688/03080] [00:20:53/00:17:13, 0.742s/it]: train_loss_raw=0.7487, running_loss=0.7310, LR=0.000100
[2025-08-27 06:45:03,472][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044816] [Batch 01696/03080] [00:20:58/00:17:07, 0.742s/it]: train_loss_raw=0.7920, running_loss=0.7280, LR=0.000100
[2025-08-27 06:45:09,363][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044824] [Batch 01704/03080] [00:21:04/00:17:01, 0.742s/it]: train_loss_raw=0.7771, running_loss=0.7261, LR=0.000100
[2025-08-27 06:45:15,217][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044832] [Batch 01712/03080] [00:21:10/00:16:55, 0.742s/it]: train_loss_raw=0.6689, running_loss=0.7251, LR=0.000100
[2025-08-27 06:45:21,062][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044840] [Batch 01720/03080] [00:21:16/00:16:49, 0.742s/it]: train_loss_raw=0.7148, running_loss=0.7282, LR=0.000100
[2025-08-27 06:45:26,914][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044848] [Batch 01728/03080] [00:21:22/00:16:43, 0.742s/it]: train_loss_raw=0.6866, running_loss=0.7277, LR=0.000100
[2025-08-27 06:45:32,745][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044856] [Batch 01736/03080] [00:21:27/00:16:37, 0.742s/it]: train_loss_raw=0.7435, running_loss=0.7273, LR=0.000100
[2025-08-27 06:45:38,599][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044864] [Batch 01744/03080] [00:21:33/00:16:31, 0.742s/it]: train_loss_raw=0.7143, running_loss=0.7254, LR=0.000100
[2025-08-27 06:45:44,445][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044872] [Batch 01752/03080] [00:21:39/00:16:25, 0.742s/it]: train_loss_raw=0.7570, running_loss=0.7247, LR=0.000100
[2025-08-27 06:45:50,411][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044880] [Batch 01760/03080] [00:21:45/00:16:19, 0.742s/it]: train_loss_raw=0.8007, running_loss=0.7241, LR=0.000100
[2025-08-27 06:45:56,495][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044888] [Batch 01768/03080] [00:21:51/00:16:13, 0.742s/it]: train_loss_raw=0.6911, running_loss=0.7241, LR=0.000100
[2025-08-27 06:46:02,517][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044896] [Batch 01776/03080] [00:21:57/00:16:07, 0.742s/it]: train_loss_raw=0.7821, running_loss=0.7246, LR=0.000100
[2025-08-27 06:46:08,375][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044904] [Batch 01784/03080] [00:22:03/00:16:01, 0.742s/it]: train_loss_raw=0.7164, running_loss=0.7260, LR=0.000100
[2025-08-27 06:46:14,337][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044912] [Batch 01792/03080] [00:22:09/00:15:55, 0.742s/it]: train_loss_raw=0.7292, running_loss=0.7281, LR=0.000100
[2025-08-27 06:46:20,275][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044920] [Batch 01800/03080] [00:22:15/00:15:49, 0.742s/it]: train_loss_raw=0.7655, running_loss=0.7293, LR=0.000100
[2025-08-27 06:46:26,174][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044928] [Batch 01808/03080] [00:22:21/00:15:43, 0.742s/it]: train_loss_raw=0.6041, running_loss=0.7269, LR=0.000100
[2025-08-27 06:46:32,124][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044936] [Batch 01816/03080] [00:22:27/00:15:37, 0.742s/it]: train_loss_raw=0.7268, running_loss=0.7285, LR=0.000100
[2025-08-27 06:46:38,045][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044944] [Batch 01824/03080] [00:22:33/00:15:31, 0.742s/it]: train_loss_raw=0.7333, running_loss=0.7290, LR=0.000100
[2025-08-27 06:46:44,101][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044952] [Batch 01832/03080] [00:22:39/00:15:26, 0.742s/it]: train_loss_raw=0.6629, running_loss=0.7281, LR=0.000100
[2025-08-27 06:46:50,047][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044960] [Batch 01840/03080] [00:22:45/00:15:20, 0.742s/it]: train_loss_raw=0.7619, running_loss=0.7273, LR=0.000100
[2025-08-27 06:46:56,024][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044968] [Batch 01848/03080] [00:22:51/00:15:14, 0.742s/it]: train_loss_raw=0.7898, running_loss=0.7277, LR=0.000100
[2025-08-27 06:47:01,893][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044976] [Batch 01856/03080] [00:22:57/00:15:08, 0.742s/it]: train_loss_raw=0.6630, running_loss=0.7252, LR=0.000100
[2025-08-27 06:47:07,750][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044984] [Batch 01864/03080] [00:23:02/00:15:02, 0.742s/it]: train_loss_raw=0.6827, running_loss=0.7237, LR=0.000100
[2025-08-27 06:47:13,620][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044992] [Batch 01872/03080] [00:23:08/00:14:56, 0.742s/it]: train_loss_raw=0.6046, running_loss=0.7213, LR=0.000100
[2025-08-27 06:47:19,537][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045000] [Batch 01880/03080] [00:23:14/00:14:50, 0.742s/it]: train_loss_raw=0.6838, running_loss=0.7209, LR=0.000100
[2025-08-27 06:47:25,276][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045008] [Batch 01888/03080] [00:23:20/00:14:44, 0.742s/it]: train_loss_raw=0.7109, running_loss=0.7226, LR=0.000100
[2025-08-27 06:47:31,205][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045016] [Batch 01896/03080] [00:23:26/00:14:38, 0.742s/it]: train_loss_raw=0.7409, running_loss=0.7238, LR=0.000100
[2025-08-27 06:47:37,176][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045024] [Batch 01904/03080] [00:23:32/00:14:32, 0.742s/it]: train_loss_raw=0.7281, running_loss=0.7237, LR=0.000100
[2025-08-27 06:47:43,375][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045032] [Batch 01912/03080] [00:23:38/00:14:26, 0.742s/it]: train_loss_raw=0.6556, running_loss=0.7237, LR=0.000100
[2025-08-27 06:47:49,485][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045040] [Batch 01920/03080] [00:23:44/00:14:20, 0.742s/it]: train_loss_raw=0.7133, running_loss=0.7230, LR=0.000100
[2025-08-27 06:47:55,552][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045048] [Batch 01928/03080] [00:23:50/00:14:14, 0.742s/it]: train_loss_raw=0.6941, running_loss=0.7230, LR=0.000100
[2025-08-27 06:48:01,563][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045056] [Batch 01936/03080] [00:23:56/00:14:09, 0.742s/it]: train_loss_raw=0.7736, running_loss=0.7223, LR=0.000100
[2025-08-27 06:48:07,579][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045064] [Batch 01944/03080] [00:24:02/00:14:03, 0.742s/it]: train_loss_raw=0.7083, running_loss=0.7214, LR=0.000100
[2025-08-27 06:48:13,394][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045072] [Batch 01952/03080] [00:24:08/00:13:57, 0.742s/it]: train_loss_raw=0.7386, running_loss=0.7195, LR=0.000100
[2025-08-27 06:48:19,242][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045080] [Batch 01960/03080] [00:24:14/00:13:51, 0.742s/it]: train_loss_raw=0.6977, running_loss=0.7190, LR=0.000100
[2025-08-27 06:48:25,085][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045088] [Batch 01968/03080] [00:24:20/00:13:45, 0.742s/it]: train_loss_raw=0.7580, running_loss=0.7211, LR=0.000100
[2025-08-27 06:48:31,435][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045096] [Batch 01976/03080] [00:24:26/00:13:39, 0.742s/it]: train_loss_raw=0.6898, running_loss=0.7214, LR=0.000100
[2025-08-27 06:48:37,447][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045104] [Batch 01984/03080] [00:24:32/00:13:33, 0.742s/it]: train_loss_raw=0.7313, running_loss=0.7205, LR=0.000100
[2025-08-27 06:48:43,265][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045112] [Batch 01992/03080] [00:24:38/00:13:27, 0.742s/it]: train_loss_raw=0.7769, running_loss=0.7203, LR=0.000100
[2025-08-27 06:48:48,993][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045120] [Batch 02000/03080] [00:24:44/00:13:21, 0.742s/it]: train_loss_raw=0.6929, running_loss=0.7197, LR=0.000100
[2025-08-27 06:48:54,868][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045128] [Batch 02008/03080] [00:24:50/00:13:15, 0.742s/it]: train_loss_raw=0.8002, running_loss=0.7223, LR=0.000100
[2025-08-27 06:49:00,923][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045136] [Batch 02016/03080] [00:24:56/00:13:09, 0.742s/it]: train_loss_raw=0.6372, running_loss=0.7191, LR=0.000100
[2025-08-27 06:49:06,850][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045144] [Batch 02024/03080] [00:25:02/00:13:03, 0.742s/it]: train_loss_raw=0.6322, running_loss=0.7184, LR=0.000100
[2025-08-27 06:49:12,823][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045152] [Batch 02032/03080] [00:25:08/00:12:57, 0.742s/it]: train_loss_raw=0.7829, running_loss=0.7174, LR=0.000100
[2025-08-27 06:49:18,732][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045160] [Batch 02040/03080] [00:25:13/00:12:51, 0.742s/it]: train_loss_raw=0.7528, running_loss=0.7179, LR=0.000100
[2025-08-27 06:49:24,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045168] [Batch 02048/03080] [00:25:19/00:12:45, 0.742s/it]: train_loss_raw=0.8008, running_loss=0.7197, LR=0.000100
[2025-08-27 06:49:30,338][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045176] [Batch 02056/03080] [00:25:25/00:12:39, 0.742s/it]: train_loss_raw=0.6914, running_loss=0.7183, LR=0.000100
[2025-08-27 06:49:36,195][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045184] [Batch 02064/03080] [00:25:31/00:12:33, 0.742s/it]: train_loss_raw=0.6895, running_loss=0.7194, LR=0.000100
[2025-08-27 06:49:42,086][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045192] [Batch 02072/03080] [00:25:37/00:12:27, 0.742s/it]: train_loss_raw=0.7276, running_loss=0.7194, LR=0.000100
[2025-08-27 06:49:48,070][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045200] [Batch 02080/03080] [00:25:43/00:12:21, 0.742s/it]: train_loss_raw=0.6754, running_loss=0.7225, LR=0.000100
[2025-08-27 06:49:54,018][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045208] [Batch 02088/03080] [00:25:49/00:12:16, 0.742s/it]: train_loss_raw=0.7992, running_loss=0.7231, LR=0.000100
[2025-08-27 06:50:00,215][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045216] [Batch 02096/03080] [00:25:55/00:12:10, 0.742s/it]: train_loss_raw=0.6756, running_loss=0.7239, LR=0.000100
[2025-08-27 06:50:06,250][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045224] [Batch 02104/03080] [00:26:01/00:12:04, 0.742s/it]: train_loss_raw=0.6956, running_loss=0.7233, LR=0.000100
[2025-08-27 06:50:12,287][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045232] [Batch 02112/03080] [00:26:07/00:11:58, 0.742s/it]: train_loss_raw=0.7223, running_loss=0.7227, LR=0.000100
[2025-08-27 06:50:18,480][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045240] [Batch 02120/03080] [00:26:13/00:11:52, 0.742s/it]: train_loss_raw=0.6854, running_loss=0.7199, LR=0.000100
[2025-08-27 06:50:24,425][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045248] [Batch 02128/03080] [00:26:19/00:11:46, 0.742s/it]: train_loss_raw=0.7218, running_loss=0.7198, LR=0.000100
[2025-08-27 06:50:30,496][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045256] [Batch 02136/03080] [00:26:25/00:11:40, 0.742s/it]: train_loss_raw=0.6889, running_loss=0.7197, LR=0.000100
[2025-08-27 06:50:36,458][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045264] [Batch 02144/03080] [00:26:31/00:11:34, 0.742s/it]: train_loss_raw=0.7295, running_loss=0.7220, LR=0.000100
[2025-08-27 06:50:42,403][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045272] [Batch 02152/03080] [00:26:37/00:11:28, 0.742s/it]: train_loss_raw=0.7560, running_loss=0.7234, LR=0.000100
[2025-08-27 06:50:48,468][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045280] [Batch 02160/03080] [00:26:43/00:11:23, 0.742s/it]: train_loss_raw=0.6765, running_loss=0.7248, LR=0.000100
[2025-08-27 06:50:54,490][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045288] [Batch 02168/03080] [00:26:49/00:11:17, 0.742s/it]: train_loss_raw=0.7985, running_loss=0.7223, LR=0.000100
[2025-08-27 06:51:00,402][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045296] [Batch 02176/03080] [00:26:55/00:11:11, 0.742s/it]: train_loss_raw=0.7540, running_loss=0.7222, LR=0.000100
[2025-08-27 06:51:06,229][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045304] [Batch 02184/03080] [00:27:01/00:11:05, 0.742s/it]: train_loss_raw=0.8191, running_loss=0.7223, LR=0.000100
[2025-08-27 06:51:11,919][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045312] [Batch 02192/03080] [00:27:07/00:10:59, 0.742s/it]: train_loss_raw=0.6622, running_loss=0.7224, LR=0.000100
[2025-08-27 06:51:17,617][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045320] [Batch 02200/03080] [00:27:12/00:10:53, 0.742s/it]: train_loss_raw=0.7086, running_loss=0.7237, LR=0.000100
[2025-08-27 06:51:23,708][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045328] [Batch 02208/03080] [00:27:18/00:10:47, 0.742s/it]: train_loss_raw=0.6835, running_loss=0.7224, LR=0.000100
[2025-08-27 06:51:29,886][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045336] [Batch 02216/03080] [00:27:25/00:10:41, 0.742s/it]: train_loss_raw=0.7419, running_loss=0.7201, LR=0.000100
[2025-08-27 06:51:35,959][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045344] [Batch 02224/03080] [00:27:31/00:10:35, 0.742s/it]: train_loss_raw=0.7521, running_loss=0.7190, LR=0.000100
[2025-08-27 06:51:41,992][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045352] [Batch 02232/03080] [00:27:37/00:10:29, 0.742s/it]: train_loss_raw=0.6731, running_loss=0.7183, LR=0.000100
[2025-08-27 06:51:48,091][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045360] [Batch 02240/03080] [00:27:43/00:10:23, 0.743s/it]: train_loss_raw=0.7649, running_loss=0.7198, LR=0.000100
[2025-08-27 06:51:54,235][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045368] [Batch 02248/03080] [00:27:49/00:10:17, 0.743s/it]: train_loss_raw=0.7671, running_loss=0.7200, LR=0.000100
[2025-08-27 06:52:00,304][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045376] [Batch 02256/03080] [00:27:55/00:10:11, 0.743s/it]: train_loss_raw=0.6477, running_loss=0.7183, LR=0.000100
[2025-08-27 06:52:06,372][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045384] [Batch 02264/03080] [00:28:01/00:10:06, 0.743s/it]: train_loss_raw=0.7463, running_loss=0.7184, LR=0.000100
[2025-08-27 06:52:12,426][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045392] [Batch 02272/03080] [00:28:07/00:10:00, 0.743s/it]: train_loss_raw=0.7168, running_loss=0.7168, LR=0.000100
[2025-08-27 06:52:18,553][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045400] [Batch 02280/03080] [00:28:13/00:09:54, 0.743s/it]: train_loss_raw=0.6515, running_loss=0.7167, LR=0.000100
[2025-08-27 06:52:24,446][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045408] [Batch 02288/03080] [00:28:19/00:09:48, 0.743s/it]: train_loss_raw=0.6464, running_loss=0.7170, LR=0.000100
[2025-08-27 06:52:30,394][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045416] [Batch 02296/03080] [00:28:25/00:09:42, 0.743s/it]: train_loss_raw=0.6562, running_loss=0.7159, LR=0.000100
[2025-08-27 06:52:36,520][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045424] [Batch 02304/03080] [00:28:31/00:09:36, 0.743s/it]: train_loss_raw=0.6450, running_loss=0.7178, LR=0.000100
[2025-08-27 06:52:42,542][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045432] [Batch 02312/03080] [00:28:37/00:09:30, 0.743s/it]: train_loss_raw=0.7176, running_loss=0.7184, LR=0.000100
[2025-08-27 06:52:48,598][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045440] [Batch 02320/03080] [00:28:43/00:09:24, 0.743s/it]: train_loss_raw=0.7393, running_loss=0.7186, LR=0.000100
[2025-08-27 06:52:54,736][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045448] [Batch 02328/03080] [00:28:49/00:09:18, 0.743s/it]: train_loss_raw=0.7354, running_loss=0.7187, LR=0.000100
[2025-08-27 06:53:00,754][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045456] [Batch 02336/03080] [00:28:55/00:09:12, 0.743s/it]: train_loss_raw=0.6710, running_loss=0.7175, LR=0.000100
[2025-08-27 06:53:06,714][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045464] [Batch 02344/03080] [00:29:01/00:09:06, 0.743s/it]: train_loss_raw=0.6685, running_loss=0.7148, LR=0.000100
[2025-08-27 06:53:12,657][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045472] [Batch 02352/03080] [00:29:07/00:09:01, 0.743s/it]: train_loss_raw=0.6989, running_loss=0.7146, LR=0.000100
[2025-08-27 06:53:18,757][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045480] [Batch 02360/03080] [00:29:13/00:08:55, 0.743s/it]: train_loss_raw=0.6139, running_loss=0.7168, LR=0.000100
[2025-08-27 06:53:24,868][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045488] [Batch 02368/03080] [00:29:20/00:08:49, 0.743s/it]: train_loss_raw=0.6314, running_loss=0.7158, LR=0.000100
[2025-08-27 06:53:30,779][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045496] [Batch 02376/03080] [00:29:26/00:08:43, 0.743s/it]: train_loss_raw=0.7338, running_loss=0.7134, LR=0.000100
[2025-08-27 06:53:36,599][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045504] [Batch 02384/03080] [00:29:31/00:08:37, 0.743s/it]: train_loss_raw=0.7524, running_loss=0.7112, LR=0.000100
[2025-08-27 06:53:42,482][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045512] [Batch 02392/03080] [00:29:37/00:08:31, 0.743s/it]: train_loss_raw=0.8015, running_loss=0.7102, LR=0.000100
[2025-08-27 06:53:48,663][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045520] [Batch 02400/03080] [00:29:43/00:08:25, 0.743s/it]: train_loss_raw=0.7086, running_loss=0.7090, LR=0.000100
[2025-08-27 06:53:54,731][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045528] [Batch 02408/03080] [00:29:49/00:08:19, 0.743s/it]: train_loss_raw=0.7874, running_loss=0.7114, LR=0.000100
[2025-08-27 06:54:00,777][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045536] [Batch 02416/03080] [00:29:55/00:08:13, 0.743s/it]: train_loss_raw=0.6647, running_loss=0.7091, LR=0.000100
[2025-08-27 06:54:06,781][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045544] [Batch 02424/03080] [00:30:02/00:08:07, 0.743s/it]: train_loss_raw=0.6760, running_loss=0.7088, LR=0.000100
[2025-08-27 06:54:12,864][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045552] [Batch 02432/03080] [00:30:08/00:08:01, 0.743s/it]: train_loss_raw=0.8687, running_loss=0.7090, LR=0.000100
[2025-08-27 06:54:18,946][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045560] [Batch 02440/03080] [00:30:14/00:07:55, 0.744s/it]: train_loss_raw=0.6858, running_loss=0.7086, LR=0.000100
[2025-08-27 06:54:25,023][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045568] [Batch 02448/03080] [00:30:20/00:07:49, 0.744s/it]: train_loss_raw=0.6525, running_loss=0.7090, LR=0.000100
[2025-08-27 06:54:31,184][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045576] [Batch 02456/03080] [00:30:26/00:07:44, 0.744s/it]: train_loss_raw=0.6429, running_loss=0.7089, LR=0.000100
[2025-08-27 06:54:37,229][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045584] [Batch 02464/03080] [00:30:32/00:07:38, 0.744s/it]: train_loss_raw=0.7116, running_loss=0.7093, LR=0.000100
[2025-08-27 06:54:43,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045592] [Batch 02472/03080] [00:30:38/00:07:32, 0.744s/it]: train_loss_raw=0.8912, running_loss=0.7107, LR=0.000100
[2025-08-27 06:54:49,453][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045600] [Batch 02480/03080] [00:30:44/00:07:26, 0.744s/it]: train_loss_raw=0.7685, running_loss=0.7106, LR=0.000100
[2025-08-27 06:54:55,591][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045608] [Batch 02488/03080] [00:30:50/00:07:20, 0.744s/it]: train_loss_raw=0.6944, running_loss=0.7110, LR=0.000100
[2025-08-27 06:55:01,702][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045616] [Batch 02496/03080] [00:30:56/00:07:14, 0.744s/it]: train_loss_raw=0.7580, running_loss=0.7086, LR=0.000100
[2025-08-27 06:55:07,801][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045624] [Batch 02504/03080] [00:31:03/00:07:08, 0.744s/it]: train_loss_raw=0.7868, running_loss=0.7093, LR=0.000100
[2025-08-27 06:55:13,862][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045632] [Batch 02512/03080] [00:31:09/00:07:02, 0.744s/it]: train_loss_raw=0.7213, running_loss=0.7108, LR=0.000100
[2025-08-27 06:55:19,911][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045640] [Batch 02520/03080] [00:31:15/00:06:56, 0.744s/it]: train_loss_raw=0.6932, running_loss=0.7120, LR=0.000100
[2025-08-27 06:55:25,979][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045648] [Batch 02528/03080] [00:31:21/00:06:50, 0.744s/it]: train_loss_raw=0.6583, running_loss=0.7055, LR=0.000100
[2025-08-27 06:55:32,044][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045656] [Batch 02536/03080] [00:31:27/00:06:44, 0.744s/it]: train_loss_raw=0.7693, running_loss=0.7080, LR=0.000100
[2025-08-27 06:55:38,093][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045664] [Batch 02544/03080] [00:31:33/00:06:38, 0.744s/it]: train_loss_raw=0.6012, running_loss=0.7063, LR=0.000100
[2025-08-27 06:55:44,652][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045672] [Batch 02552/03080] [00:31:39/00:06:33, 0.744s/it]: train_loss_raw=0.7676, running_loss=0.7063, LR=0.000100
[2025-08-27 06:55:50,712][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045680] [Batch 02560/03080] [00:31:45/00:06:27, 0.745s/it]: train_loss_raw=0.7788, running_loss=0.7076, LR=0.000100
[2025-08-27 06:55:56,802][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045688] [Batch 02568/03080] [00:31:52/00:06:21, 0.745s/it]: train_loss_raw=0.7659, running_loss=0.7080, LR=0.000100
[2025-08-27 06:56:02,880][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045696] [Batch 02576/03080] [00:31:58/00:06:15, 0.745s/it]: train_loss_raw=0.6235, running_loss=0.7060, LR=0.000100
[2025-08-27 06:56:08,949][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045704] [Batch 02584/03080] [00:32:04/00:06:09, 0.745s/it]: train_loss_raw=0.6849, running_loss=0.7059, LR=0.000100
[2025-08-27 06:56:15,104][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045712] [Batch 02592/03080] [00:32:10/00:06:03, 0.745s/it]: train_loss_raw=0.7671, running_loss=0.7074, LR=0.000100
[2025-08-27 06:56:21,155][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045720] [Batch 02600/03080] [00:32:16/00:05:57, 0.745s/it]: train_loss_raw=0.7204, running_loss=0.7089, LR=0.000100
[2025-08-27 06:56:27,145][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045728] [Batch 02608/03080] [00:32:22/00:05:51, 0.745s/it]: train_loss_raw=0.6823, running_loss=0.7103, LR=0.000100
[2025-08-27 06:56:33,197][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045736] [Batch 02616/03080] [00:32:28/00:05:45, 0.745s/it]: train_loss_raw=0.7054, running_loss=0.7104, LR=0.000100
[2025-08-27 06:56:39,247][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045744] [Batch 02624/03080] [00:32:34/00:05:39, 0.745s/it]: train_loss_raw=0.6943, running_loss=0.7093, LR=0.000100
[2025-08-27 06:56:45,340][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045752] [Batch 02632/03080] [00:32:40/00:05:33, 0.745s/it]: train_loss_raw=0.7287, running_loss=0.7107, LR=0.000100
[2025-08-27 06:56:51,455][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045760] [Batch 02640/03080] [00:32:46/00:05:27, 0.745s/it]: train_loss_raw=0.7852, running_loss=0.7092, LR=0.000100
[2025-08-27 06:56:57,586][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045768] [Batch 02648/03080] [00:32:52/00:05:21, 0.745s/it]: train_loss_raw=0.7124, running_loss=0.7120, LR=0.000100
[2025-08-27 06:57:03,645][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045776] [Batch 02656/03080] [00:32:58/00:05:15, 0.745s/it]: train_loss_raw=0.8086, running_loss=0.7136, LR=0.000100
[2025-08-27 06:57:09,681][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045784] [Batch 02664/03080] [00:33:04/00:05:09, 0.745s/it]: train_loss_raw=0.6405, running_loss=0.7123, LR=0.000100
[2025-08-27 06:57:15,773][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045792] [Batch 02672/03080] [00:33:10/00:05:04, 0.745s/it]: train_loss_raw=0.6662, running_loss=0.7108, LR=0.000100
[2025-08-27 06:57:21,896][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045800] [Batch 02680/03080] [00:33:17/00:04:58, 0.745s/it]: train_loss_raw=0.6881, running_loss=0.7083, LR=0.000100
[2025-08-27 06:57:27,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045808] [Batch 02688/03080] [00:33:23/00:04:52, 0.745s/it]: train_loss_raw=0.6637, running_loss=0.7065, LR=0.000100
[2025-08-27 06:57:34,089][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045816] [Batch 02696/03080] [00:33:29/00:04:46, 0.745s/it]: train_loss_raw=0.7555, running_loss=0.7057, LR=0.000100
[2025-08-27 06:57:40,147][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045824] [Batch 02704/03080] [00:33:35/00:04:40, 0.745s/it]: train_loss_raw=0.6261, running_loss=0.7063, LR=0.000100
[2025-08-27 06:57:46,301][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045832] [Batch 02712/03080] [00:33:41/00:04:34, 0.745s/it]: train_loss_raw=0.7485, running_loss=0.7049, LR=0.000100
[2025-08-27 06:57:52,399][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045840] [Batch 02720/03080] [00:33:47/00:04:28, 0.745s/it]: train_loss_raw=0.7699, running_loss=0.7055, LR=0.000100
[2025-08-27 06:57:58,490][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045848] [Batch 02728/03080] [00:33:53/00:04:22, 0.745s/it]: train_loss_raw=0.7698, running_loss=0.7040, LR=0.000100
[2025-08-27 06:58:04,549][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045856] [Batch 02736/03080] [00:33:59/00:04:16, 0.746s/it]: train_loss_raw=0.6304, running_loss=0.7033, LR=0.000100
[2025-08-27 06:58:10,603][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045864] [Batch 02744/03080] [00:34:05/00:04:10, 0.746s/it]: train_loss_raw=0.7709, running_loss=0.7028, LR=0.000100
[2025-08-27 06:58:16,669][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045872] [Batch 02752/03080] [00:34:11/00:04:04, 0.746s/it]: train_loss_raw=0.7558, running_loss=0.7035, LR=0.000100
[2025-08-27 06:58:22,658][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045880] [Batch 02760/03080] [00:34:17/00:03:58, 0.746s/it]: train_loss_raw=0.7018, running_loss=0.7067, LR=0.000100
[2025-08-27 06:58:28,802][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045888] [Batch 02768/03080] [00:34:24/00:03:52, 0.746s/it]: train_loss_raw=0.6169, running_loss=0.7035, LR=0.000100
[2025-08-27 06:58:34,965][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045896] [Batch 02776/03080] [00:34:30/00:03:46, 0.746s/it]: train_loss_raw=0.6384, running_loss=0.7022, LR=0.000100
[2025-08-27 06:58:41,169][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045904] [Batch 02784/03080] [00:34:36/00:03:40, 0.746s/it]: train_loss_raw=0.7215, running_loss=0.7019, LR=0.000100
[2025-08-27 06:58:47,323][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045912] [Batch 02792/03080] [00:34:42/00:03:34, 0.746s/it]: train_loss_raw=0.6693, running_loss=0.7010, LR=0.000100
[2025-08-27 06:58:53,459][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045920] [Batch 02800/03080] [00:34:48/00:03:28, 0.746s/it]: train_loss_raw=0.7586, running_loss=0.7043, LR=0.000100
[2025-08-27 06:58:59,554][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045928] [Batch 02808/03080] [00:34:54/00:03:22, 0.746s/it]: train_loss_raw=0.7345, running_loss=0.7034, LR=0.000100
[2025-08-27 06:59:05,715][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045936] [Batch 02816/03080] [00:35:00/00:03:16, 0.746s/it]: train_loss_raw=0.6570, running_loss=0.7022, LR=0.000100
[2025-08-27 06:59:11,733][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045944] [Batch 02824/03080] [00:35:06/00:03:10, 0.746s/it]: train_loss_raw=0.6319, running_loss=0.7028, LR=0.000100
[2025-08-27 06:59:17,856][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045952] [Batch 02832/03080] [00:35:13/00:03:05, 0.746s/it]: train_loss_raw=0.7006, running_loss=0.7022, LR=0.000100
[2025-08-27 06:59:23,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045960] [Batch 02840/03080] [00:35:19/00:02:59, 0.746s/it]: train_loss_raw=0.6494, running_loss=0.7021, LR=0.000100
[2025-08-27 06:59:29,870][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045968] [Batch 02848/03080] [00:35:25/00:02:53, 0.746s/it]: train_loss_raw=0.6782, running_loss=0.7009, LR=0.000100
[2025-08-27 06:59:35,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045976] [Batch 02856/03080] [00:35:31/00:02:47, 0.746s/it]: train_loss_raw=0.7827, running_loss=0.7010, LR=0.000100
[2025-08-27 06:59:42,002][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045984] [Batch 02864/03080] [00:35:37/00:02:41, 0.746s/it]: train_loss_raw=0.6985, running_loss=0.6993, LR=0.000100
[2025-08-27 06:59:48,102][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045992] [Batch 02872/03080] [00:35:43/00:02:35, 0.746s/it]: train_loss_raw=0.7135, running_loss=0.6990, LR=0.000100
[2025-08-27 06:59:54,188][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046000] [Batch 02880/03080] [00:35:49/00:02:29, 0.746s/it]: train_loss_raw=0.7158, running_loss=0.6995, LR=0.000100
[2025-08-27 07:00:03,659][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046008] [Batch 02888/03080] [00:35:58/00:02:23, 0.748s/it]: train_loss_raw=0.7690, running_loss=0.6974, LR=0.000100
[2025-08-27 07:00:09,383][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046016] [Batch 02896/03080] [00:36:04/00:02:17, 0.747s/it]: train_loss_raw=0.5812, running_loss=0.6969, LR=0.000100
[2025-08-27 07:00:15,212][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046024] [Batch 02904/03080] [00:36:10/00:02:11, 0.747s/it]: train_loss_raw=0.6627, running_loss=0.6971, LR=0.000100
[2025-08-27 07:00:21,082][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046032] [Batch 02912/03080] [00:36:16/00:02:05, 0.747s/it]: train_loss_raw=0.6602, running_loss=0.6972, LR=0.000100
[2025-08-27 07:00:26,997][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046040] [Batch 02920/03080] [00:36:22/00:01:59, 0.747s/it]: train_loss_raw=0.6965, running_loss=0.6974, LR=0.000100
[2025-08-27 07:00:32,881][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046048] [Batch 02928/03080] [00:36:28/00:01:53, 0.747s/it]: train_loss_raw=0.6634, running_loss=0.7009, LR=0.000100
[2025-08-27 07:00:38,877][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046056] [Batch 02936/03080] [00:36:34/00:01:47, 0.747s/it]: train_loss_raw=0.7227, running_loss=0.7013, LR=0.000100
[2025-08-27 07:00:44,830][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046064] [Batch 02944/03080] [00:36:40/00:01:41, 0.747s/it]: train_loss_raw=0.7199, running_loss=0.6988, LR=0.000100
[2025-08-27 07:00:50,817][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046072] [Batch 02952/03080] [00:36:46/00:01:35, 0.747s/it]: train_loss_raw=0.6886, running_loss=0.6982, LR=0.000100
[2025-08-27 07:00:56,949][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046080] [Batch 02960/03080] [00:36:52/00:01:29, 0.747s/it]: train_loss_raw=0.7823, running_loss=0.6994, LR=0.000100
[2025-08-27 07:01:03,112][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046088] [Batch 02968/03080] [00:36:58/00:01:23, 0.747s/it]: train_loss_raw=0.7111, running_loss=0.6999, LR=0.000100
[2025-08-27 07:01:09,190][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046096] [Batch 02976/03080] [00:37:04/00:01:17, 0.747s/it]: train_loss_raw=0.6410, running_loss=0.6979, LR=0.000100
[2025-08-27 07:01:15,261][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046104] [Batch 02984/03080] [00:37:10/00:01:11, 0.747s/it]: train_loss_raw=0.6452, running_loss=0.6988, LR=0.000100
[2025-08-27 07:01:21,345][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046112] [Batch 02992/03080] [00:37:16/00:01:05, 0.748s/it]: train_loss_raw=0.6499, running_loss=0.6992, LR=0.000100
[2025-08-27 07:01:27,352][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046120] [Batch 03000/03080] [00:37:22/00:00:59, 0.748s/it]: train_loss_raw=0.6743, running_loss=0.6978, LR=0.000100
[2025-08-27 07:01:33,515][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046128] [Batch 03008/03080] [00:37:28/00:00:53, 0.748s/it]: train_loss_raw=0.6761, running_loss=0.6978, LR=0.000100
[2025-08-27 07:01:39,586][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046136] [Batch 03016/03080] [00:37:34/00:00:47, 0.748s/it]: train_loss_raw=0.6765, running_loss=0.6985, LR=0.000100
[2025-08-27 07:01:45,681][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046144] [Batch 03024/03080] [00:37:40/00:00:41, 0.748s/it]: train_loss_raw=0.7810, running_loss=0.6967, LR=0.000100
[2025-08-27 07:01:51,751][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046152] [Batch 03032/03080] [00:37:46/00:00:35, 0.748s/it]: train_loss_raw=0.7019, running_loss=0.6960, LR=0.000100
[2025-08-27 07:01:57,813][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046160] [Batch 03040/03080] [00:37:53/00:00:29, 0.748s/it]: train_loss_raw=0.7283, running_loss=0.6970, LR=0.000100
[2025-08-27 07:02:03,916][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046168] [Batch 03048/03080] [00:37:59/00:00:23, 0.748s/it]: train_loss_raw=0.5767, running_loss=0.6951, LR=0.000100
[2025-08-27 07:02:09,993][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046176] [Batch 03056/03080] [00:38:05/00:00:17, 0.748s/it]: train_loss_raw=0.7602, running_loss=0.6958, LR=0.000100
[2025-08-27 07:02:16,009][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046184] [Batch 03064/03080] [00:38:11/00:00:11, 0.748s/it]: train_loss_raw=0.7194, running_loss=0.6937, LR=0.000100
[2025-08-27 07:02:22,143][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046192] [Batch 03072/03080] [00:38:17/00:00:05, 0.748s/it]: train_loss_raw=0.6476, running_loss=0.6948, LR=0.000100
[2025-08-27 07:02:28,165][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046200] [Batch 03080/03080] [00:38:23/00:00:00, 0.748s/it]: train_loss_raw=0.5898, running_loss=0.6932, LR=0.000100
[2025-08-27 07:02:28,707][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-27 07:02:39,756][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00007/00310] [00:00:11/00:06:57, 1.381s/it]
[2025-08-27 07:02:51,833][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00015/00310] [00:00:23/00:07:04, 1.445s/it]
[2025-08-27 07:03:04,240][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00023/00310] [00:00:35/00:07:03, 1.481s/it]
[2025-08-27 07:03:16,866][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00031/00310] [00:00:48/00:06:58, 1.505s/it]
[2025-08-27 07:03:29,323][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00039/00310] [00:01:00/00:06:49, 1.515s/it]
[2025-08-27 07:03:41,724][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00047/00310] [00:01:13/00:06:38, 1.521s/it]
[2025-08-27 07:03:54,181][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00055/00310] [00:01:25/00:06:27, 1.526s/it]
[2025-08-27 07:04:06,556][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00063/00310] [00:01:37/00:06:16, 1.529s/it]
[2025-08-27 07:04:18,962][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00071/00310] [00:01:50/00:06:04, 1.531s/it]
[2025-08-27 07:04:30,887][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00079/00310] [00:02:02/00:05:51, 1.527s/it]
[2025-08-27 07:04:43,609][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00087/00310] [00:02:14/00:05:40, 1.533s/it]
[2025-08-27 07:04:56,078][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00095/00310] [00:02:27/00:05:28, 1.535s/it]
[2025-08-27 07:05:08,427][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00103/00310] [00:02:39/00:05:16, 1.536s/it]
[2025-08-27 07:05:20,629][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00111/00310] [00:02:51/00:05:03, 1.535s/it]
[2025-08-27 07:05:33,270][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00119/00310] [00:03:04/00:04:52, 1.538s/it]
[2025-08-27 07:05:45,234][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00127/00310] [00:03:16/00:04:39, 1.535s/it]
[2025-08-27 07:05:57,249][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00135/00310] [00:03:28/00:04:26, 1.533s/it]
[2025-08-27 07:06:09,175][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00143/00310] [00:03:40/00:04:14, 1.531s/it]
[2025-08-27 07:06:20,360][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00151/00310] [00:03:51/00:04:00, 1.524s/it]
[2025-08-27 07:06:31,195][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00159/00310] [00:04:02/00:03:47, 1.516s/it]
[2025-08-27 07:06:43,987][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00167/00310] [00:04:15/00:03:35, 1.520s/it]
[2025-08-27 07:06:55,227][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00175/00310] [00:04:26/00:03:22, 1.514s/it]
[2025-08-27 07:07:06,750][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00183/00310] [00:04:38/00:03:10, 1.511s/it]
[2025-08-27 07:07:18,188][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00191/00310] [00:04:49/00:02:57, 1.508s/it]
[2025-08-27 07:07:30,266][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00199/00310] [00:05:01/00:02:45, 1.508s/it]
[2025-08-27 07:07:42,031][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00207/00310] [00:05:13/00:02:33, 1.506s/it]
[2025-08-27 07:07:53,709][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00215/00310] [00:05:25/00:02:21, 1.505s/it]
[2025-08-27 07:08:05,483][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00223/00310] [00:05:36/00:02:09, 1.503s/it]
[2025-08-27 07:08:17,604][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00231/00310] [00:05:48/00:01:57, 1.504s/it]
[2025-08-27 07:08:29,686][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00239/00310] [00:06:00/00:01:45, 1.504s/it]
[2025-08-27 07:08:40,898][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00247/00310] [00:06:12/00:01:33, 1.501s/it]
[2025-08-27 07:08:53,049][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00255/00310] [00:06:24/00:01:21, 1.501s/it]
[2025-08-27 07:09:05,670][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00263/00310] [00:06:36/00:01:09, 1.504s/it]
[2025-08-27 07:09:17,765][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00271/00310] [00:06:49/00:00:57, 1.504s/it]
[2025-08-27 07:09:29,438][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00279/00310] [00:07:00/00:00:45, 1.503s/it]
[2025-08-27 07:09:42,181][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00287/00310] [00:07:13/00:00:33, 1.505s/it]
[2025-08-27 07:09:53,876][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00295/00310] [00:07:25/00:00:21, 1.504s/it]
[2025-08-27 07:10:06,032][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00303/00310] [00:07:37/00:00:09, 1.504s/it]
[2025-08-27 07:10:15,111][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=0.69318, valid_loss=1.67977
[2025-08-27 07:10:15,111][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-27 07:10:15,111][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.611
[2025-08-27 07:10:15,112][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.073
[2025-08-27 07:10:15,112][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.075
[2025-08-27 07:10:15,112][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.030
[2025-08-27 07:10:15,125][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 11:43:29, remaining time 11:43:29, 00:46:53 per epoch
[2025-08-27 07:10:21,396][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046208] [Batch 00008/03080] [00:00:06/00:38:45, 0.757s/it]: train_loss_raw=0.7152, running_loss=0.6743, LR=0.000100
[2025-08-27 07:10:27,488][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046216] [Batch 00016/03080] [00:00:12/00:38:46, 0.759s/it]: train_loss_raw=0.6746, running_loss=0.6744, LR=0.000100
[2025-08-27 07:10:33,461][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046224] [Batch 00024/03080] [00:00:18/00:38:27, 0.755s/it]: train_loss_raw=0.5805, running_loss=0.6766, LR=0.000100
[2025-08-27 07:10:39,460][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046232] [Batch 00032/03080] [00:00:24/00:38:17, 0.754s/it]: train_loss_raw=0.6708, running_loss=0.6788, LR=0.000100
[2025-08-27 07:10:45,365][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046240] [Batch 00040/03080] [00:00:30/00:38:01, 0.751s/it]: train_loss_raw=0.7286, running_loss=0.6802, LR=0.000100
[2025-08-27 07:10:51,273][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046248] [Batch 00048/03080] [00:00:35/00:37:49, 0.749s/it]: train_loss_raw=0.6776, running_loss=0.6794, LR=0.000100
[2025-08-27 07:10:57,218][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046256] [Batch 00056/03080] [00:00:41/00:37:41, 0.748s/it]: train_loss_raw=0.7202, running_loss=0.6795, LR=0.000100
[2025-08-27 07:11:03,314][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046264] [Batch 00064/03080] [00:00:47/00:37:40, 0.750s/it]: train_loss_raw=0.7071, running_loss=0.6805, LR=0.000100
[2025-08-27 07:11:09,415][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046272] [Batch 00072/03080] [00:00:54/00:37:39, 0.751s/it]: train_loss_raw=0.7147, running_loss=0.6815, LR=0.000100
[2025-08-27 07:11:15,637][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046280] [Batch 00080/03080] [00:01:00/00:37:41, 0.754s/it]: train_loss_raw=0.7347, running_loss=0.6797, LR=0.000100
[2025-08-27 07:11:21,742][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046288] [Batch 00088/03080] [00:01:06/00:37:37, 0.755s/it]: train_loss_raw=0.6999, running_loss=0.6798, LR=0.000100
[2025-08-27 07:11:27,889][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046296] [Batch 00096/03080] [00:01:12/00:37:35, 0.756s/it]: train_loss_raw=0.6331, running_loss=0.6819, LR=0.000100
[2025-08-27 07:11:34,007][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046304] [Batch 00104/03080] [00:01:18/00:37:31, 0.756s/it]: train_loss_raw=0.7379, running_loss=0.6841, LR=0.000100
[2025-08-27 07:11:40,116][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046312] [Batch 00112/03080] [00:01:24/00:37:26, 0.757s/it]: train_loss_raw=0.7214, running_loss=0.6850, LR=0.000100
[2025-08-27 07:11:45,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046320] [Batch 00120/03080] [00:01:30/00:37:15, 0.755s/it]: train_loss_raw=0.7923, running_loss=0.6864, LR=0.000100
[2025-08-27 07:11:51,638][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046328] [Batch 00128/03080] [00:01:36/00:37:00, 0.752s/it]: train_loss_raw=0.7040, running_loss=0.6838, LR=0.000100
[2025-08-27 07:11:57,512][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046336] [Batch 00136/03080] [00:01:42/00:36:51, 0.751s/it]: train_loss_raw=0.6660, running_loss=0.6830, LR=0.000100
[2025-08-27 07:12:03,402][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046344] [Batch 00144/03080] [00:01:48/00:36:43, 0.750s/it]: train_loss_raw=0.6983, running_loss=0.6852, LR=0.000100
[2025-08-27 07:12:09,302][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046352] [Batch 00152/03080] [00:01:53/00:36:35, 0.750s/it]: train_loss_raw=0.8230, running_loss=0.6873, LR=0.000100
[2025-08-27 07:12:14,856][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046360] [Batch 00160/03080] [00:01:59/00:36:21, 0.747s/it]: train_loss_raw=0.7718, running_loss=0.6884, LR=0.000100
[2025-08-27 07:12:20,675][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046368] [Batch 00168/03080] [00:02:05/00:36:12, 0.746s/it]: train_loss_raw=0.6377, running_loss=0.6887, LR=0.000100
[2025-08-27 07:12:26,620][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046376] [Batch 00176/03080] [00:02:11/00:36:06, 0.746s/it]: train_loss_raw=0.7117, running_loss=0.6903, LR=0.000100
[2025-08-27 07:12:32,529][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046384] [Batch 00184/03080] [00:02:17/00:35:59, 0.746s/it]: train_loss_raw=0.6861, running_loss=0.6915, LR=0.000100
[2025-08-27 07:12:38,603][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046392] [Batch 00192/03080] [00:02:23/00:35:54, 0.746s/it]: train_loss_raw=0.7056, running_loss=0.6936, LR=0.000100
[2025-08-27 07:12:44,688][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046400] [Batch 00200/03080] [00:02:29/00:35:50, 0.747s/it]: train_loss_raw=0.7273, running_loss=0.6956, LR=0.000100
[2025-08-27 07:12:50,767][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046408] [Batch 00208/03080] [00:02:35/00:35:46, 0.747s/it]: train_loss_raw=0.6488, running_loss=0.6966, LR=0.000100
[2025-08-27 07:12:56,858][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046416] [Batch 00216/03080] [00:02:41/00:35:41, 0.748s/it]: train_loss_raw=0.7010, running_loss=0.6972, LR=0.000100
[2025-08-27 07:13:02,919][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046424] [Batch 00224/03080] [00:02:47/00:35:36, 0.748s/it]: train_loss_raw=0.6171, running_loss=0.6954, LR=0.000100
[2025-08-27 07:13:08,921][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046432] [Batch 00232/03080] [00:02:53/00:35:30, 0.748s/it]: train_loss_raw=0.6952, running_loss=0.6958, LR=0.000100
[2025-08-27 07:13:15,013][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046440] [Batch 00240/03080] [00:02:59/00:35:26, 0.749s/it]: train_loss_raw=0.7813, running_loss=0.6961, LR=0.000100
[2025-08-27 07:13:21,102][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046448] [Batch 00248/03080] [00:03:05/00:35:21, 0.749s/it]: train_loss_raw=0.6695, running_loss=0.6953, LR=0.000100
[2025-08-27 07:13:27,297][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046456] [Batch 00256/03080] [00:03:11/00:35:17, 0.750s/it]: train_loss_raw=0.5668, running_loss=0.6962, LR=0.000100
[2025-08-27 07:13:33,497][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046464] [Batch 00264/03080] [00:03:18/00:35:13, 0.751s/it]: train_loss_raw=0.7390, running_loss=0.6974, LR=0.000100
[2025-08-27 07:13:39,593][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046472] [Batch 00272/03080] [00:03:24/00:35:08, 0.751s/it]: train_loss_raw=0.7106, running_loss=0.6974, LR=0.000100
[2025-08-27 07:13:45,832][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046480] [Batch 00280/03080] [00:03:30/00:35:04, 0.752s/it]: train_loss_raw=0.7377, running_loss=0.6950, LR=0.000100
[2025-08-27 07:13:51,984][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046488] [Batch 00288/03080] [00:03:36/00:35:00, 0.752s/it]: train_loss_raw=0.7178, running_loss=0.6919, LR=0.000100
[2025-08-27 07:13:58,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046496] [Batch 00296/03080] [00:03:42/00:34:55, 0.753s/it]: train_loss_raw=0.6581, running_loss=0.6881, LR=0.000100
[2025-08-27 07:14:04,256][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046504] [Batch 00304/03080] [00:03:48/00:34:50, 0.753s/it]: train_loss_raw=0.7155, running_loss=0.6849, LR=0.000100
[2025-08-27 07:14:10,347][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046512] [Batch 00312/03080] [00:03:55/00:34:44, 0.753s/it]: train_loss_raw=0.6778, running_loss=0.6842, LR=0.000100
[2025-08-27 07:14:16,492][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046520] [Batch 00320/03080] [00:04:01/00:34:39, 0.754s/it]: train_loss_raw=0.7845, running_loss=0.6850, LR=0.000100
[2025-08-27 07:14:22,557][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046528] [Batch 00328/03080] [00:04:07/00:34:34, 0.754s/it]: train_loss_raw=0.7553, running_loss=0.6855, LR=0.000100
[2025-08-27 07:14:28,637][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046536] [Batch 00336/03080] [00:04:13/00:34:28, 0.754s/it]: train_loss_raw=0.6562, running_loss=0.6841, LR=0.000100
[2025-08-27 07:14:34,823][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046544] [Batch 00344/03080] [00:04:19/00:34:23, 0.754s/it]: train_loss_raw=0.6003, running_loss=0.6851, LR=0.000100
[2025-08-27 07:14:40,880][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046552] [Batch 00352/03080] [00:04:25/00:34:17, 0.754s/it]: train_loss_raw=0.6491, running_loss=0.6868, LR=0.000100
[2025-08-27 07:14:47,054][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046560] [Batch 00360/03080] [00:04:31/00:34:12, 0.755s/it]: train_loss_raw=0.6556, running_loss=0.6870, LR=0.000100
[2025-08-27 07:14:53,177][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046568] [Batch 00368/03080] [00:04:37/00:34:07, 0.755s/it]: train_loss_raw=0.6706, running_loss=0.6855, LR=0.000100
[2025-08-27 07:14:59,295][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046576] [Batch 00376/03080] [00:04:43/00:34:02, 0.755s/it]: train_loss_raw=0.6184, running_loss=0.6840, LR=0.000100
[2025-08-27 07:15:05,408][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046584] [Batch 00384/03080] [00:04:50/00:33:56, 0.755s/it]: train_loss_raw=0.6949, running_loss=0.6860, LR=0.000100
[2025-08-27 07:15:11,526][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046592] [Batch 00392/03080] [00:04:56/00:33:50, 0.756s/it]: train_loss_raw=0.6841, running_loss=0.6829, LR=0.000100
[2025-08-27 07:15:17,538][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046600] [Batch 00400/03080] [00:05:02/00:33:44, 0.755s/it]: train_loss_raw=0.8171, running_loss=0.6837, LR=0.000100
[2025-08-27 07:15:23,592][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046608] [Batch 00408/03080] [00:05:08/00:33:38, 0.756s/it]: train_loss_raw=0.6962, running_loss=0.6824, LR=0.000100
[2025-08-27 07:15:29,745][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046616] [Batch 00416/03080] [00:05:14/00:33:33, 0.756s/it]: train_loss_raw=0.7157, running_loss=0.6806, LR=0.000100
[2025-08-27 07:15:35,802][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046624] [Batch 00424/03080] [00:05:20/00:33:27, 0.756s/it]: train_loss_raw=0.7079, running_loss=0.6830, LR=0.000100
[2025-08-27 07:15:41,984][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046632] [Batch 00432/03080] [00:05:26/00:33:22, 0.756s/it]: train_loss_raw=0.5797, running_loss=0.6812, LR=0.000100
[2025-08-27 07:15:48,027][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046640] [Batch 00440/03080] [00:05:32/00:33:16, 0.756s/it]: train_loss_raw=0.6809, running_loss=0.6788, LR=0.000100
[2025-08-27 07:15:54,039][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046648] [Batch 00448/03080] [00:05:38/00:33:09, 0.756s/it]: train_loss_raw=0.7508, running_loss=0.6790, LR=0.000100
[2025-08-27 07:16:00,119][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046656] [Batch 00456/03080] [00:05:44/00:33:03, 0.756s/it]: train_loss_raw=0.6305, running_loss=0.6775, LR=0.000100
[2025-08-27 07:16:06,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046664] [Batch 00464/03080] [00:05:50/00:32:58, 0.756s/it]: train_loss_raw=0.6900, running_loss=0.6762, LR=0.000100
[2025-08-27 07:16:12,288][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046672] [Batch 00472/03080] [00:05:56/00:32:52, 0.756s/it]: train_loss_raw=0.6470, running_loss=0.6768, LR=0.000100
[2025-08-27 07:16:18,400][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046680] [Batch 00480/03080] [00:06:03/00:32:46, 0.756s/it]: train_loss_raw=0.7058, running_loss=0.6791, LR=0.000100
[2025-08-27 07:16:24,377][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046688] [Batch 00488/03080] [00:06:09/00:32:40, 0.756s/it]: train_loss_raw=0.5910, running_loss=0.6804, LR=0.000100
[2025-08-27 07:16:30,253][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046696] [Batch 00496/03080] [00:06:14/00:32:33, 0.756s/it]: train_loss_raw=0.6430, running_loss=0.6828, LR=0.000100
[2025-08-27 07:16:36,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046704] [Batch 00504/03080] [00:06:21/00:32:27, 0.756s/it]: train_loss_raw=0.5713, running_loss=0.6811, LR=0.000100
[2025-08-27 07:16:42,303][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046712] [Batch 00512/03080] [00:06:26/00:32:20, 0.756s/it]: train_loss_raw=0.5803, running_loss=0.6800, LR=0.000100
[2025-08-27 07:16:48,348][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046720] [Batch 00520/03080] [00:06:33/00:32:14, 0.756s/it]: train_loss_raw=0.7360, running_loss=0.6806, LR=0.000100
[2025-08-27 07:16:54,372][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046728] [Batch 00528/03080] [00:06:39/00:32:08, 0.756s/it]: train_loss_raw=0.6123, running_loss=0.6806, LR=0.000100
[2025-08-27 07:17:00,449][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046736] [Batch 00536/03080] [00:06:45/00:32:02, 0.756s/it]: train_loss_raw=0.6421, running_loss=0.6817, LR=0.000100
[2025-08-27 07:17:06,488][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046744] [Batch 00544/03080] [00:06:51/00:31:56, 0.756s/it]: train_loss_raw=0.6792, running_loss=0.6808, LR=0.000100
[2025-08-27 07:17:12,537][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046752] [Batch 00552/03080] [00:06:57/00:31:50, 0.756s/it]: train_loss_raw=0.7060, running_loss=0.6813, LR=0.000100
[2025-08-27 07:17:18,594][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046760] [Batch 00560/03080] [00:07:03/00:31:44, 0.756s/it]: train_loss_raw=0.6824, running_loss=0.6793, LR=0.000100
[2025-08-27 07:17:24,782][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046768] [Batch 00568/03080] [00:07:09/00:31:39, 0.756s/it]: train_loss_raw=0.6810, running_loss=0.6784, LR=0.000100
[2025-08-27 07:17:30,898][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046776] [Batch 00576/03080] [00:07:15/00:31:33, 0.756s/it]: train_loss_raw=0.6028, running_loss=0.6781, LR=0.000100
[2025-08-27 07:17:36,972][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046784] [Batch 00584/03080] [00:07:21/00:31:27, 0.756s/it]: train_loss_raw=0.5453, running_loss=0.6755, LR=0.000100
[2025-08-27 07:17:43,023][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046792] [Batch 00592/03080] [00:07:27/00:31:21, 0.756s/it]: train_loss_raw=0.6561, running_loss=0.6750, LR=0.000100
[2025-08-27 07:17:49,170][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046800] [Batch 00600/03080] [00:07:33/00:31:15, 0.756s/it]: train_loss_raw=0.6520, running_loss=0.6746, LR=0.000100
[2025-08-27 07:17:55,237][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046808] [Batch 00608/03080] [00:07:39/00:31:09, 0.756s/it]: train_loss_raw=0.6696, running_loss=0.6725, LR=0.000100
[2025-08-27 07:18:01,299][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046816] [Batch 00616/03080] [00:07:45/00:31:03, 0.756s/it]: train_loss_raw=0.6774, running_loss=0.6729, LR=0.000100
[2025-08-27 07:18:07,348][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046824] [Batch 00624/03080] [00:07:52/00:30:57, 0.756s/it]: train_loss_raw=0.6210, running_loss=0.6717, LR=0.000100
[2025-08-27 07:18:13,489][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046832] [Batch 00632/03080] [00:07:58/00:30:52, 0.757s/it]: train_loss_raw=0.6007, running_loss=0.6714, LR=0.000100
[2025-08-27 07:18:19,555][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046840] [Batch 00640/03080] [00:08:04/00:30:46, 0.757s/it]: train_loss_raw=0.6377, running_loss=0.6717, LR=0.000100
[2025-08-27 07:18:25,677][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046848] [Batch 00648/03080] [00:08:10/00:30:40, 0.757s/it]: train_loss_raw=0.6133, running_loss=0.6714, LR=0.000100
[2025-08-27 07:18:31,801][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046856] [Batch 00656/03080] [00:08:16/00:30:34, 0.757s/it]: train_loss_raw=0.7398, running_loss=0.6733, LR=0.000100
[2025-08-27 07:18:37,966][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046864] [Batch 00664/03080] [00:08:22/00:30:28, 0.757s/it]: train_loss_raw=0.6257, running_loss=0.6732, LR=0.000100
[2025-08-27 07:18:44,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046872] [Batch 00672/03080] [00:08:28/00:30:22, 0.757s/it]: train_loss_raw=0.6627, running_loss=0.6724, LR=0.000100
[2025-08-27 07:18:50,200][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046880] [Batch 00680/03080] [00:08:34/00:30:17, 0.757s/it]: train_loss_raw=0.6111, running_loss=0.6729, LR=0.000100
[2025-08-27 07:18:56,272][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046888] [Batch 00688/03080] [00:08:40/00:30:11, 0.757s/it]: train_loss_raw=0.7190, running_loss=0.6722, LR=0.000100
[2025-08-27 07:19:02,335][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046896] [Batch 00696/03080] [00:08:46/00:30:05, 0.757s/it]: train_loss_raw=0.7315, running_loss=0.6731, LR=0.000100
[2025-08-27 07:19:08,441][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046904] [Batch 00704/03080] [00:08:53/00:29:59, 0.757s/it]: train_loss_raw=0.6119, running_loss=0.6738, LR=0.000100
[2025-08-27 07:19:14,449][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046912] [Batch 00712/03080] [00:08:59/00:29:52, 0.757s/it]: train_loss_raw=0.6420, running_loss=0.6737, LR=0.000100
[2025-08-27 07:19:20,504][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046920] [Batch 00720/03080] [00:09:05/00:29:46, 0.757s/it]: train_loss_raw=0.7284, running_loss=0.6756, LR=0.000100
[2025-08-27 07:19:26,577][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046928] [Batch 00728/03080] [00:09:11/00:29:40, 0.757s/it]: train_loss_raw=0.6619, running_loss=0.6751, LR=0.000100
[2025-08-27 07:19:32,717][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046936] [Batch 00736/03080] [00:09:17/00:29:35, 0.757s/it]: train_loss_raw=0.6360, running_loss=0.6738, LR=0.000100
[2025-08-27 07:19:38,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046944] [Batch 00744/03080] [00:09:23/00:29:29, 0.757s/it]: train_loss_raw=0.6702, running_loss=0.6722, LR=0.000100
[2025-08-27 07:19:45,165][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046952] [Batch 00752/03080] [00:09:29/00:29:24, 0.758s/it]: train_loss_raw=0.6352, running_loss=0.6692, LR=0.000100
[2025-08-27 07:19:51,182][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046960] [Batch 00760/03080] [00:09:35/00:29:17, 0.758s/it]: train_loss_raw=0.6638, running_loss=0.6690, LR=0.000100
[2025-08-27 07:19:57,318][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046968] [Batch 00768/03080] [00:09:41/00:29:11, 0.758s/it]: train_loss_raw=0.6224, running_loss=0.6680, LR=0.000100
[2025-08-27 07:20:03,464][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046976] [Batch 00776/03080] [00:09:48/00:29:06, 0.758s/it]: train_loss_raw=0.5945, running_loss=0.6688, LR=0.000100
[2025-08-27 07:20:09,531][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046984] [Batch 00784/03080] [00:09:54/00:29:00, 0.758s/it]: train_loss_raw=0.5934, running_loss=0.6682, LR=0.000100
[2025-08-27 07:20:15,612][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046992] [Batch 00792/03080] [00:10:00/00:28:54, 0.758s/it]: train_loss_raw=0.7520, running_loss=0.6695, LR=0.000100
[2025-08-27 07:20:21,709][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047000] [Batch 00800/03080] [00:10:06/00:28:48, 0.758s/it]: train_loss_raw=0.6139, running_loss=0.6697, LR=0.000100
[2025-08-27 07:20:27,912][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047008] [Batch 00808/03080] [00:10:12/00:28:42, 0.758s/it]: train_loss_raw=0.7054, running_loss=0.6697, LR=0.000100
[2025-08-27 07:20:34,007][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047016] [Batch 00816/03080] [00:10:18/00:28:36, 0.758s/it]: train_loss_raw=0.6299, running_loss=0.6680, LR=0.000100
[2025-08-27 07:20:40,158][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047024] [Batch 00824/03080] [00:10:24/00:28:30, 0.758s/it]: train_loss_raw=0.6529, running_loss=0.6687, LR=0.000100
[2025-08-27 07:20:46,304][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047032] [Batch 00832/03080] [00:10:30/00:28:24, 0.758s/it]: train_loss_raw=0.6614, running_loss=0.6687, LR=0.000100
[2025-08-27 07:20:52,425][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047040] [Batch 00840/03080] [00:10:37/00:28:18, 0.758s/it]: train_loss_raw=0.6848, running_loss=0.6681, LR=0.000100
[2025-08-27 07:20:58,470][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047048] [Batch 00848/03080] [00:10:43/00:28:12, 0.758s/it]: train_loss_raw=0.6908, running_loss=0.6699, LR=0.000100
[2025-08-27 07:21:04,573][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047056] [Batch 00856/03080] [00:10:49/00:28:06, 0.758s/it]: train_loss_raw=0.6739, running_loss=0.6685, LR=0.000100
[2025-08-27 07:21:10,717][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047064] [Batch 00864/03080] [00:10:55/00:28:00, 0.759s/it]: train_loss_raw=0.7453, running_loss=0.6704, LR=0.000100
[2025-08-27 07:21:16,888][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047072] [Batch 00872/03080] [00:11:01/00:27:55, 0.759s/it]: train_loss_raw=0.6404, running_loss=0.6687, LR=0.000100
[2025-08-27 07:21:22,987][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047080] [Batch 00880/03080] [00:11:07/00:27:49, 0.759s/it]: train_loss_raw=0.6109, running_loss=0.6668, LR=0.000100
[2025-08-27 07:21:29,034][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047088] [Batch 00888/03080] [00:11:13/00:27:42, 0.759s/it]: train_loss_raw=0.6019, running_loss=0.6668, LR=0.000100
[2025-08-27 07:21:35,187][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047096] [Batch 00896/03080] [00:11:19/00:27:37, 0.759s/it]: train_loss_raw=0.5728, running_loss=0.6644, LR=0.000100
[2025-08-27 07:21:41,230][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047104] [Batch 00904/03080] [00:11:25/00:27:30, 0.759s/it]: train_loss_raw=0.6699, running_loss=0.6653, LR=0.000100
[2025-08-27 07:21:47,350][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047112] [Batch 00912/03080] [00:11:32/00:27:25, 0.759s/it]: train_loss_raw=0.6291, running_loss=0.6658, LR=0.000100
[2025-08-27 07:21:53,500][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047120] [Batch 00920/03080] [00:11:38/00:27:19, 0.759s/it]: train_loss_raw=0.6536, running_loss=0.6641, LR=0.000100
[2025-08-27 07:21:59,659][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047128] [Batch 00928/03080] [00:11:44/00:27:13, 0.759s/it]: train_loss_raw=0.5864, running_loss=0.6619, LR=0.000100
[2025-08-27 07:22:05,735][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047136] [Batch 00936/03080] [00:11:50/00:27:07, 0.759s/it]: train_loss_raw=0.6617, running_loss=0.6623, LR=0.000100
[2025-08-27 07:22:11,802][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047144] [Batch 00944/03080] [00:11:56/00:27:01, 0.759s/it]: train_loss_raw=0.6411, running_loss=0.6642, LR=0.000100
[2025-08-27 07:22:17,913][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047152] [Batch 00952/03080] [00:12:02/00:26:55, 0.759s/it]: train_loss_raw=0.6855, running_loss=0.6654, LR=0.000100
[2025-08-27 07:22:23,925][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047160] [Batch 00960/03080] [00:12:08/00:26:48, 0.759s/it]: train_loss_raw=0.6185, running_loss=0.6654, LR=0.000100
[2025-08-27 07:22:29,973][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047168] [Batch 00968/03080] [00:12:14/00:26:42, 0.759s/it]: train_loss_raw=0.5896, running_loss=0.6649, LR=0.000100
[2025-08-27 07:22:36,069][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047176] [Batch 00976/03080] [00:12:20/00:26:36, 0.759s/it]: train_loss_raw=0.5387, running_loss=0.6617, LR=0.000100
[2025-08-27 07:22:42,124][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047184] [Batch 00984/03080] [00:12:26/00:26:30, 0.759s/it]: train_loss_raw=0.5774, running_loss=0.6607, LR=0.000100
[2025-08-27 07:22:48,181][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047192] [Batch 00992/03080] [00:12:32/00:26:24, 0.759s/it]: train_loss_raw=0.7210, running_loss=0.6607, LR=0.000100
[2025-08-27 07:22:54,272][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047200] [Batch 01000/03080] [00:12:38/00:26:18, 0.759s/it]: train_loss_raw=0.5709, running_loss=0.6617, LR=0.000100
[2025-08-27 07:23:00,499][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047208] [Batch 01008/03080] [00:12:45/00:26:12, 0.759s/it]: train_loss_raw=0.6832, running_loss=0.6650, LR=0.000100
[2025-08-27 07:23:06,585][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047216] [Batch 01016/03080] [00:12:51/00:26:06, 0.759s/it]: train_loss_raw=0.5615, running_loss=0.6646, LR=0.000100
[2025-08-27 07:23:12,638][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047224] [Batch 01024/03080] [00:12:57/00:26:00, 0.759s/it]: train_loss_raw=0.7524, running_loss=0.6656, LR=0.000100
[2025-08-27 07:23:18,710][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047232] [Batch 01032/03080] [00:13:03/00:25:54, 0.759s/it]: train_loss_raw=0.6653, running_loss=0.6656, LR=0.000100
[2025-08-27 07:23:24,887][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047240] [Batch 01040/03080] [00:13:09/00:25:48, 0.759s/it]: train_loss_raw=0.6573, running_loss=0.6649, LR=0.000100
[2025-08-27 07:23:31,045][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047248] [Batch 01048/03080] [00:13:15/00:25:42, 0.759s/it]: train_loss_raw=0.7443, running_loss=0.6658, LR=0.000100
[2025-08-27 07:23:37,142][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047256] [Batch 01056/03080] [00:13:21/00:25:36, 0.759s/it]: train_loss_raw=0.6774, running_loss=0.6658, LR=0.000100
[2025-08-27 07:23:43,264][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047264] [Batch 01064/03080] [00:13:27/00:25:30, 0.759s/it]: train_loss_raw=0.6517, running_loss=0.6648, LR=0.000100
[2025-08-27 07:23:49,477][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047272] [Batch 01072/03080] [00:13:34/00:25:24, 0.759s/it]: train_loss_raw=0.6448, running_loss=0.6627, LR=0.000100
[2025-08-27 07:23:55,483][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047280] [Batch 01080/03080] [00:13:40/00:25:18, 0.759s/it]: train_loss_raw=0.6819, running_loss=0.6652, LR=0.000100
[2025-08-27 07:24:01,571][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047288] [Batch 01088/03080] [00:13:46/00:25:12, 0.759s/it]: train_loss_raw=0.6355, running_loss=0.6669, LR=0.000100
[2025-08-27 07:24:07,662][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047296] [Batch 01096/03080] [00:13:52/00:25:06, 0.759s/it]: train_loss_raw=0.7086, running_loss=0.6662, LR=0.000100
[2025-08-27 07:24:13,730][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047304] [Batch 01104/03080] [00:13:58/00:25:00, 0.759s/it]: train_loss_raw=0.6439, running_loss=0.6668, LR=0.000100
[2025-08-27 07:24:19,728][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047312] [Batch 01112/03080] [00:14:04/00:24:54, 0.759s/it]: train_loss_raw=0.6593, running_loss=0.6677, LR=0.000100
[2025-08-27 07:24:25,724][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047320] [Batch 01120/03080] [00:14:10/00:24:48, 0.759s/it]: train_loss_raw=0.7077, running_loss=0.6725, LR=0.000100
[2025-08-27 07:24:31,837][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047328] [Batch 01128/03080] [00:14:16/00:24:42, 0.759s/it]: train_loss_raw=0.6341, running_loss=0.6731, LR=0.000100
[2025-08-27 07:24:37,910][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047336] [Batch 01136/03080] [00:14:22/00:24:36, 0.759s/it]: train_loss_raw=0.6966, running_loss=0.6714, LR=0.000100
[2025-08-27 07:24:44,036][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047344] [Batch 01144/03080] [00:14:28/00:24:30, 0.759s/it]: train_loss_raw=0.6955, running_loss=0.6731, LR=0.000100
[2025-08-27 07:24:50,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047352] [Batch 01152/03080] [00:14:34/00:24:24, 0.759s/it]: train_loss_raw=0.6245, running_loss=0.6691, LR=0.000100
[2025-08-27 07:24:56,239][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047360] [Batch 01160/03080] [00:14:40/00:24:18, 0.759s/it]: train_loss_raw=0.6554, running_loss=0.6691, LR=0.000100
[2025-08-27 07:25:02,329][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047368] [Batch 01168/03080] [00:14:46/00:24:11, 0.759s/it]: train_loss_raw=0.7278, running_loss=0.6643, LR=0.000100
[2025-08-27 07:25:08,212][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047376] [Batch 01176/03080] [00:14:52/00:24:05, 0.759s/it]: train_loss_raw=0.6621, running_loss=0.6630, LR=0.000100
[2025-08-27 07:25:14,085][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047384] [Batch 01184/03080] [00:14:58/00:23:59, 0.759s/it]: train_loss_raw=0.6306, running_loss=0.6634, LR=0.000100
[2025-08-27 07:25:19,973][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047392] [Batch 01192/03080] [00:15:04/00:23:52, 0.759s/it]: train_loss_raw=0.6633, running_loss=0.6651, LR=0.000100
[2025-08-27 07:25:25,984][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047400] [Batch 01200/03080] [00:15:10/00:23:46, 0.759s/it]: train_loss_raw=0.5154, running_loss=0.6622, LR=0.000100
[2025-08-27 07:25:32,070][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047408] [Batch 01208/03080] [00:15:16/00:23:40, 0.759s/it]: train_loss_raw=0.7060, running_loss=0.6655, LR=0.000100
[2025-08-27 07:25:37,998][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047416] [Batch 01216/03080] [00:15:22/00:23:34, 0.759s/it]: train_loss_raw=0.5447, running_loss=0.6650, LR=0.000100
[2025-08-27 07:25:44,111][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047424] [Batch 01224/03080] [00:15:28/00:23:28, 0.759s/it]: train_loss_raw=0.6464, running_loss=0.6641, LR=0.000100
[2025-08-27 07:25:50,268][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047432] [Batch 01232/03080] [00:15:34/00:23:22, 0.759s/it]: train_loss_raw=0.6053, running_loss=0.6640, LR=0.000100
[2025-08-27 07:25:56,535][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047440] [Batch 01240/03080] [00:15:41/00:23:16, 0.759s/it]: train_loss_raw=0.6231, running_loss=0.6636, LR=0.000100
[2025-08-27 07:26:02,626][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047448] [Batch 01248/03080] [00:15:47/00:23:10, 0.759s/it]: train_loss_raw=0.7042, running_loss=0.6655, LR=0.000100
[2025-08-27 07:26:08,636][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047456] [Batch 01256/03080] [00:15:53/00:23:04, 0.759s/it]: train_loss_raw=0.7106, running_loss=0.6611, LR=0.000100
[2025-08-27 07:26:14,751][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047464] [Batch 01264/03080] [00:15:59/00:22:58, 0.759s/it]: train_loss_raw=0.6342, running_loss=0.6612, LR=0.000100
[2025-08-27 07:26:20,901][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047472] [Batch 01272/03080] [00:16:05/00:22:52, 0.759s/it]: train_loss_raw=0.7073, running_loss=0.6638, LR=0.000100
[2025-08-27 07:26:27,021][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047480] [Batch 01280/03080] [00:16:11/00:22:46, 0.759s/it]: train_loss_raw=0.7236, running_loss=0.6674, LR=0.000100
[2025-08-27 07:26:33,166][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047488] [Batch 01288/03080] [00:16:17/00:22:40, 0.759s/it]: train_loss_raw=0.7021, running_loss=0.6665, LR=0.000100
[2025-08-27 07:26:39,319][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047496] [Batch 01296/03080] [00:16:23/00:22:34, 0.759s/it]: train_loss_raw=0.6198, running_loss=0.6648, LR=0.000100
[2025-08-27 07:26:45,434][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047504] [Batch 01304/03080] [00:16:30/00:22:28, 0.759s/it]: train_loss_raw=0.6345, running_loss=0.6643, LR=0.000100
[2025-08-27 07:26:51,533][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047512] [Batch 01312/03080] [00:16:36/00:22:22, 0.759s/it]: train_loss_raw=0.6302, running_loss=0.6636, LR=0.000100
[2025-08-27 07:26:58,227][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047520] [Batch 01320/03080] [00:16:42/00:22:17, 0.760s/it]: train_loss_raw=0.6637, running_loss=0.6641, LR=0.000100
[2025-08-27 07:27:04,367][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047528] [Batch 01328/03080] [00:16:49/00:22:11, 0.760s/it]: train_loss_raw=0.7295, running_loss=0.6640, LR=0.000100
[2025-08-27 07:27:10,536][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047536] [Batch 01336/03080] [00:16:55/00:22:05, 0.760s/it]: train_loss_raw=0.6726, running_loss=0.6633, LR=0.000100
[2025-08-27 07:27:16,501][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047544] [Batch 01344/03080] [00:17:01/00:21:59, 0.760s/it]: train_loss_raw=0.6074, running_loss=0.6645, LR=0.000100
[2025-08-27 07:27:22,698][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047552] [Batch 01352/03080] [00:17:07/00:21:53, 0.760s/it]: train_loss_raw=0.7624, running_loss=0.6633, LR=0.000100
[2025-08-27 07:27:28,855][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047560] [Batch 01360/03080] [00:17:13/00:21:47, 0.760s/it]: train_loss_raw=0.6817, running_loss=0.6640, LR=0.000100
[2025-08-27 07:27:34,925][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047568] [Batch 01368/03080] [00:17:19/00:21:41, 0.760s/it]: train_loss_raw=0.6741, running_loss=0.6660, LR=0.000100
[2025-08-27 07:27:41,092][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047576] [Batch 01376/03080] [00:17:25/00:21:35, 0.760s/it]: train_loss_raw=0.5661, running_loss=0.6610, LR=0.000100
[2025-08-27 07:27:47,135][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047584] [Batch 01384/03080] [00:17:31/00:21:28, 0.760s/it]: train_loss_raw=0.7202, running_loss=0.6620, LR=0.000100
[2025-08-27 07:27:53,297][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047592] [Batch 01392/03080] [00:17:37/00:21:22, 0.760s/it]: train_loss_raw=0.6225, running_loss=0.6597, LR=0.000100
[2025-08-27 07:27:59,555][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047600] [Batch 01400/03080] [00:17:44/00:21:17, 0.760s/it]: train_loss_raw=0.6369, running_loss=0.6598, LR=0.000100
[2025-08-27 07:28:05,455][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047608] [Batch 01408/03080] [00:17:50/00:21:10, 0.760s/it]: train_loss_raw=0.6325, running_loss=0.6606, LR=0.000100
[2025-08-27 07:28:11,468][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047616] [Batch 01416/03080] [00:17:56/00:21:04, 0.760s/it]: train_loss_raw=0.6778, running_loss=0.6609, LR=0.000100
[2025-08-27 07:28:17,759][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047624] [Batch 01424/03080] [00:18:02/00:20:58, 0.760s/it]: train_loss_raw=0.6298, running_loss=0.6602, LR=0.000100
[2025-08-27 07:28:23,769][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047632] [Batch 01432/03080] [00:18:08/00:20:52, 0.760s/it]: train_loss_raw=0.7127, running_loss=0.6592, LR=0.000100
[2025-08-27 07:28:29,924][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047640] [Batch 01440/03080] [00:18:14/00:20:46, 0.760s/it]: train_loss_raw=0.6677, running_loss=0.6579, LR=0.000100
[2025-08-27 07:28:35,837][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047648] [Batch 01448/03080] [00:18:20/00:20:40, 0.760s/it]: train_loss_raw=0.6705, running_loss=0.6583, LR=0.000100
[2025-08-27 07:28:41,747][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047656] [Batch 01456/03080] [00:18:26/00:20:34, 0.760s/it]: train_loss_raw=0.6546, running_loss=0.6585, LR=0.000100
[2025-08-27 07:28:47,573][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047664] [Batch 01464/03080] [00:18:32/00:20:27, 0.760s/it]: train_loss_raw=0.6786, running_loss=0.6565, LR=0.000100
[2025-08-27 07:28:53,701][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047672] [Batch 01472/03080] [00:18:38/00:20:21, 0.760s/it]: train_loss_raw=0.6925, running_loss=0.6556, LR=0.000100
[2025-08-27 07:28:59,896][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047680] [Batch 01480/03080] [00:18:44/00:20:15, 0.760s/it]: train_loss_raw=0.6768, running_loss=0.6548, LR=0.000100
[2025-08-27 07:29:06,065][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047688] [Batch 01488/03080] [00:18:50/00:20:09, 0.760s/it]: train_loss_raw=0.7832, running_loss=0.6566, LR=0.000100
[2025-08-27 07:29:12,129][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047696] [Batch 01496/03080] [00:18:56/00:20:03, 0.760s/it]: train_loss_raw=0.6302, running_loss=0.6552, LR=0.000100
[2025-08-27 07:29:18,386][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047704] [Batch 01504/03080] [00:19:03/00:19:57, 0.760s/it]: train_loss_raw=0.7848, running_loss=0.6552, LR=0.000100
[2025-08-27 07:29:24,538][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047712] [Batch 01512/03080] [00:19:09/00:19:51, 0.760s/it]: train_loss_raw=0.6152, running_loss=0.6548, LR=0.000100
[2025-08-27 07:29:30,483][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047720] [Batch 01520/03080] [00:19:15/00:19:45, 0.760s/it]: train_loss_raw=0.6342, running_loss=0.6552, LR=0.000100
[2025-08-27 07:29:36,494][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047728] [Batch 01528/03080] [00:19:21/00:19:39, 0.760s/it]: train_loss_raw=0.6415, running_loss=0.6546, LR=0.000100
[2025-08-27 07:29:42,630][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047736] [Batch 01536/03080] [00:19:27/00:19:33, 0.760s/it]: train_loss_raw=0.7248, running_loss=0.6543, LR=0.000100
[2025-08-27 07:29:48,835][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047744] [Batch 01544/03080] [00:19:33/00:19:27, 0.760s/it]: train_loss_raw=0.6059, running_loss=0.6553, LR=0.000100
[2025-08-27 07:29:54,893][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047752] [Batch 01552/03080] [00:19:39/00:19:21, 0.760s/it]: train_loss_raw=0.6655, running_loss=0.6539, LR=0.000100
[2025-08-27 07:30:01,015][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047760] [Batch 01560/03080] [00:19:45/00:19:15, 0.760s/it]: train_loss_raw=0.7213, running_loss=0.6563, LR=0.000100
[2025-08-27 07:30:07,069][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047768] [Batch 01568/03080] [00:19:51/00:19:09, 0.760s/it]: train_loss_raw=0.7669, running_loss=0.6575, LR=0.000100
[2025-08-27 07:30:13,234][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047776] [Batch 01576/03080] [00:19:57/00:19:03, 0.760s/it]: train_loss_raw=0.6689, running_loss=0.6592, LR=0.000100
[2025-08-27 07:30:19,262][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047784] [Batch 01584/03080] [00:20:03/00:18:57, 0.760s/it]: train_loss_raw=0.7228, running_loss=0.6588, LR=0.000100
[2025-08-27 07:30:25,345][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047792] [Batch 01592/03080] [00:20:10/00:18:50, 0.760s/it]: train_loss_raw=0.7100, running_loss=0.6577, LR=0.000100
[2025-08-27 07:30:31,427][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047800] [Batch 01600/03080] [00:20:16/00:18:44, 0.760s/it]: train_loss_raw=0.6472, running_loss=0.6552, LR=0.000100
[2025-08-27 07:30:37,507][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047808] [Batch 01608/03080] [00:20:22/00:18:38, 0.760s/it]: train_loss_raw=0.6384, running_loss=0.6561, LR=0.000100
[2025-08-27 07:30:43,727][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047816] [Batch 01616/03080] [00:20:28/00:18:32, 0.760s/it]: train_loss_raw=0.6309, running_loss=0.6564, LR=0.000100
[2025-08-27 07:30:49,814][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047824] [Batch 01624/03080] [00:20:34/00:18:26, 0.760s/it]: train_loss_raw=0.5889, running_loss=0.6541, LR=0.000100
[2025-08-27 07:30:55,819][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047832] [Batch 01632/03080] [00:20:40/00:18:20, 0.760s/it]: train_loss_raw=0.5941, running_loss=0.6557, LR=0.000100
[2025-08-27 07:31:01,912][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047840] [Batch 01640/03080] [00:20:46/00:18:14, 0.760s/it]: train_loss_raw=0.6285, running_loss=0.6579, LR=0.000100
[2025-08-27 07:31:08,042][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047848] [Batch 01648/03080] [00:20:52/00:18:08, 0.760s/it]: train_loss_raw=0.4978, running_loss=0.6572, LR=0.000100
[2025-08-27 07:31:14,373][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047856] [Batch 01656/03080] [00:20:59/00:18:02, 0.760s/it]: train_loss_raw=0.6772, running_loss=0.6562, LR=0.000100
[2025-08-27 07:31:20,433][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047864] [Batch 01664/03080] [00:21:05/00:17:56, 0.760s/it]: train_loss_raw=0.6102, running_loss=0.6556, LR=0.000100
[2025-08-27 07:31:26,485][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047872] [Batch 01672/03080] [00:21:11/00:17:50, 0.760s/it]: train_loss_raw=0.6422, running_loss=0.6554, LR=0.000100
[2025-08-27 07:31:32,526][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047880] [Batch 01680/03080] [00:21:17/00:17:44, 0.760s/it]: train_loss_raw=0.6343, running_loss=0.6558, LR=0.000100
[2025-08-27 07:31:38,722][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047888] [Batch 01688/03080] [00:21:23/00:17:38, 0.760s/it]: train_loss_raw=0.5916, running_loss=0.6552, LR=0.000100
[2025-08-27 07:31:44,926][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047896] [Batch 01696/03080] [00:21:29/00:17:32, 0.760s/it]: train_loss_raw=0.6618, running_loss=0.6543, LR=0.000100
[2025-08-27 07:31:50,951][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047904] [Batch 01704/03080] [00:21:35/00:17:26, 0.760s/it]: train_loss_raw=0.6294, running_loss=0.6543, LR=0.000100
[2025-08-27 07:31:57,096][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047912] [Batch 01712/03080] [00:21:41/00:17:20, 0.760s/it]: train_loss_raw=0.7403, running_loss=0.6552, LR=0.000100
[2025-08-27 07:32:03,056][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047920] [Batch 01720/03080] [00:21:47/00:17:14, 0.760s/it]: train_loss_raw=0.6073, running_loss=0.6536, LR=0.000100
[2025-08-27 07:32:08,856][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047928] [Batch 01728/03080] [00:21:53/00:17:07, 0.760s/it]: train_loss_raw=0.7145, running_loss=0.6552, LR=0.000100
[2025-08-27 07:32:14,664][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047936] [Batch 01736/03080] [00:21:59/00:17:01, 0.760s/it]: train_loss_raw=0.6378, running_loss=0.6524, LR=0.000100
[2025-08-27 07:32:20,610][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047944] [Batch 01744/03080] [00:22:05/00:16:55, 0.760s/it]: train_loss_raw=0.8828, running_loss=0.6549, LR=0.000100
[2025-08-27 07:32:26,257][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047952] [Batch 01752/03080] [00:22:10/00:16:48, 0.760s/it]: train_loss_raw=0.6442, running_loss=0.6535, LR=0.000100
[2025-08-27 07:32:31,730][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047960] [Batch 01760/03080] [00:22:16/00:16:42, 0.759s/it]: train_loss_raw=0.6415, running_loss=0.6533, LR=0.000100
[2025-08-27 07:32:37,554][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047968] [Batch 01768/03080] [00:22:22/00:16:36, 0.759s/it]: train_loss_raw=0.6889, running_loss=0.6545, LR=0.000100
[2025-08-27 07:32:43,711][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047976] [Batch 01776/03080] [00:22:28/00:16:30, 0.759s/it]: train_loss_raw=0.6578, running_loss=0.6519, LR=0.000100
[2025-08-27 07:32:49,913][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047984] [Batch 01784/03080] [00:22:34/00:16:24, 0.759s/it]: train_loss_raw=0.7663, running_loss=0.6530, LR=0.000100
[2025-08-27 07:32:55,989][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047992] [Batch 01792/03080] [00:22:40/00:16:17, 0.759s/it]: train_loss_raw=0.5864, running_loss=0.6514, LR=0.000100
[2025-08-27 07:33:02,133][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048000] [Batch 01800/03080] [00:22:46/00:16:11, 0.759s/it]: train_loss_raw=0.6310, running_loss=0.6476, LR=0.000100
[2025-08-27 07:33:12,440][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048008] [Batch 01808/03080] [00:22:57/00:16:08, 0.762s/it]: train_loss_raw=0.5938, running_loss=0.6468, LR=0.000100
[2025-08-27 07:33:18,385][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048016] [Batch 01816/03080] [00:23:03/00:16:02, 0.762s/it]: train_loss_raw=0.6751, running_loss=0.6481, LR=0.000100
[2025-08-27 07:33:24,336][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048024] [Batch 01824/03080] [00:23:08/00:15:56, 0.762s/it]: train_loss_raw=0.5265, running_loss=0.6462, LR=0.000100
[2025-08-27 07:33:30,543][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048032] [Batch 01832/03080] [00:23:15/00:15:50, 0.762s/it]: train_loss_raw=0.6981, running_loss=0.6484, LR=0.000100
[2025-08-27 07:33:36,669][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048040] [Batch 01840/03080] [00:23:21/00:15:44, 0.762s/it]: train_loss_raw=0.7225, running_loss=0.6499, LR=0.000100
[2025-08-27 07:33:42,798][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048048] [Batch 01848/03080] [00:23:27/00:15:38, 0.762s/it]: train_loss_raw=0.6655, running_loss=0.6521, LR=0.000100
[2025-08-27 07:33:48,891][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048056] [Batch 01856/03080] [00:23:33/00:15:32, 0.762s/it]: train_loss_raw=0.7038, running_loss=0.6519, LR=0.000100
[2025-08-27 07:33:54,932][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048064] [Batch 01864/03080] [00:23:39/00:15:26, 0.762s/it]: train_loss_raw=0.6598, running_loss=0.6521, LR=0.000100
[2025-08-27 07:34:01,180][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048072] [Batch 01872/03080] [00:23:45/00:15:20, 0.762s/it]: train_loss_raw=0.6244, running_loss=0.6509, LR=0.000100
[2025-08-27 07:34:07,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048080] [Batch 01880/03080] [00:23:51/00:15:13, 0.762s/it]: train_loss_raw=0.6513, running_loss=0.6499, LR=0.000100
[2025-08-27 07:34:13,416][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048088] [Batch 01888/03080] [00:23:58/00:15:07, 0.762s/it]: train_loss_raw=0.6361, running_loss=0.6508, LR=0.000100
[2025-08-27 07:34:19,336][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048096] [Batch 01896/03080] [00:24:03/00:15:01, 0.762s/it]: train_loss_raw=0.6557, running_loss=0.6526, LR=0.000100
[2025-08-27 07:34:25,187][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048104] [Batch 01904/03080] [00:24:09/00:14:55, 0.761s/it]: train_loss_raw=0.6637, running_loss=0.6511, LR=0.000100
[2025-08-27 07:34:31,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048112] [Batch 01912/03080] [00:24:15/00:14:49, 0.761s/it]: train_loss_raw=0.6330, running_loss=0.6489, LR=0.000100
[2025-08-27 07:34:36,958][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048120] [Batch 01920/03080] [00:24:21/00:14:43, 0.761s/it]: train_loss_raw=0.6041, running_loss=0.6471, LR=0.000100
[2025-08-27 07:34:42,896][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048128] [Batch 01928/03080] [00:24:27/00:14:36, 0.761s/it]: train_loss_raw=0.5911, running_loss=0.6475, LR=0.000100
[2025-08-27 07:34:49,028][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048136] [Batch 01936/03080] [00:24:33/00:14:30, 0.761s/it]: train_loss_raw=0.5648, running_loss=0.6457, LR=0.000100
[2025-08-27 07:34:55,069][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048144] [Batch 01944/03080] [00:24:39/00:14:24, 0.761s/it]: train_loss_raw=0.6357, running_loss=0.6440, LR=0.000100
[2025-08-27 07:35:01,113][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048152] [Batch 01952/03080] [00:24:45/00:14:18, 0.761s/it]: train_loss_raw=0.6756, running_loss=0.6451, LR=0.000100
[2025-08-27 07:35:07,084][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048160] [Batch 01960/03080] [00:24:51/00:14:12, 0.761s/it]: train_loss_raw=0.5844, running_loss=0.6426, LR=0.000100
[2025-08-27 07:35:13,077][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048168] [Batch 01968/03080] [00:24:57/00:14:06, 0.761s/it]: train_loss_raw=0.5887, running_loss=0.6421, LR=0.000100
[2025-08-27 07:35:19,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048176] [Batch 01976/03080] [00:25:03/00:14:00, 0.761s/it]: train_loss_raw=0.5604, running_loss=0.6414, LR=0.000100
[2025-08-27 07:35:25,123][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048184] [Batch 01984/03080] [00:25:09/00:13:54, 0.761s/it]: train_loss_raw=0.6674, running_loss=0.6424, LR=0.000100
[2025-08-27 07:35:30,924][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048192] [Batch 01992/03080] [00:25:15/00:13:47, 0.761s/it]: train_loss_raw=0.7064, running_loss=0.6429, LR=0.000100
[2025-08-27 07:35:37,164][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048200] [Batch 02000/03080] [00:25:21/00:13:41, 0.761s/it]: train_loss_raw=0.6443, running_loss=0.6435, LR=0.000100
[2025-08-27 07:35:43,214][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048208] [Batch 02008/03080] [00:25:27/00:13:35, 0.761s/it]: train_loss_raw=0.7469, running_loss=0.6430, LR=0.000100
[2025-08-27 07:35:49,364][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048216] [Batch 02016/03080] [00:25:34/00:13:29, 0.761s/it]: train_loss_raw=0.7069, running_loss=0.6445, LR=0.000100
[2025-08-27 07:35:55,221][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048224] [Batch 02024/03080] [00:25:39/00:13:23, 0.761s/it]: train_loss_raw=0.6965, running_loss=0.6454, LR=0.000100
[2025-08-27 07:36:01,074][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048232] [Batch 02032/03080] [00:25:45/00:13:17, 0.761s/it]: train_loss_raw=0.6113, running_loss=0.6464, LR=0.000100
[2025-08-27 07:36:06,987][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048240] [Batch 02040/03080] [00:25:51/00:13:11, 0.761s/it]: train_loss_raw=0.5792, running_loss=0.6459, LR=0.000100
[2025-08-27 07:36:13,098][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048248] [Batch 02048/03080] [00:25:57/00:13:04, 0.761s/it]: train_loss_raw=0.5670, running_loss=0.6457, LR=0.000100
[2025-08-27 07:36:19,029][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048256] [Batch 02056/03080] [00:26:03/00:12:58, 0.761s/it]: train_loss_raw=0.6479, running_loss=0.6460, LR=0.000100
[2025-08-27 07:36:25,055][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048264] [Batch 02064/03080] [00:26:09/00:12:52, 0.761s/it]: train_loss_raw=0.6287, running_loss=0.6476, LR=0.000100
[2025-08-27 07:36:31,361][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048272] [Batch 02072/03080] [00:26:16/00:12:46, 0.761s/it]: train_loss_raw=0.6655, running_loss=0.6479, LR=0.000100
[2025-08-27 07:36:37,546][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048280] [Batch 02080/03080] [00:26:22/00:12:40, 0.761s/it]: train_loss_raw=0.7534, running_loss=0.6470, LR=0.000100
[2025-08-27 07:36:43,708][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048288] [Batch 02088/03080] [00:26:28/00:12:34, 0.761s/it]: train_loss_raw=0.6137, running_loss=0.6466, LR=0.000100
[2025-08-27 07:36:49,822][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048296] [Batch 02096/03080] [00:26:34/00:12:28, 0.761s/it]: train_loss_raw=0.5886, running_loss=0.6475, LR=0.000100
[2025-08-27 07:36:55,800][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048304] [Batch 02104/03080] [00:26:40/00:12:22, 0.761s/it]: train_loss_raw=0.7473, running_loss=0.6497, LR=0.000100
[2025-08-27 07:37:01,680][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048312] [Batch 02112/03080] [00:26:46/00:12:16, 0.761s/it]: train_loss_raw=0.5920, running_loss=0.6477, LR=0.000100
[2025-08-27 07:37:07,459][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048320] [Batch 02120/03080] [00:26:52/00:12:10, 0.760s/it]: train_loss_raw=0.6006, running_loss=0.6481, LR=0.000100
[2025-08-27 07:37:13,242][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048328] [Batch 02128/03080] [00:26:57/00:12:03, 0.760s/it]: train_loss_raw=0.6883, running_loss=0.6489, LR=0.000100
[2025-08-27 07:37:19,355][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048336] [Batch 02136/03080] [00:27:04/00:11:57, 0.760s/it]: train_loss_raw=0.6120, running_loss=0.6481, LR=0.000100
[2025-08-27 07:37:25,176][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048344] [Batch 02144/03080] [00:27:09/00:11:51, 0.760s/it]: train_loss_raw=0.6744, running_loss=0.6485, LR=0.000100
[2025-08-27 07:37:31,333][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048352] [Batch 02152/03080] [00:27:15/00:11:45, 0.760s/it]: train_loss_raw=0.5954, running_loss=0.6499, LR=0.000100
[2025-08-27 07:37:37,436][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048360] [Batch 02160/03080] [00:27:22/00:11:39, 0.760s/it]: train_loss_raw=0.6495, running_loss=0.6504, LR=0.000100
[2025-08-27 07:37:43,482][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048368] [Batch 02168/03080] [00:27:28/00:11:33, 0.760s/it]: train_loss_raw=0.6227, running_loss=0.6516, LR=0.000100
[2025-08-27 07:37:49,612][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048376] [Batch 02176/03080] [00:27:34/00:11:27, 0.760s/it]: train_loss_raw=0.6635, running_loss=0.6505, LR=0.000100
[2025-08-27 07:37:55,766][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048384] [Batch 02184/03080] [00:27:40/00:11:21, 0.760s/it]: train_loss_raw=0.6329, running_loss=0.6499, LR=0.000100
[2025-08-27 07:38:01,743][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048392] [Batch 02192/03080] [00:27:46/00:11:15, 0.760s/it]: train_loss_raw=0.6221, running_loss=0.6463, LR=0.000100
[2025-08-27 07:38:07,793][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048400] [Batch 02200/03080] [00:27:52/00:11:08, 0.760s/it]: train_loss_raw=0.6594, running_loss=0.6461, LR=0.000100
[2025-08-27 07:38:13,853][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048408] [Batch 02208/03080] [00:27:58/00:11:02, 0.760s/it]: train_loss_raw=0.6314, running_loss=0.6468, LR=0.000100
[2025-08-27 07:38:19,856][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048416] [Batch 02216/03080] [00:28:04/00:10:56, 0.760s/it]: train_loss_raw=0.6185, running_loss=0.6443, LR=0.000100
[2025-08-27 07:38:25,936][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048424] [Batch 02224/03080] [00:28:10/00:10:50, 0.760s/it]: train_loss_raw=0.6546, running_loss=0.6459, LR=0.000100
[2025-08-27 07:38:31,918][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048432] [Batch 02232/03080] [00:28:16/00:10:44, 0.760s/it]: train_loss_raw=0.6329, running_loss=0.6448, LR=0.000100
[2025-08-27 07:38:37,880][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048440] [Batch 02240/03080] [00:28:22/00:10:38, 0.760s/it]: train_loss_raw=0.5959, running_loss=0.6426, LR=0.000100
[2025-08-27 07:38:44,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048448] [Batch 02248/03080] [00:28:28/00:10:32, 0.760s/it]: train_loss_raw=0.6607, running_loss=0.6425, LR=0.000100
[2025-08-27 07:38:50,045][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048456] [Batch 02256/03080] [00:28:34/00:10:26, 0.760s/it]: train_loss_raw=0.6511, running_loss=0.6452, LR=0.000100
[2025-08-27 07:38:55,955][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048464] [Batch 02264/03080] [00:28:40/00:10:20, 0.760s/it]: train_loss_raw=0.6561, running_loss=0.6456, LR=0.000100
[2025-08-27 07:39:02,129][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048472] [Batch 02272/03080] [00:28:46/00:10:14, 0.760s/it]: train_loss_raw=0.7301, running_loss=0.6456, LR=0.000100
[2025-08-27 07:39:08,450][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048480] [Batch 02280/03080] [00:28:53/00:10:08, 0.760s/it]: train_loss_raw=0.6134, running_loss=0.6462, LR=0.000100
[2025-08-27 07:39:14,761][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048488] [Batch 02288/03080] [00:28:59/00:10:02, 0.760s/it]: train_loss_raw=0.5757, running_loss=0.6446, LR=0.000100
[2025-08-27 07:39:20,904][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048496] [Batch 02296/03080] [00:29:05/00:09:56, 0.760s/it]: train_loss_raw=0.5802, running_loss=0.6445, LR=0.000100
[2025-08-27 07:39:26,961][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048504] [Batch 02304/03080] [00:29:11/00:09:49, 0.760s/it]: train_loss_raw=0.6375, running_loss=0.6451, LR=0.000100
[2025-08-27 07:39:33,331][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048512] [Batch 02312/03080] [00:29:17/00:09:43, 0.760s/it]: train_loss_raw=0.5940, running_loss=0.6430, LR=0.000100
[2025-08-27 07:39:39,451][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048520] [Batch 02320/03080] [00:29:24/00:09:37, 0.760s/it]: train_loss_raw=0.6040, running_loss=0.6393, LR=0.000100
[2025-08-27 07:39:45,530][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048528] [Batch 02328/03080] [00:29:30/00:09:31, 0.760s/it]: train_loss_raw=0.5577, running_loss=0.6365, LR=0.000100
[2025-08-27 07:39:51,609][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048536] [Batch 02336/03080] [00:29:36/00:09:25, 0.760s/it]: train_loss_raw=0.6949, running_loss=0.6377, LR=0.000100
[2025-08-27 07:39:57,666][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048544] [Batch 02344/03080] [00:29:42/00:09:19, 0.760s/it]: train_loss_raw=0.5848, running_loss=0.6362, LR=0.000100
[2025-08-27 07:40:03,769][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048552] [Batch 02352/03080] [00:29:48/00:09:13, 0.760s/it]: train_loss_raw=0.6067, running_loss=0.6355, LR=0.000100
[2025-08-27 07:40:10,031][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048560] [Batch 02360/03080] [00:29:54/00:09:07, 0.760s/it]: train_loss_raw=0.5932, running_loss=0.6366, LR=0.000100
[2025-08-27 07:40:16,169][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048568] [Batch 02368/03080] [00:30:00/00:09:01, 0.760s/it]: train_loss_raw=0.7200, running_loss=0.6365, LR=0.000100
[2025-08-27 07:40:22,273][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048576] [Batch 02376/03080] [00:30:06/00:08:55, 0.760s/it]: train_loss_raw=0.5908, running_loss=0.6354, LR=0.000100
[2025-08-27 07:40:28,473][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048584] [Batch 02384/03080] [00:30:13/00:08:49, 0.761s/it]: train_loss_raw=0.6757, running_loss=0.6352, LR=0.000100
[2025-08-27 07:40:34,597][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048592] [Batch 02392/03080] [00:30:19/00:08:43, 0.761s/it]: train_loss_raw=0.5930, running_loss=0.6362, LR=0.000100
[2025-08-27 07:40:40,699][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048600] [Batch 02400/03080] [00:30:25/00:08:37, 0.761s/it]: train_loss_raw=0.6329, running_loss=0.6372, LR=0.000100
[2025-08-27 07:40:46,844][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048608] [Batch 02408/03080] [00:30:31/00:08:31, 0.761s/it]: train_loss_raw=0.6549, running_loss=0.6354, LR=0.000100
[2025-08-27 07:40:53,098][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048616] [Batch 02416/03080] [00:30:37/00:08:25, 0.761s/it]: train_loss_raw=0.6769, running_loss=0.6360, LR=0.000100
[2025-08-27 07:40:59,223][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048624] [Batch 02424/03080] [00:30:43/00:08:19, 0.761s/it]: train_loss_raw=0.6193, running_loss=0.6362, LR=0.000100
[2025-08-27 07:41:05,456][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048632] [Batch 02432/03080] [00:30:50/00:08:12, 0.761s/it]: train_loss_raw=0.6097, running_loss=0.6351, LR=0.000100
[2025-08-27 07:41:11,254][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048640] [Batch 02440/03080] [00:30:55/00:08:06, 0.761s/it]: train_loss_raw=0.6965, running_loss=0.6403, LR=0.000100
[2025-08-27 07:41:16,804][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048648] [Batch 02448/03080] [00:31:01/00:08:00, 0.760s/it]: train_loss_raw=0.6680, running_loss=0.6386, LR=0.000100
[2025-08-27 07:41:22,457][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048656] [Batch 02456/03080] [00:31:07/00:07:54, 0.760s/it]: train_loss_raw=0.6589, running_loss=0.6379, LR=0.000100
[2025-08-27 07:41:28,482][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048664] [Batch 02464/03080] [00:31:13/00:07:48, 0.760s/it]: train_loss_raw=0.6458, running_loss=0.6394, LR=0.000100
[2025-08-27 07:41:34,585][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048672] [Batch 02472/03080] [00:31:19/00:07:42, 0.760s/it]: train_loss_raw=0.6310, running_loss=0.6381, LR=0.000100
[2025-08-27 07:41:40,448][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048680] [Batch 02480/03080] [00:31:25/00:07:36, 0.760s/it]: train_loss_raw=0.5795, running_loss=0.6387, LR=0.000100
[2025-08-27 07:41:46,532][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048688] [Batch 02488/03080] [00:31:31/00:07:29, 0.760s/it]: train_loss_raw=0.6448, running_loss=0.6404, LR=0.000100
[2025-08-27 07:41:52,721][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048696] [Batch 02496/03080] [00:31:37/00:07:23, 0.760s/it]: train_loss_raw=0.6097, running_loss=0.6399, LR=0.000100
[2025-08-27 07:41:58,845][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048704] [Batch 02504/03080] [00:31:43/00:07:17, 0.760s/it]: train_loss_raw=0.6687, running_loss=0.6421, LR=0.000100
[2025-08-27 07:42:04,881][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048712] [Batch 02512/03080] [00:31:49/00:07:11, 0.760s/it]: train_loss_raw=0.5787, running_loss=0.6418, LR=0.000100
[2025-08-27 07:42:11,206][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048720] [Batch 02520/03080] [00:31:55/00:07:05, 0.760s/it]: train_loss_raw=0.7393, running_loss=0.6440, LR=0.000100
[2025-08-27 07:42:17,229][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048728] [Batch 02528/03080] [00:32:01/00:06:59, 0.760s/it]: train_loss_raw=0.6272, running_loss=0.6444, LR=0.000100
[2025-08-27 07:42:23,364][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048736] [Batch 02536/03080] [00:32:08/00:06:53, 0.760s/it]: train_loss_raw=0.6021, running_loss=0.6447, LR=0.000100
[2025-08-27 07:42:29,424][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048744] [Batch 02544/03080] [00:32:14/00:06:47, 0.760s/it]: train_loss_raw=0.6987, running_loss=0.6453, LR=0.000100
[2025-08-27 07:42:35,591][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048752] [Batch 02552/03080] [00:32:20/00:06:41, 0.760s/it]: train_loss_raw=0.6698, running_loss=0.6438, LR=0.000100
[2025-08-27 07:42:41,670][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048760] [Batch 02560/03080] [00:32:26/00:06:35, 0.760s/it]: train_loss_raw=0.7120, running_loss=0.6421, LR=0.000100
[2025-08-27 07:42:47,762][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048768] [Batch 02568/03080] [00:32:32/00:06:29, 0.760s/it]: train_loss_raw=0.6818, running_loss=0.6436, LR=0.000100
[2025-08-27 07:42:53,842][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048776] [Batch 02576/03080] [00:32:38/00:06:23, 0.760s/it]: train_loss_raw=0.5948, running_loss=0.6425, LR=0.000100
[2025-08-27 07:43:00,024][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048784] [Batch 02584/03080] [00:32:44/00:06:17, 0.760s/it]: train_loss_raw=0.6006, running_loss=0.6371, LR=0.000100
[2025-08-27 07:43:06,091][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048792] [Batch 02592/03080] [00:32:50/00:06:11, 0.760s/it]: train_loss_raw=0.5749, running_loss=0.6339, LR=0.000100
[2025-08-27 07:43:12,154][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048800] [Batch 02600/03080] [00:32:56/00:06:04, 0.760s/it]: train_loss_raw=0.7227, running_loss=0.6368, LR=0.000100
[2025-08-27 07:43:18,192][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048808] [Batch 02608/03080] [00:33:02/00:05:58, 0.760s/it]: train_loss_raw=0.6770, running_loss=0.6358, LR=0.000100
[2025-08-27 07:43:24,333][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048816] [Batch 02616/03080] [00:33:08/00:05:52, 0.760s/it]: train_loss_raw=0.6099, running_loss=0.6362, LR=0.000100
[2025-08-27 07:43:30,248][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048824] [Batch 02624/03080] [00:33:14/00:05:46, 0.760s/it]: train_loss_raw=0.6634, running_loss=0.6385, LR=0.000100
[2025-08-27 07:43:36,213][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048832] [Batch 02632/03080] [00:33:20/00:05:40, 0.760s/it]: train_loss_raw=0.5402, running_loss=0.6372, LR=0.000100
[2025-08-27 07:43:42,198][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048840] [Batch 02640/03080] [00:33:26/00:05:34, 0.760s/it]: train_loss_raw=0.7632, running_loss=0.6388, LR=0.000100
[2025-08-27 07:43:48,415][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048848] [Batch 02648/03080] [00:33:33/00:05:28, 0.760s/it]: train_loss_raw=0.6257, running_loss=0.6366, LR=0.000100
[2025-08-27 07:43:54,431][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048856] [Batch 02656/03080] [00:33:39/00:05:22, 0.760s/it]: train_loss_raw=0.6605, running_loss=0.6350, LR=0.000100
[2025-08-27 07:44:00,545][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048864] [Batch 02664/03080] [00:33:45/00:05:16, 0.760s/it]: train_loss_raw=0.6203, running_loss=0.6317, LR=0.000100
[2025-08-27 07:44:06,702][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048872] [Batch 02672/03080] [00:33:51/00:05:10, 0.760s/it]: train_loss_raw=0.6941, running_loss=0.6323, LR=0.000100
[2025-08-27 07:44:12,826][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048880] [Batch 02680/03080] [00:33:57/00:05:04, 0.760s/it]: train_loss_raw=0.6571, running_loss=0.6347, LR=0.000100
[2025-08-27 07:44:18,933][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048888] [Batch 02688/03080] [00:34:03/00:04:58, 0.760s/it]: train_loss_raw=0.5296, running_loss=0.6331, LR=0.000100
[2025-08-27 07:44:24,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048896] [Batch 02696/03080] [00:34:09/00:04:51, 0.760s/it]: train_loss_raw=0.6150, running_loss=0.6330, LR=0.000100
[2025-08-27 07:44:31,042][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048904] [Batch 02704/03080] [00:34:15/00:04:45, 0.760s/it]: train_loss_raw=0.6690, running_loss=0.6338, LR=0.000100
[2025-08-27 07:44:37,237][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048912] [Batch 02712/03080] [00:34:21/00:04:39, 0.760s/it]: train_loss_raw=0.6122, running_loss=0.6353, LR=0.000100
[2025-08-27 07:44:43,247][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048920] [Batch 02720/03080] [00:34:27/00:04:33, 0.760s/it]: train_loss_raw=0.4950, running_loss=0.6330, LR=0.000100
[2025-08-27 07:44:49,466][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048928] [Batch 02728/03080] [00:34:34/00:04:27, 0.760s/it]: train_loss_raw=0.6452, running_loss=0.6331, LR=0.000100
[2025-08-27 07:44:55,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048936] [Batch 02736/03080] [00:34:40/00:04:21, 0.760s/it]: train_loss_raw=0.5654, running_loss=0.6317, LR=0.000100
[2025-08-27 07:45:01,541][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048944] [Batch 02744/03080] [00:34:46/00:04:15, 0.760s/it]: train_loss_raw=0.6799, running_loss=0.6351, LR=0.000100
[2025-08-27 07:45:07,628][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048952] [Batch 02752/03080] [00:34:52/00:04:09, 0.760s/it]: train_loss_raw=0.5743, running_loss=0.6334, LR=0.000100
[2025-08-27 07:45:13,736][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048960] [Batch 02760/03080] [00:34:58/00:04:03, 0.760s/it]: train_loss_raw=0.6637, running_loss=0.6332, LR=0.000100
[2025-08-27 07:45:19,799][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048968] [Batch 02768/03080] [00:35:04/00:03:57, 0.760s/it]: train_loss_raw=0.6433, running_loss=0.6326, LR=0.000100
[2025-08-27 07:45:25,870][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048976] [Batch 02776/03080] [00:35:10/00:03:51, 0.760s/it]: train_loss_raw=0.6392, running_loss=0.6337, LR=0.000100
[2025-08-27 07:45:31,888][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048984] [Batch 02784/03080] [00:35:16/00:03:45, 0.760s/it]: train_loss_raw=0.6683, running_loss=0.6312, LR=0.000100
[2025-08-27 07:45:38,019][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048992] [Batch 02792/03080] [00:35:22/00:03:38, 0.760s/it]: train_loss_raw=0.6619, running_loss=0.6321, LR=0.000100
[2025-08-27 07:45:44,084][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049000] [Batch 02800/03080] [00:35:28/00:03:32, 0.760s/it]: train_loss_raw=0.5788, running_loss=0.6287, LR=0.000100
[2025-08-27 07:45:50,431][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049008] [Batch 02808/03080] [00:35:35/00:03:26, 0.760s/it]: train_loss_raw=0.6969, running_loss=0.6300, LR=0.000100
[2025-08-27 07:45:56,586][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049016] [Batch 02816/03080] [00:35:41/00:03:20, 0.760s/it]: train_loss_raw=0.6517, running_loss=0.6295, LR=0.000100
[2025-08-27 07:46:02,547][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049024] [Batch 02824/03080] [00:35:47/00:03:14, 0.760s/it]: train_loss_raw=0.5562, running_loss=0.6281, LR=0.000100
[2025-08-27 07:46:08,572][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049032] [Batch 02832/03080] [00:35:53/00:03:08, 0.760s/it]: train_loss_raw=0.6508, running_loss=0.6281, LR=0.000100
[2025-08-27 07:46:14,703][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049040] [Batch 02840/03080] [00:35:59/00:03:02, 0.760s/it]: train_loss_raw=0.5740, running_loss=0.6286, LR=0.000100
[2025-08-27 07:46:20,751][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049048] [Batch 02848/03080] [00:36:05/00:02:56, 0.760s/it]: train_loss_raw=0.6493, running_loss=0.6305, LR=0.000100
[2025-08-27 07:46:26,852][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049056] [Batch 02856/03080] [00:36:11/00:02:50, 0.760s/it]: train_loss_raw=0.6157, running_loss=0.6298, LR=0.000100
[2025-08-27 07:46:32,792][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049064] [Batch 02864/03080] [00:36:17/00:02:44, 0.760s/it]: train_loss_raw=0.6570, running_loss=0.6313, LR=0.000100
[2025-08-27 07:46:38,654][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049072] [Batch 02872/03080] [00:36:23/00:02:38, 0.760s/it]: train_loss_raw=0.7008, running_loss=0.6323, LR=0.000100
[2025-08-27 07:46:44,744][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049080] [Batch 02880/03080] [00:36:29/00:02:32, 0.760s/it]: train_loss_raw=0.7557, running_loss=0.6322, LR=0.000100
[2025-08-27 07:46:50,907][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049088] [Batch 02888/03080] [00:36:35/00:02:25, 0.760s/it]: train_loss_raw=0.6258, running_loss=0.6297, LR=0.000100
[2025-08-27 07:46:57,023][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049096] [Batch 02896/03080] [00:36:41/00:02:19, 0.760s/it]: train_loss_raw=0.5726, running_loss=0.6278, LR=0.000100
[2025-08-27 07:47:03,280][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049104] [Batch 02904/03080] [00:36:47/00:02:13, 0.760s/it]: train_loss_raw=0.5516, running_loss=0.6267, LR=0.000100
[2025-08-27 07:47:09,473][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049112] [Batch 02912/03080] [00:36:54/00:02:07, 0.760s/it]: train_loss_raw=0.5746, running_loss=0.6259, LR=0.000100
[2025-08-27 07:47:15,649][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049120] [Batch 02920/03080] [00:37:00/00:02:01, 0.760s/it]: train_loss_raw=0.6943, running_loss=0.6268, LR=0.000100
[2025-08-27 07:47:21,746][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049128] [Batch 02928/03080] [00:37:06/00:01:55, 0.760s/it]: train_loss_raw=0.6298, running_loss=0.6265, LR=0.000100
[2025-08-27 07:47:27,841][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049136] [Batch 02936/03080] [00:37:12/00:01:49, 0.760s/it]: train_loss_raw=0.6605, running_loss=0.6274, LR=0.000100
[2025-08-27 07:47:33,952][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049144] [Batch 02944/03080] [00:37:18/00:01:43, 0.760s/it]: train_loss_raw=0.6949, running_loss=0.6285, LR=0.000100
[2025-08-27 07:47:39,975][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049152] [Batch 02952/03080] [00:37:24/00:01:37, 0.760s/it]: train_loss_raw=0.6257, running_loss=0.6277, LR=0.000100
[2025-08-27 07:47:46,168][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049160] [Batch 02960/03080] [00:37:30/00:01:31, 0.760s/it]: train_loss_raw=0.6514, running_loss=0.6252, LR=0.000100
[2025-08-27 07:47:52,228][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049168] [Batch 02968/03080] [00:37:36/00:01:25, 0.760s/it]: train_loss_raw=0.5371, running_loss=0.6238, LR=0.000100
[2025-08-27 07:47:58,009][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049176] [Batch 02976/03080] [00:37:42/00:01:19, 0.760s/it]: train_loss_raw=0.5796, running_loss=0.6245, LR=0.000100
[2025-08-27 07:48:04,117][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049184] [Batch 02984/03080] [00:37:48/00:01:12, 0.760s/it]: train_loss_raw=0.6081, running_loss=0.6241, LR=0.000100
[2025-08-27 07:48:10,213][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049192] [Batch 02992/03080] [00:37:54/00:01:06, 0.760s/it]: train_loss_raw=0.4838, running_loss=0.6205, LR=0.000100
[2025-08-27 07:48:16,338][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049200] [Batch 03000/03080] [00:38:00/00:01:00, 0.760s/it]: train_loss_raw=0.6265, running_loss=0.6205, LR=0.000100
[2025-08-27 07:48:22,445][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049208] [Batch 03008/03080] [00:38:07/00:00:54, 0.760s/it]: train_loss_raw=0.6031, running_loss=0.6224, LR=0.000100
[2025-08-27 07:48:28,674][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049216] [Batch 03016/03080] [00:38:13/00:00:48, 0.760s/it]: train_loss_raw=0.6256, running_loss=0.6233, LR=0.000100
[2025-08-27 07:48:34,900][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049224] [Batch 03024/03080] [00:38:19/00:00:42, 0.760s/it]: train_loss_raw=0.5616, running_loss=0.6237, LR=0.000100
[2025-08-27 07:48:40,928][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049232] [Batch 03032/03080] [00:38:25/00:00:36, 0.760s/it]: train_loss_raw=0.5795, running_loss=0.6242, LR=0.000100
[2025-08-27 07:48:47,001][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049240] [Batch 03040/03080] [00:38:31/00:00:30, 0.760s/it]: train_loss_raw=0.6877, running_loss=0.6240, LR=0.000100
[2025-08-27 07:48:53,049][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049248] [Batch 03048/03080] [00:38:37/00:00:24, 0.760s/it]: train_loss_raw=0.5552, running_loss=0.6253, LR=0.000100
[2025-08-27 07:48:59,127][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049256] [Batch 03056/03080] [00:38:43/00:00:18, 0.760s/it]: train_loss_raw=0.6391, running_loss=0.6262, LR=0.000100
[2025-08-27 07:49:05,188][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049264] [Batch 03064/03080] [00:38:49/00:00:12, 0.760s/it]: train_loss_raw=0.7855, running_loss=0.6288, LR=0.000100
[2025-08-27 07:49:11,398][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049272] [Batch 03072/03080] [00:38:56/00:00:06, 0.760s/it]: train_loss_raw=0.6711, running_loss=0.6298, LR=0.000100
[2025-08-27 07:49:23,160][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049280] [Batch 03080/03080] [00:39:07/00:00:00, 0.762s/it]: train_loss_raw=0.4977, running_loss=0.6299, LR=0.000100
[2025-08-27 07:49:23,794][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-27 07:49:35,109][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00007/00310] [00:00:11/00:07:07, 1.414s/it]
[2025-08-27 07:49:46,553][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00015/00310] [00:00:22/00:06:58, 1.422s/it]
[2025-08-27 07:49:58,487][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00023/00310] [00:00:34/00:06:53, 1.446s/it]
[2025-08-27 07:50:11,605][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00031/00310] [00:00:47/00:06:55, 1.494s/it]
[2025-08-27 07:50:23,969][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00039/00310] [00:01:00/00:06:46, 1.504s/it]
[2025-08-27 07:50:35,063][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00047/00310] [00:01:11/00:06:29, 1.485s/it]
[2025-08-27 07:50:47,613][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00055/00310] [00:01:23/00:06:20, 1.497s/it]
[2025-08-27 07:50:58,591][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00063/00310] [00:01:34/00:06:04, 1.481s/it]
[2025-08-27 07:51:09,729][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00071/00310] [00:01:45/00:05:50, 1.471s/it]
[2025-08-27 07:51:21,331][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00079/00310] [00:01:57/00:05:37, 1.469s/it]
[2025-08-27 07:51:33,210][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00087/00310] [00:02:09/00:05:26, 1.471s/it]
[2025-08-27 07:51:45,345][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00095/00310] [00:02:21/00:05:15, 1.474s/it]
[2025-08-27 07:51:57,513][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00103/00310] [00:02:33/00:05:04, 1.478s/it]
[2025-08-27 07:52:10,216][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00111/00310] [00:02:46/00:04:54, 1.486s/it]
[2025-08-27 07:52:22,440][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00119/00310] [00:02:58/00:04:42, 1.489s/it]
[2025-08-27 07:52:34,901][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00127/00310] [00:03:11/00:04:31, 1.493s/it]
[2025-08-27 07:52:46,960][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00135/00310] [00:03:23/00:04:19, 1.494s/it]
[2025-08-27 07:52:59,694][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00143/00310] [00:03:35/00:04:08, 1.499s/it]
[2025-08-27 07:53:10,195][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00151/00310] [00:03:46/00:03:55, 1.489s/it]
[2025-08-27 07:53:21,814][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00159/00310] [00:03:58/00:03:43, 1.488s/it]
[2025-08-27 07:53:33,989][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00167/00310] [00:04:10/00:03:31, 1.489s/it]
[2025-08-27 07:53:45,570][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00175/00310] [00:04:21/00:03:19, 1.487s/it]
[2025-08-27 07:53:56,684][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00183/00310] [00:04:32/00:03:06, 1.483s/it]
[2025-08-27 07:54:08,930][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00191/00310] [00:04:45/00:02:55, 1.485s/it]
[2025-08-27 07:54:21,317][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00199/00310] [00:04:57/00:02:43, 1.488s/it]
[2025-08-27 07:54:33,027][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00207/00310] [00:05:09/00:02:31, 1.487s/it]
[2025-08-27 07:54:45,192][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00215/00310] [00:05:21/00:02:19, 1.488s/it]
[2025-08-27 07:54:57,372][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00223/00310] [00:05:33/00:02:08, 1.489s/it]
[2025-08-27 07:55:10,038][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00231/00310] [00:05:46/00:01:56, 1.492s/it]
[2025-08-27 07:55:22,170][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00239/00310] [00:05:58/00:01:44, 1.493s/it]
[2025-08-27 07:55:33,412][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00247/00310] [00:06:09/00:01:32, 1.490s/it]
[2025-08-27 07:55:45,412][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00255/00310] [00:06:21/00:01:20, 1.491s/it]
[2025-08-27 07:55:57,978][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00263/00310] [00:06:34/00:01:08, 1.493s/it]
[2025-08-27 07:56:11,168][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00271/00310] [00:06:47/00:00:56, 1.498s/it]
[2025-08-27 07:56:23,021][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00279/00310] [00:06:59/00:00:44, 1.497s/it]
[2025-08-27 07:56:34,939][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00287/00310] [00:07:11/00:00:32, 1.497s/it]
[2025-08-27 07:56:46,239][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00295/00310] [00:07:22/00:00:20, 1.495s/it]
[2025-08-27 07:56:58,998][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00303/00310] [00:07:35/00:00:08, 1.497s/it]
[2025-08-27 07:57:08,009][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=0.62993, valid_loss=1.59391
[2025-08-27 07:57:08,009][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-27 07:57:08,009][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.591
[2025-08-27 07:57:08,009][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.086
[2025-08-27 07:57:08,010][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.089
[2025-08-27 07:57:08,010][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.037
[2025-08-27 07:57:08,021][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 12:30:21, remaining time 10:56:34, 00:46:53 per epoch
[2025-08-27 07:57:22,341][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049288] [Batch 00008/03080] [00:00:14/01:29:46, 1.753s/it]: train_loss_raw=0.5998, running_loss=0.5996, LR=0.000100
[2025-08-27 07:57:28,409][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049296] [Batch 00016/03080] [00:00:20/01:04:08, 1.256s/it]: train_loss_raw=0.5928, running_loss=0.6007, LR=0.000100
[2025-08-27 07:57:34,521][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049304] [Batch 00024/03080] [00:00:26/00:55:36, 1.092s/it]: train_loss_raw=0.6642, running_loss=0.6013, LR=0.000100
[2025-08-27 07:57:40,563][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049312] [Batch 00032/03080] [00:00:32/00:51:11, 1.008s/it]: train_loss_raw=0.6447, running_loss=0.6023, LR=0.000100
[2025-08-27 07:57:46,782][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049320] [Batch 00040/03080] [00:00:38/00:48:43, 0.962s/it]: train_loss_raw=0.6287, running_loss=0.6004, LR=0.000100
[2025-08-27 07:57:52,795][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049328] [Batch 00048/03080] [00:00:44/00:46:49, 0.927s/it]: train_loss_raw=0.5892, running_loss=0.5966, LR=0.000100
[2025-08-27 07:57:58,881][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049336] [Batch 00056/03080] [00:00:50/00:45:30, 0.903s/it]: train_loss_raw=0.5508, running_loss=0.5940, LR=0.000100
[2025-08-27 07:58:04,911][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049344] [Batch 00064/03080] [00:00:56/00:44:27, 0.884s/it]: train_loss_raw=0.6039, running_loss=0.5937, LR=0.000100
[2025-08-27 07:58:10,989][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049352] [Batch 00072/03080] [00:01:02/00:43:38, 0.870s/it]: train_loss_raw=0.6100, running_loss=0.5959, LR=0.000100
[2025-08-27 07:58:16,968][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049360] [Batch 00080/03080] [00:01:08/00:42:54, 0.858s/it]: train_loss_raw=0.5258, running_loss=0.5943, LR=0.000100
[2025-08-27 07:58:23,030][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049368] [Batch 00088/03080] [00:01:14/00:42:20, 0.849s/it]: train_loss_raw=0.6161, running_loss=0.5946, LR=0.000100
[2025-08-27 07:58:29,089][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049376] [Batch 00096/03080] [00:01:20/00:41:50, 0.841s/it]: train_loss_raw=0.4696, running_loss=0.5936, LR=0.000100
[2025-08-27 07:58:35,136][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049384] [Batch 00104/03080] [00:01:26/00:41:24, 0.835s/it]: train_loss_raw=0.5442, running_loss=0.5933, LR=0.000100
[2025-08-27 07:58:41,236][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049392] [Batch 00112/03080] [00:01:32/00:41:02, 0.830s/it]: train_loss_raw=0.5878, running_loss=0.5915, LR=0.000100
[2025-08-27 07:58:47,446][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049400] [Batch 00120/03080] [00:01:39/00:40:45, 0.826s/it]: train_loss_raw=0.6051, running_loss=0.5921, LR=0.000100
[2025-08-27 07:58:53,500][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049408] [Batch 00128/03080] [00:01:45/00:40:25, 0.822s/it]: train_loss_raw=0.4867, running_loss=0.5912, LR=0.000100
[2025-08-27 07:58:59,505][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049416] [Batch 00136/03080] [00:01:51/00:40:06, 0.818s/it]: train_loss_raw=0.6472, running_loss=0.5911, LR=0.000100
[2025-08-27 07:59:05,939][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049424] [Batch 00144/03080] [00:01:57/00:39:58, 0.817s/it]: train_loss_raw=0.5533, running_loss=0.5931, LR=0.000100
[2025-08-27 07:59:12,005][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049432] [Batch 00152/03080] [00:02:03/00:39:42, 0.814s/it]: train_loss_raw=0.6511, running_loss=0.5947, LR=0.000100
[2025-08-27 07:59:18,074][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049440] [Batch 00160/03080] [00:02:09/00:39:28, 0.811s/it]: train_loss_raw=0.5913, running_loss=0.5938, LR=0.000100
[2025-08-27 07:59:24,126][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049448] [Batch 00168/03080] [00:02:15/00:39:14, 0.808s/it]: train_loss_raw=0.4917, running_loss=0.5916, LR=0.000100
[2025-08-27 07:59:30,188][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049456] [Batch 00176/03080] [00:02:21/00:39:00, 0.806s/it]: train_loss_raw=0.6377, running_loss=0.5958, LR=0.000100
[2025-08-27 07:59:36,406][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049464] [Batch 00184/03080] [00:02:28/00:38:50, 0.805s/it]: train_loss_raw=0.6009, running_loss=0.5998, LR=0.000100
[2025-08-27 07:59:42,443][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049472] [Batch 00192/03080] [00:02:34/00:38:38, 0.803s/it]: train_loss_raw=0.7095, running_loss=0.6026, LR=0.000100
[2025-08-27 07:59:48,550][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049480] [Batch 00200/03080] [00:02:40/00:38:27, 0.801s/it]: train_loss_raw=0.6208, running_loss=0.6045, LR=0.000100
[2025-08-27 07:59:54,795][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049488] [Batch 00208/03080] [00:02:46/00:38:18, 0.800s/it]: train_loss_raw=0.6181, running_loss=0.6061, LR=0.000100
[2025-08-27 08:00:00,869][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049496] [Batch 00216/03080] [00:02:52/00:38:07, 0.799s/it]: train_loss_raw=0.6743, running_loss=0.6082, LR=0.000100
[2025-08-27 08:00:06,930][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049504] [Batch 00224/03080] [00:02:58/00:37:57, 0.797s/it]: train_loss_raw=0.6119, running_loss=0.6077, LR=0.000100
[2025-08-27 08:00:13,127][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049512] [Batch 00232/03080] [00:03:04/00:37:48, 0.797s/it]: train_loss_raw=0.5646, running_loss=0.6051, LR=0.000100
[2025-08-27 08:00:19,322][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049520] [Batch 00240/03080] [00:03:11/00:37:40, 0.796s/it]: train_loss_raw=0.5657, running_loss=0.6026, LR=0.000100
[2025-08-27 08:00:25,559][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049528] [Batch 00248/03080] [00:03:17/00:37:32, 0.795s/it]: train_loss_raw=0.5885, running_loss=0.6019, LR=0.000100
[2025-08-27 08:00:31,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049536] [Batch 00256/03080] [00:03:23/00:37:21, 0.794s/it]: train_loss_raw=0.6230, running_loss=0.6009, LR=0.000100
[2025-08-27 08:00:37,601][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049544] [Batch 00264/03080] [00:03:29/00:37:12, 0.793s/it]: train_loss_raw=0.6085, running_loss=0.6004, LR=0.000100
[2025-08-27 08:00:43,163][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049552] [Batch 00272/03080] [00:03:34/00:36:57, 0.790s/it]: train_loss_raw=0.5732, running_loss=0.5984, LR=0.000100
[2025-08-27 08:00:49,205][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049560] [Batch 00280/03080] [00:03:40/00:36:48, 0.789s/it]: train_loss_raw=0.6411, running_loss=0.5979, LR=0.000100
[2025-08-27 08:00:55,382][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049568] [Batch 00288/03080] [00:03:47/00:36:41, 0.788s/it]: train_loss_raw=0.6456, running_loss=0.5977, LR=0.000100
[2025-08-27 08:01:01,342][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049576] [Batch 00296/03080] [00:03:53/00:36:31, 0.787s/it]: train_loss_raw=0.5315, running_loss=0.5962, LR=0.000100
[2025-08-27 08:01:07,376][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049584] [Batch 00304/03080] [00:03:59/00:36:23, 0.786s/it]: train_loss_raw=0.6777, running_loss=0.5961, LR=0.000100
[2025-08-27 08:01:13,454][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049592] [Batch 00312/03080] [00:04:05/00:36:14, 0.786s/it]: train_loss_raw=0.5775, running_loss=0.5975, LR=0.000100
[2025-08-27 08:01:19,578][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049600] [Batch 00320/03080] [00:04:11/00:36:07, 0.785s/it]: train_loss_raw=0.5279, running_loss=0.5962, LR=0.000100
[2025-08-27 08:01:25,781][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049608] [Batch 00328/03080] [00:04:17/00:36:00, 0.785s/it]: train_loss_raw=0.5210, running_loss=0.5962, LR=0.000100
[2025-08-27 08:01:31,868][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049616] [Batch 00336/03080] [00:04:23/00:35:52, 0.784s/it]: train_loss_raw=0.6991, running_loss=0.5956, LR=0.000100
[2025-08-27 08:01:37,936][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049624] [Batch 00344/03080] [00:04:29/00:35:44, 0.784s/it]: train_loss_raw=0.6755, running_loss=0.5968, LR=0.000100
[2025-08-27 08:01:44,051][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049632] [Batch 00352/03080] [00:04:35/00:35:36, 0.783s/it]: train_loss_raw=0.5475, running_loss=0.5958, LR=0.000100
[2025-08-27 08:01:50,185][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049640] [Batch 00360/03080] [00:04:41/00:35:29, 0.783s/it]: train_loss_raw=0.4749, running_loss=0.5970, LR=0.000100
[2025-08-27 08:01:56,279][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049648] [Batch 00368/03080] [00:04:47/00:35:22, 0.783s/it]: train_loss_raw=0.6064, running_loss=0.5986, LR=0.000100
[2025-08-27 08:02:02,447][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049656] [Batch 00376/03080] [00:04:54/00:35:15, 0.782s/it]: train_loss_raw=0.6243, running_loss=0.5965, LR=0.000100
[2025-08-27 08:02:08,486][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049664] [Batch 00384/03080] [00:05:00/00:35:07, 0.782s/it]: train_loss_raw=0.6570, running_loss=0.5971, LR=0.000100
[2025-08-27 08:02:14,635][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049672] [Batch 00392/03080] [00:05:06/00:35:00, 0.781s/it]: train_loss_raw=0.5577, running_loss=0.5963, LR=0.000100
[2025-08-27 08:02:20,737][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049680] [Batch 00400/03080] [00:05:12/00:34:53, 0.781s/it]: train_loss_raw=0.5777, running_loss=0.5938, LR=0.000100
[2025-08-27 08:02:26,918][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049688] [Batch 00408/03080] [00:05:18/00:34:46, 0.781s/it]: train_loss_raw=0.6225, running_loss=0.5946, LR=0.000100
[2025-08-27 08:02:32,982][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049696] [Batch 00416/03080] [00:05:24/00:34:39, 0.780s/it]: train_loss_raw=0.6333, running_loss=0.5950, LR=0.000100
[2025-08-27 08:02:39,149][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049704] [Batch 00424/03080] [00:05:30/00:34:32, 0.780s/it]: train_loss_raw=0.5951, running_loss=0.5981, LR=0.000100
[2025-08-27 08:02:45,376][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049712] [Batch 00432/03080] [00:05:37/00:34:26, 0.780s/it]: train_loss_raw=0.6062, running_loss=0.5996, LR=0.000100
[2025-08-27 08:02:51,367][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049720] [Batch 00440/03080] [00:05:43/00:34:18, 0.780s/it]: train_loss_raw=0.5972, running_loss=0.5986, LR=0.000100
[2025-08-27 08:02:57,576][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049728] [Batch 00448/03080] [00:05:49/00:34:11, 0.780s/it]: train_loss_raw=0.5912, running_loss=0.5969, LR=0.000100
[2025-08-27 08:03:03,845][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049736] [Batch 00456/03080] [00:05:55/00:34:05, 0.780s/it]: train_loss_raw=0.5874, running_loss=0.5949, LR=0.000100
[2025-08-27 08:03:10,124][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049744] [Batch 00464/03080] [00:06:01/00:33:59, 0.780s/it]: train_loss_raw=0.5281, running_loss=0.5943, LR=0.000100
[2025-08-27 08:03:16,216][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049752] [Batch 00472/03080] [00:06:07/00:33:52, 0.779s/it]: train_loss_raw=0.6387, running_loss=0.5928, LR=0.000100
[2025-08-27 08:03:22,362][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049760] [Batch 00480/03080] [00:06:14/00:33:46, 0.779s/it]: train_loss_raw=0.5866, running_loss=0.5922, LR=0.000100
[2025-08-27 08:03:28,518][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049768] [Batch 00488/03080] [00:06:20/00:33:39, 0.779s/it]: train_loss_raw=0.6300, running_loss=0.5927, LR=0.000100
[2025-08-27 08:03:34,563][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049776] [Batch 00496/03080] [00:06:26/00:33:32, 0.779s/it]: train_loss_raw=0.6182, running_loss=0.5956, LR=0.000100
[2025-08-27 08:03:40,659][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049784] [Batch 00504/03080] [00:06:32/00:33:25, 0.778s/it]: train_loss_raw=0.5026, running_loss=0.5937, LR=0.000100
[2025-08-27 08:03:46,741][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049792] [Batch 00512/03080] [00:06:38/00:33:18, 0.778s/it]: train_loss_raw=0.5761, running_loss=0.5943, LR=0.000100
[2025-08-27 08:03:52,245][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049800] [Batch 00520/03080] [00:06:43/00:33:08, 0.777s/it]: train_loss_raw=0.5372, running_loss=0.5925, LR=0.000100
[2025-08-27 08:03:58,197][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049808] [Batch 00528/03080] [00:06:49/00:33:01, 0.776s/it]: train_loss_raw=0.5608, running_loss=0.5955, LR=0.000100
[2025-08-27 08:04:04,307][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049816] [Batch 00536/03080] [00:06:55/00:32:54, 0.776s/it]: train_loss_raw=0.6918, running_loss=0.5968, LR=0.000100
[2025-08-27 08:04:10,495][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049824] [Batch 00544/03080] [00:07:02/00:32:48, 0.776s/it]: train_loss_raw=0.6839, running_loss=0.5963, LR=0.000100
[2025-08-27 08:04:16,654][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049832] [Batch 00552/03080] [00:07:08/00:32:41, 0.776s/it]: train_loss_raw=0.6080, running_loss=0.5968, LR=0.000100
[2025-08-27 08:04:22,739][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049840] [Batch 00560/03080] [00:07:14/00:32:34, 0.776s/it]: train_loss_raw=0.5487, running_loss=0.5938, LR=0.000100
[2025-08-27 08:04:28,968][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049848] [Batch 00568/03080] [00:07:20/00:32:28, 0.776s/it]: train_loss_raw=0.5805, running_loss=0.5925, LR=0.000100
[2025-08-27 08:04:35,042][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049856] [Batch 00576/03080] [00:07:26/00:32:22, 0.776s/it]: train_loss_raw=0.6213, running_loss=0.5911, LR=0.000100
[2025-08-27 08:04:40,934][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049864] [Batch 00584/03080] [00:07:32/00:32:14, 0.775s/it]: train_loss_raw=0.5622, running_loss=0.5914, LR=0.000100
[2025-08-27 08:04:46,953][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049872] [Batch 00592/03080] [00:07:38/00:32:07, 0.775s/it]: train_loss_raw=0.4903, running_loss=0.5900, LR=0.000100
[2025-08-27 08:04:53,267][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049880] [Batch 00600/03080] [00:07:44/00:32:01, 0.775s/it]: train_loss_raw=0.6124, running_loss=0.5907, LR=0.000100
[2025-08-27 08:04:59,330][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049888] [Batch 00608/03080] [00:07:51/00:31:55, 0.775s/it]: train_loss_raw=0.6125, running_loss=0.5923, LR=0.000100
[2025-08-27 08:05:05,410][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049896] [Batch 00616/03080] [00:07:57/00:31:48, 0.775s/it]: train_loss_raw=0.5700, running_loss=0.5953, LR=0.000100
[2025-08-27 08:05:11,557][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049904] [Batch 00624/03080] [00:08:03/00:31:41, 0.774s/it]: train_loss_raw=0.5427, running_loss=0.5937, LR=0.000100
[2025-08-27 08:05:17,653][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049912] [Batch 00632/03080] [00:08:09/00:31:35, 0.774s/it]: train_loss_raw=0.4928, running_loss=0.5937, LR=0.000100
[2025-08-27 08:05:23,935][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049920] [Batch 00640/03080] [00:08:15/00:31:29, 0.774s/it]: train_loss_raw=0.5478, running_loss=0.5947, LR=0.000100
[2025-08-27 08:05:30,122][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049928] [Batch 00648/03080] [00:08:21/00:31:23, 0.774s/it]: train_loss_raw=0.6743, running_loss=0.5946, LR=0.000100
[2025-08-27 08:05:36,307][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049936] [Batch 00656/03080] [00:08:27/00:31:17, 0.774s/it]: train_loss_raw=0.5884, running_loss=0.5963, LR=0.000100
[2025-08-27 08:05:42,382][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049944] [Batch 00664/03080] [00:08:34/00:31:10, 0.774s/it]: train_loss_raw=0.5819, running_loss=0.5951, LR=0.000100
[2025-08-27 08:05:48,511][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049952] [Batch 00672/03080] [00:08:40/00:31:04, 0.774s/it]: train_loss_raw=0.5064, running_loss=0.5919, LR=0.000100
[2025-08-27 08:05:54,547][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049960] [Batch 00680/03080] [00:08:46/00:30:57, 0.774s/it]: train_loss_raw=0.5959, running_loss=0.5906, LR=0.000100
[2025-08-27 08:06:00,621][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049968] [Batch 00688/03080] [00:08:52/00:30:50, 0.774s/it]: train_loss_raw=0.6763, running_loss=0.5930, LR=0.000100
[2025-08-27 08:06:06,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049976] [Batch 00696/03080] [00:08:58/00:30:44, 0.774s/it]: train_loss_raw=0.5988, running_loss=0.5978, LR=0.000100
[2025-08-27 08:06:12,761][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049984] [Batch 00704/03080] [00:09:04/00:30:37, 0.773s/it]: train_loss_raw=0.5451, running_loss=0.5993, LR=0.000100
[2025-08-27 08:06:18,949][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049992] [Batch 00712/03080] [00:09:10/00:30:31, 0.773s/it]: train_loss_raw=0.6660, running_loss=0.6001, LR=0.000100
[2025-08-27 08:06:25,037][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050000] [Batch 00720/03080] [00:09:16/00:30:24, 0.773s/it]: train_loss_raw=0.6616, running_loss=0.5979, LR=0.000100
[2025-08-27 08:06:34,531][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050008] [Batch 00728/03080] [00:09:26/00:30:29, 0.778s/it]: train_loss_raw=0.5154, running_loss=0.5982, LR=0.000100
[2025-08-27 08:06:40,099][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050016] [Batch 00736/03080] [00:09:31/00:30:21, 0.777s/it]: train_loss_raw=0.6491, running_loss=0.5974, LR=0.000100
[2025-08-27 08:06:46,227][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050024] [Batch 00744/03080] [00:09:37/00:30:14, 0.777s/it]: train_loss_raw=0.5777, running_loss=0.5964, LR=0.000100
[2025-08-27 08:06:52,344][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050032] [Batch 00752/03080] [00:09:44/00:30:08, 0.777s/it]: train_loss_raw=0.7068, running_loss=0.5968, LR=0.000100
[2025-08-27 08:06:58,287][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050040] [Batch 00760/03080] [00:09:49/00:30:00, 0.776s/it]: train_loss_raw=0.5203, running_loss=0.5944, LR=0.000100
[2025-08-27 08:07:04,555][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050048] [Batch 00768/03080] [00:09:56/00:29:54, 0.776s/it]: train_loss_raw=0.5765, running_loss=0.5942, LR=0.000100
[2025-08-27 08:07:10,593][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050056] [Batch 00776/03080] [00:10:02/00:29:48, 0.776s/it]: train_loss_raw=0.5969, running_loss=0.5968, LR=0.000100
[2025-08-27 08:07:16,802][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050064] [Batch 00784/03080] [00:10:08/00:29:41, 0.776s/it]: train_loss_raw=0.5683, running_loss=0.5963, LR=0.000100
[2025-08-27 08:07:22,961][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050072] [Batch 00792/03080] [00:10:14/00:29:35, 0.776s/it]: train_loss_raw=0.5138, running_loss=0.5951, LR=0.000100
[2025-08-27 08:07:29,297][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050080] [Batch 00800/03080] [00:10:20/00:29:29, 0.776s/it]: train_loss_raw=0.5755, running_loss=0.5958, LR=0.000100
[2025-08-27 08:07:35,479][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050088] [Batch 00808/03080] [00:10:27/00:29:23, 0.776s/it]: train_loss_raw=0.5841, running_loss=0.5962, LR=0.000100
[2025-08-27 08:07:41,724][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050096] [Batch 00816/03080] [00:10:33/00:29:17, 0.776s/it]: train_loss_raw=0.5667, running_loss=0.5938, LR=0.000100
[2025-08-27 08:07:47,810][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050104] [Batch 00824/03080] [00:10:39/00:29:10, 0.776s/it]: train_loss_raw=0.5936, running_loss=0.5955, LR=0.000100
[2025-08-27 08:07:54,060][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050112] [Batch 00832/03080] [00:10:45/00:29:04, 0.776s/it]: train_loss_raw=0.5502, running_loss=0.5945, LR=0.000100
[2025-08-27 08:08:00,145][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050120] [Batch 00840/03080] [00:10:51/00:28:58, 0.776s/it]: train_loss_raw=0.6230, running_loss=0.5937, LR=0.000100
[2025-08-27 08:08:06,295][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050128] [Batch 00848/03080] [00:10:57/00:28:51, 0.776s/it]: train_loss_raw=0.6584, running_loss=0.5920, LR=0.000100
[2025-08-27 08:08:12,594][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050136] [Batch 00856/03080] [00:11:04/00:28:45, 0.776s/it]: train_loss_raw=0.6349, running_loss=0.5919, LR=0.000100
[2025-08-27 08:08:18,686][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050144] [Batch 00864/03080] [00:11:10/00:28:39, 0.776s/it]: train_loss_raw=0.5395, running_loss=0.5912, LR=0.000100
[2025-08-27 08:08:24,867][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050152] [Batch 00872/03080] [00:11:16/00:28:33, 0.776s/it]: train_loss_raw=0.6209, running_loss=0.5896, LR=0.000100
[2025-08-27 08:08:31,022][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050160] [Batch 00880/03080] [00:11:22/00:28:26, 0.776s/it]: train_loss_raw=0.6233, running_loss=0.5912, LR=0.000100
[2025-08-27 08:08:37,195][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050168] [Batch 00888/03080] [00:11:28/00:28:20, 0.776s/it]: train_loss_raw=0.5709, running_loss=0.5914, LR=0.000100
[2025-08-27 08:08:43,338][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050176] [Batch 00896/03080] [00:11:35/00:28:14, 0.776s/it]: train_loss_raw=0.5967, running_loss=0.5896, LR=0.000100
[2025-08-27 08:08:49,480][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050184] [Batch 00904/03080] [00:11:41/00:28:07, 0.776s/it]: train_loss_raw=0.6001, running_loss=0.5901, LR=0.000100
[2025-08-27 08:08:55,538][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050192] [Batch 00912/03080] [00:11:47/00:28:01, 0.775s/it]: train_loss_raw=0.6214, running_loss=0.5916, LR=0.000100
[2025-08-27 08:09:01,721][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050200] [Batch 00920/03080] [00:11:53/00:27:54, 0.775s/it]: train_loss_raw=0.5019, running_loss=0.5907, LR=0.000100
[2025-08-27 08:09:07,821][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050208] [Batch 00928/03080] [00:11:59/00:27:48, 0.775s/it]: train_loss_raw=0.6358, running_loss=0.5885, LR=0.000100
[2025-08-27 08:09:13,907][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050216] [Batch 00936/03080] [00:12:05/00:27:42, 0.775s/it]: train_loss_raw=0.6044, running_loss=0.5890, LR=0.000100
[2025-08-27 08:09:20,193][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050224] [Batch 00944/03080] [00:12:11/00:27:36, 0.775s/it]: train_loss_raw=0.5746, running_loss=0.5908, LR=0.000100
[2025-08-27 08:09:26,330][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050232] [Batch 00952/03080] [00:12:18/00:27:29, 0.775s/it]: train_loss_raw=0.5038, running_loss=0.5912, LR=0.000100
[2025-08-27 08:09:32,433][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050240] [Batch 00960/03080] [00:12:24/00:27:23, 0.775s/it]: train_loss_raw=0.6840, running_loss=0.5920, LR=0.000100
[2025-08-27 08:09:38,535][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050248] [Batch 00968/03080] [00:12:30/00:27:16, 0.775s/it]: train_loss_raw=0.6048, running_loss=0.5920, LR=0.000100
[2025-08-27 08:09:44,848][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050256] [Batch 00976/03080] [00:12:36/00:27:10, 0.775s/it]: train_loss_raw=0.5768, running_loss=0.5906, LR=0.000100
[2025-08-27 08:09:50,900][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050264] [Batch 00984/03080] [00:12:42/00:27:04, 0.775s/it]: train_loss_raw=0.5337, running_loss=0.5900, LR=0.000100
[2025-08-27 08:09:56,990][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050272] [Batch 00992/03080] [00:12:48/00:26:57, 0.775s/it]: train_loss_raw=0.4540, running_loss=0.5909, LR=0.000100
[2025-08-27 08:10:03,000][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050280] [Batch 01000/03080] [00:12:54/00:26:51, 0.775s/it]: train_loss_raw=0.5760, running_loss=0.5882, LR=0.000100
[2025-08-27 08:10:09,036][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050288] [Batch 01008/03080] [00:13:00/00:26:44, 0.775s/it]: train_loss_raw=0.5667, running_loss=0.5883, LR=0.000100
[2025-08-27 08:10:15,184][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050296] [Batch 01016/03080] [00:13:06/00:26:38, 0.774s/it]: train_loss_raw=0.4864, running_loss=0.5873, LR=0.000100
[2025-08-27 08:10:21,353][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050304] [Batch 01024/03080] [00:13:13/00:26:32, 0.774s/it]: train_loss_raw=0.5628, running_loss=0.5879, LR=0.000100
[2025-08-27 08:10:27,538][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050312] [Batch 01032/03080] [00:13:19/00:26:26, 0.774s/it]: train_loss_raw=0.5891, running_loss=0.5898, LR=0.000100
[2025-08-27 08:10:33,608][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050320] [Batch 01040/03080] [00:13:25/00:26:19, 0.774s/it]: train_loss_raw=0.5672, running_loss=0.5889, LR=0.000100
[2025-08-27 08:10:39,831][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050328] [Batch 01048/03080] [00:13:31/00:26:13, 0.774s/it]: train_loss_raw=0.5751, running_loss=0.5905, LR=0.000100
[2025-08-27 08:10:46,068][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050336] [Batch 01056/03080] [00:13:37/00:26:07, 0.774s/it]: train_loss_raw=0.5307, running_loss=0.5881, LR=0.000100
[2025-08-27 08:10:52,217][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050344] [Batch 01064/03080] [00:13:43/00:26:01, 0.774s/it]: train_loss_raw=0.6620, running_loss=0.5900, LR=0.000100
[2025-08-27 08:10:58,411][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050352] [Batch 01072/03080] [00:13:50/00:25:54, 0.774s/it]: train_loss_raw=0.5806, running_loss=0.5934, LR=0.000100
[2025-08-27 08:11:04,482][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050360] [Batch 01080/03080] [00:13:56/00:25:48, 0.774s/it]: train_loss_raw=0.4942, running_loss=0.5934, LR=0.000100
[2025-08-27 08:11:10,636][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050368] [Batch 01088/03080] [00:14:02/00:25:42, 0.774s/it]: train_loss_raw=0.4951, running_loss=0.5930, LR=0.000100
[2025-08-27 08:11:16,682][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050376] [Batch 01096/03080] [00:14:08/00:25:35, 0.774s/it]: train_loss_raw=0.5147, running_loss=0.5907, LR=0.000100
[2025-08-27 08:11:22,718][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050384] [Batch 01104/03080] [00:14:14/00:25:29, 0.774s/it]: train_loss_raw=0.6514, running_loss=0.5906, LR=0.000100
[2025-08-27 08:11:28,841][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050392] [Batch 01112/03080] [00:14:20/00:25:22, 0.774s/it]: train_loss_raw=0.5303, running_loss=0.5911, LR=0.000100
[2025-08-27 08:11:35,020][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050400] [Batch 01120/03080] [00:14:26/00:25:16, 0.774s/it]: train_loss_raw=0.5918, running_loss=0.5912, LR=0.000100
[2025-08-27 08:11:41,172][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050408] [Batch 01128/03080] [00:14:32/00:25:10, 0.774s/it]: train_loss_raw=0.4705, running_loss=0.5927, LR=0.000100
[2025-08-27 08:11:47,277][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050416] [Batch 01136/03080] [00:14:38/00:25:04, 0.774s/it]: train_loss_raw=0.5622, running_loss=0.5907, LR=0.000100
[2025-08-27 08:11:53,269][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050424] [Batch 01144/03080] [00:14:44/00:24:57, 0.774s/it]: train_loss_raw=0.5516, running_loss=0.5924, LR=0.000100
[2025-08-27 08:11:59,419][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050432] [Batch 01152/03080] [00:14:51/00:24:51, 0.774s/it]: train_loss_raw=0.5455, running_loss=0.5914, LR=0.000100
[2025-08-27 08:12:05,499][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050440] [Batch 01160/03080] [00:14:57/00:24:44, 0.773s/it]: train_loss_raw=0.6228, running_loss=0.5921, LR=0.000100
[2025-08-27 08:12:11,634][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050448] [Batch 01168/03080] [00:15:03/00:24:38, 0.773s/it]: train_loss_raw=0.6112, running_loss=0.5914, LR=0.000100
[2025-08-27 08:12:17,712][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050456] [Batch 01176/03080] [00:15:09/00:24:32, 0.773s/it]: train_loss_raw=0.4949, running_loss=0.5919, LR=0.000100
[2025-08-27 08:12:23,847][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050464] [Batch 01184/03080] [00:15:15/00:24:26, 0.773s/it]: train_loss_raw=0.4982, running_loss=0.5907, LR=0.000100
[2025-08-27 08:12:30,022][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050472] [Batch 01192/03080] [00:15:21/00:24:19, 0.773s/it]: train_loss_raw=0.6545, running_loss=0.5911, LR=0.000100
[2025-08-27 08:12:35,991][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050480] [Batch 01200/03080] [00:15:27/00:24:13, 0.773s/it]: train_loss_raw=0.5128, running_loss=0.5913, LR=0.000100
[2025-08-27 08:12:41,630][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050488] [Batch 01208/03080] [00:15:33/00:24:06, 0.773s/it]: train_loss_raw=0.5644, running_loss=0.5903, LR=0.000100
[2025-08-27 08:12:47,811][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050496] [Batch 01216/03080] [00:15:39/00:24:00, 0.773s/it]: train_loss_raw=0.5878, running_loss=0.5881, LR=0.000100
[2025-08-27 08:12:53,939][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050504] [Batch 01224/03080] [00:15:45/00:23:53, 0.773s/it]: train_loss_raw=0.5455, running_loss=0.5883, LR=0.000100
[2025-08-27 08:12:59,885][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050512] [Batch 01232/03080] [00:15:51/00:23:47, 0.772s/it]: train_loss_raw=0.5466, running_loss=0.5867, LR=0.000100
[2025-08-27 08:13:06,059][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050520] [Batch 01240/03080] [00:15:57/00:23:41, 0.772s/it]: train_loss_raw=0.5059, running_loss=0.5842, LR=0.000100
[2025-08-27 08:13:12,177][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050528] [Batch 01248/03080] [00:16:03/00:23:34, 0.772s/it]: train_loss_raw=0.5755, running_loss=0.5845, LR=0.000100
[2025-08-27 08:13:18,280][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050536] [Batch 01256/03080] [00:16:09/00:23:28, 0.772s/it]: train_loss_raw=0.5955, running_loss=0.5859, LR=0.000100
[2025-08-27 08:13:24,488][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050544] [Batch 01264/03080] [00:16:16/00:23:22, 0.772s/it]: train_loss_raw=0.6009, running_loss=0.5876, LR=0.000100
[2025-08-27 08:13:30,514][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050552] [Batch 01272/03080] [00:16:22/00:23:16, 0.772s/it]: train_loss_raw=0.5626, running_loss=0.5887, LR=0.000100
[2025-08-27 08:13:36,620][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050560] [Batch 01280/03080] [00:16:28/00:23:09, 0.772s/it]: train_loss_raw=0.5921, running_loss=0.5871, LR=0.000100
[2025-08-27 08:13:42,960][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050568] [Batch 01288/03080] [00:16:34/00:23:03, 0.772s/it]: train_loss_raw=0.6153, running_loss=0.5870, LR=0.000100
[2025-08-27 08:13:49,228][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050576] [Batch 01296/03080] [00:16:40/00:22:57, 0.772s/it]: train_loss_raw=0.6102, running_loss=0.5876, LR=0.000100
[2025-08-27 08:13:55,412][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050584] [Batch 01304/03080] [00:16:47/00:22:51, 0.772s/it]: train_loss_raw=0.5963, running_loss=0.5854, LR=0.000100
[2025-08-27 08:14:01,542][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050592] [Batch 01312/03080] [00:16:53/00:22:45, 0.772s/it]: train_loss_raw=0.5686, running_loss=0.5847, LR=0.000100
[2025-08-27 08:14:07,706][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050600] [Batch 01320/03080] [00:16:59/00:22:39, 0.772s/it]: train_loss_raw=0.5785, running_loss=0.5848, LR=0.000100
[2025-08-27 08:14:13,804][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050608] [Batch 01328/03080] [00:17:05/00:22:32, 0.772s/it]: train_loss_raw=0.6300, running_loss=0.5840, LR=0.000100
[2025-08-27 08:14:19,960][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050616] [Batch 01336/03080] [00:17:11/00:22:26, 0.772s/it]: train_loss_raw=0.5440, running_loss=0.5845, LR=0.000100
[2025-08-27 08:14:26,020][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050624] [Batch 01344/03080] [00:17:17/00:22:20, 0.772s/it]: train_loss_raw=0.5343, running_loss=0.5857, LR=0.000100
[2025-08-27 08:14:32,144][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050632] [Batch 01352/03080] [00:17:23/00:22:14, 0.772s/it]: train_loss_raw=0.4506, running_loss=0.5847, LR=0.000100
[2025-08-27 08:14:38,242][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050640] [Batch 01360/03080] [00:17:29/00:22:07, 0.772s/it]: train_loss_raw=0.5981, running_loss=0.5859, LR=0.000100
[2025-08-27 08:14:44,423][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050648] [Batch 01368/03080] [00:17:36/00:22:01, 0.772s/it]: train_loss_raw=0.5553, running_loss=0.5837, LR=0.000100
[2025-08-27 08:14:50,530][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050656] [Batch 01376/03080] [00:17:42/00:21:55, 0.772s/it]: train_loss_raw=0.4930, running_loss=0.5828, LR=0.000100
[2025-08-27 08:14:56,667][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050664] [Batch 01384/03080] [00:17:48/00:21:49, 0.772s/it]: train_loss_raw=0.5621, running_loss=0.5849, LR=0.000100
[2025-08-27 08:15:02,856][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050672] [Batch 01392/03080] [00:17:54/00:21:43, 0.772s/it]: train_loss_raw=0.5050, running_loss=0.5840, LR=0.000100
[2025-08-27 08:15:08,664][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050680] [Batch 01400/03080] [00:18:00/00:21:36, 0.772s/it]: train_loss_raw=0.6367, running_loss=0.5840, LR=0.000100
[2025-08-27 08:15:14,757][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050688] [Batch 01408/03080] [00:18:06/00:21:30, 0.772s/it]: train_loss_raw=0.5747, running_loss=0.5858, LR=0.000100
[2025-08-27 08:15:20,810][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050696] [Batch 01416/03080] [00:18:12/00:21:23, 0.772s/it]: train_loss_raw=0.6398, running_loss=0.5851, LR=0.000100
[2025-08-27 08:15:26,910][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050704] [Batch 01424/03080] [00:18:18/00:21:17, 0.771s/it]: train_loss_raw=0.6704, running_loss=0.5868, LR=0.000100
[2025-08-27 08:15:33,090][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050712] [Batch 01432/03080] [00:18:24/00:21:11, 0.771s/it]: train_loss_raw=0.5924, running_loss=0.5881, LR=0.000100
[2025-08-27 08:15:39,132][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050720] [Batch 01440/03080] [00:18:30/00:21:05, 0.771s/it]: train_loss_raw=0.5578, running_loss=0.5905, LR=0.000100
[2025-08-27 08:15:45,265][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050728] [Batch 01448/03080] [00:18:36/00:20:58, 0.771s/it]: train_loss_raw=0.5348, running_loss=0.5894, LR=0.000100
[2025-08-27 08:15:51,496][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050736] [Batch 01456/03080] [00:18:43/00:20:52, 0.771s/it]: train_loss_raw=0.5408, running_loss=0.5891, LR=0.000100
[2025-08-27 08:15:57,744][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050744] [Batch 01464/03080] [00:18:49/00:20:46, 0.771s/it]: train_loss_raw=0.6376, running_loss=0.5900, LR=0.000100
[2025-08-27 08:16:03,886][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050752] [Batch 01472/03080] [00:18:55/00:20:40, 0.771s/it]: train_loss_raw=0.5212, running_loss=0.5891, LR=0.000100
[2025-08-27 08:16:10,038][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050760] [Batch 01480/03080] [00:19:01/00:20:34, 0.771s/it]: train_loss_raw=0.5601, running_loss=0.5871, LR=0.000100
[2025-08-27 08:16:16,172][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050768] [Batch 01488/03080] [00:19:07/00:20:28, 0.771s/it]: train_loss_raw=0.5756, running_loss=0.5864, LR=0.000100
[2025-08-27 08:16:22,404][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050776] [Batch 01496/03080] [00:19:14/00:20:21, 0.771s/it]: train_loss_raw=0.5881, running_loss=0.5848, LR=0.000100
[2025-08-27 08:16:28,425][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050784] [Batch 01504/03080] [00:19:20/00:20:15, 0.771s/it]: train_loss_raw=0.5207, running_loss=0.5842, LR=0.000100
[2025-08-27 08:16:34,561][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050792] [Batch 01512/03080] [00:19:26/00:20:09, 0.771s/it]: train_loss_raw=0.5220, running_loss=0.5842, LR=0.000100
[2025-08-27 08:16:40,720][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050800] [Batch 01520/03080] [00:19:32/00:20:03, 0.771s/it]: train_loss_raw=0.6141, running_loss=0.5854, LR=0.000100
[2025-08-27 08:16:46,810][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050808] [Batch 01528/03080] [00:19:38/00:19:57, 0.771s/it]: train_loss_raw=0.5847, running_loss=0.5842, LR=0.000100
[2025-08-27 08:16:52,920][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050816] [Batch 01536/03080] [00:19:44/00:19:50, 0.771s/it]: train_loss_raw=0.6144, running_loss=0.5856, LR=0.000100
[2025-08-27 08:16:59,004][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050824] [Batch 01544/03080] [00:19:50/00:19:44, 0.771s/it]: train_loss_raw=0.5128, running_loss=0.5855, LR=0.000100
[2025-08-27 08:17:05,140][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050832] [Batch 01552/03080] [00:19:56/00:19:38, 0.771s/it]: train_loss_raw=0.6411, running_loss=0.5860, LR=0.000100
[2025-08-27 08:17:11,258][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050840] [Batch 01560/03080] [00:20:02/00:19:32, 0.771s/it]: train_loss_raw=0.5351, running_loss=0.5834, LR=0.000100
[2025-08-27 08:17:17,358][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050848] [Batch 01568/03080] [00:20:09/00:19:25, 0.771s/it]: train_loss_raw=0.6198, running_loss=0.5832, LR=0.000100
[2025-08-27 08:17:23,527][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050856] [Batch 01576/03080] [00:20:15/00:19:19, 0.771s/it]: train_loss_raw=0.6347, running_loss=0.5831, LR=0.000100
[2025-08-27 08:17:29,548][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050864] [Batch 01584/03080] [00:20:21/00:19:13, 0.771s/it]: train_loss_raw=0.5718, running_loss=0.5834, LR=0.000100
[2025-08-27 08:17:35,767][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050872] [Batch 01592/03080] [00:20:27/00:19:07, 0.771s/it]: train_loss_raw=0.6916, running_loss=0.5857, LR=0.000100
[2025-08-27 08:17:41,932][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050880] [Batch 01600/03080] [00:20:33/00:19:01, 0.771s/it]: train_loss_raw=0.6040, running_loss=0.5849, LR=0.000100
[2025-08-27 08:17:48,145][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050888] [Batch 01608/03080] [00:20:39/00:18:54, 0.771s/it]: train_loss_raw=0.5597, running_loss=0.5859, LR=0.000100
[2025-08-27 08:17:54,196][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050896] [Batch 01616/03080] [00:20:45/00:18:48, 0.771s/it]: train_loss_raw=0.5862, running_loss=0.5828, LR=0.000100
[2025-08-27 08:18:00,305][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050904] [Batch 01624/03080] [00:20:51/00:18:42, 0.771s/it]: train_loss_raw=0.5296, running_loss=0.5832, LR=0.000100
[2025-08-27 08:18:06,403][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050912] [Batch 01632/03080] [00:20:58/00:18:36, 0.771s/it]: train_loss_raw=0.6063, running_loss=0.5834, LR=0.000100
[2025-08-27 08:18:12,505][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050920] [Batch 01640/03080] [00:21:04/00:18:30, 0.771s/it]: train_loss_raw=0.6390, running_loss=0.5865, LR=0.000100
[2025-08-27 08:18:18,565][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050928] [Batch 01648/03080] [00:21:10/00:18:23, 0.771s/it]: train_loss_raw=0.5489, running_loss=0.5860, LR=0.000100
[2025-08-27 08:18:24,676][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050936] [Batch 01656/03080] [00:21:16/00:18:17, 0.771s/it]: train_loss_raw=0.5774, running_loss=0.5854, LR=0.000100
[2025-08-27 08:18:30,769][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050944] [Batch 01664/03080] [00:21:22/00:18:11, 0.771s/it]: train_loss_raw=0.4840, running_loss=0.5839, LR=0.000100
[2025-08-27 08:18:36,892][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050952] [Batch 01672/03080] [00:21:28/00:18:05, 0.771s/it]: train_loss_raw=0.6089, running_loss=0.5852, LR=0.000100
[2025-08-27 08:18:42,978][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050960] [Batch 01680/03080] [00:21:34/00:17:58, 0.771s/it]: train_loss_raw=0.5485, running_loss=0.5858, LR=0.000100
[2025-08-27 08:18:49,092][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050968] [Batch 01688/03080] [00:21:40/00:17:52, 0.771s/it]: train_loss_raw=0.6010, running_loss=0.5885, LR=0.000100
[2025-08-27 08:18:55,221][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050976] [Batch 01696/03080] [00:21:46/00:17:46, 0.771s/it]: train_loss_raw=0.5163, running_loss=0.5900, LR=0.000100
[2025-08-27 08:19:01,475][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050984] [Batch 01704/03080] [00:21:53/00:17:40, 0.771s/it]: train_loss_raw=0.5902, running_loss=0.5868, LR=0.000100
[2025-08-27 08:19:07,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050992] [Batch 01712/03080] [00:21:59/00:17:34, 0.771s/it]: train_loss_raw=0.5398, running_loss=0.5860, LR=0.000100
[2025-08-27 08:19:13,748][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051000] [Batch 01720/03080] [00:22:05/00:17:28, 0.771s/it]: train_loss_raw=0.5796, running_loss=0.5853, LR=0.000100
[2025-08-27 08:19:19,981][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051008] [Batch 01728/03080] [00:22:11/00:17:21, 0.771s/it]: train_loss_raw=0.6719, running_loss=0.5855, LR=0.000100
[2025-08-27 08:19:26,077][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051016] [Batch 01736/03080] [00:22:17/00:17:15, 0.771s/it]: train_loss_raw=0.5506, running_loss=0.5855, LR=0.000100
[2025-08-27 08:19:32,162][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051024] [Batch 01744/03080] [00:22:23/00:17:09, 0.771s/it]: train_loss_raw=0.6247, running_loss=0.5863, LR=0.000100
[2025-08-27 08:19:38,289][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051032] [Batch 01752/03080] [00:22:29/00:17:03, 0.771s/it]: train_loss_raw=0.6675, running_loss=0.5842, LR=0.000100
[2025-08-27 08:19:44,406][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051040] [Batch 01760/03080] [00:22:36/00:16:57, 0.771s/it]: train_loss_raw=0.5598, running_loss=0.5829, LR=0.000100
[2025-08-27 08:19:50,477][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051048] [Batch 01768/03080] [00:22:42/00:16:50, 0.770s/it]: train_loss_raw=0.5959, running_loss=0.5812, LR=0.000100
[2025-08-27 08:19:56,590][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051056] [Batch 01776/03080] [00:22:48/00:16:44, 0.770s/it]: train_loss_raw=0.6294, running_loss=0.5834, LR=0.000100
[2025-08-27 08:20:02,755][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051064] [Batch 01784/03080] [00:22:54/00:16:38, 0.770s/it]: train_loss_raw=0.5739, running_loss=0.5828, LR=0.000100
[2025-08-27 08:20:08,871][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051072] [Batch 01792/03080] [00:23:00/00:16:32, 0.770s/it]: train_loss_raw=0.4875, running_loss=0.5841, LR=0.000100
[2025-08-27 08:20:15,017][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051080] [Batch 01800/03080] [00:23:06/00:16:26, 0.770s/it]: train_loss_raw=0.4586, running_loss=0.5826, LR=0.000100
[2025-08-27 08:20:21,111][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051088] [Batch 01808/03080] [00:23:12/00:16:19, 0.770s/it]: train_loss_raw=0.6017, running_loss=0.5829, LR=0.000100
[2025-08-27 08:20:27,372][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051096] [Batch 01816/03080] [00:23:19/00:16:13, 0.770s/it]: train_loss_raw=0.5293, running_loss=0.5814, LR=0.000100
[2025-08-27 08:20:33,303][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051104] [Batch 01824/03080] [00:23:24/00:16:07, 0.770s/it]: train_loss_raw=0.6229, running_loss=0.5823, LR=0.000100
[2025-08-27 08:20:39,447][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051112] [Batch 01832/03080] [00:23:31/00:16:01, 0.770s/it]: train_loss_raw=0.5503, running_loss=0.5808, LR=0.000100
[2025-08-27 08:20:45,483][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051120] [Batch 01840/03080] [00:23:37/00:15:55, 0.770s/it]: train_loss_raw=0.6740, running_loss=0.5804, LR=0.000100
[2025-08-27 08:20:51,312][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051128] [Batch 01848/03080] [00:23:42/00:15:48, 0.770s/it]: train_loss_raw=0.6147, running_loss=0.5806, LR=0.000100
[2025-08-27 08:20:57,395][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051136] [Batch 01856/03080] [00:23:49/00:15:42, 0.770s/it]: train_loss_raw=0.4535, running_loss=0.5808, LR=0.000100
[2025-08-27 08:21:03,488][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051144] [Batch 01864/03080] [00:23:55/00:15:36, 0.770s/it]: train_loss_raw=0.5789, running_loss=0.5782, LR=0.000100
[2025-08-27 08:21:09,371][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051152] [Batch 01872/03080] [00:24:01/00:15:29, 0.770s/it]: train_loss_raw=0.5808, running_loss=0.5774, LR=0.000100
[2025-08-27 08:21:15,518][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051160] [Batch 01880/03080] [00:24:07/00:15:23, 0.770s/it]: train_loss_raw=0.5154, running_loss=0.5776, LR=0.000100
[2025-08-27 08:21:21,800][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051168] [Batch 01888/03080] [00:24:13/00:15:17, 0.770s/it]: train_loss_raw=0.6259, running_loss=0.5784, LR=0.000100
[2025-08-27 08:21:27,811][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051176] [Batch 01896/03080] [00:24:19/00:15:11, 0.770s/it]: train_loss_raw=0.5278, running_loss=0.5769, LR=0.000100
[2025-08-27 08:21:33,911][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051184] [Batch 01904/03080] [00:24:25/00:15:05, 0.770s/it]: train_loss_raw=0.5984, running_loss=0.5769, LR=0.000100
[2025-08-27 08:21:39,746][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051192] [Batch 01912/03080] [00:24:31/00:14:58, 0.770s/it]: train_loss_raw=0.6326, running_loss=0.5784, LR=0.000100
[2025-08-27 08:21:45,746][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051200] [Batch 01920/03080] [00:24:37/00:14:52, 0.769s/it]: train_loss_raw=0.5790, running_loss=0.5790, LR=0.000100
[2025-08-27 08:21:51,891][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051208] [Batch 01928/03080] [00:24:43/00:14:46, 0.769s/it]: train_loss_raw=0.6131, running_loss=0.5800, LR=0.000100
[2025-08-27 08:21:57,904][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051216] [Batch 01936/03080] [00:24:49/00:14:40, 0.769s/it]: train_loss_raw=0.5459, running_loss=0.5795, LR=0.000100
[2025-08-27 08:22:03,832][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051224] [Batch 01944/03080] [00:24:55/00:14:33, 0.769s/it]: train_loss_raw=0.4977, running_loss=0.5803, LR=0.000100
[2025-08-27 08:22:09,682][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051232] [Batch 01952/03080] [00:25:01/00:14:27, 0.769s/it]: train_loss_raw=0.5146, running_loss=0.5775, LR=0.000100
[2025-08-27 08:22:15,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051240] [Batch 01960/03080] [00:25:07/00:14:21, 0.769s/it]: train_loss_raw=0.6031, running_loss=0.5791, LR=0.000100
[2025-08-27 08:22:21,320][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051248] [Batch 01968/03080] [00:25:13/00:14:14, 0.769s/it]: train_loss_raw=0.6207, running_loss=0.5804, LR=0.000100
[2025-08-27 08:22:27,228][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051256] [Batch 01976/03080] [00:25:18/00:14:08, 0.769s/it]: train_loss_raw=0.5514, running_loss=0.5770, LR=0.000100
[2025-08-27 08:22:33,229][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051264] [Batch 01984/03080] [00:25:24/00:14:02, 0.769s/it]: train_loss_raw=0.5039, running_loss=0.5794, LR=0.000100
[2025-08-27 08:22:39,279][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051272] [Batch 01992/03080] [00:25:30/00:13:56, 0.769s/it]: train_loss_raw=0.5788, running_loss=0.5788, LR=0.000100
[2025-08-27 08:22:45,485][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051280] [Batch 02000/03080] [00:25:37/00:13:50, 0.769s/it]: train_loss_raw=0.6360, running_loss=0.5823, LR=0.000100
[2025-08-27 08:22:51,421][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051288] [Batch 02008/03080] [00:25:43/00:13:43, 0.768s/it]: train_loss_raw=0.5833, running_loss=0.5810, LR=0.000100
[2025-08-27 08:22:57,515][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051296] [Batch 02016/03080] [00:25:49/00:13:37, 0.768s/it]: train_loss_raw=0.4991, running_loss=0.5785, LR=0.000100
[2025-08-27 08:23:03,275][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051304] [Batch 02024/03080] [00:25:54/00:13:31, 0.768s/it]: train_loss_raw=0.5586, running_loss=0.5771, LR=0.000100
[2025-08-27 08:23:09,126][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051312] [Batch 02032/03080] [00:26:00/00:13:24, 0.768s/it]: train_loss_raw=0.5851, running_loss=0.5768, LR=0.000100
[2025-08-27 08:23:15,023][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051320] [Batch 02040/03080] [00:26:06/00:13:18, 0.768s/it]: train_loss_raw=0.6377, running_loss=0.5758, LR=0.000100
[2025-08-27 08:23:20,846][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051328] [Batch 02048/03080] [00:26:12/00:13:12, 0.768s/it]: train_loss_raw=0.5416, running_loss=0.5742, LR=0.000100
[2025-08-27 08:23:26,742][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051336] [Batch 02056/03080] [00:26:18/00:13:06, 0.768s/it]: train_loss_raw=0.5410, running_loss=0.5742, LR=0.000100
[2025-08-27 08:23:32,794][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051344] [Batch 02064/03080] [00:26:24/00:12:59, 0.768s/it]: train_loss_raw=0.5792, running_loss=0.5734, LR=0.000100
[2025-08-27 08:23:38,915][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051352] [Batch 02072/03080] [00:26:30/00:12:53, 0.768s/it]: train_loss_raw=0.6093, running_loss=0.5742, LR=0.000100
[2025-08-27 08:23:45,103][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051360] [Batch 02080/03080] [00:26:36/00:12:47, 0.768s/it]: train_loss_raw=0.6297, running_loss=0.5729, LR=0.000100
[2025-08-27 08:23:51,178][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051368] [Batch 02088/03080] [00:26:42/00:12:41, 0.768s/it]: train_loss_raw=0.5554, running_loss=0.5756, LR=0.000100
[2025-08-27 08:23:57,329][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051376] [Batch 02096/03080] [00:26:49/00:12:35, 0.768s/it]: train_loss_raw=0.5514, running_loss=0.5771, LR=0.000100
[2025-08-27 08:24:03,448][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051384] [Batch 02104/03080] [00:26:55/00:12:29, 0.768s/it]: train_loss_raw=0.6303, running_loss=0.5802, LR=0.000100
[2025-08-27 08:24:09,593][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051392] [Batch 02112/03080] [00:27:01/00:12:23, 0.768s/it]: train_loss_raw=0.5648, running_loss=0.5793, LR=0.000100
[2025-08-27 08:24:15,879][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051400] [Batch 02120/03080] [00:27:07/00:12:17, 0.768s/it]: train_loss_raw=0.6634, running_loss=0.5768, LR=0.000100
[2025-08-27 08:24:21,884][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051408] [Batch 02128/03080] [00:27:13/00:12:10, 0.768s/it]: train_loss_raw=0.5622, running_loss=0.5750, LR=0.000100
[2025-08-27 08:24:28,039][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051416] [Batch 02136/03080] [00:27:19/00:12:04, 0.768s/it]: train_loss_raw=0.5422, running_loss=0.5725, LR=0.000100
[2025-08-27 08:24:34,163][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051424] [Batch 02144/03080] [00:27:25/00:11:58, 0.768s/it]: train_loss_raw=0.4721, running_loss=0.5713, LR=0.000100
[2025-08-27 08:24:40,396][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051432] [Batch 02152/03080] [00:27:32/00:11:52, 0.768s/it]: train_loss_raw=0.5759, running_loss=0.5740, LR=0.000100
[2025-08-27 08:24:46,501][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051440] [Batch 02160/03080] [00:27:38/00:11:46, 0.768s/it]: train_loss_raw=0.6771, running_loss=0.5747, LR=0.000100
[2025-08-27 08:24:52,640][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051448] [Batch 02168/03080] [00:27:44/00:11:40, 0.768s/it]: train_loss_raw=0.5485, running_loss=0.5736, LR=0.000100
[2025-08-27 08:24:58,898][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051456] [Batch 02176/03080] [00:27:50/00:11:34, 0.768s/it]: train_loss_raw=0.4767, running_loss=0.5702, LR=0.000100
[2025-08-27 08:25:04,952][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051464] [Batch 02184/03080] [00:27:56/00:11:27, 0.768s/it]: train_loss_raw=0.5570, running_loss=0.5710, LR=0.000100
[2025-08-27 08:25:10,983][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051472] [Batch 02192/03080] [00:28:02/00:11:21, 0.768s/it]: train_loss_raw=0.5692, running_loss=0.5718, LR=0.000100
[2025-08-27 08:25:17,210][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051480] [Batch 02200/03080] [00:28:08/00:11:15, 0.768s/it]: train_loss_raw=0.5227, running_loss=0.5729, LR=0.000100
[2025-08-27 08:25:23,300][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051488] [Batch 02208/03080] [00:28:14/00:11:09, 0.768s/it]: train_loss_raw=0.6132, running_loss=0.5742, LR=0.000100
[2025-08-27 08:25:29,386][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051496] [Batch 02216/03080] [00:28:21/00:11:03, 0.768s/it]: train_loss_raw=0.5151, running_loss=0.5757, LR=0.000100
[2025-08-27 08:25:35,548][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051504] [Batch 02224/03080] [00:28:27/00:10:57, 0.768s/it]: train_loss_raw=0.6294, running_loss=0.5757, LR=0.000100
[2025-08-27 08:25:41,712][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051512] [Batch 02232/03080] [00:28:33/00:10:50, 0.768s/it]: train_loss_raw=0.6769, running_loss=0.5768, LR=0.000100
[2025-08-27 08:25:47,786][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051520] [Batch 02240/03080] [00:28:39/00:10:44, 0.768s/it]: train_loss_raw=0.5798, running_loss=0.5783, LR=0.000100
[2025-08-27 08:25:53,861][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051528] [Batch 02248/03080] [00:28:45/00:10:38, 0.768s/it]: train_loss_raw=0.5770, running_loss=0.5757, LR=0.000100
[2025-08-27 08:26:00,044][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051536] [Batch 02256/03080] [00:28:51/00:10:32, 0.768s/it]: train_loss_raw=0.5519, running_loss=0.5766, LR=0.000100
[2025-08-27 08:26:06,108][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051544] [Batch 02264/03080] [00:28:57/00:10:26, 0.768s/it]: train_loss_raw=0.5421, running_loss=0.5750, LR=0.000100
[2025-08-27 08:26:12,289][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051552] [Batch 02272/03080] [00:29:03/00:10:20, 0.768s/it]: train_loss_raw=0.6306, running_loss=0.5770, LR=0.000100
[2025-08-27 08:26:18,399][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051560] [Batch 02280/03080] [00:29:10/00:10:14, 0.768s/it]: train_loss_raw=0.5301, running_loss=0.5747, LR=0.000100
[2025-08-27 08:26:24,490][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051568] [Batch 02288/03080] [00:29:16/00:10:07, 0.768s/it]: train_loss_raw=0.5697, running_loss=0.5755, LR=0.000100
[2025-08-27 08:26:30,677][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051576] [Batch 02296/03080] [00:29:22/00:10:01, 0.768s/it]: train_loss_raw=0.6612, running_loss=0.5748, LR=0.000100
[2025-08-27 08:26:36,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051584] [Batch 02304/03080] [00:29:28/00:09:55, 0.767s/it]: train_loss_raw=0.5875, running_loss=0.5775, LR=0.000100
[2025-08-27 08:26:42,524][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051592] [Batch 02312/03080] [00:29:34/00:09:49, 0.767s/it]: train_loss_raw=0.5827, running_loss=0.5792, LR=0.000100
[2025-08-27 08:26:48,626][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051600] [Batch 02320/03080] [00:29:40/00:09:43, 0.767s/it]: train_loss_raw=0.5943, running_loss=0.5769, LR=0.000100
[2025-08-27 08:26:54,802][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051608] [Batch 02328/03080] [00:29:46/00:09:37, 0.767s/it]: train_loss_raw=0.6401, running_loss=0.5784, LR=0.000100
[2025-08-27 08:27:00,923][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051616] [Batch 02336/03080] [00:29:52/00:09:30, 0.767s/it]: train_loss_raw=0.5854, running_loss=0.5775, LR=0.000100
[2025-08-27 08:27:07,074][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051624] [Batch 02344/03080] [00:29:58/00:09:24, 0.767s/it]: train_loss_raw=0.5720, running_loss=0.5764, LR=0.000100
[2025-08-27 08:27:13,207][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051632] [Batch 02352/03080] [00:30:04/00:09:18, 0.767s/it]: train_loss_raw=0.6340, running_loss=0.5765, LR=0.000100
[2025-08-27 08:27:19,406][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051640] [Batch 02360/03080] [00:30:11/00:09:12, 0.767s/it]: train_loss_raw=0.5983, running_loss=0.5758, LR=0.000100
[2025-08-27 08:27:25,735][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051648] [Batch 02368/03080] [00:30:17/00:09:06, 0.767s/it]: train_loss_raw=0.5809, running_loss=0.5750, LR=0.000100
[2025-08-27 08:27:31,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051656] [Batch 02376/03080] [00:30:23/00:09:00, 0.767s/it]: train_loss_raw=0.5245, running_loss=0.5744, LR=0.000100
[2025-08-27 08:27:37,950][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051664] [Batch 02384/03080] [00:30:29/00:08:54, 0.767s/it]: train_loss_raw=0.5199, running_loss=0.5748, LR=0.000100
[2025-08-27 08:27:44,076][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051672] [Batch 02392/03080] [00:30:35/00:08:48, 0.767s/it]: train_loss_raw=0.5576, running_loss=0.5746, LR=0.000100
[2025-08-27 08:27:50,123][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051680] [Batch 02400/03080] [00:30:41/00:08:41, 0.767s/it]: train_loss_raw=0.6146, running_loss=0.5738, LR=0.000100
[2025-08-27 08:27:56,135][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051688] [Batch 02408/03080] [00:30:47/00:08:35, 0.767s/it]: train_loss_raw=0.5752, running_loss=0.5743, LR=0.000100
[2025-08-27 08:28:02,281][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051696] [Batch 02416/03080] [00:30:53/00:08:29, 0.767s/it]: train_loss_raw=0.5216, running_loss=0.5750, LR=0.000100
[2025-08-27 08:28:08,444][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051704] [Batch 02424/03080] [00:31:00/00:08:23, 0.767s/it]: train_loss_raw=0.5893, running_loss=0.5732, LR=0.000100
[2025-08-27 08:28:13,950][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051712] [Batch 02432/03080] [00:31:05/00:08:17, 0.767s/it]: train_loss_raw=0.5892, running_loss=0.5721, LR=0.000100
[2025-08-27 08:28:19,938][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051720] [Batch 02440/03080] [00:31:11/00:08:10, 0.767s/it]: train_loss_raw=0.5049, running_loss=0.5734, LR=0.000100
[2025-08-27 08:28:26,042][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051728] [Batch 02448/03080] [00:31:17/00:08:04, 0.767s/it]: train_loss_raw=0.6206, running_loss=0.5750, LR=0.000100
[2025-08-27 08:28:32,351][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051736] [Batch 02456/03080] [00:31:24/00:07:58, 0.767s/it]: train_loss_raw=0.5792, running_loss=0.5735, LR=0.000100
[2025-08-27 08:28:38,508][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051744] [Batch 02464/03080] [00:31:30/00:07:52, 0.767s/it]: train_loss_raw=0.4993, running_loss=0.5719, LR=0.000100
[2025-08-27 08:28:44,796][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051752] [Batch 02472/03080] [00:31:36/00:07:46, 0.767s/it]: train_loss_raw=0.6323, running_loss=0.5728, LR=0.000100
[2025-08-27 08:28:50,940][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051760] [Batch 02480/03080] [00:31:42/00:07:40, 0.767s/it]: train_loss_raw=0.4806, running_loss=0.5715, LR=0.000100
[2025-08-27 08:28:57,024][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051768] [Batch 02488/03080] [00:31:48/00:07:34, 0.767s/it]: train_loss_raw=0.5966, running_loss=0.5701, LR=0.000100
[2025-08-27 08:29:03,074][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051776] [Batch 02496/03080] [00:31:54/00:07:28, 0.767s/it]: train_loss_raw=0.5537, running_loss=0.5718, LR=0.000100
[2025-08-27 08:29:09,123][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051784] [Batch 02504/03080] [00:32:00/00:07:21, 0.767s/it]: train_loss_raw=0.4650, running_loss=0.5692, LR=0.000100
[2025-08-27 08:29:15,211][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051792] [Batch 02512/03080] [00:32:06/00:07:15, 0.767s/it]: train_loss_raw=0.6600, running_loss=0.5703, LR=0.000100
[2025-08-27 08:29:21,304][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051800] [Batch 02520/03080] [00:32:12/00:07:09, 0.767s/it]: train_loss_raw=0.5696, running_loss=0.5693, LR=0.000100
[2025-08-27 08:29:27,444][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051808] [Batch 02528/03080] [00:32:19/00:07:03, 0.767s/it]: train_loss_raw=0.5526, running_loss=0.5669, LR=0.000100
[2025-08-27 08:29:33,499][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051816] [Batch 02536/03080] [00:32:25/00:06:57, 0.767s/it]: train_loss_raw=0.5063, running_loss=0.5660, LR=0.000100
[2025-08-27 08:29:39,658][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051824] [Batch 02544/03080] [00:32:31/00:06:51, 0.767s/it]: train_loss_raw=0.5547, running_loss=0.5652, LR=0.000100
[2025-08-27 08:29:45,524][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051832] [Batch 02552/03080] [00:32:37/00:06:44, 0.767s/it]: train_loss_raw=0.5848, running_loss=0.5654, LR=0.000100
[2025-08-27 08:29:51,545][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051840] [Batch 02560/03080] [00:32:43/00:06:38, 0.767s/it]: train_loss_raw=0.5520, running_loss=0.5633, LR=0.000100
[2025-08-27 08:29:57,399][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051848] [Batch 02568/03080] [00:32:49/00:06:32, 0.767s/it]: train_loss_raw=0.4878, running_loss=0.5633, LR=0.000100
[2025-08-27 08:30:03,412][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051856] [Batch 02576/03080] [00:32:55/00:06:26, 0.767s/it]: train_loss_raw=0.5490, running_loss=0.5641, LR=0.000100
[2025-08-27 08:30:09,528][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051864] [Batch 02584/03080] [00:33:01/00:06:20, 0.767s/it]: train_loss_raw=0.5459, running_loss=0.5644, LR=0.000100
[2025-08-27 08:30:15,242][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051872] [Batch 02592/03080] [00:33:06/00:06:14, 0.767s/it]: train_loss_raw=0.6192, running_loss=0.5659, LR=0.000100
[2025-08-27 08:30:21,148][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051880] [Batch 02600/03080] [00:33:12/00:06:07, 0.766s/it]: train_loss_raw=0.5793, running_loss=0.5678, LR=0.000100
[2025-08-27 08:30:27,271][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051888] [Batch 02608/03080] [00:33:18/00:06:01, 0.766s/it]: train_loss_raw=0.5632, running_loss=0.5708, LR=0.000100
[2025-08-27 08:30:33,407][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051896] [Batch 02616/03080] [00:33:25/00:05:55, 0.766s/it]: train_loss_raw=0.5359, running_loss=0.5689, LR=0.000100
[2025-08-27 08:30:39,395][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051904] [Batch 02624/03080] [00:33:31/00:05:49, 0.766s/it]: train_loss_raw=0.5752, running_loss=0.5666, LR=0.000100
[2025-08-27 08:30:45,545][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051912] [Batch 02632/03080] [00:33:37/00:05:43, 0.766s/it]: train_loss_raw=0.6198, running_loss=0.5662, LR=0.000100
[2025-08-27 08:30:51,801][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051920] [Batch 02640/03080] [00:33:43/00:05:37, 0.766s/it]: train_loss_raw=0.5268, running_loss=0.5641, LR=0.000100
[2025-08-27 08:30:57,941][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051928] [Batch 02648/03080] [00:33:49/00:05:31, 0.766s/it]: train_loss_raw=0.5757, running_loss=0.5658, LR=0.000100
[2025-08-27 08:31:04,079][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051936] [Batch 02656/03080] [00:33:55/00:05:24, 0.766s/it]: train_loss_raw=0.6848, running_loss=0.5662, LR=0.000100
[2025-08-27 08:31:10,206][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051944] [Batch 02664/03080] [00:34:01/00:05:18, 0.766s/it]: train_loss_raw=0.5093, running_loss=0.5679, LR=0.000100
[2025-08-27 08:31:16,472][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051952] [Batch 02672/03080] [00:34:08/00:05:12, 0.767s/it]: train_loss_raw=0.5437, running_loss=0.5667, LR=0.000100
[2025-08-27 08:31:22,617][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051960] [Batch 02680/03080] [00:34:14/00:05:06, 0.767s/it]: train_loss_raw=0.4076, running_loss=0.5643, LR=0.000100
[2025-08-27 08:31:28,765][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051968] [Batch 02688/03080] [00:34:20/00:05:00, 0.767s/it]: train_loss_raw=0.6243, running_loss=0.5646, LR=0.000100
[2025-08-27 08:31:34,482][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051976] [Batch 02696/03080] [00:34:26/00:04:54, 0.766s/it]: train_loss_raw=0.5677, running_loss=0.5681, LR=0.000100
[2025-08-27 08:31:40,014][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051984] [Batch 02704/03080] [00:34:31/00:04:48, 0.766s/it]: train_loss_raw=0.4621, running_loss=0.5660, LR=0.000100
[2025-08-27 08:31:45,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051992] [Batch 02712/03080] [00:34:37/00:04:41, 0.766s/it]: train_loss_raw=0.5514, running_loss=0.5664, LR=0.000100
[2025-08-27 08:31:51,630][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052000] [Batch 02720/03080] [00:34:43/00:04:35, 0.766s/it]: train_loss_raw=0.5075, running_loss=0.5639, LR=0.000100
[2025-08-27 08:32:01,830][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052008] [Batch 02728/03080] [00:34:53/00:04:30, 0.767s/it]: train_loss_raw=0.5098, running_loss=0.5647, LR=0.000100
[2025-08-27 08:32:07,943][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052016] [Batch 02736/03080] [00:34:59/00:04:23, 0.767s/it]: train_loss_raw=0.5222, running_loss=0.5650, LR=0.000100
[2025-08-27 08:32:14,061][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052024] [Batch 02744/03080] [00:35:05/00:04:17, 0.767s/it]: train_loss_raw=0.5985, running_loss=0.5653, LR=0.000100
[2025-08-27 08:32:20,127][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052032] [Batch 02752/03080] [00:35:11/00:04:11, 0.767s/it]: train_loss_raw=0.6447, running_loss=0.5692, LR=0.000100
[2025-08-27 08:32:26,158][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052040] [Batch 02760/03080] [00:35:17/00:04:05, 0.767s/it]: train_loss_raw=0.5546, running_loss=0.5702, LR=0.000100
[2025-08-27 08:32:32,270][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052048] [Batch 02768/03080] [00:35:23/00:03:59, 0.767s/it]: train_loss_raw=0.5728, running_loss=0.5699, LR=0.000100
[2025-08-27 08:32:38,478][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052056] [Batch 02776/03080] [00:35:30/00:03:53, 0.767s/it]: train_loss_raw=0.5580, running_loss=0.5698, LR=0.000100
[2025-08-27 08:32:44,606][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052064] [Batch 02784/03080] [00:35:36/00:03:47, 0.767s/it]: train_loss_raw=0.5528, running_loss=0.5691, LR=0.000100
[2025-08-27 08:32:50,571][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052072] [Batch 02792/03080] [00:35:42/00:03:40, 0.767s/it]: train_loss_raw=0.5557, running_loss=0.5704, LR=0.000100
[2025-08-27 08:32:56,692][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052080] [Batch 02800/03080] [00:35:48/00:03:34, 0.767s/it]: train_loss_raw=0.5127, running_loss=0.5691, LR=0.000100
[2025-08-27 08:33:02,548][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052088] [Batch 02808/03080] [00:35:54/00:03:28, 0.767s/it]: train_loss_raw=0.5786, running_loss=0.5673, LR=0.000100
[2025-08-27 08:33:08,760][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052096] [Batch 02816/03080] [00:36:00/00:03:22, 0.767s/it]: train_loss_raw=0.5719, running_loss=0.5650, LR=0.000100
[2025-08-27 08:33:14,894][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052104] [Batch 02824/03080] [00:36:06/00:03:16, 0.767s/it]: train_loss_raw=0.5957, running_loss=0.5635, LR=0.000100
[2025-08-27 08:33:20,836][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052112] [Batch 02832/03080] [00:36:12/00:03:10, 0.767s/it]: train_loss_raw=0.5591, running_loss=0.5635, LR=0.000100
[2025-08-27 08:33:27,195][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052120] [Batch 02840/03080] [00:36:18/00:03:04, 0.767s/it]: train_loss_raw=0.5807, running_loss=0.5649, LR=0.000100
[2025-08-27 08:33:33,259][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052128] [Batch 02848/03080] [00:36:24/00:02:57, 0.767s/it]: train_loss_raw=0.4689, running_loss=0.5641, LR=0.000100
[2025-08-27 08:33:39,362][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052136] [Batch 02856/03080] [00:36:31/00:02:51, 0.767s/it]: train_loss_raw=0.5093, running_loss=0.5641, LR=0.000100
[2025-08-27 08:33:45,626][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052144] [Batch 02864/03080] [00:36:37/00:02:45, 0.767s/it]: train_loss_raw=0.5211, running_loss=0.5619, LR=0.000100
[2025-08-27 08:33:51,953][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052152] [Batch 02872/03080] [00:36:43/00:02:39, 0.767s/it]: train_loss_raw=0.5668, running_loss=0.5621, LR=0.000100
[2025-08-27 08:33:58,111][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052160] [Batch 02880/03080] [00:36:49/00:02:33, 0.767s/it]: train_loss_raw=0.4407, running_loss=0.5634, LR=0.000100
[2025-08-27 08:34:04,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052168] [Batch 02888/03080] [00:36:55/00:02:27, 0.767s/it]: train_loss_raw=0.5706, running_loss=0.5647, LR=0.000100
[2025-08-27 08:34:10,231][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052176] [Batch 02896/03080] [00:37:01/00:02:21, 0.767s/it]: train_loss_raw=0.5945, running_loss=0.5646, LR=0.000100
[2025-08-27 08:34:16,060][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052184] [Batch 02904/03080] [00:37:07/00:02:15, 0.767s/it]: train_loss_raw=0.5310, running_loss=0.5625, LR=0.000100
[2025-08-27 08:34:21,959][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052192] [Batch 02912/03080] [00:37:13/00:02:08, 0.767s/it]: train_loss_raw=0.6608, running_loss=0.5653, LR=0.000100
[2025-08-27 08:34:27,681][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052200] [Batch 02920/03080] [00:37:19/00:02:02, 0.767s/it]: train_loss_raw=0.6093, running_loss=0.5665, LR=0.000100
[2025-08-27 08:34:33,509][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052208] [Batch 02928/03080] [00:37:25/00:01:56, 0.767s/it]: train_loss_raw=0.5666, running_loss=0.5668, LR=0.000100
[2025-08-27 08:34:39,386][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052216] [Batch 02936/03080] [00:37:31/00:01:50, 0.767s/it]: train_loss_raw=0.5696, running_loss=0.5682, LR=0.000100
[2025-08-27 08:34:45,409][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052224] [Batch 02944/03080] [00:37:37/00:01:44, 0.767s/it]: train_loss_raw=0.5310, running_loss=0.5693, LR=0.000100
[2025-08-27 08:34:51,519][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052232] [Batch 02952/03080] [00:37:43/00:01:38, 0.767s/it]: train_loss_raw=0.5602, running_loss=0.5698, LR=0.000100
[2025-08-27 08:34:57,686][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052240] [Batch 02960/03080] [00:37:49/00:01:32, 0.767s/it]: train_loss_raw=0.6229, running_loss=0.5705, LR=0.000100
[2025-08-27 08:35:03,641][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052248] [Batch 02968/03080] [00:37:55/00:01:25, 0.767s/it]: train_loss_raw=0.5264, running_loss=0.5690, LR=0.000100
[2025-08-27 08:35:09,828][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052256] [Batch 02976/03080] [00:38:01/00:01:19, 0.767s/it]: train_loss_raw=0.5867, running_loss=0.5682, LR=0.000100
[2025-08-27 08:35:15,623][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052264] [Batch 02984/03080] [00:38:07/00:01:13, 0.767s/it]: train_loss_raw=0.4895, running_loss=0.5673, LR=0.000100
[2025-08-27 08:35:21,674][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052272] [Batch 02992/03080] [00:38:13/00:01:07, 0.766s/it]: train_loss_raw=0.5722, running_loss=0.5674, LR=0.000100
[2025-08-27 08:35:27,741][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052280] [Batch 03000/03080] [00:38:19/00:01:01, 0.766s/it]: train_loss_raw=0.5139, running_loss=0.5661, LR=0.000100
[2025-08-27 08:35:33,888][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052288] [Batch 03008/03080] [00:38:25/00:00:55, 0.766s/it]: train_loss_raw=0.5151, running_loss=0.5642, LR=0.000100
[2025-08-27 08:35:39,832][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052296] [Batch 03016/03080] [00:38:31/00:00:49, 0.766s/it]: train_loss_raw=0.5567, running_loss=0.5625, LR=0.000100
[2025-08-27 08:35:45,807][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052304] [Batch 03024/03080] [00:38:37/00:00:42, 0.766s/it]: train_loss_raw=0.6336, running_loss=0.5638, LR=0.000100
[2025-08-27 08:35:51,882][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052312] [Batch 03032/03080] [00:38:43/00:00:36, 0.766s/it]: train_loss_raw=0.5135, running_loss=0.5642, LR=0.000100
[2025-08-27 08:35:57,887][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052320] [Batch 03040/03080] [00:38:49/00:00:30, 0.766s/it]: train_loss_raw=0.4815, running_loss=0.5622, LR=0.000100
[2025-08-27 08:36:03,749][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052328] [Batch 03048/03080] [00:38:55/00:00:24, 0.766s/it]: train_loss_raw=0.6847, running_loss=0.5634, LR=0.000100
[2025-08-27 08:36:09,827][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052336] [Batch 03056/03080] [00:39:01/00:00:18, 0.766s/it]: train_loss_raw=0.5322, running_loss=0.5607, LR=0.000100
[2025-08-27 08:36:15,909][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052344] [Batch 03064/03080] [00:39:07/00:00:12, 0.766s/it]: train_loss_raw=0.5253, running_loss=0.5629, LR=0.000100
[2025-08-27 08:36:21,581][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052352] [Batch 03072/03080] [00:39:13/00:00:06, 0.766s/it]: train_loss_raw=0.5524, running_loss=0.5623, LR=0.000100
[2025-08-27 08:36:27,622][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052360] [Batch 03080/03080] [00:39:19/00:00:00, 0.766s/it]: train_loss_raw=0.5132, running_loss=0.5624, LR=0.000100
[2025-08-27 08:36:28,172][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-27 08:36:39,655][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00007/00310] [00:00:11/00:07:13, 1.435s/it]
[2025-08-27 08:36:50,702][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00015/00310] [00:00:22/00:06:53, 1.408s/it]
[2025-08-27 08:37:02,630][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00023/00310] [00:00:34/00:06:50, 1.436s/it]
[2025-08-27 08:37:15,338][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00031/00310] [00:00:47/00:06:49, 1.474s/it]
[2025-08-27 08:37:27,869][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00039/00310] [00:00:59/00:06:42, 1.492s/it]
[2025-08-27 08:37:39,868][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00047/00310] [00:01:11/00:06:31, 1.494s/it]
[2025-08-27 08:37:52,170][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00055/00310] [00:01:23/00:06:20, 1.500s/it]
[2025-08-27 08:38:04,329][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00063/00310] [00:01:36/00:06:09, 1.502s/it]
[2025-08-27 08:38:16,400][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00071/00310] [00:01:48/00:05:57, 1.503s/it]
[2025-08-27 08:38:28,985][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00079/00310] [00:02:00/00:05:47, 1.510s/it]
[2025-08-27 08:38:41,237][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00087/00310] [00:02:13/00:05:35, 1.512s/it]
[2025-08-27 08:38:53,136][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00095/00310] [00:02:24/00:05:23, 1.510s/it]
[2025-08-27 08:39:05,519][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00103/00310] [00:02:37/00:05:11, 1.513s/it]
[2025-08-27 08:39:18,296][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00111/00310] [00:02:50/00:05:00, 1.519s/it]
[2025-08-27 08:39:30,849][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00119/00310] [00:03:02/00:04:49, 1.522s/it]
[2025-08-27 08:39:43,288][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00127/00310] [00:03:15/00:04:37, 1.524s/it]
[2025-08-27 08:39:55,055][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00135/00310] [00:03:26/00:04:24, 1.521s/it]
[2025-08-27 08:40:06,787][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00143/00310] [00:03:38/00:04:12, 1.518s/it]
[2025-08-27 08:40:16,839][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00151/00310] [00:03:48/00:03:57, 1.504s/it]
[2025-08-27 08:40:27,237][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00159/00310] [00:03:59/00:03:44, 1.494s/it]
[2025-08-27 08:40:39,599][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00167/00310] [00:04:11/00:03:32, 1.497s/it]
[2025-08-27 08:40:50,470][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00175/00310] [00:04:22/00:03:19, 1.490s/it]
[2025-08-27 08:41:02,196][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00183/00310] [00:04:34/00:03:07, 1.489s/it]
[2025-08-27 08:41:13,957][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00191/00310] [00:04:45/00:02:55, 1.488s/it]
[2025-08-27 08:41:25,377][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00199/00310] [00:04:57/00:02:43, 1.486s/it]
[2025-08-27 08:41:36,805][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00207/00310] [00:05:08/00:02:31, 1.484s/it]
[2025-08-27 08:41:48,789][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00215/00310] [00:05:20/00:02:19, 1.484s/it]
[2025-08-27 08:42:01,265][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00223/00310] [00:05:33/00:02:07, 1.487s/it]
[2025-08-27 08:42:12,803][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00231/00310] [00:05:44/00:01:55, 1.485s/it]
[2025-08-27 08:42:24,276][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00239/00310] [00:05:56/00:01:43, 1.484s/it]
[2025-08-27 08:42:35,498][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00247/00310] [00:06:07/00:01:31, 1.481s/it]
[2025-08-27 08:42:47,500][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00255/00310] [00:06:19/00:01:20, 1.482s/it]
[2025-08-27 08:43:00,202][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00263/00310] [00:06:32/00:01:08, 1.485s/it]
[2025-08-27 08:43:12,582][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00271/00310] [00:06:44/00:00:56, 1.487s/it]
[2025-08-27 08:43:24,594][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00279/00310] [00:06:56/00:00:44, 1.487s/it]
[2025-08-27 08:43:36,190][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00287/00310] [00:07:08/00:00:32, 1.486s/it]
[2025-08-27 08:43:46,810][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00295/00310] [00:07:18/00:00:20, 1.482s/it]
[2025-08-27 08:43:59,057][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00303/00310] [00:07:30/00:00:08, 1.483s/it]
[2025-08-27 08:44:07,346][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=0.56237, valid_loss=1.54043
[2025-08-27 08:44:07,347][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-27 08:44:07,347][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.558
[2025-08-27 08:44:07,347][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.097
[2025-08-27 08:44:07,347][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.099
[2025-08-27 08:44:07,347][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.046
[2025-08-27 08:44:07,354][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 13:17:21, remaining time 10:09:44, 00:46:54 per epoch
[2025-08-27 08:44:13,023][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052368] [Batch 00008/03080] [00:00:05/00:34:56, 0.682s/it]: train_loss_raw=0.6109, running_loss=0.6683, LR=0.000100
[2025-08-27 08:44:19,417][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052376] [Batch 00016/03080] [00:00:11/00:37:49, 0.741s/it]: train_loss_raw=0.6423, running_loss=0.6601, LR=0.000100
[2025-08-27 08:44:25,416][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052384] [Batch 00024/03080] [00:00:17/00:37:53, 0.744s/it]: train_loss_raw=0.5988, running_loss=0.6537, LR=0.000100
[2025-08-27 08:44:31,323][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052392] [Batch 00032/03080] [00:00:23/00:37:42, 0.742s/it]: train_loss_raw=0.4908, running_loss=0.6411, LR=0.000100
[2025-08-27 08:44:37,421][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052400] [Batch 00040/03080] [00:00:29/00:37:49, 0.746s/it]: train_loss_raw=0.6034, running_loss=0.6350, LR=0.000100
[2025-08-27 08:44:43,416][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052408] [Batch 00048/03080] [00:00:35/00:37:44, 0.747s/it]: train_loss_raw=0.6516, running_loss=0.6307, LR=0.000100
[2025-08-27 08:44:49,440][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052416] [Batch 00056/03080] [00:00:41/00:37:41, 0.748s/it]: train_loss_raw=0.6569, running_loss=0.6270, LR=0.000100
[2025-08-27 08:44:55,451][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052424] [Batch 00064/03080] [00:00:47/00:37:36, 0.748s/it]: train_loss_raw=0.5661, running_loss=0.6207, LR=0.000100
[2025-08-27 08:45:01,446][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052432] [Batch 00072/03080] [00:00:53/00:37:31, 0.748s/it]: train_loss_raw=0.5218, running_loss=0.6151, LR=0.000100
[2025-08-27 08:45:07,426][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052440] [Batch 00080/03080] [00:00:59/00:37:24, 0.748s/it]: train_loss_raw=0.5781, running_loss=0.6103, LR=0.000100
[2025-08-27 08:45:13,210][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052448] [Batch 00088/03080] [00:01:05/00:37:11, 0.746s/it]: train_loss_raw=0.5263, running_loss=0.6046, LR=0.000100
[2025-08-27 08:45:19,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052456] [Batch 00096/03080] [00:01:11/00:37:13, 0.749s/it]: train_loss_raw=0.6369, running_loss=0.5997, LR=0.000100
[2025-08-27 08:45:25,636][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052464] [Batch 00104/03080] [00:01:18/00:37:14, 0.751s/it]: train_loss_raw=0.5740, running_loss=0.5960, LR=0.000100
[2025-08-27 08:45:31,656][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052472] [Batch 00112/03080] [00:01:24/00:37:08, 0.751s/it]: train_loss_raw=0.5732, running_loss=0.5939, LR=0.000100
[2025-08-27 08:45:37,669][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052480] [Batch 00120/03080] [00:01:30/00:37:02, 0.751s/it]: train_loss_raw=0.5342, running_loss=0.5915, LR=0.000100
[2025-08-27 08:45:43,572][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052488] [Batch 00128/03080] [00:01:36/00:36:54, 0.750s/it]: train_loss_raw=0.5346, running_loss=0.5877, LR=0.000100
[2025-08-27 08:45:49,602][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052496] [Batch 00136/03080] [00:01:42/00:36:48, 0.750s/it]: train_loss_raw=0.5431, running_loss=0.5841, LR=0.000100
[2025-08-27 08:45:55,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052504] [Batch 00144/03080] [00:01:48/00:36:46, 0.752s/it]: train_loss_raw=0.5511, running_loss=0.5811, LR=0.000100
[2025-08-27 08:46:01,944][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052512] [Batch 00152/03080] [00:01:54/00:36:43, 0.752s/it]: train_loss_raw=0.4876, running_loss=0.5778, LR=0.000100
[2025-08-27 08:46:07,912][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052520] [Batch 00160/03080] [00:02:00/00:36:36, 0.752s/it]: train_loss_raw=0.5901, running_loss=0.5798, LR=0.000100
[2025-08-27 08:46:13,898][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052528] [Batch 00168/03080] [00:02:06/00:36:29, 0.752s/it]: train_loss_raw=0.4467, running_loss=0.5771, LR=0.000100
[2025-08-27 08:46:19,858][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052536] [Batch 00176/03080] [00:02:12/00:36:22, 0.752s/it]: train_loss_raw=0.6547, running_loss=0.5784, LR=0.000100
[2025-08-27 08:46:25,838][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052544] [Batch 00184/03080] [00:02:18/00:36:16, 0.751s/it]: train_loss_raw=0.5966, running_loss=0.5773, LR=0.000100
[2025-08-27 08:46:31,681][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052552] [Batch 00192/03080] [00:02:24/00:36:07, 0.751s/it]: train_loss_raw=0.5447, running_loss=0.5750, LR=0.000100
[2025-08-27 08:46:37,384][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052560] [Batch 00200/03080] [00:02:29/00:35:57, 0.749s/it]: train_loss_raw=0.5916, running_loss=0.5738, LR=0.000100
[2025-08-27 08:46:43,175][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052568] [Batch 00208/03080] [00:02:35/00:35:48, 0.748s/it]: train_loss_raw=0.6275, running_loss=0.5721, LR=0.000100
[2025-08-27 08:46:49,188][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052576] [Batch 00216/03080] [00:02:41/00:35:43, 0.748s/it]: train_loss_raw=0.5463, running_loss=0.5708, LR=0.000100
[2025-08-27 08:46:55,270][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052584] [Batch 00224/03080] [00:02:47/00:35:38, 0.749s/it]: train_loss_raw=0.5256, running_loss=0.5696, LR=0.000100
[2025-08-27 08:47:01,462][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052592] [Batch 00232/03080] [00:02:53/00:35:34, 0.750s/it]: train_loss_raw=0.5567, running_loss=0.5707, LR=0.000100
[2025-08-27 08:47:07,441][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052600] [Batch 00240/03080] [00:02:59/00:35:28, 0.749s/it]: train_loss_raw=0.5382, running_loss=0.5711, LR=0.000100
[2025-08-27 08:47:13,682][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052608] [Batch 00248/03080] [00:03:06/00:35:25, 0.750s/it]: train_loss_raw=0.5633, running_loss=0.5699, LR=0.000100
[2025-08-27 08:47:19,691][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052616] [Batch 00256/03080] [00:03:12/00:35:19, 0.750s/it]: train_loss_raw=0.5933, running_loss=0.5689, LR=0.000100
[2025-08-27 08:47:25,691][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052624] [Batch 00264/03080] [00:03:18/00:35:13, 0.750s/it]: train_loss_raw=0.4995, running_loss=0.5704, LR=0.000100
[2025-08-27 08:47:31,690][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052632] [Batch 00272/03080] [00:03:24/00:35:07, 0.750s/it]: train_loss_raw=0.5407, running_loss=0.5703, LR=0.000100
[2025-08-27 08:47:37,712][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052640] [Batch 00280/03080] [00:03:30/00:35:01, 0.751s/it]: train_loss_raw=0.6427, running_loss=0.5685, LR=0.000100
[2025-08-27 08:47:43,706][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052648] [Batch 00288/03080] [00:03:36/00:34:55, 0.750s/it]: train_loss_raw=0.6196, running_loss=0.5674, LR=0.000100
[2025-08-27 08:47:49,916][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052656] [Batch 00296/03080] [00:03:42/00:34:51, 0.751s/it]: train_loss_raw=0.5595, running_loss=0.5657, LR=0.000100
[2025-08-27 08:47:56,020][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052664] [Batch 00304/03080] [00:03:48/00:34:46, 0.751s/it]: train_loss_raw=0.5503, running_loss=0.5656, LR=0.000100
[2025-08-27 08:48:01,816][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052672] [Batch 00312/03080] [00:03:54/00:34:38, 0.751s/it]: train_loss_raw=0.5845, running_loss=0.5656, LR=0.000100
[2025-08-27 08:48:07,659][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052680] [Batch 00320/03080] [00:04:00/00:34:30, 0.750s/it]: train_loss_raw=0.5096, running_loss=0.5651, LR=0.000100
[2025-08-27 08:48:13,468][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052688] [Batch 00328/03080] [00:04:05/00:34:23, 0.750s/it]: train_loss_raw=0.6529, running_loss=0.5651, LR=0.000100
[2025-08-27 08:48:19,455][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052696] [Batch 00336/03080] [00:04:11/00:34:17, 0.750s/it]: train_loss_raw=0.4454, running_loss=0.5631, LR=0.000100
[2025-08-27 08:48:25,420][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052704] [Batch 00344/03080] [00:04:17/00:34:10, 0.750s/it]: train_loss_raw=0.5222, running_loss=0.5631, LR=0.000100
[2025-08-27 08:48:31,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052712] [Batch 00352/03080] [00:04:23/00:34:04, 0.750s/it]: train_loss_raw=0.5518, running_loss=0.5607, LR=0.000100
[2025-08-27 08:48:37,439][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052720] [Batch 00360/03080] [00:04:29/00:33:59, 0.750s/it]: train_loss_raw=0.5611, running_loss=0.5603, LR=0.000100
[2025-08-27 08:48:43,085][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052728] [Batch 00368/03080] [00:04:35/00:33:50, 0.749s/it]: train_loss_raw=0.5908, running_loss=0.5614, LR=0.000100
[2025-08-27 08:48:48,748][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052736] [Batch 00376/03080] [00:04:41/00:33:42, 0.748s/it]: train_loss_raw=0.5835, running_loss=0.5616, LR=0.000100
[2025-08-27 08:48:54,161][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052744] [Batch 00384/03080] [00:04:46/00:33:32, 0.746s/it]: train_loss_raw=0.5694, running_loss=0.5611, LR=0.000100
[2025-08-27 08:48:59,981][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052752] [Batch 00392/03080] [00:04:52/00:33:25, 0.746s/it]: train_loss_raw=0.6203, running_loss=0.5625, LR=0.000100
[2025-08-27 08:49:06,014][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052760] [Batch 00400/03080] [00:04:58/00:33:19, 0.746s/it]: train_loss_raw=0.5182, running_loss=0.5618, LR=0.000100
[2025-08-27 08:49:12,036][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052768] [Batch 00408/03080] [00:05:04/00:33:13, 0.746s/it]: train_loss_raw=0.5534, running_loss=0.5634, LR=0.000100
[2025-08-27 08:49:18,160][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052776] [Batch 00416/03080] [00:05:10/00:33:09, 0.747s/it]: train_loss_raw=0.5897, running_loss=0.5615, LR=0.000100
[2025-08-27 08:49:24,330][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052784] [Batch 00424/03080] [00:05:16/00:33:04, 0.747s/it]: train_loss_raw=0.6010, running_loss=0.5610, LR=0.000100
[2025-08-27 08:49:30,336][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052792] [Batch 00432/03080] [00:05:22/00:32:58, 0.747s/it]: train_loss_raw=0.6020, running_loss=0.5600, LR=0.000100
[2025-08-27 08:49:36,443][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052800] [Batch 00440/03080] [00:05:28/00:32:53, 0.747s/it]: train_loss_raw=0.6246, running_loss=0.5596, LR=0.000100
[2025-08-27 08:49:42,451][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052808] [Batch 00448/03080] [00:05:34/00:32:47, 0.748s/it]: train_loss_raw=0.4700, running_loss=0.5580, LR=0.000100
[2025-08-27 08:49:48,437][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052816] [Batch 00456/03080] [00:05:40/00:32:41, 0.748s/it]: train_loss_raw=0.5182, running_loss=0.5586, LR=0.000100
[2025-08-27 08:49:54,387][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052824] [Batch 00464/03080] [00:05:46/00:32:35, 0.747s/it]: train_loss_raw=0.5943, running_loss=0.5574, LR=0.000100
[2025-08-27 08:50:00,094][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052832] [Batch 00472/03080] [00:05:52/00:32:27, 0.747s/it]: train_loss_raw=0.6701, running_loss=0.5585, LR=0.000100
[2025-08-27 08:50:05,686][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052840] [Batch 00480/03080] [00:05:58/00:32:19, 0.746s/it]: train_loss_raw=0.5332, running_loss=0.5585, LR=0.000100
[2025-08-27 08:50:11,950][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052848] [Batch 00488/03080] [00:06:04/00:32:15, 0.747s/it]: train_loss_raw=0.5897, running_loss=0.5551, LR=0.000100
[2025-08-27 08:50:17,929][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052856] [Batch 00496/03080] [00:06:10/00:32:09, 0.747s/it]: train_loss_raw=0.6355, running_loss=0.5562, LR=0.000100
[2025-08-27 08:50:23,625][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052864] [Batch 00504/03080] [00:06:16/00:32:02, 0.746s/it]: train_loss_raw=0.4974, running_loss=0.5524, LR=0.000100
[2025-08-27 08:50:29,026][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052872] [Batch 00512/03080] [00:06:21/00:31:53, 0.745s/it]: train_loss_raw=0.4914, running_loss=0.5528, LR=0.000100
[2025-08-27 08:50:34,732][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052880] [Batch 00520/03080] [00:06:27/00:31:46, 0.745s/it]: train_loss_raw=0.5673, running_loss=0.5548, LR=0.000100
[2025-08-27 08:50:40,419][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052888] [Batch 00528/03080] [00:06:32/00:31:38, 0.744s/it]: train_loss_raw=0.4563, running_loss=0.5538, LR=0.000100
[2025-08-27 08:50:45,879][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052896] [Batch 00536/03080] [00:06:38/00:31:30, 0.743s/it]: train_loss_raw=0.5555, running_loss=0.5570, LR=0.000100
[2025-08-27 08:50:51,493][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052904] [Batch 00544/03080] [00:06:43/00:31:23, 0.743s/it]: train_loss_raw=0.6251, running_loss=0.5592, LR=0.000100
[2025-08-27 08:50:56,955][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052912] [Batch 00552/03080] [00:06:49/00:31:14, 0.742s/it]: train_loss_raw=0.5033, running_loss=0.5595, LR=0.000100
[2025-08-27 08:51:02,672][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052920] [Batch 00560/03080] [00:06:55/00:31:07, 0.741s/it]: train_loss_raw=0.5121, running_loss=0.5599, LR=0.000100
[2025-08-27 08:51:08,629][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052928] [Batch 00568/03080] [00:07:01/00:31:02, 0.741s/it]: train_loss_raw=0.5082, running_loss=0.5575, LR=0.000100
[2025-08-27 08:51:14,793][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052936] [Batch 00576/03080] [00:07:07/00:30:57, 0.742s/it]: train_loss_raw=0.5043, running_loss=0.5569, LR=0.000100
[2025-08-27 08:51:20,742][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052944] [Batch 00584/03080] [00:07:13/00:30:51, 0.742s/it]: train_loss_raw=0.5521, running_loss=0.5558, LR=0.000100
[2025-08-27 08:51:26,669][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052952] [Batch 00592/03080] [00:07:19/00:30:45, 0.742s/it]: train_loss_raw=0.5780, running_loss=0.5553, LR=0.000100
[2025-08-27 08:51:32,662][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052960] [Batch 00600/03080] [00:07:25/00:30:39, 0.742s/it]: train_loss_raw=0.5642, running_loss=0.5575, LR=0.000100
[2025-08-27 08:51:38,676][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052968] [Batch 00608/03080] [00:07:31/00:30:34, 0.742s/it]: train_loss_raw=0.6386, running_loss=0.5588, LR=0.000100
[2025-08-27 08:51:44,726][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052976] [Batch 00616/03080] [00:07:37/00:30:28, 0.742s/it]: train_loss_raw=0.4950, running_loss=0.5574, LR=0.000100
[2025-08-27 08:51:50,633][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052984] [Batch 00624/03080] [00:07:43/00:30:22, 0.742s/it]: train_loss_raw=0.4967, running_loss=0.5565, LR=0.000100
[2025-08-27 08:51:56,720][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052992] [Batch 00632/03080] [00:07:49/00:30:17, 0.742s/it]: train_loss_raw=0.5150, running_loss=0.5544, LR=0.000100
[2025-08-27 08:52:02,760][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053000] [Batch 00640/03080] [00:07:55/00:30:11, 0.742s/it]: train_loss_raw=0.5155, running_loss=0.5540, LR=0.000100
[2025-08-27 08:52:08,822][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053008] [Batch 00648/03080] [00:08:01/00:30:06, 0.743s/it]: train_loss_raw=0.5971, running_loss=0.5542, LR=0.000100
[2025-08-27 08:52:14,774][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053016] [Batch 00656/03080] [00:08:07/00:30:00, 0.743s/it]: train_loss_raw=0.5653, running_loss=0.5547, LR=0.000100
[2025-08-27 08:52:20,846][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053024] [Batch 00664/03080] [00:08:13/00:29:54, 0.743s/it]: train_loss_raw=0.5420, running_loss=0.5523, LR=0.000100
[2025-08-27 08:52:26,563][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053032] [Batch 00672/03080] [00:08:18/00:29:48, 0.743s/it]: train_loss_raw=0.5030, running_loss=0.5518, LR=0.000100
[2025-08-27 08:52:31,964][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053040] [Batch 00680/03080] [00:08:24/00:29:40, 0.742s/it]: train_loss_raw=0.5504, running_loss=0.5542, LR=0.000100
[2025-08-27 08:52:37,356][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053048] [Batch 00688/03080] [00:08:29/00:29:32, 0.741s/it]: train_loss_raw=0.5791, running_loss=0.5541, LR=0.000100
[2025-08-27 08:52:43,452][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053056] [Batch 00696/03080] [00:08:35/00:29:27, 0.741s/it]: train_loss_raw=0.5366, running_loss=0.5534, LR=0.000100
[2025-08-27 08:52:49,227][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053064] [Batch 00704/03080] [00:08:41/00:29:20, 0.741s/it]: train_loss_raw=0.4823, running_loss=0.5528, LR=0.000100
[2025-08-27 08:52:55,322][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053072] [Batch 00712/03080] [00:08:47/00:29:15, 0.741s/it]: train_loss_raw=0.5669, running_loss=0.5528, LR=0.000100
[2025-08-27 08:53:01,278][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053080] [Batch 00720/03080] [00:08:53/00:29:09, 0.741s/it]: train_loss_raw=0.6026, running_loss=0.5532, LR=0.000100
[2025-08-27 08:53:07,269][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053088] [Batch 00728/03080] [00:08:59/00:29:03, 0.741s/it]: train_loss_raw=0.5275, running_loss=0.5534, LR=0.000100
[2025-08-27 08:53:13,155][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053096] [Batch 00736/03080] [00:09:05/00:28:57, 0.741s/it]: train_loss_raw=0.5589, running_loss=0.5525, LR=0.000100
[2025-08-27 08:53:19,240][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053104] [Batch 00744/03080] [00:09:11/00:28:52, 0.741s/it]: train_loss_raw=0.5656, running_loss=0.5503, LR=0.000100
[2025-08-27 08:53:25,020][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053112] [Batch 00752/03080] [00:09:17/00:28:45, 0.741s/it]: train_loss_raw=0.5421, running_loss=0.5511, LR=0.000100
[2025-08-27 08:53:30,913][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053120] [Batch 00760/03080] [00:09:23/00:28:39, 0.741s/it]: train_loss_raw=0.4699, running_loss=0.5516, LR=0.000100
[2025-08-27 08:53:36,816][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053128] [Batch 00768/03080] [00:09:29/00:28:33, 0.741s/it]: train_loss_raw=0.4915, running_loss=0.5492, LR=0.000100
[2025-08-27 08:53:42,821][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053136] [Batch 00776/03080] [00:09:35/00:28:27, 0.741s/it]: train_loss_raw=0.5145, running_loss=0.5512, LR=0.000100
[2025-08-27 08:53:48,834][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053144] [Batch 00784/03080] [00:09:41/00:28:22, 0.741s/it]: train_loss_raw=0.5691, running_loss=0.5507, LR=0.000100
[2025-08-27 08:53:54,813][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053152] [Batch 00792/03080] [00:09:47/00:28:16, 0.741s/it]: train_loss_raw=0.4923, running_loss=0.5507, LR=0.000100
[2025-08-27 08:54:00,888][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053160] [Batch 00800/03080] [00:09:53/00:28:10, 0.742s/it]: train_loss_raw=0.6682, running_loss=0.5542, LR=0.000100
[2025-08-27 08:54:06,970][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053168] [Batch 00808/03080] [00:09:59/00:28:05, 0.742s/it]: train_loss_raw=0.5227, running_loss=0.5537, LR=0.000100
[2025-08-27 08:54:12,941][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053176] [Batch 00816/03080] [00:10:05/00:27:59, 0.742s/it]: train_loss_raw=0.5738, running_loss=0.5521, LR=0.000100
[2025-08-27 08:54:18,900][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053184] [Batch 00824/03080] [00:10:11/00:27:53, 0.742s/it]: train_loss_raw=0.6058, running_loss=0.5513, LR=0.000100
[2025-08-27 08:54:24,891][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053192] [Batch 00832/03080] [00:10:17/00:27:47, 0.742s/it]: train_loss_raw=0.6816, running_loss=0.5523, LR=0.000100
[2025-08-27 08:54:30,893][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053200] [Batch 00840/03080] [00:10:23/00:27:42, 0.742s/it]: train_loss_raw=0.5711, running_loss=0.5516, LR=0.000100
[2025-08-27 08:54:36,911][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053208] [Batch 00848/03080] [00:10:29/00:27:36, 0.742s/it]: train_loss_raw=0.6695, running_loss=0.5541, LR=0.000100
[2025-08-27 08:54:42,912][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053216] [Batch 00856/03080] [00:10:35/00:27:30, 0.742s/it]: train_loss_raw=0.4659, running_loss=0.5525, LR=0.000100
[2025-08-27 08:54:48,493][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053224] [Batch 00864/03080] [00:10:40/00:27:23, 0.742s/it]: train_loss_raw=0.6381, running_loss=0.5523, LR=0.000100
[2025-08-27 08:54:54,115][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053232] [Batch 00872/03080] [00:10:46/00:27:17, 0.741s/it]: train_loss_raw=0.6038, running_loss=0.5544, LR=0.000100
[2025-08-27 08:55:00,113][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053240] [Batch 00880/03080] [00:10:52/00:27:11, 0.742s/it]: train_loss_raw=0.5470, running_loss=0.5553, LR=0.000100
[2025-08-27 08:55:06,221][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053248] [Batch 00888/03080] [00:10:58/00:27:05, 0.742s/it]: train_loss_raw=0.4722, running_loss=0.5531, LR=0.000100
[2025-08-27 08:55:12,239][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053256] [Batch 00896/03080] [00:11:04/00:27:00, 0.742s/it]: train_loss_raw=0.4239, running_loss=0.5538, LR=0.000100
[2025-08-27 08:55:18,490][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053264] [Batch 00904/03080] [00:11:10/00:26:54, 0.742s/it]: train_loss_raw=0.6063, running_loss=0.5535, LR=0.000100
[2025-08-27 08:55:24,471][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053272] [Batch 00912/03080] [00:11:16/00:26:49, 0.742s/it]: train_loss_raw=0.4829, running_loss=0.5529, LR=0.000100
[2025-08-27 08:55:30,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053280] [Batch 00920/03080] [00:11:22/00:26:43, 0.742s/it]: train_loss_raw=0.5260, running_loss=0.5543, LR=0.000100
[2025-08-27 08:55:36,636][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053288] [Batch 00928/03080] [00:11:29/00:26:37, 0.743s/it]: train_loss_raw=0.4992, running_loss=0.5523, LR=0.000100
[2025-08-27 08:55:42,731][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053296] [Batch 00936/03080] [00:11:35/00:26:32, 0.743s/it]: train_loss_raw=0.5923, running_loss=0.5546, LR=0.000100
[2025-08-27 08:55:48,650][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053304] [Batch 00944/03080] [00:11:41/00:26:26, 0.743s/it]: train_loss_raw=0.5179, running_loss=0.5544, LR=0.000100
[2025-08-27 08:55:54,356][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053312] [Batch 00952/03080] [00:11:46/00:26:19, 0.742s/it]: train_loss_raw=0.5858, running_loss=0.5526, LR=0.000100
[2025-08-27 08:56:00,395][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053320] [Batch 00960/03080] [00:11:52/00:26:14, 0.743s/it]: train_loss_raw=0.5698, running_loss=0.5527, LR=0.000100
[2025-08-27 08:56:06,477][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053328] [Batch 00968/03080] [00:11:58/00:26:08, 0.743s/it]: train_loss_raw=0.5112, running_loss=0.5535, LR=0.000100
[2025-08-27 08:56:12,494][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053336] [Batch 00976/03080] [00:12:04/00:26:02, 0.743s/it]: train_loss_raw=0.5240, running_loss=0.5537, LR=0.000100
[2025-08-27 08:56:18,725][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053344] [Batch 00984/03080] [00:12:11/00:25:57, 0.743s/it]: train_loss_raw=0.6017, running_loss=0.5529, LR=0.000100
[2025-08-27 08:56:24,580][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053352] [Batch 00992/03080] [00:12:17/00:25:51, 0.743s/it]: train_loss_raw=0.4078, running_loss=0.5489, LR=0.000100
[2025-08-27 08:56:30,347][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053360] [Batch 01000/03080] [00:12:22/00:25:44, 0.743s/it]: train_loss_raw=0.6108, running_loss=0.5464, LR=0.000100
[2025-08-27 08:56:36,193][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053368] [Batch 01008/03080] [00:12:28/00:25:38, 0.743s/it]: train_loss_raw=0.5311, running_loss=0.5467, LR=0.000100
[2025-08-27 08:56:41,985][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053376] [Batch 01016/03080] [00:12:34/00:25:32, 0.743s/it]: train_loss_raw=0.5737, running_loss=0.5494, LR=0.000100
[2025-08-27 08:56:47,792][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053384] [Batch 01024/03080] [00:12:40/00:25:26, 0.742s/it]: train_loss_raw=0.5520, running_loss=0.5475, LR=0.000100
[2025-08-27 08:56:53,695][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053392] [Batch 01032/03080] [00:12:46/00:25:20, 0.742s/it]: train_loss_raw=0.6733, running_loss=0.5491, LR=0.000100
[2025-08-27 08:56:59,729][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053400] [Batch 01040/03080] [00:12:52/00:25:14, 0.742s/it]: train_loss_raw=0.6351, running_loss=0.5511, LR=0.000100
[2025-08-27 08:57:05,845][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053408] [Batch 01048/03080] [00:12:58/00:25:09, 0.743s/it]: train_loss_raw=0.4978, running_loss=0.5471, LR=0.000100
[2025-08-27 08:57:11,993][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053416] [Batch 01056/03080] [00:13:04/00:25:03, 0.743s/it]: train_loss_raw=0.5434, running_loss=0.5469, LR=0.000100
[2025-08-27 08:57:18,133][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053424] [Batch 01064/03080] [00:13:10/00:24:57, 0.743s/it]: train_loss_raw=0.5935, running_loss=0.5460, LR=0.000100
[2025-08-27 08:57:24,290][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053432] [Batch 01072/03080] [00:13:16/00:24:52, 0.743s/it]: train_loss_raw=0.6221, running_loss=0.5483, LR=0.000100
[2025-08-27 08:57:30,587][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053440] [Batch 01080/03080] [00:13:23/00:24:47, 0.744s/it]: train_loss_raw=0.5032, running_loss=0.5484, LR=0.000100
[2025-08-27 08:57:36,679][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053448] [Batch 01088/03080] [00:13:29/00:24:41, 0.744s/it]: train_loss_raw=0.7074, running_loss=0.5518, LR=0.000100
[2025-08-27 08:57:42,801][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053456] [Batch 01096/03080] [00:13:35/00:24:35, 0.744s/it]: train_loss_raw=0.5648, running_loss=0.5488, LR=0.000100
[2025-08-27 08:57:48,828][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053464] [Batch 01104/03080] [00:13:41/00:24:29, 0.744s/it]: train_loss_raw=0.5034, running_loss=0.5486, LR=0.000100
[2025-08-27 08:57:54,828][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053472] [Batch 01112/03080] [00:13:47/00:24:24, 0.744s/it]: train_loss_raw=0.4873, running_loss=0.5506, LR=0.000100
[2025-08-27 08:58:00,883][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053480] [Batch 01120/03080] [00:13:53/00:24:18, 0.744s/it]: train_loss_raw=0.5187, running_loss=0.5509, LR=0.000100
[2025-08-27 08:58:06,879][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053488] [Batch 01128/03080] [00:13:59/00:24:12, 0.744s/it]: train_loss_raw=0.4789, running_loss=0.5480, LR=0.000100
[2025-08-27 08:58:12,889][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053496] [Batch 01136/03080] [00:14:05/00:24:06, 0.744s/it]: train_loss_raw=0.5838, running_loss=0.5481, LR=0.000100
[2025-08-27 08:58:18,895][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053504] [Batch 01144/03080] [00:14:11/00:24:00, 0.744s/it]: train_loss_raw=0.4850, running_loss=0.5477, LR=0.000100
[2025-08-27 08:58:24,924][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053512] [Batch 01152/03080] [00:14:17/00:23:54, 0.744s/it]: train_loss_raw=0.5438, running_loss=0.5488, LR=0.000100
[2025-08-27 08:58:30,951][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053520] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=0.6282, running_loss=0.5515, LR=0.000100
[2025-08-27 08:58:36,961][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053528] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=0.6002, running_loss=0.5510, LR=0.000100
[2025-08-27 08:58:43,124][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053536] [Batch 01176/03080] [00:14:35/00:23:37, 0.745s/it]: train_loss_raw=0.5764, running_loss=0.5495, LR=0.000100
[2025-08-27 08:58:49,148][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053544] [Batch 01184/03080] [00:14:41/00:23:31, 0.745s/it]: train_loss_raw=0.5526, running_loss=0.5479, LR=0.000100
[2025-08-27 08:58:55,149][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053552] [Batch 01192/03080] [00:14:47/00:23:25, 0.745s/it]: train_loss_raw=0.5363, running_loss=0.5462, LR=0.000100
[2025-08-27 08:59:01,353][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053560] [Batch 01200/03080] [00:14:53/00:23:20, 0.745s/it]: train_loss_raw=0.6300, running_loss=0.5485, LR=0.000100
[2025-08-27 08:59:07,400][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053568] [Batch 01208/03080] [00:14:59/00:23:14, 0.745s/it]: train_loss_raw=0.5693, running_loss=0.5499, LR=0.000100
[2025-08-27 08:59:13,478][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053576] [Batch 01216/03080] [00:15:05/00:23:08, 0.745s/it]: train_loss_raw=0.6346, running_loss=0.5488, LR=0.000100
[2025-08-27 08:59:19,524][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053584] [Batch 01224/03080] [00:15:11/00:23:02, 0.745s/it]: train_loss_raw=0.5031, running_loss=0.5501, LR=0.000100
[2025-08-27 08:59:25,502][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053592] [Batch 01232/03080] [00:15:17/00:22:56, 0.745s/it]: train_loss_raw=0.4420, running_loss=0.5481, LR=0.000100
[2025-08-27 08:59:31,490][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053600] [Batch 01240/03080] [00:15:23/00:22:50, 0.745s/it]: train_loss_raw=0.6161, running_loss=0.5484, LR=0.000100
[2025-08-27 08:59:37,395][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053608] [Batch 01248/03080] [00:15:29/00:22:44, 0.745s/it]: train_loss_raw=0.5737, running_loss=0.5498, LR=0.000100
[2025-08-27 08:59:43,177][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053616] [Batch 01256/03080] [00:15:35/00:22:38, 0.745s/it]: train_loss_raw=0.5897, running_loss=0.5494, LR=0.000100
[2025-08-27 08:59:49,007][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053624] [Batch 01264/03080] [00:15:41/00:22:32, 0.745s/it]: train_loss_raw=0.5610, running_loss=0.5491, LR=0.000100
[2025-08-27 08:59:54,807][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053632] [Batch 01272/03080] [00:15:47/00:22:26, 0.745s/it]: train_loss_raw=0.5739, running_loss=0.5487, LR=0.000100
[2025-08-27 09:00:00,646][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053640] [Batch 01280/03080] [00:15:53/00:22:20, 0.745s/it]: train_loss_raw=0.6383, running_loss=0.5524, LR=0.000100
[2025-08-27 09:00:06,381][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053648] [Batch 01288/03080] [00:15:58/00:22:14, 0.744s/it]: train_loss_raw=0.5182, running_loss=0.5499, LR=0.000100
[2025-08-27 09:00:12,150][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053656] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=0.5010, running_loss=0.5496, LR=0.000100
[2025-08-27 09:00:18,258][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053664] [Batch 01304/03080] [00:16:10/00:22:02, 0.744s/it]: train_loss_raw=0.3984, running_loss=0.5476, LR=0.000100
[2025-08-27 09:00:24,436][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053672] [Batch 01312/03080] [00:16:16/00:21:56, 0.745s/it]: train_loss_raw=0.5650, running_loss=0.5476, LR=0.000100
[2025-08-27 09:00:30,702][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053680] [Batch 01320/03080] [00:16:23/00:21:50, 0.745s/it]: train_loss_raw=0.6109, running_loss=0.5481, LR=0.000100
[2025-08-27 09:00:36,642][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053688] [Batch 01328/03080] [00:16:29/00:21:44, 0.745s/it]: train_loss_raw=0.5566, running_loss=0.5453, LR=0.000100
[2025-08-27 09:00:42,751][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053696] [Batch 01336/03080] [00:16:35/00:21:39, 0.745s/it]: train_loss_raw=0.4693, running_loss=0.5434, LR=0.000100
[2025-08-27 09:00:49,012][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053704] [Batch 01344/03080] [00:16:41/00:21:33, 0.745s/it]: train_loss_raw=0.6153, running_loss=0.5450, LR=0.000100
[2025-08-27 09:00:55,161][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053712] [Batch 01352/03080] [00:16:47/00:21:27, 0.745s/it]: train_loss_raw=0.5067, running_loss=0.5461, LR=0.000100
[2025-08-27 09:01:01,207][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053720] [Batch 01360/03080] [00:16:53/00:21:21, 0.745s/it]: train_loss_raw=0.5926, running_loss=0.5480, LR=0.000100
[2025-08-27 09:01:07,257][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053728] [Batch 01368/03080] [00:16:59/00:21:16, 0.745s/it]: train_loss_raw=0.5466, running_loss=0.5469, LR=0.000100
[2025-08-27 09:01:13,315][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053736] [Batch 01376/03080] [00:17:05/00:21:10, 0.745s/it]: train_loss_raw=0.5722, running_loss=0.5475, LR=0.000100
[2025-08-27 09:01:19,493][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053744] [Batch 01384/03080] [00:17:11/00:21:04, 0.746s/it]: train_loss_raw=0.5259, running_loss=0.5487, LR=0.000100
[2025-08-27 09:01:25,512][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053752] [Batch 01392/03080] [00:17:17/00:20:58, 0.746s/it]: train_loss_raw=0.4663, running_loss=0.5477, LR=0.000100
[2025-08-27 09:01:31,526][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053760] [Batch 01400/03080] [00:17:23/00:20:52, 0.746s/it]: train_loss_raw=0.6338, running_loss=0.5504, LR=0.000100
[2025-08-27 09:01:37,600][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053768] [Batch 01408/03080] [00:17:30/00:20:46, 0.746s/it]: train_loss_raw=0.5219, running_loss=0.5501, LR=0.000100
[2025-08-27 09:01:43,887][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053776] [Batch 01416/03080] [00:17:36/00:20:41, 0.746s/it]: train_loss_raw=0.5631, running_loss=0.5474, LR=0.000100
[2025-08-27 09:01:50,056][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053784] [Batch 01424/03080] [00:17:42/00:20:35, 0.746s/it]: train_loss_raw=0.5903, running_loss=0.5486, LR=0.000100
[2025-08-27 09:01:56,229][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053792] [Batch 01432/03080] [00:17:48/00:20:29, 0.746s/it]: train_loss_raw=0.5082, running_loss=0.5479, LR=0.000100
[2025-08-27 09:02:02,244][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053800] [Batch 01440/03080] [00:17:54/00:20:23, 0.746s/it]: train_loss_raw=0.5156, running_loss=0.5442, LR=0.000100
[2025-08-27 09:02:08,244][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053808] [Batch 01448/03080] [00:18:00/00:20:18, 0.746s/it]: train_loss_raw=0.5187, running_loss=0.5437, LR=0.000100
[2025-08-27 09:02:14,323][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053816] [Batch 01456/03080] [00:18:06/00:20:12, 0.746s/it]: train_loss_raw=0.5212, running_loss=0.5436, LR=0.000100
[2025-08-27 09:02:20,232][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053824] [Batch 01464/03080] [00:18:12/00:20:06, 0.746s/it]: train_loss_raw=0.5247, running_loss=0.5442, LR=0.000100
[2025-08-27 09:02:26,077][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053832] [Batch 01472/03080] [00:18:18/00:20:00, 0.746s/it]: train_loss_raw=0.5585, running_loss=0.5425, LR=0.000100
[2025-08-27 09:02:32,222][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053840] [Batch 01480/03080] [00:18:24/00:19:54, 0.746s/it]: train_loss_raw=0.5993, running_loss=0.5470, LR=0.000100
[2025-08-27 09:02:38,285][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053848] [Batch 01488/03080] [00:18:30/00:19:48, 0.746s/it]: train_loss_raw=0.5466, running_loss=0.5479, LR=0.000100
[2025-08-27 09:02:44,417][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053856] [Batch 01496/03080] [00:18:36/00:19:42, 0.747s/it]: train_loss_raw=0.5850, running_loss=0.5485, LR=0.000100
[2025-08-27 09:02:50,419][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053864] [Batch 01504/03080] [00:18:42/00:19:36, 0.747s/it]: train_loss_raw=0.5859, running_loss=0.5466, LR=0.000100
[2025-08-27 09:02:56,462][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053872] [Batch 01512/03080] [00:18:48/00:19:30, 0.747s/it]: train_loss_raw=0.4073, running_loss=0.5433, LR=0.000100
[2025-08-27 09:03:02,604][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053880] [Batch 01520/03080] [00:18:55/00:19:24, 0.747s/it]: train_loss_raw=0.5857, running_loss=0.5453, LR=0.000100
[2025-08-27 09:03:08,772][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053888] [Batch 01528/03080] [00:19:01/00:19:19, 0.747s/it]: train_loss_raw=0.5533, running_loss=0.5484, LR=0.000100
[2025-08-27 09:03:14,775][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053896] [Batch 01536/03080] [00:19:07/00:19:13, 0.747s/it]: train_loss_raw=0.5831, running_loss=0.5487, LR=0.000100
[2025-08-27 09:03:20,812][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053904] [Batch 01544/03080] [00:19:13/00:19:07, 0.747s/it]: train_loss_raw=0.6006, running_loss=0.5481, LR=0.000100
[2025-08-27 09:03:26,876][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053912] [Batch 01552/03080] [00:19:19/00:19:01, 0.747s/it]: train_loss_raw=0.6068, running_loss=0.5497, LR=0.000100
[2025-08-27 09:03:32,934][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053920] [Batch 01560/03080] [00:19:25/00:18:55, 0.747s/it]: train_loss_raw=0.5265, running_loss=0.5490, LR=0.000100
[2025-08-27 09:03:39,220][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053928] [Batch 01568/03080] [00:19:31/00:18:49, 0.747s/it]: train_loss_raw=0.6114, running_loss=0.5480, LR=0.000100
[2025-08-27 09:03:45,341][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053936] [Batch 01576/03080] [00:19:37/00:18:43, 0.747s/it]: train_loss_raw=0.5695, running_loss=0.5468, LR=0.000100
[2025-08-27 09:03:51,390][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053944] [Batch 01584/03080] [00:19:43/00:18:38, 0.747s/it]: train_loss_raw=0.5516, running_loss=0.5483, LR=0.000100
[2025-08-27 09:03:57,362][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053952] [Batch 01592/03080] [00:19:49/00:18:32, 0.747s/it]: train_loss_raw=0.5632, running_loss=0.5467, LR=0.000100
[2025-08-27 09:04:03,425][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053960] [Batch 01600/03080] [00:19:55/00:18:26, 0.747s/it]: train_loss_raw=0.5066, running_loss=0.5455, LR=0.000100
[2025-08-27 09:04:09,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053968] [Batch 01608/03080] [00:20:01/00:18:20, 0.747s/it]: train_loss_raw=0.5151, running_loss=0.5456, LR=0.000100
[2025-08-27 09:04:15,541][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053976] [Batch 01616/03080] [00:20:07/00:18:14, 0.748s/it]: train_loss_raw=0.5982, running_loss=0.5475, LR=0.000100
[2025-08-27 09:04:21,668][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053984] [Batch 01624/03080] [00:20:14/00:18:08, 0.748s/it]: train_loss_raw=0.5405, running_loss=0.5459, LR=0.000100
[2025-08-27 09:04:27,639][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053992] [Batch 01632/03080] [00:20:20/00:18:02, 0.748s/it]: train_loss_raw=0.5110, running_loss=0.5460, LR=0.000100
[2025-08-27 09:04:33,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054000] [Batch 01640/03080] [00:20:26/00:17:56, 0.748s/it]: train_loss_raw=0.5577, running_loss=0.5463, LR=0.000100
[2025-08-27 09:04:43,604][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054008] [Batch 01648/03080] [00:20:36/00:17:54, 0.750s/it]: train_loss_raw=0.5991, running_loss=0.5435, LR=0.000100
[2025-08-27 09:04:49,689][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054016] [Batch 01656/03080] [00:20:42/00:17:48, 0.750s/it]: train_loss_raw=0.5630, running_loss=0.5431, LR=0.000100
[2025-08-27 09:04:55,810][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054024] [Batch 01664/03080] [00:20:48/00:17:42, 0.750s/it]: train_loss_raw=0.5072, running_loss=0.5438, LR=0.000100
[2025-08-27 09:05:01,824][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054032] [Batch 01672/03080] [00:20:54/00:17:36, 0.750s/it]: train_loss_raw=0.4683, running_loss=0.5436, LR=0.000100
[2025-08-27 09:05:07,865][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054040] [Batch 01680/03080] [00:21:00/00:17:30, 0.750s/it]: train_loss_raw=0.6391, running_loss=0.5428, LR=0.000100
[2025-08-27 09:05:14,001][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054048] [Batch 01688/03080] [00:21:06/00:17:24, 0.750s/it]: train_loss_raw=0.5541, running_loss=0.5438, LR=0.000100
[2025-08-27 09:05:20,165][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054056] [Batch 01696/03080] [00:21:12/00:17:18, 0.750s/it]: train_loss_raw=0.5153, running_loss=0.5417, LR=0.000100
[2025-08-27 09:05:26,130][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054064] [Batch 01704/03080] [00:21:18/00:17:12, 0.750s/it]: train_loss_raw=0.4723, running_loss=0.5404, LR=0.000100
[2025-08-27 09:05:32,174][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054072] [Batch 01712/03080] [00:21:24/00:17:06, 0.750s/it]: train_loss_raw=0.5500, running_loss=0.5413, LR=0.000100
[2025-08-27 09:05:38,181][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054080] [Batch 01720/03080] [00:21:30/00:17:00, 0.750s/it]: train_loss_raw=0.5021, running_loss=0.5392, LR=0.000100
[2025-08-27 09:05:44,336][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054088] [Batch 01728/03080] [00:21:36/00:16:54, 0.750s/it]: train_loss_raw=0.5201, running_loss=0.5361, LR=0.000100
[2025-08-27 09:05:50,357][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054096] [Batch 01736/03080] [00:21:42/00:16:48, 0.750s/it]: train_loss_raw=0.5766, running_loss=0.5370, LR=0.000100
[2025-08-27 09:05:56,376][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054104] [Batch 01744/03080] [00:21:48/00:16:42, 0.750s/it]: train_loss_raw=0.5939, running_loss=0.5382, LR=0.000100
[2025-08-27 09:06:02,446][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054112] [Batch 01752/03080] [00:21:54/00:16:36, 0.751s/it]: train_loss_raw=0.5467, running_loss=0.5398, LR=0.000100
[2025-08-27 09:06:08,454][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054120] [Batch 01760/03080] [00:22:00/00:16:30, 0.751s/it]: train_loss_raw=0.5535, running_loss=0.5394, LR=0.000100
[2025-08-27 09:06:14,448][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054128] [Batch 01768/03080] [00:22:06/00:16:24, 0.750s/it]: train_loss_raw=0.6240, running_loss=0.5416, LR=0.000100
[2025-08-27 09:06:20,436][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054136] [Batch 01776/03080] [00:22:12/00:16:18, 0.750s/it]: train_loss_raw=0.4306, running_loss=0.5398, LR=0.000100
[2025-08-27 09:06:26,434][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054144] [Batch 01784/03080] [00:22:18/00:16:12, 0.750s/it]: train_loss_raw=0.5746, running_loss=0.5383, LR=0.000100
[2025-08-27 09:06:32,344][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054152] [Batch 01792/03080] [00:22:24/00:16:06, 0.750s/it]: train_loss_raw=0.4976, running_loss=0.5368, LR=0.000100
[2025-08-27 09:06:38,081][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054160] [Batch 01800/03080] [00:22:30/00:16:00, 0.750s/it]: train_loss_raw=0.5562, running_loss=0.5387, LR=0.000100
[2025-08-27 09:06:44,149][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054168] [Batch 01808/03080] [00:22:36/00:15:54, 0.750s/it]: train_loss_raw=0.4442, running_loss=0.5362, LR=0.000100
[2025-08-27 09:06:50,189][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054176] [Batch 01816/03080] [00:22:42/00:15:48, 0.750s/it]: train_loss_raw=0.5352, running_loss=0.5402, LR=0.000100
[2025-08-27 09:06:56,229][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054184] [Batch 01824/03080] [00:22:48/00:15:42, 0.750s/it]: train_loss_raw=0.5157, running_loss=0.5407, LR=0.000100
[2025-08-27 09:07:02,254][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054192] [Batch 01832/03080] [00:22:54/00:15:36, 0.750s/it]: train_loss_raw=0.5098, running_loss=0.5395, LR=0.000100
[2025-08-27 09:07:08,268][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054200] [Batch 01840/03080] [00:23:00/00:15:30, 0.750s/it]: train_loss_raw=0.5587, running_loss=0.5426, LR=0.000100
[2025-08-27 09:07:14,395][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054208] [Batch 01848/03080] [00:23:06/00:15:24, 0.750s/it]: train_loss_raw=0.5592, running_loss=0.5396, LR=0.000100
[2025-08-27 09:07:20,371][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054216] [Batch 01856/03080] [00:23:12/00:15:18, 0.750s/it]: train_loss_raw=0.5736, running_loss=0.5409, LR=0.000100
[2025-08-27 09:07:26,330][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054224] [Batch 01864/03080] [00:23:18/00:15:12, 0.750s/it]: train_loss_raw=0.5256, running_loss=0.5416, LR=0.000100
[2025-08-27 09:07:32,315][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054232] [Batch 01872/03080] [00:23:24/00:15:06, 0.750s/it]: train_loss_raw=0.5782, running_loss=0.5408, LR=0.000100
[2025-08-27 09:07:38,306][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054240] [Batch 01880/03080] [00:23:30/00:15:00, 0.750s/it]: train_loss_raw=0.6384, running_loss=0.5403, LR=0.000100
[2025-08-27 09:07:44,332][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054248] [Batch 01888/03080] [00:23:36/00:14:54, 0.750s/it]: train_loss_raw=0.6121, running_loss=0.5402, LR=0.000100
[2025-08-27 09:07:50,462][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054256] [Batch 01896/03080] [00:23:42/00:14:48, 0.750s/it]: train_loss_raw=0.5666, running_loss=0.5408, LR=0.000100
[2025-08-27 09:07:56,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054264] [Batch 01904/03080] [00:23:48/00:14:42, 0.751s/it]: train_loss_raw=0.5533, running_loss=0.5420, LR=0.000100
[2025-08-27 09:08:02,942][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054272] [Batch 01912/03080] [00:23:55/00:14:36, 0.751s/it]: train_loss_raw=0.5288, running_loss=0.5393, LR=0.000100
[2025-08-27 09:08:09,183][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054280] [Batch 01920/03080] [00:24:01/00:14:30, 0.751s/it]: train_loss_raw=0.5129, running_loss=0.5406, LR=0.000100
[2025-08-27 09:08:15,257][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054288] [Batch 01928/03080] [00:24:07/00:14:25, 0.751s/it]: train_loss_raw=0.5863, running_loss=0.5411, LR=0.000100
[2025-08-27 09:08:21,323][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054296] [Batch 01936/03080] [00:24:13/00:14:19, 0.751s/it]: train_loss_raw=0.5982, running_loss=0.5419, LR=0.000100
[2025-08-27 09:08:27,534][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054304] [Batch 01944/03080] [00:24:19/00:14:13, 0.751s/it]: train_loss_raw=0.4706, running_loss=0.5428, LR=0.000100
[2025-08-27 09:08:33,599][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054312] [Batch 01952/03080] [00:24:26/00:14:07, 0.751s/it]: train_loss_raw=0.5246, running_loss=0.5403, LR=0.000100
[2025-08-27 09:08:39,634][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054320] [Batch 01960/03080] [00:24:32/00:14:01, 0.751s/it]: train_loss_raw=0.5330, running_loss=0.5393, LR=0.000100
[2025-08-27 09:08:45,711][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054328] [Batch 01968/03080] [00:24:38/00:13:55, 0.751s/it]: train_loss_raw=0.3864, running_loss=0.5374, LR=0.000100
[2025-08-27 09:08:51,969][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054336] [Batch 01976/03080] [00:24:44/00:13:49, 0.751s/it]: train_loss_raw=0.5859, running_loss=0.5379, LR=0.000100
[2025-08-27 09:08:58,017][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054344] [Batch 01984/03080] [00:24:50/00:13:43, 0.751s/it]: train_loss_raw=0.7010, running_loss=0.5406, LR=0.000100
[2025-08-27 09:09:04,232][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054352] [Batch 01992/03080] [00:24:56/00:13:37, 0.751s/it]: train_loss_raw=0.4999, running_loss=0.5399, LR=0.000100
[2025-08-27 09:09:10,282][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054360] [Batch 02000/03080] [00:25:02/00:13:31, 0.751s/it]: train_loss_raw=0.4831, running_loss=0.5401, LR=0.000100
[2025-08-27 09:09:16,311][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054368] [Batch 02008/03080] [00:25:08/00:13:25, 0.751s/it]: train_loss_raw=0.5443, running_loss=0.5412, LR=0.000100
[2025-08-27 09:09:22,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054376] [Batch 02016/03080] [00:25:14/00:13:19, 0.751s/it]: train_loss_raw=0.5510, running_loss=0.5415, LR=0.000100
[2025-08-27 09:09:28,533][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054384] [Batch 02024/03080] [00:25:20/00:13:13, 0.751s/it]: train_loss_raw=0.5305, running_loss=0.5393, LR=0.000100
[2025-08-27 09:09:34,598][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054392] [Batch 02032/03080] [00:25:27/00:13:07, 0.751s/it]: train_loss_raw=0.5896, running_loss=0.5380, LR=0.000100
[2025-08-27 09:09:40,754][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054400] [Batch 02040/03080] [00:25:33/00:13:01, 0.752s/it]: train_loss_raw=0.5704, running_loss=0.5371, LR=0.000100
[2025-08-27 09:09:46,787][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054408] [Batch 02048/03080] [00:25:39/00:12:55, 0.752s/it]: train_loss_raw=0.5321, running_loss=0.5387, LR=0.000100
[2025-08-27 09:09:52,891][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054416] [Batch 02056/03080] [00:25:45/00:12:49, 0.752s/it]: train_loss_raw=0.5668, running_loss=0.5378, LR=0.000100
[2025-08-27 09:09:59,050][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054424] [Batch 02064/03080] [00:25:51/00:12:43, 0.752s/it]: train_loss_raw=0.4179, running_loss=0.5358, LR=0.000100
[2025-08-27 09:10:05,355][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054432] [Batch 02072/03080] [00:25:57/00:12:37, 0.752s/it]: train_loss_raw=0.5216, running_loss=0.5363, LR=0.000100
[2025-08-27 09:10:11,476][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054440] [Batch 02080/03080] [00:26:03/00:12:31, 0.752s/it]: train_loss_raw=0.6048, running_loss=0.5379, LR=0.000100
[2025-08-27 09:10:17,397][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054448] [Batch 02088/03080] [00:26:09/00:12:25, 0.752s/it]: train_loss_raw=0.5762, running_loss=0.5389, LR=0.000100
[2025-08-27 09:10:23,412][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054456] [Batch 02096/03080] [00:26:15/00:12:19, 0.752s/it]: train_loss_raw=0.5836, running_loss=0.5399, LR=0.000100
[2025-08-27 09:10:29,419][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054464] [Batch 02104/03080] [00:26:21/00:12:13, 0.752s/it]: train_loss_raw=0.5145, running_loss=0.5396, LR=0.000100
[2025-08-27 09:10:35,496][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054472] [Batch 02112/03080] [00:26:27/00:12:07, 0.752s/it]: train_loss_raw=0.4898, running_loss=0.5381, LR=0.000100
[2025-08-27 09:10:41,656][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054480] [Batch 02120/03080] [00:26:34/00:12:01, 0.752s/it]: train_loss_raw=0.5095, running_loss=0.5374, LR=0.000100
[2025-08-27 09:10:47,657][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054488] [Batch 02128/03080] [00:26:40/00:11:55, 0.752s/it]: train_loss_raw=0.5977, running_loss=0.5402, LR=0.000100
[2025-08-27 09:10:53,772][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054496] [Batch 02136/03080] [00:26:46/00:11:49, 0.752s/it]: train_loss_raw=0.4471, running_loss=0.5388, LR=0.000100
[2025-08-27 09:10:59,799][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054504] [Batch 02144/03080] [00:26:52/00:11:43, 0.752s/it]: train_loss_raw=0.6373, running_loss=0.5383, LR=0.000100
[2025-08-27 09:11:05,875][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054512] [Batch 02152/03080] [00:26:58/00:11:37, 0.752s/it]: train_loss_raw=0.5408, running_loss=0.5389, LR=0.000100
[2025-08-27 09:11:11,966][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054520] [Batch 02160/03080] [00:27:04/00:11:31, 0.752s/it]: train_loss_raw=0.5109, running_loss=0.5377, LR=0.000100
[2025-08-27 09:11:17,985][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054528] [Batch 02168/03080] [00:27:10/00:11:25, 0.752s/it]: train_loss_raw=0.4367, running_loss=0.5382, LR=0.000100
[2025-08-27 09:11:24,049][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054536] [Batch 02176/03080] [00:27:16/00:11:19, 0.752s/it]: train_loss_raw=0.5957, running_loss=0.5399, LR=0.000100
[2025-08-27 09:11:30,161][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054544] [Batch 02184/03080] [00:27:22/00:11:13, 0.752s/it]: train_loss_raw=0.4855, running_loss=0.5389, LR=0.000100
[2025-08-27 09:11:36,285][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054552] [Batch 02192/03080] [00:27:28/00:11:07, 0.752s/it]: train_loss_raw=0.6388, running_loss=0.5380, LR=0.000100
[2025-08-27 09:11:42,335][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054560] [Batch 02200/03080] [00:27:34/00:11:01, 0.752s/it]: train_loss_raw=0.5381, running_loss=0.5381, LR=0.000100
[2025-08-27 09:11:48,430][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054568] [Batch 02208/03080] [00:27:40/00:10:55, 0.752s/it]: train_loss_raw=0.4824, running_loss=0.5365, LR=0.000100
[2025-08-27 09:11:54,541][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054576] [Batch 02216/03080] [00:27:46/00:10:49, 0.752s/it]: train_loss_raw=0.4915, running_loss=0.5366, LR=0.000100
[2025-08-27 09:12:00,584][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054584] [Batch 02224/03080] [00:27:53/00:10:43, 0.752s/it]: train_loss_raw=0.5001, running_loss=0.5348, LR=0.000100
[2025-08-27 09:12:06,803][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054592] [Batch 02232/03080] [00:27:59/00:10:37, 0.752s/it]: train_loss_raw=0.5028, running_loss=0.5328, LR=0.000100
[2025-08-27 09:12:12,908][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054600] [Batch 02240/03080] [00:28:05/00:10:32, 0.752s/it]: train_loss_raw=0.6118, running_loss=0.5317, LR=0.000100
[2025-08-27 09:12:19,114][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054608] [Batch 02248/03080] [00:28:11/00:10:26, 0.752s/it]: train_loss_raw=0.4881, running_loss=0.5335, LR=0.000100
[2025-08-27 09:12:25,107][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054616] [Batch 02256/03080] [00:28:17/00:10:20, 0.752s/it]: train_loss_raw=0.5370, running_loss=0.5321, LR=0.000100
[2025-08-27 09:12:31,276][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054624] [Batch 02264/03080] [00:28:23/00:10:14, 0.753s/it]: train_loss_raw=0.6342, running_loss=0.5335, LR=0.000100
[2025-08-27 09:12:37,367][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054632] [Batch 02272/03080] [00:28:29/00:10:08, 0.753s/it]: train_loss_raw=0.5585, running_loss=0.5355, LR=0.000100
[2025-08-27 09:12:43,486][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054640] [Batch 02280/03080] [00:28:35/00:10:02, 0.753s/it]: train_loss_raw=0.4739, running_loss=0.5339, LR=0.000100
[2025-08-27 09:12:49,552][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054648] [Batch 02288/03080] [00:28:41/00:09:56, 0.753s/it]: train_loss_raw=0.5317, running_loss=0.5359, LR=0.000100
[2025-08-27 09:12:55,387][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054656] [Batch 02296/03080] [00:28:47/00:09:49, 0.753s/it]: train_loss_raw=0.5258, running_loss=0.5325, LR=0.000100
[2025-08-27 09:13:00,881][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054664] [Batch 02304/03080] [00:28:53/00:09:43, 0.752s/it]: train_loss_raw=0.5800, running_loss=0.5346, LR=0.000100
[2025-08-27 09:13:06,874][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054672] [Batch 02312/03080] [00:28:59/00:09:37, 0.752s/it]: train_loss_raw=0.6337, running_loss=0.5346, LR=0.000100
[2025-08-27 09:13:12,955][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054680] [Batch 02320/03080] [00:29:05/00:09:31, 0.752s/it]: train_loss_raw=0.6011, running_loss=0.5372, LR=0.000100
[2025-08-27 09:13:19,180][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054688] [Batch 02328/03080] [00:29:11/00:09:25, 0.752s/it]: train_loss_raw=0.4900, running_loss=0.5352, LR=0.000100
[2025-08-27 09:13:25,294][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054696] [Batch 02336/03080] [00:29:17/00:09:19, 0.752s/it]: train_loss_raw=0.5311, running_loss=0.5363, LR=0.000100
[2025-08-27 09:13:31,280][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054704] [Batch 02344/03080] [00:29:23/00:09:13, 0.752s/it]: train_loss_raw=0.4931, running_loss=0.5372, LR=0.000100
[2025-08-27 09:13:37,496][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054712] [Batch 02352/03080] [00:29:29/00:09:07, 0.753s/it]: train_loss_raw=0.5659, running_loss=0.5365, LR=0.000100
[2025-08-27 09:13:43,239][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054720] [Batch 02360/03080] [00:29:35/00:09:01, 0.752s/it]: train_loss_raw=0.5345, running_loss=0.5375, LR=0.000100
[2025-08-27 09:13:49,298][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054728] [Batch 02368/03080] [00:29:41/00:08:55, 0.752s/it]: train_loss_raw=0.4845, running_loss=0.5379, LR=0.000100
[2025-08-27 09:13:55,273][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054736] [Batch 02376/03080] [00:29:47/00:08:49, 0.752s/it]: train_loss_raw=0.5439, running_loss=0.5384, LR=0.000100
[2025-08-27 09:14:01,384][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054744] [Batch 02384/03080] [00:29:53/00:08:43, 0.752s/it]: train_loss_raw=0.5462, running_loss=0.5380, LR=0.000100
[2025-08-27 09:14:07,394][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054752] [Batch 02392/03080] [00:29:59/00:08:37, 0.752s/it]: train_loss_raw=0.5701, running_loss=0.5360, LR=0.000100
[2025-08-27 09:14:13,484][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054760] [Batch 02400/03080] [00:30:05/00:08:31, 0.752s/it]: train_loss_raw=0.5096, running_loss=0.5349, LR=0.000100
[2025-08-27 09:14:19,485][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054768] [Batch 02408/03080] [00:30:11/00:08:25, 0.752s/it]: train_loss_raw=0.5493, running_loss=0.5351, LR=0.000100
[2025-08-27 09:14:25,585][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054776] [Batch 02416/03080] [00:30:18/00:08:19, 0.752s/it]: train_loss_raw=0.5390, running_loss=0.5327, LR=0.000100
[2025-08-27 09:14:31,865][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054784] [Batch 02424/03080] [00:30:24/00:08:13, 0.753s/it]: train_loss_raw=0.3772, running_loss=0.5302, LR=0.000100
[2025-08-27 09:14:37,877][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054792] [Batch 02432/03080] [00:30:30/00:08:07, 0.753s/it]: train_loss_raw=0.4960, running_loss=0.5288, LR=0.000100
[2025-08-27 09:14:43,861][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054800] [Batch 02440/03080] [00:30:36/00:08:01, 0.753s/it]: train_loss_raw=0.6114, running_loss=0.5294, LR=0.000100
[2025-08-27 09:14:49,880][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054808] [Batch 02448/03080] [00:30:42/00:07:55, 0.753s/it]: train_loss_raw=0.4484, running_loss=0.5313, LR=0.000100
[2025-08-27 09:14:55,916][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054816] [Batch 02456/03080] [00:30:48/00:07:49, 0.753s/it]: train_loss_raw=0.4908, running_loss=0.5315, LR=0.000100
[2025-08-27 09:15:01,957][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054824] [Batch 02464/03080] [00:30:54/00:07:43, 0.753s/it]: train_loss_raw=0.4757, running_loss=0.5293, LR=0.000100
[2025-08-27 09:15:08,005][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054832] [Batch 02472/03080] [00:31:00/00:07:37, 0.753s/it]: train_loss_raw=0.5401, running_loss=0.5278, LR=0.000100
[2025-08-27 09:15:14,034][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054840] [Batch 02480/03080] [00:31:06/00:07:31, 0.753s/it]: train_loss_raw=0.5889, running_loss=0.5280, LR=0.000100
[2025-08-27 09:15:20,044][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054848] [Batch 02488/03080] [00:31:12/00:07:25, 0.753s/it]: train_loss_raw=0.4903, running_loss=0.5297, LR=0.000100
[2025-08-27 09:15:26,050][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054856] [Batch 02496/03080] [00:31:18/00:07:19, 0.753s/it]: train_loss_raw=0.5166, running_loss=0.5303, LR=0.000100
[2025-08-27 09:15:32,089][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054864] [Batch 02504/03080] [00:31:24/00:07:13, 0.753s/it]: train_loss_raw=0.4526, running_loss=0.5304, LR=0.000100
[2025-08-27 09:15:38,188][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054872] [Batch 02512/03080] [00:31:30/00:07:07, 0.753s/it]: train_loss_raw=0.5425, running_loss=0.5333, LR=0.000100
[2025-08-27 09:15:44,295][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054880] [Batch 02520/03080] [00:31:36/00:07:01, 0.753s/it]: train_loss_raw=0.4860, running_loss=0.5324, LR=0.000100
[2025-08-27 09:15:50,392][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054888] [Batch 02528/03080] [00:31:42/00:06:55, 0.753s/it]: train_loss_raw=0.5036, running_loss=0.5316, LR=0.000100
[2025-08-27 09:15:56,266][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054896] [Batch 02536/03080] [00:31:48/00:06:49, 0.753s/it]: train_loss_raw=0.4921, running_loss=0.5306, LR=0.000100
[2025-08-27 09:16:02,276][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054904] [Batch 02544/03080] [00:31:54/00:06:43, 0.753s/it]: train_loss_raw=0.5734, running_loss=0.5314, LR=0.000100
[2025-08-27 09:16:08,324][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054912] [Batch 02552/03080] [00:32:00/00:06:37, 0.753s/it]: train_loss_raw=0.5750, running_loss=0.5329, LR=0.000100
[2025-08-27 09:16:14,361][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054920] [Batch 02560/03080] [00:32:06/00:06:31, 0.753s/it]: train_loss_raw=0.5326, running_loss=0.5330, LR=0.000100
[2025-08-27 09:16:20,419][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054928] [Batch 02568/03080] [00:32:12/00:06:25, 0.753s/it]: train_loss_raw=0.5407, running_loss=0.5314, LR=0.000100
[2025-08-27 09:16:26,540][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054936] [Batch 02576/03080] [00:32:18/00:06:19, 0.753s/it]: train_loss_raw=0.5316, running_loss=0.5285, LR=0.000100
[2025-08-27 09:16:32,658][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054944] [Batch 02584/03080] [00:32:25/00:06:13, 0.753s/it]: train_loss_raw=0.4529, running_loss=0.5303, LR=0.000100
[2025-08-27 09:16:38,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054952] [Batch 02592/03080] [00:32:31/00:06:07, 0.753s/it]: train_loss_raw=0.5454, running_loss=0.5296, LR=0.000100
[2025-08-27 09:16:44,847][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054960] [Batch 02600/03080] [00:32:37/00:06:01, 0.753s/it]: train_loss_raw=0.6320, running_loss=0.5322, LR=0.000100
[2025-08-27 09:16:50,901][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054968] [Batch 02608/03080] [00:32:43/00:05:55, 0.753s/it]: train_loss_raw=0.5339, running_loss=0.5349, LR=0.000100
[2025-08-27 09:16:56,954][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054976] [Batch 02616/03080] [00:32:49/00:05:49, 0.753s/it]: train_loss_raw=0.5989, running_loss=0.5356, LR=0.000100
[2025-08-27 09:17:02,941][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054984] [Batch 02624/03080] [00:32:55/00:05:43, 0.753s/it]: train_loss_raw=0.5584, running_loss=0.5370, LR=0.000100
[2025-08-27 09:17:08,961][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054992] [Batch 02632/03080] [00:33:01/00:05:37, 0.753s/it]: train_loss_raw=0.4261, running_loss=0.5360, LR=0.000100
[2025-08-27 09:17:15,226][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055000] [Batch 02640/03080] [00:33:07/00:05:31, 0.753s/it]: train_loss_raw=0.4512, running_loss=0.5328, LR=0.000100
[2025-08-27 09:17:21,216][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055008] [Batch 02648/03080] [00:33:13/00:05:25, 0.753s/it]: train_loss_raw=0.4786, running_loss=0.5344, LR=0.000100
[2025-08-27 09:17:27,377][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055016] [Batch 02656/03080] [00:33:19/00:05:19, 0.753s/it]: train_loss_raw=0.5976, running_loss=0.5342, LR=0.000100
[2025-08-27 09:17:33,437][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055024] [Batch 02664/03080] [00:33:25/00:05:13, 0.753s/it]: train_loss_raw=0.5205, running_loss=0.5329, LR=0.000100
[2025-08-27 09:17:39,659][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055032] [Batch 02672/03080] [00:33:32/00:05:07, 0.753s/it]: train_loss_raw=0.5335, running_loss=0.5336, LR=0.000100
[2025-08-27 09:17:45,621][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055040] [Batch 02680/03080] [00:33:38/00:05:01, 0.753s/it]: train_loss_raw=0.4261, running_loss=0.5318, LR=0.000100
[2025-08-27 09:17:51,733][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055048] [Batch 02688/03080] [00:33:44/00:04:55, 0.753s/it]: train_loss_raw=0.5194, running_loss=0.5307, LR=0.000100
[2025-08-27 09:17:57,709][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055056] [Batch 02696/03080] [00:33:50/00:04:49, 0.753s/it]: train_loss_raw=0.5318, running_loss=0.5289, LR=0.000100
[2025-08-27 09:18:03,759][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055064] [Batch 02704/03080] [00:33:56/00:04:43, 0.753s/it]: train_loss_raw=0.4354, running_loss=0.5307, LR=0.000100
[2025-08-27 09:18:09,762][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055072] [Batch 02712/03080] [00:34:02/00:04:37, 0.753s/it]: train_loss_raw=0.4487, running_loss=0.5318, LR=0.000100
[2025-08-27 09:18:15,829][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055080] [Batch 02720/03080] [00:34:08/00:04:31, 0.753s/it]: train_loss_raw=0.4971, running_loss=0.5322, LR=0.000100
[2025-08-27 09:18:21,876][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055088] [Batch 02728/03080] [00:34:14/00:04:25, 0.753s/it]: train_loss_raw=0.6553, running_loss=0.5332, LR=0.000100
[2025-08-27 09:18:27,863][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055096] [Batch 02736/03080] [00:34:20/00:04:19, 0.753s/it]: train_loss_raw=0.5876, running_loss=0.5367, LR=0.000100
[2025-08-27 09:18:33,909][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055104] [Batch 02744/03080] [00:34:26/00:04:13, 0.753s/it]: train_loss_raw=0.5318, running_loss=0.5366, LR=0.000100
[2025-08-27 09:18:40,000][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055112] [Batch 02752/03080] [00:34:32/00:04:07, 0.753s/it]: train_loss_raw=0.6479, running_loss=0.5368, LR=0.000100
[2025-08-27 09:18:45,998][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055120] [Batch 02760/03080] [00:34:38/00:04:00, 0.753s/it]: train_loss_raw=0.5665, running_loss=0.5356, LR=0.000100
[2025-08-27 09:18:52,016][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055128] [Batch 02768/03080] [00:34:44/00:03:54, 0.753s/it]: train_loss_raw=0.6448, running_loss=0.5384, LR=0.000100
[2025-08-27 09:18:58,017][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055136] [Batch 02776/03080] [00:34:50/00:03:48, 0.753s/it]: train_loss_raw=0.5789, running_loss=0.5377, LR=0.000100
[2025-08-27 09:19:03,990][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055144] [Batch 02784/03080] [00:34:56/00:03:42, 0.753s/it]: train_loss_raw=0.5576, running_loss=0.5370, LR=0.000100
[2025-08-27 09:19:10,047][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055152] [Batch 02792/03080] [00:35:02/00:03:36, 0.753s/it]: train_loss_raw=0.5322, running_loss=0.5357, LR=0.000100
[2025-08-27 09:19:16,089][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055160] [Batch 02800/03080] [00:35:08/00:03:30, 0.753s/it]: train_loss_raw=0.4260, running_loss=0.5340, LR=0.000100
[2025-08-27 09:19:22,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055168] [Batch 02808/03080] [00:35:14/00:03:24, 0.753s/it]: train_loss_raw=0.5154, running_loss=0.5311, LR=0.000100
[2025-08-27 09:19:28,120][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055176] [Batch 02816/03080] [00:35:20/00:03:18, 0.753s/it]: train_loss_raw=0.4902, running_loss=0.5308, LR=0.000100
[2025-08-27 09:19:34,115][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055184] [Batch 02824/03080] [00:35:26/00:03:12, 0.753s/it]: train_loss_raw=0.6138, running_loss=0.5317, LR=0.000100
[2025-08-27 09:19:40,096][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055192] [Batch 02832/03080] [00:35:32/00:03:06, 0.753s/it]: train_loss_raw=0.5257, running_loss=0.5327, LR=0.000100
[2025-08-27 09:19:46,150][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055200] [Batch 02840/03080] [00:35:38/00:03:00, 0.753s/it]: train_loss_raw=0.4529, running_loss=0.5314, LR=0.000100
[2025-08-27 09:19:52,161][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055208] [Batch 02848/03080] [00:35:44/00:02:54, 0.753s/it]: train_loss_raw=0.5242, running_loss=0.5309, LR=0.000100
[2025-08-27 09:19:58,164][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055216] [Batch 02856/03080] [00:35:50/00:02:48, 0.753s/it]: train_loss_raw=0.5123, running_loss=0.5297, LR=0.000100
[2025-08-27 09:20:04,007][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055224] [Batch 02864/03080] [00:35:56/00:02:42, 0.753s/it]: train_loss_raw=0.5576, running_loss=0.5302, LR=0.000100
[2025-08-27 09:20:09,895][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055232] [Batch 02872/03080] [00:36:02/00:02:36, 0.753s/it]: train_loss_raw=0.6735, running_loss=0.5307, LR=0.000100
[2025-08-27 09:20:15,871][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055240] [Batch 02880/03080] [00:36:08/00:02:30, 0.753s/it]: train_loss_raw=0.4740, running_loss=0.5303, LR=0.000100
[2025-08-27 09:20:21,870][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055248] [Batch 02888/03080] [00:36:14/00:02:24, 0.753s/it]: train_loss_raw=0.5794, running_loss=0.5308, LR=0.000100
[2025-08-27 09:20:27,936][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055256] [Batch 02896/03080] [00:36:20/00:02:18, 0.753s/it]: train_loss_raw=0.5629, running_loss=0.5301, LR=0.000100
[2025-08-27 09:20:33,937][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055264] [Batch 02904/03080] [00:36:26/00:02:12, 0.753s/it]: train_loss_raw=0.6733, running_loss=0.5317, LR=0.000100
[2025-08-27 09:20:39,972][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055272] [Batch 02912/03080] [00:36:32/00:02:06, 0.753s/it]: train_loss_raw=0.4987, running_loss=0.5302, LR=0.000100
[2025-08-27 09:20:45,950][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055280] [Batch 02920/03080] [00:36:38/00:02:00, 0.753s/it]: train_loss_raw=0.6118, running_loss=0.5312, LR=0.000100
[2025-08-27 09:20:51,987][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055288] [Batch 02928/03080] [00:36:44/00:01:54, 0.753s/it]: train_loss_raw=0.5244, running_loss=0.5307, LR=0.000100
[2025-08-27 09:20:58,048][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055296] [Batch 02936/03080] [00:36:50/00:01:48, 0.753s/it]: train_loss_raw=0.5619, running_loss=0.5307, LR=0.000100
[2025-08-27 09:21:04,056][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055304] [Batch 02944/03080] [00:36:56/00:01:42, 0.753s/it]: train_loss_raw=0.5898, running_loss=0.5290, LR=0.000100
[2025-08-27 09:21:10,154][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055312] [Batch 02952/03080] [00:37:02/00:01:36, 0.753s/it]: train_loss_raw=0.4703, running_loss=0.5294, LR=0.000100
[2025-08-27 09:21:16,254][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055320] [Batch 02960/03080] [00:37:08/00:01:30, 0.753s/it]: train_loss_raw=0.5452, running_loss=0.5303, LR=0.000100
[2025-08-27 09:21:22,253][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055328] [Batch 02968/03080] [00:37:14/00:01:24, 0.753s/it]: train_loss_raw=0.5090, running_loss=0.5300, LR=0.000100
[2025-08-27 09:21:28,386][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055336] [Batch 02976/03080] [00:37:20/00:01:18, 0.753s/it]: train_loss_raw=0.4715, running_loss=0.5311, LR=0.000100
[2025-08-27 09:21:34,314][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055344] [Batch 02984/03080] [00:37:26/00:01:12, 0.753s/it]: train_loss_raw=0.6118, running_loss=0.5312, LR=0.000100
[2025-08-27 09:21:40,310][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055352] [Batch 02992/03080] [00:37:32/00:01:06, 0.753s/it]: train_loss_raw=0.4472, running_loss=0.5300, LR=0.000100
[2025-08-27 09:21:46,295][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055360] [Batch 03000/03080] [00:37:38/00:01:00, 0.753s/it]: train_loss_raw=0.5670, running_loss=0.5295, LR=0.000100
[2025-08-27 09:21:52,002][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055368] [Batch 03008/03080] [00:37:44/00:00:54, 0.753s/it]: train_loss_raw=0.4379, running_loss=0.5298, LR=0.000100
[2025-08-27 09:21:57,739][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055376] [Batch 03016/03080] [00:37:50/00:00:48, 0.753s/it]: train_loss_raw=0.5075, running_loss=0.5302, LR=0.000100
[2025-08-27 09:22:03,819][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055384] [Batch 03024/03080] [00:37:56/00:00:42, 0.753s/it]: train_loss_raw=0.5516, running_loss=0.5311, LR=0.000100
[2025-08-27 09:22:09,808][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055392] [Batch 03032/03080] [00:38:02/00:00:36, 0.753s/it]: train_loss_raw=0.6123, running_loss=0.5320, LR=0.000100
[2025-08-27 09:22:15,881][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055400] [Batch 03040/03080] [00:38:08/00:00:30, 0.753s/it]: train_loss_raw=0.4659, running_loss=0.5316, LR=0.000100
[2025-08-27 09:22:21,834][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055408] [Batch 03048/03080] [00:38:14/00:00:24, 0.753s/it]: train_loss_raw=0.4751, running_loss=0.5318, LR=0.000100
[2025-08-27 09:22:27,865][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055416] [Batch 03056/03080] [00:38:20/00:00:18, 0.753s/it]: train_loss_raw=0.5149, running_loss=0.5307, LR=0.000100
[2025-08-27 09:22:33,971][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055424] [Batch 03064/03080] [00:38:26/00:00:12, 0.753s/it]: train_loss_raw=0.6005, running_loss=0.5334, LR=0.000100
[2025-08-27 09:22:40,013][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055432] [Batch 03072/03080] [00:38:32/00:00:06, 0.753s/it]: train_loss_raw=0.5031, running_loss=0.5302, LR=0.000100
[2025-08-27 09:22:50,918][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055440] [Batch 03080/03080] [00:38:43/00:00:00, 0.754s/it]: train_loss_raw=0.5065, running_loss=0.5301, LR=0.000100
[2025-08-27 09:22:51,545][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-27 09:23:02,066][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00007/00310] [00:00:10/00:06:37, 1.315s/it]
[2025-08-27 09:23:14,314][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00015/00310] [00:00:22/00:06:58, 1.423s/it]
[2025-08-27 09:23:25,742][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00023/00310] [00:00:34/00:06:47, 1.425s/it]
[2025-08-27 09:23:37,813][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00031/00310] [00:00:46/00:06:41, 1.446s/it]
[2025-08-27 09:23:48,866][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00039/00310] [00:00:57/00:06:26, 1.433s/it]
[2025-08-27 09:24:01,225][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00047/00310] [00:01:09/00:06:20, 1.452s/it]
[2025-08-27 09:24:12,907][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00055/00310] [00:01:21/00:06:09, 1.453s/it]
[2025-08-27 09:24:24,142][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00063/00310] [00:01:32/00:05:55, 1.447s/it]
[2025-08-27 09:24:35,715][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00071/00310] [00:01:44/00:05:44, 1.447s/it]
[2025-08-27 09:24:47,877][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00079/00310] [00:01:56/00:05:34, 1.454s/it]
[2025-08-27 09:24:59,358][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00087/00310] [00:02:07/00:05:22, 1.452s/it]
[2025-08-27 09:25:10,962][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00095/00310] [00:02:19/00:05:10, 1.452s/it]
[2025-08-27 09:25:22,923][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00103/00310] [00:02:31/00:04:59, 1.456s/it]
[2025-08-27 09:25:34,314][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00111/00310] [00:02:42/00:04:47, 1.453s/it]
[2025-08-27 09:25:45,205][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00119/00310] [00:02:53/00:04:34, 1.447s/it]
[2025-08-27 09:25:57,308][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00127/00310] [00:03:05/00:04:24, 1.451s/it]
[2025-08-27 09:26:08,918][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00135/00310] [00:03:17/00:04:12, 1.451s/it]
[2025-08-27 09:26:21,663][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00143/00310] [00:03:30/00:04:02, 1.459s/it]
[2025-08-27 09:26:32,684][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00151/00310] [00:03:41/00:03:49, 1.455s/it]
[2025-08-27 09:26:43,167][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00159/00310] [00:03:51/00:03:37, 1.448s/it]
[2025-08-27 09:26:54,460][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00167/00310] [00:04:02/00:03:25, 1.446s/it]
[2025-08-27 09:27:04,098][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00175/00310] [00:04:12/00:03:12, 1.435s/it]
[2025-08-27 09:27:14,418][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00183/00310] [00:04:22/00:03:00, 1.429s/it]
[2025-08-27 09:27:26,737][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00191/00310] [00:04:35/00:02:49, 1.433s/it]
[2025-08-27 09:27:38,319][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00199/00310] [00:04:46/00:02:37, 1.434s/it]
[2025-08-27 09:27:49,758][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00207/00310] [00:04:58/00:02:26, 1.434s/it]
[2025-08-27 09:28:00,406][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00215/00310] [00:05:08/00:02:14, 1.430s/it]
[2025-08-27 09:28:12,080][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00223/00310] [00:05:20/00:02:03, 1.431s/it]
[2025-08-27 09:28:23,270][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00231/00310] [00:05:31/00:01:51, 1.430s/it]
[2025-08-27 09:28:34,327][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00239/00310] [00:05:42/00:01:39, 1.428s/it]
[2025-08-27 09:28:45,553][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00247/00310] [00:05:54/00:01:28, 1.427s/it]
[2025-08-27 09:28:57,372][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00255/00310] [00:06:05/00:01:17, 1.429s/it]
[2025-08-27 09:29:09,383][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00263/00310] [00:06:17/00:01:05, 1.431s/it]
[2025-08-27 09:29:20,596][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00271/00310] [00:06:29/00:00:54, 1.430s/it]
[2025-08-27 09:29:31,373][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00279/00310] [00:06:39/00:00:42, 1.428s/it]
[2025-08-27 09:29:43,396][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00287/00310] [00:06:51/00:00:31, 1.430s/it]
[2025-08-27 09:29:54,617][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00295/00310] [00:07:03/00:00:20, 1.429s/it]
[2025-08-27 09:30:07,180][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00303/00310] [00:07:15/00:00:08, 1.433s/it]
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=0.53010, valid_loss=1.50756
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.547
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.106
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.109
[2025-08-27 09:30:16,164][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.051
[2025-08-27 09:30:16,172][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 14:03:30, remaining time 09:22:20, 00:46:51 per epoch
[2025-08-27 09:30:31,523][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055448] [Batch 00008/03080] [00:00:15/01:37:00, 1.895s/it]: train_loss_raw=0.5413, running_loss=0.5784, LR=0.000100
[2025-08-27 09:30:37,541][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055456] [Batch 00016/03080] [00:00:21/01:07:34, 1.323s/it]: train_loss_raw=0.4767, running_loss=0.5723, LR=0.000100
[2025-08-27 09:30:43,538][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055464] [Batch 00024/03080] [00:00:27/00:57:39, 1.132s/it]: train_loss_raw=0.5175, running_loss=0.5680, LR=0.000100
[2025-08-27 09:30:49,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055472] [Batch 00032/03080] [00:00:33/00:52:39, 1.037s/it]: train_loss_raw=0.4118, running_loss=0.5630, LR=0.000100
[2025-08-27 09:30:55,559][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055480] [Batch 00040/03080] [00:00:39/00:49:38, 0.980s/it]: train_loss_raw=0.5083, running_loss=0.5582, LR=0.000100
[2025-08-27 09:31:01,525][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055488] [Batch 00048/03080] [00:00:45/00:47:32, 0.941s/it]: train_loss_raw=0.5450, running_loss=0.5545, LR=0.000100
[2025-08-27 09:31:07,548][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055496] [Batch 00056/03080] [00:00:51/00:46:03, 0.914s/it]: train_loss_raw=0.4968, running_loss=0.5521, LR=0.000100
[2025-08-27 09:31:13,606][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055504] [Batch 00064/03080] [00:00:57/00:44:57, 0.894s/it]: train_loss_raw=0.4546, running_loss=0.5500, LR=0.000100
[2025-08-27 09:31:19,543][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055512] [Batch 00072/03080] [00:01:03/00:43:59, 0.877s/it]: train_loss_raw=0.4082, running_loss=0.5442, LR=0.000100
[2025-08-27 09:31:25,540][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055520] [Batch 00080/03080] [00:01:09/00:43:14, 0.865s/it]: train_loss_raw=0.4604, running_loss=0.5395, LR=0.000100
[2025-08-27 09:31:31,665][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055528] [Batch 00088/03080] [00:01:15/00:42:40, 0.856s/it]: train_loss_raw=0.5319, running_loss=0.5378, LR=0.000100
[2025-08-27 09:31:37,674][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055536] [Batch 00096/03080] [00:01:21/00:42:07, 0.847s/it]: train_loss_raw=0.5360, running_loss=0.5353, LR=0.000100
[2025-08-27 09:31:43,705][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055544] [Batch 00104/03080] [00:01:27/00:41:39, 0.840s/it]: train_loss_raw=0.5324, running_loss=0.5351, LR=0.000100
[2025-08-27 09:31:49,878][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055552] [Batch 00112/03080] [00:01:33/00:41:18, 0.835s/it]: train_loss_raw=0.5784, running_loss=0.5341, LR=0.000100
[2025-08-27 09:31:55,875][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055560] [Batch 00120/03080] [00:01:39/00:40:54, 0.829s/it]: train_loss_raw=0.5535, running_loss=0.5332, LR=0.000100
[2025-08-27 09:32:01,490][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055568] [Batch 00128/03080] [00:01:45/00:40:24, 0.821s/it]: train_loss_raw=0.4999, running_loss=0.5306, LR=0.000100
[2025-08-27 09:32:07,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055576] [Batch 00136/03080] [00:01:50/00:39:59, 0.815s/it]: train_loss_raw=0.5238, running_loss=0.5289, LR=0.000100
[2025-08-27 09:32:13,340][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055584] [Batch 00144/03080] [00:01:56/00:39:44, 0.812s/it]: train_loss_raw=0.4459, running_loss=0.5265, LR=0.000100
[2025-08-27 09:32:19,424][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055592] [Batch 00152/03080] [00:02:03/00:39:30, 0.810s/it]: train_loss_raw=0.5001, running_loss=0.5243, LR=0.000100
[2025-08-27 09:32:25,427][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055600] [Batch 00160/03080] [00:02:09/00:39:15, 0.807s/it]: train_loss_raw=0.5084, running_loss=0.5244, LR=0.000100
[2025-08-27 09:32:31,421][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055608] [Batch 00168/03080] [00:02:15/00:39:00, 0.804s/it]: train_loss_raw=0.4722, running_loss=0.5250, LR=0.000100
[2025-08-27 09:32:37,436][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055616] [Batch 00176/03080] [00:02:21/00:38:47, 0.802s/it]: train_loss_raw=0.5064, running_loss=0.5250, LR=0.000100
[2025-08-27 09:32:43,572][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055624] [Batch 00184/03080] [00:02:27/00:38:36, 0.800s/it]: train_loss_raw=0.4198, running_loss=0.5213, LR=0.000100
[2025-08-27 09:32:49,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055632] [Batch 00192/03080] [00:02:33/00:38:23, 0.798s/it]: train_loss_raw=0.4452, running_loss=0.5165, LR=0.000100
[2025-08-27 09:32:55,639][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055640] [Batch 00200/03080] [00:02:39/00:38:13, 0.796s/it]: train_loss_raw=0.5238, running_loss=0.5158, LR=0.000100
[2025-08-27 09:33:01,693][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055648] [Batch 00208/03080] [00:02:45/00:38:02, 0.795s/it]: train_loss_raw=0.5645, running_loss=0.5177, LR=0.000100
[2025-08-27 09:33:07,733][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055656] [Batch 00216/03080] [00:02:51/00:37:52, 0.793s/it]: train_loss_raw=0.5114, running_loss=0.5145, LR=0.000100
[2025-08-27 09:33:13,815][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055664] [Batch 00224/03080] [00:02:57/00:37:42, 0.792s/it]: train_loss_raw=0.4770, running_loss=0.5123, LR=0.000100
[2025-08-27 09:33:19,857][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055672] [Batch 00232/03080] [00:03:03/00:37:32, 0.791s/it]: train_loss_raw=0.4509, running_loss=0.5111, LR=0.000100
[2025-08-27 09:33:25,887][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055680] [Batch 00240/03080] [00:03:09/00:37:22, 0.790s/it]: train_loss_raw=0.5408, running_loss=0.5104, LR=0.000100
[2025-08-27 09:33:32,069][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055688] [Batch 00248/03080] [00:03:15/00:37:14, 0.789s/it]: train_loss_raw=0.5445, running_loss=0.5107, LR=0.000100
[2025-08-27 09:33:38,082][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055696] [Batch 00256/03080] [00:03:21/00:37:05, 0.788s/it]: train_loss_raw=0.4954, running_loss=0.5088, LR=0.000100
[2025-08-27 09:33:44,064][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055704] [Batch 00264/03080] [00:03:27/00:36:55, 0.787s/it]: train_loss_raw=0.4587, running_loss=0.5074, LR=0.000100
[2025-08-27 09:33:50,061][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055712] [Batch 00272/03080] [00:03:33/00:36:46, 0.786s/it]: train_loss_raw=0.5185, running_loss=0.5064, LR=0.000100
[2025-08-27 09:33:56,120][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055720] [Batch 00280/03080] [00:03:39/00:36:37, 0.785s/it]: train_loss_raw=0.5619, running_loss=0.5066, LR=0.000100
[2025-08-27 09:34:02,370][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055728] [Batch 00288/03080] [00:03:46/00:36:30, 0.785s/it]: train_loss_raw=0.4895, running_loss=0.5060, LR=0.000100
[2025-08-27 09:34:08,360][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055736] [Batch 00296/03080] [00:03:51/00:36:21, 0.784s/it]: train_loss_raw=0.3512, running_loss=0.5052, LR=0.000100
[2025-08-27 09:34:14,360][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055744] [Batch 00304/03080] [00:03:57/00:36:13, 0.783s/it]: train_loss_raw=0.4127, running_loss=0.5051, LR=0.000100
[2025-08-27 09:34:20,381][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055752] [Batch 00312/03080] [00:04:04/00:36:04, 0.782s/it]: train_loss_raw=0.5009, running_loss=0.5040, LR=0.000100
[2025-08-27 09:34:26,365][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055760] [Batch 00320/03080] [00:04:09/00:35:56, 0.781s/it]: train_loss_raw=0.5213, running_loss=0.5058, LR=0.000100
[2025-08-27 09:34:32,345][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055768] [Batch 00328/03080] [00:04:15/00:35:47, 0.780s/it]: train_loss_raw=0.4864, running_loss=0.5046, LR=0.000100
[2025-08-27 09:34:38,492][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055776] [Batch 00336/03080] [00:04:22/00:35:40, 0.780s/it]: train_loss_raw=0.4232, running_loss=0.5053, LR=0.000100
[2025-08-27 09:34:44,489][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055784] [Batch 00344/03080] [00:04:28/00:35:32, 0.779s/it]: train_loss_raw=0.6581, running_loss=0.5046, LR=0.000100
[2025-08-27 09:34:50,667][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055792] [Batch 00352/03080] [00:04:34/00:35:25, 0.779s/it]: train_loss_raw=0.4765, running_loss=0.5034, LR=0.000100
[2025-08-27 09:34:56,582][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055800] [Batch 00360/03080] [00:04:40/00:35:17, 0.778s/it]: train_loss_raw=0.4077, running_loss=0.5023, LR=0.000100
[2025-08-27 09:35:02,653][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055808] [Batch 00368/03080] [00:04:46/00:35:09, 0.778s/it]: train_loss_raw=0.4508, running_loss=0.5010, LR=0.000100
[2025-08-27 09:35:08,448][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055816] [Batch 00376/03080] [00:04:52/00:35:00, 0.777s/it]: train_loss_raw=0.4779, running_loss=0.4994, LR=0.000100
[2025-08-27 09:35:14,380][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055824] [Batch 00384/03080] [00:04:58/00:34:52, 0.776s/it]: train_loss_raw=0.5813, running_loss=0.5007, LR=0.000100
[2025-08-27 09:35:20,333][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055832] [Batch 00392/03080] [00:05:03/00:34:44, 0.775s/it]: train_loss_raw=0.5783, running_loss=0.5006, LR=0.000100
[2025-08-27 09:35:26,209][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055840] [Batch 00400/03080] [00:05:09/00:34:35, 0.775s/it]: train_loss_raw=0.4409, running_loss=0.4992, LR=0.000100
[2025-08-27 09:35:32,317][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055848] [Batch 00408/03080] [00:05:15/00:34:29, 0.774s/it]: train_loss_raw=0.5256, running_loss=0.4995, LR=0.000100
[2025-08-27 09:35:38,284][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055856] [Batch 00416/03080] [00:05:21/00:34:21, 0.774s/it]: train_loss_raw=0.5505, running_loss=0.5011, LR=0.000100
[2025-08-27 09:35:44,310][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055864] [Batch 00424/03080] [00:05:27/00:34:14, 0.773s/it]: train_loss_raw=0.5006, running_loss=0.5019, LR=0.000100
[2025-08-27 09:35:50,261][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055872] [Batch 00432/03080] [00:05:33/00:34:06, 0.773s/it]: train_loss_raw=0.4605, running_loss=0.5019, LR=0.000100
[2025-08-27 09:35:56,214][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055880] [Batch 00440/03080] [00:05:39/00:33:59, 0.772s/it]: train_loss_raw=0.5240, running_loss=0.5011, LR=0.000100
[2025-08-27 09:36:02,202][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055888] [Batch 00448/03080] [00:05:45/00:33:51, 0.772s/it]: train_loss_raw=0.5726, running_loss=0.5030, LR=0.000100
[2025-08-27 09:36:08,195][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055896] [Batch 00456/03080] [00:05:51/00:33:44, 0.772s/it]: train_loss_raw=0.4339, running_loss=0.5031, LR=0.000100
[2025-08-27 09:36:14,182][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055904] [Batch 00464/03080] [00:05:57/00:33:37, 0.771s/it]: train_loss_raw=0.4652, running_loss=0.5041, LR=0.000100
[2025-08-27 09:36:20,204][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055912] [Batch 00472/03080] [00:06:03/00:33:30, 0.771s/it]: train_loss_raw=0.5114, running_loss=0.5029, LR=0.000100
[2025-08-27 09:36:26,243][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055920] [Batch 00480/03080] [00:06:09/00:33:23, 0.771s/it]: train_loss_raw=0.4702, running_loss=0.5028, LR=0.000100
[2025-08-27 09:36:32,294][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055928] [Batch 00488/03080] [00:06:15/00:33:16, 0.770s/it]: train_loss_raw=0.5319, running_loss=0.5028, LR=0.000100
[2025-08-27 09:36:38,235][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055936] [Batch 00496/03080] [00:06:21/00:33:09, 0.770s/it]: train_loss_raw=0.3840, running_loss=0.5025, LR=0.000100
[2025-08-27 09:36:44,429][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055944] [Batch 00504/03080] [00:06:28/00:33:03, 0.770s/it]: train_loss_raw=0.4766, running_loss=0.5034, LR=0.000100
[2025-08-27 09:36:50,508][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055952] [Batch 00512/03080] [00:06:34/00:32:56, 0.770s/it]: train_loss_raw=0.5152, running_loss=0.5033, LR=0.000100
[2025-08-27 09:36:56,503][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055960] [Batch 00520/03080] [00:06:40/00:32:49, 0.769s/it]: train_loss_raw=0.5212, running_loss=0.5043, LR=0.000100
[2025-08-27 09:37:02,739][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055968] [Batch 00528/03080] [00:06:46/00:32:44, 0.770s/it]: train_loss_raw=0.4859, running_loss=0.5022, LR=0.000100
[2025-08-27 09:37:08,748][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055976] [Batch 00536/03080] [00:06:52/00:32:37, 0.769s/it]: train_loss_raw=0.5289, running_loss=0.5041, LR=0.000100
[2025-08-27 09:37:14,912][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055984] [Batch 00544/03080] [00:06:58/00:32:31, 0.769s/it]: train_loss_raw=0.5225, running_loss=0.5050, LR=0.000100
[2025-08-27 09:37:20,903][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055992] [Batch 00552/03080] [00:07:04/00:32:24, 0.769s/it]: train_loss_raw=0.5024, running_loss=0.5027, LR=0.000100
[2025-08-27 09:37:26,920][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056000] [Batch 00560/03080] [00:07:10/00:32:17, 0.769s/it]: train_loss_raw=0.4765, running_loss=0.5034, LR=0.000100
[2025-08-27 09:37:36,243][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056008] [Batch 00568/03080] [00:07:19/00:32:25, 0.774s/it]: train_loss_raw=0.6073, running_loss=0.5041, LR=0.000100
[2025-08-27 09:37:41,721][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056016] [Batch 00576/03080] [00:07:25/00:32:16, 0.773s/it]: train_loss_raw=0.5091, running_loss=0.5010, LR=0.000100
[2025-08-27 09:37:47,677][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056024] [Batch 00584/03080] [00:07:31/00:32:08, 0.773s/it]: train_loss_raw=0.4787, running_loss=0.5020, LR=0.000100
[2025-08-27 09:37:53,664][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056032] [Batch 00592/03080] [00:07:37/00:32:01, 0.772s/it]: train_loss_raw=0.5973, running_loss=0.5038, LR=0.000100
[2025-08-27 09:37:59,790][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056040] [Batch 00600/03080] [00:07:43/00:31:55, 0.772s/it]: train_loss_raw=0.5448, running_loss=0.5052, LR=0.000100
[2025-08-27 09:38:06,027][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056048] [Batch 00608/03080] [00:07:49/00:31:49, 0.772s/it]: train_loss_raw=0.4420, running_loss=0.5038, LR=0.000100
[2025-08-27 09:38:12,114][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056056] [Batch 00616/03080] [00:07:55/00:31:42, 0.772s/it]: train_loss_raw=0.5452, running_loss=0.5013, LR=0.000100
[2025-08-27 09:38:18,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056064] [Batch 00624/03080] [00:08:02/00:31:37, 0.772s/it]: train_loss_raw=0.4449, running_loss=0.5029, LR=0.000100
[2025-08-27 09:38:24,308][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056072] [Batch 00632/03080] [00:08:07/00:31:30, 0.772s/it]: train_loss_raw=0.4577, running_loss=0.5013, LR=0.000100
[2025-08-27 09:38:30,298][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056080] [Batch 00640/03080] [00:08:13/00:31:23, 0.772s/it]: train_loss_raw=0.4549, running_loss=0.5000, LR=0.000100
[2025-08-27 09:38:36,369][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056088] [Batch 00648/03080] [00:08:20/00:31:16, 0.772s/it]: train_loss_raw=0.5346, running_loss=0.5010, LR=0.000100
[2025-08-27 09:38:42,380][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056096] [Batch 00656/03080] [00:08:26/00:31:09, 0.771s/it]: train_loss_raw=0.5302, running_loss=0.5011, LR=0.000100
[2025-08-27 09:38:48,385][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056104] [Batch 00664/03080] [00:08:32/00:31:03, 0.771s/it]: train_loss_raw=0.4629, running_loss=0.5038, LR=0.000100
[2025-08-27 09:38:54,545][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056112] [Batch 00672/03080] [00:08:38/00:30:56, 0.771s/it]: train_loss_raw=0.5218, running_loss=0.5037, LR=0.000100
[2025-08-27 09:39:00,520][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056120] [Batch 00680/03080] [00:08:44/00:30:49, 0.771s/it]: train_loss_raw=0.4883, running_loss=0.5055, LR=0.000100
[2025-08-27 09:39:06,213][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056128] [Batch 00688/03080] [00:08:49/00:30:42, 0.770s/it]: train_loss_raw=0.5758, running_loss=0.5060, LR=0.000100
[2025-08-27 09:39:11,874][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056136] [Batch 00696/03080] [00:08:55/00:30:34, 0.769s/it]: train_loss_raw=0.4458, running_loss=0.5036, LR=0.000100
[2025-08-27 09:39:17,818][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056144] [Batch 00704/03080] [00:09:01/00:30:27, 0.769s/it]: train_loss_raw=0.5319, running_loss=0.5051, LR=0.000100
[2025-08-27 09:39:23,738][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056152] [Batch 00712/03080] [00:09:07/00:30:20, 0.769s/it]: train_loss_raw=0.5364, running_loss=0.5057, LR=0.000100
[2025-08-27 09:39:29,627][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056160] [Batch 00720/03080] [00:09:13/00:30:13, 0.768s/it]: train_loss_raw=0.4574, running_loss=0.5045, LR=0.000100
[2025-08-27 09:39:35,174][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056168] [Batch 00728/03080] [00:09:18/00:30:05, 0.768s/it]: train_loss_raw=0.5413, running_loss=0.5068, LR=0.000100
[2025-08-27 09:39:40,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056176] [Batch 00736/03080] [00:09:24/00:29:57, 0.767s/it]: train_loss_raw=0.4473, running_loss=0.5055, LR=0.000100
[2025-08-27 09:39:46,689][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056184] [Batch 00744/03080] [00:09:30/00:29:50, 0.767s/it]: train_loss_raw=0.4658, running_loss=0.5079, LR=0.000100
[2025-08-27 09:39:52,571][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056192] [Batch 00752/03080] [00:09:36/00:29:43, 0.766s/it]: train_loss_raw=0.4851, running_loss=0.5053, LR=0.000100
[2025-08-27 09:39:58,789][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056200] [Batch 00760/03080] [00:09:42/00:29:37, 0.766s/it]: train_loss_raw=0.5648, running_loss=0.5028, LR=0.000100
[2025-08-27 09:40:04,807][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056208] [Batch 00768/03080] [00:09:48/00:29:31, 0.766s/it]: train_loss_raw=0.5356, running_loss=0.5032, LR=0.000100
[2025-08-27 09:40:10,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056216] [Batch 00776/03080] [00:09:54/00:29:25, 0.766s/it]: train_loss_raw=0.4731, running_loss=0.5021, LR=0.000100
[2025-08-27 09:40:16,990][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056224] [Batch 00784/03080] [00:10:00/00:29:18, 0.766s/it]: train_loss_raw=0.5534, running_loss=0.5015, LR=0.000100
[2025-08-27 09:40:22,533][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056232] [Batch 00792/03080] [00:10:06/00:29:11, 0.765s/it]: train_loss_raw=0.4806, running_loss=0.5016, LR=0.000100
[2025-08-27 09:40:28,527][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056240] [Batch 00800/03080] [00:10:12/00:29:04, 0.765s/it]: train_loss_raw=0.5900, running_loss=0.5060, LR=0.000100
[2025-08-27 09:40:34,688][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056248] [Batch 00808/03080] [00:10:18/00:28:58, 0.765s/it]: train_loss_raw=0.4564, running_loss=0.5051, LR=0.000100
[2025-08-27 09:40:40,720][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056256] [Batch 00816/03080] [00:10:24/00:28:52, 0.765s/it]: train_loss_raw=0.4043, running_loss=0.5055, LR=0.000100
[2025-08-27 09:40:46,719][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056264] [Batch 00824/03080] [00:10:30/00:28:45, 0.765s/it]: train_loss_raw=0.5131, running_loss=0.5042, LR=0.000100
[2025-08-27 09:40:52,750][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056272] [Batch 00832/03080] [00:10:36/00:28:39, 0.765s/it]: train_loss_raw=0.4898, running_loss=0.5033, LR=0.000100
[2025-08-27 09:40:58,834][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056280] [Batch 00840/03080] [00:10:42/00:28:33, 0.765s/it]: train_loss_raw=0.3817, running_loss=0.5010, LR=0.000100
[2025-08-27 09:41:04,913][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056288] [Batch 00848/03080] [00:10:48/00:28:27, 0.765s/it]: train_loss_raw=0.5087, running_loss=0.5016, LR=0.000100
[2025-08-27 09:41:10,963][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056296] [Batch 00856/03080] [00:10:54/00:28:20, 0.765s/it]: train_loss_raw=0.5888, running_loss=0.5006, LR=0.000100
[2025-08-27 09:41:17,104][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056304] [Batch 00864/03080] [00:11:00/00:28:14, 0.765s/it]: train_loss_raw=0.5027, running_loss=0.5032, LR=0.000100
[2025-08-27 09:41:23,044][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056312] [Batch 00872/03080] [00:11:06/00:28:08, 0.765s/it]: train_loss_raw=0.5430, running_loss=0.5024, LR=0.000100
[2025-08-27 09:41:29,121][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056320] [Batch 00880/03080] [00:11:12/00:28:01, 0.764s/it]: train_loss_raw=0.4920, running_loss=0.5036, LR=0.000100
[2025-08-27 09:41:35,178][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056328] [Batch 00888/03080] [00:11:18/00:27:55, 0.764s/it]: train_loss_raw=0.4665, running_loss=0.5035, LR=0.000100
[2025-08-27 09:41:41,209][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056336] [Batch 00896/03080] [00:11:24/00:27:49, 0.764s/it]: train_loss_raw=0.5864, running_loss=0.5032, LR=0.000100
[2025-08-27 09:41:47,160][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056344] [Batch 00904/03080] [00:11:30/00:27:42, 0.764s/it]: train_loss_raw=0.4122, running_loss=0.5037, LR=0.000100
[2025-08-27 09:41:53,174][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056352] [Batch 00912/03080] [00:11:36/00:27:36, 0.764s/it]: train_loss_raw=0.3724, running_loss=0.5009, LR=0.000100
[2025-08-27 09:41:59,198][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056360] [Batch 00920/03080] [00:11:42/00:27:30, 0.764s/it]: train_loss_raw=0.5063, running_loss=0.4974, LR=0.000100
[2025-08-27 09:42:05,205][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056368] [Batch 00928/03080] [00:11:48/00:27:23, 0.764s/it]: train_loss_raw=0.5503, running_loss=0.4979, LR=0.000100
[2025-08-27 09:42:11,459][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056376] [Batch 00936/03080] [00:11:55/00:27:17, 0.764s/it]: train_loss_raw=0.4936, running_loss=0.5007, LR=0.000100
[2025-08-27 09:42:17,503][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056384] [Batch 00944/03080] [00:12:01/00:27:11, 0.764s/it]: train_loss_raw=0.4938, running_loss=0.5018, LR=0.000100
[2025-08-27 09:42:23,580][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056392] [Batch 00952/03080] [00:12:07/00:27:05, 0.764s/it]: train_loss_raw=0.5714, running_loss=0.5019, LR=0.000100
[2025-08-27 09:42:29,672][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056400] [Batch 00960/03080] [00:12:13/00:26:59, 0.764s/it]: train_loss_raw=0.4697, running_loss=0.5006, LR=0.000100
[2025-08-27 09:42:35,825][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056408] [Batch 00968/03080] [00:12:19/00:26:53, 0.764s/it]: train_loss_raw=0.4932, running_loss=0.4997, LR=0.000100
[2025-08-27 09:42:42,200][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056416] [Batch 00976/03080] [00:12:25/00:26:47, 0.764s/it]: train_loss_raw=0.5167, running_loss=0.4984, LR=0.000100
[2025-08-27 09:42:48,184][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056424] [Batch 00984/03080] [00:12:31/00:26:41, 0.764s/it]: train_loss_raw=0.4981, running_loss=0.4964, LR=0.000100
[2025-08-27 09:42:54,105][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056432] [Batch 00992/03080] [00:12:37/00:26:34, 0.764s/it]: train_loss_raw=0.4328, running_loss=0.4965, LR=0.000100
[2025-08-27 09:43:00,176][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056440] [Batch 01000/03080] [00:12:43/00:26:28, 0.764s/it]: train_loss_raw=0.4494, running_loss=0.4970, LR=0.000100
[2025-08-27 09:43:06,250][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056448] [Batch 01008/03080] [00:12:49/00:26:22, 0.764s/it]: train_loss_raw=0.5323, running_loss=0.4988, LR=0.000100
[2025-08-27 09:43:12,106][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056456] [Batch 01016/03080] [00:12:55/00:26:15, 0.764s/it]: train_loss_raw=0.5809, running_loss=0.4983, LR=0.000100
[2025-08-27 09:43:18,234][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056464] [Batch 01024/03080] [00:13:01/00:26:09, 0.764s/it]: train_loss_raw=0.6272, running_loss=0.4990, LR=0.000100
[2025-08-27 09:43:24,323][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056472] [Batch 01032/03080] [00:13:07/00:26:03, 0.764s/it]: train_loss_raw=0.4860, running_loss=0.4989, LR=0.000100
[2025-08-27 09:43:30,368][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056480] [Batch 01040/03080] [00:13:14/00:25:57, 0.763s/it]: train_loss_raw=0.5288, running_loss=0.4984, LR=0.000100
[2025-08-27 09:43:36,362][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056488] [Batch 01048/03080] [00:13:19/00:25:51, 0.763s/it]: train_loss_raw=0.4995, running_loss=0.4993, LR=0.000100
[2025-08-27 09:43:42,358][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056496] [Batch 01056/03080] [00:13:25/00:25:44, 0.763s/it]: train_loss_raw=0.5462, running_loss=0.5030, LR=0.000100
[2025-08-27 09:43:48,449][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056504] [Batch 01064/03080] [00:13:32/00:25:38, 0.763s/it]: train_loss_raw=0.5819, running_loss=0.5029, LR=0.000100
[2025-08-27 09:43:54,591][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056512] [Batch 01072/03080] [00:13:38/00:25:32, 0.763s/it]: train_loss_raw=0.5276, running_loss=0.5029, LR=0.000100
[2025-08-27 09:44:00,574][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056520] [Batch 01080/03080] [00:13:44/00:25:26, 0.763s/it]: train_loss_raw=0.5390, running_loss=0.5042, LR=0.000100
[2025-08-27 09:44:06,682][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056528] [Batch 01088/03080] [00:13:50/00:25:20, 0.763s/it]: train_loss_raw=0.4950, running_loss=0.5015, LR=0.000100
[2025-08-27 09:44:12,738][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056536] [Batch 01096/03080] [00:13:56/00:25:14, 0.763s/it]: train_loss_raw=0.5452, running_loss=0.5017, LR=0.000100
[2025-08-27 09:44:18,762][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056544] [Batch 01104/03080] [00:14:02/00:25:07, 0.763s/it]: train_loss_raw=0.5667, running_loss=0.5021, LR=0.000100
[2025-08-27 09:44:24,802][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056552] [Batch 01112/03080] [00:14:08/00:25:01, 0.763s/it]: train_loss_raw=0.5280, running_loss=0.5005, LR=0.000100
[2025-08-27 09:44:30,924][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056560] [Batch 01120/03080] [00:14:14/00:24:55, 0.763s/it]: train_loss_raw=0.5184, running_loss=0.5027, LR=0.000100
[2025-08-27 09:44:36,967][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056568] [Batch 01128/03080] [00:14:20/00:24:49, 0.763s/it]: train_loss_raw=0.4847, running_loss=0.5021, LR=0.000100
[2025-08-27 09:44:42,959][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056576] [Batch 01136/03080] [00:14:26/00:24:42, 0.763s/it]: train_loss_raw=0.6066, running_loss=0.5031, LR=0.000100
[2025-08-27 09:44:48,982][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056584] [Batch 01144/03080] [00:14:32/00:24:36, 0.763s/it]: train_loss_raw=0.5081, running_loss=0.5038, LR=0.000100
[2025-08-27 09:44:55,054][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056592] [Batch 01152/03080] [00:14:38/00:24:30, 0.763s/it]: train_loss_raw=0.5303, running_loss=0.5026, LR=0.000100
[2025-08-27 09:45:01,069][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056600] [Batch 01160/03080] [00:14:44/00:24:24, 0.763s/it]: train_loss_raw=0.4391, running_loss=0.5033, LR=0.000100
[2025-08-27 09:45:07,219][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056608] [Batch 01168/03080] [00:14:50/00:24:18, 0.763s/it]: train_loss_raw=0.4746, running_loss=0.5043, LR=0.000100
[2025-08-27 09:45:13,171][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056616] [Batch 01176/03080] [00:14:56/00:24:11, 0.763s/it]: train_loss_raw=0.5599, running_loss=0.5033, LR=0.000100
[2025-08-27 09:45:19,234][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056624] [Batch 01184/03080] [00:15:02/00:24:05, 0.763s/it]: train_loss_raw=0.4842, running_loss=0.5036, LR=0.000100
[2025-08-27 09:45:25,271][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056632] [Batch 01192/03080] [00:15:08/00:23:59, 0.763s/it]: train_loss_raw=0.4540, running_loss=0.5037, LR=0.000100
[2025-08-27 09:45:31,317][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056640] [Batch 01200/03080] [00:15:14/00:23:53, 0.762s/it]: train_loss_raw=0.5226, running_loss=0.5049, LR=0.000100
[2025-08-27 09:45:37,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056648] [Batch 01208/03080] [00:15:21/00:23:47, 0.762s/it]: train_loss_raw=0.4599, running_loss=0.5047, LR=0.000100
[2025-08-27 09:45:43,377][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056656] [Batch 01216/03080] [00:15:27/00:23:41, 0.762s/it]: train_loss_raw=0.5456, running_loss=0.5049, LR=0.000100
[2025-08-27 09:45:49,453][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056664] [Batch 01224/03080] [00:15:33/00:23:34, 0.762s/it]: train_loss_raw=0.5341, running_loss=0.5079, LR=0.000100
[2025-08-27 09:45:55,511][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056672] [Batch 01232/03080] [00:15:39/00:23:28, 0.762s/it]: train_loss_raw=0.4564, running_loss=0.5087, LR=0.000100
[2025-08-27 09:46:01,530][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056680] [Batch 01240/03080] [00:15:45/00:23:22, 0.762s/it]: train_loss_raw=0.4832, running_loss=0.5079, LR=0.000100
[2025-08-27 09:46:07,482][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056688] [Batch 01248/03080] [00:15:51/00:23:16, 0.762s/it]: train_loss_raw=0.4882, running_loss=0.5105, LR=0.000100
[2025-08-27 09:46:13,449][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056696] [Batch 01256/03080] [00:15:57/00:23:09, 0.762s/it]: train_loss_raw=0.5666, running_loss=0.5091, LR=0.000100
[2025-08-27 09:46:19,593][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056704] [Batch 01264/03080] [00:16:03/00:23:03, 0.762s/it]: train_loss_raw=0.3949, running_loss=0.5059, LR=0.000100
[2025-08-27 09:46:25,848][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056712] [Batch 01272/03080] [00:16:09/00:22:58, 0.762s/it]: train_loss_raw=0.5272, running_loss=0.5050, LR=0.000100
[2025-08-27 09:46:32,082][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056720] [Batch 01280/03080] [00:16:15/00:22:52, 0.762s/it]: train_loss_raw=0.5131, running_loss=0.5045, LR=0.000100
[2025-08-27 09:46:38,229][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056728] [Batch 01288/03080] [00:16:21/00:22:46, 0.762s/it]: train_loss_raw=0.4880, running_loss=0.5013, LR=0.000100
[2025-08-27 09:46:44,211][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056736] [Batch 01296/03080] [00:16:27/00:22:39, 0.762s/it]: train_loss_raw=0.4415, running_loss=0.4999, LR=0.000100
[2025-08-27 09:46:50,309][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056744] [Batch 01304/03080] [00:16:33/00:22:33, 0.762s/it]: train_loss_raw=0.5382, running_loss=0.5003, LR=0.000100
[2025-08-27 09:46:56,393][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056752] [Batch 01312/03080] [00:16:40/00:22:27, 0.762s/it]: train_loss_raw=0.4421, running_loss=0.5013, LR=0.000100
[2025-08-27 09:47:02,443][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056760] [Batch 01320/03080] [00:16:46/00:22:21, 0.762s/it]: train_loss_raw=0.4640, running_loss=0.5001, LR=0.000100
[2025-08-27 09:47:08,642][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056768] [Batch 01328/03080] [00:16:52/00:22:15, 0.762s/it]: train_loss_raw=0.4653, running_loss=0.5006, LR=0.000100
[2025-08-27 09:47:14,646][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056776] [Batch 01336/03080] [00:16:58/00:22:09, 0.762s/it]: train_loss_raw=0.5132, running_loss=0.5003, LR=0.000100
[2025-08-27 09:47:20,651][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056784] [Batch 01344/03080] [00:17:04/00:22:03, 0.762s/it]: train_loss_raw=0.5593, running_loss=0.5022, LR=0.000100
[2025-08-27 09:47:26,767][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056792] [Batch 01352/03080] [00:17:10/00:21:56, 0.762s/it]: train_loss_raw=0.4251, running_loss=0.4996, LR=0.000100
[2025-08-27 09:47:32,751][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056800] [Batch 01360/03080] [00:17:16/00:21:50, 0.762s/it]: train_loss_raw=0.3795, running_loss=0.4999, LR=0.000100
[2025-08-27 09:47:38,939][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056808] [Batch 01368/03080] [00:17:22/00:21:44, 0.762s/it]: train_loss_raw=0.4603, running_loss=0.4993, LR=0.000100
[2025-08-27 09:47:44,977][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056816] [Batch 01376/03080] [00:17:28/00:21:38, 0.762s/it]: train_loss_raw=0.4650, running_loss=0.4968, LR=0.000100
[2025-08-27 09:47:51,054][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056824] [Batch 01384/03080] [00:17:34/00:21:32, 0.762s/it]: train_loss_raw=0.5174, running_loss=0.4964, LR=0.000100
[2025-08-27 09:47:57,017][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056832] [Batch 01392/03080] [00:17:40/00:21:26, 0.762s/it]: train_loss_raw=0.4537, running_loss=0.4964, LR=0.000100
[2025-08-27 09:48:03,041][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056840] [Batch 01400/03080] [00:17:46/00:21:20, 0.762s/it]: train_loss_raw=0.4841, running_loss=0.4974, LR=0.000100
[2025-08-27 09:48:09,037][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056848] [Batch 01408/03080] [00:17:52/00:21:13, 0.762s/it]: train_loss_raw=0.5601, running_loss=0.4986, LR=0.000100
[2025-08-27 09:48:15,079][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056856] [Batch 01416/03080] [00:17:58/00:21:07, 0.762s/it]: train_loss_raw=0.4363, running_loss=0.4968, LR=0.000100
[2025-08-27 09:48:21,164][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056864] [Batch 01424/03080] [00:18:04/00:21:01, 0.762s/it]: train_loss_raw=0.4099, running_loss=0.4977, LR=0.000100
[2025-08-27 09:48:27,333][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056872] [Batch 01432/03080] [00:18:10/00:20:55, 0.762s/it]: train_loss_raw=0.4635, running_loss=0.4959, LR=0.000100
[2025-08-27 09:48:33,479][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056880] [Batch 01440/03080] [00:18:17/00:20:49, 0.762s/it]: train_loss_raw=0.4959, running_loss=0.4966, LR=0.000100
[2025-08-27 09:48:38,983][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056888] [Batch 01448/03080] [00:18:22/00:20:42, 0.761s/it]: train_loss_raw=0.5255, running_loss=0.4966, LR=0.000100
[2025-08-27 09:48:44,550][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056896] [Batch 01456/03080] [00:18:28/00:20:36, 0.761s/it]: train_loss_raw=0.5788, running_loss=0.4978, LR=0.000100
[2025-08-27 09:48:50,260][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056904] [Batch 01464/03080] [00:18:33/00:20:29, 0.761s/it]: train_loss_raw=0.4615, running_loss=0.5003, LR=0.000100
[2025-08-27 09:48:55,929][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056912] [Batch 01472/03080] [00:18:39/00:20:23, 0.761s/it]: train_loss_raw=0.5878, running_loss=0.5001, LR=0.000100
[2025-08-27 09:49:01,797][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056920] [Batch 01480/03080] [00:18:45/00:20:16, 0.760s/it]: train_loss_raw=0.3840, running_loss=0.4985, LR=0.000100
[2025-08-27 09:49:07,612][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056928] [Batch 01488/03080] [00:18:51/00:20:10, 0.760s/it]: train_loss_raw=0.5217, running_loss=0.4989, LR=0.000100
[2025-08-27 09:49:13,407][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056936] [Batch 01496/03080] [00:18:57/00:20:03, 0.760s/it]: train_loss_raw=0.5275, running_loss=0.4994, LR=0.000100
[2025-08-27 09:49:18,911][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056944] [Batch 01504/03080] [00:19:02/00:19:57, 0.760s/it]: train_loss_raw=0.4302, running_loss=0.4981, LR=0.000100
[2025-08-27 09:49:24,533][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056952] [Batch 01512/03080] [00:19:08/00:19:50, 0.759s/it]: train_loss_raw=0.5802, running_loss=0.4978, LR=0.000100
[2025-08-27 09:49:30,293][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056960] [Batch 01520/03080] [00:19:13/00:19:44, 0.759s/it]: train_loss_raw=0.5106, running_loss=0.4992, LR=0.000100
[2025-08-27 09:49:35,795][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056968] [Batch 01528/03080] [00:19:19/00:19:37, 0.759s/it]: train_loss_raw=0.6234, running_loss=0.5008, LR=0.000100
[2025-08-27 09:49:41,438][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056976] [Batch 01536/03080] [00:19:25/00:19:31, 0.759s/it]: train_loss_raw=0.4836, running_loss=0.5002, LR=0.000100
[2025-08-27 09:49:47,233][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056984] [Batch 01544/03080] [00:19:30/00:19:24, 0.758s/it]: train_loss_raw=0.4175, running_loss=0.5023, LR=0.000100
[2025-08-27 09:49:53,132][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056992] [Batch 01552/03080] [00:19:36/00:19:18, 0.758s/it]: train_loss_raw=0.4829, running_loss=0.5019, LR=0.000100
[2025-08-27 09:49:58,883][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057000] [Batch 01560/03080] [00:19:42/00:19:12, 0.758s/it]: train_loss_raw=0.5435, running_loss=0.5020, LR=0.000100
[2025-08-27 09:50:04,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057008] [Batch 01568/03080] [00:19:48/00:19:06, 0.758s/it]: train_loss_raw=0.5143, running_loss=0.5012, LR=0.000100
[2025-08-27 09:50:10,743][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057016] [Batch 01576/03080] [00:19:54/00:18:59, 0.758s/it]: train_loss_raw=0.5193, running_loss=0.5038, LR=0.000100
[2025-08-27 09:50:16,937][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057024] [Batch 01584/03080] [00:20:00/00:18:53, 0.758s/it]: train_loss_raw=0.4922, running_loss=0.5040, LR=0.000100
[2025-08-27 09:50:23,018][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057032] [Batch 01592/03080] [00:20:06/00:18:47, 0.758s/it]: train_loss_raw=0.5202, running_loss=0.5052, LR=0.000100
[2025-08-27 09:50:29,026][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057040] [Batch 01600/03080] [00:20:12/00:18:41, 0.758s/it]: train_loss_raw=0.5030, running_loss=0.5048, LR=0.000100
[2025-08-27 09:50:35,124][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057048] [Batch 01608/03080] [00:20:18/00:18:35, 0.758s/it]: train_loss_raw=0.5011, running_loss=0.5062, LR=0.000100
[2025-08-27 09:50:41,241][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057056] [Batch 01616/03080] [00:20:24/00:18:29, 0.758s/it]: train_loss_raw=0.4420, running_loss=0.5025, LR=0.000100
[2025-08-27 09:50:47,279][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057064] [Batch 01624/03080] [00:20:30/00:18:23, 0.758s/it]: train_loss_raw=0.5848, running_loss=0.5044, LR=0.000100
[2025-08-27 09:50:53,301][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057072] [Batch 01632/03080] [00:20:36/00:18:17, 0.758s/it]: train_loss_raw=0.4360, running_loss=0.5021, LR=0.000100
[2025-08-27 09:50:59,334][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057080] [Batch 01640/03080] [00:20:42/00:18:11, 0.758s/it]: train_loss_raw=0.5050, running_loss=0.5045, LR=0.000100
[2025-08-27 09:51:05,378][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057088] [Batch 01648/03080] [00:20:49/00:18:05, 0.758s/it]: train_loss_raw=0.5229, running_loss=0.5045, LR=0.000100
[2025-08-27 09:51:11,359][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057096] [Batch 01656/03080] [00:20:54/00:17:59, 0.758s/it]: train_loss_raw=0.5387, running_loss=0.5061, LR=0.000100
[2025-08-27 09:51:17,432][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057104] [Batch 01664/03080] [00:21:01/00:17:53, 0.758s/it]: train_loss_raw=0.4983, running_loss=0.5049, LR=0.000100
[2025-08-27 09:51:23,463][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057112] [Batch 01672/03080] [00:21:07/00:17:47, 0.758s/it]: train_loss_raw=0.5638, running_loss=0.5055, LR=0.000100
[2025-08-27 09:51:29,637][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057120] [Batch 01680/03080] [00:21:13/00:17:41, 0.758s/it]: train_loss_raw=0.5257, running_loss=0.5065, LR=0.000100
[2025-08-27 09:51:35,834][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057128] [Batch 01688/03080] [00:21:19/00:17:35, 0.758s/it]: train_loss_raw=0.5180, running_loss=0.5039, LR=0.000100
[2025-08-27 09:51:41,911][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057136] [Batch 01696/03080] [00:21:25/00:17:29, 0.758s/it]: train_loss_raw=0.4136, running_loss=0.5016, LR=0.000100
[2025-08-27 09:51:47,954][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057144] [Batch 01704/03080] [00:21:31/00:17:22, 0.758s/it]: train_loss_raw=0.4771, running_loss=0.5012, LR=0.000100
[2025-08-27 09:51:53,980][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057152] [Batch 01712/03080] [00:21:37/00:17:16, 0.758s/it]: train_loss_raw=0.5314, running_loss=0.5006, LR=0.000100
[2025-08-27 09:51:59,998][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057160] [Batch 01720/03080] [00:21:43/00:17:10, 0.758s/it]: train_loss_raw=0.4738, running_loss=0.5006, LR=0.000100
[2025-08-27 09:52:06,020][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057168] [Batch 01728/03080] [00:21:49/00:17:04, 0.758s/it]: train_loss_raw=0.3784, running_loss=0.5002, LR=0.000100
[2025-08-27 09:52:12,184][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057176] [Batch 01736/03080] [00:21:55/00:16:58, 0.758s/it]: train_loss_raw=0.5026, running_loss=0.5004, LR=0.000100
[2025-08-27 09:52:18,234][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057184] [Batch 01744/03080] [00:22:01/00:16:52, 0.758s/it]: train_loss_raw=0.5581, running_loss=0.5006, LR=0.000100
[2025-08-27 09:52:24,388][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057192] [Batch 01752/03080] [00:22:08/00:16:46, 0.758s/it]: train_loss_raw=0.4386, running_loss=0.4977, LR=0.000100
[2025-08-27 09:52:30,460][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057200] [Batch 01760/03080] [00:22:14/00:16:40, 0.758s/it]: train_loss_raw=0.4698, running_loss=0.4976, LR=0.000100
[2025-08-27 09:52:36,501][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057208] [Batch 01768/03080] [00:22:20/00:16:34, 0.758s/it]: train_loss_raw=0.5621, running_loss=0.4979, LR=0.000100
[2025-08-27 09:52:42,591][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057216] [Batch 01776/03080] [00:22:26/00:16:28, 0.758s/it]: train_loss_raw=0.4526, running_loss=0.4979, LR=0.000100
[2025-08-27 09:52:48,614][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057224] [Batch 01784/03080] [00:22:32/00:16:22, 0.758s/it]: train_loss_raw=0.5913, running_loss=0.4977, LR=0.000100
[2025-08-27 09:52:54,610][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057232] [Batch 01792/03080] [00:22:38/00:16:16, 0.758s/it]: train_loss_raw=0.5120, running_loss=0.4980, LR=0.000100
[2025-08-27 09:53:00,643][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057240] [Batch 01800/03080] [00:22:44/00:16:10, 0.758s/it]: train_loss_raw=0.4482, running_loss=0.4965, LR=0.000100
[2025-08-27 09:53:06,744][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057248] [Batch 01808/03080] [00:22:50/00:16:04, 0.758s/it]: train_loss_raw=0.5504, running_loss=0.4987, LR=0.000100
[2025-08-27 09:53:12,767][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057256] [Batch 01816/03080] [00:22:56/00:15:58, 0.758s/it]: train_loss_raw=0.5479, running_loss=0.4992, LR=0.000100
[2025-08-27 09:53:19,060][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057264] [Batch 01824/03080] [00:23:02/00:15:52, 0.758s/it]: train_loss_raw=0.5292, running_loss=0.4979, LR=0.000100
[2025-08-27 09:53:25,114][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057272] [Batch 01832/03080] [00:23:08/00:15:46, 0.758s/it]: train_loss_raw=0.5599, running_loss=0.4964, LR=0.000100
[2025-08-27 09:53:31,230][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057280] [Batch 01840/03080] [00:23:14/00:15:40, 0.758s/it]: train_loss_raw=0.4818, running_loss=0.4956, LR=0.000100
[2025-08-27 09:53:37,240][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057288] [Batch 01848/03080] [00:23:20/00:15:33, 0.758s/it]: train_loss_raw=0.4563, running_loss=0.4962, LR=0.000100
[2025-08-27 09:53:43,307][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057296] [Batch 01856/03080] [00:23:26/00:15:27, 0.758s/it]: train_loss_raw=0.4987, running_loss=0.4971, LR=0.000100
[2025-08-27 09:53:49,353][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057304] [Batch 01864/03080] [00:23:32/00:15:21, 0.758s/it]: train_loss_raw=0.5589, running_loss=0.4981, LR=0.000100
[2025-08-27 09:53:55,450][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057312] [Batch 01872/03080] [00:23:39/00:15:15, 0.758s/it]: train_loss_raw=0.4843, running_loss=0.4969, LR=0.000100
[2025-08-27 09:54:01,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057320] [Batch 01880/03080] [00:23:45/00:15:09, 0.758s/it]: train_loss_raw=0.5084, running_loss=0.4963, LR=0.000100
[2025-08-27 09:54:07,561][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057328] [Batch 01888/03080] [00:23:51/00:15:03, 0.758s/it]: train_loss_raw=0.5565, running_loss=0.4959, LR=0.000100
[2025-08-27 09:54:13,619][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057336] [Batch 01896/03080] [00:23:57/00:14:57, 0.758s/it]: train_loss_raw=0.4326, running_loss=0.4924, LR=0.000100
[2025-08-27 09:54:19,709][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057344] [Batch 01904/03080] [00:24:03/00:14:51, 0.758s/it]: train_loss_raw=0.5844, running_loss=0.4921, LR=0.000100
[2025-08-27 09:54:25,861][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057352] [Batch 01912/03080] [00:24:09/00:14:45, 0.758s/it]: train_loss_raw=0.4763, running_loss=0.4897, LR=0.000100
[2025-08-27 09:54:31,868][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057360] [Batch 01920/03080] [00:24:15/00:14:39, 0.758s/it]: train_loss_raw=0.4430, running_loss=0.4890, LR=0.000100
[2025-08-27 09:54:37,907][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057368] [Batch 01928/03080] [00:24:21/00:14:33, 0.758s/it]: train_loss_raw=0.4586, running_loss=0.4893, LR=0.000100
[2025-08-27 09:54:43,845][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057376] [Batch 01936/03080] [00:24:27/00:14:27, 0.758s/it]: train_loss_raw=0.4581, running_loss=0.4895, LR=0.000100
[2025-08-27 09:54:49,973][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057384] [Batch 01944/03080] [00:24:33/00:14:21, 0.758s/it]: train_loss_raw=0.4613, running_loss=0.4904, LR=0.000100
[2025-08-27 09:54:56,075][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057392] [Batch 01952/03080] [00:24:39/00:14:15, 0.758s/it]: train_loss_raw=0.4977, running_loss=0.4922, LR=0.000100
[2025-08-27 09:55:02,118][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057400] [Batch 01960/03080] [00:24:45/00:14:09, 0.758s/it]: train_loss_raw=0.4586, running_loss=0.4933, LR=0.000100
[2025-08-27 09:55:08,134][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057408] [Batch 01968/03080] [00:24:51/00:14:02, 0.758s/it]: train_loss_raw=0.5104, running_loss=0.4949, LR=0.000100
[2025-08-27 09:55:14,404][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057416] [Batch 01976/03080] [00:24:58/00:13:56, 0.758s/it]: train_loss_raw=0.4380, running_loss=0.4951, LR=0.000100
[2025-08-27 09:55:20,227][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057424] [Batch 01984/03080] [00:25:03/00:13:50, 0.758s/it]: train_loss_raw=0.4276, running_loss=0.4919, LR=0.000100
[2025-08-27 09:55:26,281][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057432] [Batch 01992/03080] [00:25:09/00:13:44, 0.758s/it]: train_loss_raw=0.5140, running_loss=0.4921, LR=0.000100
[2025-08-27 09:55:32,324][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057440] [Batch 02000/03080] [00:25:15/00:13:38, 0.758s/it]: train_loss_raw=0.5299, running_loss=0.4934, LR=0.000100
[2025-08-27 09:55:38,400][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057448] [Batch 02008/03080] [00:25:22/00:13:32, 0.758s/it]: train_loss_raw=0.4396, running_loss=0.4935, LR=0.000100
[2025-08-27 09:55:44,581][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057456] [Batch 02016/03080] [00:25:28/00:13:26, 0.758s/it]: train_loss_raw=0.5103, running_loss=0.4939, LR=0.000100
[2025-08-27 09:55:50,710][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057464] [Batch 02024/03080] [00:25:34/00:13:20, 0.758s/it]: train_loss_raw=0.4465, running_loss=0.4919, LR=0.000100
[2025-08-27 09:55:56,767][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057472] [Batch 02032/03080] [00:25:40/00:13:14, 0.758s/it]: train_loss_raw=0.5216, running_loss=0.4930, LR=0.000100
[2025-08-27 09:56:02,811][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057480] [Batch 02040/03080] [00:25:46/00:13:08, 0.758s/it]: train_loss_raw=0.4594, running_loss=0.4930, LR=0.000100
[2025-08-27 09:56:08,964][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057488] [Batch 02048/03080] [00:25:52/00:13:02, 0.758s/it]: train_loss_raw=0.4436, running_loss=0.4924, LR=0.000100
[2025-08-27 09:56:14,983][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057496] [Batch 02056/03080] [00:25:58/00:12:56, 0.758s/it]: train_loss_raw=0.4855, running_loss=0.4932, LR=0.000100
[2025-08-27 09:56:20,961][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057504] [Batch 02064/03080] [00:26:04/00:12:50, 0.758s/it]: train_loss_raw=0.4528, running_loss=0.4936, LR=0.000100
[2025-08-27 09:56:26,640][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057512] [Batch 02072/03080] [00:26:10/00:12:43, 0.758s/it]: train_loss_raw=0.5408, running_loss=0.4938, LR=0.000100
[2025-08-27 09:56:32,548][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057520] [Batch 02080/03080] [00:26:16/00:12:37, 0.758s/it]: train_loss_raw=0.4646, running_loss=0.4920, LR=0.000100
[2025-08-27 09:56:38,484][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057528] [Batch 02088/03080] [00:26:22/00:12:31, 0.758s/it]: train_loss_raw=0.4840, running_loss=0.4901, LR=0.000100
[2025-08-27 09:56:44,552][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057536] [Batch 02096/03080] [00:26:28/00:12:25, 0.758s/it]: train_loss_raw=0.4288, running_loss=0.4894, LR=0.000100
[2025-08-27 09:56:50,735][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057544] [Batch 02104/03080] [00:26:34/00:12:19, 0.758s/it]: train_loss_raw=0.5212, running_loss=0.4891, LR=0.000100
[2025-08-27 09:56:57,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057552] [Batch 02112/03080] [00:26:40/00:12:13, 0.758s/it]: train_loss_raw=0.5251, running_loss=0.4916, LR=0.000100
[2025-08-27 09:57:03,197][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057560] [Batch 02120/03080] [00:26:46/00:12:07, 0.758s/it]: train_loss_raw=0.5165, running_loss=0.4927, LR=0.000100
[2025-08-27 09:57:09,326][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057568] [Batch 02128/03080] [00:26:52/00:12:01, 0.758s/it]: train_loss_raw=0.5333, running_loss=0.4938, LR=0.000100
[2025-08-27 09:57:15,436][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057576] [Batch 02136/03080] [00:26:59/00:11:55, 0.758s/it]: train_loss_raw=0.4841, running_loss=0.4953, LR=0.000100
[2025-08-27 09:57:21,395][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057584] [Batch 02144/03080] [00:27:05/00:11:49, 0.758s/it]: train_loss_raw=0.5562, running_loss=0.4953, LR=0.000100
[2025-08-27 09:57:27,471][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057592] [Batch 02152/03080] [00:27:11/00:11:43, 0.758s/it]: train_loss_raw=0.5006, running_loss=0.4951, LR=0.000100
[2025-08-27 09:57:33,309][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057600] [Batch 02160/03080] [00:27:16/00:11:37, 0.758s/it]: train_loss_raw=0.5338, running_loss=0.4952, LR=0.000100
[2025-08-27 09:57:39,252][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057608] [Batch 02168/03080] [00:27:22/00:11:31, 0.758s/it]: train_loss_raw=0.4975, running_loss=0.4971, LR=0.000100
[2025-08-27 09:57:45,327][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057616] [Batch 02176/03080] [00:27:28/00:11:25, 0.758s/it]: train_loss_raw=0.4927, running_loss=0.4977, LR=0.000100
[2025-08-27 09:57:51,462][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057624] [Batch 02184/03080] [00:27:35/00:11:19, 0.758s/it]: train_loss_raw=0.4542, running_loss=0.4982, LR=0.000100
[2025-08-27 09:57:57,514][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057632] [Batch 02192/03080] [00:27:41/00:11:12, 0.758s/it]: train_loss_raw=0.5011, running_loss=0.4991, LR=0.000100
[2025-08-27 09:58:03,704][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057640] [Batch 02200/03080] [00:27:47/00:11:06, 0.758s/it]: train_loss_raw=0.4841, running_loss=0.4976, LR=0.000100
[2025-08-27 09:58:09,818][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057648] [Batch 02208/03080] [00:27:53/00:11:00, 0.758s/it]: train_loss_raw=0.4989, running_loss=0.4969, LR=0.000100
[2025-08-27 09:58:16,028][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057656] [Batch 02216/03080] [00:27:59/00:10:54, 0.758s/it]: train_loss_raw=0.4371, running_loss=0.4945, LR=0.000100
[2025-08-27 09:58:22,238][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057664] [Batch 02224/03080] [00:28:05/00:10:48, 0.758s/it]: train_loss_raw=0.6164, running_loss=0.4942, LR=0.000100
[2025-08-27 09:58:28,273][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057672] [Batch 02232/03080] [00:28:11/00:10:42, 0.758s/it]: train_loss_raw=0.5188, running_loss=0.4939, LR=0.000100
[2025-08-27 09:58:34,395][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057680] [Batch 02240/03080] [00:28:18/00:10:36, 0.758s/it]: train_loss_raw=0.5726, running_loss=0.4952, LR=0.000100
[2025-08-27 09:58:40,521][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057688] [Batch 02248/03080] [00:28:24/00:10:30, 0.758s/it]: train_loss_raw=0.5759, running_loss=0.4959, LR=0.000100
[2025-08-27 09:58:46,531][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057696] [Batch 02256/03080] [00:28:30/00:10:24, 0.758s/it]: train_loss_raw=0.4788, running_loss=0.4963, LR=0.000100
[2025-08-27 09:58:52,389][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057704] [Batch 02264/03080] [00:28:36/00:10:18, 0.758s/it]: train_loss_raw=0.4884, running_loss=0.4954, LR=0.000100
[2025-08-27 09:58:58,206][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057712] [Batch 02272/03080] [00:28:41/00:10:12, 0.758s/it]: train_loss_raw=0.4636, running_loss=0.4963, LR=0.000100
[2025-08-27 09:59:03,900][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057720] [Batch 02280/03080] [00:28:47/00:10:06, 0.758s/it]: train_loss_raw=0.5251, running_loss=0.4950, LR=0.000100
[2025-08-27 09:59:10,059][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057728] [Batch 02288/03080] [00:28:53/00:10:00, 0.758s/it]: train_loss_raw=0.5404, running_loss=0.4951, LR=0.000100
[2025-08-27 09:59:16,252][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057736] [Batch 02296/03080] [00:28:59/00:09:54, 0.758s/it]: train_loss_raw=0.4484, running_loss=0.4939, LR=0.000100
[2025-08-27 09:59:22,192][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057744] [Batch 02304/03080] [00:29:05/00:09:48, 0.758s/it]: train_loss_raw=0.5963, running_loss=0.4963, LR=0.000100
[2025-08-27 09:59:27,819][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057752] [Batch 02312/03080] [00:29:11/00:09:41, 0.758s/it]: train_loss_raw=0.4234, running_loss=0.4957, LR=0.000100
[2025-08-27 09:59:33,429][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057760] [Batch 02320/03080] [00:29:17/00:09:35, 0.757s/it]: train_loss_raw=0.3741, running_loss=0.4919, LR=0.000100
[2025-08-27 09:59:39,312][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057768] [Batch 02328/03080] [00:29:22/00:09:29, 0.757s/it]: train_loss_raw=0.4985, running_loss=0.4932, LR=0.000100
[2025-08-27 09:59:45,174][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057776] [Batch 02336/03080] [00:29:28/00:09:23, 0.757s/it]: train_loss_raw=0.4965, running_loss=0.4898, LR=0.000100
[2025-08-27 09:59:51,183][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057784] [Batch 02344/03080] [00:29:34/00:09:17, 0.757s/it]: train_loss_raw=0.4556, running_loss=0.4904, LR=0.000100
[2025-08-27 09:59:57,145][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057792] [Batch 02352/03080] [00:29:40/00:09:11, 0.757s/it]: train_loss_raw=0.4691, running_loss=0.4901, LR=0.000100
[2025-08-27 10:00:03,035][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057800] [Batch 02360/03080] [00:29:46/00:09:05, 0.757s/it]: train_loss_raw=0.5173, running_loss=0.4920, LR=0.000100
[2025-08-27 10:00:09,315][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057808] [Batch 02368/03080] [00:29:52/00:08:59, 0.757s/it]: train_loss_raw=0.5284, running_loss=0.4936, LR=0.000100
[2025-08-27 10:00:15,343][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057816] [Batch 02376/03080] [00:29:58/00:08:53, 0.757s/it]: train_loss_raw=0.4849, running_loss=0.4937, LR=0.000100
[2025-08-27 10:00:21,467][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057824] [Batch 02384/03080] [00:30:05/00:08:46, 0.757s/it]: train_loss_raw=0.5095, running_loss=0.4939, LR=0.000100
[2025-08-27 10:00:27,306][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057832] [Batch 02392/03080] [00:30:10/00:08:40, 0.757s/it]: train_loss_raw=0.4005, running_loss=0.4938, LR=0.000100
[2025-08-27 10:00:33,395][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057840] [Batch 02400/03080] [00:30:17/00:08:34, 0.757s/it]: train_loss_raw=0.3915, running_loss=0.4929, LR=0.000100
[2025-08-27 10:00:39,445][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057848] [Batch 02408/03080] [00:30:23/00:08:28, 0.757s/it]: train_loss_raw=0.4302, running_loss=0.4920, LR=0.000100
[2025-08-27 10:00:45,508][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057856] [Batch 02416/03080] [00:30:29/00:08:22, 0.757s/it]: train_loss_raw=0.4774, running_loss=0.4907, LR=0.000100
[2025-08-27 10:00:51,578][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057864] [Batch 02424/03080] [00:30:35/00:08:16, 0.757s/it]: train_loss_raw=0.5716, running_loss=0.4922, LR=0.000100
[2025-08-27 10:00:57,694][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057872] [Batch 02432/03080] [00:30:41/00:08:10, 0.757s/it]: train_loss_raw=0.4809, running_loss=0.4926, LR=0.000100
[2025-08-27 10:01:03,792][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057880] [Batch 02440/03080] [00:30:47/00:08:04, 0.757s/it]: train_loss_raw=0.4689, running_loss=0.4917, LR=0.000100
[2025-08-27 10:01:09,925][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057888] [Batch 02448/03080] [00:30:53/00:07:58, 0.757s/it]: train_loss_raw=0.5597, running_loss=0.4938, LR=0.000100
[2025-08-27 10:01:15,994][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057896] [Batch 02456/03080] [00:30:59/00:07:52, 0.757s/it]: train_loss_raw=0.5250, running_loss=0.4935, LR=0.000100
[2025-08-27 10:01:22,116][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057904] [Batch 02464/03080] [00:31:05/00:07:46, 0.757s/it]: train_loss_raw=0.5784, running_loss=0.4938, LR=0.000100
[2025-08-27 10:01:28,160][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057912] [Batch 02472/03080] [00:31:11/00:07:40, 0.757s/it]: train_loss_raw=0.4640, running_loss=0.4939, LR=0.000100
[2025-08-27 10:01:33,979][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057920] [Batch 02480/03080] [00:31:17/00:07:34, 0.757s/it]: train_loss_raw=0.4610, running_loss=0.4925, LR=0.000100
[2025-08-27 10:01:39,914][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057928] [Batch 02488/03080] [00:31:23/00:07:28, 0.757s/it]: train_loss_raw=0.5304, running_loss=0.4937, LR=0.000100
[2025-08-27 10:01:45,969][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057936] [Batch 02496/03080] [00:31:29/00:07:22, 0.757s/it]: train_loss_raw=0.5867, running_loss=0.4957, LR=0.000100
[2025-08-27 10:01:51,917][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057944] [Batch 02504/03080] [00:31:35/00:07:16, 0.757s/it]: train_loss_raw=0.5013, running_loss=0.4948, LR=0.000100
[2025-08-27 10:01:57,973][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057952] [Batch 02512/03080] [00:31:41/00:07:09, 0.757s/it]: train_loss_raw=0.5396, running_loss=0.4946, LR=0.000100
[2025-08-27 10:02:03,927][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057960] [Batch 02520/03080] [00:31:47/00:07:03, 0.757s/it]: train_loss_raw=0.3920, running_loss=0.4937, LR=0.000100
[2025-08-27 10:02:09,692][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057968] [Batch 02528/03080] [00:31:53/00:06:57, 0.757s/it]: train_loss_raw=0.4394, running_loss=0.4926, LR=0.000100
[2025-08-27 10:02:15,489][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057976] [Batch 02536/03080] [00:31:59/00:06:51, 0.757s/it]: train_loss_raw=0.4618, running_loss=0.4916, LR=0.000100
[2025-08-27 10:02:21,020][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057984] [Batch 02544/03080] [00:32:04/00:06:45, 0.757s/it]: train_loss_raw=0.6094, running_loss=0.4916, LR=0.000100
[2025-08-27 10:02:26,709][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057992] [Batch 02552/03080] [00:32:10/00:06:39, 0.756s/it]: train_loss_raw=0.4037, running_loss=0.4920, LR=0.000100
[2025-08-27 10:02:32,575][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058000] [Batch 02560/03080] [00:32:16/00:06:33, 0.756s/it]: train_loss_raw=0.5286, running_loss=0.4907, LR=0.000100
[2025-08-27 10:02:42,019][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058008] [Batch 02568/03080] [00:32:25/00:06:27, 0.758s/it]: train_loss_raw=0.5204, running_loss=0.4926, LR=0.000100
[2025-08-27 10:02:47,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058016] [Batch 02576/03080] [00:32:31/00:06:21, 0.757s/it]: train_loss_raw=0.5863, running_loss=0.4917, LR=0.000100
[2025-08-27 10:02:53,058][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058024] [Batch 02584/03080] [00:32:36/00:06:15, 0.757s/it]: train_loss_raw=0.4258, running_loss=0.4902, LR=0.000100
[2025-08-27 10:02:58,915][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058032] [Batch 02592/03080] [00:32:42/00:06:09, 0.757s/it]: train_loss_raw=0.5101, running_loss=0.4870, LR=0.000100
[2025-08-27 10:03:04,841][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058040] [Batch 02600/03080] [00:32:48/00:06:03, 0.757s/it]: train_loss_raw=0.4621, running_loss=0.4877, LR=0.000100
[2025-08-27 10:03:10,785][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058048] [Batch 02608/03080] [00:32:54/00:05:57, 0.757s/it]: train_loss_raw=0.4483, running_loss=0.4860, LR=0.000100
[2025-08-27 10:03:16,719][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058056] [Batch 02616/03080] [00:33:00/00:05:51, 0.757s/it]: train_loss_raw=0.5213, running_loss=0.4877, LR=0.000100
[2025-08-27 10:03:22,870][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058064] [Batch 02624/03080] [00:33:06/00:05:45, 0.757s/it]: train_loss_raw=0.3952, running_loss=0.4877, LR=0.000100
[2025-08-27 10:03:28,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058072] [Batch 02632/03080] [00:33:12/00:05:39, 0.757s/it]: train_loss_raw=0.4405, running_loss=0.4873, LR=0.000100
[2025-08-27 10:03:34,993][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058080] [Batch 02640/03080] [00:33:18/00:05:33, 0.757s/it]: train_loss_raw=0.4501, running_loss=0.4854, LR=0.000100
[2025-08-27 10:03:41,038][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058088] [Batch 02648/03080] [00:33:24/00:05:27, 0.757s/it]: train_loss_raw=0.4545, running_loss=0.4848, LR=0.000100
[2025-08-27 10:03:47,039][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058096] [Batch 02656/03080] [00:33:30/00:05:20, 0.757s/it]: train_loss_raw=0.4866, running_loss=0.4861, LR=0.000100
[2025-08-27 10:03:52,782][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058104] [Batch 02664/03080] [00:33:36/00:05:14, 0.757s/it]: train_loss_raw=0.4317, running_loss=0.4843, LR=0.000100
[2025-08-27 10:03:58,624][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058112] [Batch 02672/03080] [00:33:42/00:05:08, 0.757s/it]: train_loss_raw=0.5343, running_loss=0.4839, LR=0.000100
[2025-08-27 10:04:04,678][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058120] [Batch 02680/03080] [00:33:48/00:05:02, 0.757s/it]: train_loss_raw=0.6246, running_loss=0.4883, LR=0.000100
[2025-08-27 10:04:10,740][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058128] [Batch 02688/03080] [00:33:54/00:04:56, 0.757s/it]: train_loss_raw=0.4466, running_loss=0.4885, LR=0.000100
[2025-08-27 10:04:16,564][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058136] [Batch 02696/03080] [00:34:00/00:04:50, 0.757s/it]: train_loss_raw=0.4899, running_loss=0.4896, LR=0.000100
[2025-08-27 10:04:22,375][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058144] [Batch 02704/03080] [00:34:06/00:04:44, 0.757s/it]: train_loss_raw=0.5599, running_loss=0.4926, LR=0.000100
[2025-08-27 10:04:28,117][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058152] [Batch 02712/03080] [00:34:11/00:04:38, 0.757s/it]: train_loss_raw=0.4072, running_loss=0.4884, LR=0.000100
[2025-08-27 10:04:34,048][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058160] [Batch 02720/03080] [00:34:17/00:04:32, 0.757s/it]: train_loss_raw=0.4561, running_loss=0.4873, LR=0.000100
[2025-08-27 10:04:39,831][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058168] [Batch 02728/03080] [00:34:23/00:04:26, 0.756s/it]: train_loss_raw=0.4509, running_loss=0.4883, LR=0.000100
[2025-08-27 10:04:45,663][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058176] [Batch 02736/03080] [00:34:29/00:04:20, 0.756s/it]: train_loss_raw=0.4842, running_loss=0.4868, LR=0.000100
[2025-08-27 10:04:51,610][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058184] [Batch 02744/03080] [00:34:35/00:04:14, 0.756s/it]: train_loss_raw=0.5071, running_loss=0.4893, LR=0.000100
[2025-08-27 10:04:57,626][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058192] [Batch 02752/03080] [00:34:41/00:04:08, 0.756s/it]: train_loss_raw=0.5222, running_loss=0.4884, LR=0.000100
[2025-08-27 10:05:03,731][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058200] [Batch 02760/03080] [00:34:47/00:04:02, 0.756s/it]: train_loss_raw=0.4338, running_loss=0.4896, LR=0.000100
[2025-08-27 10:05:09,803][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058208] [Batch 02768/03080] [00:34:53/00:03:55, 0.756s/it]: train_loss_raw=0.4410, running_loss=0.4905, LR=0.000100
[2025-08-27 10:05:15,866][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058216] [Batch 02776/03080] [00:34:59/00:03:49, 0.756s/it]: train_loss_raw=0.5190, running_loss=0.4917, LR=0.000100
[2025-08-27 10:05:22,030][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058224] [Batch 02784/03080] [00:35:05/00:03:43, 0.756s/it]: train_loss_raw=0.5055, running_loss=0.4916, LR=0.000100
[2025-08-27 10:05:28,048][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058232] [Batch 02792/03080] [00:35:11/00:03:37, 0.756s/it]: train_loss_raw=0.4591, running_loss=0.4905, LR=0.000100
[2025-08-27 10:05:34,266][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058240] [Batch 02800/03080] [00:35:17/00:03:31, 0.756s/it]: train_loss_raw=0.6075, running_loss=0.4918, LR=0.000100
[2025-08-27 10:05:40,501][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058248] [Batch 02808/03080] [00:35:24/00:03:25, 0.756s/it]: train_loss_raw=0.4367, running_loss=0.4915, LR=0.000100
[2025-08-27 10:05:46,448][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058256] [Batch 02816/03080] [00:35:30/00:03:19, 0.756s/it]: train_loss_raw=0.5362, running_loss=0.4925, LR=0.000100
[2025-08-27 10:05:52,540][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058264] [Batch 02824/03080] [00:35:36/00:03:13, 0.756s/it]: train_loss_raw=0.4996, running_loss=0.4941, LR=0.000100
[2025-08-27 10:05:58,482][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058272] [Batch 02832/03080] [00:35:42/00:03:07, 0.756s/it]: train_loss_raw=0.4475, running_loss=0.4916, LR=0.000100
[2025-08-27 10:06:04,152][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058280] [Batch 02840/03080] [00:35:47/00:03:01, 0.756s/it]: train_loss_raw=0.5120, running_loss=0.4926, LR=0.000100
[2025-08-27 10:06:10,185][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058288] [Batch 02848/03080] [00:35:53/00:02:55, 0.756s/it]: train_loss_raw=0.5219, running_loss=0.4936, LR=0.000100
[2025-08-27 10:06:16,359][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058296] [Batch 02856/03080] [00:35:59/00:02:49, 0.756s/it]: train_loss_raw=0.4004, running_loss=0.4921, LR=0.000100
[2025-08-27 10:06:22,301][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058304] [Batch 02864/03080] [00:36:05/00:02:43, 0.756s/it]: train_loss_raw=0.5873, running_loss=0.4938, LR=0.000100
[2025-08-27 10:06:28,260][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058312] [Batch 02872/03080] [00:36:11/00:02:37, 0.756s/it]: train_loss_raw=0.4658, running_loss=0.4913, LR=0.000100
[2025-08-27 10:06:34,313][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058320] [Batch 02880/03080] [00:36:17/00:02:31, 0.756s/it]: train_loss_raw=0.5286, running_loss=0.4931, LR=0.000100
[2025-08-27 10:06:40,418][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058328] [Batch 02888/03080] [00:36:24/00:02:25, 0.756s/it]: train_loss_raw=0.4304, running_loss=0.4929, LR=0.000100
[2025-08-27 10:06:46,113][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058336] [Batch 02896/03080] [00:36:29/00:02:19, 0.756s/it]: train_loss_raw=0.5968, running_loss=0.4940, LR=0.000100
[2025-08-27 10:06:52,807][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058344] [Batch 02904/03080] [00:36:36/00:02:13, 0.756s/it]: train_loss_raw=0.4927, running_loss=0.4916, LR=0.000100
[2025-08-27 10:06:58,781][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058352] [Batch 02912/03080] [00:36:42/00:02:07, 0.756s/it]: train_loss_raw=0.4648, running_loss=0.4884, LR=0.000100
[2025-08-27 10:07:04,670][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058360] [Batch 02920/03080] [00:36:48/00:02:01, 0.756s/it]: train_loss_raw=0.4772, running_loss=0.4866, LR=0.000100
[2025-08-27 10:07:10,732][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058368] [Batch 02928/03080] [00:36:54/00:01:54, 0.756s/it]: train_loss_raw=0.5560, running_loss=0.4873, LR=0.000100
[2025-08-27 10:07:16,719][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058376] [Batch 02936/03080] [00:37:00/00:01:48, 0.756s/it]: train_loss_raw=0.4941, running_loss=0.4876, LR=0.000100
[2025-08-27 10:07:22,636][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058384] [Batch 02944/03080] [00:37:06/00:01:42, 0.756s/it]: train_loss_raw=0.4230, running_loss=0.4897, LR=0.000100
[2025-08-27 10:07:28,401][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058392] [Batch 02952/03080] [00:37:12/00:01:36, 0.756s/it]: train_loss_raw=0.4775, running_loss=0.4889, LR=0.000100
[2025-08-27 10:07:34,184][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058400] [Batch 02960/03080] [00:37:17/00:01:30, 0.756s/it]: train_loss_raw=0.4769, running_loss=0.4870, LR=0.000100
[2025-08-27 10:07:40,110][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058408] [Batch 02968/03080] [00:37:23/00:01:24, 0.756s/it]: train_loss_raw=0.4646, running_loss=0.4885, LR=0.000100
[2025-08-27 10:07:45,950][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058416] [Batch 02976/03080] [00:37:29/00:01:18, 0.756s/it]: train_loss_raw=0.5310, running_loss=0.4898, LR=0.000100
[2025-08-27 10:07:51,727][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058424] [Batch 02984/03080] [00:37:35/00:01:12, 0.756s/it]: train_loss_raw=0.4538, running_loss=0.4900, LR=0.000100
[2025-08-27 10:07:57,622][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058432] [Batch 02992/03080] [00:37:41/00:01:06, 0.756s/it]: train_loss_raw=0.3822, running_loss=0.4895, LR=0.000100
[2025-08-27 10:08:03,682][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058440] [Batch 03000/03080] [00:37:47/00:01:00, 0.756s/it]: train_loss_raw=0.4363, running_loss=0.4883, LR=0.000100
[2025-08-27 10:08:09,772][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058448] [Batch 03008/03080] [00:37:53/00:00:54, 0.756s/it]: train_loss_raw=0.5034, running_loss=0.4885, LR=0.000100
[2025-08-27 10:08:15,862][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058456] [Batch 03016/03080] [00:37:59/00:00:48, 0.756s/it]: train_loss_raw=0.4792, running_loss=0.4867, LR=0.000100
[2025-08-27 10:08:22,027][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058464] [Batch 03024/03080] [00:38:05/00:00:42, 0.756s/it]: train_loss_raw=0.5111, running_loss=0.4867, LR=0.000100
[2025-08-27 10:08:28,133][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058472] [Batch 03032/03080] [00:38:11/00:00:36, 0.756s/it]: train_loss_raw=0.4686, running_loss=0.4858, LR=0.000100
[2025-08-27 10:08:34,305][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058480] [Batch 03040/03080] [00:38:17/00:00:30, 0.756s/it]: train_loss_raw=0.5023, running_loss=0.4864, LR=0.000100
[2025-08-27 10:08:40,183][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058488] [Batch 03048/03080] [00:38:23/00:00:24, 0.756s/it]: train_loss_raw=0.4487, running_loss=0.4859, LR=0.000100
[2025-08-27 10:08:46,244][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058496] [Batch 03056/03080] [00:38:29/00:00:18, 0.756s/it]: train_loss_raw=0.4227, running_loss=0.4855, LR=0.000100
[2025-08-27 10:08:52,227][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058504] [Batch 03064/03080] [00:38:35/00:00:12, 0.756s/it]: train_loss_raw=0.4833, running_loss=0.4850, LR=0.000100
[2025-08-27 10:08:58,225][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058512] [Batch 03072/03080] [00:38:41/00:00:06, 0.756s/it]: train_loss_raw=0.4603, running_loss=0.4858, LR=0.000100
[2025-08-27 10:09:04,274][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058520] [Batch 03080/03080] [00:38:47/00:00:00, 0.756s/it]: train_loss_raw=0.4713, running_loss=0.4873, LR=0.000100
[2025-08-27 10:09:04,811][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-27 10:09:15,975][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00007/00310] [00:00:11/00:07:01, 1.395s/it]
[2025-08-27 10:09:27,213][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00015/00310] [00:00:22/00:06:51, 1.400s/it]
[2025-08-27 10:09:39,866][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00023/00310] [00:00:35/00:06:57, 1.461s/it]
[2025-08-27 10:09:51,506][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00031/00310] [00:00:46/00:06:45, 1.459s/it]
[2025-08-27 10:10:03,232][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00039/00310] [00:00:58/00:06:34, 1.461s/it]
[2025-08-27 10:10:16,049][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00047/00310] [00:01:11/00:06:28, 1.484s/it]
[2025-08-27 10:10:28,278][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00055/00310] [00:01:23/00:06:18, 1.490s/it]
[2025-08-27 10:10:40,244][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00063/00310] [00:01:35/00:06:06, 1.491s/it]
[2025-08-27 10:10:51,890][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00071/00310] [00:01:47/00:05:53, 1.487s/it]
[2025-08-27 10:11:03,544][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00079/00310] [00:01:58/00:05:41, 1.484s/it]
[2025-08-27 10:11:15,524][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00087/00310] [00:02:10/00:05:29, 1.485s/it]
[2025-08-27 10:11:28,016][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00095/00310] [00:02:23/00:05:19, 1.492s/it]
[2025-08-27 10:11:39,568][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00103/00310] [00:02:34/00:05:06, 1.488s/it]
[2025-08-27 10:11:51,801][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00111/00310] [00:02:46/00:04:55, 1.491s/it]
[2025-08-27 10:12:03,369][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00119/00310] [00:02:58/00:04:42, 1.488s/it]
[2025-08-27 10:12:14,823][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00127/00310] [00:03:10/00:04:30, 1.484s/it]
[2025-08-27 10:12:27,260][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00135/00310] [00:03:22/00:04:19, 1.489s/it]
[2025-08-27 10:12:40,048][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00143/00310] [00:03:35/00:04:08, 1.495s/it]
[2025-08-27 10:12:51,144][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00151/00310] [00:03:46/00:03:55, 1.489s/it]
[2025-08-27 10:13:01,624][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00159/00310] [00:03:56/00:03:42, 1.480s/it]
[2025-08-27 10:13:13,215][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00167/00310] [00:04:08/00:03:29, 1.479s/it]
[2025-08-27 10:13:24,366][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00175/00310] [00:04:19/00:03:17, 1.475s/it]
[2025-08-27 10:13:35,579][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00183/00310] [00:04:30/00:03:05, 1.472s/it]
[2025-08-27 10:13:47,809][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00191/00310] [00:04:42/00:02:53, 1.474s/it]
[2025-08-27 10:13:59,601][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00199/00310] [00:04:54/00:02:42, 1.474s/it]
[2025-08-27 10:14:10,722][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00207/00310] [00:05:05/00:02:30, 1.471s/it]
[2025-08-27 10:14:21,729][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00215/00310] [00:05:16/00:02:17, 1.467s/it]
[2025-08-27 10:14:33,990][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00223/00310] [00:05:29/00:02:06, 1.470s/it]
[2025-08-27 10:14:46,842][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00231/00310] [00:05:42/00:01:54, 1.474s/it]
[2025-08-27 10:14:58,562][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00239/00310] [00:05:53/00:01:43, 1.474s/it]
[2025-08-27 10:15:09,455][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00247/00310] [00:06:04/00:01:31, 1.470s/it]
[2025-08-27 10:15:21,636][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00255/00310] [00:06:16/00:01:19, 1.472s/it]
[2025-08-27 10:15:34,055][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00263/00310] [00:06:29/00:01:07, 1.474s/it]
[2025-08-27 10:15:45,821][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00271/00310] [00:06:41/00:00:56, 1.474s/it]
[2025-08-27 10:15:57,686][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00279/00310] [00:06:52/00:00:44, 1.475s/it]
[2025-08-27 10:16:09,878][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00287/00310] [00:07:05/00:00:32, 1.476s/it]
[2025-08-27 10:16:21,619][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00295/00310] [00:07:16/00:00:20, 1.476s/it]
[2025-08-27 10:16:33,271][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00303/00310] [00:07:28/00:00:08, 1.475s/it]
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=0.48726, valid_loss=1.46064
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.530
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.119
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.122
[2025-08-27 10:16:43,071][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.059
[2025-08-27 10:16:43,078][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 14:49:56, remaining time 08:35:14, 00:46:50 per epoch
[2025-08-27 10:16:58,579][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058528] [Batch 00008/03080] [00:00:15/01:37:51, 1.911s/it]: train_loss_raw=0.4938, running_loss=0.4376, LR=0.000100
[2025-08-27 10:17:04,427][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058536] [Batch 00016/03080] [00:00:21/01:07:28, 1.321s/it]: train_loss_raw=0.5374, running_loss=0.4424, LR=0.000100
[2025-08-27 10:17:10,395][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058544] [Batch 00024/03080] [00:00:27/00:57:31, 1.129s/it]: train_loss_raw=0.4574, running_loss=0.4473, LR=0.000100
[2025-08-27 10:17:16,502][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058552] [Batch 00032/03080] [00:00:33/00:52:43, 1.038s/it]: train_loss_raw=0.4180, running_loss=0.4492, LR=0.000100
[2025-08-27 10:17:22,576][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058560] [Batch 00040/03080] [00:00:39/00:49:45, 0.982s/it]: train_loss_raw=0.4290, running_loss=0.4529, LR=0.000100
[2025-08-27 10:17:28,490][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058568] [Batch 00048/03080] [00:00:45/00:47:35, 0.942s/it]: train_loss_raw=0.4752, running_loss=0.4544, LR=0.000100
[2025-08-27 10:17:34,469][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058576] [Batch 00056/03080] [00:00:51/00:46:03, 0.914s/it]: train_loss_raw=0.5276, running_loss=0.4576, LR=0.000100
[2025-08-27 10:17:40,552][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058584] [Batch 00064/03080] [00:00:57/00:44:58, 0.895s/it]: train_loss_raw=0.4809, running_loss=0.4580, LR=0.000100
[2025-08-27 10:17:46,579][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058592] [Batch 00072/03080] [00:01:03/00:44:04, 0.879s/it]: train_loss_raw=0.4720, running_loss=0.4612, LR=0.000100
[2025-08-27 10:17:52,612][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058600] [Batch 00080/03080] [00:01:09/00:43:19, 0.867s/it]: train_loss_raw=0.4800, running_loss=0.4606, LR=0.000100
[2025-08-27 10:17:58,657][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058608] [Batch 00088/03080] [00:01:15/00:42:42, 0.856s/it]: train_loss_raw=0.4969, running_loss=0.4633, LR=0.000100
[2025-08-27 10:18:04,623][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058616] [Batch 00096/03080] [00:01:21/00:42:08, 0.847s/it]: train_loss_raw=0.4273, running_loss=0.4642, LR=0.000100
[2025-08-27 10:18:10,765][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058624] [Batch 00104/03080] [00:01:27/00:41:43, 0.841s/it]: train_loss_raw=0.4029, running_loss=0.4643, LR=0.000100
[2025-08-27 10:18:16,564][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058632] [Batch 00112/03080] [00:01:33/00:41:11, 0.833s/it]: train_loss_raw=0.4708, running_loss=0.4660, LR=0.000100
[2025-08-27 10:18:22,455][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058640] [Batch 00120/03080] [00:01:39/00:40:46, 0.826s/it]: train_loss_raw=0.4768, running_loss=0.4671, LR=0.000100
[2025-08-27 10:18:28,523][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058648] [Batch 00128/03080] [00:01:45/00:40:26, 0.822s/it]: train_loss_raw=0.4855, running_loss=0.4686, LR=0.000100
[2025-08-27 10:18:34,667][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058656] [Batch 00136/03080] [00:01:51/00:40:11, 0.819s/it]: train_loss_raw=0.5938, running_loss=0.4716, LR=0.000100
[2025-08-27 10:18:40,670][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058664] [Batch 00144/03080] [00:01:57/00:39:53, 0.815s/it]: train_loss_raw=0.4643, running_loss=0.4734, LR=0.000100
[2025-08-27 10:18:46,727][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058672] [Batch 00152/03080] [00:02:03/00:39:37, 0.812s/it]: train_loss_raw=0.4185, running_loss=0.4740, LR=0.000100
[2025-08-27 10:18:52,822][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058680] [Batch 00160/03080] [00:02:09/00:39:23, 0.810s/it]: train_loss_raw=0.5209, running_loss=0.4725, LR=0.000100
[2025-08-27 10:18:58,960][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058688] [Batch 00168/03080] [00:02:15/00:39:11, 0.808s/it]: train_loss_raw=0.4637, running_loss=0.4740, LR=0.000100
[2025-08-27 10:19:05,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058696] [Batch 00176/03080] [00:02:21/00:38:58, 0.805s/it]: train_loss_raw=0.4344, running_loss=0.4738, LR=0.000100
[2025-08-27 10:19:11,009][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058704] [Batch 00184/03080] [00:02:27/00:38:44, 0.803s/it]: train_loss_raw=0.4411, running_loss=0.4750, LR=0.000100
[2025-08-27 10:19:16,980][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058712] [Batch 00192/03080] [00:02:33/00:38:31, 0.800s/it]: train_loss_raw=0.3996, running_loss=0.4734, LR=0.000100
[2025-08-27 10:19:22,943][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058720] [Batch 00200/03080] [00:02:39/00:38:19, 0.798s/it]: train_loss_raw=0.5445, running_loss=0.4754, LR=0.000100
[2025-08-27 10:19:28,963][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058728] [Batch 00208/03080] [00:02:45/00:38:07, 0.797s/it]: train_loss_raw=0.5512, running_loss=0.4770, LR=0.000100
[2025-08-27 10:19:34,941][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058736] [Batch 00216/03080] [00:02:51/00:37:55, 0.795s/it]: train_loss_raw=0.4435, running_loss=0.4792, LR=0.000100
[2025-08-27 10:19:41,197][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058744] [Batch 00224/03080] [00:02:57/00:37:48, 0.794s/it]: train_loss_raw=0.4757, running_loss=0.4809, LR=0.000100
[2025-08-27 10:19:47,340][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058752] [Batch 00232/03080] [00:03:04/00:37:39, 0.793s/it]: train_loss_raw=0.5135, running_loss=0.4816, LR=0.000100
[2025-08-27 10:19:53,423][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058760] [Batch 00240/03080] [00:03:10/00:37:29, 0.792s/it]: train_loss_raw=0.5412, running_loss=0.4823, LR=0.000100
[2025-08-27 10:19:59,458][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058768] [Batch 00248/03080] [00:03:16/00:37:20, 0.791s/it]: train_loss_raw=0.5049, running_loss=0.4815, LR=0.000100
[2025-08-27 10:20:05,592][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058776] [Batch 00256/03080] [00:03:22/00:37:11, 0.790s/it]: train_loss_raw=0.5022, running_loss=0.4809, LR=0.000100
[2025-08-27 10:20:11,329][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058784] [Batch 00264/03080] [00:03:28/00:36:59, 0.788s/it]: train_loss_raw=0.5287, running_loss=0.4813, LR=0.000100
[2025-08-27 10:20:17,238][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058792] [Batch 00272/03080] [00:03:33/00:36:48, 0.787s/it]: train_loss_raw=0.4798, running_loss=0.4828, LR=0.000100
[2025-08-27 10:20:23,373][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058800] [Batch 00280/03080] [00:03:40/00:36:40, 0.786s/it]: train_loss_raw=0.4037, running_loss=0.4834, LR=0.000100
[2025-08-27 10:20:29,604][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058808] [Batch 00288/03080] [00:03:46/00:36:34, 0.786s/it]: train_loss_raw=0.4349, running_loss=0.4841, LR=0.000100
[2025-08-27 10:20:35,809][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058816] [Batch 00296/03080] [00:03:52/00:36:26, 0.786s/it]: train_loss_raw=0.4395, running_loss=0.4815, LR=0.000100
[2025-08-27 10:20:41,894][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058824] [Batch 00304/03080] [00:03:58/00:36:18, 0.785s/it]: train_loss_raw=0.4609, running_loss=0.4812, LR=0.000100
[2025-08-27 10:20:47,950][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058832] [Batch 00312/03080] [00:04:04/00:36:10, 0.784s/it]: train_loss_raw=0.5506, running_loss=0.4796, LR=0.000100
[2025-08-27 10:20:53,844][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058840] [Batch 00320/03080] [00:04:10/00:36:01, 0.783s/it]: train_loss_raw=0.4729, running_loss=0.4772, LR=0.000100
[2025-08-27 10:20:59,837][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058848] [Batch 00328/03080] [00:04:16/00:35:52, 0.782s/it]: train_loss_raw=0.6342, running_loss=0.4796, LR=0.000100
[2025-08-27 10:21:06,032][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058856] [Batch 00336/03080] [00:04:22/00:35:45, 0.782s/it]: train_loss_raw=0.5709, running_loss=0.4797, LR=0.000100
[2025-08-27 10:21:12,029][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058864] [Batch 00344/03080] [00:04:28/00:35:37, 0.781s/it]: train_loss_raw=0.5553, running_loss=0.4809, LR=0.000100
[2025-08-27 10:21:18,124][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058872] [Batch 00352/03080] [00:04:34/00:35:29, 0.781s/it]: train_loss_raw=0.4657, running_loss=0.4821, LR=0.000100
[2025-08-27 10:21:24,194][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058880] [Batch 00360/03080] [00:04:40/00:35:22, 0.780s/it]: train_loss_raw=0.5062, running_loss=0.4823, LR=0.000100
[2025-08-27 10:21:29,919][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058888] [Batch 00368/03080] [00:04:46/00:35:12, 0.779s/it]: train_loss_raw=0.4194, running_loss=0.4816, LR=0.000100
[2025-08-27 10:21:35,705][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058896] [Batch 00376/03080] [00:04:52/00:35:02, 0.778s/it]: train_loss_raw=0.5060, running_loss=0.4832, LR=0.000100
[2025-08-27 10:21:41,997][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058904] [Batch 00384/03080] [00:04:58/00:34:57, 0.778s/it]: train_loss_raw=0.4991, running_loss=0.4850, LR=0.000100
[2025-08-27 10:21:48,144][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058912] [Batch 00392/03080] [00:05:04/00:34:50, 0.778s/it]: train_loss_raw=0.3930, running_loss=0.4866, LR=0.000100
[2025-08-27 10:21:54,320][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058920] [Batch 00400/03080] [00:05:11/00:34:43, 0.778s/it]: train_loss_raw=0.3979, running_loss=0.4860, LR=0.000100
[2025-08-27 10:21:59,996][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058928] [Batch 00408/03080] [00:05:16/00:34:34, 0.776s/it]: train_loss_raw=0.4580, running_loss=0.4829, LR=0.000100
[2025-08-27 10:22:05,722][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058936] [Batch 00416/03080] [00:05:22/00:34:24, 0.775s/it]: train_loss_raw=0.4730, running_loss=0.4821, LR=0.000100
[2025-08-27 10:22:11,584][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058944] [Batch 00424/03080] [00:05:28/00:34:16, 0.774s/it]: train_loss_raw=0.4275, running_loss=0.4817, LR=0.000100
[2025-08-27 10:22:17,291][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058952] [Batch 00432/03080] [00:05:34/00:34:07, 0.773s/it]: train_loss_raw=0.5235, running_loss=0.4831, LR=0.000100
[2025-08-27 10:22:23,619][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058960] [Batch 00440/03080] [00:05:40/00:34:01, 0.773s/it]: train_loss_raw=0.5402, running_loss=0.4852, LR=0.000100
[2025-08-27 10:22:29,921][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058968] [Batch 00448/03080] [00:05:46/00:33:56, 0.774s/it]: train_loss_raw=0.4336, running_loss=0.4874, LR=0.000100
[2025-08-27 10:22:36,166][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058976] [Batch 00456/03080] [00:05:52/00:33:50, 0.774s/it]: train_loss_raw=0.5207, running_loss=0.4871, LR=0.000100
[2025-08-27 10:22:41,811][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058984] [Batch 00464/03080] [00:05:58/00:33:41, 0.773s/it]: train_loss_raw=0.5326, running_loss=0.4860, LR=0.000100
[2025-08-27 10:22:47,668][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058992] [Batch 00472/03080] [00:06:04/00:33:33, 0.772s/it]: train_loss_raw=0.4819, running_loss=0.4866, LR=0.000100
[2025-08-27 10:22:53,562][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059000] [Batch 00480/03080] [00:06:10/00:33:25, 0.771s/it]: train_loss_raw=0.4340, running_loss=0.4841, LR=0.000100
[2025-08-27 10:22:59,527][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059008] [Batch 00488/03080] [00:06:16/00:33:18, 0.771s/it]: train_loss_raw=0.4631, running_loss=0.4825, LR=0.000100
[2025-08-27 10:23:05,824][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059016] [Batch 00496/03080] [00:06:22/00:33:12, 0.771s/it]: train_loss_raw=0.4749, running_loss=0.4827, LR=0.000100
[2025-08-27 10:23:11,787][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059024] [Batch 00504/03080] [00:06:28/00:33:05, 0.771s/it]: train_loss_raw=0.5404, running_loss=0.4816, LR=0.000100
[2025-08-27 10:23:17,895][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059032] [Batch 00512/03080] [00:06:34/00:32:59, 0.771s/it]: train_loss_raw=0.4690, running_loss=0.4799, LR=0.000100
[2025-08-27 10:23:23,978][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059040] [Batch 00520/03080] [00:06:40/00:32:52, 0.771s/it]: train_loss_raw=0.4666, running_loss=0.4780, LR=0.000100
[2025-08-27 10:23:30,193][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059048] [Batch 00528/03080] [00:06:46/00:32:46, 0.771s/it]: train_loss_raw=0.5104, running_loss=0.4782, LR=0.000100
[2025-08-27 10:23:36,320][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059056] [Batch 00536/03080] [00:06:53/00:32:40, 0.771s/it]: train_loss_raw=0.5070, running_loss=0.4819, LR=0.000100
[2025-08-27 10:23:42,373][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059064] [Batch 00544/03080] [00:06:59/00:32:33, 0.770s/it]: train_loss_raw=0.5693, running_loss=0.4827, LR=0.000100
[2025-08-27 10:23:48,557][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059072] [Batch 00552/03080] [00:07:05/00:32:27, 0.770s/it]: train_loss_raw=0.5160, running_loss=0.4835, LR=0.000100
[2025-08-27 10:23:54,570][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059080] [Batch 00560/03080] [00:07:11/00:32:20, 0.770s/it]: train_loss_raw=0.4982, running_loss=0.4836, LR=0.000100
[2025-08-27 10:24:00,686][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059088] [Batch 00568/03080] [00:07:17/00:32:14, 0.770s/it]: train_loss_raw=0.6103, running_loss=0.4856, LR=0.000100
[2025-08-27 10:24:06,707][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059096] [Batch 00576/03080] [00:07:23/00:32:07, 0.770s/it]: train_loss_raw=0.5002, running_loss=0.4866, LR=0.000100
[2025-08-27 10:24:12,683][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059104] [Batch 00584/03080] [00:07:29/00:32:00, 0.770s/it]: train_loss_raw=0.4557, running_loss=0.4847, LR=0.000100
[2025-08-27 10:24:18,819][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059112] [Batch 00592/03080] [00:07:35/00:31:54, 0.769s/it]: train_loss_raw=0.4507, running_loss=0.4835, LR=0.000100
[2025-08-27 10:24:24,913][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059120] [Batch 00600/03080] [00:07:41/00:31:48, 0.769s/it]: train_loss_raw=0.4982, running_loss=0.4839, LR=0.000100
[2025-08-27 10:24:30,942][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059128] [Batch 00608/03080] [00:07:47/00:31:41, 0.769s/it]: train_loss_raw=0.4573, running_loss=0.4831, LR=0.000100
[2025-08-27 10:24:37,125][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059136] [Batch 00616/03080] [00:07:53/00:31:35, 0.769s/it]: train_loss_raw=0.4843, running_loss=0.4825, LR=0.000100
[2025-08-27 10:24:43,332][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059144] [Batch 00624/03080] [00:08:00/00:31:29, 0.769s/it]: train_loss_raw=0.3907, running_loss=0.4820, LR=0.000100
[2025-08-27 10:24:49,300][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059152] [Batch 00632/03080] [00:08:06/00:31:22, 0.769s/it]: train_loss_raw=0.4370, running_loss=0.4797, LR=0.000100
[2025-08-27 10:24:55,447][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059160] [Batch 00640/03080] [00:08:12/00:31:16, 0.769s/it]: train_loss_raw=0.4191, running_loss=0.4798, LR=0.000100
[2025-08-27 10:25:01,436][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059168] [Batch 00648/03080] [00:08:18/00:31:09, 0.769s/it]: train_loss_raw=0.4817, running_loss=0.4797, LR=0.000100
[2025-08-27 10:25:07,359][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059176] [Batch 00656/03080] [00:08:24/00:31:02, 0.768s/it]: train_loss_raw=0.4556, running_loss=0.4798, LR=0.000100
[2025-08-27 10:25:12,826][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059184] [Batch 00664/03080] [00:08:29/00:30:53, 0.767s/it]: train_loss_raw=0.4355, running_loss=0.4784, LR=0.000100
[2025-08-27 10:25:18,696][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059192] [Batch 00672/03080] [00:08:35/00:30:46, 0.767s/it]: train_loss_raw=0.4246, running_loss=0.4793, LR=0.000100
[2025-08-27 10:25:24,666][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059200] [Batch 00680/03080] [00:08:41/00:30:40, 0.767s/it]: train_loss_raw=0.4821, running_loss=0.4779, LR=0.000100
[2025-08-27 10:25:30,584][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059208] [Batch 00688/03080] [00:08:47/00:30:33, 0.766s/it]: train_loss_raw=0.5106, running_loss=0.4796, LR=0.000100
[2025-08-27 10:25:36,575][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059216] [Batch 00696/03080] [00:08:53/00:30:26, 0.766s/it]: train_loss_raw=0.5212, running_loss=0.4798, LR=0.000100
[2025-08-27 10:25:42,609][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059224] [Batch 00704/03080] [00:08:59/00:30:20, 0.766s/it]: train_loss_raw=0.4280, running_loss=0.4812, LR=0.000100
[2025-08-27 10:25:48,645][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059232] [Batch 00712/03080] [00:09:05/00:30:13, 0.766s/it]: train_loss_raw=0.5084, running_loss=0.4832, LR=0.000100
[2025-08-27 10:25:54,405][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059240] [Batch 00720/03080] [00:09:11/00:30:06, 0.765s/it]: train_loss_raw=0.4817, running_loss=0.4849, LR=0.000100
[2025-08-27 10:26:00,282][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059248] [Batch 00728/03080] [00:09:16/00:29:59, 0.765s/it]: train_loss_raw=0.4277, running_loss=0.4822, LR=0.000100
[2025-08-27 10:26:06,395][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059256] [Batch 00736/03080] [00:09:23/00:29:53, 0.765s/it]: train_loss_raw=0.4714, running_loss=0.4825, LR=0.000100
[2025-08-27 10:26:12,308][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059264] [Batch 00744/03080] [00:09:29/00:29:46, 0.765s/it]: train_loss_raw=0.4580, running_loss=0.4863, LR=0.000100
[2025-08-27 10:26:18,091][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059272] [Batch 00752/03080] [00:09:34/00:29:39, 0.764s/it]: train_loss_raw=0.4663, running_loss=0.4860, LR=0.000100
[2025-08-27 10:26:23,649][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059280] [Batch 00760/03080] [00:09:40/00:29:31, 0.764s/it]: train_loss_raw=0.4888, running_loss=0.4837, LR=0.000100
[2025-08-27 10:26:29,038][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059288] [Batch 00768/03080] [00:09:45/00:29:23, 0.763s/it]: train_loss_raw=0.3984, running_loss=0.4820, LR=0.000100
[2025-08-27 10:26:34,666][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059296] [Batch 00776/03080] [00:09:51/00:29:15, 0.762s/it]: train_loss_raw=0.6067, running_loss=0.4839, LR=0.000100
[2025-08-27 10:26:40,477][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059304] [Batch 00784/03080] [00:09:57/00:29:08, 0.762s/it]: train_loss_raw=0.4461, running_loss=0.4840, LR=0.000100
[2025-08-27 10:26:46,391][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059312] [Batch 00792/03080] [00:10:03/00:29:02, 0.761s/it]: train_loss_raw=0.5233, running_loss=0.4846, LR=0.000100
[2025-08-27 10:26:52,073][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059320] [Batch 00800/03080] [00:10:08/00:28:55, 0.761s/it]: train_loss_raw=0.5126, running_loss=0.4843, LR=0.000100
[2025-08-27 10:26:58,234][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059328] [Batch 00808/03080] [00:10:14/00:28:49, 0.761s/it]: train_loss_raw=0.4527, running_loss=0.4821, LR=0.000100
[2025-08-27 10:27:03,949][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059336] [Batch 00816/03080] [00:10:20/00:28:42, 0.761s/it]: train_loss_raw=0.5300, running_loss=0.4844, LR=0.000100
[2025-08-27 10:27:09,587][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059344] [Batch 00824/03080] [00:10:26/00:28:34, 0.760s/it]: train_loss_raw=0.4724, running_loss=0.4820, LR=0.000100
[2025-08-27 10:27:15,459][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059352] [Batch 00832/03080] [00:10:32/00:28:28, 0.760s/it]: train_loss_raw=0.5462, running_loss=0.4824, LR=0.000100
[2025-08-27 10:27:21,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059360] [Batch 00840/03080] [00:10:38/00:28:21, 0.760s/it]: train_loss_raw=0.4314, running_loss=0.4823, LR=0.000100
[2025-08-27 10:27:27,456][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059368] [Batch 00848/03080] [00:10:44/00:28:15, 0.760s/it]: train_loss_raw=0.5275, running_loss=0.4832, LR=0.000100
[2025-08-27 10:27:33,378][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059376] [Batch 00856/03080] [00:10:50/00:28:09, 0.759s/it]: train_loss_raw=0.5260, running_loss=0.4827, LR=0.000100
[2025-08-27 10:27:39,380][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059384] [Batch 00864/03080] [00:10:56/00:28:02, 0.759s/it]: train_loss_raw=0.5456, running_loss=0.4833, LR=0.000100
[2025-08-27 10:27:45,353][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059392] [Batch 00872/03080] [00:11:02/00:27:56, 0.759s/it]: train_loss_raw=0.4726, running_loss=0.4822, LR=0.000100
[2025-08-27 10:27:51,354][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059400] [Batch 00880/03080] [00:11:08/00:27:50, 0.759s/it]: train_loss_raw=0.5210, running_loss=0.4811, LR=0.000100
[2025-08-27 10:27:57,401][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059408] [Batch 00888/03080] [00:11:14/00:27:44, 0.759s/it]: train_loss_raw=0.4856, running_loss=0.4825, LR=0.000100
[2025-08-27 10:28:03,404][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059416] [Batch 00896/03080] [00:11:20/00:27:37, 0.759s/it]: train_loss_raw=0.4461, running_loss=0.4812, LR=0.000100
[2025-08-27 10:28:09,396][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059424] [Batch 00904/03080] [00:11:26/00:27:31, 0.759s/it]: train_loss_raw=0.4578, running_loss=0.4803, LR=0.000100
[2025-08-27 10:28:15,366][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059432] [Batch 00912/03080] [00:11:32/00:27:25, 0.759s/it]: train_loss_raw=0.4470, running_loss=0.4774, LR=0.000100
[2025-08-27 10:28:21,408][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059440] [Batch 00920/03080] [00:11:38/00:27:19, 0.759s/it]: train_loss_raw=0.4253, running_loss=0.4757, LR=0.000100
[2025-08-27 10:28:27,371][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059448] [Batch 00928/03080] [00:11:44/00:27:12, 0.759s/it]: train_loss_raw=0.4491, running_loss=0.4764, LR=0.000100
[2025-08-27 10:28:33,372][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059456] [Batch 00936/03080] [00:11:50/00:27:06, 0.759s/it]: train_loss_raw=0.4144, running_loss=0.4754, LR=0.000100
[2025-08-27 10:28:39,339][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059464] [Batch 00944/03080] [00:11:56/00:27:00, 0.759s/it]: train_loss_raw=0.5352, running_loss=0.4775, LR=0.000100
[2025-08-27 10:28:45,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059472] [Batch 00952/03080] [00:12:02/00:26:53, 0.758s/it]: train_loss_raw=0.5960, running_loss=0.4776, LR=0.000100
[2025-08-27 10:28:51,340][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059480] [Batch 00960/03080] [00:12:08/00:26:47, 0.758s/it]: train_loss_raw=0.4208, running_loss=0.4766, LR=0.000100
[2025-08-27 10:28:57,322][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059488] [Batch 00968/03080] [00:12:14/00:26:41, 0.758s/it]: train_loss_raw=0.4103, running_loss=0.4754, LR=0.000100
[2025-08-27 10:29:03,338][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059496] [Batch 00976/03080] [00:12:20/00:26:35, 0.758s/it]: train_loss_raw=0.3859, running_loss=0.4752, LR=0.000100
[2025-08-27 10:29:09,279][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059504] [Batch 00984/03080] [00:12:25/00:26:29, 0.758s/it]: train_loss_raw=0.4958, running_loss=0.4787, LR=0.000100
[2025-08-27 10:29:15,272][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059512] [Batch 00992/03080] [00:12:31/00:26:22, 0.758s/it]: train_loss_raw=0.4640, running_loss=0.4787, LR=0.000100
[2025-08-27 10:29:21,183][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059520] [Batch 01000/03080] [00:12:37/00:26:16, 0.758s/it]: train_loss_raw=0.5734, running_loss=0.4783, LR=0.000100
[2025-08-27 10:29:27,246][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059528] [Batch 01008/03080] [00:12:43/00:26:10, 0.758s/it]: train_loss_raw=0.4558, running_loss=0.4782, LR=0.000100
[2025-08-27 10:29:33,254][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059536] [Batch 01016/03080] [00:12:49/00:26:04, 0.758s/it]: train_loss_raw=0.5061, running_loss=0.4804, LR=0.000100
[2025-08-27 10:29:39,216][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059544] [Batch 01024/03080] [00:12:55/00:25:57, 0.758s/it]: train_loss_raw=0.5379, running_loss=0.4804, LR=0.000100
[2025-08-27 10:29:45,259][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059552] [Batch 01032/03080] [00:13:01/00:25:51, 0.758s/it]: train_loss_raw=0.5631, running_loss=0.4802, LR=0.000100
[2025-08-27 10:29:51,248][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059560] [Batch 01040/03080] [00:13:07/00:25:45, 0.758s/it]: train_loss_raw=0.5000, running_loss=0.4794, LR=0.000100
[2025-08-27 10:29:57,196][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059568] [Batch 01048/03080] [00:13:13/00:25:39, 0.758s/it]: train_loss_raw=0.4575, running_loss=0.4813, LR=0.000100
[2025-08-27 10:30:03,198][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059576] [Batch 01056/03080] [00:13:19/00:25:33, 0.757s/it]: train_loss_raw=0.4475, running_loss=0.4808, LR=0.000100
[2025-08-27 10:30:09,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059584] [Batch 01064/03080] [00:13:25/00:25:27, 0.757s/it]: train_loss_raw=0.5281, running_loss=0.4803, LR=0.000100
[2025-08-27 10:30:15,235][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059592] [Batch 01072/03080] [00:13:31/00:25:20, 0.757s/it]: train_loss_raw=0.4442, running_loss=0.4811, LR=0.000100
[2025-08-27 10:30:21,249][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059600] [Batch 01080/03080] [00:13:37/00:25:14, 0.757s/it]: train_loss_raw=0.4024, running_loss=0.4815, LR=0.000100
[2025-08-27 10:30:27,221][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059608] [Batch 01088/03080] [00:13:43/00:25:08, 0.757s/it]: train_loss_raw=0.4705, running_loss=0.4808, LR=0.000100
[2025-08-27 10:30:33,203][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059616] [Batch 01096/03080] [00:13:49/00:25:02, 0.757s/it]: train_loss_raw=0.5699, running_loss=0.4795, LR=0.000100
[2025-08-27 10:30:39,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059624] [Batch 01104/03080] [00:13:55/00:24:56, 0.757s/it]: train_loss_raw=0.4539, running_loss=0.4797, LR=0.000100
[2025-08-27 10:30:45,363][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059632] [Batch 01112/03080] [00:14:02/00:24:50, 0.757s/it]: train_loss_raw=0.4254, running_loss=0.4793, LR=0.000100
[2025-08-27 10:30:51,235][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059640] [Batch 01120/03080] [00:14:07/00:24:43, 0.757s/it]: train_loss_raw=0.4278, running_loss=0.4805, LR=0.000100
[2025-08-27 10:30:57,112][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059648] [Batch 01128/03080] [00:14:13/00:24:37, 0.757s/it]: train_loss_raw=0.4827, running_loss=0.4779, LR=0.000100
[2025-08-27 10:31:03,126][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059656] [Batch 01136/03080] [00:14:19/00:24:31, 0.757s/it]: train_loss_raw=0.3919, running_loss=0.4787, LR=0.000100
[2025-08-27 10:31:09,036][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059664] [Batch 01144/03080] [00:14:25/00:24:25, 0.757s/it]: train_loss_raw=0.3652, running_loss=0.4805, LR=0.000100
[2025-08-27 10:31:15,074][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059672] [Batch 01152/03080] [00:14:31/00:24:19, 0.757s/it]: train_loss_raw=0.5369, running_loss=0.4810, LR=0.000100
[2025-08-27 10:31:21,094][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059680] [Batch 01160/03080] [00:14:37/00:24:12, 0.757s/it]: train_loss_raw=0.5304, running_loss=0.4807, LR=0.000100
[2025-08-27 10:31:27,188][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059688] [Batch 01168/03080] [00:14:43/00:24:06, 0.757s/it]: train_loss_raw=0.4978, running_loss=0.4814, LR=0.000100
[2025-08-27 10:31:33,302][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059696] [Batch 01176/03080] [00:14:50/00:24:00, 0.757s/it]: train_loss_raw=0.4596, running_loss=0.4810, LR=0.000100
[2025-08-27 10:31:39,387][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059704] [Batch 01184/03080] [00:14:56/00:23:54, 0.757s/it]: train_loss_raw=0.5472, running_loss=0.4813, LR=0.000100
[2025-08-27 10:31:45,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059712] [Batch 01192/03080] [00:15:02/00:23:49, 0.757s/it]: train_loss_raw=0.5308, running_loss=0.4836, LR=0.000100
[2025-08-27 10:31:51,581][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059720] [Batch 01200/03080] [00:15:08/00:23:42, 0.757s/it]: train_loss_raw=0.5077, running_loss=0.4834, LR=0.000100
[2025-08-27 10:31:57,603][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059728] [Batch 01208/03080] [00:15:14/00:23:36, 0.757s/it]: train_loss_raw=0.4666, running_loss=0.4821, LR=0.000100
[2025-08-27 10:32:03,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059736] [Batch 01216/03080] [00:15:20/00:23:30, 0.757s/it]: train_loss_raw=0.4171, running_loss=0.4809, LR=0.000100
[2025-08-27 10:32:09,760][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059744] [Batch 01224/03080] [00:15:26/00:23:24, 0.757s/it]: train_loss_raw=0.4362, running_loss=0.4810, LR=0.000100
[2025-08-27 10:32:15,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059752] [Batch 01232/03080] [00:15:32/00:23:18, 0.757s/it]: train_loss_raw=0.4544, running_loss=0.4804, LR=0.000100
[2025-08-27 10:32:21,045][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059760] [Batch 01240/03080] [00:15:37/00:23:11, 0.756s/it]: train_loss_raw=0.4381, running_loss=0.4802, LR=0.000100
[2025-08-27 10:32:26,575][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059768] [Batch 01248/03080] [00:15:43/00:23:04, 0.756s/it]: train_loss_raw=0.5521, running_loss=0.4800, LR=0.000100
[2025-08-27 10:32:32,566][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059776] [Batch 01256/03080] [00:15:49/00:22:58, 0.756s/it]: train_loss_raw=0.4167, running_loss=0.4779, LR=0.000100
[2025-08-27 10:32:38,556][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059784] [Batch 01264/03080] [00:15:55/00:22:52, 0.756s/it]: train_loss_raw=0.4297, running_loss=0.4766, LR=0.000100
[2025-08-27 10:32:44,460][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059792] [Batch 01272/03080] [00:16:01/00:22:46, 0.756s/it]: train_loss_raw=0.5369, running_loss=0.4768, LR=0.000100
[2025-08-27 10:32:49,919][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059800] [Batch 01280/03080] [00:16:06/00:22:39, 0.755s/it]: train_loss_raw=0.4948, running_loss=0.4791, LR=0.000100
[2025-08-27 10:32:55,709][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059808] [Batch 01288/03080] [00:16:12/00:22:32, 0.755s/it]: train_loss_raw=0.5538, running_loss=0.4803, LR=0.000100
[2025-08-27 10:33:01,705][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059816] [Batch 01296/03080] [00:16:18/00:22:26, 0.755s/it]: train_loss_raw=0.4503, running_loss=0.4806, LR=0.000100
[2025-08-27 10:33:07,694][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059824] [Batch 01304/03080] [00:16:24/00:22:20, 0.755s/it]: train_loss_raw=0.4442, running_loss=0.4802, LR=0.000100
[2025-08-27 10:33:13,731][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059832] [Batch 01312/03080] [00:16:30/00:22:14, 0.755s/it]: train_loss_raw=0.3419, running_loss=0.4781, LR=0.000100
[2025-08-27 10:33:19,814][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059840] [Batch 01320/03080] [00:16:36/00:22:08, 0.755s/it]: train_loss_raw=0.4443, running_loss=0.4794, LR=0.000100
[2025-08-27 10:33:25,866][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059848] [Batch 01328/03080] [00:16:42/00:22:02, 0.755s/it]: train_loss_raw=0.4921, running_loss=0.4792, LR=0.000100
[2025-08-27 10:33:31,855][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059856] [Batch 01336/03080] [00:16:48/00:21:56, 0.755s/it]: train_loss_raw=0.4864, running_loss=0.4796, LR=0.000100
[2025-08-27 10:33:37,820][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059864] [Batch 01344/03080] [00:16:54/00:21:50, 0.755s/it]: train_loss_raw=0.4825, running_loss=0.4810, LR=0.000100
[2025-08-27 10:33:43,825][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059872] [Batch 01352/03080] [00:17:00/00:21:44, 0.755s/it]: train_loss_raw=0.4104, running_loss=0.4809, LR=0.000100
[2025-08-27 10:33:49,816][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059880] [Batch 01360/03080] [00:17:06/00:21:38, 0.755s/it]: train_loss_raw=0.4392, running_loss=0.4803, LR=0.000100
[2025-08-27 10:33:55,823][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059888] [Batch 01368/03080] [00:17:12/00:21:32, 0.755s/it]: train_loss_raw=0.4111, running_loss=0.4802, LR=0.000100
[2025-08-27 10:34:01,967][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059896] [Batch 01376/03080] [00:17:18/00:21:26, 0.755s/it]: train_loss_raw=0.5953, running_loss=0.4818, LR=0.000100
[2025-08-27 10:34:07,921][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059904] [Batch 01384/03080] [00:17:24/00:21:20, 0.755s/it]: train_loss_raw=0.4937, running_loss=0.4795, LR=0.000100
[2025-08-27 10:34:13,716][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059912] [Batch 01392/03080] [00:17:30/00:21:13, 0.755s/it]: train_loss_raw=0.4961, running_loss=0.4779, LR=0.000100
[2025-08-27 10:34:19,686][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059920] [Batch 01400/03080] [00:17:36/00:21:07, 0.755s/it]: train_loss_raw=0.4768, running_loss=0.4763, LR=0.000100
[2025-08-27 10:34:25,693][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059928] [Batch 01408/03080] [00:17:42/00:21:01, 0.755s/it]: train_loss_raw=0.4756, running_loss=0.4766, LR=0.000100
[2025-08-27 10:34:31,693][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059936] [Batch 01416/03080] [00:17:48/00:20:55, 0.755s/it]: train_loss_raw=0.3939, running_loss=0.4749, LR=0.000100
[2025-08-27 10:34:37,970][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059944] [Batch 01424/03080] [00:17:54/00:20:49, 0.755s/it]: train_loss_raw=0.4292, running_loss=0.4734, LR=0.000100
[2025-08-27 10:34:43,996][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059952] [Batch 01432/03080] [00:18:00/00:20:43, 0.755s/it]: train_loss_raw=0.6203, running_loss=0.4746, LR=0.000100
[2025-08-27 10:34:49,757][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059960] [Batch 01440/03080] [00:18:06/00:20:37, 0.754s/it]: train_loss_raw=0.4493, running_loss=0.4747, LR=0.000100
[2025-08-27 10:34:55,272][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059968] [Batch 01448/03080] [00:18:11/00:20:30, 0.754s/it]: train_loss_raw=0.4103, running_loss=0.4751, LR=0.000100
[2025-08-27 10:35:01,333][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059976] [Batch 01456/03080] [00:18:18/00:20:24, 0.754s/it]: train_loss_raw=0.4345, running_loss=0.4765, LR=0.000100
[2025-08-27 10:35:07,365][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059984] [Batch 01464/03080] [00:18:24/00:20:18, 0.754s/it]: train_loss_raw=0.4679, running_loss=0.4775, LR=0.000100
[2025-08-27 10:35:13,155][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059992] [Batch 01472/03080] [00:18:29/00:20:12, 0.754s/it]: train_loss_raw=0.4461, running_loss=0.4767, LR=0.000100
[2025-08-27 10:35:19,091][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060000] [Batch 01480/03080] [00:18:35/00:20:06, 0.754s/it]: train_loss_raw=0.3881, running_loss=0.4756, LR=0.000100
[2025-08-27 10:35:28,517][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060008] [Batch 01488/03080] [00:18:45/00:20:03, 0.756s/it]: train_loss_raw=0.4071, running_loss=0.4743, LR=0.000100
[2025-08-27 10:35:34,594][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060016] [Batch 01496/03080] [00:18:51/00:19:57, 0.756s/it]: train_loss_raw=0.5664, running_loss=0.4737, LR=0.000100
[2025-08-27 10:35:40,579][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060024] [Batch 01504/03080] [00:18:57/00:19:51, 0.756s/it]: train_loss_raw=0.4873, running_loss=0.4739, LR=0.000100
[2025-08-27 10:35:46,563][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060032] [Batch 01512/03080] [00:19:03/00:19:45, 0.756s/it]: train_loss_raw=0.4481, running_loss=0.4720, LR=0.000100
[2025-08-27 10:35:52,583][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060040] [Batch 01520/03080] [00:19:09/00:19:39, 0.756s/it]: train_loss_raw=0.5792, running_loss=0.4752, LR=0.000100
[2025-08-27 10:35:58,530][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060048] [Batch 01528/03080] [00:19:15/00:19:33, 0.756s/it]: train_loss_raw=0.4894, running_loss=0.4749, LR=0.000100
[2025-08-27 10:36:04,586][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060056] [Batch 01536/03080] [00:19:21/00:19:27, 0.756s/it]: train_loss_raw=0.5321, running_loss=0.4770, LR=0.000100
[2025-08-27 10:36:10,570][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060064] [Batch 01544/03080] [00:19:27/00:19:21, 0.756s/it]: train_loss_raw=0.5286, running_loss=0.4795, LR=0.000100
[2025-08-27 10:36:16,553][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060072] [Batch 01552/03080] [00:19:33/00:19:15, 0.756s/it]: train_loss_raw=0.5295, running_loss=0.4820, LR=0.000100
[2025-08-27 10:36:22,561][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060080] [Batch 01560/03080] [00:19:39/00:19:09, 0.756s/it]: train_loss_raw=0.4625, running_loss=0.4799, LR=0.000100
[2025-08-27 10:36:28,634][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060088] [Batch 01568/03080] [00:19:45/00:19:03, 0.756s/it]: train_loss_raw=0.5440, running_loss=0.4828, LR=0.000100
[2025-08-27 10:36:34,550][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060096] [Batch 01576/03080] [00:19:51/00:18:56, 0.756s/it]: train_loss_raw=0.5037, running_loss=0.4820, LR=0.000100
[2025-08-27 10:36:40,310][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060104] [Batch 01584/03080] [00:19:57/00:18:50, 0.756s/it]: train_loss_raw=0.4736, running_loss=0.4832, LR=0.000100
[2025-08-27 10:36:45,949][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060112] [Batch 01592/03080] [00:20:02/00:18:44, 0.755s/it]: train_loss_raw=0.4376, running_loss=0.4816, LR=0.000100
[2025-08-27 10:36:51,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060120] [Batch 01600/03080] [00:20:08/00:18:37, 0.755s/it]: train_loss_raw=0.4817, running_loss=0.4803, LR=0.000100
[2025-08-27 10:36:57,121][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060128] [Batch 01608/03080] [00:20:13/00:18:31, 0.755s/it]: train_loss_raw=0.4155, running_loss=0.4816, LR=0.000100
[2025-08-27 10:37:03,087][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060136] [Batch 01616/03080] [00:20:19/00:18:25, 0.755s/it]: train_loss_raw=0.4990, running_loss=0.4801, LR=0.000100
[2025-08-27 10:37:09,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060144] [Batch 01624/03080] [00:20:25/00:18:18, 0.755s/it]: train_loss_raw=0.5725, running_loss=0.4814, LR=0.000100
[2025-08-27 10:37:15,043][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060152] [Batch 01632/03080] [00:20:31/00:18:12, 0.755s/it]: train_loss_raw=0.5891, running_loss=0.4811, LR=0.000100
[2025-08-27 10:37:21,072][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060160] [Batch 01640/03080] [00:20:37/00:18:06, 0.755s/it]: train_loss_raw=0.4976, running_loss=0.4816, LR=0.000100
[2025-08-27 10:37:26,983][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060168] [Batch 01648/03080] [00:20:43/00:18:00, 0.755s/it]: train_loss_raw=0.4930, running_loss=0.4814, LR=0.000100
[2025-08-27 10:37:32,957][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060176] [Batch 01656/03080] [00:20:49/00:17:54, 0.755s/it]: train_loss_raw=0.5741, running_loss=0.4812, LR=0.000100
[2025-08-27 10:37:38,860][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060184] [Batch 01664/03080] [00:20:55/00:17:48, 0.755s/it]: train_loss_raw=0.3310, running_loss=0.4799, LR=0.000100
[2025-08-27 10:37:44,827][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060192] [Batch 01672/03080] [00:21:01/00:17:42, 0.755s/it]: train_loss_raw=0.5818, running_loss=0.4816, LR=0.000100
[2025-08-27 10:37:50,817][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060200] [Batch 01680/03080] [00:21:07/00:17:36, 0.754s/it]: train_loss_raw=0.5583, running_loss=0.4832, LR=0.000100
[2025-08-27 10:37:56,874][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060208] [Batch 01688/03080] [00:21:13/00:17:30, 0.754s/it]: train_loss_raw=0.5343, running_loss=0.4841, LR=0.000100
[2025-08-27 10:38:02,936][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060216] [Batch 01696/03080] [00:21:19/00:17:24, 0.755s/it]: train_loss_raw=0.4581, running_loss=0.4826, LR=0.000100
[2025-08-27 10:38:08,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060224] [Batch 01704/03080] [00:21:25/00:17:18, 0.754s/it]: train_loss_raw=0.5021, running_loss=0.4829, LR=0.000100
[2025-08-27 10:38:14,964][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060232] [Batch 01712/03080] [00:21:31/00:17:12, 0.754s/it]: train_loss_raw=0.5279, running_loss=0.4816, LR=0.000100
[2025-08-27 10:38:20,983][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060240] [Batch 01720/03080] [00:21:37/00:17:06, 0.754s/it]: train_loss_raw=0.5556, running_loss=0.4793, LR=0.000100
[2025-08-27 10:38:26,997][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060248] [Batch 01728/03080] [00:21:43/00:17:00, 0.754s/it]: train_loss_raw=0.4060, running_loss=0.4798, LR=0.000100
[2025-08-27 10:38:32,979][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060256] [Batch 01736/03080] [00:21:49/00:16:53, 0.754s/it]: train_loss_raw=0.4258, running_loss=0.4812, LR=0.000100
[2025-08-27 10:38:38,959][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060264] [Batch 01744/03080] [00:21:55/00:16:47, 0.754s/it]: train_loss_raw=0.4845, running_loss=0.4837, LR=0.000100
[2025-08-27 10:38:44,952][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060272] [Batch 01752/03080] [00:22:01/00:16:41, 0.754s/it]: train_loss_raw=0.5123, running_loss=0.4847, LR=0.000100
[2025-08-27 10:38:50,954][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060280] [Batch 01760/03080] [00:22:07/00:16:35, 0.754s/it]: train_loss_raw=0.5293, running_loss=0.4857, LR=0.000100
[2025-08-27 10:38:56,967][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060288] [Batch 01768/03080] [00:22:13/00:16:29, 0.754s/it]: train_loss_raw=0.4990, running_loss=0.4873, LR=0.000100
[2025-08-27 10:39:02,972][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060296] [Batch 01776/03080] [00:22:19/00:16:23, 0.754s/it]: train_loss_raw=0.4135, running_loss=0.4859, LR=0.000100
[2025-08-27 10:39:09,020][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060304] [Batch 01784/03080] [00:22:25/00:16:17, 0.754s/it]: train_loss_raw=0.4220, running_loss=0.4831, LR=0.000100
[2025-08-27 10:39:15,051][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060312] [Batch 01792/03080] [00:22:31/00:16:11, 0.754s/it]: train_loss_raw=0.4251, running_loss=0.4810, LR=0.000100
[2025-08-27 10:39:21,079][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060320] [Batch 01800/03080] [00:22:37/00:16:05, 0.754s/it]: train_loss_raw=0.5263, running_loss=0.4807, LR=0.000100
[2025-08-27 10:39:27,094][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060328] [Batch 01808/03080] [00:22:43/00:15:59, 0.754s/it]: train_loss_raw=0.5855, running_loss=0.4814, LR=0.000100
[2025-08-27 10:39:33,122][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060336] [Batch 01816/03080] [00:22:49/00:15:53, 0.754s/it]: train_loss_raw=0.4961, running_loss=0.4811, LR=0.000100
[2025-08-27 10:39:39,151][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060344] [Batch 01824/03080] [00:22:55/00:15:47, 0.754s/it]: train_loss_raw=0.3892, running_loss=0.4797, LR=0.000100
[2025-08-27 10:39:45,095][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060352] [Batch 01832/03080] [00:23:01/00:15:41, 0.754s/it]: train_loss_raw=0.5181, running_loss=0.4781, LR=0.000100
[2025-08-27 10:39:51,034][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060360] [Batch 01840/03080] [00:23:07/00:15:35, 0.754s/it]: train_loss_raw=0.6481, running_loss=0.4795, LR=0.000100
[2025-08-27 10:39:57,017][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060368] [Batch 01848/03080] [00:23:13/00:15:29, 0.754s/it]: train_loss_raw=0.4362, running_loss=0.4819, LR=0.000100
[2025-08-27 10:40:02,700][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060376] [Batch 01856/03080] [00:23:19/00:15:22, 0.754s/it]: train_loss_raw=0.4510, running_loss=0.4797, LR=0.000100
[2025-08-27 10:40:08,697][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060384] [Batch 01864/03080] [00:23:25/00:15:16, 0.754s/it]: train_loss_raw=0.3880, running_loss=0.4790, LR=0.000100
[2025-08-27 10:40:14,722][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060392] [Batch 01872/03080] [00:23:31/00:15:10, 0.754s/it]: train_loss_raw=0.4560, running_loss=0.4808, LR=0.000100
[2025-08-27 10:40:20,840][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060400] [Batch 01880/03080] [00:23:37/00:15:04, 0.754s/it]: train_loss_raw=0.5082, running_loss=0.4764, LR=0.000100
[2025-08-27 10:40:26,779][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060408] [Batch 01888/03080] [00:23:43/00:14:58, 0.754s/it]: train_loss_raw=0.4913, running_loss=0.4776, LR=0.000100
[2025-08-27 10:40:32,823][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060416] [Batch 01896/03080] [00:23:49/00:14:52, 0.754s/it]: train_loss_raw=0.4435, running_loss=0.4784, LR=0.000100
[2025-08-27 10:40:38,824][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060424] [Batch 01904/03080] [00:23:55/00:14:46, 0.754s/it]: train_loss_raw=0.4403, running_loss=0.4776, LR=0.000100
[2025-08-27 10:40:44,841][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060432] [Batch 01912/03080] [00:24:01/00:14:40, 0.754s/it]: train_loss_raw=0.4817, running_loss=0.4763, LR=0.000100
[2025-08-27 10:40:50,771][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060440] [Batch 01920/03080] [00:24:07/00:14:34, 0.754s/it]: train_loss_raw=0.3879, running_loss=0.4781, LR=0.000100
[2025-08-27 10:40:56,763][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060448] [Batch 01928/03080] [00:24:13/00:14:28, 0.754s/it]: train_loss_raw=0.4583, running_loss=0.4796, LR=0.000100
[2025-08-27 10:41:02,860][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060456] [Batch 01936/03080] [00:24:19/00:14:22, 0.754s/it]: train_loss_raw=0.3878, running_loss=0.4805, LR=0.000100
[2025-08-27 10:41:08,902][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060464] [Batch 01944/03080] [00:24:25/00:14:16, 0.754s/it]: train_loss_raw=0.4673, running_loss=0.4799, LR=0.000100
[2025-08-27 10:41:14,930][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060472] [Batch 01952/03080] [00:24:31/00:14:10, 0.754s/it]: train_loss_raw=0.5396, running_loss=0.4775, LR=0.000100
[2025-08-27 10:41:21,178][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060480] [Batch 01960/03080] [00:24:37/00:14:04, 0.754s/it]: train_loss_raw=0.4278, running_loss=0.4772, LR=0.000100
[2025-08-27 10:41:27,318][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060488] [Batch 01968/03080] [00:24:44/00:13:58, 0.754s/it]: train_loss_raw=0.4699, running_loss=0.4770, LR=0.000100
[2025-08-27 10:41:33,387][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060496] [Batch 01976/03080] [00:24:50/00:13:52, 0.754s/it]: train_loss_raw=0.5172, running_loss=0.4761, LR=0.000100
[2025-08-27 10:41:39,396][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060504] [Batch 01984/03080] [00:24:56/00:13:46, 0.754s/it]: train_loss_raw=0.4505, running_loss=0.4738, LR=0.000100
[2025-08-27 10:41:45,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060512] [Batch 01992/03080] [00:25:02/00:13:40, 0.754s/it]: train_loss_raw=0.4303, running_loss=0.4757, LR=0.000100
[2025-08-27 10:41:51,319][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060520] [Batch 02000/03080] [00:25:08/00:13:34, 0.754s/it]: train_loss_raw=0.4391, running_loss=0.4749, LR=0.000100
[2025-08-27 10:41:57,249][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060528] [Batch 02008/03080] [00:25:13/00:13:28, 0.754s/it]: train_loss_raw=0.5560, running_loss=0.4746, LR=0.000100
[2025-08-27 10:42:03,226][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060536] [Batch 02016/03080] [00:25:19/00:13:22, 0.754s/it]: train_loss_raw=0.4755, running_loss=0.4762, LR=0.000100
[2025-08-27 10:42:09,197][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060544] [Batch 02024/03080] [00:25:25/00:13:16, 0.754s/it]: train_loss_raw=0.3645, running_loss=0.4747, LR=0.000100
[2025-08-27 10:42:15,230][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060552] [Batch 02032/03080] [00:25:31/00:13:10, 0.754s/it]: train_loss_raw=0.4304, running_loss=0.4743, LR=0.000100
[2025-08-27 10:42:21,285][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060560] [Batch 02040/03080] [00:25:37/00:13:04, 0.754s/it]: train_loss_raw=0.4793, running_loss=0.4754, LR=0.000100
[2025-08-27 10:42:27,308][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060568] [Batch 02048/03080] [00:25:44/00:12:58, 0.754s/it]: train_loss_raw=0.4747, running_loss=0.4762, LR=0.000100
[2025-08-27 10:42:33,344][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060576] [Batch 02056/03080] [00:25:50/00:12:52, 0.754s/it]: train_loss_raw=0.5774, running_loss=0.4755, LR=0.000100
[2025-08-27 10:42:39,311][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060584] [Batch 02064/03080] [00:25:56/00:12:45, 0.754s/it]: train_loss_raw=0.5727, running_loss=0.4767, LR=0.000100
[2025-08-27 10:42:45,374][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060592] [Batch 02072/03080] [00:26:02/00:12:39, 0.754s/it]: train_loss_raw=0.4586, running_loss=0.4769, LR=0.000100
[2025-08-27 10:42:51,437][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060600] [Batch 02080/03080] [00:26:08/00:12:33, 0.754s/it]: train_loss_raw=0.4674, running_loss=0.4752, LR=0.000100
[2025-08-27 10:42:57,486][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060608] [Batch 02088/03080] [00:26:14/00:12:27, 0.754s/it]: train_loss_raw=0.4503, running_loss=0.4769, LR=0.000100
[2025-08-27 10:43:03,553][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060616] [Batch 02096/03080] [00:26:20/00:12:21, 0.754s/it]: train_loss_raw=0.4724, running_loss=0.4741, LR=0.000100
[2025-08-27 10:43:09,556][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060624] [Batch 02104/03080] [00:26:26/00:12:15, 0.754s/it]: train_loss_raw=0.4452, running_loss=0.4728, LR=0.000100
[2025-08-27 10:43:15,557][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060632] [Batch 02112/03080] [00:26:32/00:12:09, 0.754s/it]: train_loss_raw=0.4343, running_loss=0.4722, LR=0.000100
[2025-08-27 10:43:21,579][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060640] [Batch 02120/03080] [00:26:38/00:12:03, 0.754s/it]: train_loss_raw=0.4104, running_loss=0.4711, LR=0.000100
[2025-08-27 10:43:27,692][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060648] [Batch 02128/03080] [00:26:44/00:11:57, 0.754s/it]: train_loss_raw=0.5250, running_loss=0.4711, LR=0.000100
[2025-08-27 10:43:33,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060656] [Batch 02136/03080] [00:26:50/00:11:51, 0.754s/it]: train_loss_raw=0.5029, running_loss=0.4694, LR=0.000100
[2025-08-27 10:43:39,668][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060664] [Batch 02144/03080] [00:26:56/00:11:45, 0.754s/it]: train_loss_raw=0.3327, running_loss=0.4696, LR=0.000100
[2025-08-27 10:43:45,708][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060672] [Batch 02152/03080] [00:27:02/00:11:39, 0.754s/it]: train_loss_raw=0.5537, running_loss=0.4713, LR=0.000100
[2025-08-27 10:43:51,830][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060680] [Batch 02160/03080] [00:27:08/00:11:33, 0.754s/it]: train_loss_raw=0.5221, running_loss=0.4715, LR=0.000100
[2025-08-27 10:43:58,152][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060688] [Batch 02168/03080] [00:27:14/00:11:27, 0.754s/it]: train_loss_raw=0.4461, running_loss=0.4722, LR=0.000100
[2025-08-27 10:44:04,113][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060696] [Batch 02176/03080] [00:27:20/00:11:21, 0.754s/it]: train_loss_raw=0.5450, running_loss=0.4709, LR=0.000100
[2025-08-27 10:44:09,779][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060704] [Batch 02184/03080] [00:27:26/00:11:15, 0.754s/it]: train_loss_raw=0.3926, running_loss=0.4692, LR=0.000100
[2025-08-27 10:44:15,777][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060712] [Batch 02192/03080] [00:27:32/00:11:09, 0.754s/it]: train_loss_raw=0.4852, running_loss=0.4703, LR=0.000100
[2025-08-27 10:44:21,770][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060720] [Batch 02200/03080] [00:27:38/00:11:03, 0.754s/it]: train_loss_raw=0.4312, running_loss=0.4668, LR=0.000100
[2025-08-27 10:44:27,895][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060728] [Batch 02208/03080] [00:27:44/00:10:57, 0.754s/it]: train_loss_raw=0.5480, running_loss=0.4680, LR=0.000100
[2025-08-27 10:44:33,884][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060736] [Batch 02216/03080] [00:27:50/00:10:51, 0.754s/it]: train_loss_raw=0.4346, running_loss=0.4698, LR=0.000100
[2025-08-27 10:44:39,941][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060744] [Batch 02224/03080] [00:27:56/00:10:45, 0.754s/it]: train_loss_raw=0.4318, running_loss=0.4710, LR=0.000100
[2025-08-27 10:44:46,015][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060752] [Batch 02232/03080] [00:28:02/00:10:39, 0.754s/it]: train_loss_raw=0.4460, running_loss=0.4695, LR=0.000100
[2025-08-27 10:44:52,235][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060760] [Batch 02240/03080] [00:28:08/00:10:33, 0.754s/it]: train_loss_raw=0.4842, running_loss=0.4685, LR=0.000100
[2025-08-27 10:44:58,464][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060768] [Batch 02248/03080] [00:28:15/00:10:27, 0.754s/it]: train_loss_raw=0.4885, running_loss=0.4672, LR=0.000100
[2025-08-27 10:45:04,580][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060776] [Batch 02256/03080] [00:28:21/00:10:21, 0.754s/it]: train_loss_raw=0.4716, running_loss=0.4688, LR=0.000100
[2025-08-27 10:45:10,675][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060784] [Batch 02264/03080] [00:28:27/00:10:15, 0.754s/it]: train_loss_raw=0.5090, running_loss=0.4688, LR=0.000100
[2025-08-27 10:45:16,876][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060792] [Batch 02272/03080] [00:28:33/00:10:09, 0.754s/it]: train_loss_raw=0.5110, running_loss=0.4685, LR=0.000100
[2025-08-27 10:45:23,137][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060800] [Batch 02280/03080] [00:28:39/00:10:03, 0.754s/it]: train_loss_raw=0.5133, running_loss=0.4706, LR=0.000100
[2025-08-27 10:45:29,312][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060808] [Batch 02288/03080] [00:28:46/00:09:57, 0.754s/it]: train_loss_raw=0.4363, running_loss=0.4699, LR=0.000100
[2025-08-27 10:45:35,408][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060816] [Batch 02296/03080] [00:28:52/00:09:51, 0.754s/it]: train_loss_raw=0.4444, running_loss=0.4691, LR=0.000100
[2025-08-27 10:45:41,446][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060824] [Batch 02304/03080] [00:28:58/00:09:45, 0.754s/it]: train_loss_raw=0.5580, running_loss=0.4712, LR=0.000100
[2025-08-27 10:45:47,502][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060832] [Batch 02312/03080] [00:29:04/00:09:39, 0.754s/it]: train_loss_raw=0.3568, running_loss=0.4701, LR=0.000100
[2025-08-27 10:45:53,518][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060840] [Batch 02320/03080] [00:29:10/00:09:33, 0.754s/it]: train_loss_raw=0.5174, running_loss=0.4729, LR=0.000100
[2025-08-27 10:45:59,533][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060848] [Batch 02328/03080] [00:29:16/00:09:27, 0.754s/it]: train_loss_raw=0.4873, running_loss=0.4728, LR=0.000100
[2025-08-27 10:46:05,740][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060856] [Batch 02336/03080] [00:29:22/00:09:21, 0.754s/it]: train_loss_raw=0.4646, running_loss=0.4721, LR=0.000100
[2025-08-27 10:46:11,656][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060864] [Batch 02344/03080] [00:29:28/00:09:15, 0.754s/it]: train_loss_raw=0.4623, running_loss=0.4717, LR=0.000100
[2025-08-27 10:46:17,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060872] [Batch 02352/03080] [00:29:34/00:09:09, 0.754s/it]: train_loss_raw=0.5320, running_loss=0.4750, LR=0.000100
[2025-08-27 10:46:23,117][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060880] [Batch 02360/03080] [00:29:39/00:09:02, 0.754s/it]: train_loss_raw=0.4831, running_loss=0.4751, LR=0.000100
[2025-08-27 10:46:29,070][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060888] [Batch 02368/03080] [00:29:45/00:08:56, 0.754s/it]: train_loss_raw=0.4402, running_loss=0.4747, LR=0.000100
[2025-08-27 10:46:34,856][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060896] [Batch 02376/03080] [00:29:51/00:08:50, 0.754s/it]: train_loss_raw=0.3821, running_loss=0.4750, LR=0.000100
[2025-08-27 10:46:40,596][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060904] [Batch 02384/03080] [00:29:57/00:08:44, 0.754s/it]: train_loss_raw=0.3998, running_loss=0.4743, LR=0.000100
[2025-08-27 10:46:46,178][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060912] [Batch 02392/03080] [00:30:02/00:08:38, 0.754s/it]: train_loss_raw=0.5011, running_loss=0.4762, LR=0.000100
[2025-08-27 10:46:51,992][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060920] [Batch 02400/03080] [00:30:08/00:08:32, 0.754s/it]: train_loss_raw=0.5198, running_loss=0.4739, LR=0.000100
[2025-08-27 10:46:57,862][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060928] [Batch 02408/03080] [00:30:14/00:08:26, 0.754s/it]: train_loss_raw=0.3889, running_loss=0.4701, LR=0.000100
[2025-08-27 10:47:03,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060936] [Batch 02416/03080] [00:30:20/00:08:20, 0.753s/it]: train_loss_raw=0.5436, running_loss=0.4686, LR=0.000100
[2025-08-27 10:47:09,604][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060944] [Batch 02424/03080] [00:30:26/00:08:14, 0.753s/it]: train_loss_raw=0.5005, running_loss=0.4707, LR=0.000100
[2025-08-27 10:47:15,702][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060952] [Batch 02432/03080] [00:30:32/00:08:08, 0.753s/it]: train_loss_raw=0.5388, running_loss=0.4713, LR=0.000100
[2025-08-27 10:47:21,933][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060960] [Batch 02440/03080] [00:30:38/00:08:02, 0.754s/it]: train_loss_raw=0.4717, running_loss=0.4705, LR=0.000100
[2025-08-27 10:47:27,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060968] [Batch 02448/03080] [00:30:44/00:07:56, 0.753s/it]: train_loss_raw=0.4944, running_loss=0.4726, LR=0.000100
[2025-08-27 10:47:33,635][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060976] [Batch 02456/03080] [00:30:50/00:07:50, 0.753s/it]: train_loss_raw=0.4620, running_loss=0.4731, LR=0.000100
[2025-08-27 10:47:39,562][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060984] [Batch 02464/03080] [00:30:56/00:07:44, 0.753s/it]: train_loss_raw=0.4192, running_loss=0.4730, LR=0.000100
[2025-08-27 10:47:45,361][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060992] [Batch 02472/03080] [00:31:02/00:07:37, 0.753s/it]: train_loss_raw=0.4636, running_loss=0.4720, LR=0.000100
[2025-08-27 10:47:51,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061000] [Batch 02480/03080] [00:31:08/00:07:31, 0.753s/it]: train_loss_raw=0.4360, running_loss=0.4712, LR=0.000100
[2025-08-27 10:47:57,210][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061008] [Batch 02488/03080] [00:31:13/00:07:25, 0.753s/it]: train_loss_raw=0.4236, running_loss=0.4722, LR=0.000100
[2025-08-27 10:48:02,999][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061016] [Batch 02496/03080] [00:31:19/00:07:19, 0.753s/it]: train_loss_raw=0.4127, running_loss=0.4690, LR=0.000100
[2025-08-27 10:48:08,784][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061024] [Batch 02504/03080] [00:31:25/00:07:13, 0.753s/it]: train_loss_raw=0.4894, running_loss=0.4698, LR=0.000100
[2025-08-27 10:48:14,655][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061032] [Batch 02512/03080] [00:31:31/00:07:07, 0.753s/it]: train_loss_raw=0.4098, running_loss=0.4667, LR=0.000100
[2025-08-27 10:48:20,506][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061040] [Batch 02520/03080] [00:31:37/00:07:01, 0.753s/it]: train_loss_raw=0.5289, running_loss=0.4687, LR=0.000100
[2025-08-27 10:48:26,472][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061048] [Batch 02528/03080] [00:31:43/00:06:55, 0.753s/it]: train_loss_raw=0.5322, running_loss=0.4705, LR=0.000100
[2025-08-27 10:48:32,437][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061056] [Batch 02536/03080] [00:31:49/00:06:49, 0.753s/it]: train_loss_raw=0.5127, running_loss=0.4703, LR=0.000100
[2025-08-27 10:48:38,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061064] [Batch 02544/03080] [00:31:55/00:06:43, 0.753s/it]: train_loss_raw=0.4290, running_loss=0.4702, LR=0.000100
[2025-08-27 10:48:44,300][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061072] [Batch 02552/03080] [00:32:01/00:06:37, 0.753s/it]: train_loss_raw=0.4655, running_loss=0.4713, LR=0.000100
[2025-08-27 10:48:50,169][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061080] [Batch 02560/03080] [00:32:06/00:06:31, 0.753s/it]: train_loss_raw=0.5910, running_loss=0.4709, LR=0.000100
[2025-08-27 10:48:56,035][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061088] [Batch 02568/03080] [00:32:12/00:06:25, 0.753s/it]: train_loss_raw=0.5153, running_loss=0.4712, LR=0.000100
[2025-08-27 10:49:01,974][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061096] [Batch 02576/03080] [00:32:18/00:06:19, 0.753s/it]: train_loss_raw=0.4912, running_loss=0.4744, LR=0.000100
[2025-08-27 10:49:07,780][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061104] [Batch 02584/03080] [00:32:24/00:06:13, 0.753s/it]: train_loss_raw=0.5691, running_loss=0.4753, LR=0.000100
[2025-08-27 10:49:13,754][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061112] [Batch 02592/03080] [00:32:30/00:06:07, 0.752s/it]: train_loss_raw=0.4739, running_loss=0.4727, LR=0.000100
[2025-08-27 10:49:19,787][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061120] [Batch 02600/03080] [00:32:36/00:06:01, 0.752s/it]: train_loss_raw=0.4592, running_loss=0.4723, LR=0.000100
[2025-08-27 10:49:25,657][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061128] [Batch 02608/03080] [00:32:42/00:05:55, 0.752s/it]: train_loss_raw=0.4381, running_loss=0.4738, LR=0.000100
[2025-08-27 10:49:31,472][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061136] [Batch 02616/03080] [00:32:48/00:05:49, 0.752s/it]: train_loss_raw=0.5199, running_loss=0.4747, LR=0.000100
[2025-08-27 10:49:37,479][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061144] [Batch 02624/03080] [00:32:54/00:05:43, 0.752s/it]: train_loss_raw=0.3936, running_loss=0.4724, LR=0.000100
[2025-08-27 10:49:43,387][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061152] [Batch 02632/03080] [00:33:00/00:05:37, 0.752s/it]: train_loss_raw=0.4638, running_loss=0.4722, LR=0.000100
[2025-08-27 10:49:49,113][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061160] [Batch 02640/03080] [00:33:05/00:05:30, 0.752s/it]: train_loss_raw=0.4763, running_loss=0.4723, LR=0.000100
[2025-08-27 10:49:55,000][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061168] [Batch 02648/03080] [00:33:11/00:05:24, 0.752s/it]: train_loss_raw=0.5189, running_loss=0.4748, LR=0.000100
[2025-08-27 10:50:01,030][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061176] [Batch 02656/03080] [00:33:17/00:05:18, 0.752s/it]: train_loss_raw=0.4330, running_loss=0.4732, LR=0.000100
[2025-08-27 10:50:07,032][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061184] [Batch 02664/03080] [00:33:23/00:05:12, 0.752s/it]: train_loss_raw=0.4977, running_loss=0.4734, LR=0.000100
[2025-08-27 10:50:13,022][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061192] [Batch 02672/03080] [00:33:29/00:05:06, 0.752s/it]: train_loss_raw=0.4689, running_loss=0.4752, LR=0.000100
[2025-08-27 10:50:19,227][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061200] [Batch 02680/03080] [00:33:35/00:05:00, 0.752s/it]: train_loss_raw=0.5123, running_loss=0.4729, LR=0.000100
[2025-08-27 10:50:25,085][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061208] [Batch 02688/03080] [00:33:41/00:04:54, 0.752s/it]: train_loss_raw=0.5187, running_loss=0.4746, LR=0.000100
[2025-08-27 10:50:30,807][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061216] [Batch 02696/03080] [00:33:47/00:04:48, 0.752s/it]: train_loss_raw=0.5569, running_loss=0.4730, LR=0.000100
[2025-08-27 10:50:36,303][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061224] [Batch 02704/03080] [00:33:53/00:04:42, 0.752s/it]: train_loss_raw=0.5077, running_loss=0.4731, LR=0.000100
[2025-08-27 10:50:42,019][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061232] [Batch 02712/03080] [00:33:58/00:04:36, 0.752s/it]: train_loss_raw=0.4059, running_loss=0.4729, LR=0.000100
[2025-08-27 10:50:48,094][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061240] [Batch 02720/03080] [00:34:04/00:04:30, 0.752s/it]: train_loss_raw=0.5268, running_loss=0.4728, LR=0.000100
[2025-08-27 10:50:53,897][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061248] [Batch 02728/03080] [00:34:10/00:04:24, 0.752s/it]: train_loss_raw=0.4498, running_loss=0.4716, LR=0.000100
[2025-08-27 10:50:59,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061256] [Batch 02736/03080] [00:34:16/00:04:18, 0.752s/it]: train_loss_raw=0.4836, running_loss=0.4712, LR=0.000100
[2025-08-27 10:51:05,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061264] [Batch 02744/03080] [00:34:22/00:04:12, 0.752s/it]: train_loss_raw=0.5211, running_loss=0.4712, LR=0.000100
[2025-08-27 10:51:11,622][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061272] [Batch 02752/03080] [00:34:28/00:04:06, 0.752s/it]: train_loss_raw=0.5439, running_loss=0.4708, LR=0.000100
[2025-08-27 10:51:17,632][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061280] [Batch 02760/03080] [00:34:34/00:04:00, 0.752s/it]: train_loss_raw=0.4510, running_loss=0.4698, LR=0.000100
[2025-08-27 10:51:23,729][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061288] [Batch 02768/03080] [00:34:40/00:03:54, 0.752s/it]: train_loss_raw=0.4139, running_loss=0.4707, LR=0.000100
[2025-08-27 10:51:29,776][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061296] [Batch 02776/03080] [00:34:46/00:03:48, 0.752s/it]: train_loss_raw=0.4127, running_loss=0.4730, LR=0.000100
[2025-08-27 10:51:35,830][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061304] [Batch 02784/03080] [00:34:52/00:03:42, 0.752s/it]: train_loss_raw=0.4902, running_loss=0.4722, LR=0.000100
[2025-08-27 10:51:41,839][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061312] [Batch 02792/03080] [00:34:58/00:03:36, 0.752s/it]: train_loss_raw=0.4378, running_loss=0.4726, LR=0.000100
[2025-08-27 10:51:48,015][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061320] [Batch 02800/03080] [00:35:04/00:03:30, 0.752s/it]: train_loss_raw=0.4944, running_loss=0.4734, LR=0.000100
[2025-08-27 10:51:53,929][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061328] [Batch 02808/03080] [00:35:10/00:03:24, 0.752s/it]: train_loss_raw=0.4986, running_loss=0.4742, LR=0.000100
[2025-08-27 10:52:00,058][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061336] [Batch 02816/03080] [00:35:16/00:03:18, 0.752s/it]: train_loss_raw=0.4621, running_loss=0.4745, LR=0.000100
[2025-08-27 10:52:06,090][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061344] [Batch 02824/03080] [00:35:22/00:03:12, 0.752s/it]: train_loss_raw=0.4696, running_loss=0.4748, LR=0.000100
[2025-08-27 10:52:12,246][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061352] [Batch 02832/03080] [00:35:28/00:03:06, 0.752s/it]: train_loss_raw=0.4222, running_loss=0.4742, LR=0.000100
[2025-08-27 10:52:18,543][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061360] [Batch 02840/03080] [00:35:35/00:03:00, 0.752s/it]: train_loss_raw=0.4364, running_loss=0.4726, LR=0.000100
[2025-08-27 10:52:24,199][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061368] [Batch 02848/03080] [00:35:40/00:02:54, 0.752s/it]: train_loss_raw=0.4410, running_loss=0.4715, LR=0.000100
[2025-08-27 10:52:30,187][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061376] [Batch 02856/03080] [00:35:46/00:02:48, 0.752s/it]: train_loss_raw=0.4800, running_loss=0.4721, LR=0.000100
[2025-08-27 10:52:36,193][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061384] [Batch 02864/03080] [00:35:52/00:02:42, 0.752s/it]: train_loss_raw=0.4088, running_loss=0.4720, LR=0.000100
[2025-08-27 10:52:42,205][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061392] [Batch 02872/03080] [00:35:58/00:02:36, 0.752s/it]: train_loss_raw=0.3645, running_loss=0.4731, LR=0.000100
[2025-08-27 10:52:48,342][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061400] [Batch 02880/03080] [00:36:05/00:02:30, 0.752s/it]: train_loss_raw=0.5138, running_loss=0.4737, LR=0.000100
[2025-08-27 10:52:54,342][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061408] [Batch 02888/03080] [00:36:11/00:02:24, 0.752s/it]: train_loss_raw=0.4635, running_loss=0.4752, LR=0.000100
[2025-08-27 10:53:00,615][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061416] [Batch 02896/03080] [00:36:17/00:02:18, 0.752s/it]: train_loss_raw=0.4293, running_loss=0.4735, LR=0.000100
[2025-08-27 10:53:06,864][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061424] [Batch 02904/03080] [00:36:23/00:02:12, 0.752s/it]: train_loss_raw=0.4207, running_loss=0.4728, LR=0.000100
[2025-08-27 10:53:12,845][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061432] [Batch 02912/03080] [00:36:29/00:02:06, 0.752s/it]: train_loss_raw=0.5011, running_loss=0.4750, LR=0.000100
[2025-08-27 10:53:18,963][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061440] [Batch 02920/03080] [00:36:35/00:02:00, 0.752s/it]: train_loss_raw=0.6150, running_loss=0.4751, LR=0.000100
[2025-08-27 10:53:24,983][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061448] [Batch 02928/03080] [00:36:41/00:01:54, 0.752s/it]: train_loss_raw=0.4247, running_loss=0.4742, LR=0.000100
[2025-08-27 10:53:31,061][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061456] [Batch 02936/03080] [00:36:47/00:01:48, 0.752s/it]: train_loss_raw=0.5726, running_loss=0.4740, LR=0.000100
[2025-08-27 10:53:37,089][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061464] [Batch 02944/03080] [00:36:53/00:01:42, 0.752s/it]: train_loss_raw=0.5059, running_loss=0.4737, LR=0.000100
[2025-08-27 10:53:43,136][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061472] [Batch 02952/03080] [00:36:59/00:01:36, 0.752s/it]: train_loss_raw=0.5437, running_loss=0.4728, LR=0.000100
[2025-08-27 10:53:49,138][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061480] [Batch 02960/03080] [00:37:05/00:01:30, 0.752s/it]: train_loss_raw=0.3696, running_loss=0.4713, LR=0.000100
[2025-08-27 10:53:55,192][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061488] [Batch 02968/03080] [00:37:11/00:01:24, 0.752s/it]: train_loss_raw=0.4099, running_loss=0.4706, LR=0.000100
[2025-08-27 10:54:01,375][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061496] [Batch 02976/03080] [00:37:18/00:01:18, 0.752s/it]: train_loss_raw=0.4671, running_loss=0.4705, LR=0.000100
[2025-08-27 10:54:07,440][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061504] [Batch 02984/03080] [00:37:24/00:01:12, 0.752s/it]: train_loss_raw=0.4463, running_loss=0.4711, LR=0.000100
[2025-08-27 10:54:13,487][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061512] [Batch 02992/03080] [00:37:30/00:01:06, 0.752s/it]: train_loss_raw=0.5146, running_loss=0.4716, LR=0.000100
[2025-08-27 10:54:19,556][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061520] [Batch 03000/03080] [00:37:36/00:01:00, 0.752s/it]: train_loss_raw=0.4856, running_loss=0.4735, LR=0.000100
[2025-08-27 10:54:25,659][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061528] [Batch 03008/03080] [00:37:42/00:00:54, 0.752s/it]: train_loss_raw=0.5867, running_loss=0.4736, LR=0.000100
[2025-08-27 10:54:31,838][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061536] [Batch 03016/03080] [00:37:48/00:00:48, 0.752s/it]: train_loss_raw=0.4743, running_loss=0.4688, LR=0.000100
[2025-08-27 10:54:37,822][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061544] [Batch 03024/03080] [00:37:54/00:00:42, 0.752s/it]: train_loss_raw=0.4990, running_loss=0.4681, LR=0.000100
[2025-08-27 10:54:43,960][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061552] [Batch 03032/03080] [00:38:00/00:00:36, 0.752s/it]: train_loss_raw=0.4421, running_loss=0.4661, LR=0.000100
[2025-08-27 10:54:49,897][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061560] [Batch 03040/03080] [00:38:06/00:00:30, 0.752s/it]: train_loss_raw=0.4994, running_loss=0.4675, LR=0.000100
[2025-08-27 10:54:56,162][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061568] [Batch 03048/03080] [00:38:12/00:00:24, 0.752s/it]: train_loss_raw=0.3849, running_loss=0.4653, LR=0.000100
[2025-08-27 10:55:02,140][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061576] [Batch 03056/03080] [00:38:18/00:00:18, 0.752s/it]: train_loss_raw=0.5016, running_loss=0.4663, LR=0.000100
[2025-08-27 10:55:08,118][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061584] [Batch 03064/03080] [00:38:24/00:00:12, 0.752s/it]: train_loss_raw=0.3994, running_loss=0.4653, LR=0.000100
[2025-08-27 10:55:14,158][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061592] [Batch 03072/03080] [00:38:30/00:00:06, 0.752s/it]: train_loss_raw=0.4677, running_loss=0.4649, LR=0.000100
[2025-08-27 10:55:25,109][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061600] [Batch 03080/03080] [00:38:41/00:00:00, 0.754s/it]: train_loss_raw=0.4702, running_loss=0.4666, LR=0.000100
[2025-08-27 10:55:25,677][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-27 10:55:36,621][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00007/00310] [00:00:10/00:06:53, 1.368s/it]
[2025-08-27 10:55:47,424][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00015/00310] [00:00:21/00:06:39, 1.359s/it]
[2025-08-27 10:55:59,830][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00023/00310] [00:00:34/00:06:46, 1.423s/it]
[2025-08-27 10:56:12,427][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00031/00310] [00:00:46/00:06:46, 1.461s/it]
[2025-08-27 10:56:24,162][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00039/00310] [00:00:58/00:06:34, 1.462s/it]
[2025-08-27 10:56:36,364][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00047/00310] [00:01:10/00:06:25, 1.473s/it]
[2025-08-27 10:56:47,928][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00055/00310] [00:01:22/00:06:13, 1.469s/it]
[2025-08-27 10:56:59,974][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00063/00310] [00:01:34/00:06:02, 1.473s/it]
[2025-08-27 10:57:11,785][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00071/00310] [00:01:46/00:05:50, 1.474s/it]
[2025-08-27 10:57:23,246][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00079/00310] [00:01:57/00:05:38, 1.470s/it]
[2025-08-27 10:57:35,605][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00087/00310] [00:02:09/00:05:27, 1.476s/it]
[2025-08-27 10:57:48,515][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00095/00310] [00:02:22/00:05:18, 1.488s/it]
[2025-08-27 10:58:01,119][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00103/00310] [00:02:35/00:05:07, 1.495s/it]
[2025-08-27 10:58:14,458][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00111/00310] [00:02:48/00:04:58, 1.507s/it]
[2025-08-27 10:58:26,061][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00119/00310] [00:03:00/00:04:45, 1.503s/it]
[2025-08-27 10:58:38,625][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00127/00310] [00:03:12/00:04:34, 1.507s/it]
[2025-08-27 10:58:51,607][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00135/00310] [00:03:25/00:04:23, 1.514s/it]
[2025-08-27 10:59:03,421][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00143/00310] [00:03:37/00:04:11, 1.512s/it]
[2025-08-27 10:59:14,534][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00151/00310] [00:03:48/00:03:57, 1.506s/it]
[2025-08-27 10:59:24,948][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00159/00310] [00:03:59/00:03:44, 1.495s/it]
[2025-08-27 10:59:36,417][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00167/00310] [00:04:10/00:03:31, 1.492s/it]
[2025-08-27 10:59:47,061][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00175/00310] [00:04:21/00:03:19, 1.485s/it]
[2025-08-27 10:59:58,238][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00183/00310] [00:04:32/00:03:06, 1.481s/it]
[2025-08-27 11:00:10,458][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00191/00310] [00:04:44/00:02:55, 1.483s/it]
[2025-08-27 11:00:22,039][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00199/00310] [00:04:56/00:02:42, 1.482s/it]
[2025-08-27 11:00:33,698][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00207/00310] [00:05:08/00:02:31, 1.481s/it]
[2025-08-27 11:00:44,410][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00215/00310] [00:05:18/00:02:18, 1.476s/it]
[2025-08-27 11:00:56,345][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00223/00310] [00:05:30/00:02:06, 1.476s/it]
[2025-08-27 11:01:08,658][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00231/00310] [00:05:42/00:01:55, 1.478s/it]
[2025-08-27 11:01:20,537][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00239/00310] [00:05:54/00:01:43, 1.479s/it]
[2025-08-27 11:01:31,563][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00247/00310] [00:06:05/00:01:31, 1.475s/it]
[2025-08-27 11:01:43,000][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00255/00310] [00:06:17/00:01:19, 1.474s/it]
[2025-08-27 11:01:55,237][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00263/00310] [00:06:29/00:01:07, 1.476s/it]
[2025-08-27 11:02:07,449][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00271/00310] [00:06:41/00:00:56, 1.477s/it]
[2025-08-27 11:02:19,731][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00279/00310] [00:06:54/00:00:44, 1.479s/it]
[2025-08-27 11:02:31,084][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00287/00310] [00:07:05/00:00:32, 1.477s/it]
[2025-08-27 11:02:42,565][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00295/00310] [00:07:16/00:00:20, 1.476s/it]
[2025-08-27 11:02:53,873][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00303/00310] [00:07:28/00:00:08, 1.474s/it]
[2025-08-27 11:03:02,229][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=0.46662, valid_loss=1.45501
[2025-08-27 11:03:02,229][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-27 11:03:02,230][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.520
[2025-08-27 11:03:02,230][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.123
[2025-08-27 11:03:02,230][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.125
[2025-08-27 11:03:02,230][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.064
[2025-08-27 11:03:02,245][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 15:36:16, remaining time 07:48:08, 00:46:48 per epoch
[2025-08-27 11:03:10,937][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061608] [Batch 00008/03080] [00:00:08/00:53:31, 1.045s/it]: train_loss_raw=0.4307, running_loss=0.4015, LR=0.000100
[2025-08-27 11:03:16,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061616] [Batch 00016/03080] [00:00:14/00:45:41, 0.895s/it]: train_loss_raw=0.3898, running_loss=0.4042, LR=0.000100
[2025-08-27 11:03:22,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061624] [Batch 00024/03080] [00:00:20/00:43:12, 0.848s/it]: train_loss_raw=0.5036, running_loss=0.4074, LR=0.000100
[2025-08-27 11:03:28,953][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061632] [Batch 00032/03080] [00:00:26/00:41:52, 0.824s/it]: train_loss_raw=0.4112, running_loss=0.4088, LR=0.000100
[2025-08-27 11:03:35,006][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061640] [Batch 00040/03080] [00:00:32/00:41:04, 0.811s/it]: train_loss_raw=0.4855, running_loss=0.4158, LR=0.000100
[2025-08-27 11:03:40,999][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061648] [Batch 00048/03080] [00:00:38/00:40:27, 0.800s/it]: train_loss_raw=0.4650, running_loss=0.4167, LR=0.000100
[2025-08-27 11:03:47,119][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061656] [Batch 00056/03080] [00:00:44/00:40:05, 0.795s/it]: train_loss_raw=0.4904, running_loss=0.4174, LR=0.000100
[2025-08-27 11:03:53,002][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061664] [Batch 00064/03080] [00:00:50/00:39:36, 0.788s/it]: train_loss_raw=0.4985, running_loss=0.4206, LR=0.000100
[2025-08-27 11:03:59,024][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061672] [Batch 00072/03080] [00:00:56/00:39:18, 0.784s/it]: train_loss_raw=0.3648, running_loss=0.4211, LR=0.000100
[2025-08-27 11:04:04,965][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061680] [Batch 00080/03080] [00:01:02/00:38:59, 0.780s/it]: train_loss_raw=0.4229, running_loss=0.4231, LR=0.000100
[2025-08-27 11:04:10,909][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061688] [Batch 00088/03080] [00:01:08/00:38:43, 0.777s/it]: train_loss_raw=0.4364, running_loss=0.4261, LR=0.000100
[2025-08-27 11:04:16,783][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061696] [Batch 00096/03080] [00:01:14/00:38:26, 0.773s/it]: train_loss_raw=0.4546, running_loss=0.4276, LR=0.000100
[2025-08-27 11:04:22,216][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061704] [Batch 00104/03080] [00:01:19/00:37:58, 0.766s/it]: train_loss_raw=0.4185, running_loss=0.4293, LR=0.000100
[2025-08-27 11:04:28,239][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061712] [Batch 00112/03080] [00:01:25/00:37:50, 0.765s/it]: train_loss_raw=0.4778, running_loss=0.4304, LR=0.000100
[2025-08-27 11:04:34,246][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061720] [Batch 00120/03080] [00:01:31/00:37:41, 0.764s/it]: train_loss_raw=0.3701, running_loss=0.4311, LR=0.000100
[2025-08-27 11:04:40,067][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061728] [Batch 00128/03080] [00:01:37/00:37:28, 0.762s/it]: train_loss_raw=0.4485, running_loss=0.4333, LR=0.000100
[2025-08-27 11:04:45,491][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061736] [Batch 00136/03080] [00:01:42/00:37:07, 0.757s/it]: train_loss_raw=0.4298, running_loss=0.4340, LR=0.000100
[2025-08-27 11:04:51,040][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061744] [Batch 00144/03080] [00:01:48/00:36:51, 0.753s/it]: train_loss_raw=0.4871, running_loss=0.4365, LR=0.000100
[2025-08-27 11:04:57,106][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061752] [Batch 00152/03080] [00:01:54/00:36:46, 0.753s/it]: train_loss_raw=0.4523, running_loss=0.4366, LR=0.000100
[2025-08-27 11:05:03,257][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061760] [Batch 00160/03080] [00:02:00/00:36:42, 0.754s/it]: train_loss_raw=0.4328, running_loss=0.4377, LR=0.000100
[2025-08-27 11:05:09,315][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061768] [Batch 00168/03080] [00:02:06/00:36:36, 0.754s/it]: train_loss_raw=0.4082, running_loss=0.4376, LR=0.000100
[2025-08-27 11:05:15,315][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061776] [Batch 00176/03080] [00:02:12/00:36:30, 0.754s/it]: train_loss_raw=0.4110, running_loss=0.4368, LR=0.000100
[2025-08-27 11:05:21,349][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061784] [Batch 00184/03080] [00:02:18/00:36:24, 0.754s/it]: train_loss_raw=0.4070, running_loss=0.4366, LR=0.000100
[2025-08-27 11:05:27,373][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061792] [Batch 00192/03080] [00:02:24/00:36:18, 0.754s/it]: train_loss_raw=0.4124, running_loss=0.4378, LR=0.000100
[2025-08-27 11:05:33,346][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061800] [Batch 00200/03080] [00:02:30/00:36:11, 0.754s/it]: train_loss_raw=0.4480, running_loss=0.4377, LR=0.000100
[2025-08-27 11:05:39,343][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061808] [Batch 00208/03080] [00:02:36/00:36:04, 0.754s/it]: train_loss_raw=0.4433, running_loss=0.4389, LR=0.000100
[2025-08-27 11:05:45,547][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061816] [Batch 00216/03080] [00:02:42/00:36:00, 0.754s/it]: train_loss_raw=0.5193, running_loss=0.4379, LR=0.000100
[2025-08-27 11:05:51,642][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061824] [Batch 00224/03080] [00:02:49/00:35:55, 0.755s/it]: train_loss_raw=0.4872, running_loss=0.4386, LR=0.000100
[2025-08-27 11:05:57,847][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061832] [Batch 00232/03080] [00:02:55/00:35:51, 0.755s/it]: train_loss_raw=0.3383, running_loss=0.4408, LR=0.000100
[2025-08-27 11:06:03,906][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061840] [Batch 00240/03080] [00:03:01/00:35:45, 0.756s/it]: train_loss_raw=0.3687, running_loss=0.4393, LR=0.000100
[2025-08-27 11:06:10,014][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061848] [Batch 00248/03080] [00:03:07/00:35:40, 0.756s/it]: train_loss_raw=0.4415, running_loss=0.4421, LR=0.000100
[2025-08-27 11:06:16,085][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061856] [Batch 00256/03080] [00:03:13/00:35:34, 0.756s/it]: train_loss_raw=0.3901, running_loss=0.4410, LR=0.000100
[2025-08-27 11:06:22,193][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061864] [Batch 00264/03080] [00:03:19/00:35:29, 0.756s/it]: train_loss_raw=0.3607, running_loss=0.4389, LR=0.000100
[2025-08-27 11:06:28,124][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061872] [Batch 00272/03080] [00:03:25/00:35:21, 0.756s/it]: train_loss_raw=0.4333, running_loss=0.4380, LR=0.000100
[2025-08-27 11:06:34,206][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061880] [Batch 00280/03080] [00:03:31/00:35:16, 0.756s/it]: train_loss_raw=0.4639, running_loss=0.4391, LR=0.000100
[2025-08-27 11:06:40,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061888] [Batch 00288/03080] [00:03:37/00:35:10, 0.756s/it]: train_loss_raw=0.3590, running_loss=0.4382, LR=0.000100
[2025-08-27 11:06:46,292][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061896] [Batch 00296/03080] [00:03:43/00:35:04, 0.756s/it]: train_loss_raw=0.4838, running_loss=0.4402, LR=0.000100
[2025-08-27 11:06:52,281][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061904] [Batch 00304/03080] [00:03:49/00:34:57, 0.756s/it]: train_loss_raw=0.3906, running_loss=0.4397, LR=0.000100
[2025-08-27 11:06:58,413][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061912] [Batch 00312/03080] [00:03:55/00:34:52, 0.756s/it]: train_loss_raw=0.4308, running_loss=0.4403, LR=0.000100
[2025-08-27 11:07:04,555][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061920] [Batch 00320/03080] [00:04:01/00:34:47, 0.756s/it]: train_loss_raw=0.4818, running_loss=0.4409, LR=0.000100
[2025-08-27 11:07:10,771][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061928] [Batch 00328/03080] [00:04:08/00:34:42, 0.757s/it]: train_loss_raw=0.4063, running_loss=0.4390, LR=0.000100
[2025-08-27 11:07:16,883][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061936] [Batch 00336/03080] [00:04:14/00:34:36, 0.757s/it]: train_loss_raw=0.4276, running_loss=0.4393, LR=0.000100
[2025-08-27 11:07:23,050][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061944] [Batch 00344/03080] [00:04:20/00:34:31, 0.757s/it]: train_loss_raw=0.4355, running_loss=0.4392, LR=0.000100
[2025-08-27 11:07:29,330][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061952] [Batch 00352/03080] [00:04:26/00:34:27, 0.758s/it]: train_loss_raw=0.6041, running_loss=0.4414, LR=0.000100
[2025-08-27 11:07:35,697][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061960] [Batch 00360/03080] [00:04:33/00:34:23, 0.759s/it]: train_loss_raw=0.4474, running_loss=0.4454, LR=0.000100
[2025-08-27 11:07:42,028][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061968] [Batch 00368/03080] [00:04:39/00:34:19, 0.759s/it]: train_loss_raw=0.5173, running_loss=0.4454, LR=0.000100
[2025-08-27 11:07:48,168][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061976] [Batch 00376/03080] [00:04:45/00:34:13, 0.760s/it]: train_loss_raw=0.4376, running_loss=0.4451, LR=0.000100
[2025-08-27 11:07:54,283][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061984] [Batch 00384/03080] [00:04:51/00:34:08, 0.760s/it]: train_loss_raw=0.4611, running_loss=0.4436, LR=0.000100
[2025-08-27 11:08:00,277][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061992] [Batch 00392/03080] [00:04:57/00:34:01, 0.759s/it]: train_loss_raw=0.5006, running_loss=0.4438, LR=0.000100
[2025-08-27 11:08:06,341][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062000] [Batch 00400/03080] [00:05:03/00:33:55, 0.759s/it]: train_loss_raw=0.4123, running_loss=0.4447, LR=0.000100
[2025-08-27 11:08:15,937][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062008] [Batch 00408/03080] [00:05:13/00:34:12, 0.768s/it]: train_loss_raw=0.4205, running_loss=0.4446, LR=0.000100
[2025-08-27 11:08:21,828][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062016] [Batch 00416/03080] [00:05:19/00:34:04, 0.767s/it]: train_loss_raw=0.4606, running_loss=0.4443, LR=0.000100
[2025-08-27 11:08:27,608][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062024] [Batch 00424/03080] [00:05:25/00:33:56, 0.767s/it]: train_loss_raw=0.4299, running_loss=0.4436, LR=0.000100
[2025-08-27 11:08:33,681][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062032] [Batch 00432/03080] [00:05:31/00:33:49, 0.766s/it]: train_loss_raw=0.4815, running_loss=0.4448, LR=0.000100
[2025-08-27 11:08:39,780][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062040] [Batch 00440/03080] [00:05:37/00:33:43, 0.766s/it]: train_loss_raw=0.4613, running_loss=0.4443, LR=0.000100
[2025-08-27 11:08:45,815][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062048] [Batch 00448/03080] [00:05:43/00:33:36, 0.766s/it]: train_loss_raw=0.5093, running_loss=0.4457, LR=0.000100
[2025-08-27 11:08:51,732][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062056] [Batch 00456/03080] [00:05:49/00:33:29, 0.766s/it]: train_loss_raw=0.4365, running_loss=0.4483, LR=0.000100
[2025-08-27 11:08:57,909][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062064] [Batch 00464/03080] [00:05:55/00:33:23, 0.766s/it]: train_loss_raw=0.4807, running_loss=0.4463, LR=0.000100
[2025-08-27 11:09:04,031][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062072] [Batch 00472/03080] [00:06:01/00:33:17, 0.766s/it]: train_loss_raw=0.5186, running_loss=0.4468, LR=0.000100
[2025-08-27 11:09:10,058][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062080] [Batch 00480/03080] [00:06:07/00:33:10, 0.766s/it]: train_loss_raw=0.5253, running_loss=0.4488, LR=0.000100
[2025-08-27 11:09:16,189][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062088] [Batch 00488/03080] [00:06:13/00:33:04, 0.766s/it]: train_loss_raw=0.4870, running_loss=0.4521, LR=0.000100
[2025-08-27 11:09:22,186][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062096] [Batch 00496/03080] [00:06:19/00:32:57, 0.765s/it]: train_loss_raw=0.4898, running_loss=0.4522, LR=0.000100
[2025-08-27 11:09:28,291][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062104] [Batch 00504/03080] [00:06:25/00:32:51, 0.765s/it]: train_loss_raw=0.6338, running_loss=0.4516, LR=0.000100
[2025-08-27 11:09:34,265][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062112] [Batch 00512/03080] [00:06:31/00:32:44, 0.765s/it]: train_loss_raw=0.4873, running_loss=0.4524, LR=0.000100
[2025-08-27 11:09:40,256][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062120] [Batch 00520/03080] [00:06:37/00:32:37, 0.765s/it]: train_loss_raw=0.4533, running_loss=0.4517, LR=0.000100
[2025-08-27 11:09:46,255][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062128] [Batch 00528/03080] [00:06:43/00:32:31, 0.765s/it]: train_loss_raw=0.3924, running_loss=0.4516, LR=0.000100
[2025-08-27 11:09:52,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062136] [Batch 00536/03080] [00:06:49/00:32:24, 0.764s/it]: train_loss_raw=0.4515, running_loss=0.4520, LR=0.000100
[2025-08-27 11:09:58,211][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062144] [Batch 00544/03080] [00:06:55/00:32:17, 0.764s/it]: train_loss_raw=0.4455, running_loss=0.4506, LR=0.000100
[2025-08-27 11:10:04,212][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062152] [Batch 00552/03080] [00:07:01/00:32:10, 0.764s/it]: train_loss_raw=0.4355, running_loss=0.4484, LR=0.000100
[2025-08-27 11:10:10,323][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062160] [Batch 00560/03080] [00:07:07/00:32:04, 0.764s/it]: train_loss_raw=0.4202, running_loss=0.4473, LR=0.000100
[2025-08-27 11:10:16,241][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062168] [Batch 00568/03080] [00:07:13/00:31:57, 0.763s/it]: train_loss_raw=0.4446, running_loss=0.4498, LR=0.000100
[2025-08-27 11:10:22,267][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062176] [Batch 00576/03080] [00:07:19/00:31:51, 0.763s/it]: train_loss_raw=0.4349, running_loss=0.4500, LR=0.000100
[2025-08-27 11:10:28,267][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062184] [Batch 00584/03080] [00:07:25/00:31:44, 0.763s/it]: train_loss_raw=0.4661, running_loss=0.4494, LR=0.000100
[2025-08-27 11:10:34,408][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062192] [Batch 00592/03080] [00:07:31/00:31:38, 0.763s/it]: train_loss_raw=0.3770, running_loss=0.4511, LR=0.000100
[2025-08-27 11:10:40,362][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062200] [Batch 00600/03080] [00:07:37/00:31:32, 0.763s/it]: train_loss_raw=0.4778, running_loss=0.4512, LR=0.000100
[2025-08-27 11:10:46,380][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062208] [Batch 00608/03080] [00:07:43/00:31:25, 0.763s/it]: train_loss_raw=0.4179, running_loss=0.4519, LR=0.000100
[2025-08-27 11:10:52,424][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062216] [Batch 00616/03080] [00:07:49/00:31:19, 0.763s/it]: train_loss_raw=0.4033, running_loss=0.4521, LR=0.000100
[2025-08-27 11:10:58,453][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062224] [Batch 00624/03080] [00:07:55/00:31:13, 0.763s/it]: train_loss_raw=0.4191, running_loss=0.4500, LR=0.000100
[2025-08-27 11:11:04,703][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062232] [Batch 00632/03080] [00:08:02/00:31:07, 0.763s/it]: train_loss_raw=0.4904, running_loss=0.4487, LR=0.000100
[2025-08-27 11:11:10,792][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062240] [Batch 00640/03080] [00:08:08/00:31:01, 0.763s/it]: train_loss_raw=0.5181, running_loss=0.4485, LR=0.000100
[2025-08-27 11:11:16,787][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062248] [Batch 00648/03080] [00:08:14/00:30:54, 0.763s/it]: train_loss_raw=0.3961, running_loss=0.4472, LR=0.000100
[2025-08-27 11:11:22,901][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062256] [Batch 00656/03080] [00:08:20/00:30:48, 0.763s/it]: train_loss_raw=0.4597, running_loss=0.4475, LR=0.000100
[2025-08-27 11:11:29,077][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062264] [Batch 00664/03080] [00:08:26/00:30:42, 0.763s/it]: train_loss_raw=0.5471, running_loss=0.4495, LR=0.000100
[2025-08-27 11:11:35,204][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062272] [Batch 00672/03080] [00:08:32/00:30:36, 0.763s/it]: train_loss_raw=0.4526, running_loss=0.4506, LR=0.000100
[2025-08-27 11:11:41,153][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062280] [Batch 00680/03080] [00:08:38/00:30:30, 0.763s/it]: train_loss_raw=0.4515, running_loss=0.4514, LR=0.000100
[2025-08-27 11:11:47,060][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062288] [Batch 00688/03080] [00:08:44/00:30:23, 0.762s/it]: train_loss_raw=0.4910, running_loss=0.4551, LR=0.000100
[2025-08-27 11:11:53,042][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062296] [Batch 00696/03080] [00:08:50/00:30:17, 0.762s/it]: train_loss_raw=0.4277, running_loss=0.4522, LR=0.000100
[2025-08-27 11:11:59,307][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062304] [Batch 00704/03080] [00:08:56/00:30:11, 0.762s/it]: train_loss_raw=0.4596, running_loss=0.4520, LR=0.000100
[2025-08-27 11:12:05,283][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062312] [Batch 00712/03080] [00:09:02/00:30:04, 0.762s/it]: train_loss_raw=0.4607, running_loss=0.4496, LR=0.000100
[2025-08-27 11:12:11,408][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062320] [Batch 00720/03080] [00:09:08/00:29:58, 0.762s/it]: train_loss_raw=0.3723, running_loss=0.4492, LR=0.000100
[2025-08-27 11:12:17,526][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062328] [Batch 00728/03080] [00:09:14/00:29:52, 0.762s/it]: train_loss_raw=0.4631, running_loss=0.4484, LR=0.000100
[2025-08-27 11:12:23,484][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062336] [Batch 00736/03080] [00:09:20/00:29:46, 0.762s/it]: train_loss_raw=0.5471, running_loss=0.4512, LR=0.000100
[2025-08-27 11:12:29,631][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062344] [Batch 00744/03080] [00:09:27/00:29:40, 0.762s/it]: train_loss_raw=0.3834, running_loss=0.4509, LR=0.000100
[2025-08-27 11:12:35,708][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062352] [Batch 00752/03080] [00:09:33/00:29:34, 0.762s/it]: train_loss_raw=0.4784, running_loss=0.4514, LR=0.000100
[2025-08-27 11:12:41,827][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062360] [Batch 00760/03080] [00:09:39/00:29:28, 0.762s/it]: train_loss_raw=0.4326, running_loss=0.4493, LR=0.000100
[2025-08-27 11:12:47,705][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062368] [Batch 00768/03080] [00:09:45/00:29:21, 0.762s/it]: train_loss_raw=0.3942, running_loss=0.4469, LR=0.000100
[2025-08-27 11:12:53,777][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062376] [Batch 00776/03080] [00:09:51/00:29:15, 0.762s/it]: train_loss_raw=0.4184, running_loss=0.4454, LR=0.000100
[2025-08-27 11:12:59,893][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062384] [Batch 00784/03080] [00:09:57/00:29:09, 0.762s/it]: train_loss_raw=0.4668, running_loss=0.4467, LR=0.000100
[2025-08-27 11:13:06,048][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062392] [Batch 00792/03080] [00:10:03/00:29:03, 0.762s/it]: train_loss_raw=0.4497, running_loss=0.4482, LR=0.000100
[2025-08-27 11:13:12,119][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062400] [Batch 00800/03080] [00:10:09/00:28:57, 0.762s/it]: train_loss_raw=0.4428, running_loss=0.4483, LR=0.000100
[2025-08-27 11:13:18,178][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062408] [Batch 00808/03080] [00:10:15/00:28:51, 0.762s/it]: train_loss_raw=0.4575, running_loss=0.4470, LR=0.000100
[2025-08-27 11:13:24,169][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062416] [Batch 00816/03080] [00:10:21/00:28:44, 0.762s/it]: train_loss_raw=0.3761, running_loss=0.4460, LR=0.000100
[2025-08-27 11:13:30,129][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062424] [Batch 00824/03080] [00:10:27/00:28:38, 0.762s/it]: train_loss_raw=0.4953, running_loss=0.4456, LR=0.000100
[2025-08-27 11:13:36,098][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062432] [Batch 00832/03080] [00:10:33/00:28:31, 0.761s/it]: train_loss_raw=0.4060, running_loss=0.4453, LR=0.000100
[2025-08-27 11:13:42,050][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062440] [Batch 00840/03080] [00:10:39/00:28:25, 0.761s/it]: train_loss_raw=0.3899, running_loss=0.4455, LR=0.000100
[2025-08-27 11:13:48,148][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062448] [Batch 00848/03080] [00:10:45/00:28:19, 0.761s/it]: train_loss_raw=0.4166, running_loss=0.4452, LR=0.000100
[2025-08-27 11:13:54,071][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062456] [Batch 00856/03080] [00:10:51/00:28:12, 0.761s/it]: train_loss_raw=0.4820, running_loss=0.4482, LR=0.000100
[2025-08-27 11:14:00,124][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062464] [Batch 00864/03080] [00:10:57/00:28:06, 0.761s/it]: train_loss_raw=0.5598, running_loss=0.4489, LR=0.000100
[2025-08-27 11:14:06,081][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062472] [Batch 00872/03080] [00:11:03/00:28:00, 0.761s/it]: train_loss_raw=0.4364, running_loss=0.4492, LR=0.000100
[2025-08-27 11:14:12,021][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062480] [Batch 00880/03080] [00:11:09/00:27:53, 0.761s/it]: train_loss_raw=0.5145, running_loss=0.4501, LR=0.000100
[2025-08-27 11:14:18,053][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062488] [Batch 00888/03080] [00:11:15/00:27:47, 0.761s/it]: train_loss_raw=0.4159, running_loss=0.4523, LR=0.000100
[2025-08-27 11:14:24,132][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062496] [Batch 00896/03080] [00:11:21/00:27:41, 0.761s/it]: train_loss_raw=0.4426, running_loss=0.4524, LR=0.000100
[2025-08-27 11:14:30,290][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062504] [Batch 00904/03080] [00:11:27/00:27:35, 0.761s/it]: train_loss_raw=0.4308, running_loss=0.4517, LR=0.000100
[2025-08-27 11:14:36,384][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062512] [Batch 00912/03080] [00:11:33/00:27:29, 0.761s/it]: train_loss_raw=0.4892, running_loss=0.4501, LR=0.000100
[2025-08-27 11:14:42,406][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062520] [Batch 00920/03080] [00:11:39/00:27:23, 0.761s/it]: train_loss_raw=0.4573, running_loss=0.4509, LR=0.000100
[2025-08-27 11:14:48,432][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062528] [Batch 00928/03080] [00:11:45/00:27:16, 0.761s/it]: train_loss_raw=0.4485, running_loss=0.4489, LR=0.000100
[2025-08-27 11:14:54,428][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062536] [Batch 00936/03080] [00:11:51/00:27:10, 0.761s/it]: train_loss_raw=0.4405, running_loss=0.4478, LR=0.000100
[2025-08-27 11:15:00,401][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062544] [Batch 00944/03080] [00:11:57/00:27:04, 0.760s/it]: train_loss_raw=0.4059, running_loss=0.4466, LR=0.000100
[2025-08-27 11:15:06,373][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062552] [Batch 00952/03080] [00:12:03/00:26:57, 0.760s/it]: train_loss_raw=0.5372, running_loss=0.4468, LR=0.000100
[2025-08-27 11:15:12,342][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062560] [Batch 00960/03080] [00:12:09/00:26:51, 0.760s/it]: train_loss_raw=0.4999, running_loss=0.4474, LR=0.000100
[2025-08-27 11:15:18,324][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062568] [Batch 00968/03080] [00:12:15/00:26:45, 0.760s/it]: train_loss_raw=0.4146, running_loss=0.4465, LR=0.000100
[2025-08-27 11:15:24,356][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062576] [Batch 00976/03080] [00:12:21/00:26:39, 0.760s/it]: train_loss_raw=0.4759, running_loss=0.4459, LR=0.000100
[2025-08-27 11:15:30,419][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062584] [Batch 00984/03080] [00:12:27/00:26:32, 0.760s/it]: train_loss_raw=0.4545, running_loss=0.4467, LR=0.000100
[2025-08-27 11:15:36,439][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062592] [Batch 00992/03080] [00:12:33/00:26:26, 0.760s/it]: train_loss_raw=0.4262, running_loss=0.4461, LR=0.000100
[2025-08-27 11:15:42,529][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062600] [Batch 01000/03080] [00:12:39/00:26:20, 0.760s/it]: train_loss_raw=0.4335, running_loss=0.4473, LR=0.000100
[2025-08-27 11:15:48,684][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062608] [Batch 01008/03080] [00:12:46/00:26:14, 0.760s/it]: train_loss_raw=0.5378, running_loss=0.4490, LR=0.000100
[2025-08-27 11:15:54,696][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062616] [Batch 01016/03080] [00:12:52/00:26:08, 0.760s/it]: train_loss_raw=0.3817, running_loss=0.4478, LR=0.000100
[2025-08-27 11:16:00,666][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062624] [Batch 01024/03080] [00:12:58/00:26:02, 0.760s/it]: train_loss_raw=0.5277, running_loss=0.4486, LR=0.000100
[2025-08-27 11:16:06,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062632] [Batch 01032/03080] [00:13:04/00:25:55, 0.760s/it]: train_loss_raw=0.4196, running_loss=0.4472, LR=0.000100
[2025-08-27 11:16:12,648][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062640] [Batch 01040/03080] [00:13:10/00:25:49, 0.760s/it]: train_loss_raw=0.4770, running_loss=0.4490, LR=0.000100
[2025-08-27 11:16:18,633][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062648] [Batch 01048/03080] [00:13:16/00:25:43, 0.760s/it]: train_loss_raw=0.4997, running_loss=0.4483, LR=0.000100
[2025-08-27 11:16:24,744][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062656] [Batch 01056/03080] [00:13:22/00:25:37, 0.760s/it]: train_loss_raw=0.5588, running_loss=0.4487, LR=0.000100
[2025-08-27 11:16:30,693][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062664] [Batch 01064/03080] [00:13:28/00:25:31, 0.760s/it]: train_loss_raw=0.4827, running_loss=0.4477, LR=0.000100
[2025-08-27 11:16:36,643][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062672] [Batch 01072/03080] [00:13:34/00:25:24, 0.759s/it]: train_loss_raw=0.4785, running_loss=0.4467, LR=0.000100
[2025-08-27 11:16:42,601][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062680] [Batch 01080/03080] [00:13:40/00:25:18, 0.759s/it]: train_loss_raw=0.4124, running_loss=0.4473, LR=0.000100
[2025-08-27 11:16:48,671][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062688] [Batch 01088/03080] [00:13:46/00:25:12, 0.759s/it]: train_loss_raw=0.3751, running_loss=0.4468, LR=0.000100
[2025-08-27 11:16:54,675][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062696] [Batch 01096/03080] [00:13:52/00:25:06, 0.759s/it]: train_loss_raw=0.3468, running_loss=0.4438, LR=0.000100
[2025-08-27 11:17:00,766][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062704] [Batch 01104/03080] [00:13:58/00:25:00, 0.759s/it]: train_loss_raw=0.3989, running_loss=0.4449, LR=0.000100
[2025-08-27 11:17:06,869][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062712] [Batch 01112/03080] [00:14:04/00:24:54, 0.759s/it]: train_loss_raw=0.4449, running_loss=0.4427, LR=0.000100
[2025-08-27 11:17:12,856][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062720] [Batch 01120/03080] [00:14:10/00:24:47, 0.759s/it]: train_loss_raw=0.4609, running_loss=0.4425, LR=0.000100
[2025-08-27 11:17:19,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062728] [Batch 01128/03080] [00:14:16/00:24:42, 0.759s/it]: train_loss_raw=0.4669, running_loss=0.4444, LR=0.000100
[2025-08-27 11:17:25,128][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062736] [Batch 01136/03080] [00:14:22/00:24:36, 0.759s/it]: train_loss_raw=0.4514, running_loss=0.4437, LR=0.000100
[2025-08-27 11:17:31,168][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062744] [Batch 01144/03080] [00:14:28/00:24:29, 0.759s/it]: train_loss_raw=0.3851, running_loss=0.4444, LR=0.000100
[2025-08-27 11:17:37,157][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062752] [Batch 01152/03080] [00:14:34/00:24:23, 0.759s/it]: train_loss_raw=0.4478, running_loss=0.4456, LR=0.000100
[2025-08-27 11:17:42,922][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062760] [Batch 01160/03080] [00:14:40/00:24:17, 0.759s/it]: train_loss_raw=0.5785, running_loss=0.4470, LR=0.000100
[2025-08-27 11:17:48,879][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062768] [Batch 01168/03080] [00:14:46/00:24:10, 0.759s/it]: train_loss_raw=0.4874, running_loss=0.4469, LR=0.000100
[2025-08-27 11:17:55,110][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062776] [Batch 01176/03080] [00:14:52/00:24:05, 0.759s/it]: train_loss_raw=0.3942, running_loss=0.4456, LR=0.000100
[2025-08-27 11:18:01,292][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062784] [Batch 01184/03080] [00:14:58/00:23:59, 0.759s/it]: train_loss_raw=0.3707, running_loss=0.4450, LR=0.000100
[2025-08-27 11:18:07,519][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062792] [Batch 01192/03080] [00:15:04/00:23:53, 0.759s/it]: train_loss_raw=0.4468, running_loss=0.4461, LR=0.000100
[2025-08-27 11:18:13,635][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062800] [Batch 01200/03080] [00:15:11/00:23:47, 0.759s/it]: train_loss_raw=0.4662, running_loss=0.4467, LR=0.000100
[2025-08-27 11:18:20,056][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062808] [Batch 01208/03080] [00:15:17/00:23:41, 0.760s/it]: train_loss_raw=0.4564, running_loss=0.4469, LR=0.000100
[2025-08-27 11:18:26,181][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062816] [Batch 01216/03080] [00:15:23/00:23:35, 0.760s/it]: train_loss_raw=0.4039, running_loss=0.4453, LR=0.000100
[2025-08-27 11:18:32,410][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062824] [Batch 01224/03080] [00:15:29/00:23:29, 0.760s/it]: train_loss_raw=0.4909, running_loss=0.4452, LR=0.000100
[2025-08-27 11:18:38,810][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062832] [Batch 01232/03080] [00:15:36/00:23:24, 0.760s/it]: train_loss_raw=0.4885, running_loss=0.4443, LR=0.000100
[2025-08-27 11:18:44,655][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062840] [Batch 01240/03080] [00:15:42/00:23:17, 0.760s/it]: train_loss_raw=0.5079, running_loss=0.4433, LR=0.000100
[2025-08-27 11:18:50,932][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062848] [Batch 01248/03080] [00:15:48/00:23:12, 0.760s/it]: train_loss_raw=0.4911, running_loss=0.4443, LR=0.000100
[2025-08-27 11:18:57,392][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062856] [Batch 01256/03080] [00:15:54/00:23:06, 0.760s/it]: train_loss_raw=0.4657, running_loss=0.4441, LR=0.000100
[2025-08-27 11:19:03,477][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062864] [Batch 01264/03080] [00:16:00/00:23:00, 0.760s/it]: train_loss_raw=0.4291, running_loss=0.4440, LR=0.000100
[2025-08-27 11:19:09,393][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062872] [Batch 01272/03080] [00:16:06/00:22:54, 0.760s/it]: train_loss_raw=0.4642, running_loss=0.4446, LR=0.000100
[2025-08-27 11:19:15,351][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062880] [Batch 01280/03080] [00:16:12/00:22:47, 0.760s/it]: train_loss_raw=0.4350, running_loss=0.4469, LR=0.000100
[2025-08-27 11:19:21,202][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062888] [Batch 01288/03080] [00:16:18/00:22:41, 0.760s/it]: train_loss_raw=0.3738, running_loss=0.4463, LR=0.000100
[2025-08-27 11:19:27,125][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062896] [Batch 01296/03080] [00:16:24/00:22:35, 0.760s/it]: train_loss_raw=0.3805, running_loss=0.4458, LR=0.000100
[2025-08-27 11:19:33,264][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062904] [Batch 01304/03080] [00:16:30/00:22:29, 0.760s/it]: train_loss_raw=0.4556, running_loss=0.4458, LR=0.000100
[2025-08-27 11:19:39,133][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062912] [Batch 01312/03080] [00:16:36/00:22:22, 0.760s/it]: train_loss_raw=0.5237, running_loss=0.4484, LR=0.000100
[2025-08-27 11:19:44,703][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062920] [Batch 01320/03080] [00:16:42/00:22:16, 0.759s/it]: train_loss_raw=0.4872, running_loss=0.4509, LR=0.000100
[2025-08-27 11:19:50,729][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062928] [Batch 01328/03080] [00:16:48/00:22:10, 0.759s/it]: train_loss_raw=0.4010, running_loss=0.4509, LR=0.000100
[2025-08-27 11:19:56,731][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062936] [Batch 01336/03080] [00:16:54/00:22:03, 0.759s/it]: train_loss_raw=0.5014, running_loss=0.4531, LR=0.000100
[2025-08-27 11:20:02,679][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062944] [Batch 01344/03080] [00:17:00/00:21:57, 0.759s/it]: train_loss_raw=0.4195, running_loss=0.4531, LR=0.000100
[2025-08-27 11:20:08,693][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062952] [Batch 01352/03080] [00:17:06/00:21:51, 0.759s/it]: train_loss_raw=0.4859, running_loss=0.4539, LR=0.000100
[2025-08-27 11:20:14,716][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062960] [Batch 01360/03080] [00:17:12/00:21:45, 0.759s/it]: train_loss_raw=0.5563, running_loss=0.4540, LR=0.000100
[2025-08-27 11:20:20,667][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062968] [Batch 01368/03080] [00:17:18/00:21:39, 0.759s/it]: train_loss_raw=0.4529, running_loss=0.4531, LR=0.000100
[2025-08-27 11:20:26,772][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062976] [Batch 01376/03080] [00:17:24/00:21:33, 0.759s/it]: train_loss_raw=0.4924, running_loss=0.4533, LR=0.000100
[2025-08-27 11:20:32,688][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062984] [Batch 01384/03080] [00:17:30/00:21:26, 0.759s/it]: train_loss_raw=0.4027, running_loss=0.4536, LR=0.000100
[2025-08-27 11:20:38,682][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062992] [Batch 01392/03080] [00:17:36/00:21:20, 0.759s/it]: train_loss_raw=0.5262, running_loss=0.4531, LR=0.000100
[2025-08-27 11:20:44,632][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063000] [Batch 01400/03080] [00:17:42/00:21:14, 0.759s/it]: train_loss_raw=0.4253, running_loss=0.4524, LR=0.000100
[2025-08-27 11:20:50,651][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063008] [Batch 01408/03080] [00:17:48/00:21:08, 0.759s/it]: train_loss_raw=0.4611, running_loss=0.4519, LR=0.000100
[2025-08-27 11:20:56,663][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063016] [Batch 01416/03080] [00:17:54/00:21:02, 0.759s/it]: train_loss_raw=0.4177, running_loss=0.4481, LR=0.000100
[2025-08-27 11:21:02,708][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063024] [Batch 01424/03080] [00:18:00/00:20:56, 0.759s/it]: train_loss_raw=0.4968, running_loss=0.4490, LR=0.000100
[2025-08-27 11:21:08,862][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063032] [Batch 01432/03080] [00:18:06/00:20:50, 0.759s/it]: train_loss_raw=0.4362, running_loss=0.4496, LR=0.000100
[2025-08-27 11:21:14,802][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063040] [Batch 01440/03080] [00:18:12/00:20:43, 0.758s/it]: train_loss_raw=0.4626, running_loss=0.4495, LR=0.000100
[2025-08-27 11:21:20,785][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063048] [Batch 01448/03080] [00:18:18/00:20:37, 0.758s/it]: train_loss_raw=0.3750, running_loss=0.4505, LR=0.000100
[2025-08-27 11:21:26,881][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063056] [Batch 01456/03080] [00:18:24/00:20:31, 0.758s/it]: train_loss_raw=0.4611, running_loss=0.4509, LR=0.000100
[2025-08-27 11:21:32,823][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063064] [Batch 01464/03080] [00:18:30/00:20:25, 0.758s/it]: train_loss_raw=0.4328, running_loss=0.4494, LR=0.000100
[2025-08-27 11:21:38,844][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063072] [Batch 01472/03080] [00:18:36/00:20:19, 0.758s/it]: train_loss_raw=0.5430, running_loss=0.4496, LR=0.000100
[2025-08-27 11:21:44,777][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063080] [Batch 01480/03080] [00:18:42/00:20:13, 0.758s/it]: train_loss_raw=0.4448, running_loss=0.4496, LR=0.000100
[2025-08-27 11:21:50,551][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063088] [Batch 01488/03080] [00:18:47/00:20:06, 0.758s/it]: train_loss_raw=0.3840, running_loss=0.4476, LR=0.000100
[2025-08-27 11:21:56,323][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063096] [Batch 01496/03080] [00:18:53/00:20:00, 0.758s/it]: train_loss_raw=0.4309, running_loss=0.4455, LR=0.000100
[2025-08-27 11:22:02,254][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063104] [Batch 01504/03080] [00:18:59/00:19:54, 0.758s/it]: train_loss_raw=0.3538, running_loss=0.4440, LR=0.000100
[2025-08-27 11:22:08,274][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063112] [Batch 01512/03080] [00:19:05/00:19:48, 0.758s/it]: train_loss_raw=0.4467, running_loss=0.4453, LR=0.000100
[2025-08-27 11:22:14,560][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063120] [Batch 01520/03080] [00:19:11/00:19:42, 0.758s/it]: train_loss_raw=0.4586, running_loss=0.4455, LR=0.000100
[2025-08-27 11:22:20,619][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063128] [Batch 01528/03080] [00:19:18/00:19:36, 0.758s/it]: train_loss_raw=0.4043, running_loss=0.4450, LR=0.000100
[2025-08-27 11:22:26,785][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063136] [Batch 01536/03080] [00:19:24/00:19:30, 0.758s/it]: train_loss_raw=0.4692, running_loss=0.4464, LR=0.000100
[2025-08-27 11:22:32,901][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063144] [Batch 01544/03080] [00:19:30/00:19:24, 0.758s/it]: train_loss_raw=0.4813, running_loss=0.4461, LR=0.000100
[2025-08-27 11:22:38,671][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063152] [Batch 01552/03080] [00:19:36/00:19:17, 0.758s/it]: train_loss_raw=0.3357, running_loss=0.4440, LR=0.000100
[2025-08-27 11:22:44,585][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063160] [Batch 01560/03080] [00:19:42/00:19:11, 0.758s/it]: train_loss_raw=0.5144, running_loss=0.4423, LR=0.000100
[2025-08-27 11:22:50,935][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063168] [Batch 01568/03080] [00:19:48/00:19:05, 0.758s/it]: train_loss_raw=0.4650, running_loss=0.4409, LR=0.000100
[2025-08-27 11:22:56,985][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063176] [Batch 01576/03080] [00:19:54/00:18:59, 0.758s/it]: train_loss_raw=0.4629, running_loss=0.4392, LR=0.000100
[2025-08-27 11:23:02,806][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063184] [Batch 01584/03080] [00:20:00/00:18:53, 0.758s/it]: train_loss_raw=0.4274, running_loss=0.4398, LR=0.000100
[2025-08-27 11:23:08,574][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063192] [Batch 01592/03080] [00:20:05/00:18:47, 0.758s/it]: train_loss_raw=0.5778, running_loss=0.4403, LR=0.000100
[2025-08-27 11:23:14,351][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063200] [Batch 01600/03080] [00:20:11/00:18:40, 0.757s/it]: train_loss_raw=0.4211, running_loss=0.4403, LR=0.000100
[2025-08-27 11:23:20,270][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063208] [Batch 01608/03080] [00:20:17/00:18:34, 0.757s/it]: train_loss_raw=0.5161, running_loss=0.4449, LR=0.000100
[2025-08-27 11:23:26,256][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063216] [Batch 01616/03080] [00:20:23/00:18:28, 0.757s/it]: train_loss_raw=0.3934, running_loss=0.4447, LR=0.000100
[2025-08-27 11:23:32,161][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063224] [Batch 01624/03080] [00:20:29/00:18:22, 0.757s/it]: train_loss_raw=0.4849, running_loss=0.4431, LR=0.000100
[2025-08-27 11:23:38,065][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063232] [Batch 01632/03080] [00:20:35/00:18:16, 0.757s/it]: train_loss_raw=0.4449, running_loss=0.4430, LR=0.000100
[2025-08-27 11:23:44,281][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063240] [Batch 01640/03080] [00:20:41/00:18:10, 0.757s/it]: train_loss_raw=0.3655, running_loss=0.4424, LR=0.000100
[2025-08-27 11:23:50,399][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063248] [Batch 01648/03080] [00:20:47/00:18:04, 0.757s/it]: train_loss_raw=0.4493, running_loss=0.4406, LR=0.000100
[2025-08-27 11:23:56,258][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063256] [Batch 01656/03080] [00:20:53/00:17:58, 0.757s/it]: train_loss_raw=0.4266, running_loss=0.4415, LR=0.000100
[2025-08-27 11:24:02,216][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063264] [Batch 01664/03080] [00:20:59/00:17:51, 0.757s/it]: train_loss_raw=0.4625, running_loss=0.4428, LR=0.000100
[2025-08-27 11:24:08,186][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063272] [Batch 01672/03080] [00:21:05/00:17:45, 0.757s/it]: train_loss_raw=0.4353, running_loss=0.4434, LR=0.000100
[2025-08-27 11:24:14,419][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063280] [Batch 01680/03080] [00:21:11/00:17:39, 0.757s/it]: train_loss_raw=0.4366, running_loss=0.4428, LR=0.000100
[2025-08-27 11:24:20,634][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063288] [Batch 01688/03080] [00:21:18/00:17:33, 0.757s/it]: train_loss_raw=0.4980, running_loss=0.4423, LR=0.000100
[2025-08-27 11:24:26,611][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063296] [Batch 01696/03080] [00:21:24/00:17:27, 0.757s/it]: train_loss_raw=0.4553, running_loss=0.4443, LR=0.000100
[2025-08-27 11:24:32,771][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063304] [Batch 01704/03080] [00:21:30/00:17:21, 0.757s/it]: train_loss_raw=0.4156, running_loss=0.4436, LR=0.000100
[2025-08-27 11:24:38,856][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063312] [Batch 01712/03080] [00:21:36/00:17:15, 0.757s/it]: train_loss_raw=0.4029, running_loss=0.4427, LR=0.000100
[2025-08-27 11:24:44,905][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063320] [Batch 01720/03080] [00:21:42/00:17:09, 0.757s/it]: train_loss_raw=0.4911, running_loss=0.4417, LR=0.000100
[2025-08-27 11:24:50,851][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063328] [Batch 01728/03080] [00:21:48/00:17:03, 0.757s/it]: train_loss_raw=0.4520, running_loss=0.4439, LR=0.000100
[2025-08-27 11:24:56,917][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063336] [Batch 01736/03080] [00:21:54/00:16:57, 0.757s/it]: train_loss_raw=0.4751, running_loss=0.4434, LR=0.000100
[2025-08-27 11:25:02,848][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063344] [Batch 01744/03080] [00:22:00/00:16:51, 0.757s/it]: train_loss_raw=0.4805, running_loss=0.4419, LR=0.000100
[2025-08-27 11:25:08,813][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063352] [Batch 01752/03080] [00:22:06/00:16:45, 0.757s/it]: train_loss_raw=0.4877, running_loss=0.4415, LR=0.000100
[2025-08-27 11:25:15,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063360] [Batch 01760/03080] [00:22:12/00:16:39, 0.757s/it]: train_loss_raw=0.4477, running_loss=0.4415, LR=0.000100
[2025-08-27 11:25:21,280][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063368] [Batch 01768/03080] [00:22:18/00:16:33, 0.757s/it]: train_loss_raw=0.5113, running_loss=0.4424, LR=0.000100
[2025-08-27 11:25:27,308][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063376] [Batch 01776/03080] [00:22:24/00:16:27, 0.757s/it]: train_loss_raw=0.4895, running_loss=0.4410, LR=0.000100
[2025-08-27 11:25:33,374][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063384] [Batch 01784/03080] [00:22:30/00:16:21, 0.757s/it]: train_loss_raw=0.3881, running_loss=0.4413, LR=0.000100
[2025-08-27 11:25:39,254][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063392] [Batch 01792/03080] [00:22:36/00:16:15, 0.757s/it]: train_loss_raw=0.4463, running_loss=0.4442, LR=0.000100
[2025-08-27 11:25:45,198][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063400] [Batch 01800/03080] [00:22:42/00:16:08, 0.757s/it]: train_loss_raw=0.4963, running_loss=0.4449, LR=0.000100
[2025-08-27 11:25:51,211][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063408] [Batch 01808/03080] [00:22:48/00:16:02, 0.757s/it]: train_loss_raw=0.4045, running_loss=0.4455, LR=0.000100
[2025-08-27 11:25:57,430][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063416] [Batch 01816/03080] [00:22:54/00:15:56, 0.757s/it]: train_loss_raw=0.3747, running_loss=0.4442, LR=0.000100
[2025-08-27 11:26:03,512][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063424] [Batch 01824/03080] [00:23:00/00:15:50, 0.757s/it]: train_loss_raw=0.4899, running_loss=0.4436, LR=0.000100
[2025-08-27 11:26:09,582][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063432] [Batch 01832/03080] [00:23:07/00:15:44, 0.757s/it]: train_loss_raw=0.4836, running_loss=0.4412, LR=0.000100
[2025-08-27 11:26:15,459][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063440] [Batch 01840/03080] [00:23:12/00:15:38, 0.757s/it]: train_loss_raw=0.5129, running_loss=0.4425, LR=0.000100
[2025-08-27 11:26:21,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063448] [Batch 01848/03080] [00:23:19/00:15:32, 0.757s/it]: train_loss_raw=0.4688, running_loss=0.4448, LR=0.000100
[2025-08-27 11:26:27,770][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063456] [Batch 01856/03080] [00:23:25/00:15:26, 0.757s/it]: train_loss_raw=0.5145, running_loss=0.4428, LR=0.000100
[2025-08-27 11:26:33,831][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063464] [Batch 01864/03080] [00:23:31/00:15:20, 0.757s/it]: train_loss_raw=0.4380, running_loss=0.4417, LR=0.000100
[2025-08-27 11:26:39,768][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063472] [Batch 01872/03080] [00:23:37/00:15:14, 0.757s/it]: train_loss_raw=0.4592, running_loss=0.4409, LR=0.000100
[2025-08-27 11:26:45,848][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063480] [Batch 01880/03080] [00:23:43/00:15:08, 0.757s/it]: train_loss_raw=0.3850, running_loss=0.4410, LR=0.000100
[2025-08-27 11:26:51,716][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063488] [Batch 01888/03080] [00:23:49/00:15:02, 0.757s/it]: train_loss_raw=0.4440, running_loss=0.4406, LR=0.000100
[2025-08-27 11:26:57,637][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063496] [Batch 01896/03080] [00:23:55/00:14:56, 0.757s/it]: train_loss_raw=0.5124, running_loss=0.4431, LR=0.000100
[2025-08-27 11:27:03,737][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063504] [Batch 01904/03080] [00:24:01/00:14:50, 0.757s/it]: train_loss_raw=0.3432, running_loss=0.4416, LR=0.000100
[2025-08-27 11:27:09,765][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063512] [Batch 01912/03080] [00:24:07/00:14:44, 0.757s/it]: train_loss_raw=0.4499, running_loss=0.4429, LR=0.000100
[2025-08-27 11:27:15,693][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063520] [Batch 01920/03080] [00:24:13/00:14:37, 0.757s/it]: train_loss_raw=0.3656, running_loss=0.4405, LR=0.000100
[2025-08-27 11:27:21,711][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063528] [Batch 01928/03080] [00:24:19/00:14:31, 0.757s/it]: train_loss_raw=0.5638, running_loss=0.4416, LR=0.000100
[2025-08-27 11:27:27,768][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063536] [Batch 01936/03080] [00:24:25/00:14:25, 0.757s/it]: train_loss_raw=0.4558, running_loss=0.4426, LR=0.000100
[2025-08-27 11:27:33,983][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063544] [Batch 01944/03080] [00:24:31/00:14:19, 0.757s/it]: train_loss_raw=0.4242, running_loss=0.4437, LR=0.000100
[2025-08-27 11:27:39,687][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063552] [Batch 01952/03080] [00:24:37/00:14:13, 0.757s/it]: train_loss_raw=0.4134, running_loss=0.4463, LR=0.000100
[2025-08-27 11:27:45,251][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063560] [Batch 01960/03080] [00:24:42/00:14:07, 0.756s/it]: train_loss_raw=0.4810, running_loss=0.4468, LR=0.000100
[2025-08-27 11:27:51,188][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063568] [Batch 01968/03080] [00:24:48/00:14:01, 0.756s/it]: train_loss_raw=0.4557, running_loss=0.4470, LR=0.000100
[2025-08-27 11:27:57,200][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063576] [Batch 01976/03080] [00:24:54/00:13:55, 0.756s/it]: train_loss_raw=0.4344, running_loss=0.4477, LR=0.000100
[2025-08-27 11:28:03,185][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063584] [Batch 01984/03080] [00:25:00/00:13:48, 0.756s/it]: train_loss_raw=0.4696, running_loss=0.4471, LR=0.000100
[2025-08-27 11:28:09,257][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063592] [Batch 01992/03080] [00:25:06/00:13:42, 0.756s/it]: train_loss_raw=0.4741, running_loss=0.4473, LR=0.000100
[2025-08-27 11:28:15,404][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063600] [Batch 02000/03080] [00:25:12/00:13:36, 0.756s/it]: train_loss_raw=0.5736, running_loss=0.4481, LR=0.000100
[2025-08-27 11:28:21,346][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063608] [Batch 02008/03080] [00:25:18/00:13:30, 0.756s/it]: train_loss_raw=0.4721, running_loss=0.4495, LR=0.000100
[2025-08-27 11:28:27,495][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063616] [Batch 02016/03080] [00:25:24/00:13:24, 0.756s/it]: train_loss_raw=0.3961, running_loss=0.4498, LR=0.000100
[2025-08-27 11:28:33,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063624] [Batch 02024/03080] [00:25:31/00:13:18, 0.757s/it]: train_loss_raw=0.4325, running_loss=0.4486, LR=0.000100
[2025-08-27 11:28:40,142][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063632] [Batch 02032/03080] [00:25:37/00:13:12, 0.757s/it]: train_loss_raw=0.4093, running_loss=0.4473, LR=0.000100
[2025-08-27 11:28:45,599][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063640] [Batch 02040/03080] [00:25:43/00:13:06, 0.756s/it]: train_loss_raw=0.5359, running_loss=0.4452, LR=0.000100
[2025-08-27 11:28:51,731][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063648] [Batch 02048/03080] [00:25:49/00:13:00, 0.756s/it]: train_loss_raw=0.4073, running_loss=0.4483, LR=0.000100
[2025-08-27 11:28:57,600][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063656] [Batch 02056/03080] [00:25:55/00:12:54, 0.756s/it]: train_loss_raw=0.3805, running_loss=0.4456, LR=0.000100
[2025-08-27 11:29:03,574][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063664] [Batch 02064/03080] [00:26:00/00:12:48, 0.756s/it]: train_loss_raw=0.4131, running_loss=0.4467, LR=0.000100
[2025-08-27 11:29:09,634][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063672] [Batch 02072/03080] [00:26:07/00:12:42, 0.756s/it]: train_loss_raw=0.4444, running_loss=0.4464, LR=0.000100
[2025-08-27 11:29:15,714][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063680] [Batch 02080/03080] [00:26:13/00:12:36, 0.756s/it]: train_loss_raw=0.5423, running_loss=0.4486, LR=0.000100
[2025-08-27 11:29:21,873][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063688] [Batch 02088/03080] [00:26:19/00:12:30, 0.756s/it]: train_loss_raw=0.4282, running_loss=0.4471, LR=0.000100
[2025-08-27 11:29:27,944][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063696] [Batch 02096/03080] [00:26:25/00:12:24, 0.756s/it]: train_loss_raw=0.5029, running_loss=0.4483, LR=0.000100
[2025-08-27 11:29:33,925][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063704] [Batch 02104/03080] [00:26:31/00:12:18, 0.756s/it]: train_loss_raw=0.3250, running_loss=0.4475, LR=0.000100
[2025-08-27 11:29:40,057][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063712] [Batch 02112/03080] [00:26:37/00:12:12, 0.756s/it]: train_loss_raw=0.4522, running_loss=0.4495, LR=0.000100
[2025-08-27 11:29:46,001][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063720] [Batch 02120/03080] [00:26:43/00:12:06, 0.756s/it]: train_loss_raw=0.4172, running_loss=0.4472, LR=0.000100
[2025-08-27 11:29:51,997][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063728] [Batch 02128/03080] [00:26:49/00:12:00, 0.756s/it]: train_loss_raw=0.4650, running_loss=0.4466, LR=0.000100
[2025-08-27 11:29:58,036][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063736] [Batch 02136/03080] [00:26:55/00:11:53, 0.756s/it]: train_loss_raw=0.3837, running_loss=0.4469, LR=0.000100
[2025-08-27 11:30:04,049][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063744] [Batch 02144/03080] [00:27:01/00:11:47, 0.756s/it]: train_loss_raw=0.3836, running_loss=0.4454, LR=0.000100
[2025-08-27 11:30:10,041][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063752] [Batch 02152/03080] [00:27:07/00:11:41, 0.756s/it]: train_loss_raw=0.4694, running_loss=0.4424, LR=0.000100
[2025-08-27 11:30:16,042][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063760] [Batch 02160/03080] [00:27:13/00:11:35, 0.756s/it]: train_loss_raw=0.4523, running_loss=0.4420, LR=0.000100
[2025-08-27 11:30:22,001][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063768] [Batch 02168/03080] [00:27:19/00:11:29, 0.756s/it]: train_loss_raw=0.3240, running_loss=0.4404, LR=0.000100
[2025-08-27 11:30:27,638][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063776] [Batch 02176/03080] [00:27:25/00:11:23, 0.756s/it]: train_loss_raw=0.4283, running_loss=0.4394, LR=0.000100
[2025-08-27 11:30:33,303][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063784] [Batch 02184/03080] [00:27:30/00:11:17, 0.756s/it]: train_loss_raw=0.4407, running_loss=0.4390, LR=0.000100
[2025-08-27 11:30:39,504][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063792] [Batch 02192/03080] [00:27:36/00:11:11, 0.756s/it]: train_loss_raw=0.4202, running_loss=0.4369, LR=0.000100
[2025-08-27 11:30:45,508][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063800] [Batch 02200/03080] [00:27:42/00:11:05, 0.756s/it]: train_loss_raw=0.3598, running_loss=0.4362, LR=0.000100
[2025-08-27 11:30:51,519][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063808] [Batch 02208/03080] [00:27:48/00:10:59, 0.756s/it]: train_loss_raw=0.4238, running_loss=0.4360, LR=0.000100
[2025-08-27 11:30:57,583][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063816] [Batch 02216/03080] [00:27:55/00:10:53, 0.756s/it]: train_loss_raw=0.4440, running_loss=0.4356, LR=0.000100
[2025-08-27 11:31:03,582][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063824] [Batch 02224/03080] [00:28:01/00:10:47, 0.756s/it]: train_loss_raw=0.4812, running_loss=0.4389, LR=0.000100
[2025-08-27 11:31:09,624][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063832] [Batch 02232/03080] [00:28:07/00:10:40, 0.756s/it]: train_loss_raw=0.4772, running_loss=0.4403, LR=0.000100
[2025-08-27 11:31:15,624][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063840] [Batch 02240/03080] [00:28:13/00:10:34, 0.756s/it]: train_loss_raw=0.4175, running_loss=0.4413, LR=0.000100
[2025-08-27 11:31:21,705][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063848] [Batch 02248/03080] [00:28:19/00:10:28, 0.756s/it]: train_loss_raw=0.4534, running_loss=0.4421, LR=0.000100
[2025-08-27 11:31:27,888][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063856] [Batch 02256/03080] [00:28:25/00:10:22, 0.756s/it]: train_loss_raw=0.4699, running_loss=0.4421, LR=0.000100
[2025-08-27 11:31:33,859][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063864] [Batch 02264/03080] [00:28:31/00:10:16, 0.756s/it]: train_loss_raw=0.4177, running_loss=0.4424, LR=0.000100
[2025-08-27 11:31:39,986][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063872] [Batch 02272/03080] [00:28:37/00:10:10, 0.756s/it]: train_loss_raw=0.4463, running_loss=0.4414, LR=0.000100
[2025-08-27 11:31:46,216][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063880] [Batch 02280/03080] [00:28:43/00:10:04, 0.756s/it]: train_loss_raw=0.4715, running_loss=0.4394, LR=0.000100
[2025-08-27 11:31:52,249][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063888] [Batch 02288/03080] [00:28:49/00:09:58, 0.756s/it]: train_loss_raw=0.4011, running_loss=0.4400, LR=0.000100
[2025-08-27 11:31:58,312][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063896] [Batch 02296/03080] [00:28:55/00:09:52, 0.756s/it]: train_loss_raw=0.4087, running_loss=0.4387, LR=0.000100
[2025-08-27 11:32:04,303][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063904] [Batch 02304/03080] [00:29:01/00:09:46, 0.756s/it]: train_loss_raw=0.5815, running_loss=0.4404, LR=0.000100
[2025-08-27 11:32:10,396][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063912] [Batch 02312/03080] [00:29:07/00:09:40, 0.756s/it]: train_loss_raw=0.4084, running_loss=0.4401, LR=0.000100
[2025-08-27 11:32:16,343][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063920] [Batch 02320/03080] [00:29:13/00:09:34, 0.756s/it]: train_loss_raw=0.3888, running_loss=0.4400, LR=0.000100
[2025-08-27 11:32:22,401][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063928] [Batch 02328/03080] [00:29:19/00:09:28, 0.756s/it]: train_loss_raw=0.4533, running_loss=0.4383, LR=0.000100
[2025-08-27 11:32:28,495][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063936] [Batch 02336/03080] [00:29:25/00:09:22, 0.756s/it]: train_loss_raw=0.4054, running_loss=0.4398, LR=0.000100
[2025-08-27 11:32:34,466][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063944] [Batch 02344/03080] [00:29:31/00:09:16, 0.756s/it]: train_loss_raw=0.5127, running_loss=0.4415, LR=0.000100
[2025-08-27 11:32:40,571][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063952] [Batch 02352/03080] [00:29:37/00:09:10, 0.756s/it]: train_loss_raw=0.4950, running_loss=0.4402, LR=0.000100
[2025-08-27 11:32:46,672][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063960] [Batch 02360/03080] [00:29:44/00:09:04, 0.756s/it]: train_loss_raw=0.4284, running_loss=0.4370, LR=0.000100
[2025-08-27 11:32:52,638][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063968] [Batch 02368/03080] [00:29:50/00:08:58, 0.756s/it]: train_loss_raw=0.5225, running_loss=0.4371, LR=0.000100
[2025-08-27 11:32:58,657][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063976] [Batch 02376/03080] [00:29:56/00:08:52, 0.756s/it]: train_loss_raw=0.3812, running_loss=0.4367, LR=0.000100
[2025-08-27 11:33:04,129][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063984] [Batch 02384/03080] [00:30:01/00:08:45, 0.756s/it]: train_loss_raw=0.4592, running_loss=0.4373, LR=0.000100
[2025-08-27 11:33:09,538][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063992] [Batch 02392/03080] [00:30:06/00:08:39, 0.755s/it]: train_loss_raw=0.4458, running_loss=0.4391, LR=0.000100
[2025-08-27 11:33:14,947][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064000] [Batch 02400/03080] [00:30:12/00:08:33, 0.755s/it]: train_loss_raw=0.4571, running_loss=0.4385, LR=0.000100
[2025-08-27 11:33:24,393][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064008] [Batch 02408/03080] [00:30:21/00:08:28, 0.757s/it]: train_loss_raw=0.4299, running_loss=0.4364, LR=0.000100
[2025-08-27 11:33:30,334][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064016] [Batch 02416/03080] [00:30:27/00:08:22, 0.757s/it]: train_loss_raw=0.4156, running_loss=0.4358, LR=0.000100
[2025-08-27 11:33:36,344][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064024] [Batch 02424/03080] [00:30:33/00:08:16, 0.757s/it]: train_loss_raw=0.4412, running_loss=0.4365, LR=0.000100
[2025-08-27 11:33:42,364][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064032] [Batch 02432/03080] [00:30:39/00:08:10, 0.756s/it]: train_loss_raw=0.3583, running_loss=0.4355, LR=0.000100
[2025-08-27 11:33:48,405][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064040] [Batch 02440/03080] [00:30:45/00:08:04, 0.756s/it]: train_loss_raw=0.3756, running_loss=0.4351, LR=0.000100
[2025-08-27 11:33:54,703][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064048] [Batch 02448/03080] [00:30:52/00:07:58, 0.757s/it]: train_loss_raw=0.4755, running_loss=0.4379, LR=0.000100
[2025-08-27 11:34:00,714][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064056] [Batch 02456/03080] [00:30:58/00:07:52, 0.757s/it]: train_loss_raw=0.4944, running_loss=0.4435, LR=0.000100
[2025-08-27 11:34:06,780][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064064] [Batch 02464/03080] [00:31:04/00:07:46, 0.757s/it]: train_loss_raw=0.3844, running_loss=0.4425, LR=0.000100
[2025-08-27 11:34:12,757][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064072] [Batch 02472/03080] [00:31:10/00:07:39, 0.757s/it]: train_loss_raw=0.3697, running_loss=0.4395, LR=0.000100
[2025-08-27 11:34:18,791][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064080] [Batch 02480/03080] [00:31:16/00:07:33, 0.757s/it]: train_loss_raw=0.4182, running_loss=0.4404, LR=0.000100
[2025-08-27 11:34:24,841][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064088] [Batch 02488/03080] [00:31:22/00:07:27, 0.757s/it]: train_loss_raw=0.4044, running_loss=0.4407, LR=0.000100
[2025-08-27 11:34:30,777][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064096] [Batch 02496/03080] [00:31:28/00:07:21, 0.756s/it]: train_loss_raw=0.4060, running_loss=0.4397, LR=0.000100
[2025-08-27 11:34:36,188][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064104] [Batch 02504/03080] [00:31:33/00:07:15, 0.756s/it]: train_loss_raw=0.5217, running_loss=0.4377, LR=0.000100
[2025-08-27 11:34:41,879][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064112] [Batch 02512/03080] [00:31:39/00:07:09, 0.756s/it]: train_loss_raw=0.3826, running_loss=0.4376, LR=0.000100
[2025-08-27 11:34:47,880][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064120] [Batch 02520/03080] [00:31:45/00:07:03, 0.756s/it]: train_loss_raw=0.5252, running_loss=0.4384, LR=0.000100
[2025-08-27 11:34:53,886][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064128] [Batch 02528/03080] [00:31:51/00:06:57, 0.756s/it]: train_loss_raw=0.3954, running_loss=0.4384, LR=0.000100
[2025-08-27 11:34:59,907][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064136] [Batch 02536/03080] [00:31:57/00:06:51, 0.756s/it]: train_loss_raw=0.4162, running_loss=0.4375, LR=0.000100
[2025-08-27 11:35:05,830][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064144] [Batch 02544/03080] [00:32:03/00:06:45, 0.756s/it]: train_loss_raw=0.4570, running_loss=0.4371, LR=0.000100
[2025-08-27 11:35:11,801][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064152] [Batch 02552/03080] [00:32:09/00:06:39, 0.756s/it]: train_loss_raw=0.5359, running_loss=0.4406, LR=0.000100
[2025-08-27 11:35:17,775][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064160] [Batch 02560/03080] [00:32:15/00:06:33, 0.756s/it]: train_loss_raw=0.3885, running_loss=0.4386, LR=0.000100
[2025-08-27 11:35:23,770][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064168] [Batch 02568/03080] [00:32:21/00:06:27, 0.756s/it]: train_loss_raw=0.4807, running_loss=0.4375, LR=0.000100
[2025-08-27 11:35:29,785][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064176] [Batch 02576/03080] [00:32:27/00:06:20, 0.756s/it]: train_loss_raw=0.4169, running_loss=0.4376, LR=0.000100
[2025-08-27 11:35:35,773][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064184] [Batch 02584/03080] [00:32:33/00:06:14, 0.756s/it]: train_loss_raw=0.4950, running_loss=0.4397, LR=0.000100
[2025-08-27 11:35:41,764][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064192] [Batch 02592/03080] [00:32:39/00:06:08, 0.756s/it]: train_loss_raw=0.4324, running_loss=0.4401, LR=0.000100
[2025-08-27 11:35:47,847][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064200] [Batch 02600/03080] [00:32:45/00:06:02, 0.756s/it]: train_loss_raw=0.4860, running_loss=0.4393, LR=0.000100
[2025-08-27 11:35:53,893][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064208] [Batch 02608/03080] [00:32:51/00:05:56, 0.756s/it]: train_loss_raw=0.4089, running_loss=0.4383, LR=0.000100
[2025-08-27 11:35:59,831][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064216] [Batch 02616/03080] [00:32:57/00:05:50, 0.756s/it]: train_loss_raw=0.3675, running_loss=0.4389, LR=0.000100
[2025-08-27 11:36:05,790][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064224] [Batch 02624/03080] [00:33:03/00:05:44, 0.756s/it]: train_loss_raw=0.4023, running_loss=0.4371, LR=0.000100
[2025-08-27 11:36:11,796][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064232] [Batch 02632/03080] [00:33:09/00:05:38, 0.756s/it]: train_loss_raw=0.5641, running_loss=0.4412, LR=0.000100
[2025-08-27 11:36:17,880][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064240] [Batch 02640/03080] [00:33:15/00:05:32, 0.756s/it]: train_loss_raw=0.4547, running_loss=0.4422, LR=0.000100
[2025-08-27 11:36:23,960][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064248] [Batch 02648/03080] [00:33:21/00:05:26, 0.756s/it]: train_loss_raw=0.3215, running_loss=0.4406, LR=0.000100
[2025-08-27 11:36:29,967][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064256] [Batch 02656/03080] [00:33:27/00:05:20, 0.756s/it]: train_loss_raw=0.4525, running_loss=0.4401, LR=0.000100
[2025-08-27 11:36:36,124][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064264] [Batch 02664/03080] [00:33:33/00:05:14, 0.756s/it]: train_loss_raw=0.3856, running_loss=0.4398, LR=0.000100
[2025-08-27 11:36:42,105][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064272] [Batch 02672/03080] [00:33:39/00:05:08, 0.756s/it]: train_loss_raw=0.4681, running_loss=0.4399, LR=0.000100
[2025-08-27 11:36:48,160][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064280] [Batch 02680/03080] [00:33:45/00:05:02, 0.756s/it]: train_loss_raw=0.3777, running_loss=0.4394, LR=0.000100
[2025-08-27 11:36:54,325][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064288] [Batch 02688/03080] [00:33:51/00:04:56, 0.756s/it]: train_loss_raw=0.4315, running_loss=0.4392, LR=0.000100
[2025-08-27 11:37:00,282][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064296] [Batch 02696/03080] [00:33:57/00:04:50, 0.756s/it]: train_loss_raw=0.3328, running_loss=0.4374, LR=0.000100
[2025-08-27 11:37:06,346][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064304] [Batch 02704/03080] [00:34:03/00:04:44, 0.756s/it]: train_loss_raw=0.4812, running_loss=0.4368, LR=0.000100
[2025-08-27 11:37:12,569][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064312] [Batch 02712/03080] [00:34:09/00:04:38, 0.756s/it]: train_loss_raw=0.4081, running_loss=0.4352, LR=0.000100
[2025-08-27 11:37:18,729][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064320] [Batch 02720/03080] [00:34:16/00:04:32, 0.756s/it]: train_loss_raw=0.4122, running_loss=0.4331, LR=0.000100
[2025-08-27 11:37:24,853][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064328] [Batch 02728/03080] [00:34:22/00:04:26, 0.756s/it]: train_loss_raw=0.3668, running_loss=0.4327, LR=0.000100
[2025-08-27 11:37:30,954][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064336] [Batch 02736/03080] [00:34:28/00:04:20, 0.756s/it]: train_loss_raw=0.4859, running_loss=0.4341, LR=0.000100
[2025-08-27 11:37:37,110][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064344] [Batch 02744/03080] [00:34:34/00:04:14, 0.756s/it]: train_loss_raw=0.4348, running_loss=0.4355, LR=0.000100
[2025-08-27 11:37:43,390][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064352] [Batch 02752/03080] [00:34:40/00:04:08, 0.756s/it]: train_loss_raw=0.3921, running_loss=0.4340, LR=0.000100
[2025-08-27 11:37:49,473][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064360] [Batch 02760/03080] [00:34:46/00:04:01, 0.756s/it]: train_loss_raw=0.4621, running_loss=0.4356, LR=0.000100
[2025-08-27 11:37:55,474][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064368] [Batch 02768/03080] [00:34:52/00:03:55, 0.756s/it]: train_loss_raw=0.4640, running_loss=0.4375, LR=0.000100
[2025-08-27 11:38:01,579][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064376] [Batch 02776/03080] [00:34:59/00:03:49, 0.756s/it]: train_loss_raw=0.4330, running_loss=0.4386, LR=0.000100
[2025-08-27 11:38:07,504][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064384] [Batch 02784/03080] [00:35:04/00:03:43, 0.756s/it]: train_loss_raw=0.3841, running_loss=0.4382, LR=0.000100
[2025-08-27 11:38:13,451][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064392] [Batch 02792/03080] [00:35:10/00:03:37, 0.756s/it]: train_loss_raw=0.3958, running_loss=0.4387, LR=0.000100
[2025-08-27 11:38:19,438][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064400] [Batch 02800/03080] [00:35:16/00:03:31, 0.756s/it]: train_loss_raw=0.3918, running_loss=0.4371, LR=0.000100
[2025-08-27 11:38:25,574][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064408] [Batch 02808/03080] [00:35:22/00:03:25, 0.756s/it]: train_loss_raw=0.5006, running_loss=0.4399, LR=0.000100
[2025-08-27 11:38:31,726][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064416] [Batch 02816/03080] [00:35:29/00:03:19, 0.756s/it]: train_loss_raw=0.4068, running_loss=0.4397, LR=0.000100
[2025-08-27 11:38:37,685][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064424] [Batch 02824/03080] [00:35:35/00:03:13, 0.756s/it]: train_loss_raw=0.4099, running_loss=0.4421, LR=0.000100
[2025-08-27 11:38:43,442][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064432] [Batch 02832/03080] [00:35:40/00:03:07, 0.756s/it]: train_loss_raw=0.4019, running_loss=0.4395, LR=0.000100
[2025-08-27 11:38:49,444][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064440] [Batch 02840/03080] [00:35:46/00:03:01, 0.756s/it]: train_loss_raw=0.4032, running_loss=0.4384, LR=0.000100
[2025-08-27 11:38:55,407][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064448] [Batch 02848/03080] [00:35:52/00:02:55, 0.756s/it]: train_loss_raw=0.6158, running_loss=0.4402, LR=0.000100
[2025-08-27 11:39:01,474][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064456] [Batch 02856/03080] [00:35:58/00:02:49, 0.756s/it]: train_loss_raw=0.3666, running_loss=0.4382, LR=0.000100
[2025-08-27 11:39:07,528][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064464] [Batch 02864/03080] [00:36:04/00:02:43, 0.756s/it]: train_loss_raw=0.4684, running_loss=0.4368, LR=0.000100
[2025-08-27 11:39:13,526][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064472] [Batch 02872/03080] [00:36:10/00:02:37, 0.756s/it]: train_loss_raw=0.4678, running_loss=0.4336, LR=0.000100
[2025-08-27 11:39:19,548][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064480] [Batch 02880/03080] [00:36:16/00:02:31, 0.756s/it]: train_loss_raw=0.4746, running_loss=0.4332, LR=0.000100
[2025-08-27 11:39:25,584][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064488] [Batch 02888/03080] [00:36:23/00:02:25, 0.756s/it]: train_loss_raw=0.4573, running_loss=0.4330, LR=0.000100
[2025-08-27 11:39:31,612][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064496] [Batch 02896/03080] [00:36:29/00:02:19, 0.756s/it]: train_loss_raw=0.4461, running_loss=0.4320, LR=0.000100
[2025-08-27 11:39:37,618][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064504] [Batch 02904/03080] [00:36:35/00:02:13, 0.756s/it]: train_loss_raw=0.4228, running_loss=0.4329, LR=0.000100
[2025-08-27 11:39:43,660][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064512] [Batch 02912/03080] [00:36:41/00:02:06, 0.756s/it]: train_loss_raw=0.4629, running_loss=0.4339, LR=0.000100
[2025-08-27 11:39:49,822][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064520] [Batch 02920/03080] [00:36:47/00:02:00, 0.756s/it]: train_loss_raw=0.4694, running_loss=0.4369, LR=0.000100
[2025-08-27 11:39:55,699][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064528] [Batch 02928/03080] [00:36:53/00:01:54, 0.756s/it]: train_loss_raw=0.4863, running_loss=0.4370, LR=0.000100
[2025-08-27 11:40:01,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064536] [Batch 02936/03080] [00:36:59/00:01:48, 0.756s/it]: train_loss_raw=0.4131, running_loss=0.4338, LR=0.000100
[2025-08-27 11:40:07,320][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064544] [Batch 02944/03080] [00:37:04/00:01:42, 0.756s/it]: train_loss_raw=0.4534, running_loss=0.4345, LR=0.000100
[2025-08-27 11:40:12,901][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064552] [Batch 02952/03080] [00:37:10/00:01:36, 0.756s/it]: train_loss_raw=0.4289, running_loss=0.4365, LR=0.000100
[2025-08-27 11:40:18,690][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064560] [Batch 02960/03080] [00:37:16/00:01:30, 0.755s/it]: train_loss_raw=0.3756, running_loss=0.4352, LR=0.000100
[2025-08-27 11:40:24,428][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064568] [Batch 02968/03080] [00:37:21/00:01:24, 0.755s/it]: train_loss_raw=0.4527, running_loss=0.4356, LR=0.000100
[2025-08-27 11:40:30,021][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064576] [Batch 02976/03080] [00:37:27/00:01:18, 0.755s/it]: train_loss_raw=0.4342, running_loss=0.4357, LR=0.000100
[2025-08-27 11:40:35,793][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064584] [Batch 02984/03080] [00:37:33/00:01:12, 0.755s/it]: train_loss_raw=0.4096, running_loss=0.4362, LR=0.000100
[2025-08-27 11:40:41,288][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064592] [Batch 02992/03080] [00:37:38/00:01:06, 0.755s/it]: train_loss_raw=0.4726, running_loss=0.4358, LR=0.000100
[2025-08-27 11:40:46,866][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064600] [Batch 03000/03080] [00:37:44/00:01:00, 0.755s/it]: train_loss_raw=0.4344, running_loss=0.4358, LR=0.000100
[2025-08-27 11:40:52,858][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064608] [Batch 03008/03080] [00:37:50/00:00:54, 0.755s/it]: train_loss_raw=0.4207, running_loss=0.4359, LR=0.000100
[2025-08-27 11:40:58,832][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064616] [Batch 03016/03080] [00:37:56/00:00:48, 0.755s/it]: train_loss_raw=0.4037, running_loss=0.4350, LR=0.000100
[2025-08-27 11:41:04,764][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064624] [Batch 03024/03080] [00:38:02/00:00:42, 0.755s/it]: train_loss_raw=0.3967, running_loss=0.4349, LR=0.000100
[2025-08-27 11:41:10,848][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064632] [Batch 03032/03080] [00:38:08/00:00:36, 0.755s/it]: train_loss_raw=0.4294, running_loss=0.4358, LR=0.000100
[2025-08-27 11:41:16,752][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064640] [Batch 03040/03080] [00:38:14/00:00:30, 0.755s/it]: train_loss_raw=0.4218, running_loss=0.4355, LR=0.000100
[2025-08-27 11:41:22,544][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064648] [Batch 03048/03080] [00:38:19/00:00:24, 0.755s/it]: train_loss_raw=0.5102, running_loss=0.4363, LR=0.000100
[2025-08-27 11:41:28,280][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064656] [Batch 03056/03080] [00:38:25/00:00:18, 0.754s/it]: train_loss_raw=0.4389, running_loss=0.4373, LR=0.000100
[2025-08-27 11:41:34,255][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064664] [Batch 03064/03080] [00:38:31/00:00:12, 0.754s/it]: train_loss_raw=0.4928, running_loss=0.4376, LR=0.000100
[2025-08-27 11:41:40,137][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064672] [Batch 03072/03080] [00:38:37/00:00:06, 0.754s/it]: train_loss_raw=0.4298, running_loss=0.4371, LR=0.000100
[2025-08-27 11:41:45,566][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064680] [Batch 03080/03080] [00:38:42/00:00:00, 0.754s/it]: train_loss_raw=0.3749, running_loss=0.4397, LR=0.000100
[2025-08-27 11:41:46,104][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-27 11:41:57,955][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00007/00310] [00:00:11/00:07:27, 1.481s/it]
[2025-08-27 11:42:09,970][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00015/00310] [00:00:23/00:07:18, 1.492s/it]
[2025-08-27 11:42:22,460][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00023/00310] [00:00:36/00:07:13, 1.515s/it]
[2025-08-27 11:42:35,114][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00031/00310] [00:00:49/00:07:05, 1.532s/it]
[2025-08-27 11:42:47,023][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00039/00310] [00:01:00/00:06:51, 1.523s/it]
[2025-08-27 11:42:59,247][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00047/00310] [00:01:13/00:06:39, 1.524s/it]
[2025-08-27 11:43:11,775][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00055/00310] [00:01:25/00:06:28, 1.530s/it]
[2025-08-27 11:43:23,428][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00063/00310] [00:01:37/00:06:14, 1.521s/it]
[2025-08-27 11:43:35,249][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00071/00310] [00:01:49/00:06:00, 1.516s/it]
[2025-08-27 11:43:47,186][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00079/00310] [00:02:01/00:05:48, 1.514s/it]
[2025-08-27 11:43:57,985][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00087/00310] [00:02:11/00:05:32, 1.499s/it]
[2025-08-27 11:44:09,779][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00095/00310] [00:02:23/00:05:20, 1.497s/it]
[2025-08-27 11:44:21,195][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00103/00310] [00:02:35/00:05:07, 1.491s/it]
[2025-08-27 11:44:32,748][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00111/00310] [00:02:46/00:04:54, 1.488s/it]
[2025-08-27 11:44:44,512][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00119/00310] [00:02:58/00:04:42, 1.487s/it]
[2025-08-27 11:44:57,143][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00127/00310] [00:03:11/00:04:31, 1.492s/it]
[2025-08-27 11:45:09,507][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00135/00310] [00:03:23/00:04:20, 1.496s/it]
[2025-08-27 11:45:21,754][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00143/00310] [00:03:35/00:04:08, 1.498s/it]
[2025-08-27 11:45:33,275][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00151/00310] [00:03:47/00:03:56, 1.495s/it]
[2025-08-27 11:45:44,576][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00159/00310] [00:03:58/00:03:43, 1.490s/it]
[2025-08-27 11:45:57,512][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00167/00310] [00:04:11/00:03:32, 1.496s/it]
[2025-08-27 11:46:07,873][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00175/00310] [00:04:21/00:03:19, 1.487s/it]
[2025-08-27 11:46:18,766][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00183/00310] [00:04:32/00:03:06, 1.482s/it]
[2025-08-27 11:46:29,272][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00191/00310] [00:04:43/00:02:54, 1.475s/it]
[2025-08-27 11:46:40,605][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00199/00310] [00:04:54/00:02:41, 1.473s/it]
[2025-08-27 11:46:51,999][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00207/00310] [00:05:05/00:02:30, 1.471s/it]
[2025-08-27 11:47:02,746][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00215/00310] [00:05:16/00:02:17, 1.466s/it]
[2025-08-27 11:47:14,497][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00223/00310] [00:05:28/00:02:06, 1.466s/it]
[2025-08-27 11:47:26,573][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00231/00310] [00:05:40/00:01:54, 1.468s/it]
[2025-08-27 11:47:38,683][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00239/00310] [00:05:52/00:01:42, 1.469s/it]
[2025-08-27 11:47:49,476][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00247/00310] [00:06:03/00:01:30, 1.465s/it]
[2025-08-27 11:48:01,131][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00255/00310] [00:06:15/00:01:19, 1.465s/it]
[2025-08-27 11:48:12,655][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00263/00310] [00:06:26/00:01:07, 1.464s/it]
[2025-08-27 11:48:23,671][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00271/00310] [00:06:37/00:00:55, 1.462s/it]
[2025-08-27 11:48:35,500][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00279/00310] [00:06:49/00:00:43, 1.462s/it]
[2025-08-27 11:48:47,180][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00287/00310] [00:07:01/00:00:32, 1.462s/it]
[2025-08-27 11:48:58,617][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00295/00310] [00:07:12/00:00:20, 1.461s/it]
[2025-08-27 11:49:10,851][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00303/00310] [00:07:24/00:00:08, 1.463s/it]
[2025-08-27 11:49:19,811][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=0.43971, valid_loss=1.43924
[2025-08-27 11:49:19,811][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-27 11:49:19,811][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.508
[2025-08-27 11:49:19,811][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.130
[2025-08-27 11:49:19,812][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.132
[2025-08-27 11:49:19,812][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.068
[2025-08-27 11:49:19,830][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 16:22:33, remaining time 07:01:05, 00:46:47 per epoch
[2025-08-27 11:49:29,841][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064688] [Batch 00008/03080] [00:00:09/01:01:43, 1.206s/it]: train_loss_raw=0.3420, running_loss=0.4538, LR=0.000100
[2025-08-27 11:49:35,804][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064696] [Batch 00016/03080] [00:00:15/00:49:48, 0.976s/it]: train_loss_raw=0.5071, running_loss=0.4523, LR=0.000100
[2025-08-27 11:49:41,742][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064704] [Batch 00024/03080] [00:00:21/00:45:43, 0.898s/it]: train_loss_raw=0.4120, running_loss=0.4498, LR=0.000100
[2025-08-27 11:49:47,663][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064712] [Batch 00032/03080] [00:00:27/00:43:36, 0.858s/it]: train_loss_raw=0.4114, running_loss=0.4481, LR=0.000100
[2025-08-27 11:49:53,770][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064720] [Batch 00040/03080] [00:00:33/00:42:31, 0.839s/it]: train_loss_raw=0.4785, running_loss=0.4459, LR=0.000100
[2025-08-27 11:49:59,936][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064728] [Batch 00048/03080] [00:00:39/00:41:50, 0.828s/it]: train_loss_raw=0.4376, running_loss=0.4436, LR=0.000100
[2025-08-27 11:50:05,891][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064736] [Batch 00056/03080] [00:00:45/00:41:07, 0.816s/it]: train_loss_raw=0.4668, running_loss=0.4417, LR=0.000100
[2025-08-27 11:50:11,973][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064744] [Batch 00064/03080] [00:00:51/00:40:40, 0.809s/it]: train_loss_raw=0.4187, running_loss=0.4415, LR=0.000100
[2025-08-27 11:50:18,055][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064752] [Batch 00072/03080] [00:00:57/00:40:17, 0.804s/it]: train_loss_raw=0.4117, running_loss=0.4396, LR=0.000100
[2025-08-27 11:50:24,109][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064760] [Batch 00080/03080] [00:01:03/00:39:56, 0.799s/it]: train_loss_raw=0.4453, running_loss=0.4392, LR=0.000100
[2025-08-27 11:50:30,293][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064768] [Batch 00088/03080] [00:01:10/00:39:43, 0.797s/it]: train_loss_raw=0.4782, running_loss=0.4406, LR=0.000100
[2025-08-27 11:50:36,253][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064776] [Batch 00096/03080] [00:01:16/00:39:24, 0.792s/it]: train_loss_raw=0.4204, running_loss=0.4388, LR=0.000100
[2025-08-27 11:50:42,266][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064784] [Batch 00104/03080] [00:01:22/00:39:08, 0.789s/it]: train_loss_raw=0.4296, running_loss=0.4385, LR=0.000100
[2025-08-27 11:50:48,217][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064792] [Batch 00112/03080] [00:01:28/00:38:52, 0.786s/it]: train_loss_raw=0.4836, running_loss=0.4388, LR=0.000100
[2025-08-27 11:50:54,324][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064800] [Batch 00120/03080] [00:01:34/00:38:41, 0.784s/it]: train_loss_raw=0.4421, running_loss=0.4392, LR=0.000100
[2025-08-27 11:51:00,303][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064808] [Batch 00128/03080] [00:01:40/00:38:28, 0.782s/it]: train_loss_raw=0.4796, running_loss=0.4401, LR=0.000100
[2025-08-27 11:51:06,280][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064816] [Batch 00136/03080] [00:01:46/00:38:16, 0.780s/it]: train_loss_raw=0.4886, running_loss=0.4400, LR=0.000100
[2025-08-27 11:51:12,503][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064824] [Batch 00144/03080] [00:01:52/00:38:09, 0.780s/it]: train_loss_raw=0.4650, running_loss=0.4410, LR=0.000100
[2025-08-27 11:51:18,439][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064832] [Batch 00152/03080] [00:01:58/00:37:57, 0.778s/it]: train_loss_raw=0.4753, running_loss=0.4393, LR=0.000100
[2025-08-27 11:51:24,464][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064840] [Batch 00160/03080] [00:02:04/00:37:47, 0.777s/it]: train_loss_raw=0.4088, running_loss=0.4396, LR=0.000100
[2025-08-27 11:51:30,741][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064848] [Batch 00168/03080] [00:02:10/00:37:42, 0.777s/it]: train_loss_raw=0.4740, running_loss=0.4380, LR=0.000100
[2025-08-27 11:51:36,751][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064856] [Batch 00176/03080] [00:02:16/00:37:33, 0.776s/it]: train_loss_raw=0.4709, running_loss=0.4404, LR=0.000100
[2025-08-27 11:51:42,714][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064864] [Batch 00184/03080] [00:02:22/00:37:23, 0.775s/it]: train_loss_raw=0.4443, running_loss=0.4390, LR=0.000100
[2025-08-27 11:51:48,695][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064872] [Batch 00192/03080] [00:02:28/00:37:13, 0.773s/it]: train_loss_raw=0.4422, running_loss=0.4390, LR=0.000100
[2025-08-27 11:51:54,656][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064880] [Batch 00200/03080] [00:02:34/00:37:04, 0.772s/it]: train_loss_raw=0.4909, running_loss=0.4396, LR=0.000100
[2025-08-27 11:52:00,738][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064888] [Batch 00208/03080] [00:02:40/00:36:56, 0.772s/it]: train_loss_raw=0.4304, running_loss=0.4395, LR=0.000100
[2025-08-27 11:52:06,581][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064896] [Batch 00216/03080] [00:02:46/00:36:46, 0.770s/it]: train_loss_raw=0.3912, running_loss=0.4377, LR=0.000100
[2025-08-27 11:52:12,633][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064904] [Batch 00224/03080] [00:02:52/00:36:38, 0.770s/it]: train_loss_raw=0.5163, running_loss=0.4378, LR=0.000100
[2025-08-27 11:52:18,827][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064912] [Batch 00232/03080] [00:02:58/00:36:32, 0.770s/it]: train_loss_raw=0.4294, running_loss=0.4355, LR=0.000100
[2025-08-27 11:52:24,942][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064920] [Batch 00240/03080] [00:03:04/00:36:26, 0.770s/it]: train_loss_raw=0.3706, running_loss=0.4339, LR=0.000100
[2025-08-27 11:52:30,925][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064928] [Batch 00248/03080] [00:03:10/00:36:18, 0.769s/it]: train_loss_raw=0.3445, running_loss=0.4326, LR=0.000100
[2025-08-27 11:52:36,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064936] [Batch 00256/03080] [00:03:16/00:36:10, 0.769s/it]: train_loss_raw=0.4200, running_loss=0.4344, LR=0.000100
[2025-08-27 11:52:43,133][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064944] [Batch 00264/03080] [00:03:22/00:36:04, 0.769s/it]: train_loss_raw=0.4193, running_loss=0.4351, LR=0.000100
[2025-08-27 11:52:49,185][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064952] [Batch 00272/03080] [00:03:28/00:35:57, 0.768s/it]: train_loss_raw=0.5160, running_loss=0.4373, LR=0.000100
[2025-08-27 11:52:55,166][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064960] [Batch 00280/03080] [00:03:34/00:35:49, 0.768s/it]: train_loss_raw=0.4670, running_loss=0.4352, LR=0.000100
[2025-08-27 11:53:01,077][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064968] [Batch 00288/03080] [00:03:40/00:35:41, 0.767s/it]: train_loss_raw=0.5121, running_loss=0.4357, LR=0.000100
[2025-08-27 11:53:07,008][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064976] [Batch 00296/03080] [00:03:46/00:35:33, 0.766s/it]: train_loss_raw=0.4125, running_loss=0.4323, LR=0.000100
[2025-08-27 11:53:13,030][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064984] [Batch 00304/03080] [00:03:52/00:35:26, 0.766s/it]: train_loss_raw=0.4608, running_loss=0.4329, LR=0.000100
[2025-08-27 11:53:19,009][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064992] [Batch 00312/03080] [00:03:58/00:35:18, 0.765s/it]: train_loss_raw=0.4248, running_loss=0.4336, LR=0.000100
[2025-08-27 11:53:25,008][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065000] [Batch 00320/03080] [00:04:04/00:35:11, 0.765s/it]: train_loss_raw=0.4711, running_loss=0.4338, LR=0.000100
[2025-08-27 11:53:31,028][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065008] [Batch 00328/03080] [00:04:10/00:35:04, 0.765s/it]: train_loss_raw=0.3958, running_loss=0.4325, LR=0.000100
[2025-08-27 11:53:37,142][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065016] [Batch 00336/03080] [00:04:16/00:34:58, 0.765s/it]: train_loss_raw=0.4942, running_loss=0.4333, LR=0.000100
[2025-08-27 11:53:43,119][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065024] [Batch 00344/03080] [00:04:22/00:34:51, 0.764s/it]: train_loss_raw=0.3895, running_loss=0.4317, LR=0.000100
[2025-08-27 11:53:49,115][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065032] [Batch 00352/03080] [00:04:28/00:34:44, 0.764s/it]: train_loss_raw=0.4451, running_loss=0.4331, LR=0.000100
[2025-08-27 11:53:54,676][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065040] [Batch 00360/03080] [00:04:34/00:34:33, 0.762s/it]: train_loss_raw=0.4198, running_loss=0.4362, LR=0.000100
[2025-08-27 11:54:00,312][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065048] [Batch 00368/03080] [00:04:40/00:34:24, 0.761s/it]: train_loss_raw=0.4549, running_loss=0.4361, LR=0.000100
[2025-08-27 11:54:06,315][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065056] [Batch 00376/03080] [00:04:46/00:34:17, 0.761s/it]: train_loss_raw=0.4431, running_loss=0.4382, LR=0.000100
[2025-08-27 11:54:12,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065064] [Batch 00384/03080] [00:04:52/00:34:11, 0.761s/it]: train_loss_raw=0.3900, running_loss=0.4375, LR=0.000100
[2025-08-27 11:54:18,397][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065072] [Batch 00392/03080] [00:04:58/00:34:04, 0.761s/it]: train_loss_raw=0.4903, running_loss=0.4384, LR=0.000100
[2025-08-27 11:54:24,535][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065080] [Batch 00400/03080] [00:05:04/00:33:59, 0.761s/it]: train_loss_raw=0.4285, running_loss=0.4387, LR=0.000100
[2025-08-27 11:54:30,646][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065088] [Batch 00408/03080] [00:05:10/00:33:53, 0.761s/it]: train_loss_raw=0.4717, running_loss=0.4400, LR=0.000100
[2025-08-27 11:54:36,560][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065096] [Batch 00416/03080] [00:05:16/00:33:45, 0.760s/it]: train_loss_raw=0.4831, running_loss=0.4419, LR=0.000100
[2025-08-27 11:54:42,518][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065104] [Batch 00424/03080] [00:05:22/00:33:39, 0.760s/it]: train_loss_raw=0.3527, running_loss=0.4413, LR=0.000100
[2025-08-27 11:54:48,682][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065112] [Batch 00432/03080] [00:05:28/00:33:33, 0.760s/it]: train_loss_raw=0.5428, running_loss=0.4414, LR=0.000100
[2025-08-27 11:54:54,557][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065120] [Batch 00440/03080] [00:05:34/00:33:26, 0.760s/it]: train_loss_raw=0.4743, running_loss=0.4404, LR=0.000100
[2025-08-27 11:55:00,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065128] [Batch 00448/03080] [00:05:40/00:33:19, 0.760s/it]: train_loss_raw=0.4103, running_loss=0.4402, LR=0.000100
[2025-08-27 11:55:06,505][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065136] [Batch 00456/03080] [00:05:46/00:33:12, 0.759s/it]: train_loss_raw=0.4473, running_loss=0.4373, LR=0.000100
[2025-08-27 11:55:12,500][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065144] [Batch 00464/03080] [00:05:52/00:33:06, 0.759s/it]: train_loss_raw=0.4939, running_loss=0.4365, LR=0.000100
[2025-08-27 11:55:18,464][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065152] [Batch 00472/03080] [00:05:58/00:32:59, 0.759s/it]: train_loss_raw=0.3135, running_loss=0.4351, LR=0.000100
[2025-08-27 11:55:24,273][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065160] [Batch 00480/03080] [00:06:04/00:32:52, 0.758s/it]: train_loss_raw=0.4642, running_loss=0.4362, LR=0.000100
[2025-08-27 11:55:30,068][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065168] [Batch 00488/03080] [00:06:09/00:32:44, 0.758s/it]: train_loss_raw=0.3793, running_loss=0.4350, LR=0.000100
[2025-08-27 11:55:36,117][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065176] [Batch 00496/03080] [00:06:15/00:32:38, 0.758s/it]: train_loss_raw=0.3405, running_loss=0.4339, LR=0.000100
[2025-08-27 11:55:42,120][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065184] [Batch 00504/03080] [00:06:21/00:32:32, 0.758s/it]: train_loss_raw=0.4562, running_loss=0.4327, LR=0.000100
[2025-08-27 11:55:48,164][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065192] [Batch 00512/03080] [00:06:27/00:32:25, 0.758s/it]: train_loss_raw=0.4289, running_loss=0.4330, LR=0.000100
[2025-08-27 11:55:54,188][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065200] [Batch 00520/03080] [00:06:33/00:32:19, 0.758s/it]: train_loss_raw=0.4312, running_loss=0.4335, LR=0.000100
[2025-08-27 11:56:00,273][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065208] [Batch 00528/03080] [00:06:40/00:32:13, 0.758s/it]: train_loss_raw=0.4287, running_loss=0.4335, LR=0.000100
[2025-08-27 11:56:06,342][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065216] [Batch 00536/03080] [00:06:46/00:32:07, 0.758s/it]: train_loss_raw=0.4879, running_loss=0.4349, LR=0.000100
[2025-08-27 11:56:12,353][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065224] [Batch 00544/03080] [00:06:52/00:32:01, 0.758s/it]: train_loss_raw=0.3951, running_loss=0.4346, LR=0.000100
[2025-08-27 11:56:18,347][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065232] [Batch 00552/03080] [00:06:58/00:31:55, 0.758s/it]: train_loss_raw=0.5386, running_loss=0.4349, LR=0.000100
[2025-08-27 11:56:24,311][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065240] [Batch 00560/03080] [00:07:04/00:31:48, 0.757s/it]: train_loss_raw=0.4928, running_loss=0.4364, LR=0.000100
[2025-08-27 11:56:30,294][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065248] [Batch 00568/03080] [00:07:10/00:31:42, 0.757s/it]: train_loss_raw=0.3819, running_loss=0.4364, LR=0.000100
[2025-08-27 11:56:36,282][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065256] [Batch 00576/03080] [00:07:16/00:31:35, 0.757s/it]: train_loss_raw=0.4409, running_loss=0.4358, LR=0.000100
[2025-08-27 11:56:42,373][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065264] [Batch 00584/03080] [00:07:22/00:31:29, 0.757s/it]: train_loss_raw=0.4867, running_loss=0.4359, LR=0.000100
[2025-08-27 11:56:48,484][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065272] [Batch 00592/03080] [00:07:28/00:31:24, 0.757s/it]: train_loss_raw=0.4541, running_loss=0.4376, LR=0.000100
[2025-08-27 11:56:54,482][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065280] [Batch 00600/03080] [00:07:34/00:31:17, 0.757s/it]: train_loss_raw=0.3897, running_loss=0.4371, LR=0.000100
[2025-08-27 11:57:00,474][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065288] [Batch 00608/03080] [00:07:40/00:31:11, 0.757s/it]: train_loss_raw=0.4039, running_loss=0.4358, LR=0.000100
[2025-08-27 11:57:06,427][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065296] [Batch 00616/03080] [00:07:46/00:31:04, 0.757s/it]: train_loss_raw=0.5097, running_loss=0.4356, LR=0.000100
[2025-08-27 11:57:12,563][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065304] [Batch 00624/03080] [00:07:52/00:30:59, 0.757s/it]: train_loss_raw=0.3486, running_loss=0.4355, LR=0.000100
[2025-08-27 11:57:18,574][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065312] [Batch 00632/03080] [00:07:58/00:30:52, 0.757s/it]: train_loss_raw=0.4428, running_loss=0.4355, LR=0.000100
[2025-08-27 11:57:24,558][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065320] [Batch 00640/03080] [00:08:04/00:30:46, 0.757s/it]: train_loss_raw=0.4374, running_loss=0.4366, LR=0.000100
[2025-08-27 11:57:30,549][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065328] [Batch 00648/03080] [00:08:10/00:30:40, 0.757s/it]: train_loss_raw=0.4542, running_loss=0.4371, LR=0.000100
[2025-08-27 11:57:36,544][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065336] [Batch 00656/03080] [00:08:16/00:30:34, 0.757s/it]: train_loss_raw=0.4408, running_loss=0.4344, LR=0.000100
[2025-08-27 11:57:42,516][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065344] [Batch 00664/03080] [00:08:22/00:30:27, 0.757s/it]: train_loss_raw=0.4226, running_loss=0.4332, LR=0.000100
[2025-08-27 11:57:48,285][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065352] [Batch 00672/03080] [00:08:28/00:30:20, 0.756s/it]: train_loss_raw=0.3995, running_loss=0.4336, LR=0.000100
[2025-08-27 11:57:54,001][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065360] [Batch 00680/03080] [00:08:33/00:30:13, 0.756s/it]: train_loss_raw=0.5118, running_loss=0.4336, LR=0.000100
[2025-08-27 11:57:59,904][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065368] [Batch 00688/03080] [00:08:39/00:30:06, 0.755s/it]: train_loss_raw=0.4019, running_loss=0.4336, LR=0.000100
[2025-08-27 11:58:05,983][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065376] [Batch 00696/03080] [00:08:45/00:30:00, 0.755s/it]: train_loss_raw=0.5408, running_loss=0.4331, LR=0.000100
[2025-08-27 11:58:12,090][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065384] [Batch 00704/03080] [00:08:51/00:29:55, 0.756s/it]: train_loss_raw=0.4255, running_loss=0.4342, LR=0.000100
[2025-08-27 11:58:18,125][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065392] [Batch 00712/03080] [00:08:57/00:29:49, 0.756s/it]: train_loss_raw=0.4720, running_loss=0.4341, LR=0.000100
[2025-08-27 11:58:24,173][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065400] [Batch 00720/03080] [00:09:03/00:29:43, 0.756s/it]: train_loss_raw=0.4362, running_loss=0.4318, LR=0.000100
[2025-08-27 11:58:30,221][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065408] [Batch 00728/03080] [00:09:10/00:29:37, 0.756s/it]: train_loss_raw=0.3936, running_loss=0.4316, LR=0.000100
[2025-08-27 11:58:36,168][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065416] [Batch 00736/03080] [00:09:15/00:29:30, 0.755s/it]: train_loss_raw=0.4730, running_loss=0.4317, LR=0.000100
[2025-08-27 11:58:42,106][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065424] [Batch 00744/03080] [00:09:21/00:29:24, 0.755s/it]: train_loss_raw=0.3745, running_loss=0.4325, LR=0.000100
[2025-08-27 11:58:47,951][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065432] [Batch 00752/03080] [00:09:27/00:29:17, 0.755s/it]: train_loss_raw=0.3828, running_loss=0.4337, LR=0.000100
[2025-08-27 11:58:53,865][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065440] [Batch 00760/03080] [00:09:33/00:29:11, 0.755s/it]: train_loss_raw=0.2859, running_loss=0.4322, LR=0.000100
[2025-08-27 11:58:59,830][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065448] [Batch 00768/03080] [00:09:39/00:29:04, 0.755s/it]: train_loss_raw=0.5144, running_loss=0.4335, LR=0.000100
[2025-08-27 11:59:05,827][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065456] [Batch 00776/03080] [00:09:45/00:28:58, 0.755s/it]: train_loss_raw=0.4150, running_loss=0.4327, LR=0.000100
[2025-08-27 11:59:11,927][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065464] [Batch 00784/03080] [00:09:51/00:28:52, 0.755s/it]: train_loss_raw=0.4507, running_loss=0.4328, LR=0.000100
[2025-08-27 11:59:17,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065472] [Batch 00792/03080] [00:09:57/00:28:46, 0.755s/it]: train_loss_raw=0.4317, running_loss=0.4337, LR=0.000100
[2025-08-27 11:59:24,062][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065480] [Batch 00800/03080] [00:10:03/00:28:41, 0.755s/it]: train_loss_raw=0.3999, running_loss=0.4325, LR=0.000100
[2025-08-27 11:59:30,035][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065488] [Batch 00808/03080] [00:10:09/00:28:34, 0.755s/it]: train_loss_raw=0.4208, running_loss=0.4336, LR=0.000100
[2025-08-27 11:59:36,015][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065496] [Batch 00816/03080] [00:10:15/00:28:28, 0.755s/it]: train_loss_raw=0.4023, running_loss=0.4319, LR=0.000100
[2025-08-27 11:59:42,093][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065504] [Batch 00824/03080] [00:10:21/00:28:22, 0.755s/it]: train_loss_raw=0.3805, running_loss=0.4310, LR=0.000100
[2025-08-27 11:59:48,072][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065512] [Batch 00832/03080] [00:10:27/00:28:16, 0.755s/it]: train_loss_raw=0.4266, running_loss=0.4320, LR=0.000100
[2025-08-27 11:59:54,161][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065520] [Batch 00840/03080] [00:10:33/00:28:10, 0.755s/it]: train_loss_raw=0.4309, running_loss=0.4301, LR=0.000100
[2025-08-27 12:00:00,086][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065528] [Batch 00848/03080] [00:10:39/00:28:04, 0.755s/it]: train_loss_raw=0.4199, running_loss=0.4299, LR=0.000100
[2025-08-27 12:00:06,041][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065536] [Batch 00856/03080] [00:10:45/00:27:57, 0.754s/it]: train_loss_raw=0.4165, running_loss=0.4297, LR=0.000100
[2025-08-27 12:00:12,023][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065544] [Batch 00864/03080] [00:10:51/00:27:51, 0.754s/it]: train_loss_raw=0.4934, running_loss=0.4316, LR=0.000100
[2025-08-27 12:00:18,010][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065552] [Batch 00872/03080] [00:10:57/00:27:45, 0.754s/it]: train_loss_raw=0.5429, running_loss=0.4350, LR=0.000100
[2025-08-27 12:00:23,978][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065560] [Batch 00880/03080] [00:11:03/00:27:39, 0.754s/it]: train_loss_raw=0.3547, running_loss=0.4352, LR=0.000100
[2025-08-27 12:00:29,935][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065568] [Batch 00888/03080] [00:11:09/00:27:33, 0.754s/it]: train_loss_raw=0.4099, running_loss=0.4363, LR=0.000100
[2025-08-27 12:00:35,930][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065576] [Batch 00896/03080] [00:11:15/00:27:27, 0.754s/it]: train_loss_raw=0.4205, running_loss=0.4364, LR=0.000100
[2025-08-27 12:00:42,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065584] [Batch 00904/03080] [00:11:21/00:27:21, 0.754s/it]: train_loss_raw=0.4414, running_loss=0.4371, LR=0.000100
[2025-08-27 12:00:47,975][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065592] [Batch 00912/03080] [00:11:27/00:27:14, 0.754s/it]: train_loss_raw=0.3913, running_loss=0.4383, LR=0.000100
[2025-08-27 12:00:53,986][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065600] [Batch 00920/03080] [00:11:33/00:27:08, 0.754s/it]: train_loss_raw=0.4472, running_loss=0.4364, LR=0.000100
[2025-08-27 12:01:00,045][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065608] [Batch 00928/03080] [00:11:39/00:27:02, 0.754s/it]: train_loss_raw=0.4817, running_loss=0.4367, LR=0.000100
[2025-08-27 12:01:06,125][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065616] [Batch 00936/03080] [00:11:45/00:26:57, 0.754s/it]: train_loss_raw=0.4009, running_loss=0.4369, LR=0.000100
[2025-08-27 12:01:12,092][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065624] [Batch 00944/03080] [00:11:51/00:26:50, 0.754s/it]: train_loss_raw=0.4704, running_loss=0.4351, LR=0.000100
[2025-08-27 12:01:18,088][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065632] [Batch 00952/03080] [00:11:57/00:26:44, 0.754s/it]: train_loss_raw=0.4947, running_loss=0.4377, LR=0.000100
[2025-08-27 12:01:24,030][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065640] [Batch 00960/03080] [00:12:03/00:26:38, 0.754s/it]: train_loss_raw=0.5148, running_loss=0.4361, LR=0.000100
[2025-08-27 12:01:29,992][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065648] [Batch 00968/03080] [00:12:09/00:26:32, 0.754s/it]: train_loss_raw=0.3613, running_loss=0.4351, LR=0.000100
[2025-08-27 12:01:35,623][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065656] [Batch 00976/03080] [00:12:15/00:26:25, 0.754s/it]: train_loss_raw=0.3823, running_loss=0.4341, LR=0.000100
[2025-08-27 12:01:41,496][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065664] [Batch 00984/03080] [00:12:21/00:26:19, 0.753s/it]: train_loss_raw=0.4266, running_loss=0.4342, LR=0.000100
[2025-08-27 12:01:47,121][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065672] [Batch 00992/03080] [00:12:26/00:26:12, 0.753s/it]: train_loss_raw=0.5605, running_loss=0.4349, LR=0.000100
[2025-08-27 12:01:52,786][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065680] [Batch 01000/03080] [00:12:32/00:26:05, 0.753s/it]: train_loss_raw=0.4098, running_loss=0.4332, LR=0.000100
[2025-08-27 12:01:58,249][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065688] [Batch 01008/03080] [00:12:38/00:25:58, 0.752s/it]: train_loss_raw=0.4698, running_loss=0.4360, LR=0.000100
[2025-08-27 12:02:03,856][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065696] [Batch 01016/03080] [00:12:43/00:25:51, 0.752s/it]: train_loss_raw=0.3996, running_loss=0.4366, LR=0.000100
[2025-08-27 12:02:09,766][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065704] [Batch 01024/03080] [00:12:49/00:25:45, 0.752s/it]: train_loss_raw=0.4631, running_loss=0.4388, LR=0.000100
[2025-08-27 12:02:15,738][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065712] [Batch 01032/03080] [00:12:55/00:25:39, 0.751s/it]: train_loss_raw=0.4448, running_loss=0.4404, LR=0.000100
[2025-08-27 12:02:21,888][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065720] [Batch 01040/03080] [00:13:01/00:25:33, 0.752s/it]: train_loss_raw=0.4465, running_loss=0.4410, LR=0.000100
[2025-08-27 12:02:27,798][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065728] [Batch 01048/03080] [00:13:07/00:25:27, 0.752s/it]: train_loss_raw=0.4363, running_loss=0.4404, LR=0.000100
[2025-08-27 12:02:33,781][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065736] [Batch 01056/03080] [00:13:13/00:25:21, 0.752s/it]: train_loss_raw=0.4495, running_loss=0.4402, LR=0.000100
[2025-08-27 12:02:39,770][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065744] [Batch 01064/03080] [00:13:19/00:25:14, 0.751s/it]: train_loss_raw=0.4708, running_loss=0.4397, LR=0.000100
[2025-08-27 12:02:45,881][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065752] [Batch 01072/03080] [00:13:25/00:25:09, 0.752s/it]: train_loss_raw=0.4865, running_loss=0.4402, LR=0.000100
[2025-08-27 12:02:51,908][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065760] [Batch 01080/03080] [00:13:31/00:25:03, 0.752s/it]: train_loss_raw=0.4369, running_loss=0.4420, LR=0.000100
[2025-08-27 12:02:57,945][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065768] [Batch 01088/03080] [00:13:37/00:24:57, 0.752s/it]: train_loss_raw=0.4931, running_loss=0.4442, LR=0.000100
[2025-08-27 12:03:03,899][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065776] [Batch 01096/03080] [00:13:43/00:24:51, 0.752s/it]: train_loss_raw=0.4031, running_loss=0.4445, LR=0.000100
[2025-08-27 12:03:09,860][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065784] [Batch 01104/03080] [00:13:49/00:24:44, 0.752s/it]: train_loss_raw=0.4621, running_loss=0.4443, LR=0.000100
[2025-08-27 12:03:16,068][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065792] [Batch 01112/03080] [00:13:55/00:24:39, 0.752s/it]: train_loss_raw=0.4426, running_loss=0.4451, LR=0.000100
[2025-08-27 12:03:22,228][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065800] [Batch 01120/03080] [00:14:02/00:24:33, 0.752s/it]: train_loss_raw=0.4455, running_loss=0.4421, LR=0.000100
[2025-08-27 12:03:28,174][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065808] [Batch 01128/03080] [00:14:07/00:24:27, 0.752s/it]: train_loss_raw=0.4296, running_loss=0.4421, LR=0.000100
[2025-08-27 12:03:34,171][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065816] [Batch 01136/03080] [00:14:13/00:24:21, 0.752s/it]: train_loss_raw=0.4161, running_loss=0.4427, LR=0.000100
[2025-08-27 12:03:40,150][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065824] [Batch 01144/03080] [00:14:19/00:24:15, 0.752s/it]: train_loss_raw=0.4309, running_loss=0.4416, LR=0.000100
[2025-08-27 12:03:46,258][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065832] [Batch 01152/03080] [00:14:26/00:24:09, 0.752s/it]: train_loss_raw=0.3920, running_loss=0.4396, LR=0.000100
[2025-08-27 12:03:52,232][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065840] [Batch 01160/03080] [00:14:32/00:24:03, 0.752s/it]: train_loss_raw=0.4552, running_loss=0.4409, LR=0.000100
[2025-08-27 12:03:58,206][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065848] [Batch 01168/03080] [00:14:38/00:23:57, 0.752s/it]: train_loss_raw=0.4254, running_loss=0.4409, LR=0.000100
[2025-08-27 12:04:04,315][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065856] [Batch 01176/03080] [00:14:44/00:23:51, 0.752s/it]: train_loss_raw=0.4261, running_loss=0.4414, LR=0.000100
[2025-08-27 12:04:10,616][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065864] [Batch 01184/03080] [00:14:50/00:23:45, 0.752s/it]: train_loss_raw=0.5556, running_loss=0.4441, LR=0.000100
[2025-08-27 12:04:16,546][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065872] [Batch 01192/03080] [00:14:56/00:23:39, 0.752s/it]: train_loss_raw=0.4552, running_loss=0.4445, LR=0.000100
[2025-08-27 12:04:22,598][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065880] [Batch 01200/03080] [00:15:02/00:23:33, 0.752s/it]: train_loss_raw=0.4466, running_loss=0.4459, LR=0.000100
[2025-08-27 12:04:28,642][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065888] [Batch 01208/03080] [00:15:08/00:23:27, 0.752s/it]: train_loss_raw=0.3820, running_loss=0.4437, LR=0.000100
[2025-08-27 12:04:34,606][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065896] [Batch 01216/03080] [00:15:14/00:23:21, 0.752s/it]: train_loss_raw=0.5240, running_loss=0.4431, LR=0.000100
[2025-08-27 12:04:40,598][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065904] [Batch 01224/03080] [00:15:20/00:23:15, 0.752s/it]: train_loss_raw=0.3873, running_loss=0.4421, LR=0.000100
[2025-08-27 12:04:46,754][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065912] [Batch 01232/03080] [00:15:26/00:23:09, 0.752s/it]: train_loss_raw=0.4296, running_loss=0.4396, LR=0.000100
[2025-08-27 12:04:52,866][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065920] [Batch 01240/03080] [00:15:32/00:23:03, 0.752s/it]: train_loss_raw=0.3854, running_loss=0.4395, LR=0.000100
[2025-08-27 12:04:58,873][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065928] [Batch 01248/03080] [00:15:38/00:22:57, 0.752s/it]: train_loss_raw=0.4525, running_loss=0.4396, LR=0.000100
[2025-08-27 12:05:04,900][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065936] [Batch 01256/03080] [00:15:44/00:22:51, 0.752s/it]: train_loss_raw=0.4790, running_loss=0.4385, LR=0.000100
[2025-08-27 12:05:10,944][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065944] [Batch 01264/03080] [00:15:50/00:22:45, 0.752s/it]: train_loss_raw=0.4941, running_loss=0.4390, LR=0.000100
[2025-08-27 12:05:16,888][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065952] [Batch 01272/03080] [00:15:56/00:22:39, 0.752s/it]: train_loss_raw=0.4638, running_loss=0.4376, LR=0.000100
[2025-08-27 12:05:23,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065960] [Batch 01280/03080] [00:16:02/00:22:33, 0.752s/it]: train_loss_raw=0.4259, running_loss=0.4375, LR=0.000100
[2025-08-27 12:05:29,004][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065968] [Batch 01288/03080] [00:16:08/00:22:27, 0.752s/it]: train_loss_raw=0.4200, running_loss=0.4361, LR=0.000100
[2025-08-27 12:05:34,945][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065976] [Batch 01296/03080] [00:16:14/00:22:21, 0.752s/it]: train_loss_raw=0.4014, running_loss=0.4355, LR=0.000100
[2025-08-27 12:05:40,950][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065984] [Batch 01304/03080] [00:16:20/00:22:15, 0.752s/it]: train_loss_raw=0.3911, running_loss=0.4353, LR=0.000100
[2025-08-27 12:05:46,922][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065992] [Batch 01312/03080] [00:16:26/00:22:09, 0.752s/it]: train_loss_raw=0.4498, running_loss=0.4347, LR=0.000100
[2025-08-27 12:05:52,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066000] [Batch 01320/03080] [00:16:32/00:22:03, 0.752s/it]: train_loss_raw=0.4363, running_loss=0.4313, LR=0.000100
[2025-08-27 12:06:02,490][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066008] [Batch 01328/03080] [00:16:42/00:22:02, 0.755s/it]: train_loss_raw=0.3849, running_loss=0.4298, LR=0.000100
[2025-08-27 12:06:08,496][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066016] [Batch 01336/03080] [00:16:48/00:21:56, 0.755s/it]: train_loss_raw=0.4222, running_loss=0.4287, LR=0.000100
[2025-08-27 12:06:14,433][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066024] [Batch 01344/03080] [00:16:54/00:21:50, 0.755s/it]: train_loss_raw=0.4027, running_loss=0.4293, LR=0.000100
[2025-08-27 12:06:20,379][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066032] [Batch 01352/03080] [00:17:00/00:21:43, 0.755s/it]: train_loss_raw=0.4794, running_loss=0.4293, LR=0.000100
[2025-08-27 12:06:26,377][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066040] [Batch 01360/03080] [00:17:06/00:21:37, 0.755s/it]: train_loss_raw=0.4085, running_loss=0.4293, LR=0.000100
[2025-08-27 12:06:32,784][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066048] [Batch 01368/03080] [00:17:12/00:21:32, 0.755s/it]: train_loss_raw=0.4320, running_loss=0.4305, LR=0.000100
[2025-08-27 12:06:38,883][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066056] [Batch 01376/03080] [00:17:18/00:21:26, 0.755s/it]: train_loss_raw=0.4167, running_loss=0.4297, LR=0.000100
[2025-08-27 12:06:44,846][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066064] [Batch 01384/03080] [00:17:24/00:21:20, 0.755s/it]: train_loss_raw=0.4381, running_loss=0.4280, LR=0.000100
[2025-08-27 12:06:51,016][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066072] [Batch 01392/03080] [00:17:30/00:21:14, 0.755s/it]: train_loss_raw=0.4474, running_loss=0.4264, LR=0.000100
[2025-08-27 12:06:57,016][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066080] [Batch 01400/03080] [00:17:36/00:21:08, 0.755s/it]: train_loss_raw=0.5801, running_loss=0.4270, LR=0.000100
[2025-08-27 12:07:03,043][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066088] [Batch 01408/03080] [00:17:42/00:21:02, 0.755s/it]: train_loss_raw=0.4200, running_loss=0.4272, LR=0.000100
[2025-08-27 12:07:08,999][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066096] [Batch 01416/03080] [00:17:48/00:20:55, 0.755s/it]: train_loss_raw=0.4034, running_loss=0.4268, LR=0.000100
[2025-08-27 12:07:14,999][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066104] [Batch 01424/03080] [00:17:54/00:20:49, 0.755s/it]: train_loss_raw=0.4439, running_loss=0.4276, LR=0.000100
[2025-08-27 12:07:20,997][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066112] [Batch 01432/03080] [00:18:00/00:20:43, 0.755s/it]: train_loss_raw=0.3933, running_loss=0.4271, LR=0.000100
[2025-08-27 12:07:27,016][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066120] [Batch 01440/03080] [00:18:06/00:20:37, 0.755s/it]: train_loss_raw=0.3623, running_loss=0.4288, LR=0.000100
[2025-08-27 12:07:32,982][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066128] [Batch 01448/03080] [00:18:12/00:20:31, 0.755s/it]: train_loss_raw=0.4884, running_loss=0.4293, LR=0.000100
[2025-08-27 12:07:38,992][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066136] [Batch 01456/03080] [00:18:18/00:20:25, 0.755s/it]: train_loss_raw=0.4056, running_loss=0.4282, LR=0.000100
[2025-08-27 12:07:45,051][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066144] [Batch 01464/03080] [00:18:24/00:20:19, 0.755s/it]: train_loss_raw=0.4255, running_loss=0.4273, LR=0.000100
[2025-08-27 12:07:51,179][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066152] [Batch 01472/03080] [00:18:30/00:20:13, 0.755s/it]: train_loss_raw=0.3782, running_loss=0.4271, LR=0.000100
[2025-08-27 12:07:57,101][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066160] [Batch 01480/03080] [00:18:36/00:20:07, 0.755s/it]: train_loss_raw=0.4582, running_loss=0.4267, LR=0.000100
[2025-08-27 12:08:03,198][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066168] [Batch 01488/03080] [00:18:43/00:20:01, 0.755s/it]: train_loss_raw=0.4473, running_loss=0.4270, LR=0.000100
[2025-08-27 12:08:09,201][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066176] [Batch 01496/03080] [00:18:49/00:19:55, 0.755s/it]: train_loss_raw=0.3900, running_loss=0.4281, LR=0.000100
[2025-08-27 12:08:15,178][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066184] [Batch 01504/03080] [00:18:54/00:19:49, 0.755s/it]: train_loss_raw=0.4743, running_loss=0.4286, LR=0.000100
[2025-08-27 12:08:21,197][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066192] [Batch 01512/03080] [00:19:01/00:19:43, 0.755s/it]: train_loss_raw=0.4190, running_loss=0.4277, LR=0.000100
[2025-08-27 12:08:27,254][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066200] [Batch 01520/03080] [00:19:07/00:19:37, 0.755s/it]: train_loss_raw=0.3639, running_loss=0.4282, LR=0.000100
[2025-08-27 12:08:33,264][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066208] [Batch 01528/03080] [00:19:13/00:19:31, 0.755s/it]: train_loss_raw=0.3364, running_loss=0.4276, LR=0.000100
[2025-08-27 12:08:39,293][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066216] [Batch 01536/03080] [00:19:19/00:19:25, 0.755s/it]: train_loss_raw=0.4723, running_loss=0.4304, LR=0.000100
[2025-08-27 12:08:45,474][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066224] [Batch 01544/03080] [00:19:25/00:19:19, 0.755s/it]: train_loss_raw=0.3879, running_loss=0.4284, LR=0.000100
[2025-08-27 12:08:51,422][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066232] [Batch 01552/03080] [00:19:31/00:19:13, 0.755s/it]: train_loss_raw=0.2842, running_loss=0.4263, LR=0.000100
[2025-08-27 12:08:57,428][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066240] [Batch 01560/03080] [00:19:37/00:19:07, 0.755s/it]: train_loss_raw=0.4189, running_loss=0.4279, LR=0.000100
[2025-08-27 12:09:03,731][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066248] [Batch 01568/03080] [00:19:43/00:19:01, 0.755s/it]: train_loss_raw=0.4418, running_loss=0.4278, LR=0.000100
[2025-08-27 12:09:09,643][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066256] [Batch 01576/03080] [00:19:49/00:18:55, 0.755s/it]: train_loss_raw=0.4237, running_loss=0.4273, LR=0.000100
[2025-08-27 12:09:15,640][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066264] [Batch 01584/03080] [00:19:55/00:18:49, 0.755s/it]: train_loss_raw=0.5044, running_loss=0.4262, LR=0.000100
[2025-08-27 12:09:21,638][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066272] [Batch 01592/03080] [00:20:01/00:18:42, 0.755s/it]: train_loss_raw=0.5119, running_loss=0.4265, LR=0.000100
[2025-08-27 12:09:27,796][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066280] [Batch 01600/03080] [00:20:07/00:18:37, 0.755s/it]: train_loss_raw=0.4071, running_loss=0.4238, LR=0.000100
[2025-08-27 12:09:33,822][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066288] [Batch 01608/03080] [00:20:13/00:18:30, 0.755s/it]: train_loss_raw=0.4738, running_loss=0.4271, LR=0.000100
[2025-08-27 12:09:39,815][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066296] [Batch 01616/03080] [00:20:19/00:18:24, 0.755s/it]: train_loss_raw=0.4062, running_loss=0.4266, LR=0.000100
[2025-08-27 12:09:45,827][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066304] [Batch 01624/03080] [00:20:25/00:18:18, 0.755s/it]: train_loss_raw=0.3738, running_loss=0.4269, LR=0.000100
[2025-08-27 12:09:51,945][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066312] [Batch 01632/03080] [00:20:31/00:18:12, 0.755s/it]: train_loss_raw=0.4417, running_loss=0.4267, LR=0.000100
[2025-08-27 12:09:57,915][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066320] [Batch 01640/03080] [00:20:37/00:18:06, 0.755s/it]: train_loss_raw=0.5115, running_loss=0.4295, LR=0.000100
[2025-08-27 12:10:03,956][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066328] [Batch 01648/03080] [00:20:43/00:18:00, 0.755s/it]: train_loss_raw=0.3810, running_loss=0.4288, LR=0.000100
[2025-08-27 12:10:10,028][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066336] [Batch 01656/03080] [00:20:49/00:17:54, 0.755s/it]: train_loss_raw=0.4829, running_loss=0.4298, LR=0.000100
[2025-08-27 12:10:16,008][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066344] [Batch 01664/03080] [00:20:55/00:17:48, 0.755s/it]: train_loss_raw=0.4528, running_loss=0.4314, LR=0.000100
[2025-08-27 12:10:22,002][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066352] [Batch 01672/03080] [00:21:01/00:17:42, 0.755s/it]: train_loss_raw=0.4824, running_loss=0.4331, LR=0.000100
[2025-08-27 12:10:28,005][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066360] [Batch 01680/03080] [00:21:07/00:17:36, 0.755s/it]: train_loss_raw=0.4029, running_loss=0.4314, LR=0.000100
[2025-08-27 12:10:34,080][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066368] [Batch 01688/03080] [00:21:13/00:17:30, 0.755s/it]: train_loss_raw=0.5480, running_loss=0.4307, LR=0.000100
[2025-08-27 12:10:40,123][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066376] [Batch 01696/03080] [00:21:19/00:17:24, 0.755s/it]: train_loss_raw=0.4318, running_loss=0.4310, LR=0.000100
[2025-08-27 12:10:46,175][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066384] [Batch 01704/03080] [00:21:25/00:17:18, 0.755s/it]: train_loss_raw=0.4557, running_loss=0.4324, LR=0.000100
[2025-08-27 12:10:52,178][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066392] [Batch 01712/03080] [00:21:31/00:17:12, 0.755s/it]: train_loss_raw=0.4240, running_loss=0.4316, LR=0.000100
[2025-08-27 12:10:58,149][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066400] [Batch 01720/03080] [00:21:37/00:17:06, 0.755s/it]: train_loss_raw=0.5017, running_loss=0.4336, LR=0.000100
[2025-08-27 12:11:04,227][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066408] [Batch 01728/03080] [00:21:44/00:17:00, 0.755s/it]: train_loss_raw=0.4517, running_loss=0.4330, LR=0.000100
[2025-08-27 12:11:10,339][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066416] [Batch 01736/03080] [00:21:50/00:16:54, 0.755s/it]: train_loss_raw=0.4554, running_loss=0.4344, LR=0.000100
[2025-08-27 12:11:16,368][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066424] [Batch 01744/03080] [00:21:56/00:16:48, 0.755s/it]: train_loss_raw=0.3277, running_loss=0.4329, LR=0.000100
[2025-08-27 12:11:22,315][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066432] [Batch 01752/03080] [00:22:02/00:16:42, 0.755s/it]: train_loss_raw=0.3531, running_loss=0.4329, LR=0.000100
[2025-08-27 12:11:28,261][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066440] [Batch 01760/03080] [00:22:08/00:16:36, 0.755s/it]: train_loss_raw=0.4982, running_loss=0.4322, LR=0.000100
[2025-08-27 12:11:34,218][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066448] [Batch 01768/03080] [00:22:14/00:16:29, 0.755s/it]: train_loss_raw=0.4118, running_loss=0.4309, LR=0.000100
[2025-08-27 12:11:39,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066456] [Batch 01776/03080] [00:22:19/00:16:23, 0.754s/it]: train_loss_raw=0.4409, running_loss=0.4300, LR=0.000100
[2025-08-27 12:11:46,022][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066464] [Batch 01784/03080] [00:22:25/00:16:17, 0.754s/it]: train_loss_raw=0.4031, running_loss=0.4316, LR=0.000100
[2025-08-27 12:11:52,211][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066472] [Batch 01792/03080] [00:22:32/00:16:11, 0.754s/it]: train_loss_raw=0.5267, running_loss=0.4317, LR=0.000100
[2025-08-27 12:11:58,197][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066480] [Batch 01800/03080] [00:22:38/00:16:05, 0.754s/it]: train_loss_raw=0.4716, running_loss=0.4339, LR=0.000100
[2025-08-27 12:12:04,190][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066488] [Batch 01808/03080] [00:22:43/00:15:59, 0.754s/it]: train_loss_raw=0.4989, running_loss=0.4345, LR=0.000100
[2025-08-27 12:12:10,393][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066496] [Batch 01816/03080] [00:22:50/00:15:53, 0.755s/it]: train_loss_raw=0.3996, running_loss=0.4346, LR=0.000100
[2025-08-27 12:12:16,446][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066504] [Batch 01824/03080] [00:22:56/00:15:47, 0.755s/it]: train_loss_raw=0.3712, running_loss=0.4322, LR=0.000100
[2025-08-27 12:12:22,518][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066512] [Batch 01832/03080] [00:23:02/00:15:41, 0.755s/it]: train_loss_raw=0.4439, running_loss=0.4323, LR=0.000100
[2025-08-27 12:12:28,534][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066520] [Batch 01840/03080] [00:23:08/00:15:35, 0.755s/it]: train_loss_raw=0.4603, running_loss=0.4340, LR=0.000100
[2025-08-27 12:12:34,469][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066528] [Batch 01848/03080] [00:23:14/00:15:29, 0.754s/it]: train_loss_raw=0.5217, running_loss=0.4356, LR=0.000100
[2025-08-27 12:12:40,559][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066536] [Batch 01856/03080] [00:23:20/00:15:23, 0.755s/it]: train_loss_raw=0.4769, running_loss=0.4354, LR=0.000100
[2025-08-27 12:12:46,664][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066544] [Batch 01864/03080] [00:23:26/00:15:17, 0.755s/it]: train_loss_raw=0.4252, running_loss=0.4364, LR=0.000100
[2025-08-27 12:12:52,641][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066552] [Batch 01872/03080] [00:23:32/00:15:11, 0.755s/it]: train_loss_raw=0.5597, running_loss=0.4385, LR=0.000100
[2025-08-27 12:12:58,603][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066560] [Batch 01880/03080] [00:23:38/00:15:05, 0.754s/it]: train_loss_raw=0.4408, running_loss=0.4381, LR=0.000100
[2025-08-27 12:13:04,532][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066568] [Batch 01888/03080] [00:23:44/00:14:59, 0.754s/it]: train_loss_raw=0.4570, running_loss=0.4355, LR=0.000100
[2025-08-27 12:13:10,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066576] [Batch 01896/03080] [00:23:50/00:14:53, 0.754s/it]: train_loss_raw=0.3776, running_loss=0.4346, LR=0.000100
[2025-08-27 12:13:16,684][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066584] [Batch 01904/03080] [00:23:56/00:14:47, 0.754s/it]: train_loss_raw=0.4147, running_loss=0.4333, LR=0.000100
[2025-08-27 12:13:22,709][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066592] [Batch 01912/03080] [00:24:02/00:14:41, 0.754s/it]: train_loss_raw=0.4416, running_loss=0.4327, LR=0.000100
[2025-08-27 12:13:28,806][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066600] [Batch 01920/03080] [00:24:08/00:14:35, 0.754s/it]: train_loss_raw=0.3819, running_loss=0.4311, LR=0.000100
[2025-08-27 12:13:34,800][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066608] [Batch 01928/03080] [00:24:14/00:14:29, 0.754s/it]: train_loss_raw=0.4313, running_loss=0.4331, LR=0.000100
[2025-08-27 12:13:40,814][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066616] [Batch 01936/03080] [00:24:20/00:14:23, 0.754s/it]: train_loss_raw=0.5191, running_loss=0.4326, LR=0.000100
[2025-08-27 12:13:46,773][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066624] [Batch 01944/03080] [00:24:26/00:14:17, 0.754s/it]: train_loss_raw=0.4582, running_loss=0.4330, LR=0.000100
[2025-08-27 12:13:52,763][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066632] [Batch 01952/03080] [00:24:32/00:14:10, 0.754s/it]: train_loss_raw=0.3719, running_loss=0.4321, LR=0.000100
[2025-08-27 12:13:58,752][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066640] [Batch 01960/03080] [00:24:38/00:14:04, 0.754s/it]: train_loss_raw=0.5235, running_loss=0.4338, LR=0.000100
[2025-08-27 12:14:04,779][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066648] [Batch 01968/03080] [00:24:44/00:13:58, 0.754s/it]: train_loss_raw=0.4188, running_loss=0.4328, LR=0.000100
[2025-08-27 12:14:10,820][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066656] [Batch 01976/03080] [00:24:50/00:13:52, 0.754s/it]: train_loss_raw=0.4409, running_loss=0.4330, LR=0.000100
[2025-08-27 12:14:16,829][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066664] [Batch 01984/03080] [00:24:56/00:13:46, 0.754s/it]: train_loss_raw=0.3682, running_loss=0.4315, LR=0.000100
[2025-08-27 12:14:22,851][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066672] [Batch 01992/03080] [00:25:02/00:13:40, 0.754s/it]: train_loss_raw=0.3878, running_loss=0.4293, LR=0.000100
[2025-08-27 12:14:28,470][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066680] [Batch 02000/03080] [00:25:08/00:13:34, 0.754s/it]: train_loss_raw=0.4393, running_loss=0.4304, LR=0.000100
[2025-08-27 12:14:33,880][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066688] [Batch 02008/03080] [00:25:13/00:13:28, 0.754s/it]: train_loss_raw=0.4288, running_loss=0.4299, LR=0.000100
[2025-08-27 12:14:39,437][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066696] [Batch 02016/03080] [00:25:19/00:13:21, 0.754s/it]: train_loss_raw=0.5024, running_loss=0.4310, LR=0.000100
[2025-08-27 12:14:45,162][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066704] [Batch 02024/03080] [00:25:24/00:13:15, 0.753s/it]: train_loss_raw=0.4119, running_loss=0.4283, LR=0.000100
[2025-08-27 12:14:50,566][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066712] [Batch 02032/03080] [00:25:30/00:13:09, 0.753s/it]: train_loss_raw=0.4112, running_loss=0.4259, LR=0.000100
[2025-08-27 12:14:56,369][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066720] [Batch 02040/03080] [00:25:36/00:13:03, 0.753s/it]: train_loss_raw=0.5459, running_loss=0.4283, LR=0.000100
[2025-08-27 12:15:02,080][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066728] [Batch 02048/03080] [00:25:41/00:12:56, 0.753s/it]: train_loss_raw=0.3764, running_loss=0.4262, LR=0.000100
[2025-08-27 12:15:08,062][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066736] [Batch 02056/03080] [00:25:47/00:12:50, 0.753s/it]: train_loss_raw=0.3682, running_loss=0.4254, LR=0.000100
[2025-08-27 12:15:14,047][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066744] [Batch 02064/03080] [00:25:53/00:12:44, 0.753s/it]: train_loss_raw=0.3547, running_loss=0.4240, LR=0.000100
[2025-08-27 12:15:20,072][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066752] [Batch 02072/03080] [00:25:59/00:12:38, 0.753s/it]: train_loss_raw=0.3596, running_loss=0.4232, LR=0.000100
[2025-08-27 12:15:26,046][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066760] [Batch 02080/03080] [00:26:05/00:12:32, 0.753s/it]: train_loss_raw=0.4035, running_loss=0.4227, LR=0.000100
[2025-08-27 12:15:32,158][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066768] [Batch 02088/03080] [00:26:11/00:12:26, 0.753s/it]: train_loss_raw=0.3815, running_loss=0.4214, LR=0.000100
[2025-08-27 12:15:38,059][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066776] [Batch 02096/03080] [00:26:17/00:12:20, 0.753s/it]: train_loss_raw=0.4426, running_loss=0.4239, LR=0.000100
[2025-08-27 12:15:44,102][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066784] [Batch 02104/03080] [00:26:23/00:12:14, 0.753s/it]: train_loss_raw=0.3877, running_loss=0.4256, LR=0.000100
[2025-08-27 12:15:50,199][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066792] [Batch 02112/03080] [00:26:30/00:12:08, 0.753s/it]: train_loss_raw=0.3704, running_loss=0.4264, LR=0.000100
[2025-08-27 12:15:56,415][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066800] [Batch 02120/03080] [00:26:36/00:12:02, 0.753s/it]: train_loss_raw=0.3737, running_loss=0.4273, LR=0.000100
[2025-08-27 12:16:02,676][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066808] [Batch 02128/03080] [00:26:42/00:11:56, 0.753s/it]: train_loss_raw=0.4587, running_loss=0.4277, LR=0.000100
[2025-08-27 12:16:08,605][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066816] [Batch 02136/03080] [00:26:48/00:11:50, 0.753s/it]: train_loss_raw=0.5057, running_loss=0.4285, LR=0.000100
[2025-08-27 12:16:14,616][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066824] [Batch 02144/03080] [00:26:54/00:11:44, 0.753s/it]: train_loss_raw=0.5158, running_loss=0.4291, LR=0.000100
[2025-08-27 12:16:20,644][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066832] [Batch 02152/03080] [00:27:00/00:11:38, 0.753s/it]: train_loss_raw=0.4843, running_loss=0.4292, LR=0.000100
[2025-08-27 12:16:26,690][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066840] [Batch 02160/03080] [00:27:06/00:11:32, 0.753s/it]: train_loss_raw=0.3885, running_loss=0.4284, LR=0.000100
[2025-08-27 12:16:32,532][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066848] [Batch 02168/03080] [00:27:12/00:11:26, 0.753s/it]: train_loss_raw=0.5380, running_loss=0.4299, LR=0.000100
[2025-08-27 12:16:38,575][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066856] [Batch 02176/03080] [00:27:18/00:11:20, 0.753s/it]: train_loss_raw=0.4583, running_loss=0.4288, LR=0.000100
[2025-08-27 12:16:44,685][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066864] [Batch 02184/03080] [00:27:24/00:11:14, 0.753s/it]: train_loss_raw=0.5334, running_loss=0.4288, LR=0.000100
[2025-08-27 12:16:50,856][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066872] [Batch 02192/03080] [00:27:30/00:11:08, 0.753s/it]: train_loss_raw=0.4824, running_loss=0.4280, LR=0.000100
[2025-08-27 12:16:56,593][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066880] [Batch 02200/03080] [00:27:36/00:11:02, 0.753s/it]: train_loss_raw=0.4946, running_loss=0.4297, LR=0.000100
[2025-08-27 12:17:02,297][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066888] [Batch 02208/03080] [00:27:42/00:10:56, 0.753s/it]: train_loss_raw=0.4305, running_loss=0.4312, LR=0.000100
[2025-08-27 12:17:08,123][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066896] [Batch 02216/03080] [00:27:47/00:10:50, 0.753s/it]: train_loss_raw=0.4621, running_loss=0.4305, LR=0.000100
[2025-08-27 12:17:13,874][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066904] [Batch 02224/03080] [00:27:53/00:10:44, 0.753s/it]: train_loss_raw=0.4518, running_loss=0.4296, LR=0.000100
[2025-08-27 12:17:19,853][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066912] [Batch 02232/03080] [00:27:59/00:10:38, 0.753s/it]: train_loss_raw=0.5204, running_loss=0.4313, LR=0.000100
[2025-08-27 12:17:25,859][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066920] [Batch 02240/03080] [00:28:05/00:10:32, 0.753s/it]: train_loss_raw=0.4546, running_loss=0.4319, LR=0.000100
[2025-08-27 12:17:31,997][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066928] [Batch 02248/03080] [00:28:11/00:10:26, 0.753s/it]: train_loss_raw=0.4645, running_loss=0.4320, LR=0.000100
[2025-08-27 12:17:37,965][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066936] [Batch 02256/03080] [00:28:17/00:10:20, 0.753s/it]: train_loss_raw=0.4305, running_loss=0.4317, LR=0.000100
[2025-08-27 12:17:44,044][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066944] [Batch 02264/03080] [00:28:23/00:10:14, 0.753s/it]: train_loss_raw=0.4450, running_loss=0.4314, LR=0.000100
[2025-08-27 12:17:50,215][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066952] [Batch 02272/03080] [00:28:30/00:10:08, 0.753s/it]: train_loss_raw=0.4361, running_loss=0.4331, LR=0.000100
[2025-08-27 12:17:56,297][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066960] [Batch 02280/03080] [00:28:36/00:10:02, 0.753s/it]: train_loss_raw=0.4462, running_loss=0.4334, LR=0.000100
[2025-08-27 12:18:02,371][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066968] [Batch 02288/03080] [00:28:42/00:09:56, 0.753s/it]: train_loss_raw=0.3850, running_loss=0.4330, LR=0.000100
[2025-08-27 12:18:08,349][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066976] [Batch 02296/03080] [00:28:48/00:09:50, 0.753s/it]: train_loss_raw=0.4779, running_loss=0.4331, LR=0.000100
[2025-08-27 12:18:14,289][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066984] [Batch 02304/03080] [00:28:54/00:09:44, 0.753s/it]: train_loss_raw=0.4522, running_loss=0.4304, LR=0.000100
[2025-08-27 12:18:20,293][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066992] [Batch 02312/03080] [00:29:00/00:09:38, 0.753s/it]: train_loss_raw=0.4331, running_loss=0.4319, LR=0.000100
[2025-08-27 12:18:26,306][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067000] [Batch 02320/03080] [00:29:06/00:09:32, 0.753s/it]: train_loss_raw=0.3957, running_loss=0.4290, LR=0.000100
[2025-08-27 12:18:32,306][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067008] [Batch 02328/03080] [00:29:12/00:09:25, 0.753s/it]: train_loss_raw=0.4317, running_loss=0.4282, LR=0.000100
[2025-08-27 12:18:38,282][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067016] [Batch 02336/03080] [00:29:18/00:09:19, 0.753s/it]: train_loss_raw=0.5451, running_loss=0.4294, LR=0.000100
[2025-08-27 12:18:44,235][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067024] [Batch 02344/03080] [00:29:24/00:09:13, 0.753s/it]: train_loss_raw=0.4593, running_loss=0.4286, LR=0.000100
[2025-08-27 12:18:50,259][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067032] [Batch 02352/03080] [00:29:30/00:09:07, 0.753s/it]: train_loss_raw=0.4507, running_loss=0.4282, LR=0.000100
[2025-08-27 12:18:56,471][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067040] [Batch 02360/03080] [00:29:36/00:09:01, 0.753s/it]: train_loss_raw=0.3472, running_loss=0.4268, LR=0.000100
[2025-08-27 12:19:02,481][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067048] [Batch 02368/03080] [00:29:42/00:08:55, 0.753s/it]: train_loss_raw=0.3260, running_loss=0.4265, LR=0.000100
[2025-08-27 12:19:08,517][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067056] [Batch 02376/03080] [00:29:48/00:08:49, 0.753s/it]: train_loss_raw=0.4969, running_loss=0.4280, LR=0.000100
[2025-08-27 12:19:14,530][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067064] [Batch 02384/03080] [00:29:54/00:08:43, 0.753s/it]: train_loss_raw=0.4829, running_loss=0.4274, LR=0.000100
[2025-08-27 12:19:20,527][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067072] [Batch 02392/03080] [00:30:00/00:08:37, 0.753s/it]: train_loss_raw=0.4273, running_loss=0.4284, LR=0.000100
[2025-08-27 12:19:26,627][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067080] [Batch 02400/03080] [00:30:06/00:08:31, 0.753s/it]: train_loss_raw=0.4573, running_loss=0.4263, LR=0.000100
[2025-08-27 12:19:32,811][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067088] [Batch 02408/03080] [00:30:12/00:08:25, 0.753s/it]: train_loss_raw=0.4452, running_loss=0.4273, LR=0.000100
[2025-08-27 12:19:38,756][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067096] [Batch 02416/03080] [00:30:18/00:08:19, 0.753s/it]: train_loss_raw=0.4461, running_loss=0.4274, LR=0.000100
[2025-08-27 12:19:44,845][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067104] [Batch 02424/03080] [00:30:24/00:08:13, 0.753s/it]: train_loss_raw=0.3906, running_loss=0.4298, LR=0.000100
[2025-08-27 12:19:50,808][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067112] [Batch 02432/03080] [00:30:30/00:08:07, 0.753s/it]: train_loss_raw=0.4125, running_loss=0.4314, LR=0.000100
[2025-08-27 12:19:56,784][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067120] [Batch 02440/03080] [00:30:36/00:08:01, 0.753s/it]: train_loss_raw=0.3648, running_loss=0.4310, LR=0.000100
[2025-08-27 12:20:02,776][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067128] [Batch 02448/03080] [00:30:42/00:07:55, 0.753s/it]: train_loss_raw=0.4464, running_loss=0.4303, LR=0.000100
[2025-08-27 12:20:08,737][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067136] [Batch 02456/03080] [00:30:48/00:07:49, 0.753s/it]: train_loss_raw=0.4222, running_loss=0.4293, LR=0.000100
[2025-08-27 12:20:14,719][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067144] [Batch 02464/03080] [00:30:54/00:07:43, 0.753s/it]: train_loss_raw=0.4543, running_loss=0.4301, LR=0.000100
[2025-08-27 12:20:20,719][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067152] [Batch 02472/03080] [00:31:00/00:07:37, 0.753s/it]: train_loss_raw=0.3108, running_loss=0.4296, LR=0.000100
[2025-08-27 12:20:26,718][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067160] [Batch 02480/03080] [00:31:06/00:07:31, 0.753s/it]: train_loss_raw=0.4276, running_loss=0.4312, LR=0.000100
[2025-08-27 12:20:32,742][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067168] [Batch 02488/03080] [00:31:12/00:07:25, 0.753s/it]: train_loss_raw=0.3401, running_loss=0.4309, LR=0.000100
[2025-08-27 12:20:38,912][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067176] [Batch 02496/03080] [00:31:18/00:07:19, 0.753s/it]: train_loss_raw=0.3901, running_loss=0.4296, LR=0.000100
[2025-08-27 12:20:44,982][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067184] [Batch 02504/03080] [00:31:24/00:07:13, 0.753s/it]: train_loss_raw=0.4901, running_loss=0.4296, LR=0.000100
[2025-08-27 12:20:50,928][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067192] [Batch 02512/03080] [00:31:30/00:07:07, 0.753s/it]: train_loss_raw=0.4167, running_loss=0.4280, LR=0.000100
[2025-08-27 12:20:56,947][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067200] [Batch 02520/03080] [00:31:36/00:07:01, 0.753s/it]: train_loss_raw=0.4543, running_loss=0.4273, LR=0.000100
[2025-08-27 12:21:02,958][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067208] [Batch 02528/03080] [00:31:42/00:06:55, 0.753s/it]: train_loss_raw=0.4318, running_loss=0.4274, LR=0.000100
[2025-08-27 12:21:08,975][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067216] [Batch 02536/03080] [00:31:48/00:06:49, 0.753s/it]: train_loss_raw=0.4069, running_loss=0.4276, LR=0.000100
[2025-08-27 12:21:15,165][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067224] [Batch 02544/03080] [00:31:54/00:06:43, 0.753s/it]: train_loss_raw=0.3539, running_loss=0.4225, LR=0.000100
[2025-08-27 12:21:21,284][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067232] [Batch 02552/03080] [00:32:01/00:06:37, 0.753s/it]: train_loss_raw=0.4482, running_loss=0.4245, LR=0.000100
[2025-08-27 12:21:27,372][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067240] [Batch 02560/03080] [00:32:07/00:06:31, 0.753s/it]: train_loss_raw=0.4897, running_loss=0.4255, LR=0.000100
[2025-08-27 12:21:33,337][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067248] [Batch 02568/03080] [00:32:13/00:06:25, 0.753s/it]: train_loss_raw=0.4961, running_loss=0.4271, LR=0.000100
[2025-08-27 12:21:39,367][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067256] [Batch 02576/03080] [00:32:19/00:06:19, 0.753s/it]: train_loss_raw=0.4118, running_loss=0.4271, LR=0.000100
[2025-08-27 12:21:45,360][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067264] [Batch 02584/03080] [00:32:25/00:06:13, 0.753s/it]: train_loss_raw=0.5190, running_loss=0.4284, LR=0.000100
[2025-08-27 12:21:51,365][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067272] [Batch 02592/03080] [00:32:31/00:06:07, 0.753s/it]: train_loss_raw=0.4515, running_loss=0.4269, LR=0.000100
[2025-08-27 12:21:57,291][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067280] [Batch 02600/03080] [00:32:37/00:06:01, 0.753s/it]: train_loss_raw=0.4294, running_loss=0.4271, LR=0.000100
[2025-08-27 12:22:03,302][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067288] [Batch 02608/03080] [00:32:43/00:05:55, 0.753s/it]: train_loss_raw=0.4012, running_loss=0.4277, LR=0.000100
[2025-08-27 12:22:09,448][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067296] [Batch 02616/03080] [00:32:49/00:05:49, 0.753s/it]: train_loss_raw=0.5543, running_loss=0.4274, LR=0.000100
[2025-08-27 12:22:15,422][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067304] [Batch 02624/03080] [00:32:55/00:05:43, 0.753s/it]: train_loss_raw=0.4680, running_loss=0.4270, LR=0.000100
[2025-08-27 12:22:21,493][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067312] [Batch 02632/03080] [00:33:01/00:05:37, 0.753s/it]: train_loss_raw=0.4149, running_loss=0.4260, LR=0.000100
[2025-08-27 12:22:27,426][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067320] [Batch 02640/03080] [00:33:07/00:05:31, 0.753s/it]: train_loss_raw=0.5410, running_loss=0.4252, LR=0.000100
[2025-08-27 12:22:33,385][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067328] [Batch 02648/03080] [00:33:13/00:05:25, 0.753s/it]: train_loss_raw=0.4735, running_loss=0.4257, LR=0.000100
[2025-08-27 12:22:39,351][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067336] [Batch 02656/03080] [00:33:19/00:05:19, 0.753s/it]: train_loss_raw=0.4259, running_loss=0.4276, LR=0.000100
[2025-08-27 12:22:45,346][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067344] [Batch 02664/03080] [00:33:25/00:05:13, 0.753s/it]: train_loss_raw=0.4262, running_loss=0.4271, LR=0.000100
[2025-08-27 12:22:51,379][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067352] [Batch 02672/03080] [00:33:31/00:05:07, 0.753s/it]: train_loss_raw=0.3893, running_loss=0.4289, LR=0.000100
[2025-08-27 12:22:57,592][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067360] [Batch 02680/03080] [00:33:37/00:05:01, 0.753s/it]: train_loss_raw=0.4904, running_loss=0.4281, LR=0.000100
[2025-08-27 12:23:03,605][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067368] [Batch 02688/03080] [00:33:43/00:04:55, 0.753s/it]: train_loss_raw=0.4599, running_loss=0.4294, LR=0.000100
[2025-08-27 12:23:09,614][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067376] [Batch 02696/03080] [00:33:49/00:04:49, 0.753s/it]: train_loss_raw=0.3685, running_loss=0.4275, LR=0.000100
[2025-08-27 12:23:15,539][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067384] [Batch 02704/03080] [00:33:55/00:04:43, 0.753s/it]: train_loss_raw=0.4128, running_loss=0.4252, LR=0.000100
[2025-08-27 12:23:21,613][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067392] [Batch 02712/03080] [00:34:01/00:04:37, 0.753s/it]: train_loss_raw=0.4679, running_loss=0.4256, LR=0.000100
[2025-08-27 12:23:27,654][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067400] [Batch 02720/03080] [00:34:07/00:04:30, 0.753s/it]: train_loss_raw=0.4660, running_loss=0.4261, LR=0.000100
[2025-08-27 12:23:33,676][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067408] [Batch 02728/03080] [00:34:13/00:04:24, 0.753s/it]: train_loss_raw=0.4910, running_loss=0.4260, LR=0.000100
[2025-08-27 12:23:39,671][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067416] [Batch 02736/03080] [00:34:19/00:04:18, 0.753s/it]: train_loss_raw=0.4850, running_loss=0.4262, LR=0.000100
[2025-08-27 12:23:45,613][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067424] [Batch 02744/03080] [00:34:25/00:04:12, 0.753s/it]: train_loss_raw=0.3648, running_loss=0.4260, LR=0.000100
[2025-08-27 12:23:51,706][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067432] [Batch 02752/03080] [00:34:31/00:04:06, 0.753s/it]: train_loss_raw=0.4108, running_loss=0.4281, LR=0.000100
[2025-08-27 12:23:57,755][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067440] [Batch 02760/03080] [00:34:37/00:04:00, 0.753s/it]: train_loss_raw=0.2984, running_loss=0.4265, LR=0.000100
[2025-08-27 12:24:03,819][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067448] [Batch 02768/03080] [00:34:43/00:03:54, 0.753s/it]: train_loss_raw=0.4411, running_loss=0.4255, LR=0.000100
[2025-08-27 12:24:09,729][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067456] [Batch 02776/03080] [00:34:49/00:03:48, 0.753s/it]: train_loss_raw=0.4368, running_loss=0.4260, LR=0.000100
[2025-08-27 12:24:15,782][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067464] [Batch 02784/03080] [00:34:55/00:03:42, 0.753s/it]: train_loss_raw=0.3772, running_loss=0.4264, LR=0.000100
[2025-08-27 12:24:21,766][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067472] [Batch 02792/03080] [00:35:01/00:03:36, 0.753s/it]: train_loss_raw=0.4040, running_loss=0.4264, LR=0.000100
[2025-08-27 12:24:27,787][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067480] [Batch 02800/03080] [00:35:07/00:03:30, 0.753s/it]: train_loss_raw=0.3862, running_loss=0.4252, LR=0.000100
[2025-08-27 12:24:33,870][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067488] [Batch 02808/03080] [00:35:13/00:03:24, 0.753s/it]: train_loss_raw=0.4145, running_loss=0.4278, LR=0.000100
[2025-08-27 12:24:39,811][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067496] [Batch 02816/03080] [00:35:19/00:03:18, 0.753s/it]: train_loss_raw=0.4096, running_loss=0.4282, LR=0.000100
[2025-08-27 12:24:45,836][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067504] [Batch 02824/03080] [00:35:25/00:03:12, 0.753s/it]: train_loss_raw=0.4414, running_loss=0.4272, LR=0.000100
[2025-08-27 12:24:51,888][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067512] [Batch 02832/03080] [00:35:31/00:03:06, 0.753s/it]: train_loss_raw=0.4060, running_loss=0.4287, LR=0.000100
[2025-08-27 12:24:57,793][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067520] [Batch 02840/03080] [00:35:37/00:03:00, 0.753s/it]: train_loss_raw=0.4467, running_loss=0.4316, LR=0.000100
[2025-08-27 12:25:03,556][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067528] [Batch 02848/03080] [00:35:43/00:02:54, 0.753s/it]: train_loss_raw=0.3864, running_loss=0.4297, LR=0.000100
[2025-08-27 12:25:09,499][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067536] [Batch 02856/03080] [00:35:49/00:02:48, 0.753s/it]: train_loss_raw=0.4510, running_loss=0.4325, LR=0.000100
[2025-08-27 12:25:15,073][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067544] [Batch 02864/03080] [00:35:54/00:02:42, 0.752s/it]: train_loss_raw=0.4127, running_loss=0.4334, LR=0.000100
[2025-08-27 12:25:21,012][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067552] [Batch 02872/03080] [00:36:00/00:02:36, 0.752s/it]: train_loss_raw=0.4487, running_loss=0.4336, LR=0.000100
[2025-08-27 12:25:27,003][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067560] [Batch 02880/03080] [00:36:06/00:02:30, 0.752s/it]: train_loss_raw=0.4195, running_loss=0.4335, LR=0.000100
[2025-08-27 12:25:32,983][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067568] [Batch 02888/03080] [00:36:12/00:02:24, 0.752s/it]: train_loss_raw=0.4749, running_loss=0.4339, LR=0.000100
[2025-08-27 12:25:38,815][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067576] [Batch 02896/03080] [00:36:18/00:02:18, 0.752s/it]: train_loss_raw=0.4551, running_loss=0.4346, LR=0.000100
[2025-08-27 12:25:44,309][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067584] [Batch 02904/03080] [00:36:24/00:02:12, 0.752s/it]: train_loss_raw=0.4261, running_loss=0.4325, LR=0.000100
[2025-08-27 12:25:50,277][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067592] [Batch 02912/03080] [00:36:30/00:02:06, 0.752s/it]: train_loss_raw=0.3586, running_loss=0.4312, LR=0.000100
[2025-08-27 12:25:56,477][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067600] [Batch 02920/03080] [00:36:36/00:02:00, 0.752s/it]: train_loss_raw=0.3718, running_loss=0.4275, LR=0.000100
[2025-08-27 12:26:02,559][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067608] [Batch 02928/03080] [00:36:42/00:01:54, 0.752s/it]: train_loss_raw=0.4130, running_loss=0.4289, LR=0.000100
[2025-08-27 12:26:08,612][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067616] [Batch 02936/03080] [00:36:48/00:01:48, 0.752s/it]: train_loss_raw=0.4212, running_loss=0.4265, LR=0.000100
[2025-08-27 12:26:14,570][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067624] [Batch 02944/03080] [00:36:54/00:01:42, 0.752s/it]: train_loss_raw=0.3487, running_loss=0.4244, LR=0.000100
[2025-08-27 12:26:20,649][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067632] [Batch 02952/03080] [00:37:00/00:01:36, 0.752s/it]: train_loss_raw=0.3260, running_loss=0.4252, LR=0.000100
[2025-08-27 12:26:26,911][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067640] [Batch 02960/03080] [00:37:06/00:01:30, 0.752s/it]: train_loss_raw=0.3533, running_loss=0.4254, LR=0.000100
[2025-08-27 12:26:33,104][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067648] [Batch 02968/03080] [00:37:12/00:01:24, 0.752s/it]: train_loss_raw=0.4448, running_loss=0.4261, LR=0.000100
[2025-08-27 12:26:39,133][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067656] [Batch 02976/03080] [00:37:18/00:01:18, 0.752s/it]: train_loss_raw=0.4517, running_loss=0.4262, LR=0.000100
[2025-08-27 12:26:45,116][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067664] [Batch 02984/03080] [00:37:24/00:01:12, 0.752s/it]: train_loss_raw=0.3414, running_loss=0.4256, LR=0.000100
[2025-08-27 12:26:51,264][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067672] [Batch 02992/03080] [00:37:31/00:01:06, 0.752s/it]: train_loss_raw=0.4999, running_loss=0.4275, LR=0.000100
[2025-08-27 12:26:57,161][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067680] [Batch 03000/03080] [00:37:36/00:01:00, 0.752s/it]: train_loss_raw=0.3758, running_loss=0.4261, LR=0.000100
[2025-08-27 12:27:03,116][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067688] [Batch 03008/03080] [00:37:42/00:00:54, 0.752s/it]: train_loss_raw=0.4065, running_loss=0.4263, LR=0.000100
[2025-08-27 12:27:09,162][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067696] [Batch 03016/03080] [00:37:48/00:00:48, 0.752s/it]: train_loss_raw=0.4688, running_loss=0.4264, LR=0.000100
[2025-08-27 12:27:15,237][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067704] [Batch 03024/03080] [00:37:55/00:00:42, 0.752s/it]: train_loss_raw=0.5090, running_loss=0.4278, LR=0.000100
[2025-08-27 12:27:21,675][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067712] [Batch 03032/03080] [00:38:01/00:00:36, 0.752s/it]: train_loss_raw=0.3711, running_loss=0.4264, LR=0.000100
[2025-08-27 12:27:28,020][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067720] [Batch 03040/03080] [00:38:07/00:00:30, 0.753s/it]: train_loss_raw=0.4799, running_loss=0.4239, LR=0.000100
[2025-08-27 12:27:33,932][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067728] [Batch 03048/03080] [00:38:13/00:00:24, 0.753s/it]: train_loss_raw=0.4150, running_loss=0.4253, LR=0.000100
[2025-08-27 12:27:39,886][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067736] [Batch 03056/03080] [00:38:19/00:00:18, 0.753s/it]: train_loss_raw=0.3963, running_loss=0.4228, LR=0.000100
[2025-08-27 12:27:45,950][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067744] [Batch 03064/03080] [00:38:25/00:00:12, 0.753s/it]: train_loss_raw=0.4069, running_loss=0.4230, LR=0.000100
[2025-08-27 12:27:51,913][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067752] [Batch 03072/03080] [00:38:31/00:00:06, 0.753s/it]: train_loss_raw=0.4622, running_loss=0.4244, LR=0.000100
[2025-08-27 12:28:02,259][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067760] [Batch 03080/03080] [00:38:42/00:00:00, 0.754s/it]: train_loss_raw=0.3982, running_loss=0.4231, LR=0.000100
[2025-08-27 12:28:02,931][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-27 12:28:14,089][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00007/00310] [00:00:11/00:07:01, 1.395s/it]
[2025-08-27 12:28:26,115][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00015/00310] [00:00:23/00:07:05, 1.449s/it]
[2025-08-27 12:28:37,029][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00023/00310] [00:00:34/00:06:46, 1.421s/it]
[2025-08-27 12:28:48,769][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00031/00310] [00:00:45/00:06:38, 1.432s/it]
[2025-08-27 12:29:00,220][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00039/00310] [00:00:57/00:06:26, 1.432s/it]
[2025-08-27 12:29:10,962][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00047/00310] [00:01:08/00:06:11, 1.417s/it]
[2025-08-27 12:29:22,874][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00055/00310] [00:01:19/00:06:02, 1.428s/it]
[2025-08-27 12:29:34,322][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00063/00310] [00:01:31/00:05:51, 1.428s/it]
[2025-08-27 12:29:45,832][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00071/00310] [00:01:42/00:05:40, 1.429s/it]
[2025-08-27 12:29:57,449][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00079/00310] [00:01:54/00:05:29, 1.431s/it]
[2025-08-27 12:30:09,590][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00087/00310] [00:02:06/00:05:19, 1.439s/it]
[2025-08-27 12:30:21,171][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00095/00310] [00:02:18/00:05:08, 1.440s/it]
[2025-08-27 12:30:33,284][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00103/00310] [00:02:30/00:04:57, 1.446s/it]
[2025-08-27 12:30:44,967][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00111/00310] [00:02:42/00:04:46, 1.447s/it]
[2025-08-27 12:30:57,465][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00119/00310] [00:02:54/00:04:36, 1.454s/it]
[2025-08-27 12:31:08,608][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00127/00310] [00:03:05/00:04:24, 1.451s/it]
[2025-08-27 12:31:20,821][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00135/00310] [00:03:17/00:04:13, 1.455s/it]
[2025-08-27 12:31:32,524][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00143/00310] [00:03:29/00:04:01, 1.456s/it]
[2025-08-27 12:31:42,498][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00151/00310] [00:03:39/00:03:48, 1.445s/it]
[2025-08-27 12:31:52,766][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00159/00310] [00:03:49/00:03:35, 1.436s/it]
[2025-08-27 12:32:04,843][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00167/00310] [00:04:01/00:03:24, 1.440s/it]
[2025-08-27 12:32:15,644][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00175/00310] [00:04:12/00:03:12, 1.436s/it]
[2025-08-27 12:32:26,993][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00183/00310] [00:04:24/00:03:00, 1.435s/it]
[2025-08-27 12:32:38,692][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00191/00310] [00:04:35/00:02:49, 1.436s/it]
[2025-08-27 12:32:49,334][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00199/00310] [00:04:46/00:02:37, 1.432s/it]
[2025-08-27 12:33:01,144][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00207/00310] [00:04:58/00:02:26, 1.434s/it]
[2025-08-27 12:33:11,777][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00215/00310] [00:05:08/00:02:14, 1.430s/it]
[2025-08-27 12:33:22,423][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00223/00310] [00:05:19/00:02:02, 1.426s/it]
[2025-08-27 12:33:34,946][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00231/00310] [00:05:32/00:01:51, 1.431s/it]
[2025-08-27 12:33:47,224][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00239/00310] [00:05:44/00:01:40, 1.435s/it]
[2025-08-27 12:33:58,885][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00247/00310] [00:05:55/00:01:28, 1.435s/it]
[2025-08-27 12:34:10,502][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00255/00310] [00:06:07/00:01:17, 1.436s/it]
[2025-08-27 12:34:22,853][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00263/00310] [00:06:19/00:01:06, 1.439s/it]
[2025-08-27 12:34:34,940][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00271/00310] [00:06:32/00:00:54, 1.441s/it]
[2025-08-27 12:34:46,703][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00279/00310] [00:06:43/00:00:43, 1.442s/it]
[2025-08-27 12:34:58,645][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00287/00310] [00:06:55/00:00:31, 1.443s/it]
[2025-08-27 12:35:10,468][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00295/00310] [00:07:07/00:00:20, 1.444s/it]
[2025-08-27 12:35:22,554][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00303/00310] [00:07:19/00:00:08, 1.446s/it]
[2025-08-27 12:35:31,852][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=0.42310, valid_loss=1.42963
[2025-08-27 12:35:31,852][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-27 12:35:31,852][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.503
[2025-08-27 12:35:31,852][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.136
[2025-08-27 12:35:31,852][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.139
[2025-08-27 12:35:31,853][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.073
[2025-08-27 12:35:31,867][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 17:08:45, remaining time 06:14:05, 00:46:45 per epoch
[2025-08-27 12:35:46,734][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067768] [Batch 00008/03080] [00:00:14/01:33:22, 1.824s/it]: train_loss_raw=0.3865, running_loss=0.3996, LR=0.000100
[2025-08-27 12:35:52,461][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067776] [Batch 00016/03080] [00:00:20/01:04:50, 1.270s/it]: train_loss_raw=0.4224, running_loss=0.4013, LR=0.000100
[2025-08-27 12:35:58,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067784] [Batch 00024/03080] [00:00:26/00:55:39, 1.093s/it]: train_loss_raw=0.4203, running_loss=0.4006, LR=0.000100
[2025-08-27 12:36:04,226][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067792] [Batch 00032/03080] [00:00:32/00:50:55, 1.003s/it]: train_loss_raw=0.3521, running_loss=0.4003, LR=0.000100
[2025-08-27 12:36:10,090][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067800] [Batch 00040/03080] [00:00:37/00:48:03, 0.949s/it]: train_loss_raw=0.4083, running_loss=0.3994, LR=0.000100
[2025-08-27 12:36:15,920][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067808] [Batch 00048/03080] [00:00:43/00:46:05, 0.912s/it]: train_loss_raw=0.3395, running_loss=0.3974, LR=0.000100
[2025-08-27 12:36:21,663][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067816] [Batch 00056/03080] [00:00:49/00:44:33, 0.884s/it]: train_loss_raw=0.5068, running_loss=0.3987, LR=0.000100
[2025-08-27 12:36:27,407][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067824] [Batch 00064/03080] [00:00:55/00:43:24, 0.863s/it]: train_loss_raw=0.4559, running_loss=0.4001, LR=0.000100
[2025-08-27 12:36:33,249][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067832] [Batch 00072/03080] [00:01:01/00:42:32, 0.849s/it]: train_loss_raw=0.3778, running_loss=0.3983, LR=0.000100
[2025-08-27 12:36:39,111][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067840] [Batch 00080/03080] [00:01:06/00:41:51, 0.837s/it]: train_loss_raw=0.3861, running_loss=0.3997, LR=0.000100
[2025-08-27 12:36:44,944][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067848] [Batch 00088/03080] [00:01:12/00:41:15, 0.827s/it]: train_loss_raw=0.4252, running_loss=0.3999, LR=0.000100
[2025-08-27 12:36:50,866][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067856] [Batch 00096/03080] [00:01:18/00:40:46, 0.820s/it]: train_loss_raw=0.3692, running_loss=0.3991, LR=0.000100
[2025-08-27 12:36:56,682][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067864] [Batch 00104/03080] [00:01:24/00:40:19, 0.813s/it]: train_loss_raw=0.3795, running_loss=0.3978, LR=0.000100
[2025-08-27 12:37:02,449][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067872] [Batch 00112/03080] [00:01:30/00:39:53, 0.806s/it]: train_loss_raw=0.3956, running_loss=0.3976, LR=0.000100
[2025-08-27 12:37:08,344][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067880] [Batch 00120/03080] [00:01:36/00:39:32, 0.802s/it]: train_loss_raw=0.4581, running_loss=0.4000, LR=0.000100
[2025-08-27 12:37:14,189][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067888] [Batch 00128/03080] [00:01:42/00:39:13, 0.797s/it]: train_loss_raw=0.4680, running_loss=0.3995, LR=0.000100
[2025-08-27 12:37:20,141][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067896] [Batch 00136/03080] [00:01:47/00:38:57, 0.794s/it]: train_loss_raw=0.3448, running_loss=0.3968, LR=0.000100
[2025-08-27 12:37:26,025][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067904] [Batch 00144/03080] [00:01:53/00:38:41, 0.791s/it]: train_loss_raw=0.3751, running_loss=0.3965, LR=0.000100
[2025-08-27 12:37:31,762][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067912] [Batch 00152/03080] [00:01:59/00:38:24, 0.787s/it]: train_loss_raw=0.3905, running_loss=0.3965, LR=0.000100
[2025-08-27 12:37:37,591][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067920] [Batch 00160/03080] [00:02:05/00:38:09, 0.784s/it]: train_loss_raw=0.3398, running_loss=0.3971, LR=0.000100
[2025-08-27 12:37:43,372][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067928] [Batch 00168/03080] [00:02:11/00:37:54, 0.781s/it]: train_loss_raw=0.3658, running_loss=0.3980, LR=0.000100
[2025-08-27 12:37:49,084][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067936] [Batch 00176/03080] [00:02:16/00:37:39, 0.778s/it]: train_loss_raw=0.3988, running_loss=0.3984, LR=0.000100
[2025-08-27 12:37:54,604][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067944] [Batch 00184/03080] [00:02:22/00:37:22, 0.774s/it]: train_loss_raw=0.5135, running_loss=0.3986, LR=0.000100
[2025-08-27 12:38:00,301][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067952] [Batch 00192/03080] [00:02:28/00:37:08, 0.772s/it]: train_loss_raw=0.3987, running_loss=0.3981, LR=0.000100
[2025-08-27 12:38:06,186][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067960] [Batch 00200/03080] [00:02:34/00:36:58, 0.770s/it]: train_loss_raw=0.4259, running_loss=0.3978, LR=0.000100
[2025-08-27 12:38:11,938][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067968] [Batch 00208/03080] [00:02:39/00:36:46, 0.768s/it]: train_loss_raw=0.4220, running_loss=0.3959, LR=0.000100
[2025-08-27 12:38:17,761][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067976] [Batch 00216/03080] [00:02:45/00:36:35, 0.767s/it]: train_loss_raw=0.3778, running_loss=0.3979, LR=0.000100
[2025-08-27 12:38:23,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067984] [Batch 00224/03080] [00:02:51/00:36:24, 0.765s/it]: train_loss_raw=0.3439, running_loss=0.3975, LR=0.000100
[2025-08-27 12:38:29,276][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067992] [Batch 00232/03080] [00:02:57/00:36:14, 0.763s/it]: train_loss_raw=0.4382, running_loss=0.3971, LR=0.000100
[2025-08-27 12:38:34,998][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068000] [Batch 00240/03080] [00:03:02/00:36:03, 0.762s/it]: train_loss_raw=0.3769, running_loss=0.3960, LR=0.000100
[2025-08-27 12:38:44,374][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068008] [Batch 00248/03080] [00:03:12/00:36:35, 0.775s/it]: train_loss_raw=0.3777, running_loss=0.3961, LR=0.000100
[2025-08-27 12:38:50,287][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068016] [Batch 00256/03080] [00:03:18/00:36:25, 0.774s/it]: train_loss_raw=0.4720, running_loss=0.3962, LR=0.000100
[2025-08-27 12:38:56,106][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068024] [Batch 00264/03080] [00:03:23/00:36:15, 0.773s/it]: train_loss_raw=0.4335, running_loss=0.3950, LR=0.000100
[2025-08-27 12:39:01,957][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068032] [Batch 00272/03080] [00:03:29/00:36:06, 0.771s/it]: train_loss_raw=0.3613, running_loss=0.3951, LR=0.000100
[2025-08-27 12:39:07,832][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068040] [Batch 00280/03080] [00:03:35/00:35:56, 0.770s/it]: train_loss_raw=0.4987, running_loss=0.3991, LR=0.000100
[2025-08-27 12:39:13,725][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068048] [Batch 00288/03080] [00:03:41/00:35:48, 0.769s/it]: train_loss_raw=0.4124, running_loss=0.4012, LR=0.000100
[2025-08-27 12:39:19,479][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068056] [Batch 00296/03080] [00:03:47/00:35:38, 0.768s/it]: train_loss_raw=0.3236, running_loss=0.4001, LR=0.000100
[2025-08-27 12:39:25,335][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068064] [Batch 00304/03080] [00:03:53/00:35:29, 0.767s/it]: train_loss_raw=0.4412, running_loss=0.4022, LR=0.000100
[2025-08-27 12:39:31,175][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068072] [Batch 00312/03080] [00:03:59/00:35:20, 0.766s/it]: train_loss_raw=0.5964, running_loss=0.4041, LR=0.000100
[2025-08-27 12:39:36,903][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068080] [Batch 00320/03080] [00:04:04/00:35:11, 0.765s/it]: train_loss_raw=0.4333, running_loss=0.4028, LR=0.000100
[2025-08-27 12:39:42,504][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068088] [Batch 00328/03080] [00:04:10/00:35:00, 0.763s/it]: train_loss_raw=0.2936, running_loss=0.4023, LR=0.000100
[2025-08-27 12:39:48,221][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068096] [Batch 00336/03080] [00:04:16/00:34:51, 0.762s/it]: train_loss_raw=0.4166, running_loss=0.4027, LR=0.000100
[2025-08-27 12:39:53,964][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068104] [Batch 00344/03080] [00:04:21/00:34:42, 0.761s/it]: train_loss_raw=0.3844, running_loss=0.4019, LR=0.000100
[2025-08-27 12:39:59,754][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068112] [Batch 00352/03080] [00:04:27/00:34:33, 0.760s/it]: train_loss_raw=0.4108, running_loss=0.4016, LR=0.000100
[2025-08-27 12:40:05,524][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068120] [Batch 00360/03080] [00:04:33/00:34:25, 0.759s/it]: train_loss_raw=0.3761, running_loss=0.4024, LR=0.000100
[2025-08-27 12:40:11,243][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068128] [Batch 00368/03080] [00:04:39/00:34:16, 0.758s/it]: train_loss_raw=0.4986, running_loss=0.4022, LR=0.000100
[2025-08-27 12:40:17,059][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068136] [Batch 00376/03080] [00:04:44/00:34:08, 0.758s/it]: train_loss_raw=0.4225, running_loss=0.4033, LR=0.000100
[2025-08-27 12:40:22,853][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068144] [Batch 00384/03080] [00:04:50/00:34:01, 0.757s/it]: train_loss_raw=0.3457, running_loss=0.4022, LR=0.000100
[2025-08-27 12:40:28,593][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068152] [Batch 00392/03080] [00:04:56/00:33:52, 0.756s/it]: train_loss_raw=0.3429, running_loss=0.4009, LR=0.000100
[2025-08-27 12:40:34,525][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068160] [Batch 00400/03080] [00:05:02/00:33:45, 0.756s/it]: train_loss_raw=0.4309, running_loss=0.4027, LR=0.000100
[2025-08-27 12:40:40,406][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068168] [Batch 00408/03080] [00:05:08/00:33:38, 0.756s/it]: train_loss_raw=0.4001, running_loss=0.4010, LR=0.000100
[2025-08-27 12:40:46,469][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068176] [Batch 00416/03080] [00:05:14/00:33:32, 0.756s/it]: train_loss_raw=0.3375, running_loss=0.4010, LR=0.000100
[2025-08-27 12:40:52,239][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068184] [Batch 00424/03080] [00:05:20/00:33:25, 0.755s/it]: train_loss_raw=0.4020, running_loss=0.4022, LR=0.000100
[2025-08-27 12:40:58,163][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068192] [Batch 00432/03080] [00:05:26/00:33:18, 0.755s/it]: train_loss_raw=0.4617, running_loss=0.4023, LR=0.000100
[2025-08-27 12:41:04,142][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068200] [Batch 00440/03080] [00:05:31/00:33:11, 0.755s/it]: train_loss_raw=0.3469, running_loss=0.4002, LR=0.000100
[2025-08-27 12:41:09,863][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068208] [Batch 00448/03080] [00:05:37/00:33:04, 0.754s/it]: train_loss_raw=0.4506, running_loss=0.4000, LR=0.000100
[2025-08-27 12:41:15,647][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068216] [Batch 00456/03080] [00:05:43/00:32:56, 0.753s/it]: train_loss_raw=0.3846, running_loss=0.3991, LR=0.000100
[2025-08-27 12:41:21,345][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068224] [Batch 00464/03080] [00:05:49/00:32:48, 0.753s/it]: train_loss_raw=0.3821, running_loss=0.3989, LR=0.000100
[2025-08-27 12:41:26,888][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068232] [Batch 00472/03080] [00:05:54/00:32:40, 0.752s/it]: train_loss_raw=0.3290, running_loss=0.3967, LR=0.000100
[2025-08-27 12:41:32,441][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068240] [Batch 00480/03080] [00:06:00/00:32:31, 0.751s/it]: train_loss_raw=0.3772, running_loss=0.3961, LR=0.000100
[2025-08-27 12:41:38,043][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068248] [Batch 00488/03080] [00:06:05/00:32:23, 0.750s/it]: train_loss_raw=0.3794, running_loss=0.3954, LR=0.000100
[2025-08-27 12:41:44,050][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068256] [Batch 00496/03080] [00:06:11/00:32:17, 0.750s/it]: train_loss_raw=0.3679, running_loss=0.3948, LR=0.000100
[2025-08-27 12:41:49,906][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068264] [Batch 00504/03080] [00:06:17/00:32:10, 0.750s/it]: train_loss_raw=0.3763, running_loss=0.3975, LR=0.000100
[2025-08-27 12:41:55,559][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068272] [Batch 00512/03080] [00:06:23/00:32:03, 0.749s/it]: train_loss_raw=0.4366, running_loss=0.3980, LR=0.000100
[2025-08-27 12:42:01,015][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068280] [Batch 00520/03080] [00:06:28/00:31:54, 0.748s/it]: train_loss_raw=0.3931, running_loss=0.3982, LR=0.000100
[2025-08-27 12:42:06,615][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068288] [Batch 00528/03080] [00:06:34/00:31:46, 0.747s/it]: train_loss_raw=0.4000, running_loss=0.3991, LR=0.000100
[2025-08-27 12:42:12,820][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068296] [Batch 00536/03080] [00:06:40/00:31:41, 0.748s/it]: train_loss_raw=0.4770, running_loss=0.3991, LR=0.000100
[2025-08-27 12:42:18,400][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068304] [Batch 00544/03080] [00:06:46/00:31:33, 0.747s/it]: train_loss_raw=0.3184, running_loss=0.3999, LR=0.000100
[2025-08-27 12:42:23,849][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068312] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=0.4630, running_loss=0.3998, LR=0.000100
[2025-08-27 12:42:29,773][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068320] [Batch 00560/03080] [00:06:57/00:31:19, 0.746s/it]: train_loss_raw=0.3760, running_loss=0.4008, LR=0.000100
[2025-08-27 12:42:35,383][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068328] [Batch 00568/03080] [00:07:03/00:31:11, 0.745s/it]: train_loss_raw=0.3907, running_loss=0.3995, LR=0.000100
[2025-08-27 12:42:41,216][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068336] [Batch 00576/03080] [00:07:09/00:31:05, 0.745s/it]: train_loss_raw=0.4265, running_loss=0.3990, LR=0.000100
[2025-08-27 12:42:46,854][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068344] [Batch 00584/03080] [00:07:14/00:30:57, 0.744s/it]: train_loss_raw=0.4412, running_loss=0.4002, LR=0.000100
[2025-08-27 12:42:52,684][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068352] [Batch 00592/03080] [00:07:20/00:30:51, 0.744s/it]: train_loss_raw=0.3963, running_loss=0.3984, LR=0.000100
[2025-08-27 12:42:58,524][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068360] [Batch 00600/03080] [00:07:26/00:30:45, 0.744s/it]: train_loss_raw=0.3600, running_loss=0.3997, LR=0.000100
[2025-08-27 12:43:04,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068368] [Batch 00608/03080] [00:07:32/00:30:39, 0.744s/it]: train_loss_raw=0.4558, running_loss=0.3988, LR=0.000100
[2025-08-27 12:43:10,267][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068376] [Batch 00616/03080] [00:07:38/00:30:32, 0.744s/it]: train_loss_raw=0.4091, running_loss=0.3985, LR=0.000100
[2025-08-27 12:43:15,949][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068384] [Batch 00624/03080] [00:07:43/00:30:25, 0.743s/it]: train_loss_raw=0.3588, running_loss=0.3982, LR=0.000100
[2025-08-27 12:43:21,715][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068392] [Batch 00632/03080] [00:07:49/00:30:18, 0.743s/it]: train_loss_raw=0.4419, running_loss=0.3974, LR=0.000100
[2025-08-27 12:43:27,479][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068400] [Batch 00640/03080] [00:07:55/00:30:12, 0.743s/it]: train_loss_raw=0.4390, running_loss=0.3988, LR=0.000100
[2025-08-27 12:43:33,301][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068408] [Batch 00648/03080] [00:08:01/00:30:05, 0.743s/it]: train_loss_raw=0.3644, running_loss=0.3971, LR=0.000100
[2025-08-27 12:43:39,129][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068416] [Batch 00656/03080] [00:08:06/00:29:59, 0.742s/it]: train_loss_raw=0.4012, running_loss=0.3975, LR=0.000100
[2025-08-27 12:43:44,691][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068424] [Batch 00664/03080] [00:08:12/00:29:52, 0.742s/it]: train_loss_raw=0.4569, running_loss=0.3984, LR=0.000100
[2025-08-27 12:43:50,433][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068432] [Batch 00672/03080] [00:08:18/00:29:45, 0.741s/it]: train_loss_raw=0.4805, running_loss=0.4004, LR=0.000100
[2025-08-27 12:43:56,155][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068440] [Batch 00680/03080] [00:08:24/00:29:38, 0.741s/it]: train_loss_raw=0.3428, running_loss=0.3997, LR=0.000100
[2025-08-27 12:44:01,940][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068448] [Batch 00688/03080] [00:08:29/00:29:32, 0.741s/it]: train_loss_raw=0.3748, running_loss=0.4017, LR=0.000100
[2025-08-27 12:44:07,985][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068456] [Batch 00696/03080] [00:08:35/00:29:26, 0.741s/it]: train_loss_raw=0.3715, running_loss=0.4024, LR=0.000100
[2025-08-27 12:44:13,857][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068464] [Batch 00704/03080] [00:08:41/00:29:20, 0.741s/it]: train_loss_raw=0.4268, running_loss=0.4045, LR=0.000100
[2025-08-27 12:44:19,755][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068472] [Batch 00712/03080] [00:08:47/00:29:14, 0.741s/it]: train_loss_raw=0.3931, running_loss=0.4058, LR=0.000100
[2025-08-27 12:44:25,650][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068480] [Batch 00720/03080] [00:08:53/00:29:08, 0.741s/it]: train_loss_raw=0.3119, running_loss=0.4052, LR=0.000100
[2025-08-27 12:44:31,487][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068488] [Batch 00728/03080] [00:08:59/00:29:02, 0.741s/it]: train_loss_raw=0.4931, running_loss=0.4085, LR=0.000100
[2025-08-27 12:44:37,322][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068496] [Batch 00736/03080] [00:09:05/00:28:56, 0.741s/it]: train_loss_raw=0.3339, running_loss=0.4045, LR=0.000100
[2025-08-27 12:44:43,142][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068504] [Batch 00744/03080] [00:09:10/00:28:50, 0.741s/it]: train_loss_raw=0.4172, running_loss=0.4046, LR=0.000100
[2025-08-27 12:44:48,995][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068512] [Batch 00752/03080] [00:09:16/00:28:43, 0.740s/it]: train_loss_raw=0.4559, running_loss=0.4050, LR=0.000100
[2025-08-27 12:44:54,807][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068520] [Batch 00760/03080] [00:09:22/00:28:37, 0.740s/it]: train_loss_raw=0.4101, running_loss=0.4051, LR=0.000100
[2025-08-27 12:45:00,569][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068528] [Batch 00768/03080] [00:09:28/00:28:31, 0.740s/it]: train_loss_raw=0.3963, running_loss=0.4051, LR=0.000100
[2025-08-27 12:45:06,312][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068536] [Batch 00776/03080] [00:09:34/00:28:24, 0.740s/it]: train_loss_raw=0.4383, running_loss=0.4034, LR=0.000100
[2025-08-27 12:45:12,190][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068544] [Batch 00784/03080] [00:09:40/00:28:18, 0.740s/it]: train_loss_raw=0.4124, running_loss=0.4038, LR=0.000100
[2025-08-27 12:45:18,194][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068552] [Batch 00792/03080] [00:09:46/00:28:13, 0.740s/it]: train_loss_raw=0.4025, running_loss=0.4024, LR=0.000100
[2025-08-27 12:45:24,018][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068560] [Batch 00800/03080] [00:09:51/00:28:06, 0.740s/it]: train_loss_raw=0.3909, running_loss=0.4035, LR=0.000100
[2025-08-27 12:45:29,788][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068568] [Batch 00808/03080] [00:09:57/00:28:00, 0.740s/it]: train_loss_raw=0.4359, running_loss=0.4051, LR=0.000100
[2025-08-27 12:45:35,493][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068576] [Batch 00816/03080] [00:10:03/00:27:53, 0.739s/it]: train_loss_raw=0.3492, running_loss=0.4040, LR=0.000100
[2025-08-27 12:45:41,230][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068584] [Batch 00824/03080] [00:10:09/00:27:47, 0.739s/it]: train_loss_raw=0.4114, running_loss=0.4036, LR=0.000100
[2025-08-27 12:45:46,975][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068592] [Batch 00832/03080] [00:10:14/00:27:41, 0.739s/it]: train_loss_raw=0.4286, running_loss=0.4041, LR=0.000100
[2025-08-27 12:45:52,724][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068600] [Batch 00840/03080] [00:10:20/00:27:34, 0.739s/it]: train_loss_raw=0.3314, running_loss=0.4028, LR=0.000100
[2025-08-27 12:45:58,540][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068608] [Batch 00848/03080] [00:10:26/00:27:28, 0.739s/it]: train_loss_raw=0.3312, running_loss=0.4023, LR=0.000100
[2025-08-27 12:46:04,361][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068616] [Batch 00856/03080] [00:10:32/00:27:22, 0.739s/it]: train_loss_raw=0.4366, running_loss=0.4030, LR=0.000100
[2025-08-27 12:46:10,315][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068624] [Batch 00864/03080] [00:10:38/00:27:16, 0.739s/it]: train_loss_raw=0.3963, running_loss=0.4050, LR=0.000100
[2025-08-27 12:46:16,260][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068632] [Batch 00872/03080] [00:10:44/00:27:10, 0.739s/it]: train_loss_raw=0.3857, running_loss=0.4057, LR=0.000100
[2025-08-27 12:46:21,913][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068640] [Batch 00880/03080] [00:10:49/00:27:04, 0.738s/it]: train_loss_raw=0.4033, running_loss=0.4064, LR=0.000100
[2025-08-27 12:46:27,749][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068648] [Batch 00888/03080] [00:10:55/00:26:58, 0.738s/it]: train_loss_raw=0.3502, running_loss=0.4072, LR=0.000100
[2025-08-27 12:46:33,613][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068656] [Batch 00896/03080] [00:11:01/00:26:52, 0.738s/it]: train_loss_raw=0.4041, running_loss=0.4083, LR=0.000100
[2025-08-27 12:46:39,431][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068664] [Batch 00904/03080] [00:11:07/00:26:46, 0.738s/it]: train_loss_raw=0.3475, running_loss=0.4078, LR=0.000100
[2025-08-27 12:46:45,249][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068672] [Batch 00912/03080] [00:11:13/00:26:40, 0.738s/it]: train_loss_raw=0.4194, running_loss=0.4068, LR=0.000100
[2025-08-27 12:46:50,990][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068680] [Batch 00920/03080] [00:11:18/00:26:33, 0.738s/it]: train_loss_raw=0.3600, running_loss=0.4066, LR=0.000100
[2025-08-27 12:46:56,896][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068688] [Batch 00928/03080] [00:11:24/00:26:27, 0.738s/it]: train_loss_raw=0.3788, running_loss=0.4092, LR=0.000100
[2025-08-27 12:47:02,779][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068696] [Batch 00936/03080] [00:11:30/00:26:21, 0.738s/it]: train_loss_raw=0.4270, running_loss=0.4099, LR=0.000100
[2025-08-27 12:47:08,528][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068704] [Batch 00944/03080] [00:11:36/00:26:15, 0.738s/it]: train_loss_raw=0.4049, running_loss=0.4083, LR=0.000100
[2025-08-27 12:47:14,507][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068712] [Batch 00952/03080] [00:11:42/00:26:09, 0.738s/it]: train_loss_raw=0.4076, running_loss=0.4082, LR=0.000100
[2025-08-27 12:47:20,229][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068720] [Batch 00960/03080] [00:11:48/00:26:03, 0.738s/it]: train_loss_raw=0.4553, running_loss=0.4085, LR=0.000100
[2025-08-27 12:47:26,015][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068728] [Batch 00968/03080] [00:11:53/00:25:57, 0.737s/it]: train_loss_raw=0.3994, running_loss=0.4055, LR=0.000100
[2025-08-27 12:47:31,822][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068736] [Batch 00976/03080] [00:11:59/00:25:51, 0.737s/it]: train_loss_raw=0.4104, running_loss=0.4070, LR=0.000100
[2025-08-27 12:47:37,705][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068744] [Batch 00984/03080] [00:12:05/00:25:45, 0.737s/it]: train_loss_raw=0.4816, running_loss=0.4074, LR=0.000100
[2025-08-27 12:47:43,646][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068752] [Batch 00992/03080] [00:12:11/00:25:39, 0.737s/it]: train_loss_raw=0.4286, running_loss=0.4066, LR=0.000100
[2025-08-27 12:47:49,440][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068760] [Batch 01000/03080] [00:12:17/00:25:33, 0.737s/it]: train_loss_raw=0.4498, running_loss=0.4097, LR=0.000100
[2025-08-27 12:47:55,177][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068768] [Batch 01008/03080] [00:12:23/00:25:27, 0.737s/it]: train_loss_raw=0.3595, running_loss=0.4077, LR=0.000100
[2025-08-27 12:48:01,100][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068776] [Batch 01016/03080] [00:12:28/00:25:21, 0.737s/it]: train_loss_raw=0.4170, running_loss=0.4055, LR=0.000100
[2025-08-27 12:48:06,706][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068784] [Batch 01024/03080] [00:12:34/00:25:15, 0.737s/it]: train_loss_raw=0.4407, running_loss=0.4055, LR=0.000100
[2025-08-27 12:48:12,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068792] [Batch 01032/03080] [00:12:40/00:25:08, 0.737s/it]: train_loss_raw=0.4080, running_loss=0.4062, LR=0.000100
[2025-08-27 12:48:18,381][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068800] [Batch 01040/03080] [00:12:46/00:25:03, 0.737s/it]: train_loss_raw=0.4739, running_loss=0.4063, LR=0.000100
[2025-08-27 12:48:24,102][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068808] [Batch 01048/03080] [00:12:51/00:24:56, 0.737s/it]: train_loss_raw=0.3700, running_loss=0.4062, LR=0.000100
[2025-08-27 12:48:29,914][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068816] [Batch 01056/03080] [00:12:57/00:24:50, 0.737s/it]: train_loss_raw=0.3841, running_loss=0.4058, LR=0.000100
[2025-08-27 12:48:35,774][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068824] [Batch 01064/03080] [00:13:03/00:24:44, 0.736s/it]: train_loss_raw=0.4590, running_loss=0.4053, LR=0.000100
[2025-08-27 12:48:41,710][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068832] [Batch 01072/03080] [00:13:09/00:24:38, 0.737s/it]: train_loss_raw=0.4193, running_loss=0.4050, LR=0.000100
[2025-08-27 12:48:47,533][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068840] [Batch 01080/03080] [00:13:15/00:24:32, 0.736s/it]: train_loss_raw=0.4429, running_loss=0.4042, LR=0.000100
[2025-08-27 12:48:53,502][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068848] [Batch 01088/03080] [00:13:21/00:24:27, 0.737s/it]: train_loss_raw=0.4173, running_loss=0.4042, LR=0.000100
[2025-08-27 12:48:59,359][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068856] [Batch 01096/03080] [00:13:27/00:24:21, 0.737s/it]: train_loss_raw=0.3489, running_loss=0.4033, LR=0.000100
[2025-08-27 12:49:05,227][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068864] [Batch 01104/03080] [00:13:33/00:24:15, 0.736s/it]: train_loss_raw=0.4039, running_loss=0.4037, LR=0.000100
[2025-08-27 12:49:10,827][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068872] [Batch 01112/03080] [00:13:38/00:24:08, 0.736s/it]: train_loss_raw=0.4827, running_loss=0.4037, LR=0.000100
[2025-08-27 12:49:16,629][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068880] [Batch 01120/03080] [00:13:44/00:24:02, 0.736s/it]: train_loss_raw=0.4642, running_loss=0.4040, LR=0.000100
[2025-08-27 12:49:22,383][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068888] [Batch 01128/03080] [00:13:50/00:23:56, 0.736s/it]: train_loss_raw=0.4245, running_loss=0.4041, LR=0.000100
[2025-08-27 12:49:28,353][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068896] [Batch 01136/03080] [00:13:56/00:23:50, 0.736s/it]: train_loss_raw=0.3810, running_loss=0.4039, LR=0.000100
[2025-08-27 12:49:34,069][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068904] [Batch 01144/03080] [00:14:01/00:23:44, 0.736s/it]: train_loss_raw=0.4032, running_loss=0.4049, LR=0.000100
[2025-08-27 12:49:39,526][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068912] [Batch 01152/03080] [00:14:07/00:23:38, 0.736s/it]: train_loss_raw=0.5084, running_loss=0.4055, LR=0.000100
[2025-08-27 12:49:44,947][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068920] [Batch 01160/03080] [00:14:12/00:23:31, 0.735s/it]: train_loss_raw=0.4449, running_loss=0.4071, LR=0.000100
[2025-08-27 12:49:50,372][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068928] [Batch 01168/03080] [00:14:18/00:23:24, 0.735s/it]: train_loss_raw=0.4242, running_loss=0.4077, LR=0.000100
[2025-08-27 12:49:55,927][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068936] [Batch 01176/03080] [00:14:23/00:23:18, 0.735s/it]: train_loss_raw=0.3940, running_loss=0.4072, LR=0.000100
[2025-08-27 12:50:01,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068944] [Batch 01184/03080] [00:14:29/00:23:11, 0.734s/it]: train_loss_raw=0.4194, running_loss=0.4058, LR=0.000100
[2025-08-27 12:50:06,918][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068952] [Batch 01192/03080] [00:14:34/00:23:05, 0.734s/it]: train_loss_raw=0.3504, running_loss=0.4061, LR=0.000100
[2025-08-27 12:50:12,800][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068960] [Batch 01200/03080] [00:14:40/00:22:59, 0.734s/it]: train_loss_raw=0.3058, running_loss=0.4027, LR=0.000100
[2025-08-27 12:50:18,619][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068968] [Batch 01208/03080] [00:14:46/00:22:53, 0.734s/it]: train_loss_raw=0.3328, running_loss=0.4018, LR=0.000100
[2025-08-27 12:50:24,347][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068976] [Batch 01216/03080] [00:14:52/00:22:47, 0.734s/it]: train_loss_raw=0.3315, running_loss=0.4009, LR=0.000100
[2025-08-27 12:50:30,148][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068984] [Batch 01224/03080] [00:14:58/00:22:41, 0.734s/it]: train_loss_raw=0.3764, running_loss=0.4011, LR=0.000100
[2025-08-27 12:50:36,245][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068992] [Batch 01232/03080] [00:15:04/00:22:36, 0.734s/it]: train_loss_raw=0.4483, running_loss=0.4012, LR=0.000100
[2025-08-27 12:50:41,975][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069000] [Batch 01240/03080] [00:15:09/00:22:30, 0.734s/it]: train_loss_raw=0.3655, running_loss=0.4034, LR=0.000100
[2025-08-27 12:50:47,752][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069008] [Batch 01248/03080] [00:15:15/00:22:24, 0.734s/it]: train_loss_raw=0.4481, running_loss=0.4044, LR=0.000100
[2025-08-27 12:50:53,406][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069016] [Batch 01256/03080] [00:15:21/00:22:17, 0.733s/it]: train_loss_raw=0.3876, running_loss=0.4040, LR=0.000100
[2025-08-27 12:50:59,158][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069024] [Batch 01264/03080] [00:15:27/00:22:11, 0.733s/it]: train_loss_raw=0.3023, running_loss=0.4020, LR=0.000100
[2025-08-27 12:51:04,928][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069032] [Batch 01272/03080] [00:15:32/00:22:05, 0.733s/it]: train_loss_raw=0.4653, running_loss=0.4035, LR=0.000100
[2025-08-27 12:51:10,692][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069040] [Batch 01280/03080] [00:15:38/00:21:59, 0.733s/it]: train_loss_raw=0.4239, running_loss=0.4043, LR=0.000100
[2025-08-27 12:51:16,543][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069048] [Batch 01288/03080] [00:15:44/00:21:53, 0.733s/it]: train_loss_raw=0.3422, running_loss=0.4028, LR=0.000100
[2025-08-27 12:51:22,469][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069056] [Batch 01296/03080] [00:15:50/00:21:48, 0.733s/it]: train_loss_raw=0.3936, running_loss=0.4028, LR=0.000100
[2025-08-27 12:51:28,318][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069064] [Batch 01304/03080] [00:15:56/00:21:42, 0.733s/it]: train_loss_raw=0.3759, running_loss=0.4037, LR=0.000100
[2025-08-27 12:51:34,240][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069072] [Batch 01312/03080] [00:16:02/00:21:36, 0.733s/it]: train_loss_raw=0.4918, running_loss=0.4036, LR=0.000100
[2025-08-27 12:51:39,964][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069080] [Batch 01320/03080] [00:16:07/00:21:30, 0.733s/it]: train_loss_raw=0.3530, running_loss=0.4046, LR=0.000100
[2025-08-27 12:51:45,850][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069088] [Batch 01328/03080] [00:16:13/00:21:24, 0.733s/it]: train_loss_raw=0.4009, running_loss=0.4035, LR=0.000100
[2025-08-27 12:51:51,751][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069096] [Batch 01336/03080] [00:16:19/00:21:18, 0.733s/it]: train_loss_raw=0.3657, running_loss=0.4030, LR=0.000100
[2025-08-27 12:51:57,463][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069104] [Batch 01344/03080] [00:16:25/00:21:12, 0.733s/it]: train_loss_raw=0.3596, running_loss=0.4027, LR=0.000100
[2025-08-27 12:52:03,323][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069112] [Batch 01352/03080] [00:16:31/00:21:06, 0.733s/it]: train_loss_raw=0.3709, running_loss=0.4013, LR=0.000100
[2025-08-27 12:52:09,201][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069120] [Batch 01360/03080] [00:16:37/00:21:00, 0.733s/it]: train_loss_raw=0.3405, running_loss=0.4019, LR=0.000100
[2025-08-27 12:52:15,133][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069128] [Batch 01368/03080] [00:16:42/00:20:55, 0.733s/it]: train_loss_raw=0.3942, running_loss=0.4030, LR=0.000100
[2025-08-27 12:52:20,905][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069136] [Batch 01376/03080] [00:16:48/00:20:49, 0.733s/it]: train_loss_raw=0.4437, running_loss=0.4028, LR=0.000100
[2025-08-27 12:52:26,676][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069144] [Batch 01384/03080] [00:16:54/00:20:43, 0.733s/it]: train_loss_raw=0.4077, running_loss=0.4037, LR=0.000100
[2025-08-27 12:52:32,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069152] [Batch 01392/03080] [00:17:00/00:20:37, 0.733s/it]: train_loss_raw=0.3850, running_loss=0.4013, LR=0.000100
[2025-08-27 12:52:38,283][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069160] [Batch 01400/03080] [00:17:06/00:20:31, 0.733s/it]: train_loss_raw=0.4997, running_loss=0.4016, LR=0.000100
[2025-08-27 12:52:43,803][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069168] [Batch 01408/03080] [00:17:11/00:20:25, 0.733s/it]: train_loss_raw=0.4488, running_loss=0.4019, LR=0.000100
[2025-08-27 12:52:49,602][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069176] [Batch 01416/03080] [00:17:17/00:20:19, 0.733s/it]: train_loss_raw=0.4449, running_loss=0.4008, LR=0.000100
[2025-08-27 12:52:55,349][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069184] [Batch 01424/03080] [00:17:23/00:20:13, 0.733s/it]: train_loss_raw=0.3429, running_loss=0.4024, LR=0.000100
[2025-08-27 12:53:01,175][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069192] [Batch 01432/03080] [00:17:29/00:20:07, 0.733s/it]: train_loss_raw=0.4382, running_loss=0.4033, LR=0.000100
[2025-08-27 12:53:06,995][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069200] [Batch 01440/03080] [00:17:34/00:20:01, 0.733s/it]: train_loss_raw=0.3440, running_loss=0.4033, LR=0.000100
[2025-08-27 12:53:12,957][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069208] [Batch 01448/03080] [00:17:40/00:19:55, 0.733s/it]: train_loss_raw=0.3440, running_loss=0.4029, LR=0.000100
[2025-08-27 12:53:18,904][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069216] [Batch 01456/03080] [00:17:46/00:19:49, 0.733s/it]: train_loss_raw=0.3419, running_loss=0.4003, LR=0.000100
[2025-08-27 12:53:24,598][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069224] [Batch 01464/03080] [00:17:52/00:19:43, 0.733s/it]: train_loss_raw=0.4239, running_loss=0.4020, LR=0.000100
[2025-08-27 12:53:30,345][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069232] [Batch 01472/03080] [00:17:58/00:19:37, 0.732s/it]: train_loss_raw=0.4171, running_loss=0.4043, LR=0.000100
[2025-08-27 12:53:36,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069240] [Batch 01480/03080] [00:18:04/00:19:32, 0.733s/it]: train_loss_raw=0.3671, running_loss=0.4045, LR=0.000100
[2025-08-27 12:53:42,533][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069248] [Batch 01488/03080] [00:18:10/00:19:26, 0.733s/it]: train_loss_raw=0.5198, running_loss=0.4060, LR=0.000100
[2025-08-27 12:53:48,656][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069256] [Batch 01496/03080] [00:18:16/00:19:21, 0.733s/it]: train_loss_raw=0.4444, running_loss=0.4091, LR=0.000100
[2025-08-27 12:53:54,389][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069264] [Batch 01504/03080] [00:18:22/00:19:15, 0.733s/it]: train_loss_raw=0.4118, running_loss=0.4100, LR=0.000100
[2025-08-27 12:54:00,117][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069272] [Batch 01512/03080] [00:18:27/00:19:09, 0.733s/it]: train_loss_raw=0.3749, running_loss=0.4101, LR=0.000100
[2025-08-27 12:54:06,213][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069280] [Batch 01520/03080] [00:18:34/00:19:03, 0.733s/it]: train_loss_raw=0.4162, running_loss=0.4090, LR=0.000100
[2025-08-27 12:54:12,065][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069288] [Batch 01528/03080] [00:18:39/00:18:57, 0.733s/it]: train_loss_raw=0.3097, running_loss=0.4076, LR=0.000100
[2025-08-27 12:54:17,843][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069296] [Batch 01536/03080] [00:18:45/00:18:51, 0.733s/it]: train_loss_raw=0.4299, running_loss=0.4070, LR=0.000100
[2025-08-27 12:54:23,608][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069304] [Batch 01544/03080] [00:18:51/00:18:45, 0.733s/it]: train_loss_raw=0.3285, running_loss=0.4067, LR=0.000100
[2025-08-27 12:54:29,334][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069312] [Batch 01552/03080] [00:18:57/00:18:39, 0.733s/it]: train_loss_raw=0.3983, running_loss=0.4072, LR=0.000100
[2025-08-27 12:54:35,136][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069320] [Batch 01560/03080] [00:19:02/00:18:33, 0.733s/it]: train_loss_raw=0.4589, running_loss=0.4075, LR=0.000100
[2025-08-27 12:54:41,032][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069328] [Batch 01568/03080] [00:19:08/00:18:27, 0.733s/it]: train_loss_raw=0.3787, running_loss=0.4090, LR=0.000100
[2025-08-27 12:54:46,913][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069336] [Batch 01576/03080] [00:19:14/00:18:22, 0.733s/it]: train_loss_raw=0.3643, running_loss=0.4084, LR=0.000100
[2025-08-27 12:54:52,896][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069344] [Batch 01584/03080] [00:19:20/00:18:16, 0.733s/it]: train_loss_raw=0.4094, running_loss=0.4095, LR=0.000100
[2025-08-27 12:54:58,487][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069352] [Batch 01592/03080] [00:19:26/00:18:10, 0.733s/it]: train_loss_raw=0.4537, running_loss=0.4080, LR=0.000100
[2025-08-27 12:55:04,320][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069360] [Batch 01600/03080] [00:19:32/00:18:04, 0.733s/it]: train_loss_raw=0.4080, running_loss=0.4067, LR=0.000100
[2025-08-27 12:55:10,158][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069368] [Batch 01608/03080] [00:19:38/00:17:58, 0.733s/it]: train_loss_raw=0.4529, running_loss=0.4083, LR=0.000100
[2025-08-27 12:55:15,956][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069376] [Batch 01616/03080] [00:19:43/00:17:52, 0.733s/it]: train_loss_raw=0.4085, running_loss=0.4066, LR=0.000100
[2025-08-27 12:55:21,757][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069384] [Batch 01624/03080] [00:19:49/00:17:46, 0.733s/it]: train_loss_raw=0.4961, running_loss=0.4079, LR=0.000100
[2025-08-27 12:55:27,425][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069392] [Batch 01632/03080] [00:19:55/00:17:40, 0.732s/it]: train_loss_raw=0.3524, running_loss=0.4071, LR=0.000100
[2025-08-27 12:55:33,231][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069400] [Batch 01640/03080] [00:20:01/00:17:34, 0.732s/it]: train_loss_raw=0.4204, running_loss=0.4073, LR=0.000100
[2025-08-27 12:55:39,024][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069408] [Batch 01648/03080] [00:20:06/00:17:28, 0.732s/it]: train_loss_raw=0.4480, running_loss=0.4074, LR=0.000100
[2025-08-27 12:55:44,738][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069416] [Batch 01656/03080] [00:20:12/00:17:22, 0.732s/it]: train_loss_raw=0.4364, running_loss=0.4083, LR=0.000100
[2025-08-27 12:55:50,483][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069424] [Batch 01664/03080] [00:20:18/00:17:16, 0.732s/it]: train_loss_raw=0.3664, running_loss=0.4068, LR=0.000100
[2025-08-27 12:55:56,460][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069432] [Batch 01672/03080] [00:20:24/00:17:11, 0.732s/it]: train_loss_raw=0.3885, running_loss=0.4050, LR=0.000100
[2025-08-27 12:56:02,199][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069440] [Batch 01680/03080] [00:20:30/00:17:05, 0.732s/it]: train_loss_raw=0.3533, running_loss=0.4047, LR=0.000100
[2025-08-27 12:56:07,899][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069448] [Batch 01688/03080] [00:20:35/00:16:59, 0.732s/it]: train_loss_raw=0.3561, running_loss=0.4025, LR=0.000100
[2025-08-27 12:56:13,803][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069456] [Batch 01696/03080] [00:20:41/00:16:53, 0.732s/it]: train_loss_raw=0.4004, running_loss=0.4030, LR=0.000100
[2025-08-27 12:56:19,899][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069464] [Batch 01704/03080] [00:20:47/00:16:47, 0.732s/it]: train_loss_raw=0.3644, running_loss=0.4039, LR=0.000100
[2025-08-27 12:56:25,772][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069472] [Batch 01712/03080] [00:20:53/00:16:41, 0.732s/it]: train_loss_raw=0.4278, running_loss=0.4053, LR=0.000100
[2025-08-27 12:56:31,636][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069480] [Batch 01720/03080] [00:20:59/00:16:35, 0.732s/it]: train_loss_raw=0.3742, running_loss=0.4053, LR=0.000100
[2025-08-27 12:56:37,741][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069488] [Batch 01728/03080] [00:21:05/00:16:30, 0.732s/it]: train_loss_raw=0.4285, running_loss=0.4046, LR=0.000100
[2025-08-27 12:56:43,508][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069496] [Batch 01736/03080] [00:21:11/00:16:24, 0.732s/it]: train_loss_raw=0.4268, running_loss=0.4055, LR=0.000100
[2025-08-27 12:56:49,315][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069504] [Batch 01744/03080] [00:21:17/00:16:18, 0.732s/it]: train_loss_raw=0.3350, running_loss=0.4032, LR=0.000100
[2025-08-27 12:56:55,337][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069512] [Batch 01752/03080] [00:21:23/00:16:12, 0.732s/it]: train_loss_raw=0.3471, running_loss=0.4022, LR=0.000100
[2025-08-27 12:57:01,264][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069520] [Batch 01760/03080] [00:21:29/00:16:06, 0.732s/it]: train_loss_raw=0.4139, running_loss=0.4018, LR=0.000100
[2025-08-27 12:57:06,979][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069528] [Batch 01768/03080] [00:21:34/00:16:00, 0.732s/it]: train_loss_raw=0.3468, running_loss=0.4001, LR=0.000100
[2025-08-27 12:57:12,693][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069536] [Batch 01776/03080] [00:21:40/00:15:54, 0.732s/it]: train_loss_raw=0.3861, running_loss=0.3987, LR=0.000100
[2025-08-27 12:57:18,413][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069544] [Batch 01784/03080] [00:21:46/00:15:48, 0.732s/it]: train_loss_raw=0.3943, running_loss=0.3998, LR=0.000100
[2025-08-27 12:57:24,127][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069552] [Batch 01792/03080] [00:21:51/00:15:42, 0.732s/it]: train_loss_raw=0.3694, running_loss=0.3989, LR=0.000100
[2025-08-27 12:57:29,838][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069560] [Batch 01800/03080] [00:21:57/00:15:37, 0.732s/it]: train_loss_raw=0.3695, running_loss=0.3980, LR=0.000100
[2025-08-27 12:57:35,627][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069568] [Batch 01808/03080] [00:22:03/00:15:31, 0.732s/it]: train_loss_raw=0.3649, running_loss=0.3978, LR=0.000100
[2025-08-27 12:57:41,432][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069576] [Batch 01816/03080] [00:22:09/00:15:25, 0.732s/it]: train_loss_raw=0.3715, running_loss=0.3952, LR=0.000100
[2025-08-27 12:57:47,162][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069584] [Batch 01824/03080] [00:22:15/00:15:19, 0.732s/it]: train_loss_raw=0.4666, running_loss=0.3951, LR=0.000100
[2025-08-27 12:57:52,997][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069592] [Batch 01832/03080] [00:22:20/00:15:13, 0.732s/it]: train_loss_raw=0.3782, running_loss=0.3944, LR=0.000100
[2025-08-27 12:57:58,740][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069600] [Batch 01840/03080] [00:22:26/00:15:07, 0.732s/it]: train_loss_raw=0.3614, running_loss=0.3945, LR=0.000100
[2025-08-27 12:58:04,460][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069608] [Batch 01848/03080] [00:22:32/00:15:01, 0.732s/it]: train_loss_raw=0.4358, running_loss=0.3955, LR=0.000100
[2025-08-27 12:58:10,182][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069616] [Batch 01856/03080] [00:22:38/00:14:55, 0.732s/it]: train_loss_raw=0.4910, running_loss=0.3958, LR=0.000100
[2025-08-27 12:58:15,839][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069624] [Batch 01864/03080] [00:22:43/00:14:49, 0.732s/it]: train_loss_raw=0.3777, running_loss=0.3975, LR=0.000100
[2025-08-27 12:58:21,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069632] [Batch 01872/03080] [00:22:49/00:14:43, 0.731s/it]: train_loss_raw=0.4260, running_loss=0.3980, LR=0.000100
[2025-08-27 12:58:26,846][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069640] [Batch 01880/03080] [00:22:54/00:14:37, 0.731s/it]: train_loss_raw=0.3581, running_loss=0.3984, LR=0.000100
[2025-08-27 12:58:32,310][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069648] [Batch 01888/03080] [00:23:00/00:14:31, 0.731s/it]: train_loss_raw=0.3930, running_loss=0.3967, LR=0.000100
[2025-08-27 12:58:38,233][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069656] [Batch 01896/03080] [00:23:06/00:14:25, 0.731s/it]: train_loss_raw=0.3381, running_loss=0.3967, LR=0.000100
[2025-08-27 12:58:43,908][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069664] [Batch 01904/03080] [00:23:11/00:14:19, 0.731s/it]: train_loss_raw=0.4382, running_loss=0.3987, LR=0.000100
[2025-08-27 12:58:49,788][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069672] [Batch 01912/03080] [00:23:17/00:14:13, 0.731s/it]: train_loss_raw=0.3371, running_loss=0.3994, LR=0.000100
[2025-08-27 12:58:55,763][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069680] [Batch 01920/03080] [00:23:23/00:14:08, 0.731s/it]: train_loss_raw=0.3685, running_loss=0.3987, LR=0.000100
[2025-08-27 12:59:01,634][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069688] [Batch 01928/03080] [00:23:29/00:14:02, 0.731s/it]: train_loss_raw=0.4489, running_loss=0.3997, LR=0.000100
[2025-08-27 12:59:07,588][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069696] [Batch 01936/03080] [00:23:35/00:13:56, 0.731s/it]: train_loss_raw=0.4574, running_loss=0.4006, LR=0.000100
[2025-08-27 12:59:13,574][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069704] [Batch 01944/03080] [00:23:41/00:13:50, 0.731s/it]: train_loss_raw=0.3768, running_loss=0.4018, LR=0.000100
[2025-08-27 12:59:19,266][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069712] [Batch 01952/03080] [00:23:47/00:13:44, 0.731s/it]: train_loss_raw=0.3919, running_loss=0.4025, LR=0.000100
[2025-08-27 12:59:24,976][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069720] [Batch 01960/03080] [00:23:52/00:13:38, 0.731s/it]: train_loss_raw=0.4197, running_loss=0.4029, LR=0.000100
[2025-08-27 12:59:30,852][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069728] [Batch 01968/03080] [00:23:58/00:13:32, 0.731s/it]: train_loss_raw=0.3774, running_loss=0.4020, LR=0.000100
[2025-08-27 12:59:36,584][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069736] [Batch 01976/03080] [00:24:04/00:13:27, 0.731s/it]: train_loss_raw=0.4220, running_loss=0.4030, LR=0.000100
[2025-08-27 12:59:42,391][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069744] [Batch 01984/03080] [00:24:10/00:13:21, 0.731s/it]: train_loss_raw=0.3479, running_loss=0.4040, LR=0.000100
[2025-08-27 12:59:48,133][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069752] [Batch 01992/03080] [00:24:15/00:13:15, 0.731s/it]: train_loss_raw=0.3478, running_loss=0.4032, LR=0.000100
[2025-08-27 12:59:54,013][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069760] [Batch 02000/03080] [00:24:21/00:13:09, 0.731s/it]: train_loss_raw=0.4429, running_loss=0.4021, LR=0.000100
[2025-08-27 12:59:59,566][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069768] [Batch 02008/03080] [00:24:27/00:13:03, 0.731s/it]: train_loss_raw=0.4665, running_loss=0.4039, LR=0.000100
[2025-08-27 13:00:05,438][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069776] [Batch 02016/03080] [00:24:33/00:12:57, 0.731s/it]: train_loss_raw=0.4757, running_loss=0.4044, LR=0.000100
[2025-08-27 13:00:11,179][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069784] [Batch 02024/03080] [00:24:39/00:12:51, 0.731s/it]: train_loss_raw=0.3820, running_loss=0.4043, LR=0.000100
[2025-08-27 13:00:16,977][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069792] [Batch 02032/03080] [00:24:44/00:12:45, 0.731s/it]: train_loss_raw=0.3451, running_loss=0.4046, LR=0.000100
[2025-08-27 13:00:22,730][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069800] [Batch 02040/03080] [00:24:50/00:12:39, 0.731s/it]: train_loss_raw=0.4384, running_loss=0.4065, LR=0.000100
[2025-08-27 13:00:28,596][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069808] [Batch 02048/03080] [00:24:56/00:12:34, 0.731s/it]: train_loss_raw=0.3530, running_loss=0.4051, LR=0.000100
[2025-08-27 13:00:34,405][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069816] [Batch 02056/03080] [00:25:02/00:12:28, 0.731s/it]: train_loss_raw=0.4049, running_loss=0.4058, LR=0.000100
[2025-08-27 13:00:40,157][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069824] [Batch 02064/03080] [00:25:08/00:12:22, 0.731s/it]: train_loss_raw=0.4401, running_loss=0.4088, LR=0.000100
[2025-08-27 13:00:46,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069832] [Batch 02072/03080] [00:25:13/00:12:16, 0.731s/it]: train_loss_raw=0.3450, running_loss=0.4092, LR=0.000100
[2025-08-27 13:00:51,989][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069840] [Batch 02080/03080] [00:25:19/00:12:10, 0.731s/it]: train_loss_raw=0.3836, running_loss=0.4075, LR=0.000100
[2025-08-27 13:00:57,988][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069848] [Batch 02088/03080] [00:25:25/00:12:04, 0.731s/it]: train_loss_raw=0.4129, running_loss=0.4058, LR=0.000100
[2025-08-27 13:01:04,201][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069856] [Batch 02096/03080] [00:25:32/00:11:59, 0.731s/it]: train_loss_raw=0.4644, running_loss=0.4063, LR=0.000100
[2025-08-27 13:01:10,170][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069864] [Batch 02104/03080] [00:25:38/00:11:53, 0.731s/it]: train_loss_raw=0.4504, running_loss=0.4056, LR=0.000100
[2025-08-27 13:01:16,183][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069872] [Batch 02112/03080] [00:25:44/00:11:47, 0.731s/it]: train_loss_raw=0.3950, running_loss=0.4054, LR=0.000100
[2025-08-27 13:01:22,134][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069880] [Batch 02120/03080] [00:25:49/00:11:41, 0.731s/it]: train_loss_raw=0.3797, running_loss=0.4053, LR=0.000100
[2025-08-27 13:01:28,078][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069888] [Batch 02128/03080] [00:25:55/00:11:36, 0.731s/it]: train_loss_raw=0.4575, running_loss=0.4053, LR=0.000100
[2025-08-27 13:01:34,041][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069896] [Batch 02136/03080] [00:26:01/00:11:30, 0.731s/it]: train_loss_raw=0.3582, running_loss=0.4050, LR=0.000100
[2025-08-27 13:01:39,993][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069904] [Batch 02144/03080] [00:26:07/00:11:24, 0.731s/it]: train_loss_raw=0.3619, running_loss=0.4036, LR=0.000100
[2025-08-27 13:01:46,158][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069912] [Batch 02152/03080] [00:26:14/00:11:18, 0.731s/it]: train_loss_raw=0.4445, running_loss=0.4032, LR=0.000100
[2025-08-27 13:01:52,125][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069920] [Batch 02160/03080] [00:26:19/00:11:12, 0.731s/it]: train_loss_raw=0.4091, running_loss=0.4043, LR=0.000100
[2025-08-27 13:01:58,127][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069928] [Batch 02168/03080] [00:26:25/00:11:07, 0.732s/it]: train_loss_raw=0.4951, running_loss=0.4072, LR=0.000100
[2025-08-27 13:02:04,094][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069936] [Batch 02176/03080] [00:26:31/00:11:01, 0.732s/it]: train_loss_raw=0.4507, running_loss=0.4084, LR=0.000100
[2025-08-27 13:02:10,076][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069944] [Batch 02184/03080] [00:26:37/00:10:55, 0.732s/it]: train_loss_raw=0.4053, running_loss=0.4061, LR=0.000100
[2025-08-27 13:02:16,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069952] [Batch 02192/03080] [00:26:43/00:10:49, 0.732s/it]: train_loss_raw=0.4417, running_loss=0.4067, LR=0.000100
[2025-08-27 13:02:22,247][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069960] [Batch 02200/03080] [00:26:50/00:10:44, 0.732s/it]: train_loss_raw=0.4746, running_loss=0.4086, LR=0.000100
[2025-08-27 13:02:28,243][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069968] [Batch 02208/03080] [00:26:56/00:10:38, 0.732s/it]: train_loss_raw=0.4824, running_loss=0.4067, LR=0.000100
[2025-08-27 13:02:34,264][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069976] [Batch 02216/03080] [00:27:02/00:10:32, 0.732s/it]: train_loss_raw=0.3347, running_loss=0.4054, LR=0.000100
[2025-08-27 13:02:40,238][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069984] [Batch 02224/03080] [00:27:08/00:10:26, 0.732s/it]: train_loss_raw=0.4746, running_loss=0.4047, LR=0.000100
[2025-08-27 13:02:46,192][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069992] [Batch 02232/03080] [00:27:14/00:10:20, 0.732s/it]: train_loss_raw=0.3803, running_loss=0.4042, LR=0.000100
[2025-08-27 13:02:52,199][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070000] [Batch 02240/03080] [00:27:20/00:10:15, 0.732s/it]: train_loss_raw=0.3900, running_loss=0.4057, LR=0.000100
[2025-08-27 13:03:02,073][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070008] [Batch 02248/03080] [00:27:29/00:10:10, 0.734s/it]: train_loss_raw=0.4491, running_loss=0.4059, LR=0.000100
[2025-08-27 13:03:08,018][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070016] [Batch 02256/03080] [00:27:35/00:10:04, 0.734s/it]: train_loss_raw=0.4965, running_loss=0.4086, LR=0.000100
[2025-08-27 13:03:14,170][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070024] [Batch 02264/03080] [00:27:42/00:09:59, 0.734s/it]: train_loss_raw=0.3944, running_loss=0.4070, LR=0.000100
[2025-08-27 13:03:20,390][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070032] [Batch 02272/03080] [00:27:48/00:09:53, 0.734s/it]: train_loss_raw=0.4037, running_loss=0.4068, LR=0.000100
[2025-08-27 13:03:26,454][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070040] [Batch 02280/03080] [00:27:54/00:09:47, 0.734s/it]: train_loss_raw=0.3741, running_loss=0.4049, LR=0.000100
[2025-08-27 13:03:32,429][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070048] [Batch 02288/03080] [00:28:00/00:09:41, 0.734s/it]: train_loss_raw=0.3751, running_loss=0.4061, LR=0.000100
[2025-08-27 13:03:38,384][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070056] [Batch 02296/03080] [00:28:06/00:09:35, 0.734s/it]: train_loss_raw=0.4775, running_loss=0.4085, LR=0.000100
[2025-08-27 13:03:44,342][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070064] [Batch 02304/03080] [00:28:12/00:09:29, 0.734s/it]: train_loss_raw=0.3803, running_loss=0.4090, LR=0.000100
[2025-08-27 13:03:49,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070072] [Batch 02312/03080] [00:28:17/00:09:23, 0.734s/it]: train_loss_raw=0.4609, running_loss=0.4071, LR=0.000100
[2025-08-27 13:03:55,343][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070080] [Batch 02320/03080] [00:28:23/00:09:17, 0.734s/it]: train_loss_raw=0.3839, running_loss=0.4053, LR=0.000100
[2025-08-27 13:04:01,034][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070088] [Batch 02328/03080] [00:28:28/00:09:12, 0.734s/it]: train_loss_raw=0.4648, running_loss=0.4064, LR=0.000100
[2025-08-27 13:04:06,850][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070096] [Batch 02336/03080] [00:28:34/00:09:06, 0.734s/it]: train_loss_raw=0.3904, running_loss=0.4054, LR=0.000100
[2025-08-27 13:04:12,771][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070104] [Batch 02344/03080] [00:28:40/00:09:00, 0.734s/it]: train_loss_raw=0.3979, running_loss=0.4042, LR=0.000100
[2025-08-27 13:04:18,294][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070112] [Batch 02352/03080] [00:28:46/00:08:54, 0.734s/it]: train_loss_raw=0.5098, running_loss=0.4063, LR=0.000100
[2025-08-27 13:04:24,153][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070120] [Batch 02360/03080] [00:28:52/00:08:48, 0.734s/it]: train_loss_raw=0.4352, running_loss=0.4057, LR=0.000100
[2025-08-27 13:04:30,006][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070128] [Batch 02368/03080] [00:28:57/00:08:42, 0.734s/it]: train_loss_raw=0.4004, running_loss=0.4073, LR=0.000100
[2025-08-27 13:04:36,010][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070136] [Batch 02376/03080] [00:29:03/00:08:36, 0.734s/it]: train_loss_raw=0.3749, running_loss=0.4064, LR=0.000100
[2025-08-27 13:04:41,975][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070144] [Batch 02384/03080] [00:29:09/00:08:30, 0.734s/it]: train_loss_raw=0.4230, running_loss=0.4072, LR=0.000100
[2025-08-27 13:04:47,922][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070152] [Batch 02392/03080] [00:29:15/00:08:25, 0.734s/it]: train_loss_raw=0.3889, running_loss=0.4063, LR=0.000100
[2025-08-27 13:04:53,748][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070160] [Batch 02400/03080] [00:29:21/00:08:19, 0.734s/it]: train_loss_raw=0.4245, running_loss=0.4059, LR=0.000100
[2025-08-27 13:04:59,793][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070168] [Batch 02408/03080] [00:29:27/00:08:13, 0.734s/it]: train_loss_raw=0.4279, running_loss=0.4050, LR=0.000100
[2025-08-27 13:05:05,795][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070176] [Batch 02416/03080] [00:29:33/00:08:07, 0.734s/it]: train_loss_raw=0.4522, running_loss=0.4054, LR=0.000100
[2025-08-27 13:05:11,777][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070184] [Batch 02424/03080] [00:29:39/00:08:01, 0.734s/it]: train_loss_raw=0.3456, running_loss=0.4056, LR=0.000100
[2025-08-27 13:05:17,808][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070192] [Batch 02432/03080] [00:29:45/00:07:55, 0.734s/it]: train_loss_raw=0.3883, running_loss=0.4061, LR=0.000100
[2025-08-27 13:05:23,793][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070200] [Batch 02440/03080] [00:29:51/00:07:49, 0.734s/it]: train_loss_raw=0.4231, running_loss=0.4065, LR=0.000100
[2025-08-27 13:05:29,701][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070208] [Batch 02448/03080] [00:29:57/00:07:44, 0.734s/it]: train_loss_raw=0.4152, running_loss=0.4043, LR=0.000100
[2025-08-27 13:05:35,120][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070216] [Batch 02456/03080] [00:30:02/00:07:38, 0.734s/it]: train_loss_raw=0.4439, running_loss=0.4032, LR=0.000100
[2025-08-27 13:05:40,714][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070224] [Batch 02464/03080] [00:30:08/00:07:32, 0.734s/it]: train_loss_raw=0.3509, running_loss=0.4010, LR=0.000100
[2025-08-27 13:05:46,341][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070232] [Batch 02472/03080] [00:30:14/00:07:26, 0.734s/it]: train_loss_raw=0.4439, running_loss=0.4008, LR=0.000100
[2025-08-27 13:05:51,739][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070240] [Batch 02480/03080] [00:30:19/00:07:20, 0.734s/it]: train_loss_raw=0.4136, running_loss=0.4022, LR=0.000100
[2025-08-27 13:05:57,569][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070248] [Batch 02488/03080] [00:30:25/00:07:14, 0.734s/it]: train_loss_raw=0.4181, running_loss=0.4015, LR=0.000100
[2025-08-27 13:06:03,662][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070256] [Batch 02496/03080] [00:30:31/00:07:08, 0.734s/it]: train_loss_raw=0.3471, running_loss=0.4002, LR=0.000100
[2025-08-27 13:06:09,636][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070264] [Batch 02504/03080] [00:30:37/00:07:02, 0.734s/it]: train_loss_raw=0.4917, running_loss=0.4014, LR=0.000100
[2025-08-27 13:06:15,816][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070272] [Batch 02512/03080] [00:30:43/00:06:56, 0.734s/it]: train_loss_raw=0.3462, running_loss=0.4007, LR=0.000100
[2025-08-27 13:06:21,725][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070280] [Batch 02520/03080] [00:30:49/00:06:51, 0.734s/it]: train_loss_raw=0.5365, running_loss=0.4031, LR=0.000100
[2025-08-27 13:06:27,856][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070288] [Batch 02528/03080] [00:30:55/00:06:45, 0.734s/it]: train_loss_raw=0.4598, running_loss=0.4051, LR=0.000100
[2025-08-27 13:06:33,857][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070296] [Batch 02536/03080] [00:31:01/00:06:39, 0.734s/it]: train_loss_raw=0.3593, running_loss=0.4042, LR=0.000100
[2025-08-27 13:06:39,858][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070304] [Batch 02544/03080] [00:31:07/00:06:33, 0.734s/it]: train_loss_raw=0.3449, running_loss=0.4038, LR=0.000100
[2025-08-27 13:06:45,927][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070312] [Batch 02552/03080] [00:31:13/00:06:27, 0.734s/it]: train_loss_raw=0.3977, running_loss=0.4046, LR=0.000100
[2025-08-27 13:06:51,954][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070320] [Batch 02560/03080] [00:31:19/00:06:21, 0.734s/it]: train_loss_raw=0.2783, running_loss=0.4008, LR=0.000100
[2025-08-27 13:06:57,911][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070328] [Batch 02568/03080] [00:31:25/00:06:15, 0.734s/it]: train_loss_raw=0.4282, running_loss=0.4012, LR=0.000100
[2025-08-27 13:07:03,900][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070336] [Batch 02576/03080] [00:31:31/00:06:10, 0.734s/it]: train_loss_raw=0.3708, running_loss=0.4023, LR=0.000100
[2025-08-27 13:07:09,903][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070344] [Batch 02584/03080] [00:31:37/00:06:04, 0.734s/it]: train_loss_raw=0.4078, running_loss=0.4016, LR=0.000100
[2025-08-27 13:07:15,903][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070352] [Batch 02592/03080] [00:31:43/00:05:58, 0.734s/it]: train_loss_raw=0.3774, running_loss=0.4003, LR=0.000100
[2025-08-27 13:07:21,947][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070360] [Batch 02600/03080] [00:31:49/00:05:52, 0.735s/it]: train_loss_raw=0.3710, running_loss=0.3986, LR=0.000100
[2025-08-27 13:07:27,879][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070368] [Batch 02608/03080] [00:31:55/00:05:46, 0.735s/it]: train_loss_raw=0.3463, running_loss=0.3982, LR=0.000100
[2025-08-27 13:07:33,884][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070376] [Batch 02616/03080] [00:32:01/00:05:40, 0.735s/it]: train_loss_raw=0.4620, running_loss=0.4021, LR=0.000100
[2025-08-27 13:07:39,867][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070384] [Batch 02624/03080] [00:32:07/00:05:35, 0.735s/it]: train_loss_raw=0.4253, running_loss=0.4017, LR=0.000100
[2025-08-27 13:07:45,895][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070392] [Batch 02632/03080] [00:32:13/00:05:29, 0.735s/it]: train_loss_raw=0.4189, running_loss=0.4027, LR=0.000100
[2025-08-27 13:07:52,040][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070400] [Batch 02640/03080] [00:32:19/00:05:23, 0.735s/it]: train_loss_raw=0.3041, running_loss=0.4036, LR=0.000100
[2025-08-27 13:07:58,071][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070408] [Batch 02648/03080] [00:32:25/00:05:17, 0.735s/it]: train_loss_raw=0.3468, running_loss=0.4033, LR=0.000100
[2025-08-27 13:08:04,022][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070416] [Batch 02656/03080] [00:32:31/00:05:11, 0.735s/it]: train_loss_raw=0.4086, running_loss=0.4024, LR=0.000100
[2025-08-27 13:08:10,041][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070424] [Batch 02664/03080] [00:32:37/00:05:05, 0.735s/it]: train_loss_raw=0.3582, running_loss=0.4031, LR=0.000100
[2025-08-27 13:08:16,029][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070432] [Batch 02672/03080] [00:32:43/00:04:59, 0.735s/it]: train_loss_raw=0.4321, running_loss=0.4041, LR=0.000100
[2025-08-27 13:08:22,071][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070440] [Batch 02680/03080] [00:32:49/00:04:54, 0.735s/it]: train_loss_raw=0.4107, running_loss=0.4038, LR=0.000100
[2025-08-27 13:08:27,689][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070448] [Batch 02688/03080] [00:32:55/00:04:48, 0.735s/it]: train_loss_raw=0.4698, running_loss=0.4040, LR=0.000100
[2025-08-27 13:08:33,352][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070456] [Batch 02696/03080] [00:33:01/00:04:42, 0.735s/it]: train_loss_raw=0.3576, running_loss=0.4022, LR=0.000100
[2025-08-27 13:08:39,336][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070464] [Batch 02704/03080] [00:33:07/00:04:36, 0.735s/it]: train_loss_raw=0.3577, running_loss=0.4018, LR=0.000100
[2025-08-27 13:08:45,332][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070472] [Batch 02712/03080] [00:33:13/00:04:30, 0.735s/it]: train_loss_raw=0.4527, running_loss=0.4006, LR=0.000100
[2025-08-27 13:08:51,314][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070480] [Batch 02720/03080] [00:33:19/00:04:24, 0.735s/it]: train_loss_raw=0.3918, running_loss=0.3997, LR=0.000100
[2025-08-27 13:08:57,328][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070488] [Batch 02728/03080] [00:33:25/00:04:18, 0.735s/it]: train_loss_raw=0.4911, running_loss=0.4014, LR=0.000100
[2025-08-27 13:09:03,488][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070496] [Batch 02736/03080] [00:33:31/00:04:12, 0.735s/it]: train_loss_raw=0.4493, running_loss=0.4019, LR=0.000100
[2025-08-27 13:09:09,503][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070504] [Batch 02744/03080] [00:33:37/00:04:07, 0.735s/it]: train_loss_raw=0.3439, running_loss=0.4019, LR=0.000100
[2025-08-27 13:09:15,547][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070512] [Batch 02752/03080] [00:33:43/00:04:01, 0.735s/it]: train_loss_raw=0.3607, running_loss=0.4032, LR=0.000100
[2025-08-27 13:09:21,489][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070520] [Batch 02760/03080] [00:33:49/00:03:55, 0.735s/it]: train_loss_raw=0.4966, running_loss=0.4058, LR=0.000100
[2025-08-27 13:09:27,510][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070528] [Batch 02768/03080] [00:33:55/00:03:49, 0.735s/it]: train_loss_raw=0.3441, running_loss=0.4055, LR=0.000100
[2025-08-27 13:09:33,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070536] [Batch 02776/03080] [00:34:01/00:03:43, 0.735s/it]: train_loss_raw=0.3237, running_loss=0.4026, LR=0.000100
[2025-08-27 13:09:39,398][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070544] [Batch 02784/03080] [00:34:07/00:03:37, 0.735s/it]: train_loss_raw=0.3385, running_loss=0.4022, LR=0.000100
[2025-08-27 13:09:45,391][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070552] [Batch 02792/03080] [00:34:13/00:03:31, 0.735s/it]: train_loss_raw=0.4469, running_loss=0.4019, LR=0.000100
[2025-08-27 13:09:51,470][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070560] [Batch 02800/03080] [00:34:19/00:03:25, 0.735s/it]: train_loss_raw=0.3954, running_loss=0.4026, LR=0.000100
[2025-08-27 13:09:57,353][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070568] [Batch 02808/03080] [00:34:25/00:03:20, 0.735s/it]: train_loss_raw=0.4368, running_loss=0.4007, LR=0.000100
[2025-08-27 13:10:03,399][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070576] [Batch 02816/03080] [00:34:31/00:03:14, 0.736s/it]: train_loss_raw=0.4201, running_loss=0.3987, LR=0.000100
[2025-08-27 13:10:09,462][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070584] [Batch 02824/03080] [00:34:37/00:03:08, 0.736s/it]: train_loss_raw=0.4091, running_loss=0.3986, LR=0.000100
[2025-08-27 13:10:15,587][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070592] [Batch 02832/03080] [00:34:43/00:03:02, 0.736s/it]: train_loss_raw=0.4417, running_loss=0.3992, LR=0.000100
[2025-08-27 13:10:21,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070600] [Batch 02840/03080] [00:34:49/00:02:56, 0.736s/it]: train_loss_raw=0.4400, running_loss=0.4003, LR=0.000100
[2025-08-27 13:10:27,706][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070608] [Batch 02848/03080] [00:34:55/00:02:50, 0.736s/it]: train_loss_raw=0.3900, running_loss=0.4025, LR=0.000100
[2025-08-27 13:10:33,447][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070616] [Batch 02856/03080] [00:35:01/00:02:44, 0.736s/it]: train_loss_raw=0.4412, running_loss=0.4023, LR=0.000100
[2025-08-27 13:10:39,395][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070624] [Batch 02864/03080] [00:35:07/00:02:38, 0.736s/it]: train_loss_raw=0.3799, running_loss=0.4028, LR=0.000100
[2025-08-27 13:10:45,383][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070632] [Batch 02872/03080] [00:35:13/00:02:33, 0.736s/it]: train_loss_raw=0.3985, running_loss=0.4044, LR=0.000100
[2025-08-27 13:10:51,360][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070640] [Batch 02880/03080] [00:35:19/00:02:27, 0.736s/it]: train_loss_raw=0.4092, running_loss=0.4038, LR=0.000100
[2025-08-27 13:10:57,561][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070648] [Batch 02888/03080] [00:35:25/00:02:21, 0.736s/it]: train_loss_raw=0.4271, running_loss=0.4045, LR=0.000100
[2025-08-27 13:11:03,575][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070656] [Batch 02896/03080] [00:35:31/00:02:15, 0.736s/it]: train_loss_raw=0.3743, running_loss=0.4015, LR=0.000100
[2025-08-27 13:11:09,575][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070664] [Batch 02904/03080] [00:35:37/00:02:09, 0.736s/it]: train_loss_raw=0.3381, running_loss=0.3993, LR=0.000100
[2025-08-27 13:11:15,736][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070672] [Batch 02912/03080] [00:35:43/00:02:03, 0.736s/it]: train_loss_raw=0.4813, running_loss=0.4000, LR=0.000100
[2025-08-27 13:11:21,806][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070680] [Batch 02920/03080] [00:35:49/00:01:57, 0.736s/it]: train_loss_raw=0.3490, running_loss=0.3983, LR=0.000100
[2025-08-27 13:11:27,753][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070688] [Batch 02928/03080] [00:35:55/00:01:51, 0.736s/it]: train_loss_raw=0.3733, running_loss=0.3972, LR=0.000100
[2025-08-27 13:11:33,973][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070696] [Batch 02936/03080] [00:36:01/00:01:46, 0.736s/it]: train_loss_raw=0.3667, running_loss=0.3989, LR=0.000100
[2025-08-27 13:11:39,944][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070704] [Batch 02944/03080] [00:36:07/00:01:40, 0.736s/it]: train_loss_raw=0.3334, running_loss=0.3991, LR=0.000100
[2025-08-27 13:11:46,327][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070712] [Batch 02952/03080] [00:36:14/00:01:34, 0.737s/it]: train_loss_raw=0.3405, running_loss=0.3980, LR=0.000100
[2025-08-27 13:11:52,577][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070720] [Batch 02960/03080] [00:36:20/00:01:28, 0.737s/it]: train_loss_raw=0.4699, running_loss=0.3993, LR=0.000100
[2025-08-27 13:11:58,739][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070728] [Batch 02968/03080] [00:36:26/00:01:22, 0.737s/it]: train_loss_raw=0.2838, running_loss=0.3975, LR=0.000100
[2025-08-27 13:12:04,892][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070736] [Batch 02976/03080] [00:36:32/00:01:16, 0.737s/it]: train_loss_raw=0.3767, running_loss=0.3986, LR=0.000100
[2025-08-27 13:12:11,034][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070744] [Batch 02984/03080] [00:36:38/00:01:10, 0.737s/it]: train_loss_raw=0.4715, running_loss=0.3985, LR=0.000100
[2025-08-27 13:12:17,038][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070752] [Batch 02992/03080] [00:36:44/00:01:04, 0.737s/it]: train_loss_raw=0.4474, running_loss=0.3988, LR=0.000100
[2025-08-27 13:12:23,053][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070760] [Batch 03000/03080] [00:36:50/00:00:58, 0.737s/it]: train_loss_raw=0.3561, running_loss=0.3988, LR=0.000100
[2025-08-27 13:12:29,035][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070768] [Batch 03008/03080] [00:36:56/00:00:53, 0.737s/it]: train_loss_raw=0.3682, running_loss=0.4005, LR=0.000100
[2025-08-27 13:12:35,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070776] [Batch 03016/03080] [00:37:02/00:00:47, 0.737s/it]: train_loss_raw=0.3464, running_loss=0.4004, LR=0.000100
[2025-08-27 13:12:41,008][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070784] [Batch 03024/03080] [00:37:08/00:00:41, 0.737s/it]: train_loss_raw=0.3997, running_loss=0.4006, LR=0.000100
[2025-08-27 13:12:47,201][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070792] [Batch 03032/03080] [00:37:15/00:00:35, 0.737s/it]: train_loss_raw=0.4003, running_loss=0.4001, LR=0.000100
[2025-08-27 13:12:53,298][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070800] [Batch 03040/03080] [00:37:21/00:00:29, 0.737s/it]: train_loss_raw=0.3977, running_loss=0.4003, LR=0.000100
[2025-08-27 13:12:59,368][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070808] [Batch 03048/03080] [00:37:27/00:00:23, 0.737s/it]: train_loss_raw=0.4103, running_loss=0.4009, LR=0.000100
[2025-08-27 13:13:05,332][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070816] [Batch 03056/03080] [00:37:33/00:00:17, 0.737s/it]: train_loss_raw=0.3276, running_loss=0.4007, LR=0.000100
[2025-08-27 13:13:10,760][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070824] [Batch 03064/03080] [00:37:38/00:00:11, 0.737s/it]: train_loss_raw=0.5041, running_loss=0.4011, LR=0.000100
[2025-08-27 13:13:16,220][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070832] [Batch 03072/03080] [00:37:44/00:00:05, 0.737s/it]: train_loss_raw=0.4906, running_loss=0.4021, LR=0.000100
[2025-08-27 13:13:22,333][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070840] [Batch 03080/03080] [00:37:50/00:00:00, 0.737s/it]: train_loss_raw=0.3878, running_loss=0.4022, LR=0.000100
[2025-08-27 13:13:22,872][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-27 13:13:33,803][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00007/00310] [00:00:10/00:06:52, 1.366s/it]
[2025-08-27 13:13:45,703][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00015/00310] [00:00:22/00:06:59, 1.427s/it]
[2025-08-27 13:13:58,066][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00023/00310] [00:00:35/00:06:59, 1.466s/it]
[2025-08-27 13:14:09,587][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00031/00310] [00:00:46/00:06:45, 1.460s/it]
[2025-08-27 13:14:22,091][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00039/00310] [00:00:59/00:06:39, 1.480s/it]
[2025-08-27 13:14:33,803][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00047/00310] [00:01:10/00:06:27, 1.478s/it]
[2025-08-27 13:14:44,751][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00055/00310] [00:01:21/00:06:11, 1.462s/it]
[2025-08-27 13:14:56,949][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00063/00310] [00:01:34/00:06:01, 1.470s/it]
[2025-08-27 13:15:08,757][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00071/00310] [00:01:45/00:05:50, 1.471s/it]
[2025-08-27 13:15:19,844][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00079/00310] [00:01:56/00:05:36, 1.462s/it]
[2025-08-27 13:15:32,153][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00087/00310] [00:02:09/00:05:26, 1.469s/it]
[2025-08-27 13:15:43,273][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00095/00310] [00:02:20/00:05:12, 1.463s/it]
[2025-08-27 13:15:54,999][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00103/00310] [00:02:32/00:05:01, 1.463s/it]
[2025-08-27 13:16:07,327][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00111/00310] [00:02:44/00:04:50, 1.468s/it]
[2025-08-27 13:16:19,994][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00119/00310] [00:02:57/00:04:40, 1.476s/it]
[2025-08-27 13:16:31,917][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00127/00310] [00:03:09/00:04:28, 1.477s/it]
[2025-08-27 13:16:43,544][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00135/00310] [00:03:20/00:04:16, 1.476s/it]
[2025-08-27 13:16:55,744][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00143/00310] [00:03:32/00:04:05, 1.478s/it]
[2025-08-27 13:17:07,166][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00151/00310] [00:03:44/00:03:53, 1.476s/it]
[2025-08-27 13:17:18,223][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00159/00310] [00:03:55/00:03:40, 1.471s/it]
[2025-08-27 13:17:29,231][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00167/00310] [00:04:06/00:03:28, 1.466s/it]
[2025-08-27 13:17:38,055][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00175/00310] [00:04:15/00:03:14, 1.450s/it]
[2025-08-27 13:17:46,751][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00183/00310] [00:04:23/00:03:00, 1.434s/it]
[2025-08-27 13:17:56,705][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00191/00310] [00:04:33/00:02:48, 1.426s/it]
[2025-08-27 13:18:08,368][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00199/00310] [00:04:45/00:02:37, 1.427s/it]
[2025-08-27 13:18:19,752][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00207/00310] [00:04:56/00:02:25, 1.427s/it]
[2025-08-27 13:18:30,317][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00215/00310] [00:05:07/00:02:13, 1.423s/it]
[2025-08-27 13:18:41,826][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00223/00310] [00:05:18/00:02:02, 1.424s/it]
[2025-08-27 13:18:52,891][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00231/00310] [00:05:30/00:01:50, 1.422s/it]
[2025-08-27 13:19:04,047][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00239/00310] [00:05:41/00:01:39, 1.422s/it]
[2025-08-27 13:19:15,708][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00247/00310] [00:05:52/00:01:28, 1.423s/it]
[2025-08-27 13:19:27,813][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00255/00310] [00:06:04/00:01:16, 1.426s/it]
[2025-08-27 13:19:38,990][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00263/00310] [00:06:16/00:01:05, 1.425s/it]
[2025-08-27 13:19:49,343][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00271/00310] [00:06:26/00:00:53, 1.421s/it]
[2025-08-27 13:20:01,123][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00279/00310] [00:06:38/00:00:42, 1.422s/it]
[2025-08-27 13:20:11,914][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00287/00310] [00:06:49/00:00:31, 1.420s/it]
[2025-08-27 13:20:22,867][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00295/00310] [00:06:59/00:00:19, 1.419s/it]
[2025-08-27 13:20:34,876][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00303/00310] [00:07:12/00:00:08, 1.421s/it]
[2025-08-27 13:20:43,802][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=0.40223, valid_loss=1.44089
[2025-08-27 13:20:43,802][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-27 13:20:43,802][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.495
[2025-08-27 13:20:43,802][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.142
[2025-08-27 13:20:43,802][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.144
[2025-08-27 13:20:43,803][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.076
[2025-08-27 13:20:43,816][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 17:53:57, remaining time 05:26:51, 00:46:41 per epoch
[2025-08-27 13:21:02,382][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070848] [Batch 00008/03080] [00:00:18/01:56:29, 2.275s/it]: train_loss_raw=0.3561, running_loss=0.3722, LR=0.000100
[2025-08-27 13:21:08,407][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070856] [Batch 00016/03080] [00:00:24/01:17:19, 1.514s/it]: train_loss_raw=0.4473, running_loss=0.3748, LR=0.000100
[2025-08-27 13:21:14,456][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070864] [Batch 00024/03080] [00:00:30/01:04:15, 1.262s/it]: train_loss_raw=0.4109, running_loss=0.3768, LR=0.000100
[2025-08-27 13:21:20,471][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070872] [Batch 00032/03080] [00:00:36/00:57:36, 1.134s/it]: train_loss_raw=0.4392, running_loss=0.3792, LR=0.000100
[2025-08-27 13:21:26,446][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070880] [Batch 00040/03080] [00:00:42/00:53:32, 1.057s/it]: train_loss_raw=0.3770, running_loss=0.3813, LR=0.000100
[2025-08-27 13:21:32,421][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070888] [Batch 00048/03080] [00:00:48/00:50:47, 1.005s/it]: train_loss_raw=0.4022, running_loss=0.3825, LR=0.000100
[2025-08-27 13:21:38,448][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070896] [Batch 00056/03080] [00:00:54/00:48:50, 0.969s/it]: train_loss_raw=0.3948, running_loss=0.3824, LR=0.000100
[2025-08-27 13:21:44,465][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070904] [Batch 00064/03080] [00:01:00/00:47:20, 0.942s/it]: train_loss_raw=0.4152, running_loss=0.3835, LR=0.000100
[2025-08-27 13:21:50,477][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070912] [Batch 00072/03080] [00:01:06/00:46:09, 0.921s/it]: train_loss_raw=0.3800, running_loss=0.3849, LR=0.000100
[2025-08-27 13:21:56,461][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070920] [Batch 00080/03080] [00:01:12/00:45:10, 0.904s/it]: train_loss_raw=0.4489, running_loss=0.3862, LR=0.000100
[2025-08-27 13:22:02,468][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070928] [Batch 00088/03080] [00:01:18/00:44:21, 0.890s/it]: train_loss_raw=0.4988, running_loss=0.3870, LR=0.000100
[2025-08-27 13:22:08,511][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070936] [Batch 00096/03080] [00:01:24/00:43:41, 0.878s/it]: train_loss_raw=0.3871, running_loss=0.3885, LR=0.000100
[2025-08-27 13:22:14,008][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070944] [Batch 00104/03080] [00:01:29/00:42:50, 0.864s/it]: train_loss_raw=0.3383, running_loss=0.3893, LR=0.000100
[2025-08-27 13:22:19,425][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070952] [Batch 00112/03080] [00:01:35/00:42:04, 0.850s/it]: train_loss_raw=0.3886, running_loss=0.3888, LR=0.000100
[2025-08-27 13:22:25,404][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070960] [Batch 00120/03080] [00:01:41/00:41:36, 0.844s/it]: train_loss_raw=0.4390, running_loss=0.3914, LR=0.000100
[2025-08-27 13:22:30,854][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070968] [Batch 00128/03080] [00:01:46/00:41:00, 0.833s/it]: train_loss_raw=0.4015, running_loss=0.3908, LR=0.000100
[2025-08-27 13:22:36,777][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070976] [Batch 00136/03080] [00:01:52/00:40:37, 0.828s/it]: train_loss_raw=0.4320, running_loss=0.3919, LR=0.000100
[2025-08-27 13:22:42,780][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070984] [Batch 00144/03080] [00:01:58/00:40:18, 0.824s/it]: train_loss_raw=0.3499, running_loss=0.3898, LR=0.000100
[2025-08-27 13:22:48,944][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070992] [Batch 00152/03080] [00:02:04/00:40:03, 0.821s/it]: train_loss_raw=0.4725, running_loss=0.3912, LR=0.000100
[2025-08-27 13:22:54,940][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071000] [Batch 00160/03080] [00:02:10/00:39:46, 0.817s/it]: train_loss_raw=0.4319, running_loss=0.3945, LR=0.000100
[2025-08-27 13:23:00,986][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071008] [Batch 00168/03080] [00:02:16/00:39:31, 0.814s/it]: train_loss_raw=0.3775, running_loss=0.3960, LR=0.000100
[2025-08-27 13:23:06,582][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071016] [Batch 00176/03080] [00:02:22/00:39:09, 0.809s/it]: train_loss_raw=0.4202, running_loss=0.3961, LR=0.000100
[2025-08-27 13:23:12,501][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071024] [Batch 00184/03080] [00:02:28/00:38:54, 0.806s/it]: train_loss_raw=0.4088, running_loss=0.3961, LR=0.000100
[2025-08-27 13:23:18,497][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071032] [Batch 00192/03080] [00:02:34/00:38:41, 0.804s/it]: train_loss_raw=0.3531, running_loss=0.3948, LR=0.000100
[2025-08-27 13:23:24,447][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071040] [Batch 00200/03080] [00:02:40/00:38:27, 0.801s/it]: train_loss_raw=0.4851, running_loss=0.3950, LR=0.000100
[2025-08-27 13:23:30,412][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071048] [Batch 00208/03080] [00:02:46/00:38:15, 0.799s/it]: train_loss_raw=0.4283, running_loss=0.3968, LR=0.000100
[2025-08-27 13:23:36,507][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071056] [Batch 00216/03080] [00:02:52/00:38:04, 0.798s/it]: train_loss_raw=0.4156, running_loss=0.3970, LR=0.000100
[2025-08-27 13:23:42,433][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071064] [Batch 00224/03080] [00:02:58/00:37:52, 0.796s/it]: train_loss_raw=0.4328, running_loss=0.3986, LR=0.000100
[2025-08-27 13:23:48,508][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071072] [Batch 00232/03080] [00:03:04/00:37:42, 0.795s/it]: train_loss_raw=0.3597, running_loss=0.3994, LR=0.000100
[2025-08-27 13:23:54,557][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071080] [Batch 00240/03080] [00:03:10/00:37:32, 0.793s/it]: train_loss_raw=0.4513, running_loss=0.4014, LR=0.000100
[2025-08-27 13:24:00,610][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071088] [Batch 00248/03080] [00:03:16/00:37:23, 0.792s/it]: train_loss_raw=0.4337, running_loss=0.4026, LR=0.000100
[2025-08-27 13:24:06,624][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071096] [Batch 00256/03080] [00:03:22/00:37:13, 0.791s/it]: train_loss_raw=0.3946, running_loss=0.4008, LR=0.000100
[2025-08-27 13:24:12,613][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071104] [Batch 00264/03080] [00:03:28/00:37:03, 0.790s/it]: train_loss_raw=0.4746, running_loss=0.3995, LR=0.000100
[2025-08-27 13:24:18,710][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071112] [Batch 00272/03080] [00:03:34/00:36:54, 0.789s/it]: train_loss_raw=0.3647, running_loss=0.3991, LR=0.000100
[2025-08-27 13:24:24,674][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071120] [Batch 00280/03080] [00:03:40/00:36:44, 0.787s/it]: train_loss_raw=0.3707, running_loss=0.3990, LR=0.000100
[2025-08-27 13:24:30,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071128] [Batch 00288/03080] [00:03:46/00:36:36, 0.787s/it]: train_loss_raw=0.4019, running_loss=0.3973, LR=0.000100
[2025-08-27 13:24:36,820][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071136] [Batch 00296/03080] [00:03:52/00:36:28, 0.786s/it]: train_loss_raw=0.3470, running_loss=0.3983, LR=0.000100
[2025-08-27 13:24:42,795][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071144] [Batch 00304/03080] [00:03:58/00:36:18, 0.785s/it]: train_loss_raw=0.3589, running_loss=0.3981, LR=0.000100
[2025-08-27 13:24:49,132][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071152] [Batch 00312/03080] [00:04:04/00:36:13, 0.785s/it]: train_loss_raw=0.3385, running_loss=0.3987, LR=0.000100
[2025-08-27 13:24:55,061][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071160] [Batch 00320/03080] [00:04:10/00:36:03, 0.784s/it]: train_loss_raw=0.4300, running_loss=0.4017, LR=0.000100
[2025-08-27 13:25:01,048][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071168] [Batch 00328/03080] [00:04:16/00:35:55, 0.783s/it]: train_loss_raw=0.4357, running_loss=0.4029, LR=0.000100
[2025-08-27 13:25:07,060][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071176] [Batch 00336/03080] [00:04:22/00:35:46, 0.782s/it]: train_loss_raw=0.4206, running_loss=0.4039, LR=0.000100
[2025-08-27 13:25:12,882][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071184] [Batch 00344/03080] [00:04:28/00:35:37, 0.781s/it]: train_loss_raw=0.4704, running_loss=0.4034, LR=0.000100
[2025-08-27 13:25:18,983][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071192] [Batch 00352/03080] [00:04:34/00:35:29, 0.781s/it]: train_loss_raw=0.4566, running_loss=0.4042, LR=0.000100
[2025-08-27 13:25:25,137][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071200] [Batch 00360/03080] [00:04:40/00:35:22, 0.780s/it]: train_loss_raw=0.3198, running_loss=0.4039, LR=0.000100
[2025-08-27 13:25:31,114][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071208] [Batch 00368/03080] [00:04:46/00:35:14, 0.780s/it]: train_loss_raw=0.3577, running_loss=0.4025, LR=0.000100
[2025-08-27 13:25:37,096][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071216] [Batch 00376/03080] [00:04:52/00:35:06, 0.779s/it]: train_loss_raw=0.4054, running_loss=0.4030, LR=0.000100
[2025-08-27 13:25:43,122][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071224] [Batch 00384/03080] [00:04:58/00:34:58, 0.778s/it]: train_loss_raw=0.4028, running_loss=0.4023, LR=0.000100
[2025-08-27 13:25:49,130][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071232] [Batch 00392/03080] [00:05:04/00:34:51, 0.778s/it]: train_loss_raw=0.3316, running_loss=0.4019, LR=0.000100
[2025-08-27 13:25:55,148][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071240] [Batch 00400/03080] [00:05:10/00:34:43, 0.777s/it]: train_loss_raw=0.3807, running_loss=0.4019, LR=0.000100
[2025-08-27 13:26:01,218][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071248] [Batch 00408/03080] [00:05:17/00:34:36, 0.777s/it]: train_loss_raw=0.4421, running_loss=0.4009, LR=0.000100
[2025-08-27 13:26:07,218][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071256] [Batch 00416/03080] [00:05:23/00:34:28, 0.777s/it]: train_loss_raw=0.3309, running_loss=0.3979, LR=0.000100
[2025-08-27 13:26:13,204][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071264] [Batch 00424/03080] [00:05:29/00:34:21, 0.776s/it]: train_loss_raw=0.4100, running_loss=0.3967, LR=0.000100
[2025-08-27 13:26:19,135][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071272] [Batch 00432/03080] [00:05:34/00:34:13, 0.775s/it]: train_loss_raw=0.3643, running_loss=0.3996, LR=0.000100
[2025-08-27 13:26:24,704][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071280] [Batch 00440/03080] [00:05:40/00:34:03, 0.774s/it]: train_loss_raw=0.4151, running_loss=0.3975, LR=0.000100
[2025-08-27 13:26:30,130][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071288] [Batch 00448/03080] [00:05:45/00:33:52, 0.772s/it]: train_loss_raw=0.5218, running_loss=0.3988, LR=0.000100
[2025-08-27 13:26:36,086][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071296] [Batch 00456/03080] [00:05:51/00:33:45, 0.772s/it]: train_loss_raw=0.4598, running_loss=0.3997, LR=0.000100
[2025-08-27 13:26:42,149][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071304] [Batch 00464/03080] [00:05:57/00:33:38, 0.771s/it]: train_loss_raw=0.3886, running_loss=0.3997, LR=0.000100
[2025-08-27 13:26:48,126][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071312] [Batch 00472/03080] [00:06:03/00:33:30, 0.771s/it]: train_loss_raw=0.4299, running_loss=0.3991, LR=0.000100
[2025-08-27 13:26:54,101][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071320] [Batch 00480/03080] [00:06:09/00:33:23, 0.771s/it]: train_loss_raw=0.4293, running_loss=0.4009, LR=0.000100
[2025-08-27 13:27:00,136][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071328] [Batch 00488/03080] [00:06:15/00:33:16, 0.770s/it]: train_loss_raw=0.3705, running_loss=0.4000, LR=0.000100
[2025-08-27 13:27:06,127][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071336] [Batch 00496/03080] [00:06:21/00:33:09, 0.770s/it]: train_loss_raw=0.4057, running_loss=0.4006, LR=0.000100
[2025-08-27 13:27:12,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071344] [Batch 00504/03080] [00:06:27/00:33:02, 0.770s/it]: train_loss_raw=0.3422, running_loss=0.4005, LR=0.000100
[2025-08-27 13:27:18,111][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071352] [Batch 00512/03080] [00:06:33/00:32:55, 0.769s/it]: train_loss_raw=0.4317, running_loss=0.4018, LR=0.000100
[2025-08-27 13:27:24,189][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071360] [Batch 00520/03080] [00:06:40/00:32:49, 0.769s/it]: train_loss_raw=0.2976, running_loss=0.4020, LR=0.000100
[2025-08-27 13:27:30,159][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071368] [Batch 00528/03080] [00:06:45/00:32:42, 0.769s/it]: train_loss_raw=0.3825, running_loss=0.4022, LR=0.000100
[2025-08-27 13:27:36,142][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071376] [Batch 00536/03080] [00:06:51/00:32:35, 0.769s/it]: train_loss_raw=0.3914, running_loss=0.3991, LR=0.000100
[2025-08-27 13:27:42,167][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071384] [Batch 00544/03080] [00:06:57/00:32:28, 0.768s/it]: train_loss_raw=0.4010, running_loss=0.3983, LR=0.000100
[2025-08-27 13:27:48,351][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071392] [Batch 00552/03080] [00:07:04/00:32:22, 0.768s/it]: train_loss_raw=0.4093, running_loss=0.3993, LR=0.000100
[2025-08-27 13:27:54,421][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071400] [Batch 00560/03080] [00:07:10/00:32:16, 0.768s/it]: train_loss_raw=0.3799, running_loss=0.4005, LR=0.000100
[2025-08-27 13:28:00,416][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071408] [Batch 00568/03080] [00:07:16/00:32:09, 0.768s/it]: train_loss_raw=0.4085, running_loss=0.3996, LR=0.000100
[2025-08-27 13:28:06,419][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071416] [Batch 00576/03080] [00:07:22/00:32:02, 0.768s/it]: train_loss_raw=0.3564, running_loss=0.4000, LR=0.000100
[2025-08-27 13:28:12,427][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071424] [Batch 00584/03080] [00:07:28/00:31:55, 0.768s/it]: train_loss_raw=0.3888, running_loss=0.3988, LR=0.000100
[2025-08-27 13:28:18,564][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071432] [Batch 00592/03080] [00:07:34/00:31:49, 0.768s/it]: train_loss_raw=0.3535, running_loss=0.3974, LR=0.000100
[2025-08-27 13:28:24,494][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071440] [Batch 00600/03080] [00:07:40/00:31:42, 0.767s/it]: train_loss_raw=0.4258, running_loss=0.3988, LR=0.000100
[2025-08-27 13:28:30,572][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071448] [Batch 00608/03080] [00:07:46/00:31:36, 0.767s/it]: train_loss_raw=0.3390, running_loss=0.3973, LR=0.000100
[2025-08-27 13:28:36,515][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071456] [Batch 00616/03080] [00:07:52/00:31:29, 0.767s/it]: train_loss_raw=0.3271, running_loss=0.3976, LR=0.000100
[2025-08-27 13:28:42,290][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071464] [Batch 00624/03080] [00:07:58/00:31:21, 0.766s/it]: train_loss_raw=0.4339, running_loss=0.3965, LR=0.000100
[2025-08-27 13:28:48,286][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071472] [Batch 00632/03080] [00:08:04/00:31:15, 0.766s/it]: train_loss_raw=0.3724, running_loss=0.3981, LR=0.000100
[2025-08-27 13:28:54,395][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071480] [Batch 00640/03080] [00:08:10/00:31:08, 0.766s/it]: train_loss_raw=0.3624, running_loss=0.3986, LR=0.000100
[2025-08-27 13:29:00,451][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071488] [Batch 00648/03080] [00:08:16/00:31:02, 0.766s/it]: train_loss_raw=0.4512, running_loss=0.4002, LR=0.000100
[2025-08-27 13:29:06,521][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071496] [Batch 00656/03080] [00:08:22/00:30:56, 0.766s/it]: train_loss_raw=0.3011, running_loss=0.3998, LR=0.000100
[2025-08-27 13:29:12,578][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071504] [Batch 00664/03080] [00:08:28/00:30:49, 0.766s/it]: train_loss_raw=0.4193, running_loss=0.3999, LR=0.000100
[2025-08-27 13:29:18,636][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071512] [Batch 00672/03080] [00:08:34/00:30:43, 0.766s/it]: train_loss_raw=0.3338, running_loss=0.3985, LR=0.000100
[2025-08-27 13:29:24,710][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071520] [Batch 00680/03080] [00:08:40/00:30:37, 0.765s/it]: train_loss_raw=0.3748, running_loss=0.3991, LR=0.000100
[2025-08-27 13:29:30,737][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071528] [Batch 00688/03080] [00:08:46/00:30:30, 0.765s/it]: train_loss_raw=0.3000, running_loss=0.3998, LR=0.000100
[2025-08-27 13:29:36,793][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071536] [Batch 00696/03080] [00:08:52/00:30:24, 0.765s/it]: train_loss_raw=0.3960, running_loss=0.3993, LR=0.000100
[2025-08-27 13:29:42,806][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071544] [Batch 00704/03080] [00:08:58/00:30:17, 0.765s/it]: train_loss_raw=0.4252, running_loss=0.4021, LR=0.000100
[2025-08-27 13:29:48,959][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071552] [Batch 00712/03080] [00:09:04/00:30:11, 0.765s/it]: train_loss_raw=0.3569, running_loss=0.4006, LR=0.000100
[2025-08-27 13:29:54,900][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071560] [Batch 00720/03080] [00:09:10/00:30:05, 0.765s/it]: train_loss_raw=0.3299, running_loss=0.3993, LR=0.000100
[2025-08-27 13:30:00,960][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071568] [Batch 00728/03080] [00:09:16/00:29:58, 0.765s/it]: train_loss_raw=0.3633, running_loss=0.3984, LR=0.000100
[2025-08-27 13:30:06,985][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071576] [Batch 00736/03080] [00:09:22/00:29:52, 0.765s/it]: train_loss_raw=0.4440, running_loss=0.4006, LR=0.000100
[2025-08-27 13:30:13,017][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071584] [Batch 00744/03080] [00:09:28/00:29:46, 0.765s/it]: train_loss_raw=0.3200, running_loss=0.4002, LR=0.000100
[2025-08-27 13:30:19,104][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071592] [Batch 00752/03080] [00:09:34/00:29:39, 0.765s/it]: train_loss_raw=0.3702, running_loss=0.4004, LR=0.000100
[2025-08-27 13:30:25,135][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071600] [Batch 00760/03080] [00:09:40/00:29:33, 0.764s/it]: train_loss_raw=0.3316, running_loss=0.3980, LR=0.000100
[2025-08-27 13:30:31,210][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071608] [Batch 00768/03080] [00:09:47/00:29:27, 0.764s/it]: train_loss_raw=0.4746, running_loss=0.3989, LR=0.000100
[2025-08-27 13:30:37,226][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071616] [Batch 00776/03080] [00:09:53/00:29:20, 0.764s/it]: train_loss_raw=0.3984, running_loss=0.3974, LR=0.000100
[2025-08-27 13:30:43,329][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071624] [Batch 00784/03080] [00:09:59/00:29:14, 0.764s/it]: train_loss_raw=0.3581, running_loss=0.3977, LR=0.000100
[2025-08-27 13:30:49,547][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071632] [Batch 00792/03080] [00:10:05/00:29:08, 0.764s/it]: train_loss_raw=0.5102, running_loss=0.3977, LR=0.000100
[2025-08-27 13:30:55,479][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071640] [Batch 00800/03080] [00:10:11/00:29:02, 0.764s/it]: train_loss_raw=0.4214, running_loss=0.3965, LR=0.000100
[2025-08-27 13:31:01,467][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071648] [Batch 00808/03080] [00:10:17/00:28:55, 0.764s/it]: train_loss_raw=0.3231, running_loss=0.3988, LR=0.000100
[2025-08-27 13:31:07,650][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071656] [Batch 00816/03080] [00:10:23/00:28:49, 0.764s/it]: train_loss_raw=0.3730, running_loss=0.3995, LR=0.000100
[2025-08-27 13:31:13,615][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071664] [Batch 00824/03080] [00:10:29/00:28:43, 0.764s/it]: train_loss_raw=0.3644, running_loss=0.4002, LR=0.000100
[2025-08-27 13:31:19,639][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071672] [Batch 00832/03080] [00:10:35/00:28:36, 0.764s/it]: train_loss_raw=0.4476, running_loss=0.4018, LR=0.000100
[2025-08-27 13:31:25,788][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071680] [Batch 00840/03080] [00:10:41/00:28:30, 0.764s/it]: train_loss_raw=0.4565, running_loss=0.4032, LR=0.000100
[2025-08-27 13:31:32,042][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071688] [Batch 00848/03080] [00:10:47/00:28:25, 0.764s/it]: train_loss_raw=0.4503, running_loss=0.4013, LR=0.000100
[2025-08-27 13:31:38,004][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071696] [Batch 00856/03080] [00:10:53/00:28:18, 0.764s/it]: train_loss_raw=0.4606, running_loss=0.4026, LR=0.000100
[2025-08-27 13:31:44,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071704] [Batch 00864/03080] [00:10:59/00:28:12, 0.764s/it]: train_loss_raw=0.3458, running_loss=0.4015, LR=0.000100
[2025-08-27 13:31:50,171][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071712] [Batch 00872/03080] [00:11:05/00:28:06, 0.764s/it]: train_loss_raw=0.3355, running_loss=0.4012, LR=0.000100
[2025-08-27 13:31:56,200][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071720] [Batch 00880/03080] [00:11:12/00:28:00, 0.764s/it]: train_loss_raw=0.3939, running_loss=0.4017, LR=0.000100
[2025-08-27 13:32:01,895][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071728] [Batch 00888/03080] [00:11:17/00:27:52, 0.763s/it]: train_loss_raw=0.4805, running_loss=0.4016, LR=0.000100
[2025-08-27 13:32:08,068][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071736] [Batch 00896/03080] [00:11:23/00:27:46, 0.763s/it]: train_loss_raw=0.4972, running_loss=0.4019, LR=0.000100
[2025-08-27 13:32:14,017][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071744] [Batch 00904/03080] [00:11:29/00:27:40, 0.763s/it]: train_loss_raw=0.4461, running_loss=0.4024, LR=0.000100
[2025-08-27 13:32:20,102][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071752] [Batch 00912/03080] [00:11:35/00:27:34, 0.763s/it]: train_loss_raw=0.3979, running_loss=0.4014, LR=0.000100
[2025-08-27 13:32:26,161][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071760] [Batch 00920/03080] [00:11:41/00:27:28, 0.763s/it]: train_loss_raw=0.4264, running_loss=0.4003, LR=0.000100
[2025-08-27 13:32:32,299][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071768] [Batch 00928/03080] [00:11:48/00:27:22, 0.763s/it]: train_loss_raw=0.3333, running_loss=0.3978, LR=0.000100
[2025-08-27 13:32:38,369][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071776] [Batch 00936/03080] [00:11:54/00:27:15, 0.763s/it]: train_loss_raw=0.3904, running_loss=0.3996, LR=0.000100
[2025-08-27 13:32:44,462][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071784] [Batch 00944/03080] [00:12:00/00:27:09, 0.763s/it]: train_loss_raw=0.4541, running_loss=0.4003, LR=0.000100
[2025-08-27 13:32:50,553][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071792] [Batch 00952/03080] [00:12:06/00:27:03, 0.763s/it]: train_loss_raw=0.4345, running_loss=0.4017, LR=0.000100
[2025-08-27 13:32:56,625][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071800] [Batch 00960/03080] [00:12:12/00:26:57, 0.763s/it]: train_loss_raw=0.4333, running_loss=0.3996, LR=0.000100
[2025-08-27 13:33:02,718][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071808] [Batch 00968/03080] [00:12:18/00:26:51, 0.763s/it]: train_loss_raw=0.4188, running_loss=0.4015, LR=0.000100
[2025-08-27 13:33:08,751][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071816] [Batch 00976/03080] [00:12:24/00:26:45, 0.763s/it]: train_loss_raw=0.3598, running_loss=0.4023, LR=0.000100
[2025-08-27 13:33:15,095][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071824] [Batch 00984/03080] [00:12:30/00:26:39, 0.763s/it]: train_loss_raw=0.4192, running_loss=0.4040, LR=0.000100
[2025-08-27 13:33:21,185][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071832] [Batch 00992/03080] [00:12:37/00:26:33, 0.763s/it]: train_loss_raw=0.4063, running_loss=0.4037, LR=0.000100
[2025-08-27 13:33:27,377][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071840] [Batch 01000/03080] [00:12:43/00:26:27, 0.763s/it]: train_loss_raw=0.3669, running_loss=0.4025, LR=0.000100
[2025-08-27 13:33:33,409][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071848] [Batch 01008/03080] [00:12:49/00:26:21, 0.763s/it]: train_loss_raw=0.4896, running_loss=0.4026, LR=0.000100
[2025-08-27 13:33:39,321][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071856] [Batch 01016/03080] [00:12:55/00:26:14, 0.763s/it]: train_loss_raw=0.3471, running_loss=0.4051, LR=0.000100
[2025-08-27 13:33:44,802][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071864] [Batch 01024/03080] [00:13:00/00:26:07, 0.762s/it]: train_loss_raw=0.5197, running_loss=0.4045, LR=0.000100
[2025-08-27 13:33:50,444][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071872] [Batch 01032/03080] [00:13:06/00:26:00, 0.762s/it]: train_loss_raw=0.4166, running_loss=0.4031, LR=0.000100
[2025-08-27 13:33:56,488][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071880] [Batch 01040/03080] [00:13:12/00:25:54, 0.762s/it]: train_loss_raw=0.4076, running_loss=0.4027, LR=0.000100
[2025-08-27 13:34:02,464][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071888] [Batch 01048/03080] [00:13:18/00:25:47, 0.762s/it]: train_loss_raw=0.4243, running_loss=0.4021, LR=0.000100
[2025-08-27 13:34:08,540][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071896] [Batch 01056/03080] [00:13:24/00:25:41, 0.762s/it]: train_loss_raw=0.4242, running_loss=0.4032, LR=0.000100
[2025-08-27 13:34:14,428][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071904] [Batch 01064/03080] [00:13:30/00:25:35, 0.762s/it]: train_loss_raw=0.4332, running_loss=0.4047, LR=0.000100
[2025-08-27 13:34:20,417][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071912] [Batch 01072/03080] [00:13:36/00:25:28, 0.761s/it]: train_loss_raw=0.4281, running_loss=0.4056, LR=0.000100
[2025-08-27 13:34:26,460][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071920] [Batch 01080/03080] [00:13:42/00:25:22, 0.761s/it]: train_loss_raw=0.3555, running_loss=0.4034, LR=0.000100
[2025-08-27 13:34:32,464][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071928] [Batch 01088/03080] [00:13:48/00:25:16, 0.761s/it]: train_loss_raw=0.4002, running_loss=0.4034, LR=0.000100
[2025-08-27 13:34:38,518][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071936] [Batch 01096/03080] [00:13:54/00:25:10, 0.761s/it]: train_loss_raw=0.4655, running_loss=0.4029, LR=0.000100
[2025-08-27 13:34:44,560][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071944] [Batch 01104/03080] [00:14:00/00:25:04, 0.761s/it]: train_loss_raw=0.3402, running_loss=0.4041, LR=0.000100
[2025-08-27 13:34:50,592][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071952] [Batch 01112/03080] [00:14:06/00:24:57, 0.761s/it]: train_loss_raw=0.4506, running_loss=0.4043, LR=0.000100
[2025-08-27 13:34:56,648][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071960] [Batch 01120/03080] [00:14:12/00:24:51, 0.761s/it]: train_loss_raw=0.3403, running_loss=0.4038, LR=0.000100
[2025-08-27 13:35:02,831][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071968] [Batch 01128/03080] [00:14:18/00:24:45, 0.761s/it]: train_loss_raw=0.3978, running_loss=0.4024, LR=0.000100
[2025-08-27 13:35:08,764][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071976] [Batch 01136/03080] [00:14:24/00:24:39, 0.761s/it]: train_loss_raw=0.4131, running_loss=0.4019, LR=0.000100
[2025-08-27 13:35:14,938][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071984] [Batch 01144/03080] [00:14:30/00:24:33, 0.761s/it]: train_loss_raw=0.4256, running_loss=0.4020, LR=0.000100
[2025-08-27 13:35:21,040][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071992] [Batch 01152/03080] [00:14:36/00:24:27, 0.761s/it]: train_loss_raw=0.4163, running_loss=0.4028, LR=0.000100
[2025-08-27 13:35:26,665][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072000] [Batch 01160/03080] [00:14:42/00:24:20, 0.761s/it]: train_loss_raw=0.3735, running_loss=0.4018, LR=0.000100
[2025-08-27 13:35:36,603][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072008] [Batch 01168/03080] [00:14:52/00:24:20, 0.764s/it]: train_loss_raw=0.3570, running_loss=0.4013, LR=0.000100
[2025-08-27 13:35:42,573][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072016] [Batch 01176/03080] [00:14:58/00:24:14, 0.764s/it]: train_loss_raw=0.4504, running_loss=0.4020, LR=0.000100
[2025-08-27 13:35:48,669][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072024] [Batch 01184/03080] [00:15:04/00:24:08, 0.764s/it]: train_loss_raw=0.3994, running_loss=0.4027, LR=0.000100
[2025-08-27 13:35:54,705][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072032] [Batch 01192/03080] [00:15:10/00:24:02, 0.764s/it]: train_loss_raw=0.3392, running_loss=0.4003, LR=0.000100
[2025-08-27 13:36:00,861][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072040] [Batch 01200/03080] [00:15:16/00:23:56, 0.764s/it]: train_loss_raw=0.3484, running_loss=0.3975, LR=0.000100
[2025-08-27 13:36:06,837][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072048] [Batch 01208/03080] [00:15:22/00:23:49, 0.764s/it]: train_loss_raw=0.4138, running_loss=0.3973, LR=0.000100
[2025-08-27 13:36:12,896][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072056] [Batch 01216/03080] [00:15:28/00:23:43, 0.764s/it]: train_loss_raw=0.3619, running_loss=0.3985, LR=0.000100
[2025-08-27 13:36:18,976][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072064] [Batch 01224/03080] [00:15:34/00:23:37, 0.764s/it]: train_loss_raw=0.4222, running_loss=0.3976, LR=0.000100
[2025-08-27 13:36:24,975][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072072] [Batch 01232/03080] [00:15:40/00:23:31, 0.764s/it]: train_loss_raw=0.3921, running_loss=0.3980, LR=0.000100
[2025-08-27 13:36:31,094][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072080] [Batch 01240/03080] [00:15:46/00:23:25, 0.764s/it]: train_loss_raw=0.3461, running_loss=0.3990, LR=0.000100
[2025-08-27 13:36:37,104][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072088] [Batch 01248/03080] [00:15:52/00:23:18, 0.764s/it]: train_loss_raw=0.4099, running_loss=0.3986, LR=0.000100
[2025-08-27 13:36:43,107][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072096] [Batch 01256/03080] [00:15:58/00:23:12, 0.763s/it]: train_loss_raw=0.4897, running_loss=0.3996, LR=0.000100
[2025-08-27 13:36:49,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072104] [Batch 01264/03080] [00:16:04/00:23:06, 0.763s/it]: train_loss_raw=0.4279, running_loss=0.3985, LR=0.000100
[2025-08-27 13:36:55,185][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072112] [Batch 01272/03080] [00:16:11/00:23:00, 0.763s/it]: train_loss_raw=0.4508, running_loss=0.3983, LR=0.000100
[2025-08-27 13:37:01,288][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072120] [Batch 01280/03080] [00:16:17/00:22:54, 0.763s/it]: train_loss_raw=0.3125, running_loss=0.3976, LR=0.000100
[2025-08-27 13:37:07,355][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072128] [Batch 01288/03080] [00:16:23/00:22:47, 0.763s/it]: train_loss_raw=0.3825, running_loss=0.3965, LR=0.000100
[2025-08-27 13:37:13,347][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072136] [Batch 01296/03080] [00:16:29/00:22:41, 0.763s/it]: train_loss_raw=0.4181, running_loss=0.3971, LR=0.000100
[2025-08-27 13:37:19,350][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072144] [Batch 01304/03080] [00:16:35/00:22:35, 0.763s/it]: train_loss_raw=0.3955, running_loss=0.3980, LR=0.000100
[2025-08-27 13:37:25,152][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072152] [Batch 01312/03080] [00:16:40/00:22:28, 0.763s/it]: train_loss_raw=0.3853, running_loss=0.3993, LR=0.000100
[2025-08-27 13:37:30,829][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072160] [Batch 01320/03080] [00:16:46/00:22:22, 0.763s/it]: train_loss_raw=0.3807, running_loss=0.4008, LR=0.000100
[2025-08-27 13:37:36,663][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072168] [Batch 01328/03080] [00:16:52/00:22:15, 0.762s/it]: train_loss_raw=0.3503, running_loss=0.3988, LR=0.000100
[2025-08-27 13:37:42,700][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072176] [Batch 01336/03080] [00:16:58/00:22:09, 0.762s/it]: train_loss_raw=0.3551, running_loss=0.3982, LR=0.000100
[2025-08-27 13:37:48,676][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072184] [Batch 01344/03080] [00:17:04/00:22:03, 0.762s/it]: train_loss_raw=0.3418, running_loss=0.3976, LR=0.000100
[2025-08-27 13:37:54,118][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072192] [Batch 01352/03080] [00:17:09/00:21:56, 0.762s/it]: train_loss_raw=0.3457, running_loss=0.3973, LR=0.000100
[2025-08-27 13:37:59,628][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072200] [Batch 01360/03080] [00:17:15/00:21:49, 0.761s/it]: train_loss_raw=0.3095, running_loss=0.3950, LR=0.000100
[2025-08-27 13:38:05,217][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072208] [Batch 01368/03080] [00:17:21/00:21:42, 0.761s/it]: train_loss_raw=0.3933, running_loss=0.3960, LR=0.000100
[2025-08-27 13:38:11,110][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072216] [Batch 01376/03080] [00:17:26/00:21:36, 0.761s/it]: train_loss_raw=0.3669, running_loss=0.3968, LR=0.000100
[2025-08-27 13:38:17,112][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072224] [Batch 01384/03080] [00:17:32/00:21:30, 0.761s/it]: train_loss_raw=0.3775, running_loss=0.3935, LR=0.000100
[2025-08-27 13:38:23,098][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072232] [Batch 01392/03080] [00:17:38/00:21:24, 0.761s/it]: train_loss_raw=0.3800, running_loss=0.3945, LR=0.000100
[2025-08-27 13:38:28,695][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072240] [Batch 01400/03080] [00:17:44/00:21:17, 0.760s/it]: train_loss_raw=0.4091, running_loss=0.3957, LR=0.000100
[2025-08-27 13:38:34,146][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072248] [Batch 01408/03080] [00:17:49/00:21:10, 0.760s/it]: train_loss_raw=0.3807, running_loss=0.3977, LR=0.000100
[2025-08-27 13:38:39,628][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072256] [Batch 01416/03080] [00:17:55/00:21:03, 0.759s/it]: train_loss_raw=0.3939, running_loss=0.3971, LR=0.000100
[2025-08-27 13:38:45,160][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072264] [Batch 01424/03080] [00:18:00/00:20:57, 0.759s/it]: train_loss_raw=0.3862, running_loss=0.3958, LR=0.000100
[2025-08-27 13:38:51,165][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072272] [Batch 01432/03080] [00:18:06/00:20:50, 0.759s/it]: train_loss_raw=0.3317, running_loss=0.3942, LR=0.000100
[2025-08-27 13:38:57,250][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072280] [Batch 01440/03080] [00:18:13/00:20:44, 0.759s/it]: train_loss_raw=0.4708, running_loss=0.3955, LR=0.000100
[2025-08-27 13:39:03,397][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072288] [Batch 01448/03080] [00:18:19/00:20:38, 0.759s/it]: train_loss_raw=0.4748, running_loss=0.3974, LR=0.000100
[2025-08-27 13:39:09,676][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072296] [Batch 01456/03080] [00:18:25/00:20:33, 0.759s/it]: train_loss_raw=0.4140, running_loss=0.3964, LR=0.000100
[2025-08-27 13:39:15,778][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072304] [Batch 01464/03080] [00:18:31/00:20:27, 0.759s/it]: train_loss_raw=0.3539, running_loss=0.3957, LR=0.000100
[2025-08-27 13:39:21,778][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072312] [Batch 01472/03080] [00:18:37/00:20:20, 0.759s/it]: train_loss_raw=0.4351, running_loss=0.3977, LR=0.000100
[2025-08-27 13:39:27,182][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072320] [Batch 01480/03080] [00:18:43/00:20:14, 0.759s/it]: train_loss_raw=0.2931, running_loss=0.3982, LR=0.000100
[2025-08-27 13:39:32,588][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072328] [Batch 01488/03080] [00:18:48/00:20:07, 0.758s/it]: train_loss_raw=0.3242, running_loss=0.3959, LR=0.000100
[2025-08-27 13:39:37,993][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072336] [Batch 01496/03080] [00:18:53/00:20:00, 0.758s/it]: train_loss_raw=0.4084, running_loss=0.3973, LR=0.000100
[2025-08-27 13:39:43,530][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072344] [Batch 01504/03080] [00:18:59/00:19:53, 0.758s/it]: train_loss_raw=0.3963, running_loss=0.3969, LR=0.000100
[2025-08-27 13:39:49,535][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072352] [Batch 01512/03080] [00:19:05/00:19:47, 0.758s/it]: train_loss_raw=0.2892, running_loss=0.3972, LR=0.000100
[2025-08-27 13:39:55,490][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072360] [Batch 01520/03080] [00:19:11/00:19:41, 0.757s/it]: train_loss_raw=0.4741, running_loss=0.4005, LR=0.000100
[2025-08-27 13:40:01,555][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072368] [Batch 01528/03080] [00:19:17/00:19:35, 0.757s/it]: train_loss_raw=0.4431, running_loss=0.4004, LR=0.000100
[2025-08-27 13:40:07,639][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072376] [Batch 01536/03080] [00:19:23/00:19:29, 0.757s/it]: train_loss_raw=0.4440, running_loss=0.4020, LR=0.000100
[2025-08-27 13:40:13,690][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072384] [Batch 01544/03080] [00:19:29/00:19:23, 0.757s/it]: train_loss_raw=0.3519, running_loss=0.4017, LR=0.000100
[2025-08-27 13:40:19,711][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072392] [Batch 01552/03080] [00:19:35/00:19:17, 0.757s/it]: train_loss_raw=0.3722, running_loss=0.4002, LR=0.000100
[2025-08-27 13:40:25,956][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072400] [Batch 01560/03080] [00:19:41/00:19:11, 0.758s/it]: train_loss_raw=0.3490, running_loss=0.4018, LR=0.000100
[2025-08-27 13:40:31,973][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072408] [Batch 01568/03080] [00:19:47/00:19:05, 0.758s/it]: train_loss_raw=0.3769, running_loss=0.4008, LR=0.000100
[2025-08-27 13:40:37,921][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072416] [Batch 01576/03080] [00:19:53/00:18:59, 0.757s/it]: train_loss_raw=0.4325, running_loss=0.4013, LR=0.000100
[2025-08-27 13:40:43,517][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072424] [Batch 01584/03080] [00:19:59/00:18:52, 0.757s/it]: train_loss_raw=0.3830, running_loss=0.4020, LR=0.000100
[2025-08-27 13:40:49,598][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072432] [Batch 01592/03080] [00:20:05/00:18:46, 0.757s/it]: train_loss_raw=0.4137, running_loss=0.4010, LR=0.000100
[2025-08-27 13:40:55,598][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072440] [Batch 01600/03080] [00:20:11/00:18:40, 0.757s/it]: train_loss_raw=0.3379, running_loss=0.3997, LR=0.000100
[2025-08-27 13:41:01,694][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072448] [Batch 01608/03080] [00:20:17/00:18:34, 0.757s/it]: train_loss_raw=0.3172, running_loss=0.3975, LR=0.000100
[2025-08-27 13:41:07,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072456] [Batch 01616/03080] [00:20:23/00:18:28, 0.757s/it]: train_loss_raw=0.3541, running_loss=0.3957, LR=0.000100
[2025-08-27 13:41:13,656][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072464] [Batch 01624/03080] [00:20:29/00:18:22, 0.757s/it]: train_loss_raw=0.4491, running_loss=0.3960, LR=0.000100
[2025-08-27 13:41:19,511][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072472] [Batch 01632/03080] [00:20:35/00:18:16, 0.757s/it]: train_loss_raw=0.3472, running_loss=0.3949, LR=0.000100
[2025-08-27 13:41:25,196][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072480] [Batch 01640/03080] [00:20:41/00:18:09, 0.757s/it]: train_loss_raw=0.3808, running_loss=0.3943, LR=0.000100
[2025-08-27 13:41:30,648][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072488] [Batch 01648/03080] [00:20:46/00:18:03, 0.756s/it]: train_loss_raw=0.5117, running_loss=0.3965, LR=0.000100
[2025-08-27 13:41:36,152][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072496] [Batch 01656/03080] [00:20:51/00:17:56, 0.756s/it]: train_loss_raw=0.4119, running_loss=0.3988, LR=0.000100
[2025-08-27 13:41:42,231][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072504] [Batch 01664/03080] [00:20:58/00:17:50, 0.756s/it]: train_loss_raw=0.3985, running_loss=0.3961, LR=0.000100
[2025-08-27 13:41:48,287][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072512] [Batch 01672/03080] [00:21:04/00:17:44, 0.756s/it]: train_loss_raw=0.3673, running_loss=0.3963, LR=0.000100
[2025-08-27 13:41:54,269][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072520] [Batch 01680/03080] [00:21:10/00:17:38, 0.756s/it]: train_loss_raw=0.3478, running_loss=0.3980, LR=0.000100
[2025-08-27 13:42:00,308][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072528] [Batch 01688/03080] [00:21:16/00:17:32, 0.756s/it]: train_loss_raw=0.3725, running_loss=0.3951, LR=0.000100
[2025-08-27 13:42:06,519][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072536] [Batch 01696/03080] [00:21:22/00:17:26, 0.756s/it]: train_loss_raw=0.3909, running_loss=0.3950, LR=0.000100
[2025-08-27 13:42:12,641][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072544] [Batch 01704/03080] [00:21:28/00:17:20, 0.756s/it]: train_loss_raw=0.3200, running_loss=0.3917, LR=0.000100
[2025-08-27 13:42:18,703][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072552] [Batch 01712/03080] [00:21:34/00:17:14, 0.756s/it]: train_loss_raw=0.2732, running_loss=0.3927, LR=0.000100
[2025-08-27 13:42:24,804][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072560] [Batch 01720/03080] [00:21:40/00:17:08, 0.756s/it]: train_loss_raw=0.4198, running_loss=0.3929, LR=0.000100
[2025-08-27 13:42:30,900][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072568] [Batch 01728/03080] [00:21:46/00:17:02, 0.756s/it]: train_loss_raw=0.3241, running_loss=0.3921, LR=0.000100
[2025-08-27 13:42:37,101][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072576] [Batch 01736/03080] [00:21:52/00:16:56, 0.756s/it]: train_loss_raw=0.3633, running_loss=0.3924, LR=0.000100
[2025-08-27 13:42:43,161][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072584] [Batch 01744/03080] [00:21:58/00:16:50, 0.756s/it]: train_loss_raw=0.4356, running_loss=0.3924, LR=0.000100
[2025-08-27 13:42:49,273][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072592] [Batch 01752/03080] [00:22:05/00:16:44, 0.756s/it]: train_loss_raw=0.3606, running_loss=0.3900, LR=0.000100
[2025-08-27 13:42:54,800][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072600] [Batch 01760/03080] [00:22:10/00:16:37, 0.756s/it]: train_loss_raw=0.4728, running_loss=0.3918, LR=0.000100
[2025-08-27 13:43:00,761][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072608] [Batch 01768/03080] [00:22:16/00:16:31, 0.756s/it]: train_loss_raw=0.3347, running_loss=0.3909, LR=0.000100
[2025-08-27 13:43:06,880][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072616] [Batch 01776/03080] [00:22:22/00:16:25, 0.756s/it]: train_loss_raw=0.3833, running_loss=0.3915, LR=0.000100
[2025-08-27 13:43:13,125][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072624] [Batch 01784/03080] [00:22:28/00:16:19, 0.756s/it]: train_loss_raw=0.3754, running_loss=0.3927, LR=0.000100
[2025-08-27 13:43:19,090][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072632] [Batch 01792/03080] [00:22:34/00:16:13, 0.756s/it]: train_loss_raw=0.3785, running_loss=0.3945, LR=0.000100
[2025-08-27 13:43:25,130][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072640] [Batch 01800/03080] [00:22:40/00:16:07, 0.756s/it]: train_loss_raw=0.4139, running_loss=0.3967, LR=0.000100
[2025-08-27 13:43:31,142][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072648] [Batch 01808/03080] [00:22:46/00:16:01, 0.756s/it]: train_loss_raw=0.3940, running_loss=0.3965, LR=0.000100
[2025-08-27 13:43:37,022][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072656] [Batch 01816/03080] [00:22:52/00:15:55, 0.756s/it]: train_loss_raw=0.4101, running_loss=0.3976, LR=0.000100
[2025-08-27 13:43:43,086][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072664] [Batch 01824/03080] [00:22:58/00:15:49, 0.756s/it]: train_loss_raw=0.4629, running_loss=0.3989, LR=0.000100
[2025-08-27 13:43:49,153][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072672] [Batch 01832/03080] [00:23:04/00:15:43, 0.756s/it]: train_loss_raw=0.3937, running_loss=0.3987, LR=0.000100
[2025-08-27 13:43:55,225][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072680] [Batch 01840/03080] [00:23:11/00:15:37, 0.756s/it]: train_loss_raw=0.3936, running_loss=0.4010, LR=0.000100
[2025-08-27 13:44:01,370][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072688] [Batch 01848/03080] [00:23:17/00:15:31, 0.756s/it]: train_loss_raw=0.3644, running_loss=0.4000, LR=0.000100
[2025-08-27 13:44:07,421][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072696] [Batch 01856/03080] [00:23:23/00:15:25, 0.756s/it]: train_loss_raw=0.3814, running_loss=0.3972, LR=0.000100
[2025-08-27 13:44:13,499][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072704] [Batch 01864/03080] [00:23:29/00:15:19, 0.756s/it]: train_loss_raw=0.3628, running_loss=0.3982, LR=0.000100
[2025-08-27 13:44:19,724][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072712] [Batch 01872/03080] [00:23:35/00:15:13, 0.756s/it]: train_loss_raw=0.3263, running_loss=0.3959, LR=0.000100
[2025-08-27 13:44:25,720][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072720] [Batch 01880/03080] [00:23:41/00:15:07, 0.756s/it]: train_loss_raw=0.3257, running_loss=0.3932, LR=0.000100
[2025-08-27 13:44:31,826][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072728] [Batch 01888/03080] [00:23:47/00:15:01, 0.756s/it]: train_loss_raw=0.4139, running_loss=0.3941, LR=0.000100
[2025-08-27 13:44:37,917][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072736] [Batch 01896/03080] [00:23:53/00:14:55, 0.756s/it]: train_loss_raw=0.3889, running_loss=0.3956, LR=0.000100
[2025-08-27 13:44:44,128][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072744] [Batch 01904/03080] [00:23:59/00:14:49, 0.756s/it]: train_loss_raw=0.3282, running_loss=0.3943, LR=0.000100
[2025-08-27 13:44:50,126][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072752] [Batch 01912/03080] [00:24:05/00:14:43, 0.756s/it]: train_loss_raw=0.3945, running_loss=0.3956, LR=0.000100
[2025-08-27 13:44:56,168][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072760] [Batch 01920/03080] [00:24:11/00:14:37, 0.756s/it]: train_loss_raw=0.4410, running_loss=0.3966, LR=0.000100
[2025-08-27 13:45:02,160][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072768] [Batch 01928/03080] [00:24:17/00:14:31, 0.756s/it]: train_loss_raw=0.3819, running_loss=0.3978, LR=0.000100
[2025-08-27 13:45:07,931][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072776] [Batch 01936/03080] [00:24:23/00:14:24, 0.756s/it]: train_loss_raw=0.3860, running_loss=0.3983, LR=0.000100
[2025-08-27 13:45:13,864][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072784] [Batch 01944/03080] [00:24:29/00:14:18, 0.756s/it]: train_loss_raw=0.4341, running_loss=0.3973, LR=0.000100
[2025-08-27 13:45:19,754][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072792] [Batch 01952/03080] [00:24:35/00:14:12, 0.756s/it]: train_loss_raw=0.5295, running_loss=0.3971, LR=0.000100
[2025-08-27 13:45:25,842][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072800] [Batch 01960/03080] [00:24:41/00:14:06, 0.756s/it]: train_loss_raw=0.4052, running_loss=0.3952, LR=0.000100
[2025-08-27 13:45:32,035][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072808] [Batch 01968/03080] [00:24:47/00:14:00, 0.756s/it]: train_loss_raw=0.3633, running_loss=0.3976, LR=0.000100
[2025-08-27 13:45:37,958][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072816] [Batch 01976/03080] [00:24:53/00:13:54, 0.756s/it]: train_loss_raw=0.4204, running_loss=0.3978, LR=0.000100
[2025-08-27 13:45:43,992][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072824] [Batch 01984/03080] [00:24:59/00:13:48, 0.756s/it]: train_loss_raw=0.3357, running_loss=0.3999, LR=0.000100
[2025-08-27 13:45:50,162][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072832] [Batch 01992/03080] [00:25:05/00:13:42, 0.756s/it]: train_loss_raw=0.3391, running_loss=0.3966, LR=0.000100
[2025-08-27 13:45:56,282][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072840] [Batch 02000/03080] [00:25:12/00:13:36, 0.756s/it]: train_loss_raw=0.4373, running_loss=0.3973, LR=0.000100
[2025-08-27 13:46:02,267][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072848] [Batch 02008/03080] [00:25:18/00:13:30, 0.756s/it]: train_loss_raw=0.3887, running_loss=0.3999, LR=0.000100
[2025-08-27 13:46:08,335][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072856] [Batch 02016/03080] [00:25:24/00:13:24, 0.756s/it]: train_loss_raw=0.4429, running_loss=0.3997, LR=0.000100
[2025-08-27 13:46:14,409][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072864] [Batch 02024/03080] [00:25:30/00:13:18, 0.756s/it]: train_loss_raw=0.3494, running_loss=0.3982, LR=0.000100
[2025-08-27 13:46:20,453][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072872] [Batch 02032/03080] [00:25:36/00:13:12, 0.756s/it]: train_loss_raw=0.3856, running_loss=0.3979, LR=0.000100
[2025-08-27 13:46:26,589][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072880] [Batch 02040/03080] [00:25:42/00:13:06, 0.756s/it]: train_loss_raw=0.3491, running_loss=0.3968, LR=0.000100
[2025-08-27 13:46:32,560][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072888] [Batch 02048/03080] [00:25:48/00:13:00, 0.756s/it]: train_loss_raw=0.3856, running_loss=0.3980, LR=0.000100
[2025-08-27 13:46:38,623][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072896] [Batch 02056/03080] [00:25:54/00:12:54, 0.756s/it]: train_loss_raw=0.4139, running_loss=0.3982, LR=0.000100
[2025-08-27 13:46:44,651][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072904] [Batch 02064/03080] [00:26:00/00:12:48, 0.756s/it]: train_loss_raw=0.3402, running_loss=0.3948, LR=0.000100
[2025-08-27 13:46:50,888][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072912] [Batch 02072/03080] [00:26:06/00:12:42, 0.756s/it]: train_loss_raw=0.4088, running_loss=0.3944, LR=0.000100
[2025-08-27 13:46:56,842][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072920] [Batch 02080/03080] [00:26:12/00:12:36, 0.756s/it]: train_loss_raw=0.3902, running_loss=0.3931, LR=0.000100
[2025-08-27 13:47:02,925][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072928] [Batch 02088/03080] [00:26:18/00:12:30, 0.756s/it]: train_loss_raw=0.3779, running_loss=0.3939, LR=0.000100
[2025-08-27 13:47:09,008][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072936] [Batch 02096/03080] [00:26:24/00:12:24, 0.756s/it]: train_loss_raw=0.2755, running_loss=0.3925, LR=0.000100
[2025-08-27 13:47:15,077][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072944] [Batch 02104/03080] [00:26:30/00:12:17, 0.756s/it]: train_loss_raw=0.3979, running_loss=0.3906, LR=0.000100
[2025-08-27 13:47:21,302][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072952] [Batch 02112/03080] [00:26:37/00:12:12, 0.756s/it]: train_loss_raw=0.4296, running_loss=0.3931, LR=0.000100
[2025-08-27 13:47:27,421][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072960] [Batch 02120/03080] [00:26:43/00:12:05, 0.756s/it]: train_loss_raw=0.3135, running_loss=0.3925, LR=0.000100
[2025-08-27 13:47:33,534][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072968] [Batch 02128/03080] [00:26:49/00:11:59, 0.756s/it]: train_loss_raw=0.4147, running_loss=0.3925, LR=0.000100
[2025-08-27 13:47:39,761][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072976] [Batch 02136/03080] [00:26:55/00:11:54, 0.756s/it]: train_loss_raw=0.3196, running_loss=0.3938, LR=0.000100
[2025-08-27 13:47:45,782][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072984] [Batch 02144/03080] [00:27:01/00:11:47, 0.756s/it]: train_loss_raw=0.3500, running_loss=0.3943, LR=0.000100
[2025-08-27 13:47:51,975][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072992] [Batch 02152/03080] [00:27:07/00:11:41, 0.756s/it]: train_loss_raw=0.3589, running_loss=0.3933, LR=0.000100
[2025-08-27 13:47:58,338][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073000] [Batch 02160/03080] [00:27:14/00:11:36, 0.757s/it]: train_loss_raw=0.4649, running_loss=0.3937, LR=0.000100
[2025-08-27 13:48:04,353][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073008] [Batch 02168/03080] [00:27:20/00:11:29, 0.757s/it]: train_loss_raw=0.4176, running_loss=0.3952, LR=0.000100
[2025-08-27 13:48:10,472][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073016] [Batch 02176/03080] [00:27:26/00:11:23, 0.757s/it]: train_loss_raw=0.3083, running_loss=0.3959, LR=0.000100
[2025-08-27 13:48:16,603][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073024] [Batch 02184/03080] [00:27:32/00:11:17, 0.757s/it]: train_loss_raw=0.4574, running_loss=0.3947, LR=0.000100
[2025-08-27 13:48:22,551][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073032] [Batch 02192/03080] [00:27:38/00:11:11, 0.757s/it]: train_loss_raw=0.4217, running_loss=0.3959, LR=0.000100
[2025-08-27 13:48:28,587][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073040] [Batch 02200/03080] [00:27:44/00:11:05, 0.757s/it]: train_loss_raw=0.4008, running_loss=0.3958, LR=0.000100
[2025-08-27 13:48:34,626][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073048] [Batch 02208/03080] [00:27:50/00:10:59, 0.757s/it]: train_loss_raw=0.3746, running_loss=0.3933, LR=0.000100
[2025-08-27 13:48:40,675][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073056] [Batch 02216/03080] [00:27:56/00:10:53, 0.757s/it]: train_loss_raw=0.4407, running_loss=0.3937, LR=0.000100
[2025-08-27 13:48:46,554][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073064] [Batch 02224/03080] [00:28:02/00:10:47, 0.756s/it]: train_loss_raw=0.3920, running_loss=0.3934, LR=0.000100
[2025-08-27 13:48:52,609][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073072] [Batch 02232/03080] [00:28:08/00:10:41, 0.756s/it]: train_loss_raw=0.3874, running_loss=0.3937, LR=0.000100
[2025-08-27 13:48:58,637][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073080] [Batch 02240/03080] [00:28:14/00:10:35, 0.756s/it]: train_loss_raw=0.3864, running_loss=0.3930, LR=0.000100
[2025-08-27 13:49:04,730][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073088] [Batch 02248/03080] [00:28:20/00:10:29, 0.756s/it]: train_loss_raw=0.3971, running_loss=0.3947, LR=0.000100
[2025-08-27 13:49:10,782][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073096] [Batch 02256/03080] [00:28:26/00:10:23, 0.756s/it]: train_loss_raw=0.3938, running_loss=0.3955, LR=0.000100
[2025-08-27 13:49:16,765][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073104] [Batch 02264/03080] [00:28:32/00:10:17, 0.756s/it]: train_loss_raw=0.4545, running_loss=0.3967, LR=0.000100
[2025-08-27 13:49:22,777][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073112] [Batch 02272/03080] [00:28:38/00:10:11, 0.756s/it]: train_loss_raw=0.4130, running_loss=0.3980, LR=0.000100
[2025-08-27 13:49:28,865][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073120] [Batch 02280/03080] [00:28:44/00:10:05, 0.756s/it]: train_loss_raw=0.4004, running_loss=0.3964, LR=0.000100
[2025-08-27 13:49:34,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073128] [Batch 02288/03080] [00:28:50/00:09:59, 0.756s/it]: train_loss_raw=0.3937, running_loss=0.3965, LR=0.000100
[2025-08-27 13:49:40,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073136] [Batch 02296/03080] [00:28:56/00:09:52, 0.756s/it]: train_loss_raw=0.3978, running_loss=0.3961, LR=0.000100
[2025-08-27 13:49:46,748][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073144] [Batch 02304/03080] [00:29:02/00:09:46, 0.756s/it]: train_loss_raw=0.3847, running_loss=0.3946, LR=0.000100
[2025-08-27 13:49:52,773][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073152] [Batch 02312/03080] [00:29:08/00:09:40, 0.756s/it]: train_loss_raw=0.4009, running_loss=0.3928, LR=0.000100
[2025-08-27 13:49:58,940][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073160] [Batch 02320/03080] [00:29:14/00:09:34, 0.756s/it]: train_loss_raw=0.3914, running_loss=0.3913, LR=0.000100
[2025-08-27 13:50:04,989][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073168] [Batch 02328/03080] [00:29:20/00:09:28, 0.756s/it]: train_loss_raw=0.4567, running_loss=0.3938, LR=0.000100
[2025-08-27 13:50:11,132][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073176] [Batch 02336/03080] [00:29:26/00:09:22, 0.756s/it]: train_loss_raw=0.3772, running_loss=0.3946, LR=0.000100
[2025-08-27 13:50:17,230][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073184] [Batch 02344/03080] [00:29:33/00:09:16, 0.756s/it]: train_loss_raw=0.4705, running_loss=0.3945, LR=0.000100
[2025-08-27 13:50:23,260][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073192] [Batch 02352/03080] [00:29:39/00:09:10, 0.756s/it]: train_loss_raw=0.3332, running_loss=0.3931, LR=0.000100
[2025-08-27 13:50:29,295][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073200] [Batch 02360/03080] [00:29:45/00:09:04, 0.756s/it]: train_loss_raw=0.4112, running_loss=0.3946, LR=0.000100
[2025-08-27 13:50:35,345][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073208] [Batch 02368/03080] [00:29:51/00:08:58, 0.756s/it]: train_loss_raw=0.4669, running_loss=0.3952, LR=0.000100
[2025-08-27 13:50:41,366][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073216] [Batch 02376/03080] [00:29:57/00:08:52, 0.756s/it]: train_loss_raw=0.4285, running_loss=0.3947, LR=0.000100
[2025-08-27 13:50:47,397][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073224] [Batch 02384/03080] [00:30:03/00:08:46, 0.756s/it]: train_loss_raw=0.4770, running_loss=0.3957, LR=0.000100
[2025-08-27 13:50:53,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073232] [Batch 02392/03080] [00:30:09/00:08:40, 0.756s/it]: train_loss_raw=0.4273, running_loss=0.3939, LR=0.000100
[2025-08-27 13:50:59,486][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073240] [Batch 02400/03080] [00:30:15/00:08:34, 0.756s/it]: train_loss_raw=0.4078, running_loss=0.3924, LR=0.000100
[2025-08-27 13:51:05,517][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073248] [Batch 02408/03080] [00:30:21/00:08:28, 0.756s/it]: train_loss_raw=0.4601, running_loss=0.3938, LR=0.000100
[2025-08-27 13:51:11,348][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073256] [Batch 02416/03080] [00:30:27/00:08:22, 0.756s/it]: train_loss_raw=0.3604, running_loss=0.3928, LR=0.000100
[2025-08-27 13:51:16,971][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073264] [Batch 02424/03080] [00:30:32/00:08:16, 0.756s/it]: train_loss_raw=0.4042, running_loss=0.3935, LR=0.000100
[2025-08-27 13:51:22,512][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073272] [Batch 02432/03080] [00:30:38/00:08:09, 0.756s/it]: train_loss_raw=0.4140, running_loss=0.3964, LR=0.000100
[2025-08-27 13:51:28,676][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073280] [Batch 02440/03080] [00:30:44/00:08:03, 0.756s/it]: train_loss_raw=0.3873, running_loss=0.3967, LR=0.000100
[2025-08-27 13:51:34,663][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073288] [Batch 02448/03080] [00:30:50/00:07:57, 0.756s/it]: train_loss_raw=0.3586, running_loss=0.3961, LR=0.000100
[2025-08-27 13:51:40,666][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073296] [Batch 02456/03080] [00:30:56/00:07:51, 0.756s/it]: train_loss_raw=0.3967, running_loss=0.3953, LR=0.000100
[2025-08-27 13:51:46,656][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073304] [Batch 02464/03080] [00:31:02/00:07:45, 0.756s/it]: train_loss_raw=0.3629, running_loss=0.3955, LR=0.000100
[2025-08-27 13:51:52,677][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073312] [Batch 02472/03080] [00:31:08/00:07:39, 0.756s/it]: train_loss_raw=0.3659, running_loss=0.3947, LR=0.000100
[2025-08-27 13:51:58,679][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073320] [Batch 02480/03080] [00:31:14/00:07:33, 0.756s/it]: train_loss_raw=0.4260, running_loss=0.3951, LR=0.000100
[2025-08-27 13:52:04,682][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073328] [Batch 02488/03080] [00:31:20/00:07:27, 0.756s/it]: train_loss_raw=0.3921, running_loss=0.3938, LR=0.000100
[2025-08-27 13:52:10,728][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073336] [Batch 02496/03080] [00:31:26/00:07:21, 0.756s/it]: train_loss_raw=0.3363, running_loss=0.3955, LR=0.000100
[2025-08-27 13:52:16,900][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073344] [Batch 02504/03080] [00:31:32/00:07:15, 0.756s/it]: train_loss_raw=0.3458, running_loss=0.3922, LR=0.000100
[2025-08-27 13:52:22,827][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073352] [Batch 02512/03080] [00:31:38/00:07:09, 0.756s/it]: train_loss_raw=0.4049, running_loss=0.3902, LR=0.000100
[2025-08-27 13:52:28,842][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073360] [Batch 02520/03080] [00:31:44/00:07:03, 0.756s/it]: train_loss_raw=0.3514, running_loss=0.3912, LR=0.000100
[2025-08-27 13:52:34,653][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073368] [Batch 02528/03080] [00:31:50/00:06:57, 0.756s/it]: train_loss_raw=0.4378, running_loss=0.3924, LR=0.000100
[2025-08-27 13:52:40,557][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073376] [Batch 02536/03080] [00:31:56/00:06:51, 0.756s/it]: train_loss_raw=0.3338, running_loss=0.3953, LR=0.000100
[2025-08-27 13:52:46,968][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073384] [Batch 02544/03080] [00:32:02/00:06:45, 0.756s/it]: train_loss_raw=0.3048, running_loss=0.3937, LR=0.000100
[2025-08-27 13:52:52,988][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073392] [Batch 02552/03080] [00:32:08/00:06:39, 0.756s/it]: train_loss_raw=0.4849, running_loss=0.3946, LR=0.000100
[2025-08-27 13:52:59,057][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073400] [Batch 02560/03080] [00:32:14/00:06:33, 0.756s/it]: train_loss_raw=0.3720, running_loss=0.3951, LR=0.000100
[2025-08-27 13:53:05,150][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073408] [Batch 02568/03080] [00:32:20/00:06:26, 0.756s/it]: train_loss_raw=0.3164, running_loss=0.3957, LR=0.000100
[2025-08-27 13:53:11,452][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073416] [Batch 02576/03080] [00:32:27/00:06:20, 0.756s/it]: train_loss_raw=0.3504, running_loss=0.3927, LR=0.000100
[2025-08-27 13:53:17,641][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073424] [Batch 02584/03080] [00:32:33/00:06:14, 0.756s/it]: train_loss_raw=0.3250, running_loss=0.3921, LR=0.000100
[2025-08-27 13:53:23,612][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073432] [Batch 02592/03080] [00:32:39/00:06:08, 0.756s/it]: train_loss_raw=0.3705, running_loss=0.3917, LR=0.000100
[2025-08-27 13:53:29,668][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073440] [Batch 02600/03080] [00:32:45/00:06:02, 0.756s/it]: train_loss_raw=0.3726, running_loss=0.3900, LR=0.000100
[2025-08-27 13:53:35,758][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073448] [Batch 02608/03080] [00:32:51/00:05:56, 0.756s/it]: train_loss_raw=0.3775, running_loss=0.3890, LR=0.000100
[2025-08-27 13:53:41,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073456] [Batch 02616/03080] [00:32:57/00:05:50, 0.756s/it]: train_loss_raw=0.5078, running_loss=0.3910, LR=0.000100
[2025-08-27 13:53:47,383][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073464] [Batch 02624/03080] [00:33:03/00:05:44, 0.756s/it]: train_loss_raw=0.3788, running_loss=0.3914, LR=0.000100
[2025-08-27 13:53:53,480][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073472] [Batch 02632/03080] [00:33:09/00:05:38, 0.756s/it]: train_loss_raw=0.2624, running_loss=0.3897, LR=0.000100
[2025-08-27 13:53:59,450][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073480] [Batch 02640/03080] [00:33:15/00:05:32, 0.756s/it]: train_loss_raw=0.4284, running_loss=0.3908, LR=0.000100
[2025-08-27 13:54:05,486][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073488] [Batch 02648/03080] [00:33:21/00:05:26, 0.756s/it]: train_loss_raw=0.4542, running_loss=0.3911, LR=0.000100
[2025-08-27 13:54:11,579][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073496] [Batch 02656/03080] [00:33:27/00:05:20, 0.756s/it]: train_loss_raw=0.2927, running_loss=0.3897, LR=0.000100
[2025-08-27 13:54:17,688][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073504] [Batch 02664/03080] [00:33:33/00:05:14, 0.756s/it]: train_loss_raw=0.4218, running_loss=0.3907, LR=0.000100
[2025-08-27 13:54:23,733][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073512] [Batch 02672/03080] [00:33:39/00:05:08, 0.756s/it]: train_loss_raw=0.3868, running_loss=0.3883, LR=0.000100
[2025-08-27 13:54:29,774][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073520] [Batch 02680/03080] [00:33:45/00:05:02, 0.756s/it]: train_loss_raw=0.4216, running_loss=0.3887, LR=0.000100
[2025-08-27 13:54:35,807][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073528] [Batch 02688/03080] [00:33:51/00:04:56, 0.756s/it]: train_loss_raw=0.3889, running_loss=0.3897, LR=0.000100
[2025-08-27 13:54:41,918][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073536] [Batch 02696/03080] [00:33:57/00:04:50, 0.756s/it]: train_loss_raw=0.3572, running_loss=0.3907, LR=0.000100
[2025-08-27 13:54:48,227][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073544] [Batch 02704/03080] [00:34:04/00:04:44, 0.756s/it]: train_loss_raw=0.4657, running_loss=0.3911, LR=0.000100
[2025-08-27 13:54:54,214][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073552] [Batch 02712/03080] [00:34:10/00:04:38, 0.756s/it]: train_loss_raw=0.3709, running_loss=0.3907, LR=0.000100
[2025-08-27 13:55:00,370][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073560] [Batch 02720/03080] [00:34:16/00:04:32, 0.756s/it]: train_loss_raw=0.4078, running_loss=0.3903, LR=0.000100
[2025-08-27 13:55:06,386][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073568] [Batch 02728/03080] [00:34:22/00:04:26, 0.756s/it]: train_loss_raw=0.3998, running_loss=0.3892, LR=0.000100
[2025-08-27 13:55:12,479][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073576] [Batch 02736/03080] [00:34:28/00:04:20, 0.756s/it]: train_loss_raw=0.4024, running_loss=0.3905, LR=0.000100
[2025-08-27 13:55:18,615][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073584] [Batch 02744/03080] [00:34:34/00:04:14, 0.756s/it]: train_loss_raw=0.4327, running_loss=0.3913, LR=0.000100
[2025-08-27 13:55:24,636][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073592] [Batch 02752/03080] [00:34:40/00:04:07, 0.756s/it]: train_loss_raw=0.4092, running_loss=0.3921, LR=0.000100
[2025-08-27 13:55:30,694][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073600] [Batch 02760/03080] [00:34:46/00:04:01, 0.756s/it]: train_loss_raw=0.3554, running_loss=0.3918, LR=0.000100
[2025-08-27 13:55:36,793][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073608] [Batch 02768/03080] [00:34:52/00:03:55, 0.756s/it]: train_loss_raw=0.4280, running_loss=0.3908, LR=0.000100
[2025-08-27 13:55:42,823][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073616] [Batch 02776/03080] [00:34:58/00:03:49, 0.756s/it]: train_loss_raw=0.3663, running_loss=0.3918, LR=0.000100
[2025-08-27 13:55:48,889][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073624] [Batch 02784/03080] [00:35:04/00:03:43, 0.756s/it]: train_loss_raw=0.4527, running_loss=0.3917, LR=0.000100
[2025-08-27 13:55:54,902][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073632] [Batch 02792/03080] [00:35:10/00:03:37, 0.756s/it]: train_loss_raw=0.4452, running_loss=0.3936, LR=0.000100
[2025-08-27 13:56:00,929][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073640] [Batch 02800/03080] [00:35:16/00:03:31, 0.756s/it]: train_loss_raw=0.3952, running_loss=0.3915, LR=0.000100
[2025-08-27 13:56:07,043][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073648] [Batch 02808/03080] [00:35:22/00:03:25, 0.756s/it]: train_loss_raw=0.5059, running_loss=0.3927, LR=0.000100
[2025-08-27 13:56:13,074][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073656] [Batch 02816/03080] [00:35:28/00:03:19, 0.756s/it]: train_loss_raw=0.4144, running_loss=0.3911, LR=0.000100
[2025-08-27 13:56:19,074][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073664] [Batch 02824/03080] [00:35:34/00:03:13, 0.756s/it]: train_loss_raw=0.4649, running_loss=0.3935, LR=0.000100
[2025-08-27 13:56:25,122][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073672] [Batch 02832/03080] [00:35:40/00:03:07, 0.756s/it]: train_loss_raw=0.4243, running_loss=0.3933, LR=0.000100
[2025-08-27 13:56:30,946][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073680] [Batch 02840/03080] [00:35:46/00:03:01, 0.756s/it]: train_loss_raw=0.3589, running_loss=0.3917, LR=0.000100
[2025-08-27 13:56:36,671][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073688] [Batch 02848/03080] [00:35:52/00:02:55, 0.756s/it]: train_loss_raw=0.3945, running_loss=0.3922, LR=0.000100
[2025-08-27 13:56:42,268][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073696] [Batch 02856/03080] [00:35:58/00:02:49, 0.756s/it]: train_loss_raw=0.3423, running_loss=0.3912, LR=0.000100
[2025-08-27 13:56:47,811][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073704] [Batch 02864/03080] [00:36:03/00:02:43, 0.755s/it]: train_loss_raw=0.4174, running_loss=0.3910, LR=0.000100
[2025-08-27 13:56:53,381][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073712] [Batch 02872/03080] [00:36:09/00:02:37, 0.755s/it]: train_loss_raw=0.3449, running_loss=0.3903, LR=0.000100
[2025-08-27 13:56:59,421][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073720] [Batch 02880/03080] [00:36:15/00:02:31, 0.755s/it]: train_loss_raw=0.3552, running_loss=0.3927, LR=0.000100
[2025-08-27 13:57:05,509][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073728] [Batch 02888/03080] [00:36:21/00:02:25, 0.755s/it]: train_loss_raw=0.4385, running_loss=0.3943, LR=0.000100
[2025-08-27 13:57:11,580][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073736] [Batch 02896/03080] [00:36:27/00:02:18, 0.755s/it]: train_loss_raw=0.3900, running_loss=0.3943, LR=0.000100
[2025-08-27 13:57:17,614][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073744] [Batch 02904/03080] [00:36:33/00:02:12, 0.755s/it]: train_loss_raw=0.3314, running_loss=0.3938, LR=0.000100
[2025-08-27 13:57:23,510][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073752] [Batch 02912/03080] [00:36:39/00:02:06, 0.755s/it]: train_loss_raw=0.4061, running_loss=0.3952, LR=0.000100
[2025-08-27 13:57:29,494][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073760] [Batch 02920/03080] [00:36:45/00:02:00, 0.755s/it]: train_loss_raw=0.4387, running_loss=0.3959, LR=0.000100
[2025-08-27 13:57:35,106][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073768] [Batch 02928/03080] [00:36:50/00:01:54, 0.755s/it]: train_loss_raw=0.4103, running_loss=0.3981, LR=0.000100
[2025-08-27 13:57:40,493][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073776] [Batch 02936/03080] [00:36:56/00:01:48, 0.755s/it]: train_loss_raw=0.2742, running_loss=0.3963, LR=0.000100
[2025-08-27 13:57:46,312][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073784] [Batch 02944/03080] [00:37:02/00:01:42, 0.755s/it]: train_loss_raw=0.3690, running_loss=0.3971, LR=0.000100
[2025-08-27 13:57:52,446][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073792] [Batch 02952/03080] [00:37:08/00:01:36, 0.755s/it]: train_loss_raw=0.3399, running_loss=0.3955, LR=0.000100
[2025-08-27 13:57:58,353][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073800] [Batch 02960/03080] [00:37:14/00:01:30, 0.755s/it]: train_loss_raw=0.4395, running_loss=0.3950, LR=0.000100
[2025-08-27 13:58:04,406][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073808] [Batch 02968/03080] [00:37:20/00:01:24, 0.755s/it]: train_loss_raw=0.4651, running_loss=0.3952, LR=0.000100
[2025-08-27 13:58:10,455][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073816] [Batch 02976/03080] [00:37:26/00:01:18, 0.755s/it]: train_loss_raw=0.4149, running_loss=0.3948, LR=0.000100
[2025-08-27 13:58:16,250][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073824] [Batch 02984/03080] [00:37:32/00:01:12, 0.755s/it]: train_loss_raw=0.4669, running_loss=0.3940, LR=0.000100
[2025-08-27 13:58:22,219][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073832] [Batch 02992/03080] [00:37:38/00:01:06, 0.755s/it]: train_loss_raw=0.4641, running_loss=0.3949, LR=0.000100
[2025-08-27 13:58:28,240][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073840] [Batch 03000/03080] [00:37:44/00:01:00, 0.755s/it]: train_loss_raw=0.3720, running_loss=0.3951, LR=0.000100
[2025-08-27 13:58:33,894][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073848] [Batch 03008/03080] [00:37:49/00:00:54, 0.755s/it]: train_loss_raw=0.4312, running_loss=0.3935, LR=0.000100
[2025-08-27 13:58:39,825][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073856] [Batch 03016/03080] [00:37:55/00:00:48, 0.755s/it]: train_loss_raw=0.4002, running_loss=0.3944, LR=0.000100
[2025-08-27 13:58:45,644][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073864] [Batch 03024/03080] [00:38:01/00:00:42, 0.754s/it]: train_loss_raw=0.3778, running_loss=0.3939, LR=0.000100
[2025-08-27 13:58:51,581][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073872] [Batch 03032/03080] [00:38:07/00:00:36, 0.754s/it]: train_loss_raw=0.3665, running_loss=0.3928, LR=0.000100
[2025-08-27 13:58:57,128][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073880] [Batch 03040/03080] [00:38:12/00:00:30, 0.754s/it]: train_loss_raw=0.2857, running_loss=0.3915, LR=0.000100
[2025-08-27 13:59:03,124][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073888] [Batch 03048/03080] [00:38:18/00:00:24, 0.754s/it]: train_loss_raw=0.3805, running_loss=0.3904, LR=0.000100
[2025-08-27 13:59:09,075][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073896] [Batch 03056/03080] [00:38:24/00:00:18, 0.754s/it]: train_loss_raw=0.3939, running_loss=0.3921, LR=0.000100
[2025-08-27 13:59:15,166][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073904] [Batch 03064/03080] [00:38:30/00:00:12, 0.754s/it]: train_loss_raw=0.3642, running_loss=0.3929, LR=0.000100
[2025-08-27 13:59:21,229][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073912] [Batch 03072/03080] [00:38:37/00:00:06, 0.754s/it]: train_loss_raw=0.3330, running_loss=0.3919, LR=0.000100
[2025-08-27 13:59:35,774][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073920] [Batch 03080/03080] [00:38:51/00:00:00, 0.757s/it]: train_loss_raw=0.3583, running_loss=0.3914, LR=0.000100
[2025-08-27 13:59:36,289][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-27 13:59:47,327][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00007/00310] [00:00:11/00:06:56, 1.380s/it]
[2025-08-27 13:59:58,299][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00015/00310] [00:00:22/00:06:44, 1.376s/it]
[2025-08-27 14:00:10,582][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00023/00310] [00:00:34/00:06:48, 1.429s/it]
[2025-08-27 14:00:22,112][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00031/00310] [00:00:45/00:06:38, 1.432s/it]
[2025-08-27 14:00:34,243][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00039/00310] [00:00:57/00:06:31, 1.449s/it]
[2025-08-27 14:00:46,437][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00047/00310] [00:01:10/00:06:22, 1.461s/it]
[2025-08-27 14:00:58,885][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00055/00310] [00:01:22/00:06:14, 1.475s/it]
[2025-08-27 14:01:10,854][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00063/00310] [00:01:34/00:06:03, 1.478s/it]
[2025-08-27 14:01:22,281][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00071/00310] [00:01:45/00:05:50, 1.472s/it]
[2025-08-27 14:01:34,153][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00079/00310] [00:01:57/00:05:38, 1.473s/it]
[2025-08-27 14:01:45,263][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00087/00310] [00:02:08/00:05:25, 1.466s/it]
[2025-08-27 14:01:57,734][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00095/00310] [00:02:21/00:05:15, 1.473s/it]
[2025-08-27 14:02:09,369][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00103/00310] [00:02:33/00:05:03, 1.472s/it]
[2025-08-27 14:02:21,459][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00111/00310] [00:02:45/00:04:51, 1.475s/it]
[2025-08-27 14:02:33,325][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00119/00310] [00:02:57/00:04:40, 1.475s/it]
[2025-08-27 14:02:45,218][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00127/00310] [00:03:08/00:04:28, 1.476s/it]
[2025-08-27 14:02:56,787][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00135/00310] [00:03:20/00:04:16, 1.474s/it]
[2025-08-27 14:03:08,996][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00143/00310] [00:03:32/00:04:05, 1.477s/it]
[2025-08-27 14:03:19,561][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00151/00310] [00:03:43/00:03:52, 1.469s/it]
[2025-08-27 14:03:30,202][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00159/00310] [00:03:53/00:03:39, 1.462s/it]
[2025-08-27 14:03:42,720][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00167/00310] [00:04:06/00:03:28, 1.467s/it]
[2025-08-27 14:03:53,738][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00175/00310] [00:04:17/00:03:16, 1.463s/it]
[2025-08-27 14:04:04,336][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00183/00310] [00:04:28/00:03:03, 1.457s/it]
[2025-08-27 14:04:14,963][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00191/00310] [00:04:38/00:02:51, 1.451s/it]
[2025-08-27 14:04:26,713][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00199/00310] [00:04:50/00:02:39, 1.452s/it]
[2025-08-27 14:04:38,221][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00207/00310] [00:05:01/00:02:28, 1.452s/it]
[2025-08-27 14:04:49,625][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00215/00310] [00:05:13/00:02:16, 1.451s/it]
[2025-08-27 14:05:00,929][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00223/00310] [00:05:24/00:02:04, 1.449s/it]
[2025-08-27 14:05:12,444][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00231/00310] [00:05:36/00:01:53, 1.449s/it]
[2025-08-27 14:05:24,067][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00239/00310] [00:05:47/00:01:41, 1.449s/it]
[2025-08-27 14:05:34,982][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00247/00310] [00:05:58/00:01:29, 1.446s/it]
[2025-08-27 14:05:46,585][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00255/00310] [00:06:10/00:01:18, 1.446s/it]
[2025-08-27 14:05:58,989][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00263/00310] [00:06:22/00:01:06, 1.450s/it]
[2025-08-27 14:06:11,073][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00271/00310] [00:06:34/00:00:55, 1.451s/it]
[2025-08-27 14:06:22,496][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00279/00310] [00:06:46/00:00:43, 1.451s/it]
[2025-08-27 14:06:34,506][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00287/00310] [00:06:58/00:00:31, 1.452s/it]
[2025-08-27 14:06:45,984][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00295/00310] [00:07:09/00:00:20, 1.452s/it]
[2025-08-27 14:06:58,156][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00303/00310] [00:07:21/00:00:08, 1.454s/it]
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=0.39137, valid_loss=1.45508
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.497
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.144
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.146
[2025-08-27 14:07:06,576][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.075
[2025-08-27 14:07:06,586][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 18:40:20, remaining time 04:40:05, 00:46:40 per epoch
[2025-08-27 14:07:13,923][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073928] [Batch 00008/03080] [00:00:07/00:45:44, 0.893s/it]: train_loss_raw=0.3406, running_loss=0.4551, LR=0.000100
[2025-08-27 14:07:20,040][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073936] [Batch 00016/03080] [00:00:13/00:42:19, 0.829s/it]: train_loss_raw=0.3617, running_loss=0.4475, LR=0.000100
[2025-08-27 14:07:26,156][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073944] [Batch 00024/03080] [00:00:19/00:41:07, 0.807s/it]: train_loss_raw=0.2936, running_loss=0.4383, LR=0.000100
[2025-08-27 14:07:32,301][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073952] [Batch 00032/03080] [00:00:25/00:40:31, 0.798s/it]: train_loss_raw=0.3363, running_loss=0.4322, LR=0.000100
[2025-08-27 14:07:37,773][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073960] [Batch 00040/03080] [00:00:30/00:39:15, 0.775s/it]: train_loss_raw=0.3990, running_loss=0.4279, LR=0.000100
[2025-08-27 14:07:43,294][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073968] [Batch 00048/03080] [00:00:36/00:38:26, 0.761s/it]: train_loss_raw=0.3687, running_loss=0.4215, LR=0.000100
[2025-08-27 14:07:49,240][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073976] [Batch 00056/03080] [00:00:42/00:38:13, 0.758s/it]: train_loss_raw=0.3619, running_loss=0.4186, LR=0.000100
[2025-08-27 14:07:54,799][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073984] [Batch 00064/03080] [00:00:48/00:37:43, 0.750s/it]: train_loss_raw=0.5235, running_loss=0.4147, LR=0.000100
[2025-08-27 14:08:00,880][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073992] [Batch 00072/03080] [00:00:54/00:37:40, 0.751s/it]: train_loss_raw=0.4097, running_loss=0.4114, LR=0.000100
[2025-08-27 14:08:06,854][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074000] [Batch 00080/03080] [00:01:00/00:37:32, 0.751s/it]: train_loss_raw=0.3668, running_loss=0.4071, LR=0.000100
[2025-08-27 14:08:16,327][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074008] [Batch 00088/03080] [00:01:09/00:39:24, 0.790s/it]: train_loss_raw=0.3373, running_loss=0.4039, LR=0.000100
[2025-08-27 14:08:22,334][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074016] [Batch 00096/03080] [00:01:15/00:39:08, 0.787s/it]: train_loss_raw=0.3444, running_loss=0.4006, LR=0.000100
[2025-08-27 14:08:28,565][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074024] [Batch 00104/03080] [00:01:21/00:39:00, 0.786s/it]: train_loss_raw=0.4176, running_loss=0.3997, LR=0.000100
[2025-08-27 14:08:34,668][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074032] [Batch 00112/03080] [00:01:27/00:38:49, 0.785s/it]: train_loss_raw=0.3746, running_loss=0.3968, LR=0.000100
[2025-08-27 14:08:40,712][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074040] [Batch 00120/03080] [00:01:33/00:38:37, 0.783s/it]: train_loss_raw=0.3381, running_loss=0.3956, LR=0.000100
[2025-08-27 14:08:46,773][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074048] [Batch 00128/03080] [00:01:39/00:38:26, 0.781s/it]: train_loss_raw=0.3608, running_loss=0.3944, LR=0.000100
[2025-08-27 14:08:52,888][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074056] [Batch 00136/03080] [00:01:46/00:38:17, 0.780s/it]: train_loss_raw=0.3486, running_loss=0.3926, LR=0.000100
[2025-08-27 14:08:58,817][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074064] [Batch 00144/03080] [00:01:52/00:38:04, 0.778s/it]: train_loss_raw=0.3715, running_loss=0.3908, LR=0.000100
[2025-08-27 14:09:04,846][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074072] [Batch 00152/03080] [00:01:58/00:37:54, 0.777s/it]: train_loss_raw=0.3482, running_loss=0.3887, LR=0.000100
[2025-08-27 14:09:10,786][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074080] [Batch 00160/03080] [00:02:04/00:37:43, 0.775s/it]: train_loss_raw=0.3653, running_loss=0.3885, LR=0.000100
[2025-08-27 14:09:16,897][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074088] [Batch 00168/03080] [00:02:10/00:37:35, 0.775s/it]: train_loss_raw=0.3750, running_loss=0.3879, LR=0.000100
[2025-08-27 14:09:22,806][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074096] [Batch 00176/03080] [00:02:16/00:37:24, 0.773s/it]: train_loss_raw=0.3768, running_loss=0.3853, LR=0.000100
[2025-08-27 14:09:28,718][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074104] [Batch 00184/03080] [00:02:21/00:37:14, 0.771s/it]: train_loss_raw=0.3759, running_loss=0.3826, LR=0.000100
[2025-08-27 14:09:34,481][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074112] [Batch 00192/03080] [00:02:27/00:37:01, 0.769s/it]: train_loss_raw=0.3917, running_loss=0.3827, LR=0.000100
[2025-08-27 14:09:40,206][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074120] [Batch 00200/03080] [00:02:33/00:36:49, 0.767s/it]: train_loss_raw=0.4119, running_loss=0.3831, LR=0.000100
[2025-08-27 14:09:46,266][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074128] [Batch 00208/03080] [00:02:39/00:36:42, 0.767s/it]: train_loss_raw=0.3542, running_loss=0.3818, LR=0.000100
[2025-08-27 14:09:52,483][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074136] [Batch 00216/03080] [00:02:45/00:36:37, 0.767s/it]: train_loss_raw=0.3364, running_loss=0.3810, LR=0.000100
[2025-08-27 14:09:58,446][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074144] [Batch 00224/03080] [00:02:51/00:36:28, 0.766s/it]: train_loss_raw=0.4173, running_loss=0.3805, LR=0.000100
[2025-08-27 14:10:04,574][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074152] [Batch 00232/03080] [00:02:57/00:36:22, 0.766s/it]: train_loss_raw=0.3896, running_loss=0.3815, LR=0.000100
[2025-08-27 14:10:10,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074160] [Batch 00240/03080] [00:03:03/00:36:15, 0.766s/it]: train_loss_raw=0.4000, running_loss=0.3797, LR=0.000100
[2025-08-27 14:10:16,887][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074168] [Batch 00248/03080] [00:03:10/00:36:10, 0.767s/it]: train_loss_raw=0.3589, running_loss=0.3783, LR=0.000100
[2025-08-27 14:10:22,695][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074176] [Batch 00256/03080] [00:03:15/00:36:01, 0.765s/it]: train_loss_raw=0.3311, running_loss=0.3768, LR=0.000100
[2025-08-27 14:10:28,671][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074184] [Batch 00264/03080] [00:03:21/00:35:53, 0.765s/it]: train_loss_raw=0.3803, running_loss=0.3768, LR=0.000100
[2025-08-27 14:10:34,714][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074192] [Batch 00272/03080] [00:03:27/00:35:46, 0.764s/it]: train_loss_raw=0.3349, running_loss=0.3767, LR=0.000100
[2025-08-27 14:10:40,776][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074200] [Batch 00280/03080] [00:03:33/00:35:39, 0.764s/it]: train_loss_raw=0.3074, running_loss=0.3754, LR=0.000100
[2025-08-27 14:10:46,859][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074208] [Batch 00288/03080] [00:03:40/00:35:33, 0.764s/it]: train_loss_raw=0.3492, running_loss=0.3741, LR=0.000100
[2025-08-27 14:10:52,960][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074216] [Batch 00296/03080] [00:03:46/00:35:27, 0.764s/it]: train_loss_raw=0.4212, running_loss=0.3754, LR=0.000100
[2025-08-27 14:10:59,117][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074224] [Batch 00304/03080] [00:03:52/00:35:21, 0.764s/it]: train_loss_raw=0.3501, running_loss=0.3731, LR=0.000100
[2025-08-27 14:11:05,229][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074232] [Batch 00312/03080] [00:03:58/00:35:15, 0.764s/it]: train_loss_raw=0.3230, running_loss=0.3711, LR=0.000100
[2025-08-27 14:11:11,229][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074240] [Batch 00320/03080] [00:04:04/00:35:08, 0.764s/it]: train_loss_raw=0.3826, running_loss=0.3720, LR=0.000100
[2025-08-27 14:11:17,444][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074248] [Batch 00328/03080] [00:04:10/00:35:03, 0.764s/it]: train_loss_raw=0.3873, running_loss=0.3705, LR=0.000100
[2025-08-27 14:11:23,456][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074256] [Batch 00336/03080] [00:04:16/00:34:56, 0.764s/it]: train_loss_raw=0.4119, running_loss=0.3706, LR=0.000100
[2025-08-27 14:11:29,608][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074264] [Batch 00344/03080] [00:04:22/00:34:50, 0.764s/it]: train_loss_raw=0.3879, running_loss=0.3697, LR=0.000100
[2025-08-27 14:11:35,687][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074272] [Batch 00352/03080] [00:04:28/00:34:44, 0.764s/it]: train_loss_raw=0.4395, running_loss=0.3686, LR=0.000100
[2025-08-27 14:11:41,814][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074280] [Batch 00360/03080] [00:04:35/00:34:38, 0.764s/it]: train_loss_raw=0.3498, running_loss=0.3691, LR=0.000100
[2025-08-27 14:11:47,888][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074288] [Batch 00368/03080] [00:04:41/00:34:31, 0.764s/it]: train_loss_raw=0.3319, running_loss=0.3704, LR=0.000100
[2025-08-27 14:11:53,963][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074296] [Batch 00376/03080] [00:04:47/00:34:25, 0.764s/it]: train_loss_raw=0.3425, running_loss=0.3698, LR=0.000100
[2025-08-27 14:12:00,030][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074304] [Batch 00384/03080] [00:04:53/00:34:18, 0.764s/it]: train_loss_raw=0.3453, running_loss=0.3716, LR=0.000100
[2025-08-27 14:12:06,144][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074312] [Batch 00392/03080] [00:04:59/00:34:12, 0.764s/it]: train_loss_raw=0.3584, running_loss=0.3721, LR=0.000100
[2025-08-27 14:12:12,235][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074320] [Batch 00400/03080] [00:05:05/00:34:06, 0.764s/it]: train_loss_raw=0.3328, running_loss=0.3697, LR=0.000100
[2025-08-27 14:12:18,542][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074328] [Batch 00408/03080] [00:05:11/00:34:01, 0.764s/it]: train_loss_raw=0.4186, running_loss=0.3701, LR=0.000100
[2025-08-27 14:12:24,553][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074336] [Batch 00416/03080] [00:05:17/00:33:54, 0.764s/it]: train_loss_raw=0.3845, running_loss=0.3687, LR=0.000100
[2025-08-27 14:12:30,635][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074344] [Batch 00424/03080] [00:05:23/00:33:48, 0.764s/it]: train_loss_raw=0.3572, running_loss=0.3671, LR=0.000100
[2025-08-27 14:12:36,756][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074352] [Batch 00432/03080] [00:05:29/00:33:42, 0.764s/it]: train_loss_raw=0.3564, running_loss=0.3691, LR=0.000100
[2025-08-27 14:12:42,831][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074360] [Batch 00440/03080] [00:05:36/00:33:36, 0.764s/it]: train_loss_raw=0.4253, running_loss=0.3698, LR=0.000100
[2025-08-27 14:12:48,920][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074368] [Batch 00448/03080] [00:05:42/00:33:30, 0.764s/it]: train_loss_raw=0.4054, running_loss=0.3698, LR=0.000100
[2025-08-27 14:12:55,057][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074376] [Batch 00456/03080] [00:05:48/00:33:24, 0.764s/it]: train_loss_raw=0.3083, running_loss=0.3712, LR=0.000100
[2025-08-27 14:13:01,224][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074384] [Batch 00464/03080] [00:05:54/00:33:18, 0.764s/it]: train_loss_raw=0.3992, running_loss=0.3695, LR=0.000100
[2025-08-27 14:13:07,551][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074392] [Batch 00472/03080] [00:06:00/00:33:13, 0.764s/it]: train_loss_raw=0.3757, running_loss=0.3692, LR=0.000100
[2025-08-27 14:13:13,551][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074400] [Batch 00480/03080] [00:06:06/00:33:06, 0.764s/it]: train_loss_raw=0.3944, running_loss=0.3701, LR=0.000100
[2025-08-27 14:13:19,618][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074408] [Batch 00488/03080] [00:06:12/00:33:00, 0.764s/it]: train_loss_raw=0.3587, running_loss=0.3720, LR=0.000100
[2025-08-27 14:13:25,635][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074416] [Batch 00496/03080] [00:06:18/00:32:53, 0.764s/it]: train_loss_raw=0.3886, running_loss=0.3720, LR=0.000100
[2025-08-27 14:13:31,665][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074424] [Batch 00504/03080] [00:06:24/00:32:47, 0.764s/it]: train_loss_raw=0.4051, running_loss=0.3706, LR=0.000100
[2025-08-27 14:13:37,282][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074432] [Batch 00512/03080] [00:06:30/00:32:38, 0.763s/it]: train_loss_raw=0.3800, running_loss=0.3688, LR=0.000100
[2025-08-27 14:13:42,824][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074440] [Batch 00520/03080] [00:06:36/00:32:29, 0.762s/it]: train_loss_raw=0.3889, running_loss=0.3686, LR=0.000100
[2025-08-27 14:13:48,784][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074448] [Batch 00528/03080] [00:06:42/00:32:23, 0.761s/it]: train_loss_raw=0.3678, running_loss=0.3696, LR=0.000100
[2025-08-27 14:13:54,708][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074456] [Batch 00536/03080] [00:06:47/00:32:16, 0.761s/it]: train_loss_raw=0.3905, running_loss=0.3701, LR=0.000100
[2025-08-27 14:14:00,850][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074464] [Batch 00544/03080] [00:06:54/00:32:10, 0.761s/it]: train_loss_raw=0.3503, running_loss=0.3705, LR=0.000100
[2025-08-27 14:14:06,980][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074472] [Batch 00552/03080] [00:07:00/00:32:04, 0.761s/it]: train_loss_raw=0.3859, running_loss=0.3719, LR=0.000100
[2025-08-27 14:14:13,048][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074480] [Batch 00560/03080] [00:07:06/00:31:58, 0.761s/it]: train_loss_raw=0.3219, running_loss=0.3713, LR=0.000100
[2025-08-27 14:14:19,080][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074488] [Batch 00568/03080] [00:07:12/00:31:51, 0.761s/it]: train_loss_raw=0.3590, running_loss=0.3711, LR=0.000100
[2025-08-27 14:14:25,259][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074496] [Batch 00576/03080] [00:07:18/00:31:46, 0.761s/it]: train_loss_raw=0.3862, running_loss=0.3713, LR=0.000100
[2025-08-27 14:14:31,302][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074504] [Batch 00584/03080] [00:07:24/00:31:39, 0.761s/it]: train_loss_raw=0.3473, running_loss=0.3712, LR=0.000100
[2025-08-27 14:14:37,464][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074512] [Batch 00592/03080] [00:07:30/00:31:34, 0.761s/it]: train_loss_raw=0.3339, running_loss=0.3705, LR=0.000100
[2025-08-27 14:14:43,638][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074520] [Batch 00600/03080] [00:07:36/00:31:28, 0.761s/it]: train_loss_raw=0.3663, running_loss=0.3727, LR=0.000100
[2025-08-27 14:14:49,706][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074528] [Batch 00608/03080] [00:07:42/00:31:22, 0.761s/it]: train_loss_raw=0.3585, running_loss=0.3727, LR=0.000100
[2025-08-27 14:14:55,808][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074536] [Batch 00616/03080] [00:07:49/00:31:16, 0.761s/it]: train_loss_raw=0.3856, running_loss=0.3719, LR=0.000100
[2025-08-27 14:15:01,892][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074544] [Batch 00624/03080] [00:07:55/00:31:10, 0.761s/it]: train_loss_raw=0.4003, running_loss=0.3711, LR=0.000100
[2025-08-27 14:15:08,076][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074552] [Batch 00632/03080] [00:08:01/00:31:04, 0.762s/it]: train_loss_raw=0.2999, running_loss=0.3713, LR=0.000100
[2025-08-27 14:15:13,736][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074560] [Batch 00640/03080] [00:08:06/00:30:56, 0.761s/it]: train_loss_raw=0.3925, running_loss=0.3694, LR=0.000100
[2025-08-27 14:15:19,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074568] [Batch 00648/03080] [00:08:12/00:30:49, 0.761s/it]: train_loss_raw=0.4063, running_loss=0.3712, LR=0.000100
[2025-08-27 14:15:25,693][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074576] [Batch 00656/03080] [00:08:18/00:30:43, 0.761s/it]: train_loss_raw=0.3963, running_loss=0.3721, LR=0.000100
[2025-08-27 14:15:31,535][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074584] [Batch 00664/03080] [00:08:24/00:30:36, 0.760s/it]: train_loss_raw=0.4247, running_loss=0.3749, LR=0.000100
[2025-08-27 14:15:37,556][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074592] [Batch 00672/03080] [00:08:30/00:30:30, 0.760s/it]: train_loss_raw=0.3012, running_loss=0.3747, LR=0.000100
[2025-08-27 14:15:43,658][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074600] [Batch 00680/03080] [00:08:36/00:30:24, 0.760s/it]: train_loss_raw=0.3530, running_loss=0.3726, LR=0.000100
[2025-08-27 14:15:49,995][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074608] [Batch 00688/03080] [00:08:43/00:30:19, 0.760s/it]: train_loss_raw=0.3854, running_loss=0.3736, LR=0.000100
[2025-08-27 14:15:55,992][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074616] [Batch 00696/03080] [00:08:49/00:30:12, 0.760s/it]: train_loss_raw=0.3676, running_loss=0.3724, LR=0.000100
[2025-08-27 14:16:02,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074624] [Batch 00704/03080] [00:08:55/00:30:06, 0.760s/it]: train_loss_raw=0.3300, running_loss=0.3713, LR=0.000100
[2025-08-27 14:16:08,086][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074632] [Batch 00712/03080] [00:09:01/00:30:00, 0.760s/it]: train_loss_raw=0.3177, running_loss=0.3711, LR=0.000100
[2025-08-27 14:16:14,239][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074640] [Batch 00720/03080] [00:09:07/00:29:54, 0.760s/it]: train_loss_raw=0.3596, running_loss=0.3729, LR=0.000100
[2025-08-27 14:16:20,167][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074648] [Batch 00728/03080] [00:09:13/00:29:47, 0.760s/it]: train_loss_raw=0.3772, running_loss=0.3727, LR=0.000100
[2025-08-27 14:16:25,653][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074656] [Batch 00736/03080] [00:09:18/00:29:39, 0.759s/it]: train_loss_raw=0.3899, running_loss=0.3734, LR=0.000100
[2025-08-27 14:16:31,462][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074664] [Batch 00744/03080] [00:09:24/00:29:32, 0.759s/it]: train_loss_raw=0.4181, running_loss=0.3742, LR=0.000100
[2025-08-27 14:16:37,477][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074672] [Batch 00752/03080] [00:09:30/00:29:26, 0.759s/it]: train_loss_raw=0.3928, running_loss=0.3760, LR=0.000100
[2025-08-27 14:16:43,625][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074680] [Batch 00760/03080] [00:09:36/00:29:20, 0.759s/it]: train_loss_raw=0.3899, running_loss=0.3763, LR=0.000100
[2025-08-27 14:16:49,815][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074688] [Batch 00768/03080] [00:09:43/00:29:15, 0.759s/it]: train_loss_raw=0.3692, running_loss=0.3758, LR=0.000100
[2025-08-27 14:16:55,992][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074696] [Batch 00776/03080] [00:09:49/00:29:09, 0.759s/it]: train_loss_raw=0.4057, running_loss=0.3748, LR=0.000100
[2025-08-27 14:17:02,091][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074704] [Batch 00784/03080] [00:09:55/00:29:03, 0.759s/it]: train_loss_raw=0.3225, running_loss=0.3745, LR=0.000100
[2025-08-27 14:17:08,193][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074712] [Batch 00792/03080] [00:10:01/00:28:57, 0.759s/it]: train_loss_raw=0.3712, running_loss=0.3736, LR=0.000100
[2025-08-27 14:17:14,207][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074720] [Batch 00800/03080] [00:10:07/00:28:51, 0.759s/it]: train_loss_raw=0.3774, running_loss=0.3735, LR=0.000100
[2025-08-27 14:17:20,267][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074728] [Batch 00808/03080] [00:10:13/00:28:45, 0.759s/it]: train_loss_raw=0.4723, running_loss=0.3723, LR=0.000100
[2025-08-27 14:17:26,323][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074736] [Batch 00816/03080] [00:10:19/00:28:38, 0.759s/it]: train_loss_raw=0.3555, running_loss=0.3728, LR=0.000100
[2025-08-27 14:17:32,580][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074744] [Batch 00824/03080] [00:10:25/00:28:33, 0.759s/it]: train_loss_raw=0.4740, running_loss=0.3739, LR=0.000100
[2025-08-27 14:17:38,671][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074752] [Batch 00832/03080] [00:10:31/00:28:27, 0.759s/it]: train_loss_raw=0.3182, running_loss=0.3738, LR=0.000100
[2025-08-27 14:17:44,726][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074760] [Batch 00840/03080] [00:10:37/00:28:21, 0.759s/it]: train_loss_raw=0.3497, running_loss=0.3726, LR=0.000100
[2025-08-27 14:17:50,759][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074768] [Batch 00848/03080] [00:10:43/00:28:15, 0.759s/it]: train_loss_raw=0.3998, running_loss=0.3713, LR=0.000100
[2025-08-27 14:17:56,779][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074776] [Batch 00856/03080] [00:10:50/00:28:08, 0.759s/it]: train_loss_raw=0.4659, running_loss=0.3738, LR=0.000100
[2025-08-27 14:18:02,801][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074784] [Batch 00864/03080] [00:10:56/00:28:02, 0.759s/it]: train_loss_raw=0.3890, running_loss=0.3754, LR=0.000100
[2025-08-27 14:18:08,823][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074792] [Batch 00872/03080] [00:11:02/00:27:56, 0.759s/it]: train_loss_raw=0.3985, running_loss=0.3751, LR=0.000100
[2025-08-27 14:18:14,856][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074800] [Batch 00880/03080] [00:11:08/00:27:50, 0.759s/it]: train_loss_raw=0.3891, running_loss=0.3739, LR=0.000100
[2025-08-27 14:18:20,963][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074808] [Batch 00888/03080] [00:11:14/00:27:44, 0.759s/it]: train_loss_raw=0.3991, running_loss=0.3716, LR=0.000100
[2025-08-27 14:18:26,972][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074816] [Batch 00896/03080] [00:11:20/00:27:37, 0.759s/it]: train_loss_raw=0.4107, running_loss=0.3719, LR=0.000100
[2025-08-27 14:18:32,977][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074824] [Batch 00904/03080] [00:11:26/00:27:31, 0.759s/it]: train_loss_raw=0.3231, running_loss=0.3712, LR=0.000100
[2025-08-27 14:18:39,000][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074832] [Batch 00912/03080] [00:11:32/00:27:25, 0.759s/it]: train_loss_raw=0.3734, running_loss=0.3710, LR=0.000100
[2025-08-27 14:18:45,068][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074840] [Batch 00920/03080] [00:11:38/00:27:19, 0.759s/it]: train_loss_raw=0.3462, running_loss=0.3698, LR=0.000100
[2025-08-27 14:18:51,084][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074848] [Batch 00928/03080] [00:11:44/00:27:13, 0.759s/it]: train_loss_raw=0.2967, running_loss=0.3680, LR=0.000100
[2025-08-27 14:18:57,190][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074856] [Batch 00936/03080] [00:11:50/00:27:07, 0.759s/it]: train_loss_raw=0.3640, running_loss=0.3688, LR=0.000100
[2025-08-27 14:19:03,273][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074864] [Batch 00944/03080] [00:11:56/00:27:01, 0.759s/it]: train_loss_raw=0.3508, running_loss=0.3670, LR=0.000100
[2025-08-27 14:19:09,240][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074872] [Batch 00952/03080] [00:12:02/00:26:54, 0.759s/it]: train_loss_raw=0.3049, running_loss=0.3656, LR=0.000100
[2025-08-27 14:19:14,968][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074880] [Batch 00960/03080] [00:12:08/00:26:48, 0.759s/it]: train_loss_raw=0.3705, running_loss=0.3647, LR=0.000100
[2025-08-27 14:19:20,975][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074888] [Batch 00968/03080] [00:12:14/00:26:41, 0.758s/it]: train_loss_raw=0.3468, running_loss=0.3653, LR=0.000100
[2025-08-27 14:19:26,989][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074896] [Batch 00976/03080] [00:12:20/00:26:35, 0.758s/it]: train_loss_raw=0.3005, running_loss=0.3663, LR=0.000100
[2025-08-27 14:19:33,028][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074904] [Batch 00984/03080] [00:12:26/00:26:29, 0.758s/it]: train_loss_raw=0.3437, running_loss=0.3659, LR=0.000100
[2025-08-27 14:19:39,081][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074912] [Batch 00992/03080] [00:12:32/00:26:23, 0.758s/it]: train_loss_raw=0.4005, running_loss=0.3658, LR=0.000100
[2025-08-27 14:19:44,940][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074920] [Batch 01000/03080] [00:12:38/00:26:16, 0.758s/it]: train_loss_raw=0.3999, running_loss=0.3678, LR=0.000100
[2025-08-27 14:19:50,718][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074928] [Batch 01008/03080] [00:12:43/00:26:10, 0.758s/it]: train_loss_raw=0.3647, running_loss=0.3676, LR=0.000100
[2025-08-27 14:19:56,690][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074936] [Batch 01016/03080] [00:12:49/00:26:04, 0.758s/it]: train_loss_raw=0.3405, running_loss=0.3688, LR=0.000100
[2025-08-27 14:20:02,749][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074944] [Batch 01024/03080] [00:12:55/00:25:58, 0.758s/it]: train_loss_raw=0.3648, running_loss=0.3674, LR=0.000100
[2025-08-27 14:20:08,654][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074952] [Batch 01032/03080] [00:13:01/00:25:51, 0.758s/it]: train_loss_raw=0.3691, running_loss=0.3661, LR=0.000100
[2025-08-27 14:20:14,769][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074960] [Batch 01040/03080] [00:13:07/00:25:45, 0.758s/it]: train_loss_raw=0.3428, running_loss=0.3657, LR=0.000100
[2025-08-27 14:20:20,734][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074968] [Batch 01048/03080] [00:13:13/00:25:39, 0.758s/it]: train_loss_raw=0.3519, running_loss=0.3637, LR=0.000100
[2025-08-27 14:20:26,713][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074976] [Batch 01056/03080] [00:13:19/00:25:33, 0.758s/it]: train_loss_raw=0.3897, running_loss=0.3651, LR=0.000100
[2025-08-27 14:20:32,822][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074984] [Batch 01064/03080] [00:13:26/00:25:27, 0.758s/it]: train_loss_raw=0.3452, running_loss=0.3641, LR=0.000100
[2025-08-27 14:20:38,888][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074992] [Batch 01072/03080] [00:13:32/00:25:21, 0.758s/it]: train_loss_raw=0.3826, running_loss=0.3655, LR=0.000100
[2025-08-27 14:20:44,991][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075000] [Batch 01080/03080] [00:13:38/00:25:15, 0.758s/it]: train_loss_raw=0.3018, running_loss=0.3640, LR=0.000100
[2025-08-27 14:20:51,066][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075008] [Batch 01088/03080] [00:13:44/00:25:09, 0.758s/it]: train_loss_raw=0.4283, running_loss=0.3677, LR=0.000100
[2025-08-27 14:20:57,151][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075016] [Batch 01096/03080] [00:13:50/00:25:03, 0.758s/it]: train_loss_raw=0.3560, running_loss=0.3698, LR=0.000100
[2025-08-27 14:21:03,222][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075024] [Batch 01104/03080] [00:13:56/00:24:57, 0.758s/it]: train_loss_raw=0.3496, running_loss=0.3694, LR=0.000100
[2025-08-27 14:21:09,497][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075032] [Batch 01112/03080] [00:14:02/00:24:51, 0.758s/it]: train_loss_raw=0.3862, running_loss=0.3718, LR=0.000100
[2025-08-27 14:21:15,697][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075040] [Batch 01120/03080] [00:14:08/00:24:45, 0.758s/it]: train_loss_raw=0.3754, running_loss=0.3722, LR=0.000100
[2025-08-27 14:21:21,708][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075048] [Batch 01128/03080] [00:14:14/00:24:39, 0.758s/it]: train_loss_raw=0.3419, running_loss=0.3735, LR=0.000100
[2025-08-27 14:21:27,733][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075056] [Batch 01136/03080] [00:14:20/00:24:33, 0.758s/it]: train_loss_raw=0.3705, running_loss=0.3733, LR=0.000100
[2025-08-27 14:21:33,868][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075064] [Batch 01144/03080] [00:14:27/00:24:27, 0.758s/it]: train_loss_raw=0.2913, running_loss=0.3732, LR=0.000100
[2025-08-27 14:21:39,867][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075072] [Batch 01152/03080] [00:14:33/00:24:21, 0.758s/it]: train_loss_raw=0.4489, running_loss=0.3743, LR=0.000100
[2025-08-27 14:21:45,964][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075080] [Batch 01160/03080] [00:14:39/00:24:15, 0.758s/it]: train_loss_raw=0.4048, running_loss=0.3754, LR=0.000100
[2025-08-27 14:21:51,963][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075088] [Batch 01168/03080] [00:14:45/00:24:09, 0.758s/it]: train_loss_raw=0.4001, running_loss=0.3743, LR=0.000100
[2025-08-27 14:21:57,988][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075096] [Batch 01176/03080] [00:14:51/00:24:02, 0.758s/it]: train_loss_raw=0.3797, running_loss=0.3758, LR=0.000100
[2025-08-27 14:22:04,061][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075104] [Batch 01184/03080] [00:14:57/00:23:56, 0.758s/it]: train_loss_raw=0.2980, running_loss=0.3751, LR=0.000100
[2025-08-27 14:22:10,095][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075112] [Batch 01192/03080] [00:15:03/00:23:50, 0.758s/it]: train_loss_raw=0.3434, running_loss=0.3743, LR=0.000100
[2025-08-27 14:22:16,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075120] [Batch 01200/03080] [00:15:09/00:23:44, 0.758s/it]: train_loss_raw=0.4496, running_loss=0.3738, LR=0.000100
[2025-08-27 14:22:22,128][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075128] [Batch 01208/03080] [00:15:15/00:23:38, 0.758s/it]: train_loss_raw=0.4021, running_loss=0.3744, LR=0.000100
[2025-08-27 14:22:27,804][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075136] [Batch 01216/03080] [00:15:21/00:23:31, 0.757s/it]: train_loss_raw=0.4061, running_loss=0.3729, LR=0.000100
[2025-08-27 14:22:33,328][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075144] [Batch 01224/03080] [00:15:26/00:23:24, 0.757s/it]: train_loss_raw=0.3930, running_loss=0.3741, LR=0.000100
[2025-08-27 14:22:39,081][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075152] [Batch 01232/03080] [00:15:32/00:23:18, 0.757s/it]: train_loss_raw=0.3783, running_loss=0.3754, LR=0.000100
[2025-08-27 14:22:45,068][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075160] [Batch 01240/03080] [00:15:38/00:23:12, 0.757s/it]: train_loss_raw=0.3517, running_loss=0.3752, LR=0.000100
[2025-08-27 14:22:51,069][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075168] [Batch 01248/03080] [00:15:44/00:23:06, 0.757s/it]: train_loss_raw=0.3585, running_loss=0.3743, LR=0.000100
[2025-08-27 14:22:57,055][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075176] [Batch 01256/03080] [00:15:50/00:23:00, 0.757s/it]: train_loss_raw=0.4407, running_loss=0.3744, LR=0.000100
[2025-08-27 14:23:03,037][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075184] [Batch 01264/03080] [00:15:56/00:22:53, 0.757s/it]: train_loss_raw=0.2549, running_loss=0.3739, LR=0.000100
[2025-08-27 14:23:09,064][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075192] [Batch 01272/03080] [00:16:02/00:22:47, 0.757s/it]: train_loss_raw=0.3428, running_loss=0.3739, LR=0.000100
[2025-08-27 14:23:15,214][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075200] [Batch 01280/03080] [00:16:08/00:22:41, 0.757s/it]: train_loss_raw=0.3346, running_loss=0.3763, LR=0.000100
[2025-08-27 14:23:21,324][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075208] [Batch 01288/03080] [00:16:14/00:22:35, 0.757s/it]: train_loss_raw=0.3529, running_loss=0.3758, LR=0.000100
[2025-08-27 14:23:27,374][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075216] [Batch 01296/03080] [00:16:20/00:22:29, 0.757s/it]: train_loss_raw=0.3597, running_loss=0.3742, LR=0.000100
[2025-08-27 14:23:33,404][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075224] [Batch 01304/03080] [00:16:26/00:22:23, 0.757s/it]: train_loss_raw=0.3372, running_loss=0.3734, LR=0.000100
[2025-08-27 14:23:39,399][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075232] [Batch 01312/03080] [00:16:32/00:22:17, 0.757s/it]: train_loss_raw=0.3789, running_loss=0.3735, LR=0.000100
[2025-08-27 14:23:44,830][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075240] [Batch 01320/03080] [00:16:38/00:22:10, 0.756s/it]: train_loss_raw=0.3085, running_loss=0.3721, LR=0.000100
[2025-08-27 14:23:50,849][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075248] [Batch 01328/03080] [00:16:44/00:22:04, 0.756s/it]: train_loss_raw=0.3365, running_loss=0.3706, LR=0.000100
[2025-08-27 14:23:56,332][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075256] [Batch 01336/03080] [00:16:49/00:21:57, 0.756s/it]: train_loss_raw=0.3883, running_loss=0.3706, LR=0.000100
[2025-08-27 14:24:02,214][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075264] [Batch 01344/03080] [00:16:55/00:21:51, 0.756s/it]: train_loss_raw=0.4730, running_loss=0.3718, LR=0.000100
[2025-08-27 14:24:08,253][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075272] [Batch 01352/03080] [00:17:01/00:21:45, 0.756s/it]: train_loss_raw=0.3276, running_loss=0.3712, LR=0.000100
[2025-08-27 14:24:14,248][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075280] [Batch 01360/03080] [00:17:07/00:21:39, 0.755s/it]: train_loss_raw=0.3211, running_loss=0.3703, LR=0.000100
[2025-08-27 14:24:20,292][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075288] [Batch 01368/03080] [00:17:13/00:21:33, 0.755s/it]: train_loss_raw=0.3644, running_loss=0.3682, LR=0.000100
[2025-08-27 14:24:26,535][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075296] [Batch 01376/03080] [00:17:19/00:21:27, 0.756s/it]: train_loss_raw=0.3673, running_loss=0.3688, LR=0.000100
[2025-08-27 14:24:32,581][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075304] [Batch 01384/03080] [00:17:25/00:21:21, 0.756s/it]: train_loss_raw=0.4566, running_loss=0.3688, LR=0.000100
[2025-08-27 14:24:38,536][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075312] [Batch 01392/03080] [00:17:31/00:21:15, 0.756s/it]: train_loss_raw=0.2739, running_loss=0.3678, LR=0.000100
[2025-08-27 14:24:44,399][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075320] [Batch 01400/03080] [00:17:37/00:21:09, 0.755s/it]: train_loss_raw=0.4007, running_loss=0.3684, LR=0.000100
[2025-08-27 14:24:50,506][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075328] [Batch 01408/03080] [00:17:43/00:21:03, 0.755s/it]: train_loss_raw=0.4176, running_loss=0.3700, LR=0.000100
[2025-08-27 14:24:56,544][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075336] [Batch 01416/03080] [00:17:49/00:20:57, 0.755s/it]: train_loss_raw=0.4436, running_loss=0.3702, LR=0.000100
[2025-08-27 14:25:02,543][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075344] [Batch 01424/03080] [00:17:55/00:20:51, 0.755s/it]: train_loss_raw=0.3242, running_loss=0.3715, LR=0.000100
[2025-08-27 14:25:08,563][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075352] [Batch 01432/03080] [00:18:01/00:20:44, 0.755s/it]: train_loss_raw=0.4163, running_loss=0.3711, LR=0.000100
[2025-08-27 14:25:14,541][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075360] [Batch 01440/03080] [00:18:07/00:20:38, 0.755s/it]: train_loss_raw=0.4239, running_loss=0.3712, LR=0.000100
[2025-08-27 14:25:20,312][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075368] [Batch 01448/03080] [00:18:13/00:20:32, 0.755s/it]: train_loss_raw=0.3606, running_loss=0.3693, LR=0.000100
[2025-08-27 14:25:25,733][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075376] [Batch 01456/03080] [00:18:18/00:20:25, 0.755s/it]: train_loss_raw=0.3388, running_loss=0.3686, LR=0.000100
[2025-08-27 14:25:31,157][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075384] [Batch 01464/03080] [00:18:24/00:20:19, 0.754s/it]: train_loss_raw=0.3534, running_loss=0.3684, LR=0.000100
[2025-08-27 14:25:36,972][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075392] [Batch 01472/03080] [00:18:30/00:20:12, 0.754s/it]: train_loss_raw=0.3697, running_loss=0.3678, LR=0.000100
[2025-08-27 14:25:42,990][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075400] [Batch 01480/03080] [00:18:36/00:20:06, 0.754s/it]: train_loss_raw=0.3390, running_loss=0.3667, LR=0.000100
[2025-08-27 14:25:48,834][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075408] [Batch 01488/03080] [00:18:42/00:20:00, 0.754s/it]: train_loss_raw=0.4125, running_loss=0.3671, LR=0.000100
[2025-08-27 14:25:54,739][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075416] [Batch 01496/03080] [00:18:47/00:19:54, 0.754s/it]: train_loss_raw=0.4367, running_loss=0.3668, LR=0.000100
[2025-08-27 14:26:00,843][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075424] [Batch 01504/03080] [00:18:54/00:19:48, 0.754s/it]: train_loss_raw=0.3007, running_loss=0.3660, LR=0.000100
[2025-08-27 14:26:06,927][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075432] [Batch 01512/03080] [00:19:00/00:19:42, 0.754s/it]: train_loss_raw=0.3403, running_loss=0.3653, LR=0.000100
[2025-08-27 14:26:12,897][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075440] [Batch 01520/03080] [00:19:06/00:19:36, 0.754s/it]: train_loss_raw=0.3530, running_loss=0.3655, LR=0.000100
[2025-08-27 14:26:18,863][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075448] [Batch 01528/03080] [00:19:12/00:19:30, 0.754s/it]: train_loss_raw=0.3115, running_loss=0.3681, LR=0.000100
[2025-08-27 14:26:24,834][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075456] [Batch 01536/03080] [00:19:18/00:19:24, 0.754s/it]: train_loss_raw=0.3468, running_loss=0.3674, LR=0.000100
[2025-08-27 14:26:30,860][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075464] [Batch 01544/03080] [00:19:24/00:19:18, 0.754s/it]: train_loss_raw=0.3105, running_loss=0.3668, LR=0.000100
[2025-08-27 14:26:36,847][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075472] [Batch 01552/03080] [00:19:30/00:19:11, 0.754s/it]: train_loss_raw=0.3431, running_loss=0.3664, LR=0.000100
[2025-08-27 14:26:43,016][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075480] [Batch 01560/03080] [00:19:36/00:19:06, 0.754s/it]: train_loss_raw=0.3881, running_loss=0.3688, LR=0.000100
[2025-08-27 14:26:49,041][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075488] [Batch 01568/03080] [00:19:42/00:19:00, 0.754s/it]: train_loss_raw=0.3823, running_loss=0.3674, LR=0.000100
[2025-08-27 14:26:55,126][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075496] [Batch 01576/03080] [00:19:48/00:18:54, 0.754s/it]: train_loss_raw=0.4014, running_loss=0.3683, LR=0.000100
[2025-08-27 14:27:01,139][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075504] [Batch 01584/03080] [00:19:54/00:18:48, 0.754s/it]: train_loss_raw=0.3404, running_loss=0.3667, LR=0.000100
[2025-08-27 14:27:07,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075512] [Batch 01592/03080] [00:20:00/00:18:42, 0.754s/it]: train_loss_raw=0.4045, running_loss=0.3667, LR=0.000100
[2025-08-27 14:27:13,386][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075520] [Batch 01600/03080] [00:20:06/00:18:36, 0.754s/it]: train_loss_raw=0.4020, running_loss=0.3690, LR=0.000100
[2025-08-27 14:27:18,851][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075528] [Batch 01608/03080] [00:20:12/00:18:29, 0.754s/it]: train_loss_raw=0.3131, running_loss=0.3690, LR=0.000100
[2025-08-27 14:27:24,377][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075536] [Batch 01616/03080] [00:20:17/00:18:23, 0.753s/it]: train_loss_raw=0.3919, running_loss=0.3693, LR=0.000100
[2025-08-27 14:27:30,483][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075544] [Batch 01624/03080] [00:20:23/00:18:17, 0.754s/it]: train_loss_raw=0.4488, running_loss=0.3712, LR=0.000100
[2025-08-27 14:27:36,359][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075552] [Batch 01632/03080] [00:20:29/00:18:10, 0.753s/it]: train_loss_raw=0.3297, running_loss=0.3716, LR=0.000100
[2025-08-27 14:27:42,343][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075560] [Batch 01640/03080] [00:20:35/00:18:04, 0.753s/it]: train_loss_raw=0.3472, running_loss=0.3702, LR=0.000100
[2025-08-27 14:27:48,596][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075568] [Batch 01648/03080] [00:20:41/00:17:59, 0.754s/it]: train_loss_raw=0.4017, running_loss=0.3696, LR=0.000100
[2025-08-27 14:27:54,627][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075576] [Batch 01656/03080] [00:20:47/00:17:53, 0.754s/it]: train_loss_raw=0.3815, running_loss=0.3718, LR=0.000100
[2025-08-27 14:28:00,688][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075584] [Batch 01664/03080] [00:20:53/00:17:47, 0.754s/it]: train_loss_raw=0.4037, running_loss=0.3734, LR=0.000100
[2025-08-27 14:28:06,661][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075592] [Batch 01672/03080] [00:20:59/00:17:40, 0.754s/it]: train_loss_raw=0.3805, running_loss=0.3734, LR=0.000100
[2025-08-27 14:28:12,616][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075600] [Batch 01680/03080] [00:21:05/00:17:34, 0.753s/it]: train_loss_raw=0.3548, running_loss=0.3724, LR=0.000100
[2025-08-27 14:28:18,632][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075608] [Batch 01688/03080] [00:21:11/00:17:28, 0.753s/it]: train_loss_raw=0.3523, running_loss=0.3731, LR=0.000100
[2025-08-27 14:28:24,568][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075616] [Batch 01696/03080] [00:21:17/00:17:22, 0.753s/it]: train_loss_raw=0.3232, running_loss=0.3729, LR=0.000100
[2025-08-27 14:28:30,517][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075624] [Batch 01704/03080] [00:21:23/00:17:16, 0.753s/it]: train_loss_raw=0.4159, running_loss=0.3733, LR=0.000100
[2025-08-27 14:28:36,740][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075632] [Batch 01712/03080] [00:21:29/00:17:10, 0.753s/it]: train_loss_raw=0.4128, running_loss=0.3739, LR=0.000100
[2025-08-27 14:28:42,964][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075640] [Batch 01720/03080] [00:21:36/00:17:04, 0.754s/it]: train_loss_raw=0.3297, running_loss=0.3748, LR=0.000100
[2025-08-27 14:28:49,080][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075648] [Batch 01728/03080] [00:21:42/00:16:58, 0.754s/it]: train_loss_raw=0.3770, running_loss=0.3766, LR=0.000100
[2025-08-27 14:28:55,113][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075656] [Batch 01736/03080] [00:21:48/00:16:52, 0.754s/it]: train_loss_raw=0.3320, running_loss=0.3764, LR=0.000100
[2025-08-27 14:29:01,106][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075664] [Batch 01744/03080] [00:21:54/00:16:46, 0.754s/it]: train_loss_raw=0.3578, running_loss=0.3762, LR=0.000100
[2025-08-27 14:29:07,136][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075672] [Batch 01752/03080] [00:22:00/00:16:40, 0.754s/it]: train_loss_raw=0.3155, running_loss=0.3743, LR=0.000100
[2025-08-27 14:29:13,394][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075680] [Batch 01760/03080] [00:22:06/00:16:34, 0.754s/it]: train_loss_raw=0.3550, running_loss=0.3731, LR=0.000100
[2025-08-27 14:29:19,436][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075688] [Batch 01768/03080] [00:22:12/00:16:28, 0.754s/it]: train_loss_raw=0.3751, running_loss=0.3733, LR=0.000100
[2025-08-27 14:29:25,397][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075696] [Batch 01776/03080] [00:22:18/00:16:22, 0.754s/it]: train_loss_raw=0.3130, running_loss=0.3723, LR=0.000100
[2025-08-27 14:29:31,297][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075704] [Batch 01784/03080] [00:22:24/00:16:16, 0.754s/it]: train_loss_raw=0.3459, running_loss=0.3719, LR=0.000100
[2025-08-27 14:29:37,199][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075712] [Batch 01792/03080] [00:22:30/00:16:10, 0.754s/it]: train_loss_raw=0.3167, running_loss=0.3721, LR=0.000100
[2025-08-27 14:29:42,957][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075720] [Batch 01800/03080] [00:22:36/00:16:04, 0.753s/it]: train_loss_raw=0.3350, running_loss=0.3697, LR=0.000100
[2025-08-27 14:29:48,926][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075728] [Batch 01808/03080] [00:22:42/00:15:58, 0.753s/it]: train_loss_raw=0.4393, running_loss=0.3702, LR=0.000100
[2025-08-27 14:29:54,861][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075736] [Batch 01816/03080] [00:22:48/00:15:52, 0.753s/it]: train_loss_raw=0.3397, running_loss=0.3706, LR=0.000100
[2025-08-27 14:30:00,875][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075744] [Batch 01824/03080] [00:22:54/00:15:46, 0.753s/it]: train_loss_raw=0.4287, running_loss=0.3693, LR=0.000100
[2025-08-27 14:30:06,813][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075752] [Batch 01832/03080] [00:23:00/00:15:40, 0.753s/it]: train_loss_raw=0.3029, running_loss=0.3694, LR=0.000100
[2025-08-27 14:30:12,727][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075760] [Batch 01840/03080] [00:23:05/00:15:34, 0.753s/it]: train_loss_raw=0.4344, running_loss=0.3716, LR=0.000100
[2025-08-27 14:30:18,754][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075768] [Batch 01848/03080] [00:23:11/00:15:27, 0.753s/it]: train_loss_raw=0.4233, running_loss=0.3714, LR=0.000100
[2025-08-27 14:30:24,662][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075776] [Batch 01856/03080] [00:23:17/00:15:21, 0.753s/it]: train_loss_raw=0.3218, running_loss=0.3691, LR=0.000100
[2025-08-27 14:30:30,635][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075784] [Batch 01864/03080] [00:23:23/00:15:15, 0.753s/it]: train_loss_raw=0.4201, running_loss=0.3713, LR=0.000100
[2025-08-27 14:30:36,634][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075792] [Batch 01872/03080] [00:23:29/00:15:09, 0.753s/it]: train_loss_raw=0.3858, running_loss=0.3698, LR=0.000100
[2025-08-27 14:30:42,630][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075800] [Batch 01880/03080] [00:23:35/00:15:03, 0.753s/it]: train_loss_raw=0.3059, running_loss=0.3704, LR=0.000100
[2025-08-27 14:30:48,655][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075808] [Batch 01888/03080] [00:23:41/00:14:57, 0.753s/it]: train_loss_raw=0.3816, running_loss=0.3719, LR=0.000100
[2025-08-27 14:30:54,750][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075816] [Batch 01896/03080] [00:23:47/00:14:51, 0.753s/it]: train_loss_raw=0.4095, running_loss=0.3718, LR=0.000100
[2025-08-27 14:31:00,730][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075824] [Batch 01904/03080] [00:23:53/00:14:45, 0.753s/it]: train_loss_raw=0.2979, running_loss=0.3712, LR=0.000100
[2025-08-27 14:31:06,598][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075832] [Batch 01912/03080] [00:23:59/00:14:39, 0.753s/it]: train_loss_raw=0.3664, running_loss=0.3718, LR=0.000100
[2025-08-27 14:31:12,645][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075840] [Batch 01920/03080] [00:24:05/00:14:33, 0.753s/it]: train_loss_raw=0.3791, running_loss=0.3722, LR=0.000100
[2025-08-27 14:31:18,480][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075848] [Batch 01928/03080] [00:24:11/00:14:27, 0.753s/it]: train_loss_raw=0.4029, running_loss=0.3719, LR=0.000100
[2025-08-27 14:31:24,448][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075856] [Batch 01936/03080] [00:24:17/00:14:21, 0.753s/it]: train_loss_raw=0.2598, running_loss=0.3724, LR=0.000100
[2025-08-27 14:31:30,577][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075864] [Batch 01944/03080] [00:24:23/00:14:15, 0.753s/it]: train_loss_raw=0.4307, running_loss=0.3732, LR=0.000100
[2025-08-27 14:31:36,729][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075872] [Batch 01952/03080] [00:24:29/00:14:09, 0.753s/it]: train_loss_raw=0.3681, running_loss=0.3733, LR=0.000100
[2025-08-27 14:31:42,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075880] [Batch 01960/03080] [00:24:35/00:14:03, 0.753s/it]: train_loss_raw=0.2950, running_loss=0.3746, LR=0.000100
[2025-08-27 14:31:48,915][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075888] [Batch 01968/03080] [00:24:42/00:13:57, 0.753s/it]: train_loss_raw=0.4513, running_loss=0.3751, LR=0.000100
[2025-08-27 14:31:55,051][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075896] [Batch 01976/03080] [00:24:48/00:13:51, 0.753s/it]: train_loss_raw=0.3896, running_loss=0.3747, LR=0.000100
[2025-08-27 14:32:00,940][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075904] [Batch 01984/03080] [00:24:54/00:13:45, 0.753s/it]: train_loss_raw=0.3543, running_loss=0.3726, LR=0.000100
[2025-08-27 14:32:07,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075912] [Batch 01992/03080] [00:25:00/00:13:39, 0.753s/it]: train_loss_raw=0.3725, running_loss=0.3712, LR=0.000100
[2025-08-27 14:32:13,098][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075920] [Batch 02000/03080] [00:25:06/00:13:33, 0.753s/it]: train_loss_raw=0.4412, running_loss=0.3711, LR=0.000100
[2025-08-27 14:32:19,121][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075928] [Batch 02008/03080] [00:25:12/00:13:27, 0.753s/it]: train_loss_raw=0.3449, running_loss=0.3704, LR=0.000100
[2025-08-27 14:32:25,160][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075936] [Batch 02016/03080] [00:25:18/00:13:21, 0.753s/it]: train_loss_raw=0.4335, running_loss=0.3709, LR=0.000100
[2025-08-27 14:32:31,320][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075944] [Batch 02024/03080] [00:25:24/00:13:15, 0.753s/it]: train_loss_raw=0.3688, running_loss=0.3704, LR=0.000100
[2025-08-27 14:32:37,395][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075952] [Batch 02032/03080] [00:25:30/00:13:09, 0.753s/it]: train_loss_raw=0.3662, running_loss=0.3722, LR=0.000100
[2025-08-27 14:32:43,338][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075960] [Batch 02040/03080] [00:25:36/00:13:03, 0.753s/it]: train_loss_raw=0.3817, running_loss=0.3702, LR=0.000100
[2025-08-27 14:32:49,235][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075968] [Batch 02048/03080] [00:25:42/00:12:57, 0.753s/it]: train_loss_raw=0.2994, running_loss=0.3674, LR=0.000100
[2025-08-27 14:32:55,188][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075976] [Batch 02056/03080] [00:25:48/00:12:51, 0.753s/it]: train_loss_raw=0.3616, running_loss=0.3690, LR=0.000100
[2025-08-27 14:33:01,351][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075984] [Batch 02064/03080] [00:25:54/00:12:45, 0.753s/it]: train_loss_raw=0.3034, running_loss=0.3682, LR=0.000100
[2025-08-27 14:33:07,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075992] [Batch 02072/03080] [00:26:00/00:12:39, 0.753s/it]: train_loss_raw=0.3840, running_loss=0.3693, LR=0.000100
[2025-08-27 14:33:13,299][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076000] [Batch 02080/03080] [00:26:06/00:12:33, 0.753s/it]: train_loss_raw=0.4549, running_loss=0.3717, LR=0.000100
[2025-08-27 14:33:23,475][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076008] [Batch 02088/03080] [00:26:16/00:12:29, 0.755s/it]: train_loss_raw=0.4104, running_loss=0.3709, LR=0.000100
[2025-08-27 14:33:29,110][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076016] [Batch 02096/03080] [00:26:22/00:12:22, 0.755s/it]: train_loss_raw=0.3995, running_loss=0.3707, LR=0.000100
[2025-08-27 14:33:34,874][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076024] [Batch 02104/03080] [00:26:28/00:12:16, 0.755s/it]: train_loss_raw=0.3756, running_loss=0.3708, LR=0.000100
[2025-08-27 14:33:41,021][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076032] [Batch 02112/03080] [00:26:34/00:12:10, 0.755s/it]: train_loss_raw=0.3585, running_loss=0.3702, LR=0.000100
[2025-08-27 14:33:47,240][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076040] [Batch 02120/03080] [00:26:40/00:12:04, 0.755s/it]: train_loss_raw=0.3058, running_loss=0.3695, LR=0.000100
[2025-08-27 14:33:53,324][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076048] [Batch 02128/03080] [00:26:46/00:11:58, 0.755s/it]: train_loss_raw=0.3323, running_loss=0.3697, LR=0.000100
[2025-08-27 14:33:59,214][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076056] [Batch 02136/03080] [00:26:52/00:11:52, 0.755s/it]: train_loss_raw=0.3727, running_loss=0.3695, LR=0.000100
[2025-08-27 14:34:04,793][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076064] [Batch 02144/03080] [00:26:58/00:11:46, 0.755s/it]: train_loss_raw=0.3680, running_loss=0.3692, LR=0.000100
[2025-08-27 14:34:10,828][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076072] [Batch 02152/03080] [00:27:04/00:11:40, 0.755s/it]: train_loss_raw=0.3607, running_loss=0.3700, LR=0.000100
[2025-08-27 14:34:16,258][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076080] [Batch 02160/03080] [00:27:09/00:11:34, 0.754s/it]: train_loss_raw=0.3812, running_loss=0.3678, LR=0.000100
[2025-08-27 14:34:21,936][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076088] [Batch 02168/03080] [00:27:15/00:11:27, 0.754s/it]: train_loss_raw=0.4078, running_loss=0.3673, LR=0.000100
[2025-08-27 14:34:27,891][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076096] [Batch 02176/03080] [00:27:21/00:11:21, 0.754s/it]: train_loss_raw=0.4442, running_loss=0.3671, LR=0.000100
[2025-08-27 14:34:33,994][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076104] [Batch 02184/03080] [00:27:27/00:11:15, 0.754s/it]: train_loss_raw=0.3271, running_loss=0.3695, LR=0.000100
[2025-08-27 14:34:39,793][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076112] [Batch 02192/03080] [00:27:33/00:11:09, 0.754s/it]: train_loss_raw=0.3300, running_loss=0.3703, LR=0.000100
[2025-08-27 14:34:45,856][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076120] [Batch 02200/03080] [00:27:39/00:11:03, 0.754s/it]: train_loss_raw=0.2902, running_loss=0.3707, LR=0.000100
[2025-08-27 14:34:51,553][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076128] [Batch 02208/03080] [00:27:44/00:10:57, 0.754s/it]: train_loss_raw=0.3636, running_loss=0.3715, LR=0.000100
[2025-08-27 14:34:57,519][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076136] [Batch 02216/03080] [00:27:50/00:10:51, 0.754s/it]: train_loss_raw=0.3623, running_loss=0.3710, LR=0.000100
[2025-08-27 14:35:03,640][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076144] [Batch 02224/03080] [00:27:56/00:10:45, 0.754s/it]: train_loss_raw=0.3759, running_loss=0.3693, LR=0.000100
[2025-08-27 14:35:09,911][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076152] [Batch 02232/03080] [00:28:03/00:10:39, 0.754s/it]: train_loss_raw=0.4425, running_loss=0.3699, LR=0.000100
[2025-08-27 14:35:16,035][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076160] [Batch 02240/03080] [00:28:09/00:10:33, 0.754s/it]: train_loss_raw=0.3624, running_loss=0.3699, LR=0.000100
[2025-08-27 14:35:21,904][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076168] [Batch 02248/03080] [00:28:15/00:10:27, 0.754s/it]: train_loss_raw=0.4175, running_loss=0.3707, LR=0.000100
[2025-08-27 14:35:27,819][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076176] [Batch 02256/03080] [00:28:21/00:10:21, 0.754s/it]: train_loss_raw=0.4136, running_loss=0.3722, LR=0.000100
[2025-08-27 14:35:33,748][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076184] [Batch 02264/03080] [00:28:26/00:10:15, 0.754s/it]: train_loss_raw=0.3478, running_loss=0.3728, LR=0.000100
[2025-08-27 14:35:39,762][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076192] [Batch 02272/03080] [00:28:32/00:10:09, 0.754s/it]: train_loss_raw=0.3588, running_loss=0.3706, LR=0.000100
[2025-08-27 14:35:45,740][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076200] [Batch 02280/03080] [00:28:38/00:10:03, 0.754s/it]: train_loss_raw=0.3153, running_loss=0.3694, LR=0.000100
[2025-08-27 14:35:51,756][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076208] [Batch 02288/03080] [00:28:44/00:09:57, 0.754s/it]: train_loss_raw=0.3640, running_loss=0.3681, LR=0.000100
[2025-08-27 14:35:57,806][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076216] [Batch 02296/03080] [00:28:51/00:09:51, 0.754s/it]: train_loss_raw=0.3239, running_loss=0.3692, LR=0.000100
[2025-08-27 14:36:03,875][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076224] [Batch 02304/03080] [00:28:57/00:09:45, 0.754s/it]: train_loss_raw=0.3437, running_loss=0.3673, LR=0.000100
[2025-08-27 14:36:09,604][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076232] [Batch 02312/03080] [00:29:02/00:09:38, 0.754s/it]: train_loss_raw=0.3795, running_loss=0.3673, LR=0.000100
[2025-08-27 14:36:15,203][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076240] [Batch 02320/03080] [00:29:08/00:09:32, 0.754s/it]: train_loss_raw=0.5004, running_loss=0.3675, LR=0.000100
[2025-08-27 14:36:20,798][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076248] [Batch 02328/03080] [00:29:14/00:09:26, 0.753s/it]: train_loss_raw=0.3399, running_loss=0.3687, LR=0.000100
[2025-08-27 14:36:26,500][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076256] [Batch 02336/03080] [00:29:19/00:09:20, 0.753s/it]: train_loss_raw=0.3854, running_loss=0.3696, LR=0.000100
[2025-08-27 14:36:32,539][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076264] [Batch 02344/03080] [00:29:25/00:09:14, 0.753s/it]: train_loss_raw=0.3519, running_loss=0.3681, LR=0.000100
[2025-08-27 14:36:38,624][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076272] [Batch 02352/03080] [00:29:31/00:09:08, 0.753s/it]: train_loss_raw=0.2798, running_loss=0.3665, LR=0.000100
[2025-08-27 14:36:44,671][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076280] [Batch 02360/03080] [00:29:37/00:09:02, 0.753s/it]: train_loss_raw=0.4597, running_loss=0.3699, LR=0.000100
[2025-08-27 14:36:50,721][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076288] [Batch 02368/03080] [00:29:43/00:08:56, 0.753s/it]: train_loss_raw=0.3554, running_loss=0.3692, LR=0.000100
[2025-08-27 14:36:56,769][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076296] [Batch 02376/03080] [00:29:49/00:08:50, 0.753s/it]: train_loss_raw=0.3640, running_loss=0.3669, LR=0.000100
[2025-08-27 14:37:02,894][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076304] [Batch 02384/03080] [00:29:56/00:08:44, 0.753s/it]: train_loss_raw=0.4207, running_loss=0.3667, LR=0.000100
[2025-08-27 14:37:09,073][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076312] [Batch 02392/03080] [00:30:02/00:08:38, 0.753s/it]: train_loss_raw=0.4083, running_loss=0.3684, LR=0.000100
[2025-08-27 14:37:15,118][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076320] [Batch 02400/03080] [00:30:08/00:08:32, 0.753s/it]: train_loss_raw=0.3244, running_loss=0.3667, LR=0.000100
[2025-08-27 14:37:21,218][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076328] [Batch 02408/03080] [00:30:14/00:08:26, 0.754s/it]: train_loss_raw=0.4096, running_loss=0.3679, LR=0.000100
[2025-08-27 14:37:27,115][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076336] [Batch 02416/03080] [00:30:20/00:08:20, 0.753s/it]: train_loss_raw=0.3193, running_loss=0.3683, LR=0.000100
[2025-08-27 14:37:33,072][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076344] [Batch 02424/03080] [00:30:26/00:08:14, 0.753s/it]: train_loss_raw=0.3669, running_loss=0.3683, LR=0.000100
[2025-08-27 14:37:39,041][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076352] [Batch 02432/03080] [00:30:32/00:08:08, 0.753s/it]: train_loss_raw=0.3728, running_loss=0.3689, LR=0.000100
[2025-08-27 14:37:44,841][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076360] [Batch 02440/03080] [00:30:38/00:08:02, 0.753s/it]: train_loss_raw=0.3057, running_loss=0.3687, LR=0.000100
[2025-08-27 14:37:50,805][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076368] [Batch 02448/03080] [00:30:44/00:07:56, 0.753s/it]: train_loss_raw=0.3554, running_loss=0.3689, LR=0.000100
[2025-08-27 14:37:56,742][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076376] [Batch 02456/03080] [00:30:49/00:07:50, 0.753s/it]: train_loss_raw=0.2980, running_loss=0.3691, LR=0.000100
[2025-08-27 14:38:02,780][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076384] [Batch 02464/03080] [00:30:56/00:07:44, 0.753s/it]: train_loss_raw=0.3278, running_loss=0.3709, LR=0.000100
[2025-08-27 14:38:08,898][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076392] [Batch 02472/03080] [00:31:02/00:07:37, 0.753s/it]: train_loss_raw=0.3775, running_loss=0.3717, LR=0.000100
[2025-08-27 14:38:14,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076400] [Batch 02480/03080] [00:31:08/00:07:31, 0.753s/it]: train_loss_raw=0.3908, running_loss=0.3732, LR=0.000100
[2025-08-27 14:38:20,948][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076408] [Batch 02488/03080] [00:31:14/00:07:25, 0.753s/it]: train_loss_raw=0.3911, running_loss=0.3722, LR=0.000100
[2025-08-27 14:38:27,015][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076416] [Batch 02496/03080] [00:31:20/00:07:19, 0.753s/it]: train_loss_raw=0.3219, running_loss=0.3722, LR=0.000100
[2025-08-27 14:38:33,230][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076424] [Batch 02504/03080] [00:31:26/00:07:13, 0.753s/it]: train_loss_raw=0.3735, running_loss=0.3727, LR=0.000100
[2025-08-27 14:38:39,352][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076432] [Batch 02512/03080] [00:31:32/00:07:07, 0.753s/it]: train_loss_raw=0.3507, running_loss=0.3726, LR=0.000100
[2025-08-27 14:38:45,433][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076440] [Batch 02520/03080] [00:31:38/00:07:01, 0.753s/it]: train_loss_raw=0.3756, running_loss=0.3727, LR=0.000100
[2025-08-27 14:38:51,412][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076448] [Batch 02528/03080] [00:31:44/00:06:55, 0.753s/it]: train_loss_raw=0.3446, running_loss=0.3715, LR=0.000100
[2025-08-27 14:38:57,391][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076456] [Batch 02536/03080] [00:31:50/00:06:49, 0.753s/it]: train_loss_raw=0.4285, running_loss=0.3705, LR=0.000100
[2025-08-27 14:39:03,551][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076464] [Batch 02544/03080] [00:31:56/00:06:43, 0.753s/it]: train_loss_raw=0.4082, running_loss=0.3703, LR=0.000100
[2025-08-27 14:39:09,550][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076472] [Batch 02552/03080] [00:32:02/00:06:37, 0.753s/it]: train_loss_raw=0.4604, running_loss=0.3716, LR=0.000100
[2025-08-27 14:39:15,189][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076480] [Batch 02560/03080] [00:32:08/00:06:31, 0.753s/it]: train_loss_raw=0.4092, running_loss=0.3712, LR=0.000100
[2025-08-27 14:39:21,193][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076488] [Batch 02568/03080] [00:32:14/00:06:25, 0.753s/it]: train_loss_raw=0.4332, running_loss=0.3712, LR=0.000100
[2025-08-27 14:39:27,173][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076496] [Batch 02576/03080] [00:32:20/00:06:19, 0.753s/it]: train_loss_raw=0.4028, running_loss=0.3734, LR=0.000100
[2025-08-27 14:39:33,349][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076504] [Batch 02584/03080] [00:32:26/00:06:13, 0.753s/it]: train_loss_raw=0.3541, running_loss=0.3734, LR=0.000100
[2025-08-27 14:39:39,276][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076512] [Batch 02592/03080] [00:32:32/00:06:07, 0.753s/it]: train_loss_raw=0.3010, running_loss=0.3708, LR=0.000100
[2025-08-27 14:39:44,840][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076520] [Batch 02600/03080] [00:32:38/00:06:01, 0.753s/it]: train_loss_raw=0.3919, running_loss=0.3714, LR=0.000100
[2025-08-27 14:39:50,588][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076528] [Batch 02608/03080] [00:32:43/00:05:55, 0.753s/it]: train_loss_raw=0.3098, running_loss=0.3702, LR=0.000100
[2025-08-27 14:39:56,395][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076536] [Batch 02616/03080] [00:32:49/00:05:49, 0.753s/it]: train_loss_raw=0.3788, running_loss=0.3709, LR=0.000100
[2025-08-27 14:40:02,366][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076544] [Batch 02624/03080] [00:32:55/00:05:43, 0.753s/it]: train_loss_raw=0.4001, running_loss=0.3746, LR=0.000100
[2025-08-27 14:40:08,416][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076552] [Batch 02632/03080] [00:33:01/00:05:37, 0.753s/it]: train_loss_raw=0.4259, running_loss=0.3742, LR=0.000100
[2025-08-27 14:40:13,799][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076560] [Batch 02640/03080] [00:33:07/00:05:31, 0.753s/it]: train_loss_raw=0.2904, running_loss=0.3711, LR=0.000100
[2025-08-27 14:40:19,432][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076568] [Batch 02648/03080] [00:33:12/00:05:25, 0.753s/it]: train_loss_raw=0.2978, running_loss=0.3694, LR=0.000100
[2025-08-27 14:40:25,410][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076576] [Batch 02656/03080] [00:33:18/00:05:19, 0.752s/it]: train_loss_raw=0.2904, running_loss=0.3666, LR=0.000100
[2025-08-27 14:40:30,831][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076584] [Batch 02664/03080] [00:33:24/00:05:12, 0.752s/it]: train_loss_raw=0.2633, running_loss=0.3668, LR=0.000100
[2025-08-27 14:40:36,604][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076592] [Batch 02672/03080] [00:33:29/00:05:06, 0.752s/it]: train_loss_raw=0.3497, running_loss=0.3667, LR=0.000100
[2025-08-27 14:40:42,181][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076600] [Batch 02680/03080] [00:33:35/00:05:00, 0.752s/it]: train_loss_raw=0.3624, running_loss=0.3666, LR=0.000100
[2025-08-27 14:40:48,049][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076608] [Batch 02688/03080] [00:33:41/00:04:54, 0.752s/it]: train_loss_raw=0.4212, running_loss=0.3678, LR=0.000100
[2025-08-27 14:40:53,741][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076616] [Batch 02696/03080] [00:33:46/00:04:48, 0.752s/it]: train_loss_raw=0.3179, running_loss=0.3695, LR=0.000100
[2025-08-27 14:40:59,360][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076624] [Batch 02704/03080] [00:33:52/00:04:42, 0.752s/it]: train_loss_raw=0.3348, running_loss=0.3712, LR=0.000100
[2025-08-27 14:41:05,028][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076632] [Batch 02712/03080] [00:33:58/00:04:36, 0.752s/it]: train_loss_raw=0.3276, running_loss=0.3703, LR=0.000100
[2025-08-27 14:41:11,289][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076640] [Batch 02720/03080] [00:34:04/00:04:30, 0.752s/it]: train_loss_raw=0.3792, running_loss=0.3693, LR=0.000100
[2025-08-27 14:41:17,178][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076648] [Batch 02728/03080] [00:34:10/00:04:24, 0.752s/it]: train_loss_raw=0.4239, running_loss=0.3689, LR=0.000100
[2025-08-27 14:41:23,162][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076656] [Batch 02736/03080] [00:34:16/00:04:18, 0.752s/it]: train_loss_raw=0.3695, running_loss=0.3698, LR=0.000100
[2025-08-27 14:41:28,595][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076664] [Batch 02744/03080] [00:34:21/00:04:12, 0.751s/it]: train_loss_raw=0.4273, running_loss=0.3697, LR=0.000100
[2025-08-27 14:41:34,573][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076672] [Batch 02752/03080] [00:34:27/00:04:06, 0.751s/it]: train_loss_raw=0.3249, running_loss=0.3712, LR=0.000100
[2025-08-27 14:41:40,573][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076680] [Batch 02760/03080] [00:34:33/00:04:00, 0.751s/it]: train_loss_raw=0.3697, running_loss=0.3711, LR=0.000100
[2025-08-27 14:41:46,415][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076688] [Batch 02768/03080] [00:34:39/00:03:54, 0.751s/it]: train_loss_raw=0.3790, running_loss=0.3697, LR=0.000100
[2025-08-27 14:41:52,359][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076696] [Batch 02776/03080] [00:34:45/00:03:48, 0.751s/it]: train_loss_raw=0.3108, running_loss=0.3716, LR=0.000100
[2025-08-27 14:41:58,532][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076704] [Batch 02784/03080] [00:34:51/00:03:42, 0.751s/it]: train_loss_raw=0.3469, running_loss=0.3724, LR=0.000100
[2025-08-27 14:42:04,836][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076712] [Batch 02792/03080] [00:34:58/00:03:36, 0.751s/it]: train_loss_raw=0.3794, running_loss=0.3722, LR=0.000100
[2025-08-27 14:42:10,693][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076720] [Batch 02800/03080] [00:35:03/00:03:30, 0.751s/it]: train_loss_raw=0.4040, running_loss=0.3724, LR=0.000100
[2025-08-27 14:42:16,655][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076728] [Batch 02808/03080] [00:35:09/00:03:24, 0.751s/it]: train_loss_raw=0.2892, running_loss=0.3703, LR=0.000100
[2025-08-27 14:42:22,448][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076736] [Batch 02816/03080] [00:35:15/00:03:18, 0.751s/it]: train_loss_raw=0.3138, running_loss=0.3687, LR=0.000100
[2025-08-27 14:42:28,479][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076744] [Batch 02824/03080] [00:35:21/00:03:12, 0.751s/it]: train_loss_raw=0.3561, running_loss=0.3677, LR=0.000100
[2025-08-27 14:42:34,083][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076752] [Batch 02832/03080] [00:35:27/00:03:06, 0.751s/it]: train_loss_raw=0.3428, running_loss=0.3662, LR=0.000100
[2025-08-27 14:42:39,668][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076760] [Batch 02840/03080] [00:35:32/00:03:00, 0.751s/it]: train_loss_raw=0.3282, running_loss=0.3639, LR=0.000100
[2025-08-27 14:42:45,738][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076768] [Batch 02848/03080] [00:35:38/00:02:54, 0.751s/it]: train_loss_raw=0.3503, running_loss=0.3651, LR=0.000100
[2025-08-27 14:42:51,540][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076776] [Batch 02856/03080] [00:35:44/00:02:48, 0.751s/it]: train_loss_raw=0.4843, running_loss=0.3656, LR=0.000100
[2025-08-27 14:42:57,818][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076784] [Batch 02864/03080] [00:35:51/00:02:42, 0.751s/it]: train_loss_raw=0.3577, running_loss=0.3678, LR=0.000100
[2025-08-27 14:43:03,790][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076792] [Batch 02872/03080] [00:35:57/00:02:36, 0.751s/it]: train_loss_raw=0.3798, running_loss=0.3688, LR=0.000100
[2025-08-27 14:43:09,801][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076800] [Batch 02880/03080] [00:36:03/00:02:30, 0.751s/it]: train_loss_raw=0.3930, running_loss=0.3684, LR=0.000100
[2025-08-27 14:43:15,728][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076808] [Batch 02888/03080] [00:36:08/00:02:24, 0.751s/it]: train_loss_raw=0.3564, running_loss=0.3677, LR=0.000100
[2025-08-27 14:43:22,075][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076816] [Batch 02896/03080] [00:36:15/00:02:18, 0.751s/it]: train_loss_raw=0.3629, running_loss=0.3666, LR=0.000100
[2025-08-27 14:43:28,190][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076824] [Batch 02904/03080] [00:36:21/00:02:12, 0.751s/it]: train_loss_raw=0.4066, running_loss=0.3682, LR=0.000100
[2025-08-27 14:43:34,532][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076832] [Batch 02912/03080] [00:36:27/00:02:06, 0.751s/it]: train_loss_raw=0.3930, running_loss=0.3692, LR=0.000100
[2025-08-27 14:43:40,593][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076840] [Batch 02920/03080] [00:36:33/00:02:00, 0.751s/it]: train_loss_raw=0.3440, running_loss=0.3687, LR=0.000100
[2025-08-27 14:43:46,645][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076848] [Batch 02928/03080] [00:36:39/00:01:54, 0.751s/it]: train_loss_raw=0.3591, running_loss=0.3695, LR=0.000100
[2025-08-27 14:43:52,697][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076856] [Batch 02936/03080] [00:36:45/00:01:48, 0.751s/it]: train_loss_raw=0.3678, running_loss=0.3707, LR=0.000100
[2025-08-27 14:43:58,767][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076864] [Batch 02944/03080] [00:36:51/00:01:42, 0.751s/it]: train_loss_raw=0.3279, running_loss=0.3696, LR=0.000100
[2025-08-27 14:44:04,686][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076872] [Batch 02952/03080] [00:36:57/00:01:36, 0.751s/it]: train_loss_raw=0.3757, running_loss=0.3698, LR=0.000100
[2025-08-27 14:44:10,422][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076880] [Batch 02960/03080] [00:37:03/00:01:30, 0.751s/it]: train_loss_raw=0.3558, running_loss=0.3692, LR=0.000100
[2025-08-27 14:44:16,502][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076888] [Batch 02968/03080] [00:37:09/00:01:24, 0.751s/it]: train_loss_raw=0.3242, running_loss=0.3677, LR=0.000100
[2025-08-27 14:44:22,643][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076896] [Batch 02976/03080] [00:37:15/00:01:18, 0.751s/it]: train_loss_raw=0.3135, running_loss=0.3677, LR=0.000100
[2025-08-27 14:44:28,740][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076904] [Batch 02984/03080] [00:37:21/00:01:12, 0.751s/it]: train_loss_raw=0.3061, running_loss=0.3675, LR=0.000100
[2025-08-27 14:44:34,601][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076912] [Batch 02992/03080] [00:37:27/00:01:06, 0.751s/it]: train_loss_raw=0.3657, running_loss=0.3668, LR=0.000100
[2025-08-27 14:44:40,608][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076920] [Batch 03000/03080] [00:37:33/00:01:00, 0.751s/it]: train_loss_raw=0.3538, running_loss=0.3658, LR=0.000100
[2025-08-27 14:44:46,575][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076928] [Batch 03008/03080] [00:37:39/00:00:54, 0.751s/it]: train_loss_raw=0.3694, running_loss=0.3671, LR=0.000100
[2025-08-27 14:44:52,770][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076936] [Batch 03016/03080] [00:37:45/00:00:48, 0.751s/it]: train_loss_raw=0.2844, running_loss=0.3675, LR=0.000100
[2025-08-27 14:44:58,871][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076944] [Batch 03024/03080] [00:37:52/00:00:42, 0.751s/it]: train_loss_raw=0.3702, running_loss=0.3684, LR=0.000100
[2025-08-27 14:45:04,931][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076952] [Batch 03032/03080] [00:37:58/00:00:36, 0.751s/it]: train_loss_raw=0.3363, running_loss=0.3681, LR=0.000100
[2025-08-27 14:45:10,758][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076960] [Batch 03040/03080] [00:38:03/00:00:30, 0.751s/it]: train_loss_raw=0.3139, running_loss=0.3672, LR=0.000100
[2025-08-27 14:45:16,592][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076968] [Batch 03048/03080] [00:38:09/00:00:24, 0.751s/it]: train_loss_raw=0.3021, running_loss=0.3672, LR=0.000100
[2025-08-27 14:45:22,868][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076976] [Batch 03056/03080] [00:38:16/00:00:18, 0.751s/it]: train_loss_raw=0.3454, running_loss=0.3693, LR=0.000100
[2025-08-27 14:45:28,865][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076984] [Batch 03064/03080] [00:38:22/00:00:12, 0.751s/it]: train_loss_raw=0.3901, running_loss=0.3685, LR=0.000100
[2025-08-27 14:45:34,538][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076992] [Batch 03072/03080] [00:38:27/00:00:06, 0.751s/it]: train_loss_raw=0.3831, running_loss=0.3690, LR=0.000100
[2025-08-27 14:45:40,519][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 077000] [Batch 03080/03080] [00:38:33/00:00:00, 0.751s/it]: train_loss_raw=0.3498, running_loss=0.3700, LR=0.000100
[2025-08-27 14:45:41,073][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-27 14:45:52,303][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00007/00310] [00:00:11/00:07:03, 1.404s/it]
[2025-08-27 14:46:04,519][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00015/00310] [00:00:23/00:07:10, 1.465s/it]
[2025-08-27 14:46:16,978][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00023/00310] [00:00:35/00:07:07, 1.496s/it]
[2025-08-27 14:46:28,925][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00031/00310] [00:00:47/00:06:55, 1.495s/it]
[2025-08-27 14:46:40,848][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00039/00310] [00:00:59/00:06:43, 1.494s/it]
[2025-08-27 14:46:52,570][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00047/00310] [00:01:11/00:06:30, 1.490s/it]
[2025-08-27 14:47:04,379][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00055/00310] [00:01:23/00:06:17, 1.488s/it]
[2025-08-27 14:47:15,627][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00063/00310] [00:01:34/00:06:03, 1.477s/it]
[2025-08-27 14:47:27,817][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00071/00310] [00:01:46/00:05:52, 1.483s/it]
[2025-08-27 14:47:38,762][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00079/00310] [00:01:57/00:05:38, 1.471s/it]
[2025-08-27 14:47:51,278][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00087/00310] [00:02:10/00:05:28, 1.480s/it]
[2025-08-27 14:48:03,507][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00095/00310] [00:02:22/00:05:17, 1.484s/it]
[2025-08-27 14:48:15,480][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00103/00310] [00:02:34/00:05:05, 1.485s/it]
[2025-08-27 14:48:28,225][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00111/00310] [00:02:47/00:04:55, 1.492s/it]
[2025-08-27 14:48:39,867][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00119/00310] [00:02:58/00:04:43, 1.490s/it]
[2025-08-27 14:48:51,677][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00127/00310] [00:03:10/00:04:31, 1.489s/it]
[2025-08-27 14:49:03,457][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00135/00310] [00:03:22/00:04:18, 1.488s/it]
[2025-08-27 14:49:15,761][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00143/00310] [00:03:34/00:04:07, 1.491s/it]
[2025-08-27 14:49:25,802][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00151/00310] [00:03:44/00:03:53, 1.478s/it]
[2025-08-27 14:49:36,406][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00159/00310] [00:03:55/00:03:40, 1.471s/it]
[2025-08-27 14:49:48,402][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00167/00310] [00:04:07/00:03:29, 1.472s/it]
[2025-08-27 14:49:58,376][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00175/00310] [00:04:17/00:03:15, 1.462s/it]
[2025-08-27 14:50:09,371][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00183/00310] [00:04:28/00:03:03, 1.458s/it]
[2025-08-27 14:50:20,603][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00191/00310] [00:04:39/00:02:51, 1.456s/it]
[2025-08-27 14:50:32,382][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00199/00310] [00:04:51/00:02:40, 1.457s/it]
[2025-08-27 14:50:43,296][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00207/00310] [00:05:02/00:02:28, 1.453s/it]
[2025-08-27 14:50:53,396][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00215/00310] [00:05:12/00:02:15, 1.446s/it]
[2025-08-27 14:51:03,973][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00223/00310] [00:05:22/00:02:03, 1.442s/it]
[2025-08-27 14:51:17,118][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00231/00310] [00:05:36/00:01:52, 1.448s/it]
[2025-08-27 14:51:29,254][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00239/00310] [00:05:48/00:01:41, 1.451s/it]
[2025-08-27 14:51:40,563][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00247/00310] [00:05:59/00:01:29, 1.450s/it]
[2025-08-27 14:51:52,088][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00255/00310] [00:06:11/00:01:18, 1.449s/it]
[2025-08-27 14:52:03,285][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00263/00310] [00:06:22/00:01:06, 1.448s/it]
[2025-08-27 14:52:14,958][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00271/00310] [00:06:33/00:00:55, 1.448s/it]
[2025-08-27 14:52:25,485][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00279/00310] [00:06:44/00:00:43, 1.444s/it]
[2025-08-27 14:52:36,479][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00287/00310] [00:06:55/00:00:31, 1.442s/it]
[2025-08-27 14:52:47,053][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00295/00310] [00:07:05/00:00:20, 1.439s/it]
[2025-08-27 14:52:58,770][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00303/00310] [00:07:17/00:00:08, 1.440s/it]
[2025-08-27 14:53:08,071][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.37004, valid_loss=1.44883
[2025-08-27 14:53:08,071][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-27 14:53:08,071][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.488
[2025-08-27 14:53:08,071][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.149
[2025-08-27 14:53:08,071][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.152
[2025-08-27 14:53:08,072][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.081
[2025-08-27 14:53:08,082][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 19:26:21, remaining time 03:53:16, 00:46:39 per epoch
[2025-08-27 14:53:15,754][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077008] [Batch 00008/03080] [00:00:07/00:47:55, 0.936s/it]: train_loss_raw=0.3687, running_loss=0.3401, LR=0.000100
[2025-08-27 14:53:22,042][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077016] [Batch 00016/03080] [00:00:13/00:43:58, 0.861s/it]: train_loss_raw=0.4115, running_loss=0.3457, LR=0.000100
[2025-08-27 14:53:27,626][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077024] [Batch 00024/03080] [00:00:19/00:41:05, 0.807s/it]: train_loss_raw=0.3981, running_loss=0.3485, LR=0.000100
[2025-08-27 14:53:33,576][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077032] [Batch 00032/03080] [00:00:25/00:40:10, 0.791s/it]: train_loss_raw=0.3603, running_loss=0.3500, LR=0.000100
[2025-08-27 14:53:39,238][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077040] [Batch 00040/03080] [00:00:30/00:39:14, 0.774s/it]: train_loss_raw=0.3304, running_loss=0.3524, LR=0.000100
[2025-08-27 14:53:45,343][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077048] [Batch 00048/03080] [00:00:37/00:39:02, 0.772s/it]: train_loss_raw=0.3787, running_loss=0.3524, LR=0.000100
[2025-08-27 14:53:51,115][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077056] [Batch 00056/03080] [00:00:42/00:38:33, 0.765s/it]: train_loss_raw=0.2765, running_loss=0.3542, LR=0.000100
[2025-08-27 14:53:56,854][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077064] [Batch 00064/03080] [00:00:48/00:38:09, 0.759s/it]: train_loss_raw=0.3709, running_loss=0.3549, LR=0.000100
[2025-08-27 14:54:02,673][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077072] [Batch 00072/03080] [00:00:54/00:37:53, 0.756s/it]: train_loss_raw=0.4174, running_loss=0.3574, LR=0.000100
[2025-08-27 14:54:08,189][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077080] [Batch 00080/03080] [00:00:59/00:37:27, 0.749s/it]: train_loss_raw=0.3397, running_loss=0.3580, LR=0.000100
[2025-08-27 14:54:13,805][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077088] [Batch 00088/03080] [00:01:05/00:37:08, 0.745s/it]: train_loss_raw=0.4138, running_loss=0.3608, LR=0.000100
[2025-08-27 14:54:19,727][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077096] [Batch 00096/03080] [00:01:11/00:37:01, 0.744s/it]: train_loss_raw=0.4058, running_loss=0.3624, LR=0.000100
[2025-08-27 14:54:25,715][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077104] [Batch 00104/03080] [00:01:17/00:36:56, 0.745s/it]: train_loss_raw=0.3658, running_loss=0.3631, LR=0.000100
[2025-08-27 14:54:31,685][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077112] [Batch 00112/03080] [00:01:23/00:36:50, 0.745s/it]: train_loss_raw=0.3337, running_loss=0.3626, LR=0.000100
[2025-08-27 14:54:37,667][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077120] [Batch 00120/03080] [00:01:29/00:36:45, 0.745s/it]: train_loss_raw=0.3248, running_loss=0.3635, LR=0.000100
[2025-08-27 14:54:43,698][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077128] [Batch 00128/03080] [00:01:35/00:36:40, 0.746s/it]: train_loss_raw=0.3963, running_loss=0.3630, LR=0.000100
[2025-08-27 14:54:49,381][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077136] [Batch 00136/03080] [00:01:41/00:36:28, 0.744s/it]: train_loss_raw=0.3914, running_loss=0.3657, LR=0.000100
[2025-08-27 14:54:55,256][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077144] [Batch 00144/03080] [00:01:46/00:36:21, 0.743s/it]: train_loss_raw=0.3750, running_loss=0.3663, LR=0.000100
[2025-08-27 14:55:00,636][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077152] [Batch 00152/03080] [00:01:52/00:36:04, 0.739s/it]: train_loss_raw=0.3500, running_loss=0.3644, LR=0.000100
[2025-08-27 14:55:06,390][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077160] [Batch 00160/03080] [00:01:58/00:35:55, 0.738s/it]: train_loss_raw=0.3091, running_loss=0.3632, LR=0.000100
[2025-08-27 14:55:11,958][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077168] [Batch 00168/03080] [00:02:03/00:35:44, 0.736s/it]: train_loss_raw=0.4620, running_loss=0.3638, LR=0.000100
[2025-08-27 14:55:17,346][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077176] [Batch 00176/03080] [00:02:09/00:35:29, 0.733s/it]: train_loss_raw=0.3379, running_loss=0.3638, LR=0.000100
[2025-08-27 14:55:23,061][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077184] [Batch 00184/03080] [00:02:14/00:35:21, 0.733s/it]: train_loss_raw=0.3264, running_loss=0.3654, LR=0.000100
[2025-08-27 14:55:28,438][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077192] [Batch 00192/03080] [00:02:20/00:35:08, 0.730s/it]: train_loss_raw=0.3372, running_loss=0.3682, LR=0.000100
[2025-08-27 14:55:34,327][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077200] [Batch 00200/03080] [00:02:26/00:35:03, 0.730s/it]: train_loss_raw=0.3432, running_loss=0.3694, LR=0.000100
[2025-08-27 14:55:40,323][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077208] [Batch 00208/03080] [00:02:32/00:34:59, 0.731s/it]: train_loss_raw=0.3496, running_loss=0.3711, LR=0.000100
[2025-08-27 14:55:46,317][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077216] [Batch 00216/03080] [00:02:38/00:34:55, 0.732s/it]: train_loss_raw=0.4134, running_loss=0.3705, LR=0.000100
[2025-08-27 14:55:52,309][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077224] [Batch 00224/03080] [00:02:44/00:34:51, 0.732s/it]: train_loss_raw=0.3566, running_loss=0.3715, LR=0.000100
[2025-08-27 14:55:58,330][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077232] [Batch 00232/03080] [00:02:50/00:34:47, 0.733s/it]: train_loss_raw=0.4249, running_loss=0.3710, LR=0.000100
[2025-08-27 14:56:04,278][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077240] [Batch 00240/03080] [00:02:56/00:34:42, 0.733s/it]: train_loss_raw=0.2701, running_loss=0.3707, LR=0.000100
[2025-08-27 14:56:10,268][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077248] [Batch 00248/03080] [00:03:02/00:34:38, 0.734s/it]: train_loss_raw=0.3466, running_loss=0.3707, LR=0.000100
[2025-08-27 14:56:15,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077256] [Batch 00256/03080] [00:03:07/00:34:29, 0.733s/it]: train_loss_raw=0.3450, running_loss=0.3698, LR=0.000100
[2025-08-27 14:56:21,790][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077264] [Batch 00264/03080] [00:03:13/00:34:24, 0.733s/it]: train_loss_raw=0.3219, running_loss=0.3705, LR=0.000100
[2025-08-27 14:56:27,886][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077272] [Batch 00272/03080] [00:03:19/00:34:20, 0.734s/it]: train_loss_raw=0.3532, running_loss=0.3690, LR=0.000100
[2025-08-27 14:56:34,052][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077280] [Batch 00280/03080] [00:03:25/00:34:17, 0.735s/it]: train_loss_raw=0.3510, running_loss=0.3658, LR=0.000100
[2025-08-27 14:56:39,740][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077288] [Batch 00288/03080] [00:03:31/00:34:10, 0.734s/it]: train_loss_raw=0.3628, running_loss=0.3645, LR=0.000100
[2025-08-27 14:56:45,199][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077296] [Batch 00296/03080] [00:03:36/00:34:00, 0.733s/it]: train_loss_raw=0.2965, running_loss=0.3670, LR=0.000100
[2025-08-27 14:56:50,914][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077304] [Batch 00304/03080] [00:03:42/00:33:53, 0.732s/it]: train_loss_raw=0.3140, running_loss=0.3650, LR=0.000100
[2025-08-27 14:56:56,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077312] [Batch 00312/03080] [00:03:48/00:33:43, 0.731s/it]: train_loss_raw=0.3829, running_loss=0.3648, LR=0.000100
[2025-08-27 14:57:01,783][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077320] [Batch 00320/03080] [00:03:53/00:33:34, 0.730s/it]: train_loss_raw=0.4689, running_loss=0.3657, LR=0.000100
[2025-08-27 14:57:07,784][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077328] [Batch 00328/03080] [00:03:59/00:33:29, 0.730s/it]: train_loss_raw=0.3665, running_loss=0.3658, LR=0.000100
[2025-08-27 14:57:13,857][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077336] [Batch 00336/03080] [00:04:05/00:33:25, 0.731s/it]: train_loss_raw=0.3902, running_loss=0.3673, LR=0.000100
[2025-08-27 14:57:19,931][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077344] [Batch 00344/03080] [00:04:11/00:33:21, 0.732s/it]: train_loss_raw=0.3200, running_loss=0.3646, LR=0.000100
[2025-08-27 14:57:25,687][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077352] [Batch 00352/03080] [00:04:17/00:33:15, 0.731s/it]: train_loss_raw=0.3414, running_loss=0.3661, LR=0.000100
[2025-08-27 14:57:31,217][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077360] [Batch 00360/03080] [00:04:22/00:33:06, 0.730s/it]: train_loss_raw=0.3305, running_loss=0.3654, LR=0.000100
[2025-08-27 14:57:36,639][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077368] [Batch 00368/03080] [00:04:28/00:32:57, 0.729s/it]: train_loss_raw=0.4337, running_loss=0.3659, LR=0.000100
[2025-08-27 14:57:42,289][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077376] [Batch 00376/03080] [00:04:34/00:32:50, 0.729s/it]: train_loss_raw=0.3648, running_loss=0.3663, LR=0.000100
[2025-08-27 14:57:48,013][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077384] [Batch 00384/03080] [00:04:39/00:32:44, 0.729s/it]: train_loss_raw=0.3383, running_loss=0.3647, LR=0.000100
[2025-08-27 14:57:53,966][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077392] [Batch 00392/03080] [00:04:45/00:32:39, 0.729s/it]: train_loss_raw=0.3418, running_loss=0.3656, LR=0.000100
[2025-08-27 14:57:59,738][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077400] [Batch 00400/03080] [00:04:51/00:32:32, 0.729s/it]: train_loss_raw=0.3644, running_loss=0.3672, LR=0.000100
[2025-08-27 14:58:05,274][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077408] [Batch 00408/03080] [00:04:57/00:32:25, 0.728s/it]: train_loss_raw=0.3914, running_loss=0.3659, LR=0.000100
[2025-08-27 14:58:11,233][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077416] [Batch 00416/03080] [00:05:02/00:32:20, 0.728s/it]: train_loss_raw=0.4105, running_loss=0.3663, LR=0.000100
[2025-08-27 14:58:17,417][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077424] [Batch 00424/03080] [00:05:09/00:32:16, 0.729s/it]: train_loss_raw=0.3497, running_loss=0.3651, LR=0.000100
[2025-08-27 14:58:23,617][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077432] [Batch 00432/03080] [00:05:15/00:32:12, 0.730s/it]: train_loss_raw=0.3534, running_loss=0.3666, LR=0.000100
[2025-08-27 14:58:29,823][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077440] [Batch 00440/03080] [00:05:21/00:32:09, 0.731s/it]: train_loss_raw=0.3460, running_loss=0.3683, LR=0.000100
[2025-08-27 14:58:35,670][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077448] [Batch 00448/03080] [00:05:27/00:32:03, 0.731s/it]: train_loss_raw=0.3506, running_loss=0.3677, LR=0.000100
[2025-08-27 14:58:41,756][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077456] [Batch 00456/03080] [00:05:33/00:31:59, 0.731s/it]: train_loss_raw=0.3880, running_loss=0.3686, LR=0.000100
[2025-08-27 14:58:47,348][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077464] [Batch 00464/03080] [00:05:39/00:31:51, 0.731s/it]: train_loss_raw=0.3819, running_loss=0.3682, LR=0.000100
[2025-08-27 14:58:53,048][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077472] [Batch 00472/03080] [00:05:44/00:31:45, 0.730s/it]: train_loss_raw=0.2943, running_loss=0.3667, LR=0.000100
[2025-08-27 14:58:58,614][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077480] [Batch 00480/03080] [00:05:50/00:31:37, 0.730s/it]: train_loss_raw=0.3750, running_loss=0.3666, LR=0.000100
[2025-08-27 14:59:04,716][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077488] [Batch 00488/03080] [00:05:56/00:31:33, 0.730s/it]: train_loss_raw=0.3860, running_loss=0.3676, LR=0.000100
[2025-08-27 14:59:10,636][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077496] [Batch 00496/03080] [00:06:02/00:31:27, 0.731s/it]: train_loss_raw=0.3571, running_loss=0.3677, LR=0.000100
[2025-08-27 14:59:16,600][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077504] [Batch 00504/03080] [00:06:08/00:31:22, 0.731s/it]: train_loss_raw=0.4509, running_loss=0.3691, LR=0.000100
[2025-08-27 14:59:22,798][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077512] [Batch 00512/03080] [00:06:14/00:31:18, 0.732s/it]: train_loss_raw=0.3795, running_loss=0.3703, LR=0.000100
[2025-08-27 14:59:28,969][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077520] [Batch 00520/03080] [00:06:20/00:31:14, 0.732s/it]: train_loss_raw=0.4457, running_loss=0.3732, LR=0.000100
[2025-08-27 14:59:35,010][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077528] [Batch 00528/03080] [00:06:26/00:31:09, 0.732s/it]: train_loss_raw=0.4646, running_loss=0.3754, LR=0.000100
[2025-08-27 14:59:40,973][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077536] [Batch 00536/03080] [00:06:32/00:31:03, 0.733s/it]: train_loss_raw=0.3904, running_loss=0.3754, LR=0.000100
[2025-08-27 14:59:47,016][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077544] [Batch 00544/03080] [00:06:38/00:30:58, 0.733s/it]: train_loss_raw=0.3978, running_loss=0.3749, LR=0.000100
[2025-08-27 14:59:53,130][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077552] [Batch 00552/03080] [00:06:44/00:30:54, 0.733s/it]: train_loss_raw=0.2937, running_loss=0.3730, LR=0.000100
[2025-08-27 14:59:59,402][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077560] [Batch 00560/03080] [00:06:51/00:30:50, 0.734s/it]: train_loss_raw=0.3954, running_loss=0.3743, LR=0.000100
[2025-08-27 15:00:05,383][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077568] [Batch 00568/03080] [00:06:57/00:30:44, 0.734s/it]: train_loss_raw=0.3436, running_loss=0.3770, LR=0.000100
[2025-08-27 15:00:11,695][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077576] [Batch 00576/03080] [00:07:03/00:30:40, 0.735s/it]: train_loss_raw=0.3511, running_loss=0.3779, LR=0.000100
[2025-08-27 15:00:17,366][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077584] [Batch 00584/03080] [00:07:09/00:30:33, 0.735s/it]: train_loss_raw=0.4487, running_loss=0.3780, LR=0.000100
[2025-08-27 15:00:23,554][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077592] [Batch 00592/03080] [00:07:15/00:30:29, 0.735s/it]: train_loss_raw=0.2979, running_loss=0.3754, LR=0.000100
[2025-08-27 15:00:29,516][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077600] [Batch 00600/03080] [00:07:21/00:30:23, 0.735s/it]: train_loss_raw=0.3429, running_loss=0.3748, LR=0.000100
[2025-08-27 15:00:35,575][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077608] [Batch 00608/03080] [00:07:27/00:30:18, 0.736s/it]: train_loss_raw=0.3530, running_loss=0.3743, LR=0.000100
[2025-08-27 15:00:41,713][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077616] [Batch 00616/03080] [00:07:33/00:30:13, 0.736s/it]: train_loss_raw=0.4013, running_loss=0.3738, LR=0.000100
[2025-08-27 15:00:47,803][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077624] [Batch 00624/03080] [00:07:39/00:30:08, 0.736s/it]: train_loss_raw=0.3708, running_loss=0.3734, LR=0.000100
[2025-08-27 15:00:53,919][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077632] [Batch 00632/03080] [00:07:45/00:30:03, 0.737s/it]: train_loss_raw=0.3627, running_loss=0.3723, LR=0.000100
[2025-08-27 15:01:00,045][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077640] [Batch 00640/03080] [00:07:51/00:29:58, 0.737s/it]: train_loss_raw=0.3138, running_loss=0.3722, LR=0.000100
[2025-08-27 15:01:05,784][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077648] [Batch 00648/03080] [00:07:57/00:29:52, 0.737s/it]: train_loss_raw=0.3570, running_loss=0.3692, LR=0.000100
[2025-08-27 15:01:11,661][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077656] [Batch 00656/03080] [00:08:03/00:29:46, 0.737s/it]: train_loss_raw=0.3710, running_loss=0.3691, LR=0.000100
[2025-08-27 15:01:17,832][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077664] [Batch 00664/03080] [00:08:09/00:29:41, 0.737s/it]: train_loss_raw=0.4451, running_loss=0.3719, LR=0.000100
[2025-08-27 15:01:23,815][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077672] [Batch 00672/03080] [00:08:15/00:29:35, 0.737s/it]: train_loss_raw=0.3762, running_loss=0.3727, LR=0.000100
[2025-08-27 15:01:29,845][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077680] [Batch 00680/03080] [00:08:21/00:29:30, 0.738s/it]: train_loss_raw=0.3366, running_loss=0.3715, LR=0.000100
[2025-08-27 15:01:35,963][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077688] [Batch 00688/03080] [00:08:27/00:29:25, 0.738s/it]: train_loss_raw=0.3057, running_loss=0.3714, LR=0.000100
[2025-08-27 15:01:42,015][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077696] [Batch 00696/03080] [00:08:33/00:29:19, 0.738s/it]: train_loss_raw=0.3254, running_loss=0.3718, LR=0.000100
[2025-08-27 15:01:48,038][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077704] [Batch 00704/03080] [00:08:39/00:29:14, 0.738s/it]: train_loss_raw=0.3695, running_loss=0.3727, LR=0.000100
[2025-08-27 15:01:53,982][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077712] [Batch 00712/03080] [00:08:45/00:29:08, 0.738s/it]: train_loss_raw=0.3431, running_loss=0.3718, LR=0.000100
[2025-08-27 15:02:00,050][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077720] [Batch 00720/03080] [00:08:51/00:29:03, 0.739s/it]: train_loss_raw=0.3284, running_loss=0.3731, LR=0.000100
[2025-08-27 15:02:06,063][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077728] [Batch 00728/03080] [00:08:57/00:28:57, 0.739s/it]: train_loss_raw=0.3336, running_loss=0.3718, LR=0.000100
[2025-08-27 15:02:12,138][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077736] [Batch 00736/03080] [00:09:03/00:28:52, 0.739s/it]: train_loss_raw=0.3884, running_loss=0.3712, LR=0.000100
[2025-08-27 15:02:18,150][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077744] [Batch 00744/03080] [00:09:09/00:28:46, 0.739s/it]: train_loss_raw=0.3580, running_loss=0.3732, LR=0.000100
[2025-08-27 15:02:24,041][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077752] [Batch 00752/03080] [00:09:15/00:28:40, 0.739s/it]: train_loss_raw=0.3281, running_loss=0.3726, LR=0.000100
[2025-08-27 15:02:29,781][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077760] [Batch 00760/03080] [00:09:21/00:28:34, 0.739s/it]: train_loss_raw=0.3732, running_loss=0.3733, LR=0.000100
[2025-08-27 15:02:35,874][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077768] [Batch 00768/03080] [00:09:27/00:28:28, 0.739s/it]: train_loss_raw=0.4371, running_loss=0.3732, LR=0.000100
[2025-08-27 15:02:41,899][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077776] [Batch 00776/03080] [00:09:33/00:28:23, 0.739s/it]: train_loss_raw=0.3461, running_loss=0.3734, LR=0.000100
[2025-08-27 15:02:47,695][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077784] [Batch 00784/03080] [00:09:39/00:28:16, 0.739s/it]: train_loss_raw=0.3022, running_loss=0.3736, LR=0.000100
[2025-08-27 15:02:53,242][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077792] [Batch 00792/03080] [00:09:44/00:28:09, 0.739s/it]: train_loss_raw=0.3649, running_loss=0.3708, LR=0.000100
[2025-08-27 15:02:58,760][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077800] [Batch 00800/03080] [00:09:50/00:28:02, 0.738s/it]: train_loss_raw=0.2850, running_loss=0.3681, LR=0.000100
[2025-08-27 15:03:04,465][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077808] [Batch 00808/03080] [00:09:56/00:27:56, 0.738s/it]: train_loss_raw=0.3192, running_loss=0.3684, LR=0.000100
[2025-08-27 15:03:10,387][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077816] [Batch 00816/03080] [00:10:02/00:27:50, 0.738s/it]: train_loss_raw=0.3948, running_loss=0.3686, LR=0.000100
[2025-08-27 15:03:16,423][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077824] [Batch 00824/03080] [00:10:08/00:27:45, 0.738s/it]: train_loss_raw=0.3414, running_loss=0.3705, LR=0.000100
[2025-08-27 15:03:22,262][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077832] [Batch 00832/03080] [00:10:13/00:27:38, 0.738s/it]: train_loss_raw=0.2893, running_loss=0.3694, LR=0.000100
[2025-08-27 15:03:28,295][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077840] [Batch 00840/03080] [00:10:20/00:27:33, 0.738s/it]: train_loss_raw=0.3815, running_loss=0.3722, LR=0.000100
[2025-08-27 15:03:34,200][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077848] [Batch 00848/03080] [00:10:25/00:27:27, 0.738s/it]: train_loss_raw=0.3709, running_loss=0.3739, LR=0.000100
[2025-08-27 15:03:40,213][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077856] [Batch 00856/03080] [00:10:31/00:27:21, 0.738s/it]: train_loss_raw=0.4355, running_loss=0.3727, LR=0.000100
[2025-08-27 15:03:46,104][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077864] [Batch 00864/03080] [00:10:37/00:27:15, 0.738s/it]: train_loss_raw=0.3603, running_loss=0.3728, LR=0.000100
[2025-08-27 15:03:52,287][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077872] [Batch 00872/03080] [00:10:44/00:27:10, 0.739s/it]: train_loss_raw=0.4332, running_loss=0.3742, LR=0.000100
[2025-08-27 15:03:58,404][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077880] [Batch 00880/03080] [00:10:50/00:27:05, 0.739s/it]: train_loss_raw=0.3503, running_loss=0.3737, LR=0.000100
[2025-08-27 15:04:04,420][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077888] [Batch 00888/03080] [00:10:56/00:26:59, 0.739s/it]: train_loss_raw=0.4356, running_loss=0.3761, LR=0.000100
[2025-08-27 15:04:10,366][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077896] [Batch 00896/03080] [00:11:02/00:26:53, 0.739s/it]: train_loss_raw=0.4181, running_loss=0.3768, LR=0.000100
[2025-08-27 15:04:16,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077904] [Batch 00904/03080] [00:11:08/00:26:47, 0.739s/it]: train_loss_raw=0.3721, running_loss=0.3748, LR=0.000100
[2025-08-27 15:04:21,932][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077912] [Batch 00912/03080] [00:11:13/00:26:41, 0.739s/it]: train_loss_raw=0.3901, running_loss=0.3738, LR=0.000100
[2025-08-27 15:04:27,894][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077920] [Batch 00920/03080] [00:11:19/00:26:35, 0.739s/it]: train_loss_raw=0.3764, running_loss=0.3741, LR=0.000100
[2025-08-27 15:04:33,464][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077928] [Batch 00928/03080] [00:11:25/00:26:28, 0.738s/it]: train_loss_raw=0.3951, running_loss=0.3732, LR=0.000100
[2025-08-27 15:04:39,231][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077936] [Batch 00936/03080] [00:11:30/00:26:22, 0.738s/it]: train_loss_raw=0.3931, running_loss=0.3726, LR=0.000100
[2025-08-27 15:04:44,907][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077944] [Batch 00944/03080] [00:11:36/00:26:16, 0.738s/it]: train_loss_raw=0.4379, running_loss=0.3744, LR=0.000100
[2025-08-27 15:04:51,077][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077952] [Batch 00952/03080] [00:11:42/00:26:10, 0.738s/it]: train_loss_raw=0.4524, running_loss=0.3724, LR=0.000100
[2025-08-27 15:04:57,021][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077960] [Batch 00960/03080] [00:11:48/00:26:05, 0.738s/it]: train_loss_raw=0.3586, running_loss=0.3720, LR=0.000100
[2025-08-27 15:05:03,022][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077968] [Batch 00968/03080] [00:11:54/00:25:59, 0.738s/it]: train_loss_raw=0.3342, running_loss=0.3702, LR=0.000100
[2025-08-27 15:05:09,037][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077976] [Batch 00976/03080] [00:12:00/00:25:53, 0.738s/it]: train_loss_raw=0.4217, running_loss=0.3705, LR=0.000100
[2025-08-27 15:05:15,071][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077984] [Batch 00984/03080] [00:12:06/00:25:48, 0.739s/it]: train_loss_raw=0.3730, running_loss=0.3714, LR=0.000100
[2025-08-27 15:05:21,179][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077992] [Batch 00992/03080] [00:12:12/00:25:42, 0.739s/it]: train_loss_raw=0.3346, running_loss=0.3700, LR=0.000100
[2025-08-27 15:05:27,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078000] [Batch 01000/03080] [00:12:19/00:25:37, 0.739s/it]: train_loss_raw=0.4167, running_loss=0.3690, LR=0.000100
[2025-08-27 15:05:36,313][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078008] [Batch 01008/03080] [00:12:28/00:25:37, 0.742s/it]: train_loss_raw=0.4327, running_loss=0.3699, LR=0.000100
[2025-08-27 15:05:41,903][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078016] [Batch 01016/03080] [00:12:33/00:25:31, 0.742s/it]: train_loss_raw=0.3832, running_loss=0.3709, LR=0.000100
[2025-08-27 15:05:47,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078024] [Batch 01024/03080] [00:12:39/00:25:25, 0.742s/it]: train_loss_raw=0.3562, running_loss=0.3719, LR=0.000100
[2025-08-27 15:05:53,869][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078032] [Batch 01032/03080] [00:12:45/00:25:19, 0.742s/it]: train_loss_raw=0.4045, running_loss=0.3711, LR=0.000100
[2025-08-27 15:05:59,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078040] [Batch 01040/03080] [00:12:51/00:25:13, 0.742s/it]: train_loss_raw=0.3307, running_loss=0.3726, LR=0.000100
[2025-08-27 15:06:05,955][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078048] [Batch 01048/03080] [00:12:57/00:25:07, 0.742s/it]: train_loss_raw=0.3678, running_loss=0.3725, LR=0.000100
[2025-08-27 15:06:12,030][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078056] [Batch 01056/03080] [00:13:03/00:25:02, 0.742s/it]: train_loss_raw=0.3410, running_loss=0.3727, LR=0.000100
[2025-08-27 15:06:18,104][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078064] [Batch 01064/03080] [00:13:09/00:24:56, 0.742s/it]: train_loss_raw=0.2883, running_loss=0.3727, LR=0.000100
[2025-08-27 15:06:23,685][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078072] [Batch 01072/03080] [00:13:15/00:24:49, 0.742s/it]: train_loss_raw=0.4024, running_loss=0.3721, LR=0.000100
[2025-08-27 15:06:29,831][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078080] [Batch 01080/03080] [00:13:21/00:24:44, 0.742s/it]: train_loss_raw=0.3960, running_loss=0.3716, LR=0.000100
[2025-08-27 15:06:35,930][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078088] [Batch 01088/03080] [00:13:27/00:24:38, 0.742s/it]: train_loss_raw=0.3657, running_loss=0.3704, LR=0.000100
[2025-08-27 15:06:41,649][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078096] [Batch 01096/03080] [00:13:33/00:24:32, 0.742s/it]: train_loss_raw=0.4627, running_loss=0.3678, LR=0.000100
[2025-08-27 15:06:47,190][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078104] [Batch 01104/03080] [00:13:38/00:24:25, 0.742s/it]: train_loss_raw=0.3687, running_loss=0.3698, LR=0.000100
[2025-08-27 15:06:52,974][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078112] [Batch 01112/03080] [00:13:44/00:24:19, 0.742s/it]: train_loss_raw=0.4305, running_loss=0.3701, LR=0.000100
[2025-08-27 15:06:58,640][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078120] [Batch 01120/03080] [00:13:50/00:24:13, 0.741s/it]: train_loss_raw=0.3282, running_loss=0.3696, LR=0.000100
[2025-08-27 15:07:04,205][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078128] [Batch 01128/03080] [00:13:55/00:24:06, 0.741s/it]: train_loss_raw=0.3159, running_loss=0.3692, LR=0.000100
[2025-08-27 15:07:09,925][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078136] [Batch 01136/03080] [00:14:01/00:24:00, 0.741s/it]: train_loss_raw=0.4121, running_loss=0.3687, LR=0.000100
[2025-08-27 15:07:15,889][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078144] [Batch 01144/03080] [00:14:07/00:23:54, 0.741s/it]: train_loss_raw=0.3542, running_loss=0.3666, LR=0.000100
[2025-08-27 15:07:21,585][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078152] [Batch 01152/03080] [00:14:13/00:23:48, 0.741s/it]: train_loss_raw=0.2915, running_loss=0.3684, LR=0.000100
[2025-08-27 15:07:27,167][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078160] [Batch 01160/03080] [00:14:18/00:23:41, 0.740s/it]: train_loss_raw=0.3376, running_loss=0.3674, LR=0.000100
[2025-08-27 15:07:32,866][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078168] [Batch 01168/03080] [00:14:24/00:23:35, 0.740s/it]: train_loss_raw=0.3228, running_loss=0.3671, LR=0.000100
[2025-08-27 15:07:38,812][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078176] [Batch 01176/03080] [00:14:30/00:23:29, 0.740s/it]: train_loss_raw=0.3359, running_loss=0.3671, LR=0.000100
[2025-08-27 15:07:44,460][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078184] [Batch 01184/03080] [00:14:36/00:23:23, 0.740s/it]: train_loss_raw=0.4246, running_loss=0.3698, LR=0.000100
[2025-08-27 15:07:50,142][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078192] [Batch 01192/03080] [00:14:41/00:23:16, 0.740s/it]: train_loss_raw=0.3773, running_loss=0.3697, LR=0.000100
[2025-08-27 15:07:56,157][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078200] [Batch 01200/03080] [00:14:47/00:23:11, 0.740s/it]: train_loss_raw=0.4615, running_loss=0.3704, LR=0.000100
[2025-08-27 15:08:01,703][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078208] [Batch 01208/03080] [00:14:53/00:23:04, 0.740s/it]: train_loss_raw=0.3884, running_loss=0.3703, LR=0.000100
[2025-08-27 15:08:07,342][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078216] [Batch 01216/03080] [00:14:59/00:22:58, 0.739s/it]: train_loss_raw=0.4017, running_loss=0.3705, LR=0.000100
[2025-08-27 15:08:13,053][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078224] [Batch 01224/03080] [00:15:04/00:22:51, 0.739s/it]: train_loss_raw=0.3228, running_loss=0.3708, LR=0.000100
[2025-08-27 15:08:18,891][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078232] [Batch 01232/03080] [00:15:10/00:22:45, 0.739s/it]: train_loss_raw=0.3576, running_loss=0.3704, LR=0.000100
[2025-08-27 15:08:24,422][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078240] [Batch 01240/03080] [00:15:16/00:22:39, 0.739s/it]: train_loss_raw=0.4155, running_loss=0.3694, LR=0.000100
[2025-08-27 15:08:29,957][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078248] [Batch 01248/03080] [00:15:21/00:22:32, 0.739s/it]: train_loss_raw=0.4120, running_loss=0.3699, LR=0.000100
[2025-08-27 15:08:35,944][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078256] [Batch 01256/03080] [00:15:27/00:22:27, 0.739s/it]: train_loss_raw=0.3829, running_loss=0.3718, LR=0.000100
[2025-08-27 15:08:41,443][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078264] [Batch 01264/03080] [00:15:33/00:22:20, 0.738s/it]: train_loss_raw=0.3684, running_loss=0.3704, LR=0.000100
[2025-08-27 15:08:46,872][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078272] [Batch 01272/03080] [00:15:38/00:22:14, 0.738s/it]: train_loss_raw=0.4626, running_loss=0.3701, LR=0.000100
[2025-08-27 15:08:52,632][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078280] [Batch 01280/03080] [00:15:44/00:22:08, 0.738s/it]: train_loss_raw=0.3403, running_loss=0.3701, LR=0.000100
[2025-08-27 15:08:58,621][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078288] [Batch 01288/03080] [00:15:50/00:22:02, 0.738s/it]: train_loss_raw=0.4339, running_loss=0.3722, LR=0.000100
[2025-08-27 15:09:04,274][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078296] [Batch 01296/03080] [00:15:56/00:21:55, 0.738s/it]: train_loss_raw=0.4236, running_loss=0.3718, LR=0.000100
[2025-08-27 15:09:09,809][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078304] [Batch 01304/03080] [00:16:01/00:21:49, 0.737s/it]: train_loss_raw=0.3936, running_loss=0.3721, LR=0.000100
[2025-08-27 15:09:15,756][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078312] [Batch 01312/03080] [00:16:07/00:21:43, 0.737s/it]: train_loss_raw=0.3969, running_loss=0.3735, LR=0.000100
[2025-08-27 15:09:21,849][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078320] [Batch 01320/03080] [00:16:13/00:21:38, 0.738s/it]: train_loss_raw=0.3923, running_loss=0.3746, LR=0.000100
[2025-08-27 15:09:27,734][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078328] [Batch 01328/03080] [00:16:19/00:21:32, 0.738s/it]: train_loss_raw=0.4021, running_loss=0.3762, LR=0.000100
[2025-08-27 15:09:33,734][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078336] [Batch 01336/03080] [00:16:25/00:21:26, 0.738s/it]: train_loss_raw=0.3424, running_loss=0.3752, LR=0.000100
[2025-08-27 15:09:39,092][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078344] [Batch 01344/03080] [00:16:30/00:21:19, 0.737s/it]: train_loss_raw=0.3766, running_loss=0.3735, LR=0.000100
[2025-08-27 15:09:44,897][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078352] [Batch 01352/03080] [00:16:36/00:21:13, 0.737s/it]: train_loss_raw=0.4551, running_loss=0.3735, LR=0.000100
[2025-08-27 15:09:50,735][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078360] [Batch 01360/03080] [00:16:42/00:21:07, 0.737s/it]: train_loss_raw=0.3496, running_loss=0.3736, LR=0.000100
[2025-08-27 15:09:56,571][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078368] [Batch 01368/03080] [00:16:48/00:21:01, 0.737s/it]: train_loss_raw=0.2820, running_loss=0.3730, LR=0.000100
[2025-08-27 15:10:02,712][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078376] [Batch 01376/03080] [00:16:54/00:20:56, 0.737s/it]: train_loss_raw=0.4925, running_loss=0.3740, LR=0.000100
[2025-08-27 15:10:08,606][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078384] [Batch 01384/03080] [00:17:00/00:20:50, 0.737s/it]: train_loss_raw=0.3934, running_loss=0.3750, LR=0.000100
[2025-08-27 15:10:14,637][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078392] [Batch 01392/03080] [00:17:06/00:20:44, 0.737s/it]: train_loss_raw=0.4123, running_loss=0.3756, LR=0.000100
[2025-08-27 15:10:20,518][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078400] [Batch 01400/03080] [00:17:12/00:20:38, 0.737s/it]: train_loss_raw=0.3222, running_loss=0.3743, LR=0.000100
[2025-08-27 15:10:26,619][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078408] [Batch 01408/03080] [00:17:18/00:20:33, 0.737s/it]: train_loss_raw=0.4423, running_loss=0.3754, LR=0.000100
[2025-08-27 15:10:32,607][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078416] [Batch 01416/03080] [00:17:24/00:20:27, 0.738s/it]: train_loss_raw=0.4229, running_loss=0.3748, LR=0.000100
[2025-08-27 15:10:38,203][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078424] [Batch 01424/03080] [00:17:29/00:20:20, 0.737s/it]: train_loss_raw=0.3466, running_loss=0.3738, LR=0.000100
[2025-08-27 15:10:43,908][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078432] [Batch 01432/03080] [00:17:35/00:20:14, 0.737s/it]: train_loss_raw=0.3603, running_loss=0.3731, LR=0.000100
[2025-08-27 15:10:49,923][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078440] [Batch 01440/03080] [00:17:41/00:20:09, 0.737s/it]: train_loss_raw=0.3801, running_loss=0.3729, LR=0.000100
[2025-08-27 15:10:55,977][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078448] [Batch 01448/03080] [00:17:47/00:20:03, 0.737s/it]: train_loss_raw=0.3909, running_loss=0.3727, LR=0.000100
[2025-08-27 15:11:02,079][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078456] [Batch 01456/03080] [00:17:53/00:19:57, 0.738s/it]: train_loss_raw=0.3472, running_loss=0.3711, LR=0.000100
[2025-08-27 15:11:08,075][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078464] [Batch 01464/03080] [00:17:59/00:19:51, 0.738s/it]: train_loss_raw=0.3263, running_loss=0.3698, LR=0.000100
[2025-08-27 15:11:13,745][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078472] [Batch 01472/03080] [00:18:05/00:19:45, 0.737s/it]: train_loss_raw=0.3205, running_loss=0.3672, LR=0.000100
[2025-08-27 15:11:19,673][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078480] [Batch 01480/03080] [00:18:11/00:19:39, 0.737s/it]: train_loss_raw=0.3697, running_loss=0.3667, LR=0.000100
[2025-08-27 15:11:25,755][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078488] [Batch 01488/03080] [00:18:17/00:19:34, 0.738s/it]: train_loss_raw=0.2763, running_loss=0.3666, LR=0.000100
[2025-08-27 15:11:31,455][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078496] [Batch 01496/03080] [00:18:23/00:19:28, 0.737s/it]: train_loss_raw=0.2594, running_loss=0.3665, LR=0.000100
[2025-08-27 15:11:37,305][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078504] [Batch 01504/03080] [00:18:29/00:19:22, 0.737s/it]: train_loss_raw=0.2622, running_loss=0.3662, LR=0.000100
[2025-08-27 15:11:43,295][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078512] [Batch 01512/03080] [00:18:35/00:19:16, 0.737s/it]: train_loss_raw=0.3765, running_loss=0.3657, LR=0.000100
[2025-08-27 15:11:49,262][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078520] [Batch 01520/03080] [00:18:40/00:19:10, 0.737s/it]: train_loss_raw=0.4065, running_loss=0.3641, LR=0.000100
[2025-08-27 15:11:54,752][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078528] [Batch 01528/03080] [00:18:46/00:19:04, 0.737s/it]: train_loss_raw=0.3592, running_loss=0.3640, LR=0.000100
[2025-08-27 15:12:00,858][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078536] [Batch 01536/03080] [00:18:52/00:18:58, 0.737s/it]: train_loss_raw=0.3814, running_loss=0.3644, LR=0.000100
[2025-08-27 15:12:06,927][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078544] [Batch 01544/03080] [00:18:58/00:18:52, 0.737s/it]: train_loss_raw=0.3222, running_loss=0.3631, LR=0.000100
[2025-08-27 15:12:12,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078552] [Batch 01552/03080] [00:19:04/00:18:46, 0.738s/it]: train_loss_raw=0.3359, running_loss=0.3641, LR=0.000100
[2025-08-27 15:12:18,870][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078560] [Batch 01560/03080] [00:19:10/00:18:41, 0.738s/it]: train_loss_raw=0.4342, running_loss=0.3669, LR=0.000100
[2025-08-27 15:12:24,820][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078568] [Batch 01568/03080] [00:19:16/00:18:35, 0.738s/it]: train_loss_raw=0.4285, running_loss=0.3688, LR=0.000100
[2025-08-27 15:12:30,542][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078576] [Batch 01576/03080] [00:19:22/00:18:29, 0.737s/it]: train_loss_raw=0.3621, running_loss=0.3677, LR=0.000100
[2025-08-27 15:12:36,627][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078584] [Batch 01584/03080] [00:19:28/00:18:23, 0.738s/it]: train_loss_raw=0.3720, running_loss=0.3673, LR=0.000100
[2025-08-27 15:12:42,166][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078592] [Batch 01592/03080] [00:19:33/00:18:17, 0.737s/it]: train_loss_raw=0.5425, running_loss=0.3679, LR=0.000100
[2025-08-27 15:12:48,123][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078600] [Batch 01600/03080] [00:19:39/00:18:11, 0.737s/it]: train_loss_raw=0.3892, running_loss=0.3683, LR=0.000100
[2025-08-27 15:12:54,162][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078608] [Batch 01608/03080] [00:19:45/00:18:05, 0.737s/it]: train_loss_raw=0.3317, running_loss=0.3682, LR=0.000100
[2025-08-27 15:13:00,103][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078616] [Batch 01616/03080] [00:19:51/00:17:59, 0.738s/it]: train_loss_raw=0.4252, running_loss=0.3705, LR=0.000100
[2025-08-27 15:13:05,878][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078624] [Batch 01624/03080] [00:19:57/00:17:53, 0.737s/it]: train_loss_raw=0.3693, running_loss=0.3700, LR=0.000100
[2025-08-27 15:13:11,646][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078632] [Batch 01632/03080] [00:20:03/00:17:47, 0.737s/it]: train_loss_raw=0.2748, running_loss=0.3698, LR=0.000100
[2025-08-27 15:13:17,666][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078640] [Batch 01640/03080] [00:20:09/00:17:41, 0.737s/it]: train_loss_raw=0.4082, running_loss=0.3707, LR=0.000100
[2025-08-27 15:13:23,715][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078648] [Batch 01648/03080] [00:20:15/00:17:36, 0.738s/it]: train_loss_raw=0.3053, running_loss=0.3704, LR=0.000100
[2025-08-27 15:13:29,904][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078656] [Batch 01656/03080] [00:20:21/00:17:30, 0.738s/it]: train_loss_raw=0.3121, running_loss=0.3698, LR=0.000100
[2025-08-27 15:13:35,824][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078664] [Batch 01664/03080] [00:20:27/00:17:24, 0.738s/it]: train_loss_raw=0.3276, running_loss=0.3693, LR=0.000100
[2025-08-27 15:13:41,326][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078672] [Batch 01672/03080] [00:20:33/00:17:18, 0.737s/it]: train_loss_raw=0.4280, running_loss=0.3719, LR=0.000100
[2025-08-27 15:13:47,477][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078680] [Batch 01680/03080] [00:20:39/00:17:12, 0.738s/it]: train_loss_raw=0.4893, running_loss=0.3734, LR=0.000100
[2025-08-27 15:13:53,435][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078688] [Batch 01688/03080] [00:20:45/00:17:06, 0.738s/it]: train_loss_raw=0.2476, running_loss=0.3720, LR=0.000100
[2025-08-27 15:13:59,351][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078696] [Batch 01696/03080] [00:20:51/00:17:00, 0.738s/it]: train_loss_raw=0.3843, running_loss=0.3705, LR=0.000100
[2025-08-27 15:14:05,197][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078704] [Batch 01704/03080] [00:20:56/00:16:54, 0.738s/it]: train_loss_raw=0.2789, running_loss=0.3708, LR=0.000100
[2025-08-27 15:14:11,227][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078712] [Batch 01712/03080] [00:21:02/00:16:49, 0.738s/it]: train_loss_raw=0.3079, running_loss=0.3700, LR=0.000100
[2025-08-27 15:14:17,245][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078720] [Batch 01720/03080] [00:21:08/00:16:43, 0.738s/it]: train_loss_raw=0.3322, running_loss=0.3699, LR=0.000100
[2025-08-27 15:14:23,360][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078728] [Batch 01728/03080] [00:21:15/00:16:37, 0.738s/it]: train_loss_raw=0.2952, running_loss=0.3682, LR=0.000100
[2025-08-27 15:14:29,479][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078736] [Batch 01736/03080] [00:21:21/00:16:31, 0.738s/it]: train_loss_raw=0.3184, running_loss=0.3683, LR=0.000100
[2025-08-27 15:14:35,117][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078744] [Batch 01744/03080] [00:21:26/00:16:25, 0.738s/it]: train_loss_raw=0.3185, running_loss=0.3675, LR=0.000100
[2025-08-27 15:14:41,133][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078752] [Batch 01752/03080] [00:21:32/00:16:19, 0.738s/it]: train_loss_raw=0.3448, running_loss=0.3669, LR=0.000100
[2025-08-27 15:14:46,985][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078760] [Batch 01760/03080] [00:21:38/00:16:14, 0.738s/it]: train_loss_raw=0.3296, running_loss=0.3668, LR=0.000100
[2025-08-27 15:14:53,040][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078768] [Batch 01768/03080] [00:21:44/00:16:08, 0.738s/it]: train_loss_raw=0.3374, running_loss=0.3659, LR=0.000100
[2025-08-27 15:14:58,742][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078776] [Batch 01776/03080] [00:21:50/00:16:02, 0.738s/it]: train_loss_raw=0.3246, running_loss=0.3667, LR=0.000100
[2025-08-27 15:15:04,400][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078784] [Batch 01784/03080] [00:21:56/00:15:56, 0.738s/it]: train_loss_raw=0.3794, running_loss=0.3679, LR=0.000100
[2025-08-27 15:15:09,828][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078792] [Batch 01792/03080] [00:22:01/00:15:49, 0.737s/it]: train_loss_raw=0.3489, running_loss=0.3658, LR=0.000100
[2025-08-27 15:15:15,932][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078800] [Batch 01800/03080] [00:22:07/00:15:44, 0.738s/it]: train_loss_raw=0.3831, running_loss=0.3668, LR=0.000100
[2025-08-27 15:15:22,134][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078808] [Batch 01808/03080] [00:22:13/00:15:38, 0.738s/it]: train_loss_raw=0.4247, running_loss=0.3669, LR=0.000100
[2025-08-27 15:15:27,990][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078816] [Batch 01816/03080] [00:22:19/00:15:32, 0.738s/it]: train_loss_raw=0.3706, running_loss=0.3696, LR=0.000100
[2025-08-27 15:15:33,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078824] [Batch 01824/03080] [00:22:25/00:15:26, 0.738s/it]: train_loss_raw=0.3781, running_loss=0.3698, LR=0.000100
[2025-08-27 15:15:39,610][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078832] [Batch 01832/03080] [00:22:31/00:15:20, 0.738s/it]: train_loss_raw=0.4943, running_loss=0.3720, LR=0.000100
[2025-08-27 15:15:45,474][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078840] [Batch 01840/03080] [00:22:37/00:15:14, 0.738s/it]: train_loss_raw=0.4120, running_loss=0.3712, LR=0.000100
[2025-08-27 15:15:51,263][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078848] [Batch 01848/03080] [00:22:42/00:15:08, 0.738s/it]: train_loss_raw=0.3401, running_loss=0.3697, LR=0.000100
[2025-08-27 15:15:56,770][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078856] [Batch 01856/03080] [00:22:48/00:15:02, 0.737s/it]: train_loss_raw=0.4152, running_loss=0.3691, LR=0.000100
[2025-08-27 15:16:02,611][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078864] [Batch 01864/03080] [00:22:54/00:14:56, 0.737s/it]: train_loss_raw=0.3085, running_loss=0.3695, LR=0.000100
[2025-08-27 15:16:08,229][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078872] [Batch 01872/03080] [00:22:59/00:14:50, 0.737s/it]: train_loss_raw=0.4014, running_loss=0.3702, LR=0.000100
[2025-08-27 15:16:13,812][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078880] [Batch 01880/03080] [00:23:05/00:14:44, 0.737s/it]: train_loss_raw=0.3354, running_loss=0.3689, LR=0.000100
[2025-08-27 15:16:19,734][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078888] [Batch 01888/03080] [00:23:11/00:14:38, 0.737s/it]: train_loss_raw=0.4259, running_loss=0.3708, LR=0.000100
[2025-08-27 15:16:25,489][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078896] [Batch 01896/03080] [00:23:17/00:14:32, 0.737s/it]: train_loss_raw=0.4156, running_loss=0.3717, LR=0.000100
[2025-08-27 15:16:31,613][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078904] [Batch 01904/03080] [00:23:23/00:14:26, 0.737s/it]: train_loss_raw=0.3705, running_loss=0.3708, LR=0.000100
[2025-08-27 15:16:37,642][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078912] [Batch 01912/03080] [00:23:29/00:14:20, 0.737s/it]: train_loss_raw=0.4369, running_loss=0.3709, LR=0.000100
[2025-08-27 15:16:43,730][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078920] [Batch 01920/03080] [00:23:35/00:14:15, 0.737s/it]: train_loss_raw=0.2928, running_loss=0.3686, LR=0.000100
[2025-08-27 15:16:49,710][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078928] [Batch 01928/03080] [00:23:41/00:14:09, 0.737s/it]: train_loss_raw=0.3590, running_loss=0.3668, LR=0.000100
[2025-08-27 15:16:55,532][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078936] [Batch 01936/03080] [00:23:47/00:14:03, 0.737s/it]: train_loss_raw=0.3356, running_loss=0.3663, LR=0.000100
[2025-08-27 15:17:01,598][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078944] [Batch 01944/03080] [00:23:53/00:13:57, 0.737s/it]: train_loss_raw=0.3470, running_loss=0.3654, LR=0.000100
[2025-08-27 15:17:07,209][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078952] [Batch 01952/03080] [00:23:58/00:13:51, 0.737s/it]: train_loss_raw=0.3984, running_loss=0.3673, LR=0.000100
[2025-08-27 15:17:13,123][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078960] [Batch 01960/03080] [00:24:04/00:13:45, 0.737s/it]: train_loss_raw=0.3511, running_loss=0.3671, LR=0.000100
[2025-08-27 15:17:19,183][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078968] [Batch 01968/03080] [00:24:10/00:13:39, 0.737s/it]: train_loss_raw=0.3753, running_loss=0.3676, LR=0.000100
[2025-08-27 15:17:25,160][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078976] [Batch 01976/03080] [00:24:16/00:13:33, 0.737s/it]: train_loss_raw=0.4070, running_loss=0.3674, LR=0.000100
[2025-08-27 15:17:31,081][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078984] [Batch 01984/03080] [00:24:22/00:13:28, 0.737s/it]: train_loss_raw=0.3862, running_loss=0.3690, LR=0.000100
[2025-08-27 15:17:36,764][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078992] [Batch 01992/03080] [00:24:28/00:13:22, 0.737s/it]: train_loss_raw=0.3584, running_loss=0.3695, LR=0.000100
[2025-08-27 15:17:42,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079000] [Batch 02000/03080] [00:24:34/00:13:16, 0.737s/it]: train_loss_raw=0.3497, running_loss=0.3690, LR=0.000100
[2025-08-27 15:17:48,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079008] [Batch 02008/03080] [00:24:40/00:13:10, 0.737s/it]: train_loss_raw=0.3333, running_loss=0.3697, LR=0.000100
[2025-08-27 15:17:53,763][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079016] [Batch 02016/03080] [00:24:45/00:13:04, 0.737s/it]: train_loss_raw=0.2871, running_loss=0.3669, LR=0.000100
[2025-08-27 15:17:59,719][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079024] [Batch 02024/03080] [00:24:51/00:12:58, 0.737s/it]: train_loss_raw=0.4041, running_loss=0.3658, LR=0.000100
[2025-08-27 15:18:05,805][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079032] [Batch 02032/03080] [00:24:57/00:12:52, 0.737s/it]: train_loss_raw=0.4382, running_loss=0.3672, LR=0.000100
[2025-08-27 15:18:11,776][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079040] [Batch 02040/03080] [00:25:03/00:12:46, 0.737s/it]: train_loss_raw=0.2569, running_loss=0.3654, LR=0.000100
[2025-08-27 15:18:17,759][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079048] [Batch 02048/03080] [00:25:09/00:12:40, 0.737s/it]: train_loss_raw=0.3549, running_loss=0.3655, LR=0.000100
[2025-08-27 15:18:23,728][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079056] [Batch 02056/03080] [00:25:15/00:12:34, 0.737s/it]: train_loss_raw=0.4080, running_loss=0.3659, LR=0.000100
[2025-08-27 15:18:29,405][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079064] [Batch 02064/03080] [00:25:21/00:12:28, 0.737s/it]: train_loss_raw=0.4006, running_loss=0.3658, LR=0.000100
[2025-08-27 15:18:35,156][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079072] [Batch 02072/03080] [00:25:26/00:12:22, 0.737s/it]: train_loss_raw=0.3225, running_loss=0.3650, LR=0.000100
[2025-08-27 15:18:40,913][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079080] [Batch 02080/03080] [00:25:32/00:12:16, 0.737s/it]: train_loss_raw=0.3451, running_loss=0.3669, LR=0.000100
[2025-08-27 15:18:46,849][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079088] [Batch 02088/03080] [00:25:38/00:12:10, 0.737s/it]: train_loss_raw=0.3667, running_loss=0.3677, LR=0.000100
[2025-08-27 15:18:52,634][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079096] [Batch 02096/03080] [00:25:44/00:12:05, 0.737s/it]: train_loss_raw=0.3372, running_loss=0.3671, LR=0.000100
[2025-08-27 15:18:58,535][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079104] [Batch 02104/03080] [00:25:50/00:11:59, 0.737s/it]: train_loss_raw=0.2735, running_loss=0.3640, LR=0.000100
[2025-08-27 15:19:03,912][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079112] [Batch 02112/03080] [00:25:55/00:11:53, 0.737s/it]: train_loss_raw=0.3701, running_loss=0.3642, LR=0.000100
[2025-08-27 15:19:09,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079120] [Batch 02120/03080] [00:26:01/00:11:47, 0.737s/it]: train_loss_raw=0.3520, running_loss=0.3652, LR=0.000100
[2025-08-27 15:19:15,826][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079128] [Batch 02128/03080] [00:26:07/00:11:41, 0.737s/it]: train_loss_raw=0.4461, running_loss=0.3638, LR=0.000100
[2025-08-27 15:19:21,958][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079136] [Batch 02136/03080] [00:26:13/00:11:35, 0.737s/it]: train_loss_raw=0.3946, running_loss=0.3646, LR=0.000100
[2025-08-27 15:19:27,625][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079144] [Batch 02144/03080] [00:26:19/00:11:29, 0.737s/it]: train_loss_raw=0.3821, running_loss=0.3662, LR=0.000100
[2025-08-27 15:19:33,504][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079152] [Batch 02152/03080] [00:26:25/00:11:23, 0.737s/it]: train_loss_raw=0.4089, running_loss=0.3681, LR=0.000100
[2025-08-27 15:19:39,154][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079160] [Batch 02160/03080] [00:26:30/00:11:17, 0.737s/it]: train_loss_raw=0.3455, running_loss=0.3664, LR=0.000100
[2025-08-27 15:19:44,540][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079168] [Batch 02168/03080] [00:26:36/00:11:11, 0.736s/it]: train_loss_raw=0.3284, running_loss=0.3645, LR=0.000100
[2025-08-27 15:19:50,203][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079176] [Batch 02176/03080] [00:26:41/00:11:05, 0.736s/it]: train_loss_raw=0.4057, running_loss=0.3634, LR=0.000100
[2025-08-27 15:19:55,627][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079184] [Batch 02184/03080] [00:26:47/00:10:59, 0.736s/it]: train_loss_raw=0.3209, running_loss=0.3638, LR=0.000100
[2025-08-27 15:20:01,761][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079192] [Batch 02192/03080] [00:26:53/00:10:53, 0.736s/it]: train_loss_raw=0.3542, running_loss=0.3628, LR=0.000100
[2025-08-27 15:20:07,796][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079200] [Batch 02200/03080] [00:26:59/00:10:47, 0.736s/it]: train_loss_raw=0.3974, running_loss=0.3631, LR=0.000100
[2025-08-27 15:20:13,788][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079208] [Batch 02208/03080] [00:27:05/00:10:41, 0.736s/it]: train_loss_raw=0.3961, running_loss=0.3638, LR=0.000100
[2025-08-27 15:20:19,750][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079216] [Batch 02216/03080] [00:27:11/00:10:36, 0.736s/it]: train_loss_raw=0.3949, running_loss=0.3652, LR=0.000100
[2025-08-27 15:20:25,579][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079224] [Batch 02224/03080] [00:27:17/00:10:30, 0.736s/it]: train_loss_raw=0.3949, running_loss=0.3662, LR=0.000100
[2025-08-27 15:20:31,259][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079232] [Batch 02232/03080] [00:27:22/00:10:24, 0.736s/it]: train_loss_raw=0.3454, running_loss=0.3659, LR=0.000100
[2025-08-27 15:20:36,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079240] [Batch 02240/03080] [00:27:28/00:10:18, 0.736s/it]: train_loss_raw=0.3886, running_loss=0.3673, LR=0.000100
[2025-08-27 15:20:43,057][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079248] [Batch 02248/03080] [00:27:34/00:10:12, 0.736s/it]: train_loss_raw=0.4217, running_loss=0.3697, LR=0.000100
[2025-08-27 15:20:48,808][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079256] [Batch 02256/03080] [00:27:40/00:10:06, 0.736s/it]: train_loss_raw=0.3381, running_loss=0.3710, LR=0.000100
[2025-08-27 15:20:54,805][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079264] [Batch 02264/03080] [00:27:46/00:10:00, 0.736s/it]: train_loss_raw=0.4152, running_loss=0.3710, LR=0.000100
[2025-08-27 15:21:00,817][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079272] [Batch 02272/03080] [00:27:52/00:09:54, 0.736s/it]: train_loss_raw=0.3190, running_loss=0.3695, LR=0.000100
[2025-08-27 15:21:06,823][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079280] [Batch 02280/03080] [00:27:58/00:09:48, 0.736s/it]: train_loss_raw=0.3917, running_loss=0.3691, LR=0.000100
[2025-08-27 15:21:12,850][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079288] [Batch 02288/03080] [00:28:04/00:09:43, 0.736s/it]: train_loss_raw=0.3842, running_loss=0.3679, LR=0.000100
[2025-08-27 15:21:18,921][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079296] [Batch 02296/03080] [00:28:10/00:09:37, 0.736s/it]: train_loss_raw=0.2949, running_loss=0.3669, LR=0.000100
[2025-08-27 15:21:24,858][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079304] [Batch 02304/03080] [00:28:16/00:09:31, 0.736s/it]: train_loss_raw=0.3841, running_loss=0.3652, LR=0.000100
[2025-08-27 15:21:31,048][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079312] [Batch 02312/03080] [00:28:22/00:09:25, 0.736s/it]: train_loss_raw=0.4501, running_loss=0.3661, LR=0.000100
[2025-08-27 15:21:37,198][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079320] [Batch 02320/03080] [00:28:28/00:09:19, 0.737s/it]: train_loss_raw=0.3619, running_loss=0.3668, LR=0.000100
[2025-08-27 15:21:43,306][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079328] [Batch 02328/03080] [00:28:35/00:09:13, 0.737s/it]: train_loss_raw=0.3399, running_loss=0.3673, LR=0.000100
[2025-08-27 15:21:48,916][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079336] [Batch 02336/03080] [00:28:40/00:09:08, 0.737s/it]: train_loss_raw=0.4072, running_loss=0.3669, LR=0.000100
[2025-08-27 15:21:54,572][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079344] [Batch 02344/03080] [00:28:46/00:09:02, 0.736s/it]: train_loss_raw=0.3174, running_loss=0.3668, LR=0.000100
[2025-08-27 15:22:00,593][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079352] [Batch 02352/03080] [00:28:52/00:08:56, 0.737s/it]: train_loss_raw=0.3416, running_loss=0.3679, LR=0.000100
[2025-08-27 15:22:06,592][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079360] [Batch 02360/03080] [00:28:58/00:08:50, 0.737s/it]: train_loss_raw=0.4772, running_loss=0.3702, LR=0.000100
[2025-08-27 15:22:12,367][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079368] [Batch 02368/03080] [00:29:04/00:08:44, 0.737s/it]: train_loss_raw=0.3126, running_loss=0.3676, LR=0.000100
[2025-08-27 15:22:18,352][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079376] [Batch 02376/03080] [00:29:10/00:08:38, 0.737s/it]: train_loss_raw=0.3656, running_loss=0.3686, LR=0.000100
[2025-08-27 15:22:24,557][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079384] [Batch 02384/03080] [00:29:16/00:08:32, 0.737s/it]: train_loss_raw=0.4117, running_loss=0.3685, LR=0.000100
[2025-08-27 15:22:30,020][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079392] [Batch 02392/03080] [00:29:21/00:08:26, 0.737s/it]: train_loss_raw=0.2977, running_loss=0.3684, LR=0.000100
[2025-08-27 15:22:35,965][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079400] [Batch 02400/03080] [00:29:27/00:08:20, 0.737s/it]: train_loss_raw=0.3897, running_loss=0.3681, LR=0.000100
[2025-08-27 15:22:41,994][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079408] [Batch 02408/03080] [00:29:33/00:08:14, 0.737s/it]: train_loss_raw=0.3854, running_loss=0.3680, LR=0.000100
[2025-08-27 15:22:47,963][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079416] [Batch 02416/03080] [00:29:39/00:08:09, 0.737s/it]: train_loss_raw=0.3705, running_loss=0.3689, LR=0.000100
[2025-08-27 15:22:53,751][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079424] [Batch 02424/03080] [00:29:45/00:08:03, 0.737s/it]: train_loss_raw=0.2838, running_loss=0.3681, LR=0.000100
[2025-08-27 15:22:59,670][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079432] [Batch 02432/03080] [00:29:51/00:07:57, 0.737s/it]: train_loss_raw=0.3723, running_loss=0.3674, LR=0.000100
[2025-08-27 15:23:05,666][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079440] [Batch 02440/03080] [00:29:57/00:07:51, 0.737s/it]: train_loss_raw=0.4174, running_loss=0.3684, LR=0.000100
[2025-08-27 15:23:11,348][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079448] [Batch 02448/03080] [00:30:03/00:07:45, 0.737s/it]: train_loss_raw=0.3399, running_loss=0.3665, LR=0.000100
[2025-08-27 15:23:17,182][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079456] [Batch 02456/03080] [00:30:08/00:07:39, 0.737s/it]: train_loss_raw=0.3819, running_loss=0.3661, LR=0.000100
[2025-08-27 15:23:23,310][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079464] [Batch 02464/03080] [00:30:15/00:07:33, 0.737s/it]: train_loss_raw=0.3399, running_loss=0.3675, LR=0.000100
[2025-08-27 15:23:29,410][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079472] [Batch 02472/03080] [00:30:21/00:07:27, 0.737s/it]: train_loss_raw=0.4109, running_loss=0.3663, LR=0.000100
[2025-08-27 15:23:35,466][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079480] [Batch 02480/03080] [00:30:27/00:07:22, 0.737s/it]: train_loss_raw=0.3258, running_loss=0.3670, LR=0.000100
[2025-08-27 15:23:41,393][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079488] [Batch 02488/03080] [00:30:33/00:07:16, 0.737s/it]: train_loss_raw=0.4234, running_loss=0.3667, LR=0.000100
[2025-08-27 15:23:47,180][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079496] [Batch 02496/03080] [00:30:38/00:07:10, 0.737s/it]: train_loss_raw=0.3604, running_loss=0.3675, LR=0.000100
[2025-08-27 15:23:52,801][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079504] [Batch 02504/03080] [00:30:44/00:07:04, 0.737s/it]: train_loss_raw=0.2986, running_loss=0.3678, LR=0.000100
[2025-08-27 15:23:58,520][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079512] [Batch 02512/03080] [00:30:50/00:06:58, 0.737s/it]: train_loss_raw=0.3298, running_loss=0.3661, LR=0.000100
[2025-08-27 15:24:04,302][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079520] [Batch 02520/03080] [00:30:56/00:06:52, 0.737s/it]: train_loss_raw=0.4363, running_loss=0.3670, LR=0.000100
[2025-08-27 15:24:10,358][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079528] [Batch 02528/03080] [00:31:02/00:06:46, 0.737s/it]: train_loss_raw=0.3572, running_loss=0.3691, LR=0.000100
[2025-08-27 15:24:16,422][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079536] [Batch 02536/03080] [00:31:08/00:06:40, 0.737s/it]: train_loss_raw=0.3036, running_loss=0.3679, LR=0.000100
[2025-08-27 15:24:22,325][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079544] [Batch 02544/03080] [00:31:14/00:06:34, 0.737s/it]: train_loss_raw=0.3316, running_loss=0.3685, LR=0.000100
[2025-08-27 15:24:28,388][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079552] [Batch 02552/03080] [00:31:20/00:06:28, 0.737s/it]: train_loss_raw=0.3791, running_loss=0.3679, LR=0.000100
[2025-08-27 15:24:34,043][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079560] [Batch 02560/03080] [00:31:25/00:06:23, 0.737s/it]: train_loss_raw=0.3920, running_loss=0.3698, LR=0.000100
[2025-08-27 15:24:40,120][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079568] [Batch 02568/03080] [00:31:31/00:06:17, 0.737s/it]: train_loss_raw=0.4171, running_loss=0.3682, LR=0.000100
[2025-08-27 15:24:46,211][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079576] [Batch 02576/03080] [00:31:37/00:06:11, 0.737s/it]: train_loss_raw=0.4513, running_loss=0.3688, LR=0.000100
[2025-08-27 15:24:52,222][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079584] [Batch 02584/03080] [00:31:43/00:06:05, 0.737s/it]: train_loss_raw=0.4325, running_loss=0.3695, LR=0.000100
[2025-08-27 15:24:58,093][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079592] [Batch 02592/03080] [00:31:49/00:05:59, 0.737s/it]: train_loss_raw=0.4430, running_loss=0.3702, LR=0.000100
[2025-08-27 15:25:04,164][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079600] [Batch 02600/03080] [00:31:55/00:05:53, 0.737s/it]: train_loss_raw=0.3869, running_loss=0.3689, LR=0.000100
[2025-08-27 15:25:10,219][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079608] [Batch 02608/03080] [00:32:01/00:05:47, 0.737s/it]: train_loss_raw=0.3237, running_loss=0.3705, LR=0.000100
[2025-08-27 15:25:16,472][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079616] [Batch 02616/03080] [00:32:08/00:05:42, 0.737s/it]: train_loss_raw=0.3519, running_loss=0.3701, LR=0.000100
[2025-08-27 15:25:22,583][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079624] [Batch 02624/03080] [00:32:14/00:05:36, 0.737s/it]: train_loss_raw=0.3230, running_loss=0.3694, LR=0.000100
[2025-08-27 15:25:28,392][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079632] [Batch 02632/03080] [00:32:20/00:05:30, 0.737s/it]: train_loss_raw=0.3018, running_loss=0.3701, LR=0.000100
[2025-08-27 15:25:34,594][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079640] [Batch 02640/03080] [00:32:26/00:05:24, 0.737s/it]: train_loss_raw=0.3911, running_loss=0.3712, LR=0.000100
[2025-08-27 15:25:40,594][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079648] [Batch 02648/03080] [00:32:32/00:05:18, 0.737s/it]: train_loss_raw=0.4058, running_loss=0.3730, LR=0.000100
[2025-08-27 15:25:46,503][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079656] [Batch 02656/03080] [00:32:38/00:05:12, 0.737s/it]: train_loss_raw=0.4322, running_loss=0.3724, LR=0.000100
[2025-08-27 15:25:52,392][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079664] [Batch 02664/03080] [00:32:44/00:05:06, 0.737s/it]: train_loss_raw=0.4028, running_loss=0.3729, LR=0.000100
[2025-08-27 15:25:58,110][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079672] [Batch 02672/03080] [00:32:49/00:05:00, 0.737s/it]: train_loss_raw=0.2836, running_loss=0.3720, LR=0.000100
[2025-08-27 15:26:04,004][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079680] [Batch 02680/03080] [00:32:55/00:04:54, 0.737s/it]: train_loss_raw=0.3641, running_loss=0.3730, LR=0.000100
[2025-08-27 15:26:10,153][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079688] [Batch 02688/03080] [00:33:01/00:04:49, 0.737s/it]: train_loss_raw=0.3670, running_loss=0.3728, LR=0.000100
[2025-08-27 15:26:16,121][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079696] [Batch 02696/03080] [00:33:07/00:04:43, 0.737s/it]: train_loss_raw=0.4465, running_loss=0.3726, LR=0.000100
[2025-08-27 15:26:22,259][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079704] [Batch 02704/03080] [00:33:13/00:04:37, 0.737s/it]: train_loss_raw=0.3748, running_loss=0.3729, LR=0.000100
[2025-08-27 15:26:28,125][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079712] [Batch 02712/03080] [00:33:19/00:04:31, 0.737s/it]: train_loss_raw=0.3516, running_loss=0.3729, LR=0.000100
[2025-08-27 15:26:34,133][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079720] [Batch 02720/03080] [00:33:25/00:04:25, 0.737s/it]: train_loss_raw=0.3084, running_loss=0.3717, LR=0.000100
[2025-08-27 15:26:40,153][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079728] [Batch 02728/03080] [00:33:31/00:04:19, 0.737s/it]: train_loss_raw=0.3510, running_loss=0.3708, LR=0.000100
[2025-08-27 15:26:46,265][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079736] [Batch 02736/03080] [00:33:38/00:04:13, 0.738s/it]: train_loss_raw=0.3690, running_loss=0.3708, LR=0.000100
[2025-08-27 15:26:51,803][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079744] [Batch 02744/03080] [00:33:43/00:04:07, 0.737s/it]: train_loss_raw=0.3050, running_loss=0.3711, LR=0.000100
[2025-08-27 15:26:57,756][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079752] [Batch 02752/03080] [00:33:49/00:04:01, 0.737s/it]: train_loss_raw=0.3341, running_loss=0.3710, LR=0.000100
[2025-08-27 15:27:03,348][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079760] [Batch 02760/03080] [00:33:55/00:03:55, 0.737s/it]: train_loss_raw=0.3671, running_loss=0.3696, LR=0.000100
[2025-08-27 15:27:09,326][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079768] [Batch 02768/03080] [00:34:01/00:03:50, 0.737s/it]: train_loss_raw=0.3137, running_loss=0.3686, LR=0.000100
[2025-08-27 15:27:15,266][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079776] [Batch 02776/03080] [00:34:07/00:03:44, 0.737s/it]: train_loss_raw=0.3225, running_loss=0.3685, LR=0.000100
[2025-08-27 15:27:21,221][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079784] [Batch 02784/03080] [00:34:12/00:03:38, 0.737s/it]: train_loss_raw=0.4157, running_loss=0.3665, LR=0.000100
[2025-08-27 15:27:26,958][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079792] [Batch 02792/03080] [00:34:18/00:03:32, 0.737s/it]: train_loss_raw=0.3893, running_loss=0.3655, LR=0.000100
[2025-08-27 15:27:33,111][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079800] [Batch 02800/03080] [00:34:24/00:03:26, 0.737s/it]: train_loss_raw=0.3690, running_loss=0.3652, LR=0.000100
[2025-08-27 15:27:38,896][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079808] [Batch 02808/03080] [00:34:30/00:03:20, 0.737s/it]: train_loss_raw=0.3674, running_loss=0.3653, LR=0.000100
[2025-08-27 15:27:44,576][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079816] [Batch 02816/03080] [00:34:36/00:03:14, 0.737s/it]: train_loss_raw=0.2868, running_loss=0.3610, LR=0.000100
[2025-08-27 15:27:50,428][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079824] [Batch 02824/03080] [00:34:42/00:03:08, 0.737s/it]: train_loss_raw=0.3306, running_loss=0.3630, LR=0.000100
[2025-08-27 15:27:56,338][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079832] [Batch 02832/03080] [00:34:48/00:03:02, 0.737s/it]: train_loss_raw=0.3678, running_loss=0.3634, LR=0.000100
[2025-08-27 15:28:02,679][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079840] [Batch 02840/03080] [00:34:54/00:02:56, 0.737s/it]: train_loss_raw=0.4234, running_loss=0.3646, LR=0.000100
[2025-08-27 15:28:08,678][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079848] [Batch 02848/03080] [00:35:00/00:02:51, 0.738s/it]: train_loss_raw=0.3946, running_loss=0.3652, LR=0.000100
[2025-08-27 15:28:14,648][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079856] [Batch 02856/03080] [00:35:06/00:02:45, 0.738s/it]: train_loss_raw=0.3367, running_loss=0.3647, LR=0.000100
[2025-08-27 15:28:20,810][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079864] [Batch 02864/03080] [00:35:12/00:02:39, 0.738s/it]: train_loss_raw=0.4124, running_loss=0.3639, LR=0.000100
[2025-08-27 15:28:27,030][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079872] [Batch 02872/03080] [00:35:18/00:02:33, 0.738s/it]: train_loss_raw=0.3840, running_loss=0.3639, LR=0.000100
[2025-08-27 15:28:32,694][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079880] [Batch 02880/03080] [00:35:24/00:02:27, 0.738s/it]: train_loss_raw=0.3260, running_loss=0.3615, LR=0.000100
[2025-08-27 15:28:38,810][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079888] [Batch 02888/03080] [00:35:30/00:02:21, 0.738s/it]: train_loss_raw=0.4463, running_loss=0.3640, LR=0.000100
[2025-08-27 15:28:44,864][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079896] [Batch 02896/03080] [00:35:36/00:02:15, 0.738s/it]: train_loss_raw=0.3095, running_loss=0.3634, LR=0.000100
[2025-08-27 15:28:51,014][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079904] [Batch 02904/03080] [00:35:42/00:02:09, 0.738s/it]: train_loss_raw=0.3541, running_loss=0.3629, LR=0.000100
[2025-08-27 15:28:56,922][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079912] [Batch 02912/03080] [00:35:48/00:02:03, 0.738s/it]: train_loss_raw=0.4095, running_loss=0.3651, LR=0.000100
[2025-08-27 15:29:02,326][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079920] [Batch 02920/03080] [00:35:54/00:01:58, 0.738s/it]: train_loss_raw=0.3561, running_loss=0.3624, LR=0.000100
[2025-08-27 15:29:08,161][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079928] [Batch 02928/03080] [00:35:59/00:01:52, 0.738s/it]: train_loss_raw=0.3252, running_loss=0.3622, LR=0.000100
[2025-08-27 15:29:14,097][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079936] [Batch 02936/03080] [00:36:05/00:01:46, 0.738s/it]: train_loss_raw=0.3516, running_loss=0.3597, LR=0.000100
[2025-08-27 15:29:19,606][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079944] [Batch 02944/03080] [00:36:11/00:01:40, 0.738s/it]: train_loss_raw=0.3257, running_loss=0.3611, LR=0.000100
[2025-08-27 15:29:25,436][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079952] [Batch 02952/03080] [00:36:17/00:01:34, 0.738s/it]: train_loss_raw=0.3519, running_loss=0.3628, LR=0.000100
[2025-08-27 15:29:31,562][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079960] [Batch 02960/03080] [00:36:23/00:01:28, 0.738s/it]: train_loss_raw=0.3907, running_loss=0.3636, LR=0.000100
[2025-08-27 15:29:37,703][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079968] [Batch 02968/03080] [00:36:29/00:01:22, 0.738s/it]: train_loss_raw=0.3033, running_loss=0.3634, LR=0.000100
[2025-08-27 15:29:43,772][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079976] [Batch 02976/03080] [00:36:35/00:01:16, 0.738s/it]: train_loss_raw=0.3237, running_loss=0.3621, LR=0.000100
[2025-08-27 15:29:49,967][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079984] [Batch 02984/03080] [00:36:41/00:01:10, 0.738s/it]: train_loss_raw=0.4369, running_loss=0.3642, LR=0.000100
[2025-08-27 15:29:56,013][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079992] [Batch 02992/03080] [00:36:47/00:01:04, 0.738s/it]: train_loss_raw=0.3269, running_loss=0.3633, LR=0.000100
[2025-08-27 15:30:01,529][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080000] [Batch 03000/03080] [00:36:53/00:00:59, 0.738s/it]: train_loss_raw=0.3572, running_loss=0.3632, LR=0.000100
[2025-08-27 15:30:11,153][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080008] [Batch 03008/03080] [00:37:02/00:00:53, 0.739s/it]: train_loss_raw=0.3240, running_loss=0.3634, LR=0.000100
[2025-08-27 15:30:16,987][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080016] [Batch 03016/03080] [00:37:08/00:00:47, 0.739s/it]: train_loss_raw=0.3562, running_loss=0.3641, LR=0.000100
[2025-08-27 15:30:22,770][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080024] [Batch 03024/03080] [00:37:14/00:00:41, 0.739s/it]: train_loss_raw=0.3347, running_loss=0.3649, LR=0.000100
[2025-08-27 15:30:28,554][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080032] [Batch 03032/03080] [00:37:20/00:00:35, 0.739s/it]: train_loss_raw=0.4172, running_loss=0.3647, LR=0.000100
[2025-08-27 15:30:34,524][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080040] [Batch 03040/03080] [00:37:26/00:00:29, 0.739s/it]: train_loss_raw=0.3196, running_loss=0.3645, LR=0.000100
[2025-08-27 15:30:40,384][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080048] [Batch 03048/03080] [00:37:32/00:00:23, 0.739s/it]: train_loss_raw=0.4225, running_loss=0.3660, LR=0.000100
[2025-08-27 15:30:46,076][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080056] [Batch 03056/03080] [00:37:37/00:00:17, 0.739s/it]: train_loss_raw=0.3470, running_loss=0.3669, LR=0.000100
[2025-08-27 15:30:51,881][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080064] [Batch 03064/03080] [00:37:43/00:00:11, 0.739s/it]: train_loss_raw=0.4432, running_loss=0.3682, LR=0.000100
[2025-08-27 15:30:57,436][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080072] [Batch 03072/03080] [00:37:49/00:00:05, 0.739s/it]: train_loss_raw=0.3242, running_loss=0.3679, LR=0.000100
[2025-08-27 15:31:09,927][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080080] [Batch 03080/03080] [00:38:01/00:00:00, 0.741s/it]: train_loss_raw=0.3227, running_loss=0.3666, LR=0.000100
[2025-08-27 15:31:10,387][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-27 15:31:21,016][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00007/00310] [00:00:10/00:06:41, 1.329s/it]
[2025-08-27 15:31:32,675][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00015/00310] [00:00:22/00:06:49, 1.393s/it]
[2025-08-27 15:31:43,837][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00023/00310] [00:00:33/00:06:38, 1.394s/it]
[2025-08-27 15:31:55,996][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00031/00310] [00:00:45/00:06:36, 1.425s/it]
[2025-08-27 15:32:08,296][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00039/00310] [00:00:57/00:06:30, 1.448s/it]
[2025-08-27 15:32:19,824][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00047/00310] [00:01:09/00:06:19, 1.447s/it]
[2025-08-27 15:32:31,710][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00055/00310] [00:01:21/00:06:08, 1.452s/it]
[2025-08-27 15:32:43,957][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00063/00310] [00:01:33/00:05:59, 1.462s/it]
[2025-08-27 15:32:55,698][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00071/00310] [00:01:45/00:05:48, 1.463s/it]
[2025-08-27 15:33:07,369][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00079/00310] [00:01:56/00:05:36, 1.462s/it]
[2025-08-27 15:33:18,494][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00087/00310] [00:02:08/00:05:23, 1.456s/it]
[2025-08-27 15:33:30,632][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00095/00310] [00:02:20/00:05:12, 1.461s/it]
[2025-08-27 15:33:42,430][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00103/00310] [00:02:32/00:05:01, 1.462s/it]
[2025-08-27 15:33:53,992][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00111/00310] [00:02:43/00:04:49, 1.461s/it]
[2025-08-27 15:34:06,021][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00119/00310] [00:02:55/00:04:38, 1.464s/it]
[2025-08-27 15:34:18,071][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00127/00310] [00:03:07/00:04:26, 1.466s/it]
[2025-08-27 15:34:30,443][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00135/00310] [00:03:20/00:04:15, 1.471s/it]
[2025-08-27 15:34:42,148][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00143/00310] [00:03:31/00:04:04, 1.471s/it]
[2025-08-27 15:34:53,445][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00151/00310] [00:03:43/00:03:51, 1.467s/it]
[2025-08-27 15:35:03,721][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00159/00310] [00:03:53/00:03:38, 1.458s/it]
[2025-08-27 15:35:15,172][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00167/00310] [00:04:04/00:03:26, 1.457s/it]
[2025-08-27 15:35:25,923][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00175/00310] [00:04:15/00:03:14, 1.452s/it]
[2025-08-27 15:35:36,686][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00183/00310] [00:04:26/00:03:02, 1.447s/it]
[2025-08-27 15:35:48,606][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00191/00310] [00:04:38/00:02:50, 1.449s/it]
[2025-08-27 15:35:59,334][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00199/00310] [00:04:48/00:02:38, 1.445s/it]
[2025-08-27 15:36:09,940][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00207/00310] [00:04:59/00:02:26, 1.440s/it]
[2025-08-27 15:36:21,193][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00215/00310] [00:05:10/00:02:15, 1.439s/it]
[2025-08-27 15:36:32,805][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00223/00310] [00:05:22/00:02:03, 1.439s/it]
[2025-08-27 15:36:44,696][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00231/00310] [00:05:34/00:01:52, 1.441s/it]
[2025-08-27 15:36:55,073][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00239/00310] [00:05:44/00:01:40, 1.436s/it]
[2025-08-27 15:37:05,250][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00247/00310] [00:05:54/00:01:28, 1.431s/it]
[2025-08-27 15:37:17,489][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00255/00310] [00:06:07/00:01:17, 1.434s/it]
[2025-08-27 15:37:29,286][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00263/00310] [00:06:18/00:01:06, 1.435s/it]
[2025-08-27 15:37:41,076][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00271/00310] [00:06:30/00:00:54, 1.436s/it]
[2025-08-27 15:37:52,691][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00279/00310] [00:06:42/00:00:43, 1.437s/it]
[2025-08-27 15:38:05,103][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00287/00310] [00:06:54/00:00:31, 1.440s/it]
[2025-08-27 15:38:16,090][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00295/00310] [00:07:05/00:00:20, 1.438s/it]
[2025-08-27 15:38:28,466][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00303/00310] [00:07:18/00:00:08, 1.441s/it]
[2025-08-27 15:38:38,139][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.36663, valid_loss=1.42233
[2025-08-27 15:38:38,140][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-27 15:38:38,140][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.479
[2025-08-27 15:38:38,140][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.155
[2025-08-27 15:38:38,140][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.158
[2025-08-27 15:38:38,140][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.086
[2025-08-27 15:38:38,157][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 20:11:52, remaining time 03:06:26, 00:46:36 per epoch
[2025-08-27 15:38:44,221][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080088] [Batch 00008/03080] [00:00:05/00:36:11, 0.707s/it]: train_loss_raw=0.3166, running_loss=0.3591, LR=0.000100
[2025-08-27 15:38:50,312][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080096] [Batch 00016/03080] [00:00:11/00:37:29, 0.734s/it]: train_loss_raw=0.2899, running_loss=0.3575, LR=0.000100
[2025-08-27 15:38:56,683][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080104] [Batch 00024/03080] [00:00:18/00:38:26, 0.755s/it]: train_loss_raw=0.3969, running_loss=0.3562, LR=0.000100
[2025-08-27 15:39:02,766][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080112] [Batch 00032/03080] [00:00:24/00:38:24, 0.756s/it]: train_loss_raw=0.3102, running_loss=0.3556, LR=0.000100
[2025-08-27 15:39:08,806][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080120] [Batch 00040/03080] [00:00:30/00:38:18, 0.756s/it]: train_loss_raw=0.3484, running_loss=0.3546, LR=0.000100
[2025-08-27 15:39:14,692][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080128] [Batch 00048/03080] [00:00:36/00:38:01, 0.753s/it]: train_loss_raw=0.2739, running_loss=0.3536, LR=0.000100
[2025-08-27 15:39:20,540][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080136] [Batch 00056/03080] [00:00:41/00:37:46, 0.750s/it]: train_loss_raw=0.3355, running_loss=0.3544, LR=0.000100
[2025-08-27 15:39:26,503][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080144] [Batch 00064/03080] [00:00:47/00:37:38, 0.749s/it]: train_loss_raw=0.3627, running_loss=0.3528, LR=0.000100
[2025-08-27 15:39:32,406][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080152] [Batch 00072/03080] [00:00:53/00:37:29, 0.748s/it]: train_loss_raw=0.3385, running_loss=0.3538, LR=0.000100
[2025-08-27 15:39:38,151][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080160] [Batch 00080/03080] [00:00:59/00:37:14, 0.745s/it]: train_loss_raw=0.3563, running_loss=0.3545, LR=0.000100
[2025-08-27 15:39:44,183][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080168] [Batch 00088/03080] [00:01:05/00:37:10, 0.746s/it]: train_loss_raw=0.4157, running_loss=0.3544, LR=0.000100
[2025-08-27 15:39:50,197][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080176] [Batch 00096/03080] [00:01:11/00:37:06, 0.746s/it]: train_loss_raw=0.3786, running_loss=0.3528, LR=0.000100
[2025-08-27 15:39:56,076][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080184] [Batch 00104/03080] [00:01:17/00:36:57, 0.745s/it]: train_loss_raw=0.3956, running_loss=0.3523, LR=0.000100
[2025-08-27 15:40:02,025][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080192] [Batch 00112/03080] [00:01:23/00:36:51, 0.745s/it]: train_loss_raw=0.3638, running_loss=0.3518, LR=0.000100
[2025-08-27 15:40:08,051][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080200] [Batch 00120/03080] [00:01:29/00:36:47, 0.746s/it]: train_loss_raw=0.3302, running_loss=0.3521, LR=0.000100
[2025-08-27 15:40:14,026][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080208] [Batch 00128/03080] [00:01:35/00:36:41, 0.746s/it]: train_loss_raw=0.3083, running_loss=0.3492, LR=0.000100
[2025-08-27 15:40:19,842][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080216] [Batch 00136/03080] [00:01:41/00:36:32, 0.745s/it]: train_loss_raw=0.3203, running_loss=0.3488, LR=0.000100
[2025-08-27 15:40:25,412][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080224] [Batch 00144/03080] [00:01:46/00:36:18, 0.742s/it]: train_loss_raw=0.3519, running_loss=0.3487, LR=0.000100
[2025-08-27 15:40:31,221][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080232] [Batch 00152/03080] [00:01:52/00:36:10, 0.741s/it]: train_loss_raw=0.3815, running_loss=0.3488, LR=0.000100
[2025-08-27 15:40:36,921][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080240] [Batch 00160/03080] [00:01:58/00:35:59, 0.740s/it]: train_loss_raw=0.4172, running_loss=0.3473, LR=0.000100
[2025-08-27 15:40:43,051][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080248] [Batch 00168/03080] [00:02:04/00:35:57, 0.741s/it]: train_loss_raw=0.3390, running_loss=0.3452, LR=0.000100
[2025-08-27 15:40:48,621][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080256] [Batch 00176/03080] [00:02:10/00:35:45, 0.739s/it]: train_loss_raw=0.3528, running_loss=0.3472, LR=0.000100
[2025-08-27 15:40:54,310][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080264] [Batch 00184/03080] [00:02:15/00:35:36, 0.738s/it]: train_loss_raw=0.3708, running_loss=0.3458, LR=0.000100
[2025-08-27 15:40:59,880][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080272] [Batch 00192/03080] [00:02:21/00:35:25, 0.736s/it]: train_loss_raw=0.3482, running_loss=0.3446, LR=0.000100
[2025-08-27 15:41:05,925][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080280] [Batch 00200/03080] [00:02:27/00:35:21, 0.737s/it]: train_loss_raw=0.3097, running_loss=0.3445, LR=0.000100
[2025-08-27 15:41:11,617][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080288] [Batch 00208/03080] [00:02:33/00:35:13, 0.736s/it]: train_loss_raw=0.3350, running_loss=0.3442, LR=0.000100
[2025-08-27 15:41:17,571][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080296] [Batch 00216/03080] [00:02:39/00:35:08, 0.736s/it]: train_loss_raw=0.3518, running_loss=0.3430, LR=0.000100
[2025-08-27 15:41:23,555][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080304] [Batch 00224/03080] [00:02:44/00:35:03, 0.737s/it]: train_loss_raw=0.2868, running_loss=0.3439, LR=0.000100
[2025-08-27 15:41:29,681][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080312] [Batch 00232/03080] [00:02:51/00:35:00, 0.738s/it]: train_loss_raw=0.3062, running_loss=0.3433, LR=0.000100
[2025-08-27 15:41:35,513][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080320] [Batch 00240/03080] [00:02:56/00:34:53, 0.737s/it]: train_loss_raw=0.3050, running_loss=0.3447, LR=0.000100
[2025-08-27 15:41:41,485][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080328] [Batch 00248/03080] [00:03:02/00:34:48, 0.738s/it]: train_loss_raw=0.3129, running_loss=0.3459, LR=0.000100
[2025-08-27 15:41:47,509][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080336] [Batch 00256/03080] [00:03:08/00:34:44, 0.738s/it]: train_loss_raw=0.4003, running_loss=0.3451, LR=0.000100
[2025-08-27 15:41:53,325][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080344] [Batch 00264/03080] [00:03:14/00:34:37, 0.738s/it]: train_loss_raw=0.3542, running_loss=0.3464, LR=0.000100
[2025-08-27 15:41:59,179][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080352] [Batch 00272/03080] [00:03:20/00:34:31, 0.738s/it]: train_loss_raw=0.3771, running_loss=0.3457, LR=0.000100
[2025-08-27 15:42:05,098][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080360] [Batch 00280/03080] [00:03:26/00:34:25, 0.738s/it]: train_loss_raw=0.3167, running_loss=0.3462, LR=0.000100
[2025-08-27 15:42:11,112][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080368] [Batch 00288/03080] [00:03:32/00:34:20, 0.738s/it]: train_loss_raw=0.3748, running_loss=0.3444, LR=0.000100
[2025-08-27 15:42:17,329][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080376] [Batch 00296/03080] [00:03:38/00:34:17, 0.739s/it]: train_loss_raw=0.2852, running_loss=0.3447, LR=0.000100
[2025-08-27 15:42:22,980][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080384] [Batch 00304/03080] [00:03:44/00:34:09, 0.738s/it]: train_loss_raw=0.3128, running_loss=0.3445, LR=0.000100
[2025-08-27 15:42:28,394][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080392] [Batch 00312/03080] [00:03:49/00:33:58, 0.737s/it]: train_loss_raw=0.3049, running_loss=0.3459, LR=0.000100
[2025-08-27 15:42:33,940][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080400] [Batch 00320/03080] [00:03:55/00:33:50, 0.736s/it]: train_loss_raw=0.3282, running_loss=0.3443, LR=0.000100
[2025-08-27 15:42:39,857][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080408] [Batch 00328/03080] [00:04:01/00:33:44, 0.736s/it]: train_loss_raw=0.3323, running_loss=0.3447, LR=0.000100
[2025-08-27 15:42:45,818][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080416] [Batch 00336/03080] [00:04:07/00:33:39, 0.736s/it]: train_loss_raw=0.3626, running_loss=0.3450, LR=0.000100
[2025-08-27 15:42:51,476][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080424] [Batch 00344/03080] [00:04:12/00:33:31, 0.735s/it]: train_loss_raw=0.3416, running_loss=0.3460, LR=0.000100
[2025-08-27 15:42:56,885][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080432] [Batch 00352/03080] [00:04:18/00:33:21, 0.734s/it]: train_loss_raw=0.3573, running_loss=0.3455, LR=0.000100
[2025-08-27 15:43:02,894][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080440] [Batch 00360/03080] [00:04:24/00:33:17, 0.734s/it]: train_loss_raw=0.4470, running_loss=0.3461, LR=0.000100
[2025-08-27 15:43:09,100][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080448] [Batch 00368/03080] [00:04:30/00:33:13, 0.735s/it]: train_loss_raw=0.3403, running_loss=0.3468, LR=0.000100
[2025-08-27 15:43:14,804][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080456] [Batch 00376/03080] [00:04:36/00:33:06, 0.735s/it]: train_loss_raw=0.3840, running_loss=0.3451, LR=0.000100
[2025-08-27 15:43:20,765][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080464] [Batch 00384/03080] [00:04:42/00:33:01, 0.735s/it]: train_loss_raw=0.3448, running_loss=0.3443, LR=0.000100
[2025-08-27 15:43:26,464][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080472] [Batch 00392/03080] [00:04:47/00:32:54, 0.734s/it]: train_loss_raw=0.2539, running_loss=0.3419, LR=0.000100
[2025-08-27 15:43:31,855][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080480] [Batch 00400/03080] [00:04:53/00:32:45, 0.733s/it]: train_loss_raw=0.2800, running_loss=0.3414, LR=0.000100
[2025-08-27 15:43:37,638][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080488] [Batch 00408/03080] [00:04:59/00:32:38, 0.733s/it]: train_loss_raw=0.2684, running_loss=0.3406, LR=0.000100
[2025-08-27 15:43:43,100][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080496] [Batch 00416/03080] [00:05:04/00:32:30, 0.732s/it]: train_loss_raw=0.3455, running_loss=0.3391, LR=0.000100
[2025-08-27 15:43:48,821][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080504] [Batch 00424/03080] [00:05:10/00:32:23, 0.732s/it]: train_loss_raw=0.2574, running_loss=0.3390, LR=0.000100
[2025-08-27 15:43:54,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080512] [Batch 00432/03080] [00:05:15/00:32:16, 0.731s/it]: train_loss_raw=0.3270, running_loss=0.3386, LR=0.000100
[2025-08-27 15:44:00,546][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080520] [Batch 00440/03080] [00:05:21/00:32:11, 0.732s/it]: train_loss_raw=0.3564, running_loss=0.3390, LR=0.000100
[2025-08-27 15:44:06,554][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080528] [Batch 00448/03080] [00:05:27/00:32:06, 0.732s/it]: train_loss_raw=0.4054, running_loss=0.3402, LR=0.000100
[2025-08-27 15:44:12,513][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080536] [Batch 00456/03080] [00:05:33/00:32:01, 0.732s/it]: train_loss_raw=0.3576, running_loss=0.3400, LR=0.000100
[2025-08-27 15:44:18,429][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080544] [Batch 00464/03080] [00:05:39/00:31:56, 0.732s/it]: train_loss_raw=0.3266, running_loss=0.3394, LR=0.000100
[2025-08-27 15:44:24,155][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080552] [Batch 00472/03080] [00:05:45/00:31:49, 0.732s/it]: train_loss_raw=0.3441, running_loss=0.3390, LR=0.000100
[2025-08-27 15:44:29,910][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080560] [Batch 00480/03080] [00:05:51/00:31:43, 0.732s/it]: train_loss_raw=0.3078, running_loss=0.3384, LR=0.000100
[2025-08-27 15:44:35,361][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080568] [Batch 00488/03080] [00:05:56/00:31:35, 0.731s/it]: train_loss_raw=0.3453, running_loss=0.3393, LR=0.000100
[2025-08-27 15:44:40,916][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080576] [Batch 00496/03080] [00:06:02/00:31:27, 0.731s/it]: train_loss_raw=0.3983, running_loss=0.3394, LR=0.000100
[2025-08-27 15:44:46,829][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080584] [Batch 00504/03080] [00:06:08/00:31:22, 0.731s/it]: train_loss_raw=0.3140, running_loss=0.3383, LR=0.000100
[2025-08-27 15:44:52,564][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080592] [Batch 00512/03080] [00:06:13/00:31:15, 0.730s/it]: train_loss_raw=0.3755, running_loss=0.3386, LR=0.000100
[2025-08-27 15:44:58,614][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080600] [Batch 00520/03080] [00:06:20/00:31:11, 0.731s/it]: train_loss_raw=0.2965, running_loss=0.3387, LR=0.000100
[2025-08-27 15:45:04,602][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080608] [Batch 00528/03080] [00:06:26/00:31:05, 0.731s/it]: train_loss_raw=0.3682, running_loss=0.3382, LR=0.000100
[2025-08-27 15:45:10,608][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080616] [Batch 00536/03080] [00:06:32/00:31:00, 0.731s/it]: train_loss_raw=0.3275, running_loss=0.3400, LR=0.000100
[2025-08-27 15:45:16,626][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080624] [Batch 00544/03080] [00:06:38/00:30:55, 0.732s/it]: train_loss_raw=0.3225, running_loss=0.3382, LR=0.000100
[2025-08-27 15:45:22,493][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080632] [Batch 00552/03080] [00:06:43/00:30:49, 0.732s/it]: train_loss_raw=0.3430, running_loss=0.3397, LR=0.000100
[2025-08-27 15:45:28,352][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080640] [Batch 00560/03080] [00:06:49/00:30:44, 0.732s/it]: train_loss_raw=0.3127, running_loss=0.3379, LR=0.000100
[2025-08-27 15:45:34,234][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080648] [Batch 00568/03080] [00:06:55/00:30:38, 0.732s/it]: train_loss_raw=0.3349, running_loss=0.3397, LR=0.000100
[2025-08-27 15:45:39,765][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080656] [Batch 00576/03080] [00:07:01/00:30:31, 0.731s/it]: train_loss_raw=0.3669, running_loss=0.3391, LR=0.000100
[2025-08-27 15:45:45,513][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080664] [Batch 00584/03080] [00:07:06/00:30:24, 0.731s/it]: train_loss_raw=0.3418, running_loss=0.3376, LR=0.000100
[2025-08-27 15:45:51,491][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080672] [Batch 00592/03080] [00:07:12/00:30:19, 0.731s/it]: train_loss_raw=0.3268, running_loss=0.3392, LR=0.000100
[2025-08-27 15:45:57,671][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080680] [Batch 00600/03080] [00:07:19/00:30:14, 0.732s/it]: train_loss_raw=0.3432, running_loss=0.3395, LR=0.000100
[2025-08-27 15:46:03,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080688] [Batch 00608/03080] [00:07:25/00:30:09, 0.732s/it]: train_loss_raw=0.3070, running_loss=0.3387, LR=0.000100
[2025-08-27 15:46:09,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080696] [Batch 00616/03080] [00:07:31/00:30:04, 0.732s/it]: train_loss_raw=0.3058, running_loss=0.3411, LR=0.000100
[2025-08-27 15:46:15,369][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080704] [Batch 00624/03080] [00:07:36/00:29:57, 0.732s/it]: train_loss_raw=0.3215, running_loss=0.3422, LR=0.000100
[2025-08-27 15:46:21,030][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080712] [Batch 00632/03080] [00:07:42/00:29:51, 0.732s/it]: train_loss_raw=0.3766, running_loss=0.3417, LR=0.000100
[2025-08-27 15:46:26,657][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080720] [Batch 00640/03080] [00:07:48/00:29:44, 0.731s/it]: train_loss_raw=0.3141, running_loss=0.3416, LR=0.000100
[2025-08-27 15:46:32,748][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080728] [Batch 00648/03080] [00:07:54/00:29:39, 0.732s/it]: train_loss_raw=0.3061, running_loss=0.3406, LR=0.000100
[2025-08-27 15:46:38,844][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080736] [Batch 00656/03080] [00:08:00/00:29:34, 0.732s/it]: train_loss_raw=0.4012, running_loss=0.3416, LR=0.000100
[2025-08-27 15:46:44,548][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080744] [Batch 00664/03080] [00:08:05/00:29:28, 0.732s/it]: train_loss_raw=0.3434, running_loss=0.3412, LR=0.000100
[2025-08-27 15:46:50,141][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080752] [Batch 00672/03080] [00:08:11/00:29:21, 0.732s/it]: train_loss_raw=0.3137, running_loss=0.3399, LR=0.000100
[2025-08-27 15:46:55,929][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080760] [Batch 00680/03080] [00:08:17/00:29:15, 0.731s/it]: train_loss_raw=0.3110, running_loss=0.3398, LR=0.000100
[2025-08-27 15:47:01,823][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080768] [Batch 00688/03080] [00:08:23/00:29:09, 0.731s/it]: train_loss_raw=0.3340, running_loss=0.3392, LR=0.000100
[2025-08-27 15:47:07,847][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080776] [Batch 00696/03080] [00:08:29/00:29:04, 0.732s/it]: train_loss_raw=0.3678, running_loss=0.3408, LR=0.000100
[2025-08-27 15:47:13,446][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080784] [Batch 00704/03080] [00:08:34/00:28:57, 0.731s/it]: train_loss_raw=0.3340, running_loss=0.3409, LR=0.000100
[2025-08-27 15:47:19,312][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080792] [Batch 00712/03080] [00:08:40/00:28:51, 0.731s/it]: train_loss_raw=0.3342, running_loss=0.3406, LR=0.000100
[2025-08-27 15:47:25,080][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080800] [Batch 00720/03080] [00:08:46/00:28:45, 0.731s/it]: train_loss_raw=0.3815, running_loss=0.3395, LR=0.000100
[2025-08-27 15:47:31,099][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080808] [Batch 00728/03080] [00:08:52/00:28:40, 0.732s/it]: train_loss_raw=0.3443, running_loss=0.3413, LR=0.000100
[2025-08-27 15:47:36,938][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080816] [Batch 00736/03080] [00:08:58/00:28:34, 0.731s/it]: train_loss_raw=0.3739, running_loss=0.3416, LR=0.000100
[2025-08-27 15:47:43,254][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080824] [Batch 00744/03080] [00:09:04/00:28:30, 0.732s/it]: train_loss_raw=0.2976, running_loss=0.3422, LR=0.000100
[2025-08-27 15:47:49,287][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080832] [Batch 00752/03080] [00:09:10/00:28:24, 0.732s/it]: train_loss_raw=0.3501, running_loss=0.3419, LR=0.000100
[2025-08-27 15:47:55,354][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080840] [Batch 00760/03080] [00:09:16/00:28:19, 0.733s/it]: train_loss_raw=0.3170, running_loss=0.3407, LR=0.000100
[2025-08-27 15:48:01,353][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080848] [Batch 00768/03080] [00:09:22/00:28:14, 0.733s/it]: train_loss_raw=0.3048, running_loss=0.3412, LR=0.000100
[2025-08-27 15:48:07,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080856] [Batch 00776/03080] [00:09:28/00:28:08, 0.733s/it]: train_loss_raw=0.3833, running_loss=0.3412, LR=0.000100
[2025-08-27 15:48:12,900][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080864] [Batch 00784/03080] [00:09:34/00:28:01, 0.733s/it]: train_loss_raw=0.4024, running_loss=0.3428, LR=0.000100
[2025-08-27 15:48:18,834][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080872] [Batch 00792/03080] [00:09:40/00:27:56, 0.733s/it]: train_loss_raw=0.3596, running_loss=0.3419, LR=0.000100
[2025-08-27 15:48:24,784][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080880] [Batch 00800/03080] [00:09:46/00:27:50, 0.733s/it]: train_loss_raw=0.3494, running_loss=0.3423, LR=0.000100
[2025-08-27 15:48:30,689][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080888] [Batch 00808/03080] [00:09:52/00:27:44, 0.733s/it]: train_loss_raw=0.2737, running_loss=0.3403, LR=0.000100
[2025-08-27 15:48:36,708][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080896] [Batch 00816/03080] [00:09:58/00:27:39, 0.733s/it]: train_loss_raw=0.3357, running_loss=0.3403, LR=0.000100
[2025-08-27 15:48:42,688][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080904] [Batch 00824/03080] [00:10:04/00:27:34, 0.733s/it]: train_loss_raw=0.3587, running_loss=0.3405, LR=0.000100
[2025-08-27 15:48:48,334][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080912] [Batch 00832/03080] [00:10:09/00:27:27, 0.733s/it]: train_loss_raw=0.2669, running_loss=0.3409, LR=0.000100
[2025-08-27 15:48:54,400][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080920] [Batch 00840/03080] [00:10:15/00:27:22, 0.733s/it]: train_loss_raw=0.3208, running_loss=0.3412, LR=0.000100
[2025-08-27 15:49:00,369][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080928] [Batch 00848/03080] [00:10:21/00:27:16, 0.733s/it]: train_loss_raw=0.3462, running_loss=0.3414, LR=0.000100
[2025-08-27 15:49:06,307][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080936] [Batch 00856/03080] [00:10:27/00:27:10, 0.733s/it]: train_loss_raw=0.3085, running_loss=0.3418, LR=0.000100
[2025-08-27 15:49:11,916][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080944] [Batch 00864/03080] [00:10:33/00:27:04, 0.733s/it]: train_loss_raw=0.3366, running_loss=0.3440, LR=0.000100
[2025-08-27 15:49:17,721][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080952] [Batch 00872/03080] [00:10:39/00:26:58, 0.733s/it]: train_loss_raw=0.4469, running_loss=0.3441, LR=0.000100
[2025-08-27 15:49:23,676][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080960] [Batch 00880/03080] [00:10:45/00:26:52, 0.733s/it]: train_loss_raw=0.3457, running_loss=0.3423, LR=0.000100
[2025-08-27 15:49:29,169][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080968] [Batch 00888/03080] [00:10:50/00:26:45, 0.733s/it]: train_loss_raw=0.3690, running_loss=0.3435, LR=0.000100
[2025-08-27 15:49:34,802][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080976] [Batch 00896/03080] [00:10:56/00:26:39, 0.732s/it]: train_loss_raw=0.3655, running_loss=0.3423, LR=0.000100
[2025-08-27 15:49:40,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080984] [Batch 00904/03080] [00:11:02/00:26:34, 0.733s/it]: train_loss_raw=0.3205, running_loss=0.3430, LR=0.000100
[2025-08-27 15:49:46,300][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080992] [Batch 00912/03080] [00:11:07/00:26:27, 0.732s/it]: train_loss_raw=0.3896, running_loss=0.3450, LR=0.000100
[2025-08-27 15:49:51,750][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081000] [Batch 00920/03080] [00:11:13/00:26:20, 0.732s/it]: train_loss_raw=0.3546, running_loss=0.3453, LR=0.000100
[2025-08-27 15:49:57,249][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081008] [Batch 00928/03080] [00:11:18/00:26:13, 0.731s/it]: train_loss_raw=0.2630, running_loss=0.3431, LR=0.000100
[2025-08-27 15:50:03,088][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081016] [Batch 00936/03080] [00:11:24/00:26:07, 0.731s/it]: train_loss_raw=0.3476, running_loss=0.3454, LR=0.000100
[2025-08-27 15:50:09,048][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081024] [Batch 00944/03080] [00:11:30/00:26:02, 0.731s/it]: train_loss_raw=0.4186, running_loss=0.3439, LR=0.000100
[2025-08-27 15:50:14,555][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081032] [Batch 00952/03080] [00:11:35/00:25:55, 0.731s/it]: train_loss_raw=0.3567, running_loss=0.3437, LR=0.000100
[2025-08-27 15:50:20,548][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081040] [Batch 00960/03080] [00:11:41/00:25:50, 0.731s/it]: train_loss_raw=0.2993, running_loss=0.3451, LR=0.000100
[2025-08-27 15:50:26,266][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081048] [Batch 00968/03080] [00:11:47/00:25:44, 0.731s/it]: train_loss_raw=0.3635, running_loss=0.3460, LR=0.000100
[2025-08-27 15:50:31,944][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081056] [Batch 00976/03080] [00:11:53/00:25:37, 0.731s/it]: train_loss_raw=0.3057, running_loss=0.3455, LR=0.000100
[2025-08-27 15:50:37,606][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081064] [Batch 00984/03080] [00:11:59/00:25:31, 0.731s/it]: train_loss_raw=0.3018, running_loss=0.3451, LR=0.000100
[2025-08-27 15:50:43,392][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081072] [Batch 00992/03080] [00:12:04/00:25:25, 0.731s/it]: train_loss_raw=0.2750, running_loss=0.3450, LR=0.000100
[2025-08-27 15:50:49,477][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081080] [Batch 01000/03080] [00:12:10/00:25:20, 0.731s/it]: train_loss_raw=0.3446, running_loss=0.3455, LR=0.000100
[2025-08-27 15:50:55,178][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081088] [Batch 01008/03080] [00:12:16/00:25:14, 0.731s/it]: train_loss_raw=0.3301, running_loss=0.3452, LR=0.000100
[2025-08-27 15:51:01,238][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081096] [Batch 01016/03080] [00:12:22/00:25:08, 0.731s/it]: train_loss_raw=0.3278, running_loss=0.3440, LR=0.000100
[2025-08-27 15:51:06,879][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081104] [Batch 01024/03080] [00:12:28/00:25:02, 0.731s/it]: train_loss_raw=0.3674, running_loss=0.3429, LR=0.000100
[2025-08-27 15:51:12,556][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081112] [Batch 01032/03080] [00:12:33/00:24:56, 0.731s/it]: train_loss_raw=0.4549, running_loss=0.3430, LR=0.000100
[2025-08-27 15:51:18,011][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081120] [Batch 01040/03080] [00:12:39/00:24:49, 0.730s/it]: train_loss_raw=0.2734, running_loss=0.3416, LR=0.000100
[2025-08-27 15:51:23,432][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081128] [Batch 01048/03080] [00:12:44/00:24:43, 0.730s/it]: train_loss_raw=0.3733, running_loss=0.3421, LR=0.000100
[2025-08-27 15:51:29,132][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081136] [Batch 01056/03080] [00:12:50/00:24:36, 0.730s/it]: train_loss_raw=0.3178, running_loss=0.3403, LR=0.000100
[2025-08-27 15:51:35,046][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081144] [Batch 01064/03080] [00:12:56/00:24:31, 0.730s/it]: train_loss_raw=0.3370, running_loss=0.3378, LR=0.000100
[2025-08-27 15:51:41,097][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081152] [Batch 01072/03080] [00:13:02/00:24:25, 0.730s/it]: train_loss_raw=0.3370, running_loss=0.3389, LR=0.000100
[2025-08-27 15:51:47,059][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081160] [Batch 01080/03080] [00:13:08/00:24:20, 0.730s/it]: train_loss_raw=0.3332, running_loss=0.3404, LR=0.000100
[2025-08-27 15:51:52,833][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081168] [Batch 01088/03080] [00:13:14/00:24:14, 0.730s/it]: train_loss_raw=0.3112, running_loss=0.3391, LR=0.000100
[2025-08-27 15:51:58,780][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081176] [Batch 01096/03080] [00:13:20/00:24:08, 0.730s/it]: train_loss_raw=0.2934, running_loss=0.3404, LR=0.000100
[2025-08-27 15:52:04,647][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081184] [Batch 01104/03080] [00:13:26/00:24:02, 0.730s/it]: train_loss_raw=0.3775, running_loss=0.3416, LR=0.000100
[2025-08-27 15:52:10,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081192] [Batch 01112/03080] [00:13:31/00:23:56, 0.730s/it]: train_loss_raw=0.4021, running_loss=0.3418, LR=0.000100
[2025-08-27 15:52:16,379][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081200] [Batch 01120/03080] [00:13:37/00:23:51, 0.730s/it]: train_loss_raw=0.3724, running_loss=0.3428, LR=0.000100
[2025-08-27 15:52:22,367][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081208] [Batch 01128/03080] [00:13:43/00:23:45, 0.730s/it]: train_loss_raw=0.4034, running_loss=0.3460, LR=0.000100
[2025-08-27 15:52:28,361][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081216] [Batch 01136/03080] [00:13:49/00:23:39, 0.730s/it]: train_loss_raw=0.2528, running_loss=0.3438, LR=0.000100
[2025-08-27 15:52:34,760][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081224] [Batch 01144/03080] [00:13:56/00:23:35, 0.731s/it]: train_loss_raw=0.3213, running_loss=0.3436, LR=0.000100
[2025-08-27 15:52:40,797][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081232] [Batch 01152/03080] [00:14:02/00:23:29, 0.731s/it]: train_loss_raw=0.3071, running_loss=0.3441, LR=0.000100
[2025-08-27 15:52:46,161][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081240] [Batch 01160/03080] [00:14:07/00:23:22, 0.731s/it]: train_loss_raw=0.2530, running_loss=0.3424, LR=0.000100
[2025-08-27 15:52:51,876][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081248] [Batch 01168/03080] [00:14:13/00:23:16, 0.731s/it]: train_loss_raw=0.3796, running_loss=0.3431, LR=0.000100
[2025-08-27 15:52:57,462][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081256] [Batch 01176/03080] [00:14:18/00:23:10, 0.730s/it]: train_loss_raw=0.3576, running_loss=0.3433, LR=0.000100
[2025-08-27 15:53:03,189][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081264] [Batch 01184/03080] [00:14:24/00:23:04, 0.730s/it]: train_loss_raw=0.3980, running_loss=0.3437, LR=0.000100
[2025-08-27 15:53:08,714][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081272] [Batch 01192/03080] [00:14:30/00:22:58, 0.730s/it]: train_loss_raw=0.3526, running_loss=0.3415, LR=0.000100
[2025-08-27 15:53:14,513][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081280] [Batch 01200/03080] [00:14:35/00:22:52, 0.730s/it]: train_loss_raw=0.3219, running_loss=0.3415, LR=0.000100
[2025-08-27 15:53:20,442][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081288] [Batch 01208/03080] [00:14:41/00:22:46, 0.730s/it]: train_loss_raw=0.3387, running_loss=0.3403, LR=0.000100
[2025-08-27 15:53:26,298][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081296] [Batch 01216/03080] [00:14:47/00:22:40, 0.730s/it]: train_loss_raw=0.2718, running_loss=0.3387, LR=0.000100
[2025-08-27 15:53:31,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081304] [Batch 01224/03080] [00:14:53/00:22:34, 0.730s/it]: train_loss_raw=0.3382, running_loss=0.3397, LR=0.000100
[2025-08-27 15:53:37,278][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081312] [Batch 01232/03080] [00:14:58/00:22:28, 0.729s/it]: train_loss_raw=0.3209, running_loss=0.3407, LR=0.000100
[2025-08-27 15:53:43,210][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081320] [Batch 01240/03080] [00:15:04/00:22:22, 0.730s/it]: train_loss_raw=0.3315, running_loss=0.3423, LR=0.000100
[2025-08-27 15:53:49,172][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081328] [Batch 01248/03080] [00:15:10/00:22:16, 0.730s/it]: train_loss_raw=0.3990, running_loss=0.3431, LR=0.000100
[2025-08-27 15:53:54,875][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081336] [Batch 01256/03080] [00:15:16/00:22:10, 0.730s/it]: train_loss_raw=0.3988, running_loss=0.3435, LR=0.000100
[2025-08-27 15:54:00,998][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081344] [Batch 01264/03080] [00:15:22/00:22:05, 0.730s/it]: train_loss_raw=0.3161, running_loss=0.3433, LR=0.000100
[2025-08-27 15:54:06,706][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081352] [Batch 01272/03080] [00:15:28/00:21:59, 0.730s/it]: train_loss_raw=0.3380, running_loss=0.3427, LR=0.000100
[2025-08-27 15:54:12,306][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081360] [Batch 01280/03080] [00:15:33/00:21:53, 0.729s/it]: train_loss_raw=0.3181, running_loss=0.3438, LR=0.000100
[2025-08-27 15:54:18,402][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081368] [Batch 01288/03080] [00:15:39/00:21:47, 0.730s/it]: train_loss_raw=0.3553, running_loss=0.3423, LR=0.000100
[2025-08-27 15:54:24,455][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081376] [Batch 01296/03080] [00:15:45/00:21:42, 0.730s/it]: train_loss_raw=0.3567, running_loss=0.3429, LR=0.000100
[2025-08-27 15:54:30,334][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081384] [Batch 01304/03080] [00:15:51/00:21:36, 0.730s/it]: train_loss_raw=0.3303, running_loss=0.3433, LR=0.000100
[2025-08-27 15:54:36,245][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081392] [Batch 01312/03080] [00:15:57/00:21:30, 0.730s/it]: train_loss_raw=0.3790, running_loss=0.3439, LR=0.000100
[2025-08-27 15:54:41,987][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081400] [Batch 01320/03080] [00:16:03/00:21:24, 0.730s/it]: train_loss_raw=0.3589, running_loss=0.3459, LR=0.000100
[2025-08-27 15:54:48,145][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081408] [Batch 01328/03080] [00:16:09/00:21:19, 0.730s/it]: train_loss_raw=0.3872, running_loss=0.3475, LR=0.000100
[2025-08-27 15:54:54,150][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081416] [Batch 01336/03080] [00:16:15/00:21:13, 0.730s/it]: train_loss_raw=0.4422, running_loss=0.3485, LR=0.000100
[2025-08-27 15:55:00,116][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081424] [Batch 01344/03080] [00:16:21/00:21:07, 0.730s/it]: train_loss_raw=0.2844, running_loss=0.3475, LR=0.000100
[2025-08-27 15:55:05,949][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081432] [Batch 01352/03080] [00:16:27/00:21:01, 0.730s/it]: train_loss_raw=0.3456, running_loss=0.3477, LR=0.000100
[2025-08-27 15:55:11,752][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081440] [Batch 01360/03080] [00:16:33/00:20:56, 0.730s/it]: train_loss_raw=0.3322, running_loss=0.3499, LR=0.000100
[2025-08-27 15:55:17,650][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081448] [Batch 01368/03080] [00:16:39/00:20:50, 0.730s/it]: train_loss_raw=0.3766, running_loss=0.3524, LR=0.000100
[2025-08-27 15:55:23,587][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081456] [Batch 01376/03080] [00:16:45/00:20:44, 0.730s/it]: train_loss_raw=0.2515, running_loss=0.3523, LR=0.000100
[2025-08-27 15:55:29,128][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081464] [Batch 01384/03080] [00:16:50/00:20:38, 0.730s/it]: train_loss_raw=0.3804, running_loss=0.3500, LR=0.000100
[2025-08-27 15:55:35,315][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081472] [Batch 01392/03080] [00:16:56/00:20:32, 0.730s/it]: train_loss_raw=0.2658, running_loss=0.3487, LR=0.000100
[2025-08-27 15:55:41,684][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081480] [Batch 01400/03080] [00:17:03/00:20:27, 0.731s/it]: train_loss_raw=0.3643, running_loss=0.3466, LR=0.000100
[2025-08-27 15:55:47,687][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081488] [Batch 01408/03080] [00:17:09/00:20:22, 0.731s/it]: train_loss_raw=0.3384, running_loss=0.3481, LR=0.000100
[2025-08-27 15:55:53,661][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081496] [Batch 01416/03080] [00:17:15/00:20:16, 0.731s/it]: train_loss_raw=0.3677, running_loss=0.3478, LR=0.000100
[2025-08-27 15:55:59,502][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081504] [Batch 01424/03080] [00:17:20/00:20:10, 0.731s/it]: train_loss_raw=0.3520, running_loss=0.3468, LR=0.000100
[2025-08-27 15:56:05,239][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081512] [Batch 01432/03080] [00:17:26/00:20:04, 0.731s/it]: train_loss_raw=0.3808, running_loss=0.3453, LR=0.000100
[2025-08-27 15:56:10,600][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081520] [Batch 01440/03080] [00:17:32/00:19:58, 0.731s/it]: train_loss_raw=0.3281, running_loss=0.3435, LR=0.000100
[2025-08-27 15:56:16,069][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081528] [Batch 01448/03080] [00:17:37/00:19:51, 0.730s/it]: train_loss_raw=0.3599, running_loss=0.3460, LR=0.000100
[2025-08-27 15:56:21,723][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081536] [Batch 01456/03080] [00:17:43/00:19:45, 0.730s/it]: train_loss_raw=0.3719, running_loss=0.3458, LR=0.000100
[2025-08-27 15:56:27,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081544] [Batch 01464/03080] [00:17:49/00:19:40, 0.730s/it]: train_loss_raw=0.3211, running_loss=0.3444, LR=0.000100
[2025-08-27 15:56:33,527][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081552] [Batch 01472/03080] [00:17:54/00:19:34, 0.730s/it]: train_loss_raw=0.3467, running_loss=0.3410, LR=0.000100
[2025-08-27 15:56:39,221][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081560] [Batch 01480/03080] [00:18:00/00:19:28, 0.730s/it]: train_loss_raw=0.3658, running_loss=0.3399, LR=0.000100
[2025-08-27 15:56:44,612][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081568] [Batch 01488/03080] [00:18:06/00:19:21, 0.730s/it]: train_loss_raw=0.3614, running_loss=0.3383, LR=0.000100
[2025-08-27 15:56:50,220][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081576] [Batch 01496/03080] [00:18:11/00:19:15, 0.730s/it]: train_loss_raw=0.3268, running_loss=0.3397, LR=0.000100
[2025-08-27 15:56:55,704][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081584] [Batch 01504/03080] [00:18:17/00:19:09, 0.729s/it]: train_loss_raw=0.3412, running_loss=0.3416, LR=0.000100
[2025-08-27 15:57:01,500][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081592] [Batch 01512/03080] [00:18:22/00:19:03, 0.729s/it]: train_loss_raw=0.3288, running_loss=0.3415, LR=0.000100
[2025-08-27 15:57:07,363][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081600] [Batch 01520/03080] [00:18:28/00:18:57, 0.729s/it]: train_loss_raw=0.3777, running_loss=0.3427, LR=0.000100
[2025-08-27 15:57:13,158][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081608] [Batch 01528/03080] [00:18:34/00:18:52, 0.729s/it]: train_loss_raw=0.3153, running_loss=0.3423, LR=0.000100
[2025-08-27 15:57:18,609][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081616] [Batch 01536/03080] [00:18:40/00:18:45, 0.729s/it]: train_loss_raw=0.3653, running_loss=0.3440, LR=0.000100
[2025-08-27 15:57:24,327][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081624] [Batch 01544/03080] [00:18:45/00:18:39, 0.729s/it]: train_loss_raw=0.3229, running_loss=0.3447, LR=0.000100
[2025-08-27 15:57:30,236][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081632] [Batch 01552/03080] [00:18:51/00:18:34, 0.729s/it]: train_loss_raw=0.3798, running_loss=0.3440, LR=0.000100
[2025-08-27 15:57:36,220][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081640] [Batch 01560/03080] [00:18:57/00:18:28, 0.729s/it]: train_loss_raw=0.3200, running_loss=0.3443, LR=0.000100
[2025-08-27 15:57:42,178][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081648] [Batch 01568/03080] [00:19:03/00:18:22, 0.729s/it]: train_loss_raw=0.3370, running_loss=0.3437, LR=0.000100
[2025-08-27 15:57:47,649][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081656] [Batch 01576/03080] [00:19:09/00:18:16, 0.729s/it]: train_loss_raw=0.3114, running_loss=0.3448, LR=0.000100
[2025-08-27 15:57:53,080][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081664] [Batch 01584/03080] [00:19:14/00:18:10, 0.729s/it]: train_loss_raw=0.3480, running_loss=0.3469, LR=0.000100
[2025-08-27 15:57:58,604][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081672] [Batch 01592/03080] [00:19:20/00:18:04, 0.729s/it]: train_loss_raw=0.3280, running_loss=0.3463, LR=0.000100
[2025-08-27 15:58:04,497][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081680] [Batch 01600/03080] [00:19:25/00:17:58, 0.729s/it]: train_loss_raw=0.2798, running_loss=0.3449, LR=0.000100
[2025-08-27 15:58:10,584][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081688] [Batch 01608/03080] [00:19:32/00:17:52, 0.729s/it]: train_loss_raw=0.3724, running_loss=0.3444, LR=0.000100
[2025-08-27 15:58:16,464][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081696] [Batch 01616/03080] [00:19:37/00:17:47, 0.729s/it]: train_loss_raw=0.3661, running_loss=0.3455, LR=0.000100
[2025-08-27 15:58:22,277][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081704] [Batch 01624/03080] [00:19:43/00:17:41, 0.729s/it]: train_loss_raw=0.3167, running_loss=0.3440, LR=0.000100
[2025-08-27 15:58:27,910][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081712] [Batch 01632/03080] [00:19:49/00:17:35, 0.729s/it]: train_loss_raw=0.3284, running_loss=0.3422, LR=0.000100
[2025-08-27 15:58:33,851][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081720] [Batch 01640/03080] [00:19:55/00:17:29, 0.729s/it]: train_loss_raw=0.3961, running_loss=0.3436, LR=0.000100
[2025-08-27 15:58:39,802][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081728] [Batch 01648/03080] [00:20:01/00:17:23, 0.729s/it]: train_loss_raw=0.3281, running_loss=0.3433, LR=0.000100
[2025-08-27 15:58:45,722][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081736] [Batch 01656/03080] [00:20:07/00:17:18, 0.729s/it]: train_loss_raw=0.3438, running_loss=0.3420, LR=0.000100
[2025-08-27 15:58:51,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081744] [Batch 01664/03080] [00:20:13/00:17:12, 0.729s/it]: train_loss_raw=0.3097, running_loss=0.3436, LR=0.000100
[2025-08-27 15:58:57,584][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081752] [Batch 01672/03080] [00:20:19/00:17:06, 0.729s/it]: train_loss_raw=0.3273, running_loss=0.3426, LR=0.000100
[2025-08-27 15:59:03,489][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081760] [Batch 01680/03080] [00:20:24/00:17:00, 0.729s/it]: train_loss_raw=0.3381, running_loss=0.3423, LR=0.000100
[2025-08-27 15:59:09,381][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081768] [Batch 01688/03080] [00:20:30/00:16:54, 0.729s/it]: train_loss_raw=0.3399, running_loss=0.3437, LR=0.000100
[2025-08-27 15:59:15,276][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081776] [Batch 01696/03080] [00:20:36/00:16:49, 0.729s/it]: train_loss_raw=0.2669, running_loss=0.3441, LR=0.000100
[2025-08-27 15:59:21,256][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081784] [Batch 01704/03080] [00:20:42/00:16:43, 0.729s/it]: train_loss_raw=0.3172, running_loss=0.3435, LR=0.000100
[2025-08-27 15:59:27,271][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081792] [Batch 01712/03080] [00:20:48/00:16:37, 0.729s/it]: train_loss_raw=0.3907, running_loss=0.3448, LR=0.000100
[2025-08-27 15:59:33,109][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081800] [Batch 01720/03080] [00:20:54/00:16:31, 0.729s/it]: train_loss_raw=0.3400, running_loss=0.3459, LR=0.000100
[2025-08-27 15:59:38,519][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081808] [Batch 01728/03080] [00:20:59/00:16:25, 0.729s/it]: train_loss_raw=0.3045, running_loss=0.3442, LR=0.000100
[2025-08-27 15:59:44,518][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081816] [Batch 01736/03080] [00:21:05/00:16:20, 0.729s/it]: train_loss_raw=0.2691, running_loss=0.3441, LR=0.000100
[2025-08-27 15:59:50,487][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081824] [Batch 01744/03080] [00:21:11/00:16:14, 0.729s/it]: train_loss_raw=0.2434, running_loss=0.3448, LR=0.000100
[2025-08-27 15:59:56,042][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081832] [Batch 01752/03080] [00:21:17/00:16:08, 0.729s/it]: train_loss_raw=0.3475, running_loss=0.3462, LR=0.000100
[2025-08-27 16:00:01,523][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081840] [Batch 01760/03080] [00:21:22/00:16:02, 0.729s/it]: train_loss_raw=0.2758, running_loss=0.3462, LR=0.000100
[2025-08-27 16:00:07,230][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081848] [Batch 01768/03080] [00:21:28/00:15:56, 0.729s/it]: train_loss_raw=0.3689, running_loss=0.3443, LR=0.000100
[2025-08-27 16:00:12,798][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081856] [Batch 01776/03080] [00:21:34/00:15:50, 0.729s/it]: train_loss_raw=0.3835, running_loss=0.3447, LR=0.000100
[2025-08-27 16:00:18,723][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081864] [Batch 01784/03080] [00:21:40/00:15:44, 0.729s/it]: train_loss_raw=0.4018, running_loss=0.3455, LR=0.000100
[2025-08-27 16:00:24,186][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081872] [Batch 01792/03080] [00:21:45/00:15:38, 0.729s/it]: train_loss_raw=0.3152, running_loss=0.3447, LR=0.000100
[2025-08-27 16:00:29,845][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081880] [Batch 01800/03080] [00:21:51/00:15:32, 0.728s/it]: train_loss_raw=0.3165, running_loss=0.3449, LR=0.000100
[2025-08-27 16:00:35,749][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081888] [Batch 01808/03080] [00:21:57/00:15:26, 0.729s/it]: train_loss_raw=0.2664, running_loss=0.3439, LR=0.000100
[2025-08-27 16:00:41,576][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081896] [Batch 01816/03080] [00:22:03/00:15:20, 0.729s/it]: train_loss_raw=0.3383, running_loss=0.3446, LR=0.000100
[2025-08-27 16:00:47,311][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081904] [Batch 01824/03080] [00:22:08/00:15:14, 0.728s/it]: train_loss_raw=0.3504, running_loss=0.3438, LR=0.000100
[2025-08-27 16:00:52,759][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081912] [Batch 01832/03080] [00:22:14/00:15:08, 0.728s/it]: train_loss_raw=0.3098, running_loss=0.3442, LR=0.000100
[2025-08-27 16:00:58,227][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081920] [Batch 01840/03080] [00:22:19/00:15:02, 0.728s/it]: train_loss_raw=0.3912, running_loss=0.3456, LR=0.000100
[2025-08-27 16:01:03,911][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081928] [Batch 01848/03080] [00:22:25/00:14:56, 0.728s/it]: train_loss_raw=0.3504, running_loss=0.3450, LR=0.000100
[2025-08-27 16:01:09,671][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081936] [Batch 01856/03080] [00:22:31/00:14:51, 0.728s/it]: train_loss_raw=0.4231, running_loss=0.3464, LR=0.000100
[2025-08-27 16:01:15,480][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081944] [Batch 01864/03080] [00:22:36/00:14:45, 0.728s/it]: train_loss_raw=0.4493, running_loss=0.3478, LR=0.000100
[2025-08-27 16:01:21,291][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081952] [Batch 01872/03080] [00:22:42/00:14:39, 0.728s/it]: train_loss_raw=0.3747, running_loss=0.3472, LR=0.000100
[2025-08-27 16:01:27,002][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081960] [Batch 01880/03080] [00:22:48/00:14:33, 0.728s/it]: train_loss_raw=0.3805, running_loss=0.3485, LR=0.000100
[2025-08-27 16:01:32,719][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081968] [Batch 01888/03080] [00:22:54/00:14:27, 0.728s/it]: train_loss_raw=0.3428, running_loss=0.3500, LR=0.000100
[2025-08-27 16:01:38,670][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081976] [Batch 01896/03080] [00:23:00/00:14:21, 0.728s/it]: train_loss_raw=0.3731, running_loss=0.3496, LR=0.000100
[2025-08-27 16:01:44,771][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081984] [Batch 01904/03080] [00:23:06/00:14:16, 0.728s/it]: train_loss_raw=0.3413, running_loss=0.3495, LR=0.000100
[2025-08-27 16:01:50,737][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081992] [Batch 01912/03080] [00:23:12/00:14:10, 0.728s/it]: train_loss_raw=0.3650, running_loss=0.3484, LR=0.000100
[2025-08-27 16:01:57,031][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082000] [Batch 01920/03080] [00:23:18/00:14:04, 0.728s/it]: train_loss_raw=0.3158, running_loss=0.3452, LR=0.000100
[2025-08-27 16:02:05,814][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082008] [Batch 01928/03080] [00:23:27/00:14:00, 0.730s/it]: train_loss_raw=0.3810, running_loss=0.3444, LR=0.000100
[2025-08-27 16:02:11,496][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082016] [Batch 01936/03080] [00:23:32/00:13:54, 0.730s/it]: train_loss_raw=0.3182, running_loss=0.3440, LR=0.000100
[2025-08-27 16:02:17,221][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082024] [Batch 01944/03080] [00:23:38/00:13:49, 0.730s/it]: train_loss_raw=0.3263, running_loss=0.3440, LR=0.000100
[2025-08-27 16:02:22,709][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082032] [Batch 01952/03080] [00:23:44/00:13:42, 0.730s/it]: train_loss_raw=0.4089, running_loss=0.3446, LR=0.000100
[2025-08-27 16:02:28,851][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082040] [Batch 01960/03080] [00:23:50/00:13:37, 0.730s/it]: train_loss_raw=0.2127, running_loss=0.3428, LR=0.000100
[2025-08-27 16:02:34,986][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082048] [Batch 01968/03080] [00:23:56/00:13:31, 0.730s/it]: train_loss_raw=0.3575, running_loss=0.3418, LR=0.000100
[2025-08-27 16:02:40,591][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082056] [Batch 01976/03080] [00:24:02/00:13:25, 0.730s/it]: train_loss_raw=0.3386, running_loss=0.3425, LR=0.000100
[2025-08-27 16:02:46,437][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082064] [Batch 01984/03080] [00:24:07/00:13:19, 0.730s/it]: train_loss_raw=0.3001, running_loss=0.3435, LR=0.000100
[2025-08-27 16:02:52,385][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082072] [Batch 01992/03080] [00:24:13/00:13:14, 0.730s/it]: train_loss_raw=0.2956, running_loss=0.3424, LR=0.000100
[2025-08-27 16:02:58,352][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082080] [Batch 02000/03080] [00:24:19/00:13:08, 0.730s/it]: train_loss_raw=0.3439, running_loss=0.3423, LR=0.000100
[2025-08-27 16:03:04,137][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082088] [Batch 02008/03080] [00:24:25/00:13:02, 0.730s/it]: train_loss_raw=0.3710, running_loss=0.3429, LR=0.000100
[2025-08-27 16:03:10,143][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082096] [Batch 02016/03080] [00:24:31/00:12:56, 0.730s/it]: train_loss_raw=0.2951, running_loss=0.3456, LR=0.000100
[2025-08-27 16:03:16,155][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082104] [Batch 02024/03080] [00:24:37/00:12:50, 0.730s/it]: train_loss_raw=0.3209, running_loss=0.3463, LR=0.000100
[2025-08-27 16:03:22,120][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082112] [Batch 02032/03080] [00:24:43/00:12:45, 0.730s/it]: train_loss_raw=0.3878, running_loss=0.3468, LR=0.000100
[2025-08-27 16:03:28,152][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082120] [Batch 02040/03080] [00:24:49/00:12:39, 0.730s/it]: train_loss_raw=0.3683, running_loss=0.3462, LR=0.000100
[2025-08-27 16:03:34,106][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082128] [Batch 02048/03080] [00:24:55/00:12:33, 0.730s/it]: train_loss_raw=0.3248, running_loss=0.3452, LR=0.000100
[2025-08-27 16:03:39,968][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082136] [Batch 02056/03080] [00:25:01/00:12:27, 0.730s/it]: train_loss_raw=0.3169, running_loss=0.3448, LR=0.000100
[2025-08-27 16:03:46,017][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082144] [Batch 02064/03080] [00:25:07/00:12:22, 0.730s/it]: train_loss_raw=0.3318, running_loss=0.3443, LR=0.000100
[2025-08-27 16:03:51,996][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082152] [Batch 02072/03080] [00:25:13/00:12:16, 0.730s/it]: train_loss_raw=0.3638, running_loss=0.3435, LR=0.000100
[2025-08-27 16:03:57,847][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082160] [Batch 02080/03080] [00:25:19/00:12:10, 0.730s/it]: train_loss_raw=0.2707, running_loss=0.3427, LR=0.000100
[2025-08-27 16:04:03,735][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082168] [Batch 02088/03080] [00:25:25/00:12:04, 0.730s/it]: train_loss_raw=0.3023, running_loss=0.3441, LR=0.000100
[2025-08-27 16:04:09,378][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082176] [Batch 02096/03080] [00:25:30/00:11:58, 0.730s/it]: train_loss_raw=0.4028, running_loss=0.3443, LR=0.000100
[2025-08-27 16:04:15,184][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082184] [Batch 02104/03080] [00:25:36/00:11:52, 0.730s/it]: train_loss_raw=0.2686, running_loss=0.3419, LR=0.000100
[2025-08-27 16:04:20,907][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082192] [Batch 02112/03080] [00:25:42/00:11:46, 0.730s/it]: train_loss_raw=0.3552, running_loss=0.3447, LR=0.000100
[2025-08-27 16:04:26,613][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082200] [Batch 02120/03080] [00:25:48/00:11:41, 0.730s/it]: train_loss_raw=0.3052, running_loss=0.3436, LR=0.000100
[2025-08-27 16:04:32,580][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082208] [Batch 02128/03080] [00:25:54/00:11:35, 0.730s/it]: train_loss_raw=0.3090, running_loss=0.3416, LR=0.000100
[2025-08-27 16:04:38,482][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082216] [Batch 02136/03080] [00:25:59/00:11:29, 0.730s/it]: train_loss_raw=0.3936, running_loss=0.3425, LR=0.000100
[2025-08-27 16:04:44,226][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082224] [Batch 02144/03080] [00:26:05/00:11:23, 0.730s/it]: train_loss_raw=0.3544, running_loss=0.3433, LR=0.000100
[2025-08-27 16:04:50,271][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082232] [Batch 02152/03080] [00:26:11/00:11:17, 0.730s/it]: train_loss_raw=0.2673, running_loss=0.3429, LR=0.000100
[2025-08-27 16:04:56,323][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082240] [Batch 02160/03080] [00:26:17/00:11:12, 0.730s/it]: train_loss_raw=0.3845, running_loss=0.3446, LR=0.000100
[2025-08-27 16:05:02,241][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082248] [Batch 02168/03080] [00:26:23/00:11:06, 0.730s/it]: train_loss_raw=0.3654, running_loss=0.3478, LR=0.000100
[2025-08-27 16:05:08,234][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082256] [Batch 02176/03080] [00:26:29/00:11:00, 0.731s/it]: train_loss_raw=0.3619, running_loss=0.3470, LR=0.000100
[2025-08-27 16:05:14,067][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082264] [Batch 02184/03080] [00:26:35/00:10:54, 0.731s/it]: train_loss_raw=0.3861, running_loss=0.3462, LR=0.000100
[2025-08-27 16:05:19,757][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082272] [Batch 02192/03080] [00:26:41/00:10:48, 0.730s/it]: train_loss_raw=0.3522, running_loss=0.3459, LR=0.000100
[2025-08-27 16:05:25,752][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082280] [Batch 02200/03080] [00:26:47/00:10:42, 0.731s/it]: train_loss_raw=0.3179, running_loss=0.3456, LR=0.000100
[2025-08-27 16:05:31,549][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082288] [Batch 02208/03080] [00:26:52/00:10:37, 0.731s/it]: train_loss_raw=0.2900, running_loss=0.3450, LR=0.000100
[2025-08-27 16:05:37,506][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082296] [Batch 02216/03080] [00:26:58/00:10:31, 0.731s/it]: train_loss_raw=0.3643, running_loss=0.3456, LR=0.000100
[2025-08-27 16:05:43,362][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082304] [Batch 02224/03080] [00:27:04/00:10:25, 0.731s/it]: train_loss_raw=0.3041, running_loss=0.3458, LR=0.000100
[2025-08-27 16:05:49,110][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082312] [Batch 02232/03080] [00:27:10/00:10:19, 0.731s/it]: train_loss_raw=0.3678, running_loss=0.3454, LR=0.000100
[2025-08-27 16:05:55,064][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082320] [Batch 02240/03080] [00:27:16/00:10:13, 0.731s/it]: train_loss_raw=0.3517, running_loss=0.3462, LR=0.000100
[2025-08-27 16:06:00,792][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082328] [Batch 02248/03080] [00:27:22/00:10:07, 0.731s/it]: train_loss_raw=0.3402, running_loss=0.3467, LR=0.000100
[2025-08-27 16:06:06,518][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082336] [Batch 02256/03080] [00:27:27/00:10:01, 0.730s/it]: train_loss_raw=0.3265, running_loss=0.3465, LR=0.000100
[2025-08-27 16:06:12,248][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082344] [Batch 02264/03080] [00:27:33/00:09:56, 0.730s/it]: train_loss_raw=0.3382, running_loss=0.3471, LR=0.000100
[2025-08-27 16:06:18,001][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082352] [Batch 02272/03080] [00:27:39/00:09:50, 0.730s/it]: train_loss_raw=0.3686, running_loss=0.3474, LR=0.000100
[2025-08-27 16:06:23,761][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082360] [Batch 02280/03080] [00:27:45/00:09:44, 0.730s/it]: train_loss_raw=0.3784, running_loss=0.3457, LR=0.000100
[2025-08-27 16:06:29,701][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082368] [Batch 02288/03080] [00:27:51/00:09:38, 0.730s/it]: train_loss_raw=0.3429, running_loss=0.3448, LR=0.000100
[2025-08-27 16:06:35,716][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082376] [Batch 02296/03080] [00:27:57/00:09:32, 0.730s/it]: train_loss_raw=0.2946, running_loss=0.3445, LR=0.000100
[2025-08-27 16:06:41,663][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082384] [Batch 02304/03080] [00:28:03/00:09:26, 0.731s/it]: train_loss_raw=0.3492, running_loss=0.3455, LR=0.000100
[2025-08-27 16:06:47,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082392] [Batch 02312/03080] [00:28:09/00:09:21, 0.731s/it]: train_loss_raw=0.3232, running_loss=0.3447, LR=0.000100
[2025-08-27 16:06:53,497][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082400] [Batch 02320/03080] [00:28:14/00:09:15, 0.731s/it]: train_loss_raw=0.3078, running_loss=0.3450, LR=0.000100
[2025-08-27 16:06:59,089][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082408] [Batch 02328/03080] [00:28:20/00:09:09, 0.730s/it]: train_loss_raw=0.3530, running_loss=0.3431, LR=0.000100
[2025-08-27 16:07:05,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082416] [Batch 02336/03080] [00:28:26/00:09:03, 0.731s/it]: train_loss_raw=0.3479, running_loss=0.3439, LR=0.000100
[2025-08-27 16:07:11,099][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082424] [Batch 02344/03080] [00:28:32/00:08:57, 0.731s/it]: train_loss_raw=0.3442, running_loss=0.3451, LR=0.000100
[2025-08-27 16:07:17,090][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082432] [Batch 02352/03080] [00:28:38/00:08:51, 0.731s/it]: train_loss_raw=0.3566, running_loss=0.3477, LR=0.000100
[2025-08-27 16:07:23,022][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082440] [Batch 02360/03080] [00:28:44/00:08:46, 0.731s/it]: train_loss_raw=0.2937, running_loss=0.3480, LR=0.000100
[2025-08-27 16:07:28,691][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082448] [Batch 02368/03080] [00:28:50/00:08:40, 0.731s/it]: train_loss_raw=0.3732, running_loss=0.3493, LR=0.000100
[2025-08-27 16:07:34,588][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082456] [Batch 02376/03080] [00:28:56/00:08:34, 0.731s/it]: train_loss_raw=0.3441, running_loss=0.3491, LR=0.000100
[2025-08-27 16:07:40,497][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082464] [Batch 02384/03080] [00:29:01/00:08:28, 0.731s/it]: train_loss_raw=0.4171, running_loss=0.3481, LR=0.000100
[2025-08-27 16:07:46,506][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082472] [Batch 02392/03080] [00:29:07/00:08:22, 0.731s/it]: train_loss_raw=0.2641, running_loss=0.3469, LR=0.000100
[2025-08-27 16:07:52,352][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082480] [Batch 02400/03080] [00:29:13/00:08:16, 0.731s/it]: train_loss_raw=0.3189, running_loss=0.3469, LR=0.000100
[2025-08-27 16:07:58,196][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082488] [Batch 02408/03080] [00:29:19/00:08:11, 0.731s/it]: train_loss_raw=0.3986, running_loss=0.3473, LR=0.000100
[2025-08-27 16:08:04,106][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082496] [Batch 02416/03080] [00:29:25/00:08:05, 0.731s/it]: train_loss_raw=0.3500, running_loss=0.3481, LR=0.000100
[2025-08-27 16:08:10,127][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082504] [Batch 02424/03080] [00:29:31/00:07:59, 0.731s/it]: train_loss_raw=0.3142, running_loss=0.3472, LR=0.000100
[2025-08-27 16:08:16,081][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082512] [Batch 02432/03080] [00:29:37/00:07:53, 0.731s/it]: train_loss_raw=0.3258, running_loss=0.3473, LR=0.000100
[2025-08-27 16:08:22,072][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082520] [Batch 02440/03080] [00:29:43/00:07:47, 0.731s/it]: train_loss_raw=0.3903, running_loss=0.3481, LR=0.000100
[2025-08-27 16:08:27,815][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082528] [Batch 02448/03080] [00:29:49/00:07:41, 0.731s/it]: train_loss_raw=0.3531, running_loss=0.3487, LR=0.000100
[2025-08-27 16:08:33,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082536] [Batch 02456/03080] [00:29:55/00:07:36, 0.731s/it]: train_loss_raw=0.3694, running_loss=0.3489, LR=0.000100
[2025-08-27 16:08:39,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082544] [Batch 02464/03080] [00:30:01/00:07:30, 0.731s/it]: train_loss_raw=0.3651, running_loss=0.3503, LR=0.000100
[2025-08-27 16:08:45,370][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082552] [Batch 02472/03080] [00:30:06/00:07:24, 0.731s/it]: train_loss_raw=0.3697, running_loss=0.3495, LR=0.000100
[2025-08-27 16:08:51,224][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082560] [Batch 02480/03080] [00:30:12/00:07:18, 0.731s/it]: train_loss_raw=0.2947, running_loss=0.3501, LR=0.000100
[2025-08-27 16:08:57,208][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082568] [Batch 02488/03080] [00:30:18/00:07:12, 0.731s/it]: train_loss_raw=0.3109, running_loss=0.3497, LR=0.000100
[2025-08-27 16:09:03,267][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082576] [Batch 02496/03080] [00:30:24/00:07:06, 0.731s/it]: train_loss_raw=0.3325, running_loss=0.3494, LR=0.000100
[2025-08-27 16:09:09,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082584] [Batch 02504/03080] [00:30:30/00:07:01, 0.731s/it]: train_loss_raw=0.3508, running_loss=0.3507, LR=0.000100
[2025-08-27 16:09:14,809][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082592] [Batch 02512/03080] [00:30:36/00:06:55, 0.731s/it]: train_loss_raw=0.4103, running_loss=0.3530, LR=0.000100
[2025-08-27 16:09:20,768][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082600] [Batch 02520/03080] [00:30:42/00:06:49, 0.731s/it]: train_loss_raw=0.3904, running_loss=0.3517, LR=0.000100
[2025-08-27 16:09:26,810][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082608] [Batch 02528/03080] [00:30:48/00:06:43, 0.731s/it]: train_loss_raw=0.3145, running_loss=0.3520, LR=0.000100
[2025-08-27 16:09:32,243][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082616] [Batch 02536/03080] [00:30:53/00:06:37, 0.731s/it]: train_loss_raw=0.4050, running_loss=0.3505, LR=0.000100
[2025-08-27 16:09:38,101][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082624] [Batch 02544/03080] [00:30:59/00:06:31, 0.731s/it]: train_loss_raw=0.3942, running_loss=0.3504, LR=0.000100
[2025-08-27 16:09:43,911][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082632] [Batch 02552/03080] [00:31:05/00:06:25, 0.731s/it]: train_loss_raw=0.3338, running_loss=0.3503, LR=0.000100
[2025-08-27 16:09:49,769][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082640] [Batch 02560/03080] [00:31:11/00:06:20, 0.731s/it]: train_loss_raw=0.3290, running_loss=0.3488, LR=0.000100
[2025-08-27 16:09:55,730][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082648] [Batch 02568/03080] [00:31:17/00:06:14, 0.731s/it]: train_loss_raw=0.3253, running_loss=0.3482, LR=0.000100
[2025-08-27 16:10:01,650][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082656] [Batch 02576/03080] [00:31:23/00:06:08, 0.731s/it]: train_loss_raw=0.3353, running_loss=0.3501, LR=0.000100
[2025-08-27 16:10:07,622][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082664] [Batch 02584/03080] [00:31:29/00:06:02, 0.731s/it]: train_loss_raw=0.2768, running_loss=0.3484, LR=0.000100
[2025-08-27 16:10:13,565][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082672] [Batch 02592/03080] [00:31:34/00:05:56, 0.731s/it]: train_loss_raw=0.3976, running_loss=0.3490, LR=0.000100
[2025-08-27 16:10:19,574][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082680] [Batch 02600/03080] [00:31:41/00:05:50, 0.731s/it]: train_loss_raw=0.2939, running_loss=0.3469, LR=0.000100
[2025-08-27 16:10:25,402][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082688] [Batch 02608/03080] [00:31:46/00:05:45, 0.731s/it]: train_loss_raw=0.3697, running_loss=0.3468, LR=0.000100
[2025-08-27 16:10:31,294][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082696] [Batch 02616/03080] [00:31:52/00:05:39, 0.731s/it]: train_loss_raw=0.2987, running_loss=0.3451, LR=0.000100
[2025-08-27 16:10:37,325][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082704] [Batch 02624/03080] [00:31:58/00:05:33, 0.731s/it]: train_loss_raw=0.2497, running_loss=0.3457, LR=0.000100
[2025-08-27 16:10:43,242][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082712] [Batch 02632/03080] [00:32:04/00:05:27, 0.731s/it]: train_loss_raw=0.3647, running_loss=0.3467, LR=0.000100
[2025-08-27 16:10:49,300][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082720] [Batch 02640/03080] [00:32:10/00:05:21, 0.731s/it]: train_loss_raw=0.3042, running_loss=0.3462, LR=0.000100
[2025-08-27 16:10:55,362][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082728] [Batch 02648/03080] [00:32:16/00:05:15, 0.731s/it]: train_loss_raw=0.3520, running_loss=0.3462, LR=0.000100
[2025-08-27 16:11:01,320][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082736] [Batch 02656/03080] [00:32:22/00:05:10, 0.731s/it]: train_loss_raw=0.3074, running_loss=0.3468, LR=0.000100
[2025-08-27 16:11:07,266][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082744] [Batch 02664/03080] [00:32:28/00:05:04, 0.731s/it]: train_loss_raw=0.3292, running_loss=0.3468, LR=0.000100
[2025-08-27 16:11:13,187][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082752] [Batch 02672/03080] [00:32:34/00:04:58, 0.732s/it]: train_loss_raw=0.3516, running_loss=0.3467, LR=0.000100
[2025-08-27 16:11:19,094][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082760] [Batch 02680/03080] [00:32:40/00:04:52, 0.732s/it]: train_loss_raw=0.3424, running_loss=0.3484, LR=0.000100
[2025-08-27 16:11:24,994][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082768] [Batch 02688/03080] [00:32:46/00:04:46, 0.732s/it]: train_loss_raw=0.3484, running_loss=0.3479, LR=0.000100
[2025-08-27 16:11:30,943][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082776] [Batch 02696/03080] [00:32:52/00:04:40, 0.732s/it]: train_loss_raw=0.3306, running_loss=0.3478, LR=0.000100
[2025-08-27 16:11:36,970][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082784] [Batch 02704/03080] [00:32:58/00:04:35, 0.732s/it]: train_loss_raw=0.3269, running_loss=0.3459, LR=0.000100
[2025-08-27 16:11:42,963][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082792] [Batch 02712/03080] [00:33:04/00:04:29, 0.732s/it]: train_loss_raw=0.2897, running_loss=0.3451, LR=0.000100
[2025-08-27 16:11:48,646][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082800] [Batch 02720/03080] [00:33:10/00:04:23, 0.732s/it]: train_loss_raw=0.4177, running_loss=0.3457, LR=0.000100
[2025-08-27 16:11:54,592][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082808] [Batch 02728/03080] [00:33:16/00:04:17, 0.732s/it]: train_loss_raw=0.3046, running_loss=0.3452, LR=0.000100
[2025-08-27 16:12:00,572][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082816] [Batch 02736/03080] [00:33:22/00:04:11, 0.732s/it]: train_loss_raw=0.3010, running_loss=0.3438, LR=0.000100
[2025-08-27 16:12:06,306][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082824] [Batch 02744/03080] [00:33:27/00:04:05, 0.732s/it]: train_loss_raw=0.2912, running_loss=0.3430, LR=0.000100
[2025-08-27 16:12:11,955][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082832] [Batch 02752/03080] [00:33:33/00:03:59, 0.732s/it]: train_loss_raw=0.3242, running_loss=0.3430, LR=0.000100
[2025-08-27 16:12:17,609][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082840] [Batch 02760/03080] [00:33:39/00:03:54, 0.732s/it]: train_loss_raw=0.3477, running_loss=0.3445, LR=0.000100
[2025-08-27 16:12:23,515][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082848] [Batch 02768/03080] [00:33:44/00:03:48, 0.732s/it]: train_loss_raw=0.3483, running_loss=0.3442, LR=0.000100
[2025-08-27 16:12:29,285][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082856] [Batch 02776/03080] [00:33:50/00:03:42, 0.732s/it]: train_loss_raw=0.3383, running_loss=0.3433, LR=0.000100
[2025-08-27 16:12:35,100][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082864] [Batch 02784/03080] [00:33:56/00:03:36, 0.732s/it]: train_loss_raw=0.3230, running_loss=0.3427, LR=0.000100
[2025-08-27 16:12:40,922][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082872] [Batch 02792/03080] [00:34:02/00:03:30, 0.732s/it]: train_loss_raw=0.3783, running_loss=0.3428, LR=0.000100
[2025-08-27 16:12:46,867][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082880] [Batch 02800/03080] [00:34:08/00:03:24, 0.732s/it]: train_loss_raw=0.4330, running_loss=0.3428, LR=0.000100
[2025-08-27 16:12:52,537][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082888] [Batch 02808/03080] [00:34:13/00:03:18, 0.731s/it]: train_loss_raw=0.3998, running_loss=0.3444, LR=0.000100
[2025-08-27 16:12:58,390][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082896] [Batch 02816/03080] [00:34:19/00:03:13, 0.731s/it]: train_loss_raw=0.3155, running_loss=0.3423, LR=0.000100
[2025-08-27 16:13:04,465][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082904] [Batch 02824/03080] [00:34:25/00:03:07, 0.732s/it]: train_loss_raw=0.4005, running_loss=0.3445, LR=0.000100
[2025-08-27 16:13:10,496][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082912] [Batch 02832/03080] [00:34:31/00:03:01, 0.732s/it]: train_loss_raw=0.3613, running_loss=0.3465, LR=0.000100
[2025-08-27 16:13:16,526][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082920] [Batch 02840/03080] [00:34:37/00:02:55, 0.732s/it]: train_loss_raw=0.4397, running_loss=0.3489, LR=0.000100
[2025-08-27 16:13:22,529][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082928] [Batch 02848/03080] [00:34:43/00:02:49, 0.732s/it]: train_loss_raw=0.2888, running_loss=0.3468, LR=0.000100
[2025-08-27 16:13:28,516][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082936] [Batch 02856/03080] [00:34:49/00:02:43, 0.732s/it]: train_loss_raw=0.3152, running_loss=0.3469, LR=0.000100
[2025-08-27 16:13:34,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082944] [Batch 02864/03080] [00:34:55/00:02:38, 0.732s/it]: train_loss_raw=0.2613, running_loss=0.3461, LR=0.000100
[2025-08-27 16:13:40,082][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082952] [Batch 02872/03080] [00:35:01/00:02:32, 0.732s/it]: train_loss_raw=0.3525, running_loss=0.3442, LR=0.000100
[2025-08-27 16:13:46,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082960] [Batch 02880/03080] [00:35:07/00:02:26, 0.732s/it]: train_loss_raw=0.3268, running_loss=0.3443, LR=0.000100
[2025-08-27 16:13:52,222][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082968] [Batch 02888/03080] [00:35:13/00:02:20, 0.732s/it]: train_loss_raw=0.2984, running_loss=0.3440, LR=0.000100
[2025-08-27 16:13:58,212][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082976] [Batch 02896/03080] [00:35:19/00:02:14, 0.732s/it]: train_loss_raw=0.3217, running_loss=0.3430, LR=0.000100
[2025-08-27 16:14:04,182][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082984] [Batch 02904/03080] [00:35:25/00:02:08, 0.732s/it]: train_loss_raw=0.3042, running_loss=0.3417, LR=0.000100
[2025-08-27 16:14:10,153][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082992] [Batch 02912/03080] [00:35:31/00:02:02, 0.732s/it]: train_loss_raw=0.3272, running_loss=0.3421, LR=0.000100
[2025-08-27 16:14:16,003][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083000] [Batch 02920/03080] [00:35:37/00:01:57, 0.732s/it]: train_loss_raw=0.3893, running_loss=0.3437, LR=0.000100
[2025-08-27 16:14:21,437][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083008] [Batch 02928/03080] [00:35:42/00:01:51, 0.732s/it]: train_loss_raw=0.3793, running_loss=0.3452, LR=0.000100
[2025-08-27 16:14:27,023][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083016] [Batch 02936/03080] [00:35:48/00:01:45, 0.732s/it]: train_loss_raw=0.2820, running_loss=0.3441, LR=0.000100
[2025-08-27 16:14:32,924][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083024] [Batch 02944/03080] [00:35:54/00:01:39, 0.732s/it]: train_loss_raw=0.3675, running_loss=0.3433, LR=0.000100
[2025-08-27 16:14:38,723][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083032] [Batch 02952/03080] [00:36:00/00:01:33, 0.732s/it]: train_loss_raw=0.2994, running_loss=0.3419, LR=0.000100
[2025-08-27 16:14:44,232][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083040] [Batch 02960/03080] [00:36:05/00:01:27, 0.732s/it]: train_loss_raw=0.3224, running_loss=0.3419, LR=0.000100
[2025-08-27 16:14:49,956][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083048] [Batch 02968/03080] [00:36:11/00:01:21, 0.732s/it]: train_loss_raw=0.4168, running_loss=0.3438, LR=0.000100
[2025-08-27 16:14:55,783][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083056] [Batch 02976/03080] [00:36:17/00:01:16, 0.732s/it]: train_loss_raw=0.3818, running_loss=0.3459, LR=0.000100
[2025-08-27 16:15:01,568][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083064] [Batch 02984/03080] [00:36:23/00:01:10, 0.732s/it]: train_loss_raw=0.3936, running_loss=0.3470, LR=0.000100
[2025-08-27 16:15:07,590][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083072] [Batch 02992/03080] [00:36:29/00:01:04, 0.732s/it]: train_loss_raw=0.3430, running_loss=0.3448, LR=0.000100
[2025-08-27 16:15:13,864][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083080] [Batch 03000/03080] [00:36:35/00:00:58, 0.732s/it]: train_loss_raw=0.3011, running_loss=0.3470, LR=0.000100
[2025-08-27 16:15:19,577][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083088] [Batch 03008/03080] [00:36:41/00:00:52, 0.732s/it]: train_loss_raw=0.3369, running_loss=0.3467, LR=0.000100
[2025-08-27 16:15:25,553][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083096] [Batch 03016/03080] [00:36:46/00:00:46, 0.732s/it]: train_loss_raw=0.3581, running_loss=0.3466, LR=0.000100
[2025-08-27 16:15:31,595][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083104] [Batch 03024/03080] [00:36:53/00:00:40, 0.732s/it]: train_loss_raw=0.3112, running_loss=0.3454, LR=0.000100
[2025-08-27 16:15:37,570][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083112] [Batch 03032/03080] [00:36:59/00:00:35, 0.732s/it]: train_loss_raw=0.3095, running_loss=0.3449, LR=0.000100
[2025-08-27 16:15:43,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083120] [Batch 03040/03080] [00:37:05/00:00:29, 0.732s/it]: train_loss_raw=0.3331, running_loss=0.3459, LR=0.000100
[2025-08-27 16:15:49,665][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083128] [Batch 03048/03080] [00:37:11/00:00:23, 0.732s/it]: train_loss_raw=0.3371, running_loss=0.3443, LR=0.000100
[2025-08-27 16:15:55,575][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083136] [Batch 03056/03080] [00:37:17/00:00:17, 0.732s/it]: train_loss_raw=0.3105, running_loss=0.3469, LR=0.000100
[2025-08-27 16:16:01,529][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083144] [Batch 03064/03080] [00:37:22/00:00:11, 0.732s/it]: train_loss_raw=0.3670, running_loss=0.3474, LR=0.000100
[2025-08-27 16:16:07,399][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083152] [Batch 03072/03080] [00:37:28/00:00:05, 0.732s/it]: train_loss_raw=0.3839, running_loss=0.3474, LR=0.000100
[2025-08-27 16:16:13,389][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083160] [Batch 03080/03080] [00:37:34/00:00:00, 0.732s/it]: train_loss_raw=0.3192, running_loss=0.3488, LR=0.000100
[2025-08-27 16:16:13,894][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-27 16:16:25,260][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00007/00310] [00:00:11/00:07:09, 1.421s/it]
[2025-08-27 16:16:36,643][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00015/00310] [00:00:22/00:06:57, 1.422s/it]
[2025-08-27 16:16:47,984][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00023/00310] [00:00:34/00:06:46, 1.420s/it]
[2025-08-27 16:16:59,654][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00031/00310] [00:00:45/00:06:37, 1.430s/it]
[2025-08-27 16:17:11,698][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00039/00310] [00:00:57/00:06:30, 1.445s/it]
[2025-08-27 16:17:23,994][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00047/00310] [00:01:10/00:06:22, 1.460s/it]
[2025-08-27 16:17:35,821][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00055/00310] [00:01:21/00:06:11, 1.463s/it]
[2025-08-27 16:17:47,855][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00063/00310] [00:01:33/00:06:01, 1.468s/it]
[2025-08-27 16:17:59,911][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00071/00310] [00:01:46/00:05:50, 1.472s/it]
[2025-08-27 16:18:11,589][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00079/00310] [00:01:57/00:05:38, 1.471s/it]
[2025-08-27 16:18:23,016][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00087/00310] [00:02:09/00:05:25, 1.467s/it]
[2025-08-27 16:18:34,838][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00095/00310] [00:02:20/00:05:14, 1.468s/it]
[2025-08-27 16:18:46,764][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00103/00310] [00:02:32/00:05:02, 1.470s/it]
[2025-08-27 16:18:58,309][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00111/00310] [00:02:44/00:04:50, 1.468s/it]
[2025-08-27 16:19:10,122][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00119/00310] [00:02:56/00:04:39, 1.469s/it]
[2025-08-27 16:19:21,880][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00127/00310] [00:03:07/00:04:27, 1.469s/it]
[2025-08-27 16:19:34,220][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00135/00310] [00:03:20/00:04:16, 1.473s/it]
[2025-08-27 16:19:46,315][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00143/00310] [00:03:32/00:04:04, 1.475s/it]
[2025-08-27 16:19:56,327][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00151/00310] [00:03:42/00:03:51, 1.463s/it]
[2025-08-27 16:20:06,510][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00159/00310] [00:03:52/00:03:38, 1.454s/it]
[2025-08-27 16:20:18,916][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00167/00310] [00:04:05/00:03:27, 1.458s/it]
[2025-08-27 16:20:28,447][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00175/00310] [00:04:14/00:03:13, 1.446s/it]
[2025-08-27 16:20:38,223][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00183/00310] [00:04:24/00:03:01, 1.437s/it]
[2025-08-27 16:20:49,552][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00191/00310] [00:04:35/00:02:49, 1.436s/it]
[2025-08-27 16:21:01,014][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00199/00310] [00:04:47/00:02:37, 1.436s/it]
[2025-08-27 16:21:11,792][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00207/00310] [00:04:57/00:02:26, 1.432s/it]
[2025-08-27 16:21:22,514][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00215/00310] [00:05:08/00:02:14, 1.429s/it]
[2025-08-27 16:21:34,184][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00223/00310] [00:05:20/00:02:02, 1.430s/it]
[2025-08-27 16:21:46,000][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00231/00310] [00:05:32/00:01:51, 1.431s/it]
[2025-08-27 16:21:57,272][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00239/00310] [00:05:43/00:01:40, 1.431s/it]
[2025-08-27 16:22:08,961][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00247/00310] [00:05:55/00:01:28, 1.432s/it]
[2025-08-27 16:22:21,063][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00255/00310] [00:06:07/00:01:17, 1.434s/it]
[2025-08-27 16:22:32,989][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00263/00310] [00:06:19/00:01:06, 1.436s/it]
[2025-08-27 16:22:44,174][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00271/00310] [00:06:30/00:00:54, 1.435s/it]
[2025-08-27 16:22:55,195][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00279/00310] [00:06:41/00:00:42, 1.433s/it]
[2025-08-27 16:23:06,651][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00287/00310] [00:06:52/00:00:31, 1.433s/it]
[2025-08-27 16:23:17,301][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00295/00310] [00:07:03/00:00:20, 1.430s/it]
[2025-08-27 16:23:28,886][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00303/00310] [00:07:14/00:00:08, 1.431s/it]
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.34884, valid_loss=1.43251
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.480
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.154
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.158
[2025-08-27 16:23:38,046][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.089
[2025-08-27 16:23:38,060][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 20:56:51, remaining time 02:19:39, 00:46:33 per epoch
[2025-08-27 16:23:46,037][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083168] [Batch 00008/03080] [00:00:07/00:49:23, 0.965s/it]: train_loss_raw=0.3533, running_loss=0.3878, LR=0.000100
[2025-08-27 16:23:52,118][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083176] [Batch 00016/03080] [00:00:13/00:44:02, 0.862s/it]: train_loss_raw=0.3140, running_loss=0.3845, LR=0.000100
[2025-08-27 16:23:58,228][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083184] [Batch 00024/03080] [00:00:19/00:42:14, 0.830s/it]: train_loss_raw=0.3931, running_loss=0.3827, LR=0.000100
[2025-08-27 16:24:04,302][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083192] [Batch 00032/03080] [00:00:25/00:41:14, 0.812s/it]: train_loss_raw=0.3726, running_loss=0.3815, LR=0.000100
[2025-08-27 16:24:10,422][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083200] [Batch 00040/03080] [00:00:32/00:40:39, 0.803s/it]: train_loss_raw=0.3379, running_loss=0.3792, LR=0.000100
[2025-08-27 16:24:16,448][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083208] [Batch 00048/03080] [00:00:38/00:40:08, 0.794s/it]: train_loss_raw=0.3428, running_loss=0.3760, LR=0.000100
[2025-08-27 16:24:22,301][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083216] [Batch 00056/03080] [00:00:43/00:39:35, 0.785s/it]: train_loss_raw=0.2385, running_loss=0.3721, LR=0.000100
[2025-08-27 16:24:28,145][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083224] [Batch 00064/03080] [00:00:49/00:39:08, 0.779s/it]: train_loss_raw=0.3761, running_loss=0.3712, LR=0.000100
[2025-08-27 16:24:34,105][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083232] [Batch 00072/03080] [00:00:55/00:38:50, 0.775s/it]: train_loss_raw=0.3755, running_loss=0.3684, LR=0.000100
[2025-08-27 16:24:39,947][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083240] [Batch 00080/03080] [00:01:01/00:38:31, 0.770s/it]: train_loss_raw=0.3417, running_loss=0.3667, LR=0.000100
[2025-08-27 16:24:45,795][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083248] [Batch 00088/03080] [00:01:07/00:38:14, 0.767s/it]: train_loss_raw=0.3455, running_loss=0.3663, LR=0.000100
[2025-08-27 16:24:51,587][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083256] [Batch 00096/03080] [00:01:13/00:37:57, 0.763s/it]: train_loss_raw=0.3573, running_loss=0.3659, LR=0.000100
[2025-08-27 16:24:57,493][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083264] [Batch 00104/03080] [00:01:19/00:37:45, 0.761s/it]: train_loss_raw=0.2730, running_loss=0.3625, LR=0.000100
[2025-08-27 16:25:03,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083272] [Batch 00112/03080] [00:01:25/00:37:36, 0.760s/it]: train_loss_raw=0.3514, running_loss=0.3599, LR=0.000100
[2025-08-27 16:25:09,477][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083280] [Batch 00120/03080] [00:01:31/00:37:28, 0.760s/it]: train_loss_raw=0.2407, running_loss=0.3587, LR=0.000100
[2025-08-27 16:25:15,224][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083288] [Batch 00128/03080] [00:01:36/00:37:14, 0.757s/it]: train_loss_raw=0.3629, running_loss=0.3595, LR=0.000100
[2025-08-27 16:25:21,016][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083296] [Batch 00136/03080] [00:01:42/00:37:03, 0.755s/it]: train_loss_raw=0.3789, running_loss=0.3596, LR=0.000100
[2025-08-27 16:25:26,871][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083304] [Batch 00144/03080] [00:01:48/00:36:53, 0.754s/it]: train_loss_raw=0.3503, running_loss=0.3583, LR=0.000100
[2025-08-27 16:25:32,834][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083312] [Batch 00152/03080] [00:01:54/00:36:45, 0.753s/it]: train_loss_raw=0.3215, running_loss=0.3557, LR=0.000100
[2025-08-27 16:25:38,624][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083320] [Batch 00160/03080] [00:02:00/00:36:35, 0.752s/it]: train_loss_raw=0.2643, running_loss=0.3538, LR=0.000100
[2025-08-27 16:25:44,624][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083328] [Batch 00168/03080] [00:02:06/00:36:29, 0.752s/it]: train_loss_raw=0.4444, running_loss=0.3552, LR=0.000100
[2025-08-27 16:25:50,634][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083336] [Batch 00176/03080] [00:02:12/00:36:23, 0.752s/it]: train_loss_raw=0.3482, running_loss=0.3535, LR=0.000100
[2025-08-27 16:25:56,667][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083344] [Batch 00184/03080] [00:02:18/00:36:17, 0.752s/it]: train_loss_raw=0.3531, running_loss=0.3511, LR=0.000100
[2025-08-27 16:26:02,675][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083352] [Batch 00192/03080] [00:02:24/00:36:11, 0.752s/it]: train_loss_raw=0.2975, running_loss=0.3488, LR=0.000100
[2025-08-27 16:26:08,612][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083360] [Batch 00200/03080] [00:02:30/00:36:04, 0.751s/it]: train_loss_raw=0.2847, running_loss=0.3477, LR=0.000100
[2025-08-27 16:26:14,569][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083368] [Batch 00208/03080] [00:02:36/00:35:57, 0.751s/it]: train_loss_raw=0.3532, running_loss=0.3474, LR=0.000100
[2025-08-27 16:26:20,601][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083376] [Batch 00216/03080] [00:02:42/00:35:51, 0.751s/it]: train_loss_raw=0.3291, running_loss=0.3477, LR=0.000100
[2025-08-27 16:26:26,453][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083384] [Batch 00224/03080] [00:02:48/00:35:43, 0.751s/it]: train_loss_raw=0.3674, running_loss=0.3463, LR=0.000100
[2025-08-27 16:26:32,313][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083392] [Batch 00232/03080] [00:02:53/00:35:35, 0.750s/it]: train_loss_raw=0.4093, running_loss=0.3470, LR=0.000100
[2025-08-27 16:26:38,225][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083400] [Batch 00240/03080] [00:02:59/00:35:28, 0.750s/it]: train_loss_raw=0.3589, running_loss=0.3477, LR=0.000100
[2025-08-27 16:26:44,129][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083408] [Batch 00248/03080] [00:03:05/00:35:21, 0.749s/it]: train_loss_raw=0.2468, running_loss=0.3456, LR=0.000100
[2025-08-27 16:26:49,626][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083416] [Batch 00256/03080] [00:03:11/00:35:10, 0.747s/it]: train_loss_raw=0.4372, running_loss=0.3459, LR=0.000100
[2025-08-27 16:26:55,354][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083424] [Batch 00264/03080] [00:03:17/00:35:01, 0.746s/it]: train_loss_raw=0.3768, running_loss=0.3462, LR=0.000100
[2025-08-27 16:27:01,341][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083432] [Batch 00272/03080] [00:03:23/00:34:55, 0.746s/it]: train_loss_raw=0.3739, running_loss=0.3470, LR=0.000100
[2025-08-27 16:27:06,979][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083440] [Batch 00280/03080] [00:03:28/00:34:46, 0.745s/it]: train_loss_raw=0.3296, running_loss=0.3476, LR=0.000100
[2025-08-27 16:27:12,934][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083448] [Batch 00288/03080] [00:03:34/00:34:40, 0.745s/it]: train_loss_raw=0.3424, running_loss=0.3478, LR=0.000100
[2025-08-27 16:27:18,834][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083456] [Batch 00296/03080] [00:03:40/00:34:34, 0.745s/it]: train_loss_raw=0.3966, running_loss=0.3468, LR=0.000100
[2025-08-27 16:27:24,681][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083464] [Batch 00304/03080] [00:03:46/00:34:27, 0.745s/it]: train_loss_raw=0.3492, running_loss=0.3473, LR=0.000100
[2025-08-27 16:27:30,598][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083472] [Batch 00312/03080] [00:03:52/00:34:20, 0.744s/it]: train_loss_raw=0.3405, running_loss=0.3481, LR=0.000100
[2025-08-27 16:27:36,561][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083480] [Batch 00320/03080] [00:03:58/00:34:14, 0.745s/it]: train_loss_raw=0.3539, running_loss=0.3479, LR=0.000100
[2025-08-27 16:27:42,339][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083488] [Batch 00328/03080] [00:04:04/00:34:07, 0.744s/it]: train_loss_raw=0.4167, running_loss=0.3485, LR=0.000100
[2025-08-27 16:27:48,302][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083496] [Batch 00336/03080] [00:04:09/00:34:01, 0.744s/it]: train_loss_raw=0.4663, running_loss=0.3475, LR=0.000100
[2025-08-27 16:27:54,117][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083504] [Batch 00344/03080] [00:04:15/00:33:54, 0.744s/it]: train_loss_raw=0.2625, running_loss=0.3468, LR=0.000100
[2025-08-27 16:27:59,537][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083512] [Batch 00352/03080] [00:04:21/00:33:44, 0.742s/it]: train_loss_raw=0.3127, running_loss=0.3474, LR=0.000100
[2025-08-27 16:28:05,428][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083520] [Batch 00360/03080] [00:04:27/00:33:38, 0.742s/it]: train_loss_raw=0.3892, running_loss=0.3496, LR=0.000100
[2025-08-27 16:28:11,329][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083528] [Batch 00368/03080] [00:04:33/00:33:31, 0.742s/it]: train_loss_raw=0.4157, running_loss=0.3497, LR=0.000100
[2025-08-27 16:28:17,395][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083536] [Batch 00376/03080] [00:04:39/00:33:26, 0.742s/it]: train_loss_raw=0.3159, running_loss=0.3483, LR=0.000100
[2025-08-27 16:28:23,375][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083544] [Batch 00384/03080] [00:04:45/00:33:21, 0.742s/it]: train_loss_raw=0.3716, running_loss=0.3472, LR=0.000100
[2025-08-27 16:28:29,368][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083552] [Batch 00392/03080] [00:04:51/00:33:15, 0.742s/it]: train_loss_raw=0.3452, running_loss=0.3461, LR=0.000100
[2025-08-27 16:28:35,461][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083560] [Batch 00400/03080] [00:04:57/00:33:10, 0.743s/it]: train_loss_raw=0.3536, running_loss=0.3463, LR=0.000100
[2025-08-27 16:28:41,126][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083568] [Batch 00408/03080] [00:05:02/00:33:03, 0.742s/it]: train_loss_raw=0.4218, running_loss=0.3468, LR=0.000100
[2025-08-27 16:28:47,037][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083576] [Batch 00416/03080] [00:05:08/00:32:56, 0.742s/it]: train_loss_raw=0.3382, running_loss=0.3465, LR=0.000100
[2025-08-27 16:28:52,829][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083584] [Batch 00424/03080] [00:05:14/00:32:50, 0.742s/it]: train_loss_raw=0.3220, running_loss=0.3476, LR=0.000100
[2025-08-27 16:28:58,267][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083592] [Batch 00432/03080] [00:05:19/00:32:41, 0.741s/it]: train_loss_raw=0.3282, running_loss=0.3473, LR=0.000100
[2025-08-27 16:29:04,102][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083600] [Batch 00440/03080] [00:05:25/00:32:34, 0.740s/it]: train_loss_raw=0.3500, running_loss=0.3473, LR=0.000100
[2025-08-27 16:29:09,859][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083608] [Batch 00448/03080] [00:05:31/00:32:27, 0.740s/it]: train_loss_raw=0.2967, running_loss=0.3464, LR=0.000100
[2025-08-27 16:29:15,685][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083616] [Batch 00456/03080] [00:05:37/00:32:21, 0.740s/it]: train_loss_raw=0.4691, running_loss=0.3465, LR=0.000100
[2025-08-27 16:29:21,659][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083624] [Batch 00464/03080] [00:05:43/00:32:15, 0.740s/it]: train_loss_raw=0.3350, running_loss=0.3450, LR=0.000100
[2025-08-27 16:29:27,663][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083632] [Batch 00472/03080] [00:05:49/00:32:10, 0.740s/it]: train_loss_raw=0.2811, running_loss=0.3446, LR=0.000100
[2025-08-27 16:29:33,362][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083640] [Batch 00480/03080] [00:05:55/00:32:03, 0.740s/it]: train_loss_raw=0.4643, running_loss=0.3439, LR=0.000100
[2025-08-27 16:29:39,221][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083648] [Batch 00488/03080] [00:06:00/00:31:56, 0.740s/it]: train_loss_raw=0.2763, running_loss=0.3450, LR=0.000100
[2025-08-27 16:29:45,074][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083656] [Batch 00496/03080] [00:06:06/00:31:50, 0.739s/it]: train_loss_raw=0.3416, running_loss=0.3459, LR=0.000100
[2025-08-27 16:29:50,490][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083664] [Batch 00504/03080] [00:06:12/00:31:42, 0.738s/it]: train_loss_raw=0.3323, running_loss=0.3451, LR=0.000100
[2025-08-27 16:29:56,298][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083672] [Batch 00512/03080] [00:06:17/00:31:35, 0.738s/it]: train_loss_raw=0.3325, running_loss=0.3449, LR=0.000100
[2025-08-27 16:30:02,061][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083680] [Batch 00520/03080] [00:06:23/00:31:29, 0.738s/it]: train_loss_raw=0.3256, running_loss=0.3451, LR=0.000100
[2025-08-27 16:30:07,824][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083688] [Batch 00528/03080] [00:06:29/00:31:22, 0.738s/it]: train_loss_raw=0.3869, running_loss=0.3449, LR=0.000100
[2025-08-27 16:30:13,623][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083696] [Batch 00536/03080] [00:06:35/00:31:16, 0.738s/it]: train_loss_raw=0.3944, running_loss=0.3460, LR=0.000100
[2025-08-27 16:30:19,486][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083704] [Batch 00544/03080] [00:06:41/00:31:10, 0.737s/it]: train_loss_raw=0.4192, running_loss=0.3462, LR=0.000100
[2025-08-27 16:30:25,218][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083712] [Batch 00552/03080] [00:06:46/00:31:03, 0.737s/it]: train_loss_raw=0.3433, running_loss=0.3462, LR=0.000100
[2025-08-27 16:30:30,632][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083720] [Batch 00560/03080] [00:06:52/00:30:55, 0.736s/it]: train_loss_raw=0.3361, running_loss=0.3477, LR=0.000100
[2025-08-27 16:30:36,250][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083728] [Batch 00568/03080] [00:06:57/00:30:48, 0.736s/it]: train_loss_raw=0.3180, running_loss=0.3477, LR=0.000100
[2025-08-27 16:30:41,798][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083736] [Batch 00576/03080] [00:07:03/00:30:40, 0.735s/it]: train_loss_raw=0.4018, running_loss=0.3480, LR=0.000100
[2025-08-27 16:30:47,382][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083744] [Batch 00584/03080] [00:07:09/00:30:33, 0.735s/it]: train_loss_raw=0.3853, running_loss=0.3490, LR=0.000100
[2025-08-27 16:30:53,076][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083752] [Batch 00592/03080] [00:07:14/00:30:27, 0.734s/it]: train_loss_raw=0.3722, running_loss=0.3480, LR=0.000100
[2025-08-27 16:30:58,595][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083760] [Batch 00600/03080] [00:07:20/00:30:19, 0.734s/it]: train_loss_raw=0.4035, running_loss=0.3478, LR=0.000100
[2025-08-27 16:31:04,354][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083768] [Batch 00608/03080] [00:07:26/00:30:13, 0.734s/it]: train_loss_raw=0.3514, running_loss=0.3476, LR=0.000100
[2025-08-27 16:31:10,140][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083776] [Batch 00616/03080] [00:07:31/00:30:07, 0.733s/it]: train_loss_raw=0.3972, running_loss=0.3485, LR=0.000100
[2025-08-27 16:31:16,074][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083784] [Batch 00624/03080] [00:07:37/00:30:01, 0.734s/it]: train_loss_raw=0.4153, running_loss=0.3485, LR=0.000100
[2025-08-27 16:31:21,477][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083792] [Batch 00632/03080] [00:07:43/00:29:54, 0.733s/it]: train_loss_raw=0.3062, running_loss=0.3492, LR=0.000100
[2025-08-27 16:31:27,433][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083800] [Batch 00640/03080] [00:07:49/00:29:48, 0.733s/it]: train_loss_raw=0.3411, running_loss=0.3484, LR=0.000100
[2025-08-27 16:31:33,391][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083808] [Batch 00648/03080] [00:07:55/00:29:42, 0.733s/it]: train_loss_raw=0.3065, running_loss=0.3475, LR=0.000100
[2025-08-27 16:31:39,297][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083816] [Batch 00656/03080] [00:08:00/00:29:37, 0.733s/it]: train_loss_raw=0.3812, running_loss=0.3486, LR=0.000100
[2025-08-27 16:31:44,791][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083824] [Batch 00664/03080] [00:08:06/00:29:30, 0.733s/it]: train_loss_raw=0.3724, running_loss=0.3471, LR=0.000100
[2025-08-27 16:31:50,680][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083832] [Batch 00672/03080] [00:08:12/00:29:24, 0.733s/it]: train_loss_raw=0.3804, running_loss=0.3468, LR=0.000100
[2025-08-27 16:31:56,089][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083840] [Batch 00680/03080] [00:08:17/00:29:16, 0.732s/it]: train_loss_raw=0.3705, running_loss=0.3475, LR=0.000100
[2025-08-27 16:32:01,735][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083848] [Batch 00688/03080] [00:08:23/00:29:10, 0.732s/it]: train_loss_raw=0.3787, running_loss=0.3461, LR=0.000100
[2025-08-27 16:32:07,531][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083856] [Batch 00696/03080] [00:08:29/00:29:04, 0.732s/it]: train_loss_raw=0.3266, running_loss=0.3447, LR=0.000100
[2025-08-27 16:32:13,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083864] [Batch 00704/03080] [00:08:35/00:28:58, 0.732s/it]: train_loss_raw=0.3010, running_loss=0.3420, LR=0.000100
[2025-08-27 16:32:19,318][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083872] [Batch 00712/03080] [00:08:40/00:28:52, 0.732s/it]: train_loss_raw=0.3277, running_loss=0.3416, LR=0.000100
[2025-08-27 16:32:24,876][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083880] [Batch 00720/03080] [00:08:46/00:28:45, 0.731s/it]: train_loss_raw=0.3340, running_loss=0.3386, LR=0.000100
[2025-08-27 16:32:30,946][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083888] [Batch 00728/03080] [00:08:52/00:28:40, 0.732s/it]: train_loss_raw=0.3322, running_loss=0.3393, LR=0.000100
[2025-08-27 16:32:36,375][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083896] [Batch 00736/03080] [00:08:58/00:28:33, 0.731s/it]: train_loss_raw=0.3591, running_loss=0.3382, LR=0.000100
[2025-08-27 16:32:42,401][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083904] [Batch 00744/03080] [00:09:04/00:28:28, 0.731s/it]: train_loss_raw=0.3178, running_loss=0.3395, LR=0.000100
[2025-08-27 16:32:48,265][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083912] [Batch 00752/03080] [00:09:09/00:28:22, 0.731s/it]: train_loss_raw=0.3143, running_loss=0.3382, LR=0.000100
[2025-08-27 16:32:54,283][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083920] [Batch 00760/03080] [00:09:15/00:28:17, 0.732s/it]: train_loss_raw=0.3676, running_loss=0.3401, LR=0.000100
[2025-08-27 16:33:00,126][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083928] [Batch 00768/03080] [00:09:21/00:28:11, 0.732s/it]: train_loss_raw=0.2650, running_loss=0.3390, LR=0.000100
[2025-08-27 16:33:06,010][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083936] [Batch 00776/03080] [00:09:27/00:28:05, 0.732s/it]: train_loss_raw=0.4183, running_loss=0.3407, LR=0.000100
[2025-08-27 16:33:11,924][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083944] [Batch 00784/03080] [00:09:33/00:27:59, 0.732s/it]: train_loss_raw=0.3300, running_loss=0.3399, LR=0.000100
[2025-08-27 16:33:17,521][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083952] [Batch 00792/03080] [00:09:39/00:27:53, 0.731s/it]: train_loss_raw=0.3444, running_loss=0.3391, LR=0.000100
[2025-08-27 16:33:23,416][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083960] [Batch 00800/03080] [00:09:45/00:27:47, 0.731s/it]: train_loss_raw=0.3992, running_loss=0.3403, LR=0.000100
[2025-08-27 16:33:29,202][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083968] [Batch 00808/03080] [00:09:50/00:27:41, 0.731s/it]: train_loss_raw=0.3571, running_loss=0.3419, LR=0.000100
[2025-08-27 16:33:34,986][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083976] [Batch 00816/03080] [00:09:56/00:27:35, 0.731s/it]: train_loss_raw=0.3437, running_loss=0.3406, LR=0.000100
[2025-08-27 16:33:40,503][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083984] [Batch 00824/03080] [00:10:02/00:27:28, 0.731s/it]: train_loss_raw=0.2588, running_loss=0.3381, LR=0.000100
[2025-08-27 16:33:45,917][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083992] [Batch 00832/03080] [00:10:07/00:27:21, 0.730s/it]: train_loss_raw=0.3352, running_loss=0.3375, LR=0.000100
[2025-08-27 16:33:51,335][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084000] [Batch 00840/03080] [00:10:13/00:27:14, 0.730s/it]: train_loss_raw=0.2780, running_loss=0.3361, LR=0.000100
[2025-08-27 16:34:00,624][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084008] [Batch 00848/03080] [00:10:22/00:27:17, 0.734s/it]: train_loss_raw=0.3395, running_loss=0.3375, LR=0.000100
[2025-08-27 16:34:06,132][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084016] [Batch 00856/03080] [00:10:27/00:27:11, 0.733s/it]: train_loss_raw=0.4154, running_loss=0.3391, LR=0.000100
[2025-08-27 16:34:11,985][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084024] [Batch 00864/03080] [00:10:33/00:27:05, 0.733s/it]: train_loss_raw=0.3891, running_loss=0.3399, LR=0.000100
[2025-08-27 16:34:17,776][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084032] [Batch 00872/03080] [00:10:39/00:26:59, 0.733s/it]: train_loss_raw=0.3092, running_loss=0.3385, LR=0.000100
[2025-08-27 16:34:23,341][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084040] [Batch 00880/03080] [00:10:45/00:26:52, 0.733s/it]: train_loss_raw=0.3745, running_loss=0.3402, LR=0.000100
[2025-08-27 16:34:28,831][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084048] [Batch 00888/03080] [00:10:50/00:26:45, 0.733s/it]: train_loss_raw=0.3443, running_loss=0.3423, LR=0.000100
[2025-08-27 16:34:34,511][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084056] [Batch 00896/03080] [00:10:56/00:26:39, 0.732s/it]: train_loss_raw=0.3761, running_loss=0.3423, LR=0.000100
[2025-08-27 16:34:39,976][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084064] [Batch 00904/03080] [00:11:01/00:26:32, 0.732s/it]: train_loss_raw=0.3169, running_loss=0.3427, LR=0.000100
[2025-08-27 16:34:45,879][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084072] [Batch 00912/03080] [00:11:07/00:26:26, 0.732s/it]: train_loss_raw=0.3883, running_loss=0.3439, LR=0.000100
[2025-08-27 16:34:51,946][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084080] [Batch 00920/03080] [00:11:13/00:26:21, 0.732s/it]: train_loss_raw=0.3673, running_loss=0.3423, LR=0.000100
[2025-08-27 16:34:57,745][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084088] [Batch 00928/03080] [00:11:19/00:26:15, 0.732s/it]: train_loss_raw=0.3535, running_loss=0.3430, LR=0.000100
[2025-08-27 16:35:03,428][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084096] [Batch 00936/03080] [00:11:25/00:26:09, 0.732s/it]: train_loss_raw=0.3227, running_loss=0.3418, LR=0.000100
[2025-08-27 16:35:09,053][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084104] [Batch 00944/03080] [00:11:30/00:26:02, 0.732s/it]: train_loss_raw=0.3868, running_loss=0.3432, LR=0.000100
[2025-08-27 16:35:14,663][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084112] [Batch 00952/03080] [00:11:36/00:25:56, 0.731s/it]: train_loss_raw=0.3775, running_loss=0.3437, LR=0.000100
[2025-08-27 16:35:20,775][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084120] [Batch 00960/03080] [00:11:42/00:25:51, 0.732s/it]: train_loss_raw=0.2794, running_loss=0.3433, LR=0.000100
[2025-08-27 16:35:26,269][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084128] [Batch 00968/03080] [00:11:47/00:25:44, 0.731s/it]: train_loss_raw=0.3275, running_loss=0.3443, LR=0.000100
[2025-08-27 16:35:32,126][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084136] [Batch 00976/03080] [00:11:53/00:25:38, 0.731s/it]: train_loss_raw=0.2992, running_loss=0.3454, LR=0.000100
[2025-08-27 16:35:38,141][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084144] [Batch 00984/03080] [00:11:59/00:25:33, 0.732s/it]: train_loss_raw=0.3075, running_loss=0.3469, LR=0.000100
[2025-08-27 16:35:43,828][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084152] [Batch 00992/03080] [00:12:05/00:25:27, 0.731s/it]: train_loss_raw=0.3514, running_loss=0.3491, LR=0.000100
[2025-08-27 16:35:49,706][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084160] [Batch 01000/03080] [00:12:11/00:25:21, 0.731s/it]: train_loss_raw=0.4407, running_loss=0.3505, LR=0.000100
[2025-08-27 16:35:55,745][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084168] [Batch 01008/03080] [00:12:17/00:25:15, 0.732s/it]: train_loss_raw=0.3515, running_loss=0.3494, LR=0.000100
[2025-08-27 16:36:01,495][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084176] [Batch 01016/03080] [00:12:23/00:25:09, 0.731s/it]: train_loss_raw=0.3474, running_loss=0.3474, LR=0.000100
[2025-08-27 16:36:07,289][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084184] [Batch 01024/03080] [00:12:28/00:25:03, 0.731s/it]: train_loss_raw=0.3140, running_loss=0.3457, LR=0.000100
[2025-08-27 16:36:12,905][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084192] [Batch 01032/03080] [00:12:34/00:24:57, 0.731s/it]: train_loss_raw=0.3378, running_loss=0.3454, LR=0.000100
[2025-08-27 16:36:18,495][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084200] [Batch 01040/03080] [00:12:40/00:24:51, 0.731s/it]: train_loss_raw=0.4423, running_loss=0.3463, LR=0.000100
[2025-08-27 16:36:24,148][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084208] [Batch 01048/03080] [00:12:45/00:24:44, 0.731s/it]: train_loss_raw=0.3153, running_loss=0.3466, LR=0.000100
[2025-08-27 16:36:29,861][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084216] [Batch 01056/03080] [00:12:51/00:24:38, 0.731s/it]: train_loss_raw=0.3618, running_loss=0.3459, LR=0.000100
[2025-08-27 16:36:35,485][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084224] [Batch 01064/03080] [00:12:57/00:24:32, 0.730s/it]: train_loss_raw=0.3204, running_loss=0.3463, LR=0.000100
[2025-08-27 16:36:41,321][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084232] [Batch 01072/03080] [00:13:03/00:24:26, 0.730s/it]: train_loss_raw=0.3309, running_loss=0.3458, LR=0.000100
[2025-08-27 16:36:47,347][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084240] [Batch 01080/03080] [00:13:09/00:24:21, 0.731s/it]: train_loss_raw=0.3604, running_loss=0.3469, LR=0.000100
[2025-08-27 16:36:53,294][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084248] [Batch 01088/03080] [00:13:14/00:24:15, 0.731s/it]: train_loss_raw=0.3710, running_loss=0.3461, LR=0.000100
[2025-08-27 16:36:58,801][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084256] [Batch 01096/03080] [00:13:20/00:24:09, 0.730s/it]: train_loss_raw=0.3076, running_loss=0.3453, LR=0.000100
[2025-08-27 16:37:04,939][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084264] [Batch 01104/03080] [00:13:26/00:24:03, 0.731s/it]: train_loss_raw=0.2927, running_loss=0.3439, LR=0.000100
[2025-08-27 16:37:10,333][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084272] [Batch 01112/03080] [00:13:32/00:23:57, 0.730s/it]: train_loss_raw=0.3131, running_loss=0.3443, LR=0.000100
[2025-08-27 16:37:15,992][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084280] [Batch 01120/03080] [00:13:37/00:23:50, 0.730s/it]: train_loss_raw=0.2852, running_loss=0.3411, LR=0.000100
[2025-08-27 16:37:21,938][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084288] [Batch 01128/03080] [00:13:43/00:23:45, 0.730s/it]: train_loss_raw=0.3185, running_loss=0.3405, LR=0.000100
[2025-08-27 16:37:27,316][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084296] [Batch 01136/03080] [00:13:48/00:23:38, 0.730s/it]: train_loss_raw=0.3193, running_loss=0.3383, LR=0.000100
[2025-08-27 16:37:32,790][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084304] [Batch 01144/03080] [00:13:54/00:23:32, 0.729s/it]: train_loss_raw=0.3213, running_loss=0.3395, LR=0.000100
[2025-08-27 16:37:38,857][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084312] [Batch 01152/03080] [00:14:00/00:23:26, 0.730s/it]: train_loss_raw=0.3537, running_loss=0.3376, LR=0.000100
[2025-08-27 16:37:44,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084320] [Batch 01160/03080] [00:14:06/00:23:20, 0.730s/it]: train_loss_raw=0.3756, running_loss=0.3375, LR=0.000100
[2025-08-27 16:37:50,423][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084328] [Batch 01168/03080] [00:14:12/00:23:14, 0.730s/it]: train_loss_raw=0.2742, running_loss=0.3389, LR=0.000100
[2025-08-27 16:37:56,014][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084336] [Batch 01176/03080] [00:14:17/00:23:08, 0.729s/it]: train_loss_raw=0.3358, running_loss=0.3398, LR=0.000100
[2025-08-27 16:38:01,950][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084344] [Batch 01184/03080] [00:14:23/00:23:02, 0.729s/it]: train_loss_raw=0.3218, running_loss=0.3407, LR=0.000100
[2025-08-27 16:38:07,867][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084352] [Batch 01192/03080] [00:14:29/00:22:57, 0.729s/it]: train_loss_raw=0.3295, running_loss=0.3415, LR=0.000100
[2025-08-27 16:38:13,637][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084360] [Batch 01200/03080] [00:14:35/00:22:51, 0.729s/it]: train_loss_raw=0.2782, running_loss=0.3394, LR=0.000100
[2025-08-27 16:38:19,624][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084368] [Batch 01208/03080] [00:14:41/00:22:45, 0.730s/it]: train_loss_raw=0.3743, running_loss=0.3402, LR=0.000100
[2025-08-27 16:38:25,348][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084376] [Batch 01216/03080] [00:14:47/00:22:39, 0.729s/it]: train_loss_raw=0.4194, running_loss=0.3407, LR=0.000100
[2025-08-27 16:38:31,446][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084384] [Batch 01224/03080] [00:14:53/00:22:34, 0.730s/it]: train_loss_raw=0.3332, running_loss=0.3393, LR=0.000100
[2025-08-27 16:38:37,505][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084392] [Batch 01232/03080] [00:14:59/00:22:28, 0.730s/it]: train_loss_raw=0.3386, running_loss=0.3400, LR=0.000100
[2025-08-27 16:38:43,200][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084400] [Batch 01240/03080] [00:15:04/00:22:22, 0.730s/it]: train_loss_raw=0.2858, running_loss=0.3413, LR=0.000100
[2025-08-27 16:38:48,629][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084408] [Batch 01248/03080] [00:15:10/00:22:16, 0.729s/it]: train_loss_raw=0.2852, running_loss=0.3394, LR=0.000100
[2025-08-27 16:38:54,345][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084416] [Batch 01256/03080] [00:15:16/00:22:10, 0.729s/it]: train_loss_raw=0.4365, running_loss=0.3405, LR=0.000100
[2025-08-27 16:38:59,907][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084424] [Batch 01264/03080] [00:15:21/00:22:04, 0.729s/it]: train_loss_raw=0.3022, running_loss=0.3401, LR=0.000100
[2025-08-27 16:39:05,288][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084432] [Batch 01272/03080] [00:15:26/00:21:57, 0.729s/it]: train_loss_raw=0.3553, running_loss=0.3400, LR=0.000100
[2025-08-27 16:39:11,038][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084440] [Batch 01280/03080] [00:15:32/00:21:51, 0.729s/it]: train_loss_raw=0.3890, running_loss=0.3406, LR=0.000100
[2025-08-27 16:39:16,709][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084448] [Batch 01288/03080] [00:15:38/00:21:45, 0.729s/it]: train_loss_raw=0.4184, running_loss=0.3415, LR=0.000100
[2025-08-27 16:39:22,142][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084456] [Batch 01296/03080] [00:15:43/00:21:39, 0.728s/it]: train_loss_raw=0.3682, running_loss=0.3438, LR=0.000100
[2025-08-27 16:39:27,729][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084464] [Batch 01304/03080] [00:15:49/00:21:33, 0.728s/it]: train_loss_raw=0.3216, running_loss=0.3428, LR=0.000100
[2025-08-27 16:39:33,429][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084472] [Batch 01312/03080] [00:15:55/00:21:27, 0.728s/it]: train_loss_raw=0.3699, running_loss=0.3441, LR=0.000100
[2025-08-27 16:39:39,272][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084480] [Batch 01320/03080] [00:16:00/00:21:21, 0.728s/it]: train_loss_raw=0.2710, running_loss=0.3441, LR=0.000100
[2025-08-27 16:39:44,762][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084488] [Batch 01328/03080] [00:16:06/00:21:15, 0.728s/it]: train_loss_raw=0.3301, running_loss=0.3434, LR=0.000100
[2025-08-27 16:39:50,372][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084496] [Batch 01336/03080] [00:16:12/00:21:08, 0.728s/it]: train_loss_raw=0.3396, running_loss=0.3415, LR=0.000100
[2025-08-27 16:39:56,319][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084504] [Batch 01344/03080] [00:16:17/00:21:03, 0.728s/it]: train_loss_raw=0.3364, running_loss=0.3389, LR=0.000100
[2025-08-27 16:40:02,469][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084512] [Batch 01352/03080] [00:16:24/00:20:57, 0.728s/it]: train_loss_raw=0.3673, running_loss=0.3404, LR=0.000100
[2025-08-27 16:40:08,680][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084520] [Batch 01360/03080] [00:16:30/00:20:52, 0.728s/it]: train_loss_raw=0.3699, running_loss=0.3415, LR=0.000100
[2025-08-27 16:40:14,765][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084528] [Batch 01368/03080] [00:16:36/00:20:47, 0.728s/it]: train_loss_raw=0.2749, running_loss=0.3413, LR=0.000100
[2025-08-27 16:40:20,795][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084536] [Batch 01376/03080] [00:16:42/00:20:41, 0.729s/it]: train_loss_raw=0.3818, running_loss=0.3421, LR=0.000100
[2025-08-27 16:40:26,898][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084544] [Batch 01384/03080] [00:16:48/00:20:35, 0.729s/it]: train_loss_raw=0.2930, running_loss=0.3414, LR=0.000100
[2025-08-27 16:40:32,850][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084552] [Batch 01392/03080] [00:16:54/00:20:30, 0.729s/it]: train_loss_raw=0.2751, running_loss=0.3394, LR=0.000100
[2025-08-27 16:40:38,911][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084560] [Batch 01400/03080] [00:17:00/00:20:24, 0.729s/it]: train_loss_raw=0.3195, running_loss=0.3398, LR=0.000100
[2025-08-27 16:40:44,695][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084568] [Batch 01408/03080] [00:17:06/00:20:18, 0.729s/it]: train_loss_raw=0.2674, running_loss=0.3416, LR=0.000100
[2025-08-27 16:40:50,484][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084576] [Batch 01416/03080] [00:17:12/00:20:12, 0.729s/it]: train_loss_raw=0.3910, running_loss=0.3417, LR=0.000100
[2025-08-27 16:40:56,276][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084584] [Batch 01424/03080] [00:17:17/00:20:07, 0.729s/it]: train_loss_raw=0.3481, running_loss=0.3425, LR=0.000100
[2025-08-27 16:41:02,404][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084592] [Batch 01432/03080] [00:17:24/00:20:01, 0.729s/it]: train_loss_raw=0.3709, running_loss=0.3445, LR=0.000100
[2025-08-27 16:41:08,157][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084600] [Batch 01440/03080] [00:17:29/00:19:55, 0.729s/it]: train_loss_raw=0.3613, running_loss=0.3451, LR=0.000100
[2025-08-27 16:41:14,241][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084608] [Batch 01448/03080] [00:17:35/00:19:50, 0.729s/it]: train_loss_raw=0.3742, running_loss=0.3439, LR=0.000100
[2025-08-27 16:41:20,472][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084616] [Batch 01456/03080] [00:17:42/00:19:44, 0.730s/it]: train_loss_raw=0.3631, running_loss=0.3439, LR=0.000100
[2025-08-27 16:41:26,680][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084624] [Batch 01464/03080] [00:17:48/00:19:39, 0.730s/it]: train_loss_raw=0.3247, running_loss=0.3455, LR=0.000100
[2025-08-27 16:41:32,553][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084632] [Batch 01472/03080] [00:17:54/00:19:33, 0.730s/it]: train_loss_raw=0.3067, running_loss=0.3460, LR=0.000100
[2025-08-27 16:41:38,614][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084640] [Batch 01480/03080] [00:18:00/00:19:27, 0.730s/it]: train_loss_raw=0.3688, running_loss=0.3464, LR=0.000100
[2025-08-27 16:41:44,290][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084648] [Batch 01488/03080] [00:18:05/00:19:21, 0.730s/it]: train_loss_raw=0.2691, running_loss=0.3472, LR=0.000100
[2025-08-27 16:41:50,122][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084656] [Batch 01496/03080] [00:18:11/00:19:16, 0.730s/it]: train_loss_raw=0.3373, running_loss=0.3472, LR=0.000100
[2025-08-27 16:41:55,876][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084664] [Batch 01504/03080] [00:18:17/00:19:10, 0.730s/it]: train_loss_raw=0.3784, running_loss=0.3473, LR=0.000100
[2025-08-27 16:42:01,769][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084672] [Batch 01512/03080] [00:18:23/00:19:04, 0.730s/it]: train_loss_raw=0.4326, running_loss=0.3478, LR=0.000100
[2025-08-27 16:42:07,625][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084680] [Batch 01520/03080] [00:18:29/00:18:58, 0.730s/it]: train_loss_raw=0.3368, running_loss=0.3482, LR=0.000100
[2025-08-27 16:42:13,456][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084688] [Batch 01528/03080] [00:18:35/00:18:52, 0.730s/it]: train_loss_raw=0.4394, running_loss=0.3483, LR=0.000100
[2025-08-27 16:42:19,656][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084696] [Batch 01536/03080] [00:18:41/00:18:47, 0.730s/it]: train_loss_raw=0.2916, running_loss=0.3459, LR=0.000100
[2025-08-27 16:42:25,818][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084704] [Batch 01544/03080] [00:18:47/00:18:41, 0.730s/it]: train_loss_raw=0.2735, running_loss=0.3453, LR=0.000100
[2025-08-27 16:42:32,000][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084712] [Batch 01552/03080] [00:18:53/00:18:36, 0.730s/it]: train_loss_raw=0.3205, running_loss=0.3451, LR=0.000100
[2025-08-27 16:42:37,995][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084720] [Batch 01560/03080] [00:18:59/00:18:30, 0.731s/it]: train_loss_raw=0.3936, running_loss=0.3477, LR=0.000100
[2025-08-27 16:42:44,055][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084728] [Batch 01568/03080] [00:19:05/00:18:24, 0.731s/it]: train_loss_raw=0.3322, running_loss=0.3476, LR=0.000100
[2025-08-27 16:42:50,092][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084736] [Batch 01576/03080] [00:19:11/00:18:19, 0.731s/it]: train_loss_raw=0.3023, running_loss=0.3453, LR=0.000100
[2025-08-27 16:42:56,012][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084744] [Batch 01584/03080] [00:19:17/00:18:13, 0.731s/it]: train_loss_raw=0.4474, running_loss=0.3454, LR=0.000100
[2025-08-27 16:43:01,736][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084752] [Batch 01592/03080] [00:19:23/00:18:07, 0.731s/it]: train_loss_raw=0.3194, running_loss=0.3447, LR=0.000100
[2025-08-27 16:43:07,926][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084760] [Batch 01600/03080] [00:19:29/00:18:01, 0.731s/it]: train_loss_raw=0.2859, running_loss=0.3460, LR=0.000100
[2025-08-27 16:43:13,775][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084768] [Batch 01608/03080] [00:19:35/00:17:56, 0.731s/it]: train_loss_raw=0.3914, running_loss=0.3443, LR=0.000100
[2025-08-27 16:43:19,696][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084776] [Batch 01616/03080] [00:19:41/00:17:50, 0.731s/it]: train_loss_raw=0.3109, running_loss=0.3456, LR=0.000100
[2025-08-27 16:43:25,479][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084784] [Batch 01624/03080] [00:19:47/00:17:44, 0.731s/it]: train_loss_raw=0.3170, running_loss=0.3455, LR=0.000100
[2025-08-27 16:43:31,468][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084792] [Batch 01632/03080] [00:19:53/00:17:38, 0.731s/it]: train_loss_raw=0.3680, running_loss=0.3444, LR=0.000100
[2025-08-27 16:43:37,534][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084800] [Batch 01640/03080] [00:19:59/00:17:32, 0.731s/it]: train_loss_raw=0.4080, running_loss=0.3453, LR=0.000100
[2025-08-27 16:43:43,267][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084808] [Batch 01648/03080] [00:20:04/00:17:27, 0.731s/it]: train_loss_raw=0.3967, running_loss=0.3454, LR=0.000100
[2025-08-27 16:43:49,408][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084816] [Batch 01656/03080] [00:20:11/00:17:21, 0.731s/it]: train_loss_raw=0.3544, running_loss=0.3447, LR=0.000100
[2025-08-27 16:43:55,130][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084824] [Batch 01664/03080] [00:20:16/00:17:15, 0.731s/it]: train_loss_raw=0.3541, running_loss=0.3457, LR=0.000100
[2025-08-27 16:44:01,227][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084832] [Batch 01672/03080] [00:20:22/00:17:09, 0.731s/it]: train_loss_raw=0.2711, running_loss=0.3452, LR=0.000100
[2025-08-27 16:44:06,793][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084840] [Batch 01680/03080] [00:20:28/00:17:03, 0.731s/it]: train_loss_raw=0.2666, running_loss=0.3454, LR=0.000100
[2025-08-27 16:44:12,429][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084848] [Batch 01688/03080] [00:20:34/00:16:57, 0.731s/it]: train_loss_raw=0.3666, running_loss=0.3461, LR=0.000100
[2025-08-27 16:44:18,478][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084856] [Batch 01696/03080] [00:20:40/00:16:52, 0.731s/it]: train_loss_raw=0.2988, running_loss=0.3464, LR=0.000100
[2025-08-27 16:44:24,186][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084864] [Batch 01704/03080] [00:20:45/00:16:46, 0.731s/it]: train_loss_raw=0.3335, running_loss=0.3461, LR=0.000100
[2025-08-27 16:44:29,874][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084872] [Batch 01712/03080] [00:20:51/00:16:40, 0.731s/it]: train_loss_raw=0.2498, running_loss=0.3464, LR=0.000100
[2025-08-27 16:44:35,448][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084880] [Batch 01720/03080] [00:20:57/00:16:34, 0.731s/it]: train_loss_raw=0.3916, running_loss=0.3450, LR=0.000100
[2025-08-27 16:44:40,934][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084888] [Batch 01728/03080] [00:21:02/00:16:27, 0.731s/it]: train_loss_raw=0.2943, running_loss=0.3447, LR=0.000100
[2025-08-27 16:44:46,340][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084896] [Batch 01736/03080] [00:21:08/00:16:21, 0.730s/it]: train_loss_raw=0.3542, running_loss=0.3456, LR=0.000100
[2025-08-27 16:44:51,971][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084904] [Batch 01744/03080] [00:21:13/00:16:15, 0.730s/it]: train_loss_raw=0.4120, running_loss=0.3465, LR=0.000100
[2025-08-27 16:44:57,711][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084912] [Batch 01752/03080] [00:21:19/00:16:09, 0.730s/it]: train_loss_raw=0.3206, running_loss=0.3454, LR=0.000100
[2025-08-27 16:45:03,441][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084920] [Batch 01760/03080] [00:21:25/00:16:03, 0.730s/it]: train_loss_raw=0.3461, running_loss=0.3452, LR=0.000100
[2025-08-27 16:45:09,205][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084928] [Batch 01768/03080] [00:21:30/00:15:57, 0.730s/it]: train_loss_raw=0.3158, running_loss=0.3444, LR=0.000100
[2025-08-27 16:45:15,208][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084936] [Batch 01776/03080] [00:21:36/00:15:52, 0.730s/it]: train_loss_raw=0.3433, running_loss=0.3419, LR=0.000100
[2025-08-27 16:45:21,092][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084944] [Batch 01784/03080] [00:21:42/00:15:46, 0.730s/it]: train_loss_raw=0.4274, running_loss=0.3429, LR=0.000100
[2025-08-27 16:45:26,837][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084952] [Batch 01792/03080] [00:21:48/00:15:40, 0.730s/it]: train_loss_raw=0.3338, running_loss=0.3429, LR=0.000100
[2025-08-27 16:45:32,567][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084960] [Batch 01800/03080] [00:21:54/00:15:34, 0.730s/it]: train_loss_raw=0.3771, running_loss=0.3428, LR=0.000100
[2025-08-27 16:45:38,761][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084968] [Batch 01808/03080] [00:22:00/00:15:28, 0.730s/it]: train_loss_raw=0.3141, running_loss=0.3443, LR=0.000100
[2025-08-27 16:45:44,512][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084976] [Batch 01816/03080] [00:22:06/00:15:23, 0.730s/it]: train_loss_raw=0.3976, running_loss=0.3442, LR=0.000100
[2025-08-27 16:45:50,265][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084984] [Batch 01824/03080] [00:22:11/00:15:17, 0.730s/it]: train_loss_raw=0.2968, running_loss=0.3437, LR=0.000100
[2025-08-27 16:45:55,920][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084992] [Batch 01832/03080] [00:22:17/00:15:11, 0.730s/it]: train_loss_raw=0.3467, running_loss=0.3441, LR=0.000100
[2025-08-27 16:46:01,690][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085000] [Batch 01840/03080] [00:22:23/00:15:05, 0.730s/it]: train_loss_raw=0.3343, running_loss=0.3439, LR=0.000100
[2025-08-27 16:46:07,591][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085008] [Batch 01848/03080] [00:22:29/00:14:59, 0.730s/it]: train_loss_raw=0.3513, running_loss=0.3435, LR=0.000100
[2025-08-27 16:46:13,331][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085016] [Batch 01856/03080] [00:22:35/00:14:53, 0.730s/it]: train_loss_raw=0.3166, running_loss=0.3433, LR=0.000100
[2025-08-27 16:46:19,258][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085024] [Batch 01864/03080] [00:22:40/00:14:47, 0.730s/it]: train_loss_raw=0.2796, running_loss=0.3417, LR=0.000100
[2025-08-27 16:46:25,135][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085032] [Batch 01872/03080] [00:22:46/00:14:42, 0.730s/it]: train_loss_raw=0.3143, running_loss=0.3430, LR=0.000100
[2025-08-27 16:46:30,974][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085040] [Batch 01880/03080] [00:22:52/00:14:36, 0.730s/it]: train_loss_raw=0.3373, running_loss=0.3424, LR=0.000100
[2025-08-27 16:46:36,788][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085048] [Batch 01888/03080] [00:22:58/00:14:30, 0.730s/it]: train_loss_raw=0.2813, running_loss=0.3426, LR=0.000100
[2025-08-27 16:46:42,695][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085056] [Batch 01896/03080] [00:23:04/00:14:24, 0.730s/it]: train_loss_raw=0.2884, running_loss=0.3406, LR=0.000100
[2025-08-27 16:46:48,462][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085064] [Batch 01904/03080] [00:23:10/00:14:18, 0.730s/it]: train_loss_raw=0.2969, running_loss=0.3429, LR=0.000100
[2025-08-27 16:46:53,938][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085072] [Batch 01912/03080] [00:23:15/00:14:12, 0.730s/it]: train_loss_raw=0.2964, running_loss=0.3417, LR=0.000100
[2025-08-27 16:46:59,366][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085080] [Batch 01920/03080] [00:23:21/00:14:06, 0.730s/it]: train_loss_raw=0.4076, running_loss=0.3410, LR=0.000100
[2025-08-27 16:47:04,805][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085088] [Batch 01928/03080] [00:23:26/00:14:00, 0.730s/it]: train_loss_raw=0.3369, running_loss=0.3410, LR=0.000100
[2025-08-27 16:47:10,508][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085096] [Batch 01936/03080] [00:23:32/00:13:54, 0.729s/it]: train_loss_raw=0.3655, running_loss=0.3397, LR=0.000100
[2025-08-27 16:47:16,519][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085104] [Batch 01944/03080] [00:23:38/00:13:48, 0.730s/it]: train_loss_raw=0.3641, running_loss=0.3410, LR=0.000100
[2025-08-27 16:47:22,322][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085112] [Batch 01952/03080] [00:23:44/00:13:42, 0.730s/it]: train_loss_raw=0.3377, running_loss=0.3405, LR=0.000100
[2025-08-27 16:47:28,191][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085120] [Batch 01960/03080] [00:23:49/00:13:37, 0.730s/it]: train_loss_raw=0.3547, running_loss=0.3416, LR=0.000100
[2025-08-27 16:47:33,873][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085128] [Batch 01968/03080] [00:23:55/00:13:31, 0.729s/it]: train_loss_raw=0.3994, running_loss=0.3419, LR=0.000100
[2025-08-27 16:47:39,491][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085136] [Batch 01976/03080] [00:24:01/00:13:25, 0.729s/it]: train_loss_raw=0.3362, running_loss=0.3412, LR=0.000100
[2025-08-27 16:47:45,441][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085144] [Batch 01984/03080] [00:24:07/00:13:19, 0.729s/it]: train_loss_raw=0.3698, running_loss=0.3410, LR=0.000100
[2025-08-27 16:47:51,251][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085152] [Batch 01992/03080] [00:24:12/00:13:13, 0.729s/it]: train_loss_raw=0.4760, running_loss=0.3421, LR=0.000100
[2025-08-27 16:47:56,917][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085160] [Batch 02000/03080] [00:24:18/00:13:07, 0.729s/it]: train_loss_raw=0.3178, running_loss=0.3420, LR=0.000100
[2025-08-27 16:48:02,444][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085168] [Batch 02008/03080] [00:24:24/00:13:01, 0.729s/it]: train_loss_raw=0.3932, running_loss=0.3443, LR=0.000100
[2025-08-27 16:48:08,110][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085176] [Batch 02016/03080] [00:24:29/00:12:55, 0.729s/it]: train_loss_raw=0.3650, running_loss=0.3456, LR=0.000100
[2025-08-27 16:48:13,889][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085184] [Batch 02024/03080] [00:24:35/00:12:49, 0.729s/it]: train_loss_raw=0.3449, running_loss=0.3476, LR=0.000100
[2025-08-27 16:48:19,736][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085192] [Batch 02032/03080] [00:24:41/00:12:44, 0.729s/it]: train_loss_raw=0.3167, running_loss=0.3491, LR=0.000100
[2025-08-27 16:48:25,681][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085200] [Batch 02040/03080] [00:24:47/00:12:38, 0.729s/it]: train_loss_raw=0.3054, running_loss=0.3475, LR=0.000100
[2025-08-27 16:48:31,070][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085208] [Batch 02048/03080] [00:24:52/00:12:32, 0.729s/it]: train_loss_raw=0.4009, running_loss=0.3472, LR=0.000100
[2025-08-27 16:48:36,512][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085216] [Batch 02056/03080] [00:24:58/00:12:26, 0.729s/it]: train_loss_raw=0.3712, running_loss=0.3469, LR=0.000100
[2025-08-27 16:48:42,371][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085224] [Batch 02064/03080] [00:25:04/00:12:20, 0.729s/it]: train_loss_raw=0.3702, running_loss=0.3464, LR=0.000100
[2025-08-27 16:48:48,234][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085232] [Batch 02072/03080] [00:25:09/00:12:14, 0.729s/it]: train_loss_raw=0.3929, running_loss=0.3460, LR=0.000100
[2025-08-27 16:48:53,941][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085240] [Batch 02080/03080] [00:25:15/00:12:08, 0.729s/it]: train_loss_raw=0.3492, running_loss=0.3463, LR=0.000100
[2025-08-27 16:48:59,732][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085248] [Batch 02088/03080] [00:25:21/00:12:02, 0.729s/it]: train_loss_raw=0.3012, running_loss=0.3454, LR=0.000100
[2025-08-27 16:49:05,648][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085256] [Batch 02096/03080] [00:25:27/00:11:57, 0.729s/it]: train_loss_raw=0.4040, running_loss=0.3456, LR=0.000100
[2025-08-27 16:49:11,468][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085264] [Batch 02104/03080] [00:25:33/00:11:51, 0.729s/it]: train_loss_raw=0.3820, running_loss=0.3445, LR=0.000100
[2025-08-27 16:49:17,239][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085272] [Batch 02112/03080] [00:25:38/00:11:45, 0.729s/it]: train_loss_raw=0.3094, running_loss=0.3436, LR=0.000100
[2025-08-27 16:49:23,286][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085280] [Batch 02120/03080] [00:25:44/00:11:39, 0.729s/it]: train_loss_raw=0.3428, running_loss=0.3434, LR=0.000100
[2025-08-27 16:49:29,022][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085288] [Batch 02128/03080] [00:25:50/00:11:33, 0.729s/it]: train_loss_raw=0.3637, running_loss=0.3446, LR=0.000100
[2025-08-27 16:49:34,912][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085296] [Batch 02136/03080] [00:25:56/00:11:27, 0.729s/it]: train_loss_raw=0.3200, running_loss=0.3452, LR=0.000100
[2025-08-27 16:49:40,699][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085304] [Batch 02144/03080] [00:26:02/00:11:22, 0.729s/it]: train_loss_raw=0.3599, running_loss=0.3454, LR=0.000100
[2025-08-27 16:49:46,402][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085312] [Batch 02152/03080] [00:26:08/00:11:16, 0.729s/it]: train_loss_raw=0.2880, running_loss=0.3443, LR=0.000100
[2025-08-27 16:49:52,387][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085320] [Batch 02160/03080] [00:26:14/00:11:10, 0.729s/it]: train_loss_raw=0.3196, running_loss=0.3436, LR=0.000100
[2025-08-27 16:49:58,355][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085328] [Batch 02168/03080] [00:26:20/00:11:04, 0.729s/it]: train_loss_raw=0.3459, running_loss=0.3446, LR=0.000100
[2025-08-27 16:50:04,065][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085336] [Batch 02176/03080] [00:26:25/00:10:58, 0.729s/it]: train_loss_raw=0.3670, running_loss=0.3443, LR=0.000100
[2025-08-27 16:50:10,080][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085344] [Batch 02184/03080] [00:26:31/00:10:53, 0.729s/it]: train_loss_raw=0.4487, running_loss=0.3446, LR=0.000100
[2025-08-27 16:50:15,870][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085352] [Batch 02192/03080] [00:26:37/00:10:47, 0.729s/it]: train_loss_raw=0.3343, running_loss=0.3448, LR=0.000100
[2025-08-27 16:50:21,821][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085360] [Batch 02200/03080] [00:26:43/00:10:41, 0.729s/it]: train_loss_raw=0.3846, running_loss=0.3443, LR=0.000100
[2025-08-27 16:50:27,518][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085368] [Batch 02208/03080] [00:26:49/00:10:35, 0.729s/it]: train_loss_raw=0.3519, running_loss=0.3442, LR=0.000100
[2025-08-27 16:50:33,597][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085376] [Batch 02216/03080] [00:26:55/00:10:29, 0.729s/it]: train_loss_raw=0.3421, running_loss=0.3427, LR=0.000100
[2025-08-27 16:50:39,509][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085384] [Batch 02224/03080] [00:27:01/00:10:23, 0.729s/it]: train_loss_raw=0.3739, running_loss=0.3432, LR=0.000100
[2025-08-27 16:50:45,094][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085392] [Batch 02232/03080] [00:27:06/00:10:18, 0.729s/it]: train_loss_raw=0.3255, running_loss=0.3437, LR=0.000100
[2025-08-27 16:50:51,056][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085400] [Batch 02240/03080] [00:27:12/00:10:12, 0.729s/it]: train_loss_raw=0.2878, running_loss=0.3440, LR=0.000100
[2025-08-27 16:50:56,860][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085408] [Batch 02248/03080] [00:27:18/00:10:06, 0.729s/it]: train_loss_raw=0.3649, running_loss=0.3456, LR=0.000100
[2025-08-27 16:51:02,911][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085416] [Batch 02256/03080] [00:27:24/00:10:00, 0.729s/it]: train_loss_raw=0.3076, running_loss=0.3439, LR=0.000100
[2025-08-27 16:51:08,924][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085424] [Batch 02264/03080] [00:27:30/00:09:54, 0.729s/it]: train_loss_raw=0.3837, running_loss=0.3424, LR=0.000100
[2025-08-27 16:51:14,564][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085432] [Batch 02272/03080] [00:27:36/00:09:49, 0.729s/it]: train_loss_raw=0.3682, running_loss=0.3427, LR=0.000100
[2025-08-27 16:51:20,150][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085440] [Batch 02280/03080] [00:27:41/00:09:43, 0.729s/it]: train_loss_raw=0.3788, running_loss=0.3433, LR=0.000100
[2025-08-27 16:51:26,044][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085448] [Batch 02288/03080] [00:27:47/00:09:37, 0.729s/it]: train_loss_raw=0.3281, running_loss=0.3419, LR=0.000100
[2025-08-27 16:51:31,583][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085456] [Batch 02296/03080] [00:27:53/00:09:31, 0.729s/it]: train_loss_raw=0.3790, running_loss=0.3435, LR=0.000100
[2025-08-27 16:51:37,556][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085464] [Batch 02304/03080] [00:27:59/00:09:25, 0.729s/it]: train_loss_raw=0.3577, running_loss=0.3444, LR=0.000100
[2025-08-27 16:51:43,141][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085472] [Batch 02312/03080] [00:28:04/00:09:19, 0.729s/it]: train_loss_raw=0.3766, running_loss=0.3444, LR=0.000100
[2025-08-27 16:51:49,028][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085480] [Batch 02320/03080] [00:28:10/00:09:13, 0.729s/it]: train_loss_raw=0.4089, running_loss=0.3473, LR=0.000100
[2025-08-27 16:51:54,840][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085488] [Batch 02328/03080] [00:28:16/00:09:08, 0.729s/it]: train_loss_raw=0.3361, running_loss=0.3450, LR=0.000100
[2025-08-27 16:52:00,455][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085496] [Batch 02336/03080] [00:28:22/00:09:02, 0.729s/it]: train_loss_raw=0.3263, running_loss=0.3439, LR=0.000100
[2025-08-27 16:52:06,426][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085504] [Batch 02344/03080] [00:28:28/00:08:56, 0.729s/it]: train_loss_raw=0.2887, running_loss=0.3430, LR=0.000100
[2025-08-27 16:52:12,322][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085512] [Batch 02352/03080] [00:28:34/00:08:50, 0.729s/it]: train_loss_raw=0.3794, running_loss=0.3439, LR=0.000100
[2025-08-27 16:52:18,246][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085520] [Batch 02360/03080] [00:28:39/00:08:44, 0.729s/it]: train_loss_raw=0.3523, running_loss=0.3437, LR=0.000100
[2025-08-27 16:52:24,111][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085528] [Batch 02368/03080] [00:28:45/00:08:38, 0.729s/it]: train_loss_raw=0.4172, running_loss=0.3432, LR=0.000100
[2025-08-27 16:52:29,861][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085536] [Batch 02376/03080] [00:28:51/00:08:33, 0.729s/it]: train_loss_raw=0.2535, running_loss=0.3423, LR=0.000100
[2025-08-27 16:52:35,612][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085544] [Batch 02384/03080] [00:28:57/00:08:27, 0.729s/it]: train_loss_raw=0.3485, running_loss=0.3438, LR=0.000100
[2025-08-27 16:52:41,294][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085552] [Batch 02392/03080] [00:29:02/00:08:21, 0.729s/it]: train_loss_raw=0.3154, running_loss=0.3438, LR=0.000100
[2025-08-27 16:52:47,285][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085560] [Batch 02400/03080] [00:29:08/00:08:15, 0.729s/it]: train_loss_raw=0.2357, running_loss=0.3407, LR=0.000100
[2025-08-27 16:52:52,951][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085568] [Batch 02408/03080] [00:29:14/00:08:09, 0.729s/it]: train_loss_raw=0.3250, running_loss=0.3397, LR=0.000100
[2025-08-27 16:52:58,614][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085576] [Batch 02416/03080] [00:29:20/00:08:03, 0.729s/it]: train_loss_raw=0.3704, running_loss=0.3405, LR=0.000100
[2025-08-27 16:53:04,341][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085584] [Batch 02424/03080] [00:29:26/00:07:57, 0.729s/it]: train_loss_raw=0.4528, running_loss=0.3438, LR=0.000100
[2025-08-27 16:53:10,097][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085592] [Batch 02432/03080] [00:29:31/00:07:52, 0.729s/it]: train_loss_raw=0.3596, running_loss=0.3419, LR=0.000100
[2025-08-27 16:53:15,806][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085600] [Batch 02440/03080] [00:29:37/00:07:46, 0.728s/it]: train_loss_raw=0.3728, running_loss=0.3427, LR=0.000100
[2025-08-27 16:53:21,654][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085608] [Batch 02448/03080] [00:29:43/00:07:40, 0.728s/it]: train_loss_raw=0.2694, running_loss=0.3424, LR=0.000100
[2025-08-27 16:53:27,347][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085616] [Batch 02456/03080] [00:29:49/00:07:34, 0.728s/it]: train_loss_raw=0.3887, running_loss=0.3431, LR=0.000100
[2025-08-27 16:53:33,150][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085624] [Batch 02464/03080] [00:29:54/00:07:28, 0.728s/it]: train_loss_raw=0.3297, running_loss=0.3414, LR=0.000100
[2025-08-27 16:53:38,978][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085632] [Batch 02472/03080] [00:30:00/00:07:22, 0.728s/it]: train_loss_raw=0.3367, running_loss=0.3425, LR=0.000100
[2025-08-27 16:53:44,691][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085640] [Batch 02480/03080] [00:30:06/00:07:17, 0.728s/it]: train_loss_raw=0.4130, running_loss=0.3419, LR=0.000100
[2025-08-27 16:53:50,372][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085648] [Batch 02488/03080] [00:30:12/00:07:11, 0.728s/it]: train_loss_raw=0.3130, running_loss=0.3434, LR=0.000100
[2025-08-27 16:53:55,803][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085656] [Batch 02496/03080] [00:30:17/00:07:05, 0.728s/it]: train_loss_raw=0.4205, running_loss=0.3461, LR=0.000100
[2025-08-27 16:54:01,689][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085664] [Batch 02504/03080] [00:30:23/00:06:59, 0.728s/it]: train_loss_raw=0.3058, running_loss=0.3455, LR=0.000100
[2025-08-27 16:54:07,532][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085672] [Batch 02512/03080] [00:30:29/00:06:53, 0.728s/it]: train_loss_raw=0.3237, running_loss=0.3446, LR=0.000100
[2025-08-27 16:54:13,239][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085680] [Batch 02520/03080] [00:30:34/00:06:47, 0.728s/it]: train_loss_raw=0.3704, running_loss=0.3463, LR=0.000100
[2025-08-27 16:54:19,134][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085688] [Batch 02528/03080] [00:30:40/00:06:41, 0.728s/it]: train_loss_raw=0.3227, running_loss=0.3465, LR=0.000100
[2025-08-27 16:54:24,848][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085696] [Batch 02536/03080] [00:30:46/00:06:36, 0.728s/it]: train_loss_raw=0.4227, running_loss=0.3474, LR=0.000100
[2025-08-27 16:54:30,364][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085704] [Batch 02544/03080] [00:30:52/00:06:30, 0.728s/it]: train_loss_raw=0.3556, running_loss=0.3478, LR=0.000100
[2025-08-27 16:54:36,098][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085712] [Batch 02552/03080] [00:30:57/00:06:24, 0.728s/it]: train_loss_raw=0.2719, running_loss=0.3462, LR=0.000100
[2025-08-27 16:54:42,093][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085720] [Batch 02560/03080] [00:31:03/00:06:18, 0.728s/it]: train_loss_raw=0.3405, running_loss=0.3452, LR=0.000100
[2025-08-27 16:54:48,034][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085728] [Batch 02568/03080] [00:31:09/00:06:12, 0.728s/it]: train_loss_raw=0.3448, running_loss=0.3439, LR=0.000100
[2025-08-27 16:54:53,464][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085736] [Batch 02576/03080] [00:31:15/00:06:06, 0.728s/it]: train_loss_raw=0.3756, running_loss=0.3438, LR=0.000100
[2025-08-27 16:54:58,908][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085744] [Batch 02584/03080] [00:31:20/00:06:00, 0.728s/it]: train_loss_raw=0.3798, running_loss=0.3449, LR=0.000100
[2025-08-27 16:55:04,681][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085752] [Batch 02592/03080] [00:31:26/00:05:55, 0.728s/it]: train_loss_raw=0.3557, running_loss=0.3437, LR=0.000100
[2025-08-27 16:55:10,463][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085760] [Batch 02600/03080] [00:31:32/00:05:49, 0.728s/it]: train_loss_raw=0.3700, running_loss=0.3451, LR=0.000100
[2025-08-27 16:55:15,898][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085768] [Batch 02608/03080] [00:31:37/00:05:43, 0.728s/it]: train_loss_raw=0.2991, running_loss=0.3442, LR=0.000100
[2025-08-27 16:55:21,290][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085776] [Batch 02616/03080] [00:31:42/00:05:37, 0.727s/it]: train_loss_raw=0.3867, running_loss=0.3442, LR=0.000100
[2025-08-27 16:55:27,029][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085784] [Batch 02624/03080] [00:31:48/00:05:31, 0.727s/it]: train_loss_raw=0.3632, running_loss=0.3442, LR=0.000100
[2025-08-27 16:55:32,699][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085792] [Batch 02632/03080] [00:31:54/00:05:25, 0.727s/it]: train_loss_raw=0.3199, running_loss=0.3449, LR=0.000100
[2025-08-27 16:55:38,382][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085800] [Batch 02640/03080] [00:32:00/00:05:20, 0.727s/it]: train_loss_raw=0.2861, running_loss=0.3446, LR=0.000100
[2025-08-27 16:55:44,089][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085808] [Batch 02648/03080] [00:32:05/00:05:14, 0.727s/it]: train_loss_raw=0.3024, running_loss=0.3444, LR=0.000100
[2025-08-27 16:55:49,965][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085816] [Batch 02656/03080] [00:32:11/00:05:08, 0.727s/it]: train_loss_raw=0.3758, running_loss=0.3435, LR=0.000100
[2025-08-27 16:55:55,689][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085824] [Batch 02664/03080] [00:32:17/00:05:02, 0.727s/it]: train_loss_raw=0.3108, running_loss=0.3420, LR=0.000100
[2025-08-27 16:56:01,580][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085832] [Batch 02672/03080] [00:32:23/00:04:56, 0.727s/it]: train_loss_raw=0.4423, running_loss=0.3407, LR=0.000100
[2025-08-27 16:56:07,300][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085840] [Batch 02680/03080] [00:32:28/00:04:50, 0.727s/it]: train_loss_raw=0.2387, running_loss=0.3394, LR=0.000100
[2025-08-27 16:56:13,023][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085848] [Batch 02688/03080] [00:32:34/00:04:45, 0.727s/it]: train_loss_raw=0.3094, running_loss=0.3390, LR=0.000100
[2025-08-27 16:56:18,726][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085856] [Batch 02696/03080] [00:32:40/00:04:39, 0.727s/it]: train_loss_raw=0.3887, running_loss=0.3436, LR=0.000100
[2025-08-27 16:56:24,376][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085864] [Batch 02704/03080] [00:32:46/00:04:33, 0.727s/it]: train_loss_raw=0.4475, running_loss=0.3448, LR=0.000100
[2025-08-27 16:56:30,253][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085872] [Batch 02712/03080] [00:32:51/00:04:27, 0.727s/it]: train_loss_raw=0.3784, running_loss=0.3438, LR=0.000100
[2025-08-27 16:56:35,848][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085880] [Batch 02720/03080] [00:32:57/00:04:21, 0.727s/it]: train_loss_raw=0.3686, running_loss=0.3436, LR=0.000100
[2025-08-27 16:56:41,357][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085888] [Batch 02728/03080] [00:33:03/00:04:15, 0.727s/it]: train_loss_raw=0.3484, running_loss=0.3430, LR=0.000100
[2025-08-27 16:56:47,123][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085896] [Batch 02736/03080] [00:33:08/00:04:10, 0.727s/it]: train_loss_raw=0.4029, running_loss=0.3443, LR=0.000100
[2025-08-27 16:56:52,940][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085904] [Batch 02744/03080] [00:33:14/00:04:04, 0.727s/it]: train_loss_raw=0.4119, running_loss=0.3434, LR=0.000100
[2025-08-27 16:56:59,008][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085912] [Batch 02752/03080] [00:33:20/00:03:58, 0.727s/it]: train_loss_raw=0.3054, running_loss=0.3425, LR=0.000100
[2025-08-27 16:57:04,857][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085920] [Batch 02760/03080] [00:33:26/00:03:52, 0.727s/it]: train_loss_raw=0.3282, running_loss=0.3427, LR=0.000100
[2025-08-27 16:57:10,610][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085928] [Batch 02768/03080] [00:33:32/00:03:46, 0.727s/it]: train_loss_raw=0.3919, running_loss=0.3432, LR=0.000100
[2025-08-27 16:57:16,500][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085936] [Batch 02776/03080] [00:33:38/00:03:41, 0.727s/it]: train_loss_raw=0.3875, running_loss=0.3438, LR=0.000100
[2025-08-27 16:57:22,244][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085944] [Batch 02784/03080] [00:33:43/00:03:35, 0.727s/it]: train_loss_raw=0.2624, running_loss=0.3437, LR=0.000100
[2025-08-27 16:57:28,107][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085952] [Batch 02792/03080] [00:33:49/00:03:29, 0.727s/it]: train_loss_raw=0.3719, running_loss=0.3436, LR=0.000100
[2025-08-27 16:57:34,026][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085960] [Batch 02800/03080] [00:33:55/00:03:23, 0.727s/it]: train_loss_raw=0.3432, running_loss=0.3430, LR=0.000100
[2025-08-27 16:57:39,765][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085968] [Batch 02808/03080] [00:34:01/00:03:17, 0.727s/it]: train_loss_raw=0.4017, running_loss=0.3439, LR=0.000100
[2025-08-27 16:57:45,604][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085976] [Batch 02816/03080] [00:34:07/00:03:11, 0.727s/it]: train_loss_raw=0.3398, running_loss=0.3443, LR=0.000100
[2025-08-27 16:57:51,433][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085984] [Batch 02824/03080] [00:34:13/00:03:06, 0.727s/it]: train_loss_raw=0.3982, running_loss=0.3430, LR=0.000100
[2025-08-27 16:57:57,134][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085992] [Batch 02832/03080] [00:34:18/00:03:00, 0.727s/it]: train_loss_raw=0.3083, running_loss=0.3428, LR=0.000100
[2025-08-27 16:58:03,029][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086000] [Batch 02840/03080] [00:34:24/00:02:54, 0.727s/it]: train_loss_raw=0.3266, running_loss=0.3434, LR=0.000100
[2025-08-27 16:58:12,609][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086008] [Batch 02848/03080] [00:34:34/00:02:48, 0.728s/it]: train_loss_raw=0.3477, running_loss=0.3420, LR=0.000100
[2025-08-27 16:58:18,290][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086016] [Batch 02856/03080] [00:34:39/00:02:43, 0.728s/it]: train_loss_raw=0.2987, running_loss=0.3414, LR=0.000100
[2025-08-27 16:58:24,069][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086024] [Batch 02864/03080] [00:34:45/00:02:37, 0.728s/it]: train_loss_raw=0.3432, running_loss=0.3413, LR=0.000100
[2025-08-27 16:58:29,689][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086032] [Batch 02872/03080] [00:34:51/00:02:31, 0.728s/it]: train_loss_raw=0.3727, running_loss=0.3409, LR=0.000100
[2025-08-27 16:58:35,269][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086040] [Batch 02880/03080] [00:34:56/00:02:25, 0.728s/it]: train_loss_raw=0.4290, running_loss=0.3417, LR=0.000100
[2025-08-27 16:58:41,130][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086048] [Batch 02888/03080] [00:35:02/00:02:19, 0.728s/it]: train_loss_raw=0.3389, running_loss=0.3421, LR=0.000100
[2025-08-27 16:58:46,942][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086056] [Batch 02896/03080] [00:35:08/00:02:13, 0.728s/it]: train_loss_raw=0.2568, running_loss=0.3404, LR=0.000100
[2025-08-27 16:58:53,019][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086064] [Batch 02904/03080] [00:35:14/00:02:08, 0.728s/it]: train_loss_raw=0.3372, running_loss=0.3395, LR=0.000100
[2025-08-27 16:58:58,794][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086072] [Batch 02912/03080] [00:35:20/00:02:02, 0.728s/it]: train_loss_raw=0.2567, running_loss=0.3379, LR=0.000100
[2025-08-27 16:59:04,257][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086080] [Batch 02920/03080] [00:35:25/00:01:56, 0.728s/it]: train_loss_raw=0.3318, running_loss=0.3382, LR=0.000100
[2025-08-27 16:59:10,107][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086088] [Batch 02928/03080] [00:35:31/00:01:50, 0.728s/it]: train_loss_raw=0.3262, running_loss=0.3386, LR=0.000100
[2025-08-27 16:59:16,029][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086096] [Batch 02936/03080] [00:35:37/00:01:44, 0.728s/it]: train_loss_raw=0.4082, running_loss=0.3386, LR=0.000100
[2025-08-27 16:59:21,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086104] [Batch 02944/03080] [00:35:43/00:01:39, 0.728s/it]: train_loss_raw=0.3028, running_loss=0.3385, LR=0.000100
[2025-08-27 16:59:27,108][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086112] [Batch 02952/03080] [00:35:48/00:01:33, 0.728s/it]: train_loss_raw=0.2474, running_loss=0.3380, LR=0.000100
[2025-08-27 16:59:32,875][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086120] [Batch 02960/03080] [00:35:54/00:01:27, 0.728s/it]: train_loss_raw=0.3717, running_loss=0.3381, LR=0.000100
[2025-08-27 16:59:38,902][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086128] [Batch 02968/03080] [00:36:00/00:01:21, 0.728s/it]: train_loss_raw=0.2846, running_loss=0.3389, LR=0.000100
[2025-08-27 16:59:44,684][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086136] [Batch 02976/03080] [00:36:06/00:01:15, 0.728s/it]: train_loss_raw=0.3569, running_loss=0.3384, LR=0.000100
[2025-08-27 16:59:50,595][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086144] [Batch 02984/03080] [00:36:12/00:01:09, 0.728s/it]: train_loss_raw=0.2851, running_loss=0.3407, LR=0.000100
[2025-08-27 16:59:56,450][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086152] [Batch 02992/03080] [00:36:18/00:01:04, 0.728s/it]: train_loss_raw=0.3843, running_loss=0.3404, LR=0.000100
[2025-08-27 17:00:02,306][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086160] [Batch 03000/03080] [00:36:23/00:00:58, 0.728s/it]: train_loss_raw=0.3386, running_loss=0.3394, LR=0.000100
[2025-08-27 17:00:08,348][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086168] [Batch 03008/03080] [00:36:30/00:00:52, 0.728s/it]: train_loss_raw=0.3099, running_loss=0.3407, LR=0.000100
[2025-08-27 17:00:14,083][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086176] [Batch 03016/03080] [00:36:35/00:00:46, 0.728s/it]: train_loss_raw=0.3195, running_loss=0.3410, LR=0.000100
[2025-08-27 17:00:19,949][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086184] [Batch 03024/03080] [00:36:41/00:00:40, 0.728s/it]: train_loss_raw=0.3897, running_loss=0.3434, LR=0.000100
[2025-08-27 17:00:25,657][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086192] [Batch 03032/03080] [00:36:47/00:00:34, 0.728s/it]: train_loss_raw=0.3134, running_loss=0.3424, LR=0.000100
[2025-08-27 17:00:31,725][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086200] [Batch 03040/03080] [00:36:53/00:00:29, 0.728s/it]: train_loss_raw=0.4126, running_loss=0.3417, LR=0.000100
[2025-08-27 17:00:37,889][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086208] [Batch 03048/03080] [00:36:59/00:00:23, 0.728s/it]: train_loss_raw=0.3645, running_loss=0.3412, LR=0.000100
[2025-08-27 17:00:43,645][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086216] [Batch 03056/03080] [00:37:05/00:00:17, 0.728s/it]: train_loss_raw=0.3528, running_loss=0.3404, LR=0.000100
[2025-08-27 17:00:49,171][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086224] [Batch 03064/03080] [00:37:10/00:00:11, 0.728s/it]: train_loss_raw=0.3087, running_loss=0.3414, LR=0.000100
[2025-08-27 17:00:55,232][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086232] [Batch 03072/03080] [00:37:16/00:00:05, 0.728s/it]: train_loss_raw=0.3238, running_loss=0.3425, LR=0.000100
[2025-08-27 17:01:05,405][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086240] [Batch 03080/03080] [00:37:27/00:00:00, 0.730s/it]: train_loss_raw=0.2842, running_loss=0.3432, LR=0.000100
[2025-08-27 17:01:05,928][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-27 17:01:16,720][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00007/00310] [00:00:10/00:06:47, 1.349s/it]
[2025-08-27 17:01:28,265][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00015/00310] [00:00:22/00:06:50, 1.396s/it]
[2025-08-27 17:01:40,429][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00023/00310] [00:00:34/00:06:51, 1.438s/it]
[2025-08-27 17:01:51,499][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00031/00310] [00:00:45/00:06:35, 1.424s/it]
[2025-08-27 17:02:03,574][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00039/00310] [00:00:57/00:06:29, 1.441s/it]
[2025-08-27 17:02:15,629][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00047/00310] [00:01:09/00:06:20, 1.452s/it]
[2025-08-27 17:02:27,282][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00055/00310] [00:01:21/00:06:09, 1.453s/it]
[2025-08-27 17:02:38,937][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00063/00310] [00:01:33/00:05:57, 1.453s/it]
[2025-08-27 17:02:50,041][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00071/00310] [00:01:44/00:05:44, 1.446s/it]
[2025-08-27 17:03:01,302][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00079/00310] [00:01:55/00:05:31, 1.442s/it]
[2025-08-27 17:03:13,761][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00087/00310] [00:02:07/00:05:22, 1.453s/it]
[2025-08-27 17:03:26,179][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00095/00310] [00:02:20/00:05:12, 1.461s/it]
[2025-08-27 17:03:37,669][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00103/00310] [00:02:31/00:05:00, 1.459s/it]
[2025-08-27 17:03:49,368][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00111/00310] [00:02:43/00:04:48, 1.459s/it]
[2025-08-27 17:04:00,595][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00119/00310] [00:02:54/00:04:36, 1.456s/it]
[2025-08-27 17:04:12,514][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00127/00310] [00:03:06/00:04:25, 1.458s/it]
[2025-08-27 17:04:24,502][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00135/00310] [00:03:18/00:04:14, 1.460s/it]
[2025-08-27 17:04:36,769][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00143/00310] [00:03:30/00:04:03, 1.464s/it]
[2025-08-27 17:04:48,144][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00151/00310] [00:03:42/00:03:50, 1.462s/it]
[2025-08-27 17:04:58,091][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00159/00310] [00:03:52/00:03:37, 1.451s/it]
[2025-08-27 17:05:10,055][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00167/00310] [00:04:04/00:03:26, 1.453s/it]
[2025-08-27 17:05:19,507][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00175/00310] [00:04:13/00:03:13, 1.441s/it]
[2025-08-27 17:05:29,539][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00183/00310] [00:04:23/00:03:00, 1.433s/it]
[2025-08-27 17:05:41,713][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00191/00310] [00:04:35/00:02:49, 1.436s/it]
[2025-08-27 17:05:52,710][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00199/00310] [00:04:46/00:02:37, 1.434s/it]
[2025-08-27 17:06:03,305][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00207/00310] [00:04:57/00:02:25, 1.430s/it]
[2025-08-27 17:06:14,132][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00215/00310] [00:05:08/00:02:14, 1.427s/it]
[2025-08-27 17:06:24,676][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00223/00310] [00:05:18/00:02:02, 1.423s/it]
[2025-08-27 17:06:36,171][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00231/00310] [00:05:30/00:01:51, 1.423s/it]
[2025-08-27 17:06:47,982][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00239/00310] [00:05:42/00:01:39, 1.425s/it]
[2025-08-27 17:06:59,894][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00247/00310] [00:05:53/00:01:28, 1.427s/it]
[2025-08-27 17:07:11,572][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00255/00310] [00:06:05/00:01:17, 1.428s/it]
[2025-08-27 17:07:23,935][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00263/00310] [00:06:18/00:01:05, 1.432s/it]
[2025-08-27 17:07:35,678][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00271/00310] [00:06:29/00:00:54, 1.433s/it]
[2025-08-27 17:07:46,943][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00279/00310] [00:06:41/00:00:42, 1.432s/it]
[2025-08-27 17:07:58,912][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00287/00310] [00:06:52/00:00:31, 1.434s/it]
[2025-08-27 17:08:09,523][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00295/00310] [00:07:03/00:00:20, 1.431s/it]
[2025-08-27 17:08:21,153][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00303/00310] [00:07:15/00:00:08, 1.432s/it]
[2025-08-27 17:08:30,086][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.34317, valid_loss=1.41650
[2025-08-27 17:08:30,086][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-27 17:08:30,086][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.474
[2025-08-27 17:08:30,087][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.159
[2025-08-27 17:08:30,087][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.163
[2025-08-27 17:08:30,087][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.089
[2025-08-27 17:08:30,096][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 21:41:43, remaining time 01:32:58, 00:46:29 per epoch
[2025-08-27 17:08:38,364][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086248] [Batch 00008/03080] [00:00:07/00:50:40, 0.990s/it]: train_loss_raw=0.3221, running_loss=0.2880, LR=0.000100
[2025-08-27 17:08:44,187][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086256] [Batch 00016/03080] [00:00:13/00:43:51, 0.859s/it]: train_loss_raw=0.3919, running_loss=0.2928, LR=0.000100
[2025-08-27 17:08:50,003][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086264] [Batch 00024/03080] [00:00:19/00:41:30, 0.815s/it]: train_loss_raw=0.3379, running_loss=0.2937, LR=0.000100
[2025-08-27 17:08:55,829][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086272] [Batch 00032/03080] [00:00:25/00:40:17, 0.793s/it]: train_loss_raw=0.3118, running_loss=0.2966, LR=0.000100
[2025-08-27 17:09:01,626][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086280] [Batch 00040/03080] [00:00:31/00:39:29, 0.780s/it]: train_loss_raw=0.3570, running_loss=0.3004, LR=0.000100
[2025-08-27 17:09:07,750][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086288] [Batch 00048/03080] [00:00:37/00:39:16, 0.777s/it]: train_loss_raw=0.2516, running_loss=0.3030, LR=0.000100
[2025-08-27 17:09:13,975][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086296] [Batch 00056/03080] [00:00:43/00:39:10, 0.777s/it]: train_loss_raw=0.3354, running_loss=0.3031, LR=0.000100
[2025-08-27 17:09:19,886][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086304] [Batch 00064/03080] [00:00:49/00:38:49, 0.773s/it]: train_loss_raw=0.2704, running_loss=0.3036, LR=0.000100
[2025-08-27 17:09:25,378][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086312] [Batch 00072/03080] [00:00:54/00:38:14, 0.763s/it]: train_loss_raw=0.3125, running_loss=0.3041, LR=0.000100
[2025-08-27 17:09:31,317][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086320] [Batch 00080/03080] [00:01:00/00:38:02, 0.761s/it]: train_loss_raw=0.3110, running_loss=0.3042, LR=0.000100
[2025-08-27 17:09:36,851][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086328] [Batch 00088/03080] [00:01:06/00:37:37, 0.755s/it]: train_loss_raw=0.3099, running_loss=0.3051, LR=0.000100
[2025-08-27 17:09:42,341][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086336] [Batch 00096/03080] [00:01:11/00:37:14, 0.749s/it]: train_loss_raw=0.4039, running_loss=0.3063, LR=0.000100
[2025-08-27 17:09:48,013][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086344] [Batch 00104/03080] [00:01:17/00:36:59, 0.746s/it]: train_loss_raw=0.2501, running_loss=0.3063, LR=0.000100
[2025-08-27 17:09:53,404][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086352] [Batch 00112/03080] [00:01:22/00:36:38, 0.741s/it]: train_loss_raw=0.3401, running_loss=0.3073, LR=0.000100
[2025-08-27 17:09:59,380][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086360] [Batch 00120/03080] [00:01:28/00:36:33, 0.741s/it]: train_loss_raw=0.3001, running_loss=0.3093, LR=0.000100
[2025-08-27 17:10:04,940][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086368] [Batch 00128/03080] [00:01:34/00:36:19, 0.738s/it]: train_loss_raw=0.2794, running_loss=0.3100, LR=0.000100
[2025-08-27 17:10:10,678][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086376] [Batch 00136/03080] [00:01:40/00:36:09, 0.737s/it]: train_loss_raw=0.2735, running_loss=0.3098, LR=0.000100
[2025-08-27 17:10:16,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086384] [Batch 00144/03080] [00:01:46/00:36:02, 0.737s/it]: train_loss_raw=0.3482, running_loss=0.3089, LR=0.000100
[2025-08-27 17:10:22,363][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086392] [Batch 00152/03080] [00:01:51/00:35:55, 0.736s/it]: train_loss_raw=0.3957, running_loss=0.3102, LR=0.000100
[2025-08-27 17:10:28,391][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086400] [Batch 00160/03080] [00:01:57/00:35:52, 0.737s/it]: train_loss_raw=0.3195, running_loss=0.3130, LR=0.000100
[2025-08-27 17:10:34,372][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086408] [Batch 00168/03080] [00:02:03/00:35:48, 0.738s/it]: train_loss_raw=0.2081, running_loss=0.3106, LR=0.000100
[2025-08-27 17:10:40,208][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086416] [Batch 00176/03080] [00:02:09/00:35:41, 0.737s/it]: train_loss_raw=0.3104, running_loss=0.3119, LR=0.000100
[2025-08-27 17:10:45,980][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086424] [Batch 00184/03080] [00:02:15/00:35:33, 0.737s/it]: train_loss_raw=0.3043, running_loss=0.3135, LR=0.000100
[2025-08-27 17:10:52,029][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086432] [Batch 00192/03080] [00:02:21/00:35:29, 0.737s/it]: train_loss_raw=0.3350, running_loss=0.3135, LR=0.000100
[2025-08-27 17:10:58,133][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086440] [Batch 00200/03080] [00:02:27/00:35:26, 0.738s/it]: train_loss_raw=0.3357, running_loss=0.3141, LR=0.000100
[2025-08-27 17:11:03,984][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086448] [Batch 00208/03080] [00:02:33/00:35:20, 0.738s/it]: train_loss_raw=0.3521, running_loss=0.3152, LR=0.000100
[2025-08-27 17:11:09,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086456] [Batch 00216/03080] [00:02:39/00:35:11, 0.737s/it]: train_loss_raw=0.2925, running_loss=0.3171, LR=0.000100
[2025-08-27 17:11:15,712][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086464] [Batch 00224/03080] [00:02:45/00:35:07, 0.738s/it]: train_loss_raw=0.2615, running_loss=0.3168, LR=0.000100
[2025-08-27 17:11:21,757][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086472] [Batch 00232/03080] [00:02:51/00:35:02, 0.738s/it]: train_loss_raw=0.3800, running_loss=0.3201, LR=0.000100
[2025-08-27 17:11:27,808][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086480] [Batch 00240/03080] [00:02:57/00:34:58, 0.739s/it]: train_loss_raw=0.2511, running_loss=0.3188, LR=0.000100
[2025-08-27 17:11:33,721][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086488] [Batch 00248/03080] [00:03:03/00:34:52, 0.739s/it]: train_loss_raw=0.2748, running_loss=0.3177, LR=0.000100
[2025-08-27 17:11:39,175][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086496] [Batch 00256/03080] [00:03:08/00:34:41, 0.737s/it]: train_loss_raw=0.2645, running_loss=0.3169, LR=0.000100
[2025-08-27 17:11:44,644][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086504] [Batch 00264/03080] [00:03:14/00:34:31, 0.736s/it]: train_loss_raw=0.3237, running_loss=0.3175, LR=0.000100
[2025-08-27 17:11:50,232][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086512] [Batch 00272/03080] [00:03:19/00:34:22, 0.735s/it]: train_loss_raw=0.2864, running_loss=0.3167, LR=0.000100
[2025-08-27 17:11:56,159][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086520] [Batch 00280/03080] [00:03:25/00:34:17, 0.735s/it]: train_loss_raw=0.3197, running_loss=0.3154, LR=0.000100
[2025-08-27 17:12:02,178][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086528] [Batch 00288/03080] [00:03:31/00:34:12, 0.735s/it]: train_loss_raw=0.3177, running_loss=0.3158, LR=0.000100
[2025-08-27 17:12:07,779][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086536] [Batch 00296/03080] [00:03:37/00:34:04, 0.734s/it]: train_loss_raw=0.2217, running_loss=0.3150, LR=0.000100
[2025-08-27 17:12:13,964][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086544] [Batch 00304/03080] [00:03:43/00:34:01, 0.735s/it]: train_loss_raw=0.2778, running_loss=0.3141, LR=0.000100
[2025-08-27 17:12:20,105][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086552] [Batch 00312/03080] [00:03:49/00:33:57, 0.736s/it]: train_loss_raw=0.4002, running_loss=0.3132, LR=0.000100
[2025-08-27 17:12:25,954][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086560] [Batch 00320/03080] [00:03:55/00:33:51, 0.736s/it]: train_loss_raw=0.3568, running_loss=0.3127, LR=0.000100
[2025-08-27 17:12:31,922][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086568] [Batch 00328/03080] [00:04:01/00:33:46, 0.736s/it]: train_loss_raw=0.3149, running_loss=0.3131, LR=0.000100
[2025-08-27 17:12:37,654][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086576] [Batch 00336/03080] [00:04:07/00:33:38, 0.736s/it]: train_loss_raw=0.3349, running_loss=0.3140, LR=0.000100
[2025-08-27 17:12:43,179][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086584] [Batch 00344/03080] [00:04:12/00:33:30, 0.735s/it]: train_loss_raw=0.3807, running_loss=0.3139, LR=0.000100
[2025-08-27 17:12:48,581][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086592] [Batch 00352/03080] [00:04:18/00:33:20, 0.733s/it]: train_loss_raw=0.3839, running_loss=0.3144, LR=0.000100
[2025-08-27 17:12:54,304][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086600] [Batch 00360/03080] [00:04:23/00:33:13, 0.733s/it]: train_loss_raw=0.3174, running_loss=0.3174, LR=0.000100
[2025-08-27 17:13:00,174][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086608] [Batch 00368/03080] [00:04:29/00:33:07, 0.733s/it]: train_loss_raw=0.3492, running_loss=0.3185, LR=0.000100
[2025-08-27 17:13:05,940][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086616] [Batch 00376/03080] [00:04:35/00:33:01, 0.733s/it]: train_loss_raw=0.2888, running_loss=0.3185, LR=0.000100
[2025-08-27 17:13:11,707][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086624] [Batch 00384/03080] [00:04:41/00:32:54, 0.732s/it]: train_loss_raw=0.3432, running_loss=0.3192, LR=0.000100
[2025-08-27 17:13:17,394][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086632] [Batch 00392/03080] [00:04:46/00:32:47, 0.732s/it]: train_loss_raw=0.3446, running_loss=0.3197, LR=0.000100
[2025-08-27 17:13:23,320][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086640] [Batch 00400/03080] [00:04:52/00:32:42, 0.732s/it]: train_loss_raw=0.3108, running_loss=0.3204, LR=0.000100
[2025-08-27 17:13:28,909][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086648] [Batch 00408/03080] [00:04:58/00:32:34, 0.732s/it]: train_loss_raw=0.2839, running_loss=0.3212, LR=0.000100
[2025-08-27 17:13:34,837][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086656] [Batch 00416/03080] [00:05:04/00:32:29, 0.732s/it]: train_loss_raw=0.3306, running_loss=0.3225, LR=0.000100
[2025-08-27 17:13:40,944][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086664] [Batch 00424/03080] [00:05:10/00:32:25, 0.732s/it]: train_loss_raw=0.3262, running_loss=0.3215, LR=0.000100
[2025-08-27 17:13:46,852][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086672] [Batch 00432/03080] [00:05:16/00:32:19, 0.732s/it]: train_loss_raw=0.2664, running_loss=0.3214, LR=0.000100
[2025-08-27 17:13:52,634][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086680] [Batch 00440/03080] [00:05:22/00:32:13, 0.732s/it]: train_loss_raw=0.3732, running_loss=0.3225, LR=0.000100
[2025-08-27 17:13:58,380][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086688] [Batch 00448/03080] [00:05:27/00:32:06, 0.732s/it]: train_loss_raw=0.3504, running_loss=0.3230, LR=0.000100
[2025-08-27 17:14:04,259][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086696] [Batch 00456/03080] [00:05:33/00:32:00, 0.732s/it]: train_loss_raw=0.2305, running_loss=0.3211, LR=0.000100
[2025-08-27 17:14:10,054][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086704] [Batch 00464/03080] [00:05:39/00:31:54, 0.732s/it]: train_loss_raw=0.2988, running_loss=0.3193, LR=0.000100
[2025-08-27 17:14:15,619][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086712] [Batch 00472/03080] [00:05:45/00:31:47, 0.731s/it]: train_loss_raw=0.3839, running_loss=0.3197, LR=0.000100
[2025-08-27 17:14:20,991][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086720] [Batch 00480/03080] [00:05:50/00:31:38, 0.730s/it]: train_loss_raw=0.2589, running_loss=0.3172, LR=0.000100
[2025-08-27 17:14:26,706][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086728] [Batch 00488/03080] [00:05:56/00:31:32, 0.730s/it]: train_loss_raw=0.3128, running_loss=0.3165, LR=0.000100
[2025-08-27 17:14:32,496][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086736] [Batch 00496/03080] [00:06:02/00:31:26, 0.730s/it]: train_loss_raw=0.3338, running_loss=0.3177, LR=0.000100
[2025-08-27 17:14:38,226][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086744] [Batch 00504/03080] [00:06:07/00:31:19, 0.730s/it]: train_loss_raw=0.3038, running_loss=0.3173, LR=0.000100
[2025-08-27 17:14:43,952][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086752] [Batch 00512/03080] [00:06:13/00:31:13, 0.730s/it]: train_loss_raw=0.2631, running_loss=0.3163, LR=0.000100
[2025-08-27 17:14:49,642][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086760] [Batch 00520/03080] [00:06:19/00:31:06, 0.729s/it]: train_loss_raw=0.2650, running_loss=0.3169, LR=0.000100
[2025-08-27 17:14:55,345][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086768] [Batch 00528/03080] [00:06:24/00:31:00, 0.729s/it]: train_loss_raw=0.3848, running_loss=0.3173, LR=0.000100
[2025-08-27 17:15:01,116][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086776] [Batch 00536/03080] [00:06:30/00:30:54, 0.729s/it]: train_loss_raw=0.3748, running_loss=0.3183, LR=0.000100
[2025-08-27 17:15:06,869][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086784] [Batch 00544/03080] [00:06:36/00:30:48, 0.729s/it]: train_loss_raw=0.3456, running_loss=0.3171, LR=0.000100
[2025-08-27 17:15:12,605][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086792] [Batch 00552/03080] [00:06:42/00:30:41, 0.729s/it]: train_loss_raw=0.2490, running_loss=0.3139, LR=0.000100
[2025-08-27 17:15:18,349][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086800] [Batch 00560/03080] [00:06:47/00:30:35, 0.728s/it]: train_loss_raw=0.3103, running_loss=0.3161, LR=0.000100
[2025-08-27 17:15:24,080][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086808] [Batch 00568/03080] [00:06:53/00:30:29, 0.728s/it]: train_loss_raw=0.2445, running_loss=0.3151, LR=0.000100
[2025-08-27 17:15:29,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086816] [Batch 00576/03080] [00:06:59/00:30:23, 0.728s/it]: train_loss_raw=0.2765, running_loss=0.3143, LR=0.000100
[2025-08-27 17:15:35,534][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086824] [Batch 00584/03080] [00:07:05/00:30:16, 0.728s/it]: train_loss_raw=0.3446, running_loss=0.3148, LR=0.000100
[2025-08-27 17:15:41,680][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086832] [Batch 00592/03080] [00:07:11/00:30:12, 0.728s/it]: train_loss_raw=0.2723, running_loss=0.3152, LR=0.000100
[2025-08-27 17:15:47,607][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086840] [Batch 00600/03080] [00:07:17/00:30:06, 0.729s/it]: train_loss_raw=0.2903, running_loss=0.3157, LR=0.000100
[2025-08-27 17:15:53,111][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086848] [Batch 00608/03080] [00:07:22/00:29:59, 0.728s/it]: train_loss_raw=0.3351, running_loss=0.3168, LR=0.000100
[2025-08-27 17:15:59,012][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086856] [Batch 00616/03080] [00:07:28/00:29:54, 0.728s/it]: train_loss_raw=0.3184, running_loss=0.3190, LR=0.000100
[2025-08-27 17:16:04,805][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086864] [Batch 00624/03080] [00:07:34/00:29:48, 0.728s/it]: train_loss_raw=0.3125, running_loss=0.3185, LR=0.000100
[2025-08-27 17:16:10,307][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086872] [Batch 00632/03080] [00:07:39/00:29:41, 0.728s/it]: train_loss_raw=0.4351, running_loss=0.3196, LR=0.000100
[2025-08-27 17:16:15,758][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086880] [Batch 00640/03080] [00:07:45/00:29:34, 0.727s/it]: train_loss_raw=0.3851, running_loss=0.3195, LR=0.000100
[2025-08-27 17:16:21,221][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086888] [Batch 00648/03080] [00:07:50/00:29:26, 0.727s/it]: train_loss_raw=0.2563, running_loss=0.3166, LR=0.000100
[2025-08-27 17:16:27,217][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086896] [Batch 00656/03080] [00:07:56/00:29:21, 0.727s/it]: train_loss_raw=0.2825, running_loss=0.3167, LR=0.000100
[2025-08-27 17:16:32,596][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086904] [Batch 00664/03080] [00:08:02/00:29:14, 0.726s/it]: train_loss_raw=0.3372, running_loss=0.3164, LR=0.000100
[2025-08-27 17:16:38,051][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086912] [Batch 00672/03080] [00:08:07/00:29:07, 0.726s/it]: train_loss_raw=0.2849, running_loss=0.3165, LR=0.000100
[2025-08-27 17:16:43,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086920] [Batch 00680/03080] [00:08:13/00:29:00, 0.725s/it]: train_loss_raw=0.3568, running_loss=0.3196, LR=0.000100
[2025-08-27 17:16:49,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086928] [Batch 00688/03080] [00:08:19/00:28:55, 0.726s/it]: train_loss_raw=0.2560, running_loss=0.3180, LR=0.000100
[2025-08-27 17:16:55,118][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086936] [Batch 00696/03080] [00:08:24/00:28:48, 0.725s/it]: train_loss_raw=0.2833, running_loss=0.3201, LR=0.000100
[2025-08-27 17:17:00,511][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086944] [Batch 00704/03080] [00:08:30/00:28:41, 0.725s/it]: train_loss_raw=0.2750, running_loss=0.3201, LR=0.000100
[2025-08-27 17:17:06,622][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086952] [Batch 00712/03080] [00:08:36/00:28:36, 0.725s/it]: train_loss_raw=0.2757, running_loss=0.3216, LR=0.000100
[2025-08-27 17:17:12,335][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086960] [Batch 00720/03080] [00:08:41/00:28:30, 0.725s/it]: train_loss_raw=0.3938, running_loss=0.3222, LR=0.000100
[2025-08-27 17:17:18,339][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086968] [Batch 00728/03080] [00:08:47/00:28:25, 0.725s/it]: train_loss_raw=0.3714, running_loss=0.3223, LR=0.000100
[2025-08-27 17:17:24,439][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086976] [Batch 00736/03080] [00:08:53/00:28:20, 0.726s/it]: train_loss_raw=0.2701, running_loss=0.3229, LR=0.000100
[2025-08-27 17:17:30,704][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086984] [Batch 00744/03080] [00:09:00/00:28:16, 0.726s/it]: train_loss_raw=0.3479, running_loss=0.3238, LR=0.000100
[2025-08-27 17:17:36,565][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086992] [Batch 00752/03080] [00:09:06/00:28:10, 0.726s/it]: train_loss_raw=0.3340, running_loss=0.3214, LR=0.000100
[2025-08-27 17:17:42,343][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087000] [Batch 00760/03080] [00:09:11/00:28:04, 0.726s/it]: train_loss_raw=0.2857, running_loss=0.3212, LR=0.000100
[2025-08-27 17:17:48,368][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087008] [Batch 00768/03080] [00:09:17/00:27:59, 0.726s/it]: train_loss_raw=0.2768, running_loss=0.3206, LR=0.000100
[2025-08-27 17:17:54,393][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087016] [Batch 00776/03080] [00:09:23/00:27:54, 0.727s/it]: train_loss_raw=0.3132, running_loss=0.3202, LR=0.000100
[2025-08-27 17:18:00,365][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087024] [Batch 00784/03080] [00:09:29/00:27:49, 0.727s/it]: train_loss_raw=0.2975, running_loss=0.3212, LR=0.000100
[2025-08-27 17:18:06,046][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087032] [Batch 00792/03080] [00:09:35/00:27:42, 0.727s/it]: train_loss_raw=0.3450, running_loss=0.3214, LR=0.000100
[2025-08-27 17:18:12,125][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087040] [Batch 00800/03080] [00:09:41/00:27:37, 0.727s/it]: train_loss_raw=0.3052, running_loss=0.3207, LR=0.000100
[2025-08-27 17:18:17,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087048] [Batch 00808/03080] [00:09:47/00:27:31, 0.727s/it]: train_loss_raw=0.3122, running_loss=0.3212, LR=0.000100
[2025-08-27 17:18:23,590][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087056] [Batch 00816/03080] [00:09:53/00:27:25, 0.727s/it]: train_loss_raw=0.2911, running_loss=0.3203, LR=0.000100
[2025-08-27 17:18:28,966][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087064] [Batch 00824/03080] [00:09:58/00:27:18, 0.726s/it]: train_loss_raw=0.3939, running_loss=0.3203, LR=0.000100
[2025-08-27 17:18:34,600][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087072] [Batch 00832/03080] [00:10:04/00:27:12, 0.726s/it]: train_loss_raw=0.3222, running_loss=0.3198, LR=0.000100
[2025-08-27 17:18:40,032][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087080] [Batch 00840/03080] [00:10:09/00:27:05, 0.726s/it]: train_loss_raw=0.3104, running_loss=0.3190, LR=0.000100
[2025-08-27 17:18:45,582][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087088] [Batch 00848/03080] [00:10:15/00:26:59, 0.725s/it]: train_loss_raw=0.3235, running_loss=0.3182, LR=0.000100
[2025-08-27 17:18:51,263][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087096] [Batch 00856/03080] [00:10:20/00:26:52, 0.725s/it]: train_loss_raw=0.2832, running_loss=0.3168, LR=0.000100
[2025-08-27 17:18:56,656][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087104] [Batch 00864/03080] [00:10:26/00:26:46, 0.725s/it]: train_loss_raw=0.3324, running_loss=0.3180, LR=0.000100
[2025-08-27 17:19:02,155][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087112] [Batch 00872/03080] [00:10:31/00:26:39, 0.724s/it]: train_loss_raw=0.2237, running_loss=0.3166, LR=0.000100
[2025-08-27 17:19:07,820][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087120] [Batch 00880/03080] [00:10:37/00:26:33, 0.724s/it]: train_loss_raw=0.3402, running_loss=0.3163, LR=0.000100
[2025-08-27 17:19:14,002][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087128] [Batch 00888/03080] [00:10:43/00:26:28, 0.725s/it]: train_loss_raw=0.3664, running_loss=0.3157, LR=0.000100
[2025-08-27 17:19:19,946][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087136] [Batch 00896/03080] [00:10:49/00:26:23, 0.725s/it]: train_loss_raw=0.3338, running_loss=0.3157, LR=0.000100
[2025-08-27 17:19:25,897][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087144] [Batch 00904/03080] [00:10:55/00:26:17, 0.725s/it]: train_loss_raw=0.3968, running_loss=0.3158, LR=0.000100
[2025-08-27 17:19:31,276][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087152] [Batch 00912/03080] [00:11:00/00:26:10, 0.725s/it]: train_loss_raw=0.3535, running_loss=0.3176, LR=0.000100
[2025-08-27 17:19:36,660][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087160] [Batch 00920/03080] [00:11:06/00:26:04, 0.724s/it]: train_loss_raw=0.3284, running_loss=0.3185, LR=0.000100
[2025-08-27 17:19:42,466][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087168] [Batch 00928/03080] [00:11:12/00:25:58, 0.724s/it]: train_loss_raw=0.3581, running_loss=0.3190, LR=0.000100
[2025-08-27 17:19:48,021][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087176] [Batch 00936/03080] [00:11:17/00:25:52, 0.724s/it]: train_loss_raw=0.2587, running_loss=0.3181, LR=0.000100
[2025-08-27 17:19:53,805][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087184] [Batch 00944/03080] [00:11:23/00:25:46, 0.724s/it]: train_loss_raw=0.3799, running_loss=0.3191, LR=0.000100
[2025-08-27 17:19:59,501][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087192] [Batch 00952/03080] [00:11:29/00:25:40, 0.724s/it]: train_loss_raw=0.3120, running_loss=0.3205, LR=0.000100
[2025-08-27 17:20:05,371][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087200] [Batch 00960/03080] [00:11:34/00:25:34, 0.724s/it]: train_loss_raw=0.3839, running_loss=0.3221, LR=0.000100
[2025-08-27 17:20:10,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087208] [Batch 00968/03080] [00:11:40/00:25:28, 0.724s/it]: train_loss_raw=0.3479, running_loss=0.3221, LR=0.000100
[2025-08-27 17:20:16,368][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087216] [Batch 00976/03080] [00:11:45/00:25:21, 0.723s/it]: train_loss_raw=0.3036, running_loss=0.3245, LR=0.000100
[2025-08-27 17:20:21,901][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087224] [Batch 00984/03080] [00:11:51/00:25:15, 0.723s/it]: train_loss_raw=0.3575, running_loss=0.3267, LR=0.000100
[2025-08-27 17:20:27,763][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087232] [Batch 00992/03080] [00:11:57/00:25:09, 0.723s/it]: train_loss_raw=0.3333, running_loss=0.3267, LR=0.000100
[2025-08-27 17:20:33,464][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087240] [Batch 01000/03080] [00:12:03/00:25:03, 0.723s/it]: train_loss_raw=0.2153, running_loss=0.3241, LR=0.000100
[2025-08-27 17:20:39,226][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087248] [Batch 01008/03080] [00:12:08/00:24:58, 0.723s/it]: train_loss_raw=0.3590, running_loss=0.3242, LR=0.000100
[2025-08-27 17:20:44,943][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087256] [Batch 01016/03080] [00:12:14/00:24:52, 0.723s/it]: train_loss_raw=0.2388, running_loss=0.3250, LR=0.000100
[2025-08-27 17:20:50,363][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087264] [Batch 01024/03080] [00:12:19/00:24:45, 0.723s/it]: train_loss_raw=0.3040, running_loss=0.3252, LR=0.000100
[2025-08-27 17:20:55,760][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087272] [Batch 01032/03080] [00:12:25/00:24:39, 0.722s/it]: train_loss_raw=0.2857, running_loss=0.3233, LR=0.000100
[2025-08-27 17:21:01,394][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087280] [Batch 01040/03080] [00:12:30/00:24:33, 0.722s/it]: train_loss_raw=0.3478, running_loss=0.3238, LR=0.000100
[2025-08-27 17:21:07,179][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087288] [Batch 01048/03080] [00:12:36/00:24:27, 0.722s/it]: train_loss_raw=0.3072, running_loss=0.3240, LR=0.000100
[2025-08-27 17:21:12,960][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087296] [Batch 01056/03080] [00:12:42/00:24:21, 0.722s/it]: train_loss_raw=0.3636, running_loss=0.3249, LR=0.000100
[2025-08-27 17:21:18,999][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087304] [Batch 01064/03080] [00:12:48/00:24:16, 0.722s/it]: train_loss_raw=0.3748, running_loss=0.3261, LR=0.000100
[2025-08-27 17:21:24,573][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087312] [Batch 01072/03080] [00:12:54/00:24:10, 0.722s/it]: train_loss_raw=0.3578, running_loss=0.3271, LR=0.000100
[2025-08-27 17:21:30,128][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087320] [Batch 01080/03080] [00:12:59/00:24:03, 0.722s/it]: train_loss_raw=0.2772, running_loss=0.3280, LR=0.000100
[2025-08-27 17:21:36,079][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087328] [Batch 01088/03080] [00:13:05/00:23:58, 0.722s/it]: train_loss_raw=0.3319, running_loss=0.3294, LR=0.000100
[2025-08-27 17:21:41,433][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087336] [Batch 01096/03080] [00:13:10/00:23:51, 0.722s/it]: train_loss_raw=0.3087, running_loss=0.3296, LR=0.000100
[2025-08-27 17:21:47,282][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087344] [Batch 01104/03080] [00:13:16/00:23:46, 0.722s/it]: train_loss_raw=0.4160, running_loss=0.3298, LR=0.000100
[2025-08-27 17:21:52,828][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087352] [Batch 01112/03080] [00:13:22/00:23:40, 0.722s/it]: train_loss_raw=0.3063, running_loss=0.3288, LR=0.000100
[2025-08-27 17:21:58,725][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087360] [Batch 01120/03080] [00:13:28/00:23:34, 0.722s/it]: train_loss_raw=0.3420, running_loss=0.3295, LR=0.000100
[2025-08-27 17:22:04,683][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087368] [Batch 01128/03080] [00:13:34/00:23:29, 0.722s/it]: train_loss_raw=0.3576, running_loss=0.3300, LR=0.000100
[2025-08-27 17:22:10,868][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087376] [Batch 01136/03080] [00:13:40/00:23:23, 0.722s/it]: train_loss_raw=0.3305, running_loss=0.3287, LR=0.000100
[2025-08-27 17:22:17,061][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087384] [Batch 01144/03080] [00:13:46/00:23:18, 0.723s/it]: train_loss_raw=0.3440, running_loss=0.3283, LR=0.000100
[2025-08-27 17:22:22,998][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087392] [Batch 01152/03080] [00:13:52/00:23:13, 0.723s/it]: train_loss_raw=0.3493, running_loss=0.3280, LR=0.000100
[2025-08-27 17:22:28,864][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087400] [Batch 01160/03080] [00:13:58/00:23:07, 0.723s/it]: train_loss_raw=0.5152, running_loss=0.3304, LR=0.000100
[2025-08-27 17:22:34,632][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087408] [Batch 01168/03080] [00:14:04/00:23:01, 0.723s/it]: train_loss_raw=0.2684, running_loss=0.3291, LR=0.000100
[2025-08-27 17:22:40,345][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087416] [Batch 01176/03080] [00:14:09/00:22:56, 0.723s/it]: train_loss_raw=0.3894, running_loss=0.3303, LR=0.000100
[2025-08-27 17:22:46,343][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087424] [Batch 01184/03080] [00:14:15/00:22:50, 0.723s/it]: train_loss_raw=0.3547, running_loss=0.3292, LR=0.000100
[2025-08-27 17:22:52,337][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087432] [Batch 01192/03080] [00:14:21/00:22:45, 0.723s/it]: train_loss_raw=0.2609, running_loss=0.3281, LR=0.000100
[2025-08-27 17:22:58,339][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087440] [Batch 01200/03080] [00:14:27/00:22:39, 0.723s/it]: train_loss_raw=0.2583, running_loss=0.3295, LR=0.000100
[2025-08-27 17:23:04,184][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087448] [Batch 01208/03080] [00:14:33/00:22:34, 0.723s/it]: train_loss_raw=0.3254, running_loss=0.3301, LR=0.000100
[2025-08-27 17:23:10,034][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087456] [Batch 01216/03080] [00:14:39/00:22:28, 0.723s/it]: train_loss_raw=0.3202, running_loss=0.3296, LR=0.000100
[2025-08-27 17:23:15,683][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087464] [Batch 01224/03080] [00:14:45/00:22:22, 0.723s/it]: train_loss_raw=0.2992, running_loss=0.3289, LR=0.000100
[2025-08-27 17:23:21,369][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087472] [Batch 01232/03080] [00:14:50/00:22:16, 0.723s/it]: train_loss_raw=0.2954, running_loss=0.3277, LR=0.000100
[2025-08-27 17:23:27,375][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087480] [Batch 01240/03080] [00:14:56/00:22:10, 0.723s/it]: train_loss_raw=0.3153, running_loss=0.3288, LR=0.000100
[2025-08-27 17:23:33,034][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087488] [Batch 01248/03080] [00:15:02/00:22:04, 0.723s/it]: train_loss_raw=0.3661, running_loss=0.3274, LR=0.000100
[2025-08-27 17:23:38,450][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087496] [Batch 01256/03080] [00:15:08/00:21:58, 0.723s/it]: train_loss_raw=0.3500, running_loss=0.3267, LR=0.000100
[2025-08-27 17:23:44,130][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087504] [Batch 01264/03080] [00:15:13/00:21:52, 0.723s/it]: train_loss_raw=0.2838, running_loss=0.3261, LR=0.000100
[2025-08-27 17:23:49,938][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087512] [Batch 01272/03080] [00:15:19/00:21:46, 0.723s/it]: train_loss_raw=0.3451, running_loss=0.3239, LR=0.000100
[2025-08-27 17:23:56,060][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087520] [Batch 01280/03080] [00:15:25/00:21:41, 0.723s/it]: train_loss_raw=0.2873, running_loss=0.3243, LR=0.000100
[2025-08-27 17:24:01,711][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087528] [Batch 01288/03080] [00:15:31/00:21:35, 0.723s/it]: train_loss_raw=0.4255, running_loss=0.3246, LR=0.000100
[2025-08-27 17:24:07,442][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087536] [Batch 01296/03080] [00:15:36/00:21:29, 0.723s/it]: train_loss_raw=0.3482, running_loss=0.3252, LR=0.000100
[2025-08-27 17:24:12,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087544] [Batch 01304/03080] [00:15:42/00:21:23, 0.723s/it]: train_loss_raw=0.3582, running_loss=0.3251, LR=0.000100
[2025-08-27 17:24:18,590][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087552] [Batch 01312/03080] [00:15:48/00:21:17, 0.723s/it]: train_loss_raw=0.3444, running_loss=0.3264, LR=0.000100
[2025-08-27 17:24:24,299][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087560] [Batch 01320/03080] [00:15:53/00:21:11, 0.723s/it]: train_loss_raw=0.3475, running_loss=0.3253, LR=0.000100
[2025-08-27 17:24:30,151][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087568] [Batch 01328/03080] [00:15:59/00:21:06, 0.723s/it]: train_loss_raw=0.3596, running_loss=0.3266, LR=0.000100
[2025-08-27 17:24:35,854][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087576] [Batch 01336/03080] [00:16:05/00:21:00, 0.723s/it]: train_loss_raw=0.2915, running_loss=0.3272, LR=0.000100
[2025-08-27 17:24:41,584][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087584] [Batch 01344/03080] [00:16:11/00:20:54, 0.723s/it]: train_loss_raw=0.2313, running_loss=0.3274, LR=0.000100
[2025-08-27 17:24:47,516][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087592] [Batch 01352/03080] [00:16:17/00:20:48, 0.723s/it]: train_loss_raw=0.2754, running_loss=0.3246, LR=0.000100
[2025-08-27 17:24:53,405][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087600] [Batch 01360/03080] [00:16:22/00:20:43, 0.723s/it]: train_loss_raw=0.3562, running_loss=0.3248, LR=0.000100
[2025-08-27 17:24:59,347][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087608] [Batch 01368/03080] [00:16:28/00:20:37, 0.723s/it]: train_loss_raw=0.2919, running_loss=0.3245, LR=0.000100
[2025-08-27 17:25:05,461][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087616] [Batch 01376/03080] [00:16:35/00:20:32, 0.723s/it]: train_loss_raw=0.2629, running_loss=0.3221, LR=0.000100
[2025-08-27 17:25:10,952][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087624] [Batch 01384/03080] [00:16:40/00:20:26, 0.723s/it]: train_loss_raw=0.2939, running_loss=0.3224, LR=0.000100
[2025-08-27 17:25:16,964][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087632] [Batch 01392/03080] [00:16:46/00:20:20, 0.723s/it]: train_loss_raw=0.3386, running_loss=0.3218, LR=0.000100
[2025-08-27 17:25:22,955][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087640] [Batch 01400/03080] [00:16:52/00:20:15, 0.723s/it]: train_loss_raw=0.2856, running_loss=0.3207, LR=0.000100
[2025-08-27 17:25:28,662][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087648] [Batch 01408/03080] [00:16:58/00:20:09, 0.723s/it]: train_loss_raw=0.3890, running_loss=0.3200, LR=0.000100
[2025-08-27 17:25:34,577][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087656] [Batch 01416/03080] [00:17:04/00:20:03, 0.723s/it]: train_loss_raw=0.3688, running_loss=0.3206, LR=0.000100
[2025-08-27 17:25:40,471][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087664] [Batch 01424/03080] [00:17:10/00:19:57, 0.723s/it]: train_loss_raw=0.3706, running_loss=0.3197, LR=0.000100
[2025-08-27 17:25:46,495][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087672] [Batch 01432/03080] [00:17:16/00:19:52, 0.723s/it]: train_loss_raw=0.3152, running_loss=0.3175, LR=0.000100
[2025-08-27 17:25:52,511][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087680] [Batch 01440/03080] [00:17:22/00:19:46, 0.724s/it]: train_loss_raw=0.3768, running_loss=0.3178, LR=0.000100
[2025-08-27 17:25:58,154][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087688] [Batch 01448/03080] [00:17:27/00:19:40, 0.724s/it]: train_loss_raw=0.3004, running_loss=0.3187, LR=0.000100
[2025-08-27 17:26:04,148][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087696] [Batch 01456/03080] [00:17:33/00:19:35, 0.724s/it]: train_loss_raw=0.2694, running_loss=0.3177, LR=0.000100
[2025-08-27 17:26:09,838][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087704] [Batch 01464/03080] [00:17:39/00:19:29, 0.724s/it]: train_loss_raw=0.3421, running_loss=0.3173, LR=0.000100
[2025-08-27 17:26:15,895][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087712] [Batch 01472/03080] [00:17:45/00:19:23, 0.724s/it]: train_loss_raw=0.2950, running_loss=0.3175, LR=0.000100
[2025-08-27 17:26:21,648][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087720] [Batch 01480/03080] [00:17:51/00:19:18, 0.724s/it]: train_loss_raw=0.3117, running_loss=0.3173, LR=0.000100
[2025-08-27 17:26:27,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087728] [Batch 01488/03080] [00:17:57/00:19:12, 0.724s/it]: train_loss_raw=0.3308, running_loss=0.3178, LR=0.000100
[2025-08-27 17:26:33,606][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087736] [Batch 01496/03080] [00:18:03/00:19:06, 0.724s/it]: train_loss_raw=0.3981, running_loss=0.3179, LR=0.000100
[2025-08-27 17:26:39,354][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087744] [Batch 01504/03080] [00:18:08/00:19:01, 0.724s/it]: train_loss_raw=0.3545, running_loss=0.3201, LR=0.000100
[2025-08-27 17:26:44,734][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087752] [Batch 01512/03080] [00:18:14/00:18:54, 0.724s/it]: train_loss_raw=0.3474, running_loss=0.3193, LR=0.000100
[2025-08-27 17:26:50,369][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087760] [Batch 01520/03080] [00:18:19/00:18:48, 0.724s/it]: train_loss_raw=0.3226, running_loss=0.3203, LR=0.000100
[2025-08-27 17:26:56,080][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087768] [Batch 01528/03080] [00:18:25/00:18:43, 0.724s/it]: train_loss_raw=0.2639, running_loss=0.3205, LR=0.000100
[2025-08-27 17:27:01,654][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087776] [Batch 01536/03080] [00:18:31/00:18:36, 0.723s/it]: train_loss_raw=0.3651, running_loss=0.3211, LR=0.000100
[2025-08-27 17:27:07,017][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087784] [Batch 01544/03080] [00:18:36/00:18:30, 0.723s/it]: train_loss_raw=0.2741, running_loss=0.3217, LR=0.000100
[2025-08-27 17:27:12,397][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087792] [Batch 01552/03080] [00:18:41/00:18:24, 0.723s/it]: train_loss_raw=0.2647, running_loss=0.3212, LR=0.000100
[2025-08-27 17:27:18,080][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087800] [Batch 01560/03080] [00:18:47/00:18:18, 0.723s/it]: train_loss_raw=0.2815, running_loss=0.3200, LR=0.000100
[2025-08-27 17:27:23,627][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087808] [Batch 01568/03080] [00:18:53/00:18:12, 0.723s/it]: train_loss_raw=0.3355, running_loss=0.3215, LR=0.000100
[2025-08-27 17:27:29,037][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087816] [Batch 01576/03080] [00:18:58/00:18:06, 0.722s/it]: train_loss_raw=0.3667, running_loss=0.3235, LR=0.000100
[2025-08-27 17:27:34,910][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087824] [Batch 01584/03080] [00:19:04/00:18:00, 0.723s/it]: train_loss_raw=0.3470, running_loss=0.3228, LR=0.000100
[2025-08-27 17:27:40,857][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087832] [Batch 01592/03080] [00:19:10/00:17:55, 0.723s/it]: train_loss_raw=0.2872, running_loss=0.3212, LR=0.000100
[2025-08-27 17:27:46,550][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087840] [Batch 01600/03080] [00:19:16/00:17:49, 0.723s/it]: train_loss_raw=0.2870, running_loss=0.3205, LR=0.000100
[2025-08-27 17:27:52,100][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087848] [Batch 01608/03080] [00:19:21/00:17:43, 0.722s/it]: train_loss_raw=0.3022, running_loss=0.3196, LR=0.000100
[2025-08-27 17:27:57,600][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087856] [Batch 01616/03080] [00:19:27/00:17:37, 0.722s/it]: train_loss_raw=0.3586, running_loss=0.3205, LR=0.000100
[2025-08-27 17:28:03,739][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087864] [Batch 01624/03080] [00:19:33/00:17:31, 0.722s/it]: train_loss_raw=0.2389, running_loss=0.3216, LR=0.000100
[2025-08-27 17:28:09,410][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087872] [Batch 01632/03080] [00:19:38/00:17:26, 0.722s/it]: train_loss_raw=0.2889, running_loss=0.3213, LR=0.000100
[2025-08-27 17:28:15,180][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087880] [Batch 01640/03080] [00:19:44/00:17:20, 0.722s/it]: train_loss_raw=0.3337, running_loss=0.3218, LR=0.000100
[2025-08-27 17:28:20,824][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087888] [Batch 01648/03080] [00:19:50/00:17:14, 0.722s/it]: train_loss_raw=0.2930, running_loss=0.3218, LR=0.000100
[2025-08-27 17:28:26,625][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087896] [Batch 01656/03080] [00:19:56/00:17:08, 0.722s/it]: train_loss_raw=0.3025, running_loss=0.3211, LR=0.000100
[2025-08-27 17:28:32,332][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087904] [Batch 01664/03080] [00:20:01/00:17:02, 0.722s/it]: train_loss_raw=0.2829, running_loss=0.3224, LR=0.000100
[2025-08-27 17:28:38,328][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087912] [Batch 01672/03080] [00:20:07/00:16:57, 0.722s/it]: train_loss_raw=0.2882, running_loss=0.3225, LR=0.000100
[2025-08-27 17:28:44,044][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087920] [Batch 01680/03080] [00:20:13/00:16:51, 0.722s/it]: train_loss_raw=0.3592, running_loss=0.3232, LR=0.000100
[2025-08-27 17:28:50,075][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087928] [Batch 01688/03080] [00:20:19/00:16:45, 0.723s/it]: train_loss_raw=0.3612, running_loss=0.3233, LR=0.000100
[2025-08-27 17:28:56,300][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087936] [Batch 01696/03080] [00:20:25/00:16:40, 0.723s/it]: train_loss_raw=0.3353, running_loss=0.3231, LR=0.000100
[2025-08-27 17:29:02,165][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087944] [Batch 01704/03080] [00:20:31/00:16:34, 0.723s/it]: train_loss_raw=0.2906, running_loss=0.3217, LR=0.000100
[2025-08-27 17:29:08,350][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087952] [Batch 01712/03080] [00:20:37/00:16:29, 0.723s/it]: train_loss_raw=0.3916, running_loss=0.3199, LR=0.000100
[2025-08-27 17:29:14,270][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087960] [Batch 01720/03080] [00:20:43/00:16:23, 0.723s/it]: train_loss_raw=0.3011, running_loss=0.3183, LR=0.000100
[2025-08-27 17:29:20,132][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087968] [Batch 01728/03080] [00:20:49/00:16:17, 0.723s/it]: train_loss_raw=0.3232, running_loss=0.3200, LR=0.000100
[2025-08-27 17:29:25,748][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087976] [Batch 01736/03080] [00:20:55/00:16:11, 0.723s/it]: train_loss_raw=0.2550, running_loss=0.3202, LR=0.000100
[2025-08-27 17:29:31,259][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087984] [Batch 01744/03080] [00:21:00/00:16:05, 0.723s/it]: train_loss_raw=0.3438, running_loss=0.3207, LR=0.000100
[2025-08-27 17:29:36,832][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087992] [Batch 01752/03080] [00:21:06/00:15:59, 0.723s/it]: train_loss_raw=0.2721, running_loss=0.3196, LR=0.000100
[2025-08-27 17:29:42,652][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088000] [Batch 01760/03080] [00:21:12/00:15:54, 0.723s/it]: train_loss_raw=0.2943, running_loss=0.3201, LR=0.000100
[2025-08-27 17:29:52,193][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088008] [Batch 01768/03080] [00:21:21/00:15:51, 0.725s/it]: train_loss_raw=0.3718, running_loss=0.3216, LR=0.000100
[2025-08-27 17:29:58,056][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088016] [Batch 01776/03080] [00:21:27/00:15:45, 0.725s/it]: train_loss_raw=0.3585, running_loss=0.3217, LR=0.000100
[2025-08-27 17:30:04,024][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088024] [Batch 01784/03080] [00:21:33/00:15:39, 0.725s/it]: train_loss_raw=0.3765, running_loss=0.3207, LR=0.000100
[2025-08-27 17:30:09,493][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088032] [Batch 01792/03080] [00:21:39/00:15:33, 0.725s/it]: train_loss_raw=0.3045, running_loss=0.3212, LR=0.000100
[2025-08-27 17:30:15,418][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088040] [Batch 01800/03080] [00:21:44/00:15:27, 0.725s/it]: train_loss_raw=0.2834, running_loss=0.3187, LR=0.000100
[2025-08-27 17:30:21,333][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088048] [Batch 01808/03080] [00:21:50/00:15:22, 0.725s/it]: train_loss_raw=0.2870, running_loss=0.3189, LR=0.000100
[2025-08-27 17:30:27,196][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088056] [Batch 01816/03080] [00:21:56/00:15:16, 0.725s/it]: train_loss_raw=0.2588, running_loss=0.3210, LR=0.000100
[2025-08-27 17:30:32,980][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088064] [Batch 01824/03080] [00:22:02/00:15:10, 0.725s/it]: train_loss_raw=0.3120, running_loss=0.3211, LR=0.000100
[2025-08-27 17:30:38,527][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088072] [Batch 01832/03080] [00:22:08/00:15:04, 0.725s/it]: train_loss_raw=0.4158, running_loss=0.3227, LR=0.000100
[2025-08-27 17:30:44,513][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088080] [Batch 01840/03080] [00:22:14/00:14:59, 0.725s/it]: train_loss_raw=0.3574, running_loss=0.3233, LR=0.000100
[2025-08-27 17:30:50,623][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088088] [Batch 01848/03080] [00:22:20/00:14:53, 0.725s/it]: train_loss_raw=0.3666, running_loss=0.3234, LR=0.000100
[2025-08-27 17:30:56,526][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088096] [Batch 01856/03080] [00:22:26/00:14:47, 0.725s/it]: train_loss_raw=0.3326, running_loss=0.3224, LR=0.000100
[2025-08-27 17:31:02,260][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088104] [Batch 01864/03080] [00:22:31/00:14:41, 0.725s/it]: train_loss_raw=0.4146, running_loss=0.3265, LR=0.000100
[2025-08-27 17:31:08,224][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088112] [Batch 01872/03080] [00:22:37/00:14:36, 0.725s/it]: train_loss_raw=0.2941, running_loss=0.3262, LR=0.000100
[2025-08-27 17:31:13,889][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088120] [Batch 01880/03080] [00:22:43/00:14:30, 0.725s/it]: train_loss_raw=0.2600, running_loss=0.3264, LR=0.000100
[2025-08-27 17:31:19,523][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088128] [Batch 01888/03080] [00:22:49/00:14:24, 0.725s/it]: train_loss_raw=0.3237, running_loss=0.3290, LR=0.000100
[2025-08-27 17:31:25,228][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088136] [Batch 01896/03080] [00:22:54/00:14:18, 0.725s/it]: train_loss_raw=0.3388, running_loss=0.3292, LR=0.000100
[2025-08-27 17:31:30,650][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088144] [Batch 01904/03080] [00:23:00/00:14:12, 0.725s/it]: train_loss_raw=0.3083, running_loss=0.3290, LR=0.000100
[2025-08-27 17:31:36,543][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088152] [Batch 01912/03080] [00:23:06/00:14:06, 0.725s/it]: train_loss_raw=0.3401, running_loss=0.3296, LR=0.000100
[2025-08-27 17:31:42,106][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088160] [Batch 01920/03080] [00:23:11/00:14:00, 0.725s/it]: train_loss_raw=0.3584, running_loss=0.3303, LR=0.000100
[2025-08-27 17:31:47,953][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088168] [Batch 01928/03080] [00:23:17/00:13:55, 0.725s/it]: train_loss_raw=0.3476, running_loss=0.3286, LR=0.000100
[2025-08-27 17:31:53,728][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088176] [Batch 01936/03080] [00:23:23/00:13:49, 0.725s/it]: train_loss_raw=0.3482, running_loss=0.3262, LR=0.000100
[2025-08-27 17:31:59,308][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088184] [Batch 01944/03080] [00:23:28/00:13:43, 0.725s/it]: train_loss_raw=0.3905, running_loss=0.3262, LR=0.000100
[2025-08-27 17:32:05,096][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088192] [Batch 01952/03080] [00:23:34/00:13:37, 0.725s/it]: train_loss_raw=0.3526, running_loss=0.3262, LR=0.000100
[2025-08-27 17:32:11,001][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088200] [Batch 01960/03080] [00:23:40/00:13:31, 0.725s/it]: train_loss_raw=0.2778, running_loss=0.3244, LR=0.000100
[2025-08-27 17:32:16,714][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088208] [Batch 01968/03080] [00:23:46/00:13:25, 0.725s/it]: train_loss_raw=0.3729, running_loss=0.3247, LR=0.000100
[2025-08-27 17:32:22,399][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088216] [Batch 01976/03080] [00:23:51/00:13:20, 0.725s/it]: train_loss_raw=0.3514, running_loss=0.3254, LR=0.000100
[2025-08-27 17:32:28,339][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088224] [Batch 01984/03080] [00:23:57/00:13:14, 0.725s/it]: train_loss_raw=0.2959, running_loss=0.3250, LR=0.000100
[2025-08-27 17:32:34,108][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088232] [Batch 01992/03080] [00:24:03/00:13:08, 0.725s/it]: train_loss_raw=0.3642, running_loss=0.3254, LR=0.000100
[2025-08-27 17:32:39,877][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088240] [Batch 02000/03080] [00:24:09/00:13:02, 0.725s/it]: train_loss_raw=0.3123, running_loss=0.3236, LR=0.000100
[2025-08-27 17:32:45,749][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088248] [Batch 02008/03080] [00:24:15/00:12:56, 0.725s/it]: train_loss_raw=0.2653, running_loss=0.3250, LR=0.000100
[2025-08-27 17:32:51,905][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088256] [Batch 02016/03080] [00:24:21/00:12:51, 0.725s/it]: train_loss_raw=0.3356, running_loss=0.3244, LR=0.000100
[2025-08-27 17:32:57,521][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088264] [Batch 02024/03080] [00:24:27/00:12:45, 0.725s/it]: train_loss_raw=0.2391, running_loss=0.3231, LR=0.000100
[2025-08-27 17:33:03,329][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088272] [Batch 02032/03080] [00:24:32/00:12:39, 0.725s/it]: train_loss_raw=0.3399, running_loss=0.3226, LR=0.000100
[2025-08-27 17:33:09,106][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088280] [Batch 02040/03080] [00:24:38/00:12:33, 0.725s/it]: train_loss_raw=0.3755, running_loss=0.3255, LR=0.000100
[2025-08-27 17:33:14,664][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088288] [Batch 02048/03080] [00:24:44/00:12:27, 0.725s/it]: train_loss_raw=0.2948, running_loss=0.3248, LR=0.000100
[2025-08-27 17:33:20,112][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088296] [Batch 02056/03080] [00:24:49/00:12:21, 0.725s/it]: train_loss_raw=0.2738, running_loss=0.3242, LR=0.000100
[2025-08-27 17:33:26,193][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088304] [Batch 02064/03080] [00:24:55/00:12:16, 0.725s/it]: train_loss_raw=0.3356, running_loss=0.3243, LR=0.000100
[2025-08-27 17:33:31,913][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088312] [Batch 02072/03080] [00:25:01/00:12:10, 0.725s/it]: train_loss_raw=0.3847, running_loss=0.3251, LR=0.000100
[2025-08-27 17:33:37,578][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088320] [Batch 02080/03080] [00:25:07/00:12:04, 0.725s/it]: train_loss_raw=0.3389, running_loss=0.3249, LR=0.000100
[2025-08-27 17:33:43,116][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088328] [Batch 02088/03080] [00:25:12/00:11:58, 0.724s/it]: train_loss_raw=0.3702, running_loss=0.3269, LR=0.000100
[2025-08-27 17:33:49,039][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088336] [Batch 02096/03080] [00:25:18/00:11:52, 0.725s/it]: train_loss_raw=0.3047, running_loss=0.3252, LR=0.000100
[2025-08-27 17:33:54,755][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088344] [Batch 02104/03080] [00:25:24/00:11:47, 0.724s/it]: train_loss_raw=0.3132, running_loss=0.3259, LR=0.000100
[2025-08-27 17:34:00,621][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088352] [Batch 02112/03080] [00:25:30/00:11:41, 0.725s/it]: train_loss_raw=0.4432, running_loss=0.3276, LR=0.000100
[2025-08-27 17:34:06,424][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088360] [Batch 02120/03080] [00:25:35/00:11:35, 0.725s/it]: train_loss_raw=0.3317, running_loss=0.3284, LR=0.000100
[2025-08-27 17:34:12,135][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088368] [Batch 02128/03080] [00:25:41/00:11:29, 0.724s/it]: train_loss_raw=0.3102, running_loss=0.3301, LR=0.000100
[2025-08-27 17:34:17,747][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088376] [Batch 02136/03080] [00:25:47/00:11:23, 0.724s/it]: train_loss_raw=0.3683, running_loss=0.3309, LR=0.000100
[2025-08-27 17:34:23,876][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088384] [Batch 02144/03080] [00:25:53/00:11:18, 0.725s/it]: train_loss_raw=0.3442, running_loss=0.3295, LR=0.000100
[2025-08-27 17:34:29,328][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088392] [Batch 02152/03080] [00:25:58/00:11:12, 0.724s/it]: train_loss_raw=0.3093, running_loss=0.3292, LR=0.000100
[2025-08-27 17:34:35,254][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088400] [Batch 02160/03080] [00:26:04/00:11:06, 0.724s/it]: train_loss_raw=0.3118, running_loss=0.3291, LR=0.000100
[2025-08-27 17:34:41,042][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088408] [Batch 02168/03080] [00:26:10/00:11:00, 0.724s/it]: train_loss_raw=0.3178, running_loss=0.3288, LR=0.000100
[2025-08-27 17:34:46,759][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088416] [Batch 02176/03080] [00:26:16/00:10:54, 0.724s/it]: train_loss_raw=0.3061, running_loss=0.3284, LR=0.000100
[2025-08-27 17:34:52,613][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088424] [Batch 02184/03080] [00:26:22/00:10:49, 0.724s/it]: train_loss_raw=0.3465, running_loss=0.3283, LR=0.000100
[2025-08-27 17:34:58,578][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088432] [Batch 02192/03080] [00:26:28/00:10:43, 0.725s/it]: train_loss_raw=0.3191, running_loss=0.3270, LR=0.000100
[2025-08-27 17:35:04,061][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088440] [Batch 02200/03080] [00:26:33/00:10:37, 0.724s/it]: train_loss_raw=0.3640, running_loss=0.3256, LR=0.000100
[2025-08-27 17:35:09,468][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088448] [Batch 02208/03080] [00:26:39/00:10:31, 0.724s/it]: train_loss_raw=0.4164, running_loss=0.3264, LR=0.000100
[2025-08-27 17:35:15,145][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088456] [Batch 02216/03080] [00:26:44/00:10:25, 0.724s/it]: train_loss_raw=0.3318, running_loss=0.3247, LR=0.000100
[2025-08-27 17:35:20,857][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088464] [Batch 02224/03080] [00:26:50/00:10:19, 0.724s/it]: train_loss_raw=0.3401, running_loss=0.3254, LR=0.000100
[2025-08-27 17:35:26,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088472] [Batch 02232/03080] [00:26:56/00:10:14, 0.724s/it]: train_loss_raw=0.3001, running_loss=0.3245, LR=0.000100
[2025-08-27 17:35:32,683][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088480] [Batch 02240/03080] [00:27:02/00:10:08, 0.724s/it]: train_loss_raw=0.3017, running_loss=0.3246, LR=0.000100
[2025-08-27 17:35:38,760][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088488] [Batch 02248/03080] [00:27:08/00:10:02, 0.724s/it]: train_loss_raw=0.3318, running_loss=0.3240, LR=0.000100
[2025-08-27 17:35:44,717][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088496] [Batch 02256/03080] [00:27:14/00:09:56, 0.724s/it]: train_loss_raw=0.3389, running_loss=0.3235, LR=0.000100
[2025-08-27 17:35:50,620][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088504] [Batch 02264/03080] [00:27:20/00:09:51, 0.724s/it]: train_loss_raw=0.2779, running_loss=0.3219, LR=0.000100
[2025-08-27 17:35:56,657][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088512] [Batch 02272/03080] [00:27:26/00:09:45, 0.725s/it]: train_loss_raw=0.2987, running_loss=0.3209, LR=0.000100
[2025-08-27 17:36:02,283][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088520] [Batch 02280/03080] [00:27:31/00:09:39, 0.724s/it]: train_loss_raw=0.3146, running_loss=0.3198, LR=0.000100
[2025-08-27 17:36:07,714][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088528] [Batch 02288/03080] [00:27:37/00:09:33, 0.724s/it]: train_loss_raw=0.4059, running_loss=0.3187, LR=0.000100
[2025-08-27 17:36:13,187][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088536] [Batch 02296/03080] [00:27:42/00:09:27, 0.724s/it]: train_loss_raw=0.3433, running_loss=0.3200, LR=0.000100
[2025-08-27 17:36:18,799][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088544] [Batch 02304/03080] [00:27:48/00:09:21, 0.724s/it]: train_loss_raw=0.3002, running_loss=0.3211, LR=0.000100
[2025-08-27 17:36:24,556][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088552] [Batch 02312/03080] [00:27:54/00:09:16, 0.724s/it]: train_loss_raw=0.3227, running_loss=0.3201, LR=0.000100
[2025-08-27 17:36:30,414][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088560] [Batch 02320/03080] [00:27:59/00:09:10, 0.724s/it]: train_loss_raw=0.2514, running_loss=0.3188, LR=0.000100
[2025-08-27 17:36:35,834][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088568] [Batch 02328/03080] [00:28:05/00:09:04, 0.724s/it]: train_loss_raw=0.3182, running_loss=0.3203, LR=0.000100
[2025-08-27 17:36:41,316][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088576] [Batch 02336/03080] [00:28:10/00:08:58, 0.724s/it]: train_loss_raw=0.3573, running_loss=0.3214, LR=0.000100
[2025-08-27 17:36:46,817][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088584] [Batch 02344/03080] [00:28:16/00:08:52, 0.724s/it]: train_loss_raw=0.3394, running_loss=0.3207, LR=0.000100
[2025-08-27 17:36:52,278][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088592] [Batch 02352/03080] [00:28:21/00:08:46, 0.724s/it]: train_loss_raw=0.3447, running_loss=0.3234, LR=0.000100
[2025-08-27 17:36:58,127][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088600] [Batch 02360/03080] [00:28:27/00:08:40, 0.724s/it]: train_loss_raw=0.3012, running_loss=0.3238, LR=0.000100
[2025-08-27 17:37:04,230][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088608] [Batch 02368/03080] [00:28:33/00:08:35, 0.724s/it]: train_loss_raw=0.3600, running_loss=0.3255, LR=0.000100
[2025-08-27 17:37:09,938][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088616] [Batch 02376/03080] [00:28:39/00:08:29, 0.724s/it]: train_loss_raw=0.3926, running_loss=0.3270, LR=0.000100
[2025-08-27 17:37:15,484][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088624] [Batch 02384/03080] [00:28:45/00:08:23, 0.724s/it]: train_loss_raw=0.2887, running_loss=0.3283, LR=0.000100
[2025-08-27 17:37:21,423][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088632] [Batch 02392/03080] [00:28:50/00:08:17, 0.724s/it]: train_loss_raw=0.3552, running_loss=0.3276, LR=0.000100
[2025-08-27 17:37:27,355][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088640] [Batch 02400/03080] [00:28:56/00:08:12, 0.724s/it]: train_loss_raw=0.3166, running_loss=0.3275, LR=0.000100
[2025-08-27 17:37:33,284][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088648] [Batch 02408/03080] [00:29:02/00:08:06, 0.724s/it]: train_loss_raw=0.3571, running_loss=0.3285, LR=0.000100
[2025-08-27 17:37:39,036][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088656] [Batch 02416/03080] [00:29:08/00:08:00, 0.724s/it]: train_loss_raw=0.3633, running_loss=0.3272, LR=0.000100
[2025-08-27 17:37:44,895][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088664] [Batch 02424/03080] [00:29:14/00:07:54, 0.724s/it]: train_loss_raw=0.2995, running_loss=0.3292, LR=0.000100
[2025-08-27 17:37:50,906][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088672] [Batch 02432/03080] [00:29:20/00:07:49, 0.724s/it]: train_loss_raw=0.3159, running_loss=0.3282, LR=0.000100
[2025-08-27 17:37:56,650][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088680] [Batch 02440/03080] [00:29:26/00:07:43, 0.724s/it]: train_loss_raw=0.3468, running_loss=0.3282, LR=0.000100
[2025-08-27 17:38:02,356][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088688] [Batch 02448/03080] [00:29:31/00:07:37, 0.724s/it]: train_loss_raw=0.2996, running_loss=0.3246, LR=0.000100
[2025-08-27 17:38:08,168][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088696] [Batch 02456/03080] [00:29:37/00:07:31, 0.724s/it]: train_loss_raw=0.3398, running_loss=0.3235, LR=0.000100
[2025-08-27 17:38:14,257][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088704] [Batch 02464/03080] [00:29:43/00:07:25, 0.724s/it]: train_loss_raw=0.3268, running_loss=0.3232, LR=0.000100
[2025-08-27 17:38:20,175][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088712] [Batch 02472/03080] [00:29:49/00:07:20, 0.724s/it]: train_loss_raw=0.3785, running_loss=0.3232, LR=0.000100
[2025-08-27 17:38:26,095][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088720] [Batch 02480/03080] [00:29:55/00:07:14, 0.724s/it]: train_loss_raw=0.2766, running_loss=0.3222, LR=0.000100
[2025-08-27 17:38:32,005][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088728] [Batch 02488/03080] [00:30:01/00:07:08, 0.724s/it]: train_loss_raw=0.3267, running_loss=0.3229, LR=0.000100
[2025-08-27 17:38:37,667][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088736] [Batch 02496/03080] [00:30:07/00:07:02, 0.724s/it]: train_loss_raw=0.2911, running_loss=0.3234, LR=0.000100
[2025-08-27 17:38:43,474][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088744] [Batch 02504/03080] [00:30:13/00:06:57, 0.724s/it]: train_loss_raw=0.3140, running_loss=0.3240, LR=0.000100
[2025-08-27 17:38:49,261][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088752] [Batch 02512/03080] [00:30:18/00:06:51, 0.724s/it]: train_loss_raw=0.3486, running_loss=0.3257, LR=0.000100
[2025-08-27 17:38:55,412][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088760] [Batch 02520/03080] [00:30:24/00:06:45, 0.724s/it]: train_loss_raw=0.2848, running_loss=0.3252, LR=0.000100
[2025-08-27 17:39:01,427][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088768] [Batch 02528/03080] [00:30:30/00:06:39, 0.724s/it]: train_loss_raw=0.3146, running_loss=0.3243, LR=0.000100
[2025-08-27 17:39:07,279][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088776] [Batch 02536/03080] [00:30:36/00:06:34, 0.724s/it]: train_loss_raw=0.3116, running_loss=0.3249, LR=0.000100
[2025-08-27 17:39:12,814][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088784] [Batch 02544/03080] [00:30:42/00:06:28, 0.724s/it]: train_loss_raw=0.3829, running_loss=0.3252, LR=0.000100
[2025-08-27 17:39:18,601][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088792] [Batch 02552/03080] [00:30:48/00:06:22, 0.724s/it]: train_loss_raw=0.4090, running_loss=0.3231, LR=0.000100
[2025-08-27 17:39:23,995][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088800] [Batch 02560/03080] [00:30:53/00:06:16, 0.724s/it]: train_loss_raw=0.2819, running_loss=0.3238, LR=0.000100
[2025-08-27 17:39:30,000][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088808] [Batch 02568/03080] [00:30:59/00:06:10, 0.724s/it]: train_loss_raw=0.3417, running_loss=0.3234, LR=0.000100
[2025-08-27 17:39:35,668][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088816] [Batch 02576/03080] [00:31:05/00:06:04, 0.724s/it]: train_loss_raw=0.3780, running_loss=0.3239, LR=0.000100
[2025-08-27 17:39:41,348][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088824] [Batch 02584/03080] [00:31:10/00:05:59, 0.724s/it]: train_loss_raw=0.3420, running_loss=0.3254, LR=0.000100
[2025-08-27 17:39:47,605][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088832] [Batch 02592/03080] [00:31:17/00:05:53, 0.724s/it]: train_loss_raw=0.3010, running_loss=0.3232, LR=0.000100
[2025-08-27 17:39:53,272][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088840] [Batch 02600/03080] [00:31:22/00:05:47, 0.724s/it]: train_loss_raw=0.2795, running_loss=0.3207, LR=0.000100
[2025-08-27 17:39:59,334][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088848] [Batch 02608/03080] [00:31:28/00:05:41, 0.724s/it]: train_loss_raw=0.3677, running_loss=0.3209, LR=0.000100
[2025-08-27 17:40:05,542][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088856] [Batch 02616/03080] [00:31:35/00:05:36, 0.724s/it]: train_loss_raw=0.2479, running_loss=0.3211, LR=0.000100
[2025-08-27 17:40:11,865][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088864] [Batch 02624/03080] [00:31:41/00:05:30, 0.725s/it]: train_loss_raw=0.2529, running_loss=0.3203, LR=0.000100
[2025-08-27 17:40:17,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088872] [Batch 02632/03080] [00:31:47/00:05:24, 0.725s/it]: train_loss_raw=0.3217, running_loss=0.3219, LR=0.000100
[2025-08-27 17:40:24,112][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088880] [Batch 02640/03080] [00:31:53/00:05:18, 0.725s/it]: train_loss_raw=0.3033, running_loss=0.3221, LR=0.000100
[2025-08-27 17:40:29,818][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088888] [Batch 02648/03080] [00:31:59/00:05:13, 0.725s/it]: train_loss_raw=0.3721, running_loss=0.3235, LR=0.000100
[2025-08-27 17:40:35,818][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088896] [Batch 02656/03080] [00:32:05/00:05:07, 0.725s/it]: train_loss_raw=0.4945, running_loss=0.3246, LR=0.000100
[2025-08-27 17:40:41,680][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088904] [Batch 02664/03080] [00:32:11/00:05:01, 0.725s/it]: train_loss_raw=0.2811, running_loss=0.3262, LR=0.000100
[2025-08-27 17:40:47,495][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088912] [Batch 02672/03080] [00:32:17/00:04:55, 0.725s/it]: train_loss_raw=0.3269, running_loss=0.3246, LR=0.000100
[2025-08-27 17:40:53,391][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088920] [Batch 02680/03080] [00:32:22/00:04:49, 0.725s/it]: train_loss_raw=0.3511, running_loss=0.3251, LR=0.000100
[2025-08-27 17:40:59,322][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088928] [Batch 02688/03080] [00:32:28/00:04:44, 0.725s/it]: train_loss_raw=0.3155, running_loss=0.3246, LR=0.000100
[2025-08-27 17:41:05,368][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088936] [Batch 02696/03080] [00:32:34/00:04:38, 0.725s/it]: train_loss_raw=0.3521, running_loss=0.3241, LR=0.000100
[2025-08-27 17:41:11,328][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088944] [Batch 02704/03080] [00:32:40/00:04:32, 0.725s/it]: train_loss_raw=0.2942, running_loss=0.3241, LR=0.000100
[2025-08-27 17:41:17,334][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088952] [Batch 02712/03080] [00:32:46/00:04:26, 0.725s/it]: train_loss_raw=0.3621, running_loss=0.3242, LR=0.000100
[2025-08-27 17:41:23,031][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088960] [Batch 02720/03080] [00:32:52/00:04:21, 0.725s/it]: train_loss_raw=0.2926, running_loss=0.3230, LR=0.000100
[2025-08-27 17:41:28,697][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088968] [Batch 02728/03080] [00:32:58/00:04:15, 0.725s/it]: train_loss_raw=0.3338, running_loss=0.3265, LR=0.000100
[2025-08-27 17:41:34,580][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088976] [Batch 02736/03080] [00:33:04/00:04:09, 0.725s/it]: train_loss_raw=0.3766, running_loss=0.3255, LR=0.000100
[2025-08-27 17:41:40,273][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088984] [Batch 02744/03080] [00:33:09/00:04:03, 0.725s/it]: train_loss_raw=0.3172, running_loss=0.3271, LR=0.000100
[2025-08-27 17:41:45,897][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088992] [Batch 02752/03080] [00:33:15/00:03:57, 0.725s/it]: train_loss_raw=0.2521, running_loss=0.3248, LR=0.000100
[2025-08-27 17:41:51,884][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089000] [Batch 02760/03080] [00:33:21/00:03:52, 0.725s/it]: train_loss_raw=0.3356, running_loss=0.3236, LR=0.000100
[2025-08-27 17:41:57,838][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089008] [Batch 02768/03080] [00:33:27/00:03:46, 0.725s/it]: train_loss_raw=0.3424, running_loss=0.3242, LR=0.000100
[2025-08-27 17:42:03,511][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089016] [Batch 02776/03080] [00:33:33/00:03:40, 0.725s/it]: train_loss_raw=0.2624, running_loss=0.3208, LR=0.000100
[2025-08-27 17:42:08,896][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089024] [Batch 02784/03080] [00:33:38/00:03:34, 0.725s/it]: train_loss_raw=0.3884, running_loss=0.3231, LR=0.000100
[2025-08-27 17:42:14,553][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089032] [Batch 02792/03080] [00:33:44/00:03:28, 0.725s/it]: train_loss_raw=0.3092, running_loss=0.3228, LR=0.000100
[2025-08-27 17:42:20,124][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089040] [Batch 02800/03080] [00:33:49/00:03:22, 0.725s/it]: train_loss_raw=0.2995, running_loss=0.3228, LR=0.000100
[2025-08-27 17:42:25,954][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089048] [Batch 02808/03080] [00:33:55/00:03:17, 0.725s/it]: train_loss_raw=0.3790, running_loss=0.3232, LR=0.000100
[2025-08-27 17:42:31,797][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089056] [Batch 02816/03080] [00:34:01/00:03:11, 0.725s/it]: train_loss_raw=0.2703, running_loss=0.3210, LR=0.000100
[2025-08-27 17:42:37,860][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089064] [Batch 02824/03080] [00:34:07/00:03:05, 0.725s/it]: train_loss_raw=0.3362, running_loss=0.3213, LR=0.000100
[2025-08-27 17:42:44,016][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089072] [Batch 02832/03080] [00:34:13/00:02:59, 0.725s/it]: train_loss_raw=0.3387, running_loss=0.3208, LR=0.000100
[2025-08-27 17:42:50,087][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089080] [Batch 02840/03080] [00:34:19/00:02:54, 0.725s/it]: train_loss_raw=0.2279, running_loss=0.3208, LR=0.000100
[2025-08-27 17:42:55,769][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089088] [Batch 02848/03080] [00:34:25/00:02:48, 0.725s/it]: train_loss_raw=0.2750, running_loss=0.3183, LR=0.000100
[2025-08-27 17:43:01,672][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089096] [Batch 02856/03080] [00:34:31/00:02:42, 0.725s/it]: train_loss_raw=0.3789, running_loss=0.3187, LR=0.000100
[2025-08-27 17:43:07,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089104] [Batch 02864/03080] [00:34:36/00:02:36, 0.725s/it]: train_loss_raw=0.2388, running_loss=0.3202, LR=0.000100
[2025-08-27 17:43:13,369][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089112] [Batch 02872/03080] [00:34:42/00:02:30, 0.725s/it]: train_loss_raw=0.2442, running_loss=0.3207, LR=0.000100
[2025-08-27 17:43:19,345][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089120] [Batch 02880/03080] [00:34:48/00:02:25, 0.725s/it]: train_loss_raw=0.3150, running_loss=0.3208, LR=0.000100
[2025-08-27 17:43:25,227][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089128] [Batch 02888/03080] [00:34:54/00:02:19, 0.725s/it]: train_loss_raw=0.3689, running_loss=0.3208, LR=0.000100
[2025-08-27 17:43:30,922][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089136] [Batch 02896/03080] [00:35:00/00:02:13, 0.725s/it]: train_loss_raw=0.2595, running_loss=0.3206, LR=0.000100
[2025-08-27 17:43:36,742][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089144] [Batch 02904/03080] [00:35:06/00:02:07, 0.725s/it]: train_loss_raw=0.2491, running_loss=0.3205, LR=0.000100
[2025-08-27 17:43:42,482][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089152] [Batch 02912/03080] [00:35:12/00:02:01, 0.725s/it]: train_loss_raw=0.4083, running_loss=0.3218, LR=0.000100
[2025-08-27 17:43:48,230][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089160] [Batch 02920/03080] [00:35:17/00:01:56, 0.725s/it]: train_loss_raw=0.2842, running_loss=0.3206, LR=0.000100
[2025-08-27 17:43:54,040][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089168] [Batch 02928/03080] [00:35:23/00:01:50, 0.725s/it]: train_loss_raw=0.3234, running_loss=0.3224, LR=0.000100
[2025-08-27 17:43:59,757][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089176] [Batch 02936/03080] [00:35:29/00:01:44, 0.725s/it]: train_loss_raw=0.2939, running_loss=0.3210, LR=0.000100
[2025-08-27 17:44:05,297][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089184] [Batch 02944/03080] [00:35:34/00:01:38, 0.725s/it]: train_loss_raw=0.3969, running_loss=0.3211, LR=0.000100
[2025-08-27 17:44:10,685][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089192] [Batch 02952/03080] [00:35:40/00:01:32, 0.725s/it]: train_loss_raw=0.3669, running_loss=0.3222, LR=0.000100
[2025-08-27 17:44:16,498][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089200] [Batch 02960/03080] [00:35:46/00:01:27, 0.725s/it]: train_loss_raw=0.3067, running_loss=0.3229, LR=0.000100
[2025-08-27 17:44:22,449][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089208] [Batch 02968/03080] [00:35:52/00:01:21, 0.725s/it]: train_loss_raw=0.2569, running_loss=0.3232, LR=0.000100
[2025-08-27 17:44:28,360][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089216] [Batch 02976/03080] [00:35:57/00:01:15, 0.725s/it]: train_loss_raw=0.2869, running_loss=0.3216, LR=0.000100
[2025-08-27 17:44:34,236][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089224] [Batch 02984/03080] [00:36:03/00:01:09, 0.725s/it]: train_loss_raw=0.3088, running_loss=0.3209, LR=0.000100
[2025-08-27 17:44:39,809][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089232] [Batch 02992/03080] [00:36:09/00:01:03, 0.725s/it]: train_loss_raw=0.3597, running_loss=0.3228, LR=0.000100
[2025-08-27 17:44:45,933][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089240] [Batch 03000/03080] [00:36:15/00:00:58, 0.725s/it]: train_loss_raw=0.2943, running_loss=0.3240, LR=0.000100
[2025-08-27 17:44:52,139][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089248] [Batch 03008/03080] [00:36:21/00:00:52, 0.725s/it]: train_loss_raw=0.3486, running_loss=0.3255, LR=0.000100
[2025-08-27 17:44:58,130][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089256] [Batch 03016/03080] [00:36:27/00:00:46, 0.725s/it]: train_loss_raw=0.2724, running_loss=0.3263, LR=0.000100
[2025-08-27 17:45:04,013][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089264] [Batch 03024/03080] [00:36:33/00:00:40, 0.725s/it]: train_loss_raw=0.3244, running_loss=0.3261, LR=0.000100
[2025-08-27 17:45:09,789][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089272] [Batch 03032/03080] [00:36:39/00:00:34, 0.725s/it]: train_loss_raw=0.3540, running_loss=0.3264, LR=0.000100
[2025-08-27 17:45:15,133][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089280] [Batch 03040/03080] [00:36:44/00:00:29, 0.725s/it]: train_loss_raw=0.2889, running_loss=0.3255, LR=0.000100
[2025-08-27 17:45:20,829][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089288] [Batch 03048/03080] [00:36:50/00:00:23, 0.725s/it]: train_loss_raw=0.3925, running_loss=0.3270, LR=0.000100
[2025-08-27 17:45:26,903][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089296] [Batch 03056/03080] [00:36:56/00:00:17, 0.725s/it]: train_loss_raw=0.3255, running_loss=0.3281, LR=0.000100
[2025-08-27 17:45:32,768][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089304] [Batch 03064/03080] [00:37:02/00:00:11, 0.725s/it]: train_loss_raw=0.3465, running_loss=0.3291, LR=0.000100
[2025-08-27 17:45:38,707][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089312] [Batch 03072/03080] [00:37:08/00:00:05, 0.725s/it]: train_loss_raw=0.3269, running_loss=0.3267, LR=0.000100
[2025-08-27 17:45:44,851][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089320] [Batch 03080/03080] [00:37:14/00:00:00, 0.725s/it]: train_loss_raw=0.3531, running_loss=0.3268, LR=0.000100
[2025-08-27 17:45:45,370][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-27 17:45:56,597][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00007/00310] [00:00:11/00:07:03, 1.403s/it]
[2025-08-27 17:46:07,867][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00015/00310] [00:00:22/00:06:53, 1.406s/it]
[2025-08-27 17:46:18,799][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00023/00310] [00:00:33/00:06:38, 1.393s/it]
[2025-08-27 17:46:30,914][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00031/00310] [00:00:45/00:06:35, 1.423s/it]
[2025-08-27 17:46:43,451][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00039/00310] [00:00:58/00:06:32, 1.452s/it]
[2025-08-27 17:46:55,201][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00047/00310] [00:01:09/00:06:21, 1.455s/it]
[2025-08-27 17:47:07,308][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00055/00310] [00:01:21/00:06:11, 1.463s/it]
[2025-08-27 17:47:19,059][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00063/00310] [00:01:33/00:06:00, 1.464s/it]
[2025-08-27 17:47:31,584][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00071/00310] [00:01:46/00:05:51, 1.475s/it]
[2025-08-27 17:47:43,711][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00079/00310] [00:01:58/00:05:40, 1.479s/it]
[2025-08-27 17:47:55,205][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00087/00310] [00:02:09/00:05:27, 1.475s/it]
[2025-08-27 17:48:07,104][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00095/00310] [00:02:21/00:05:15, 1.476s/it]
[2025-08-27 17:48:19,183][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00103/00310] [00:02:33/00:05:04, 1.479s/it]
[2025-08-27 17:48:30,759][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00111/00310] [00:02:45/00:04:52, 1.477s/it]
[2025-08-27 17:48:42,850][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00119/00310] [00:02:57/00:04:41, 1.479s/it]
[2025-08-27 17:48:54,169][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00127/00310] [00:03:08/00:04:28, 1.475s/it]
[2025-08-27 17:49:05,381][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00135/00310] [00:03:20/00:04:15, 1.471s/it]
[2025-08-27 17:49:17,721][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00143/00310] [00:03:32/00:04:04, 1.475s/it]
[2025-08-27 17:49:27,356][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00151/00310] [00:03:41/00:03:50, 1.460s/it]
[2025-08-27 17:49:38,020][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00159/00310] [00:03:52/00:03:38, 1.454s/it]
[2025-08-27 17:49:49,792][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00167/00310] [00:04:04/00:03:26, 1.455s/it]
[2025-08-27 17:49:59,178][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00175/00310] [00:04:13/00:03:13, 1.442s/it]
[2025-08-27 17:50:09,749][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00183/00310] [00:04:24/00:03:01, 1.437s/it]
[2025-08-27 17:50:21,591][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00191/00310] [00:04:36/00:02:49, 1.439s/it]
[2025-08-27 17:50:33,482][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00199/00310] [00:04:48/00:02:38, 1.441s/it]
[2025-08-27 17:50:44,821][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00207/00310] [00:04:59/00:02:26, 1.440s/it]
[2025-08-27 17:50:55,118][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00215/00310] [00:05:09/00:02:14, 1.434s/it]
[2025-08-27 17:51:05,569][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00223/00310] [00:05:20/00:02:02, 1.429s/it]
[2025-08-27 17:51:17,470][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00231/00310] [00:05:32/00:01:51, 1.431s/it]
[2025-08-27 17:51:27,849][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00239/00310] [00:05:42/00:01:39, 1.427s/it]
[2025-08-27 17:51:37,619][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00247/00310] [00:05:52/00:01:28, 1.420s/it]
[2025-08-27 17:51:48,638][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00255/00310] [00:06:03/00:01:16, 1.419s/it]
[2025-08-27 17:52:00,251][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00263/00310] [00:06:14/00:01:05, 1.420s/it]
[2025-08-27 17:52:11,831][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00271/00310] [00:06:26/00:00:53, 1.421s/it]
[2025-08-27 17:52:23,646][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00279/00310] [00:06:38/00:00:42, 1.422s/it]
[2025-08-27 17:52:35,416][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00287/00310] [00:06:50/00:00:31, 1.424s/it]
[2025-08-27 17:52:46,056][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00295/00310] [00:07:00/00:00:19, 1.421s/it]
[2025-08-27 17:52:57,022][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00303/00310] [00:07:11/00:00:08, 1.420s/it]
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.32683, valid_loss=1.43938
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.476
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.162
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.166
[2025-08-27 17:53:05,928][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.089
[2025-08-27 17:53:05,938][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 22:26:19, remaining time 00:46:25, 00:46:25 per epoch
[2025-08-27 17:53:19,466][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089328] [Batch 00008/03080] [00:00:13/01:24:41, 1.654s/it]: train_loss_raw=0.3634, running_loss=0.3084, LR=0.000100
[2025-08-27 17:53:25,468][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089336] [Batch 00016/03080] [00:00:19/01:01:23, 1.202s/it]: train_loss_raw=0.3409, running_loss=0.3118, LR=0.000100
[2025-08-27 17:53:31,467][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089344] [Batch 00024/03080] [00:00:25/00:53:33, 1.051s/it]: train_loss_raw=0.4199, running_loss=0.3125, LR=0.000100
[2025-08-27 17:53:37,413][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089352] [Batch 00032/03080] [00:00:31/00:49:29, 0.974s/it]: train_loss_raw=0.2902, running_loss=0.3110, LR=0.000100
[2025-08-27 17:53:43,299][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089360] [Batch 00040/03080] [00:00:37/00:46:57, 0.927s/it]: train_loss_raw=0.3951, running_loss=0.3112, LR=0.000100
[2025-08-27 17:53:49,066][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089368] [Batch 00048/03080] [00:00:42/00:45:05, 0.892s/it]: train_loss_raw=0.3063, running_loss=0.3117, LR=0.000100
[2025-08-27 17:53:55,090][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089376] [Batch 00056/03080] [00:00:48/00:43:58, 0.872s/it]: train_loss_raw=0.3219, running_loss=0.3137, LR=0.000100
[2025-08-27 17:54:01,080][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089384] [Batch 00064/03080] [00:00:54/00:43:04, 0.857s/it]: train_loss_raw=0.3150, running_loss=0.3155, LR=0.000100
[2025-08-27 17:54:07,180][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089392] [Batch 00072/03080] [00:01:00/00:42:26, 0.847s/it]: train_loss_raw=0.3232, running_loss=0.3175, LR=0.000100
[2025-08-27 17:54:13,102][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089400] [Batch 00080/03080] [00:01:06/00:41:47, 0.836s/it]: train_loss_raw=0.3633, running_loss=0.3188, LR=0.000100
[2025-08-27 17:54:19,085][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089408] [Batch 00088/03080] [00:01:12/00:41:16, 0.828s/it]: train_loss_raw=0.3790, running_loss=0.3201, LR=0.000100
[2025-08-27 17:54:25,106][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089416] [Batch 00096/03080] [00:01:18/00:40:51, 0.822s/it]: train_loss_raw=0.4093, running_loss=0.3208, LR=0.000100
[2025-08-27 17:54:30,939][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089424] [Batch 00104/03080] [00:01:24/00:40:23, 0.814s/it]: train_loss_raw=0.2914, running_loss=0.3220, LR=0.000100
[2025-08-27 17:54:36,542][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089432] [Batch 00112/03080] [00:01:30/00:39:53, 0.806s/it]: train_loss_raw=0.2814, running_loss=0.3215, LR=0.000100
[2025-08-27 17:54:42,183][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089440] [Batch 00120/03080] [00:01:35/00:39:26, 0.800s/it]: train_loss_raw=0.3054, running_loss=0.3213, LR=0.000100
[2025-08-27 17:54:48,054][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089448] [Batch 00128/03080] [00:01:41/00:39:08, 0.795s/it]: train_loss_raw=0.3201, running_loss=0.3223, LR=0.000100
[2025-08-27 17:54:54,011][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089456] [Batch 00136/03080] [00:01:47/00:38:53, 0.792s/it]: train_loss_raw=0.3556, running_loss=0.3217, LR=0.000100
[2025-08-27 17:54:59,611][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089464] [Batch 00144/03080] [00:01:53/00:38:31, 0.787s/it]: train_loss_raw=0.3310, running_loss=0.3220, LR=0.000100
[2025-08-27 17:55:05,705][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089472] [Batch 00152/03080] [00:01:59/00:38:21, 0.786s/it]: train_loss_raw=0.2934, running_loss=0.3222, LR=0.000100
[2025-08-27 17:55:11,406][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089480] [Batch 00160/03080] [00:02:05/00:38:04, 0.782s/it]: train_loss_raw=0.3461, running_loss=0.3231, LR=0.000100
[2025-08-27 17:55:17,012][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089488] [Batch 00168/03080] [00:02:10/00:37:46, 0.778s/it]: train_loss_raw=0.2927, running_loss=0.3236, LR=0.000100
[2025-08-27 17:55:22,809][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089496] [Batch 00176/03080] [00:02:16/00:37:33, 0.776s/it]: train_loss_raw=0.3373, running_loss=0.3228, LR=0.000100
[2025-08-27 17:55:28,759][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089504] [Batch 00184/03080] [00:02:22/00:37:23, 0.775s/it]: train_loss_raw=0.3618, running_loss=0.3227, LR=0.000100
[2025-08-27 17:55:34,364][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089512] [Batch 00192/03080] [00:02:28/00:37:08, 0.772s/it]: train_loss_raw=0.2638, running_loss=0.3220, LR=0.000100
[2025-08-27 17:55:40,192][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089520] [Batch 00200/03080] [00:02:33/00:36:57, 0.770s/it]: train_loss_raw=0.3287, running_loss=0.3224, LR=0.000100
[2025-08-27 17:55:45,561][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089528] [Batch 00208/03080] [00:02:39/00:36:39, 0.766s/it]: train_loss_raw=0.2920, running_loss=0.3220, LR=0.000100
[2025-08-27 17:55:51,159][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089536] [Batch 00216/03080] [00:02:44/00:36:26, 0.764s/it]: train_loss_raw=0.3149, running_loss=0.3222, LR=0.000100
[2025-08-27 17:55:57,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089544] [Batch 00224/03080] [00:02:50/00:36:18, 0.763s/it]: train_loss_raw=0.2599, running_loss=0.3204, LR=0.000100
[2025-08-27 17:56:03,059][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089552] [Batch 00232/03080] [00:02:56/00:36:10, 0.762s/it]: train_loss_raw=0.3535, running_loss=0.3220, LR=0.000100
[2025-08-27 17:56:08,846][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089560] [Batch 00240/03080] [00:03:02/00:36:00, 0.761s/it]: train_loss_raw=0.3302, running_loss=0.3224, LR=0.000100
[2025-08-27 17:56:14,781][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089568] [Batch 00248/03080] [00:03:08/00:35:53, 0.760s/it]: train_loss_raw=0.2717, running_loss=0.3203, LR=0.000100
[2025-08-27 17:56:20,696][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089576] [Batch 00256/03080] [00:03:14/00:35:45, 0.760s/it]: train_loss_raw=0.2976, running_loss=0.3200, LR=0.000100
[2025-08-27 17:56:26,317][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089584] [Batch 00264/03080] [00:03:20/00:35:34, 0.758s/it]: train_loss_raw=0.2881, running_loss=0.3191, LR=0.000100
[2025-08-27 17:56:31,801][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089592] [Batch 00272/03080] [00:03:25/00:35:22, 0.756s/it]: train_loss_raw=0.3233, running_loss=0.3188, LR=0.000100
[2025-08-27 17:56:37,811][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089600] [Batch 00280/03080] [00:03:31/00:35:15, 0.756s/it]: train_loss_raw=0.3520, running_loss=0.3175, LR=0.000100
[2025-08-27 17:56:43,589][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089608] [Batch 00288/03080] [00:03:37/00:35:07, 0.755s/it]: train_loss_raw=0.3573, running_loss=0.3182, LR=0.000100
[2025-08-27 17:56:49,322][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089616] [Batch 00296/03080] [00:03:43/00:34:58, 0.754s/it]: train_loss_raw=0.3153, running_loss=0.3180, LR=0.000100
[2025-08-27 17:56:55,079][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089624] [Batch 00304/03080] [00:03:48/00:34:49, 0.753s/it]: train_loss_raw=0.2174, running_loss=0.3167, LR=0.000100
[2025-08-27 17:57:01,067][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089632] [Batch 00312/03080] [00:03:54/00:34:43, 0.753s/it]: train_loss_raw=0.3071, running_loss=0.3178, LR=0.000100
[2025-08-27 17:57:06,624][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089640] [Batch 00320/03080] [00:04:00/00:34:33, 0.751s/it]: train_loss_raw=0.3034, running_loss=0.3185, LR=0.000100
[2025-08-27 17:57:12,232][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089648] [Batch 00328/03080] [00:04:06/00:34:24, 0.750s/it]: train_loss_raw=0.3342, running_loss=0.3179, LR=0.000100
[2025-08-27 17:57:18,238][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089656] [Batch 00336/03080] [00:04:12/00:34:18, 0.750s/it]: train_loss_raw=0.3626, running_loss=0.3190, LR=0.000100
[2025-08-27 17:57:24,236][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089664] [Batch 00344/03080] [00:04:18/00:34:12, 0.750s/it]: train_loss_raw=0.3758, running_loss=0.3170, LR=0.000100
[2025-08-27 17:57:30,225][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089672] [Batch 00352/03080] [00:04:23/00:34:05, 0.750s/it]: train_loss_raw=0.3219, running_loss=0.3162, LR=0.000100
[2025-08-27 17:57:36,416][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089680] [Batch 00360/03080] [00:04:30/00:34:01, 0.751s/it]: train_loss_raw=0.3419, running_loss=0.3166, LR=0.000100
[2025-08-27 17:57:42,489][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089688] [Batch 00368/03080] [00:04:36/00:33:55, 0.751s/it]: train_loss_raw=0.3135, running_loss=0.3166, LR=0.000100
[2025-08-27 17:57:48,459][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089696] [Batch 00376/03080] [00:04:42/00:33:49, 0.751s/it]: train_loss_raw=0.3400, running_loss=0.3156, LR=0.000100
[2025-08-27 17:57:54,487][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089704] [Batch 00384/03080] [00:04:48/00:33:43, 0.751s/it]: train_loss_raw=0.3137, running_loss=0.3182, LR=0.000100
[2025-08-27 17:58:00,044][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089712] [Batch 00392/03080] [00:04:53/00:33:34, 0.750s/it]: train_loss_raw=0.3277, running_loss=0.3176, LR=0.000100
[2025-08-27 17:58:06,184][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089720] [Batch 00400/03080] [00:04:59/00:33:29, 0.750s/it]: train_loss_raw=0.3085, running_loss=0.3151, LR=0.000100
[2025-08-27 17:58:12,205][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089728] [Batch 00408/03080] [00:05:05/00:33:23, 0.750s/it]: train_loss_raw=0.2675, running_loss=0.3166, LR=0.000100
[2025-08-27 17:58:17,892][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089736] [Batch 00416/03080] [00:05:11/00:33:15, 0.749s/it]: train_loss_raw=0.3466, running_loss=0.3192, LR=0.000100
[2025-08-27 17:58:23,518][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089744] [Batch 00424/03080] [00:05:17/00:33:07, 0.748s/it]: train_loss_raw=0.3115, running_loss=0.3175, LR=0.000100
[2025-08-27 17:58:29,247][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089752] [Batch 00432/03080] [00:05:23/00:32:59, 0.748s/it]: train_loss_raw=0.2639, running_loss=0.3176, LR=0.000100
[2025-08-27 17:58:34,704][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089760] [Batch 00440/03080] [00:05:28/00:32:50, 0.747s/it]: train_loss_raw=0.3274, running_loss=0.3168, LR=0.000100
[2025-08-27 17:58:40,506][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089768] [Batch 00448/03080] [00:05:34/00:32:43, 0.746s/it]: train_loss_raw=0.3193, running_loss=0.3169, LR=0.000100
[2025-08-27 17:58:46,273][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089776] [Batch 00456/03080] [00:05:40/00:32:36, 0.746s/it]: train_loss_raw=0.3204, running_loss=0.3160, LR=0.000100
[2025-08-27 17:58:51,839][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089784] [Batch 00464/03080] [00:05:45/00:32:28, 0.745s/it]: train_loss_raw=0.3126, running_loss=0.3152, LR=0.000100
[2025-08-27 17:58:57,360][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089792] [Batch 00472/03080] [00:05:51/00:32:20, 0.744s/it]: train_loss_raw=0.3492, running_loss=0.3149, LR=0.000100
[2025-08-27 17:59:03,217][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089800] [Batch 00480/03080] [00:05:56/00:32:13, 0.744s/it]: train_loss_raw=0.2796, running_loss=0.3148, LR=0.000100
[2025-08-27 17:59:08,552][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089808] [Batch 00488/03080] [00:06:02/00:32:04, 0.742s/it]: train_loss_raw=0.3719, running_loss=0.3158, LR=0.000100
[2025-08-27 17:59:14,601][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089816] [Batch 00496/03080] [00:06:08/00:31:59, 0.743s/it]: train_loss_raw=0.2582, running_loss=0.3176, LR=0.000100
[2025-08-27 17:59:20,601][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089824] [Batch 00504/03080] [00:06:14/00:31:53, 0.743s/it]: train_loss_raw=0.3856, running_loss=0.3209, LR=0.000100
[2025-08-27 17:59:26,328][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089832] [Batch 00512/03080] [00:06:20/00:31:46, 0.742s/it]: train_loss_raw=0.3335, running_loss=0.3209, LR=0.000100
[2025-08-27 17:59:32,147][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089840] [Batch 00520/03080] [00:06:25/00:31:39, 0.742s/it]: train_loss_raw=0.2830, running_loss=0.3217, LR=0.000100
[2025-08-27 17:59:38,096][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089848] [Batch 00528/03080] [00:06:31/00:31:34, 0.742s/it]: train_loss_raw=0.2770, running_loss=0.3213, LR=0.000100
[2025-08-27 17:59:43,557][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089856] [Batch 00536/03080] [00:06:37/00:31:25, 0.741s/it]: train_loss_raw=0.3530, running_loss=0.3222, LR=0.000100
[2025-08-27 17:59:49,258][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089864] [Batch 00544/03080] [00:06:43/00:31:18, 0.741s/it]: train_loss_raw=0.3276, running_loss=0.3219, LR=0.000100
[2025-08-27 17:59:55,103][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089872] [Batch 00552/03080] [00:06:48/00:31:12, 0.741s/it]: train_loss_raw=0.2949, running_loss=0.3215, LR=0.000100
[2025-08-27 18:00:00,646][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089880] [Batch 00560/03080] [00:06:54/00:31:04, 0.740s/it]: train_loss_raw=0.3350, running_loss=0.3213, LR=0.000100
[2025-08-27 18:00:06,630][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089888] [Batch 00568/03080] [00:07:00/00:30:59, 0.740s/it]: train_loss_raw=0.3521, running_loss=0.3217, LR=0.000100
[2025-08-27 18:00:12,302][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089896] [Batch 00576/03080] [00:07:06/00:30:52, 0.740s/it]: train_loss_raw=0.3245, running_loss=0.3205, LR=0.000100
[2025-08-27 18:00:18,172][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089904] [Batch 00584/03080] [00:07:11/00:30:46, 0.740s/it]: train_loss_raw=0.3392, running_loss=0.3217, LR=0.000100
[2025-08-27 18:00:24,233][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089912] [Batch 00592/03080] [00:07:18/00:30:40, 0.740s/it]: train_loss_raw=0.2863, running_loss=0.3215, LR=0.000100
[2025-08-27 18:00:30,389][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089920] [Batch 00600/03080] [00:07:24/00:30:35, 0.740s/it]: train_loss_raw=0.3308, running_loss=0.3197, LR=0.000100
[2025-08-27 18:00:36,174][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089928] [Batch 00608/03080] [00:07:29/00:30:29, 0.740s/it]: train_loss_raw=0.2800, running_loss=0.3203, LR=0.000100
[2025-08-27 18:00:42,135][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089936] [Batch 00616/03080] [00:07:35/00:30:23, 0.740s/it]: train_loss_raw=0.3491, running_loss=0.3194, LR=0.000100
[2025-08-27 18:00:47,805][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089944] [Batch 00624/03080] [00:07:41/00:30:16, 0.740s/it]: train_loss_raw=0.2889, running_loss=0.3196, LR=0.000100
[2025-08-27 18:00:53,770][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089952] [Batch 00632/03080] [00:07:47/00:30:10, 0.740s/it]: train_loss_raw=0.3050, running_loss=0.3204, LR=0.000100
[2025-08-27 18:00:59,619][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089960] [Batch 00640/03080] [00:07:53/00:30:04, 0.740s/it]: train_loss_raw=0.3009, running_loss=0.3197, LR=0.000100
[2025-08-27 18:01:05,184][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089968] [Batch 00648/03080] [00:07:58/00:29:57, 0.739s/it]: train_loss_raw=0.2645, running_loss=0.3197, LR=0.000100
[2025-08-27 18:01:11,132][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089976] [Batch 00656/03080] [00:08:04/00:29:51, 0.739s/it]: train_loss_raw=0.2607, running_loss=0.3196, LR=0.000100
[2025-08-27 18:01:17,285][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089984] [Batch 00664/03080] [00:08:11/00:29:46, 0.740s/it]: train_loss_raw=0.3064, running_loss=0.3177, LR=0.000100
[2025-08-27 18:01:23,176][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089992] [Batch 00672/03080] [00:08:16/00:29:40, 0.739s/it]: train_loss_raw=0.3433, running_loss=0.3184, LR=0.000100
[2025-08-27 18:01:29,141][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090000] [Batch 00680/03080] [00:08:22/00:29:34, 0.740s/it]: train_loss_raw=0.3444, running_loss=0.3178, LR=0.000100
[2025-08-27 18:01:39,262][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090008] [Batch 00688/03080] [00:08:33/00:29:43, 0.746s/it]: train_loss_raw=0.3124, running_loss=0.3185, LR=0.000100
[2025-08-27 18:01:45,489][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090016] [Batch 00696/03080] [00:08:39/00:29:38, 0.746s/it]: train_loss_raw=0.2991, running_loss=0.3182, LR=0.000100
[2025-08-27 18:01:51,400][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090024] [Batch 00704/03080] [00:08:45/00:29:32, 0.746s/it]: train_loss_raw=0.3240, running_loss=0.3168, LR=0.000100
[2025-08-27 18:01:57,159][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090032] [Batch 00712/03080] [00:08:50/00:29:25, 0.746s/it]: train_loss_raw=0.3025, running_loss=0.3199, LR=0.000100
[2025-08-27 18:02:03,265][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090040] [Batch 00720/03080] [00:08:57/00:29:20, 0.746s/it]: train_loss_raw=0.2862, running_loss=0.3209, LR=0.000100
[2025-08-27 18:02:09,086][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090048] [Batch 00728/03080] [00:09:02/00:29:13, 0.746s/it]: train_loss_raw=0.3489, running_loss=0.3217, LR=0.000100
[2025-08-27 18:02:14,496][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090056] [Batch 00736/03080] [00:09:08/00:29:06, 0.745s/it]: train_loss_raw=0.3490, running_loss=0.3227, LR=0.000100
[2025-08-27 18:02:20,048][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090064] [Batch 00744/03080] [00:09:13/00:28:58, 0.744s/it]: train_loss_raw=0.2815, running_loss=0.3228, LR=0.000100
[2025-08-27 18:02:25,890][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090072] [Batch 00752/03080] [00:09:19/00:28:52, 0.744s/it]: train_loss_raw=0.3011, running_loss=0.3239, LR=0.000100
[2025-08-27 18:02:31,736][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090080] [Batch 00760/03080] [00:09:25/00:28:46, 0.744s/it]: train_loss_raw=0.3299, running_loss=0.3254, LR=0.000100
[2025-08-27 18:02:37,658][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090088] [Batch 00768/03080] [00:09:31/00:28:40, 0.744s/it]: train_loss_raw=0.2777, running_loss=0.3257, LR=0.000100
[2025-08-27 18:02:43,089][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090096] [Batch 00776/03080] [00:09:36/00:28:32, 0.743s/it]: train_loss_raw=0.3298, running_loss=0.3258, LR=0.000100
[2025-08-27 18:02:48,803][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090104] [Batch 00784/03080] [00:09:42/00:28:26, 0.743s/it]: train_loss_raw=0.2600, running_loss=0.3251, LR=0.000100
[2025-08-27 18:02:54,887][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090112] [Batch 00792/03080] [00:09:48/00:28:20, 0.743s/it]: train_loss_raw=0.3898, running_loss=0.3250, LR=0.000100
[2025-08-27 18:03:00,790][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090120] [Batch 00800/03080] [00:09:54/00:28:14, 0.743s/it]: train_loss_raw=0.2674, running_loss=0.3250, LR=0.000100
[2025-08-27 18:03:06,960][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090128] [Batch 00808/03080] [00:10:00/00:28:09, 0.743s/it]: train_loss_raw=0.3873, running_loss=0.3266, LR=0.000100
[2025-08-27 18:03:12,827][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090136] [Batch 00816/03080] [00:10:06/00:28:03, 0.743s/it]: train_loss_raw=0.3427, running_loss=0.3281, LR=0.000100
[2025-08-27 18:03:18,443][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090144] [Batch 00824/03080] [00:10:12/00:27:56, 0.743s/it]: train_loss_raw=0.2764, running_loss=0.3253, LR=0.000100
[2025-08-27 18:03:23,902][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090152] [Batch 00832/03080] [00:10:17/00:27:48, 0.742s/it]: train_loss_raw=0.3025, running_loss=0.3250, LR=0.000100
[2025-08-27 18:03:29,319][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090160] [Batch 00840/03080] [00:10:23/00:27:41, 0.742s/it]: train_loss_raw=0.3342, running_loss=0.3255, LR=0.000100
[2025-08-27 18:03:34,906][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090168] [Batch 00848/03080] [00:10:28/00:27:34, 0.741s/it]: train_loss_raw=0.3430, running_loss=0.3263, LR=0.000100
[2025-08-27 18:03:40,910][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090176] [Batch 00856/03080] [00:10:34/00:27:28, 0.741s/it]: train_loss_raw=0.4094, running_loss=0.3271, LR=0.000100
[2025-08-27 18:03:46,741][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090184] [Batch 00864/03080] [00:10:40/00:27:22, 0.741s/it]: train_loss_raw=0.3740, running_loss=0.3271, LR=0.000100
[2025-08-27 18:03:52,953][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090192] [Batch 00872/03080] [00:10:46/00:27:17, 0.742s/it]: train_loss_raw=0.3400, running_loss=0.3270, LR=0.000100
[2025-08-27 18:03:58,870][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090200] [Batch 00880/03080] [00:10:52/00:27:11, 0.742s/it]: train_loss_raw=0.2587, running_loss=0.3245, LR=0.000100
[2025-08-27 18:04:04,665][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090208] [Batch 00888/03080] [00:10:58/00:27:05, 0.741s/it]: train_loss_raw=0.3554, running_loss=0.3260, LR=0.000100
[2025-08-27 18:04:10,509][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090216] [Batch 00896/03080] [00:11:04/00:26:59, 0.741s/it]: train_loss_raw=0.3340, running_loss=0.3249, LR=0.000100
[2025-08-27 18:04:16,166][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090224] [Batch 00904/03080] [00:11:09/00:26:52, 0.741s/it]: train_loss_raw=0.4021, running_loss=0.3241, LR=0.000100
[2025-08-27 18:04:22,173][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090232] [Batch 00912/03080] [00:11:15/00:26:46, 0.741s/it]: train_loss_raw=0.3065, running_loss=0.3230, LR=0.000100
[2025-08-27 18:04:28,254][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090240] [Batch 00920/03080] [00:11:22/00:26:41, 0.741s/it]: train_loss_raw=0.3174, running_loss=0.3232, LR=0.000100
[2025-08-27 18:04:34,278][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090248] [Batch 00928/03080] [00:11:28/00:26:35, 0.741s/it]: train_loss_raw=0.3147, running_loss=0.3235, LR=0.000100
[2025-08-27 18:04:39,625][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090256] [Batch 00936/03080] [00:11:33/00:26:28, 0.741s/it]: train_loss_raw=0.3557, running_loss=0.3233, LR=0.000100
[2025-08-27 18:04:45,163][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090264] [Batch 00944/03080] [00:11:38/00:26:21, 0.740s/it]: train_loss_raw=0.3525, running_loss=0.3251, LR=0.000100
[2025-08-27 18:04:50,774][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090272] [Batch 00952/03080] [00:11:44/00:26:14, 0.740s/it]: train_loss_raw=0.3388, running_loss=0.3270, LR=0.000100
[2025-08-27 18:04:56,309][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090280] [Batch 00960/03080] [00:11:50/00:26:08, 0.740s/it]: train_loss_raw=0.3004, running_loss=0.3267, LR=0.000100
[2025-08-27 18:05:02,065][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090288] [Batch 00968/03080] [00:11:55/00:26:01, 0.739s/it]: train_loss_raw=0.2914, running_loss=0.3268, LR=0.000100
[2025-08-27 18:05:07,598][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090296] [Batch 00976/03080] [00:12:01/00:25:55, 0.739s/it]: train_loss_raw=0.3902, running_loss=0.3283, LR=0.000100
[2025-08-27 18:05:13,490][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090304] [Batch 00984/03080] [00:12:07/00:25:49, 0.739s/it]: train_loss_raw=0.2167, running_loss=0.3267, LR=0.000100
[2025-08-27 18:05:19,219][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090312] [Batch 00992/03080] [00:12:12/00:25:42, 0.739s/it]: train_loss_raw=0.3306, running_loss=0.3270, LR=0.000100
[2025-08-27 18:05:25,004][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090320] [Batch 01000/03080] [00:12:18/00:25:36, 0.739s/it]: train_loss_raw=0.4108, running_loss=0.3265, LR=0.000100
[2025-08-27 18:05:30,753][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090328] [Batch 01008/03080] [00:12:24/00:25:30, 0.739s/it]: train_loss_raw=0.3970, running_loss=0.3270, LR=0.000100
[2025-08-27 18:05:36,330][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090336] [Batch 01016/03080] [00:12:30/00:25:23, 0.738s/it]: train_loss_raw=0.3602, running_loss=0.3261, LR=0.000100
[2025-08-27 18:05:42,197][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090344] [Batch 01024/03080] [00:12:35/00:25:17, 0.738s/it]: train_loss_raw=0.3304, running_loss=0.3264, LR=0.000100
[2025-08-27 18:05:47,785][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090352] [Batch 01032/03080] [00:12:41/00:25:11, 0.738s/it]: train_loss_raw=0.4006, running_loss=0.3258, LR=0.000100
[2025-08-27 18:05:53,431][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090360] [Batch 01040/03080] [00:12:47/00:25:04, 0.738s/it]: train_loss_raw=0.3743, running_loss=0.3262, LR=0.000100
[2025-08-27 18:05:59,064][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090368] [Batch 01048/03080] [00:12:52/00:24:58, 0.737s/it]: train_loss_raw=0.3038, running_loss=0.3264, LR=0.000100
[2025-08-27 18:06:05,242][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090376] [Batch 01056/03080] [00:12:59/00:24:53, 0.738s/it]: train_loss_raw=0.3048, running_loss=0.3262, LR=0.000100
[2025-08-27 18:06:11,248][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090384] [Batch 01064/03080] [00:13:05/00:24:47, 0.738s/it]: train_loss_raw=0.2988, running_loss=0.3275, LR=0.000100
[2025-08-27 18:06:17,500][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090392] [Batch 01072/03080] [00:13:11/00:24:42, 0.738s/it]: train_loss_raw=0.3112, running_loss=0.3261, LR=0.000100
[2025-08-27 18:06:23,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090400] [Batch 01080/03080] [00:13:17/00:24:36, 0.738s/it]: train_loss_raw=0.2873, running_loss=0.3260, LR=0.000100
[2025-08-27 18:06:29,329][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090408] [Batch 01088/03080] [00:13:23/00:24:30, 0.738s/it]: train_loss_raw=0.3715, running_loss=0.3260, LR=0.000100
[2025-08-27 18:06:35,359][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090416] [Batch 01096/03080] [00:13:29/00:24:24, 0.738s/it]: train_loss_raw=0.3337, running_loss=0.3266, LR=0.000100
[2025-08-27 18:06:41,109][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090424] [Batch 01104/03080] [00:13:34/00:24:18, 0.738s/it]: train_loss_raw=0.3286, running_loss=0.3247, LR=0.000100
[2025-08-27 18:06:46,755][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090432] [Batch 01112/03080] [00:13:40/00:24:12, 0.738s/it]: train_loss_raw=0.3153, running_loss=0.3237, LR=0.000100
[2025-08-27 18:06:52,626][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090440] [Batch 01120/03080] [00:13:46/00:24:06, 0.738s/it]: train_loss_raw=0.3385, running_loss=0.3255, LR=0.000100
[2025-08-27 18:06:58,630][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090448] [Batch 01128/03080] [00:13:52/00:24:00, 0.738s/it]: train_loss_raw=0.3095, running_loss=0.3234, LR=0.000100
[2025-08-27 18:07:04,465][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090456] [Batch 01136/03080] [00:13:58/00:23:54, 0.738s/it]: train_loss_raw=0.2750, running_loss=0.3253, LR=0.000100
[2025-08-27 18:07:10,180][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090464] [Batch 01144/03080] [00:14:03/00:23:48, 0.738s/it]: train_loss_raw=0.3121, running_loss=0.3256, LR=0.000100
[2025-08-27 18:07:16,073][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090472] [Batch 01152/03080] [00:14:09/00:23:42, 0.738s/it]: train_loss_raw=0.3472, running_loss=0.3232, LR=0.000100
[2025-08-27 18:07:22,032][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090480] [Batch 01160/03080] [00:14:15/00:23:36, 0.738s/it]: train_loss_raw=0.2463, running_loss=0.3222, LR=0.000100
[2025-08-27 18:07:28,131][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090488] [Batch 01168/03080] [00:14:21/00:23:30, 0.738s/it]: train_loss_raw=0.4104, running_loss=0.3228, LR=0.000100
[2025-08-27 18:07:33,764][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090496] [Batch 01176/03080] [00:14:27/00:23:24, 0.738s/it]: train_loss_raw=0.3176, running_loss=0.3224, LR=0.000100
[2025-08-27 18:07:39,135][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090504] [Batch 01184/03080] [00:14:32/00:23:17, 0.737s/it]: train_loss_raw=0.3167, running_loss=0.3230, LR=0.000100
[2025-08-27 18:07:44,520][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090512] [Batch 01192/03080] [00:14:38/00:23:11, 0.737s/it]: train_loss_raw=0.2976, running_loss=0.3208, LR=0.000100
[2025-08-27 18:07:50,335][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090520] [Batch 01200/03080] [00:14:44/00:23:05, 0.737s/it]: train_loss_raw=0.3078, running_loss=0.3214, LR=0.000100
[2025-08-27 18:07:55,703][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090528] [Batch 01208/03080] [00:14:49/00:22:58, 0.736s/it]: train_loss_raw=0.2725, running_loss=0.3223, LR=0.000100
[2025-08-27 18:08:01,369][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090536] [Batch 01216/03080] [00:14:55/00:22:52, 0.736s/it]: train_loss_raw=0.4594, running_loss=0.3261, LR=0.000100
[2025-08-27 18:08:07,627][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090544] [Batch 01224/03080] [00:15:01/00:22:46, 0.736s/it]: train_loss_raw=0.3591, running_loss=0.3247, LR=0.000100
[2025-08-27 18:08:13,783][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090552] [Batch 01232/03080] [00:15:07/00:22:41, 0.737s/it]: train_loss_raw=0.2606, running_loss=0.3226, LR=0.000100
[2025-08-27 18:08:19,474][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090560] [Batch 01240/03080] [00:15:13/00:22:35, 0.736s/it]: train_loss_raw=0.2958, running_loss=0.3225, LR=0.000100
[2025-08-27 18:08:25,503][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090568] [Batch 01248/03080] [00:15:19/00:22:29, 0.737s/it]: train_loss_raw=0.3224, running_loss=0.3237, LR=0.000100
[2025-08-27 18:08:31,901][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090576] [Batch 01256/03080] [00:15:25/00:22:24, 0.737s/it]: train_loss_raw=0.3472, running_loss=0.3224, LR=0.000100
[2025-08-27 18:08:37,686][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090584] [Batch 01264/03080] [00:15:31/00:22:18, 0.737s/it]: train_loss_raw=0.3196, running_loss=0.3218, LR=0.000100
[2025-08-27 18:08:43,453][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090592] [Batch 01272/03080] [00:15:37/00:22:12, 0.737s/it]: train_loss_raw=0.3143, running_loss=0.3196, LR=0.000100
[2025-08-27 18:08:49,595][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090600] [Batch 01280/03080] [00:15:43/00:22:06, 0.737s/it]: train_loss_raw=0.2798, running_loss=0.3197, LR=0.000100
[2025-08-27 18:08:55,826][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090608] [Batch 01288/03080] [00:15:49/00:22:01, 0.737s/it]: train_loss_raw=0.2475, running_loss=0.3197, LR=0.000100
[2025-08-27 18:09:01,626][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090616] [Batch 01296/03080] [00:15:55/00:21:55, 0.737s/it]: train_loss_raw=0.3648, running_loss=0.3197, LR=0.000100
[2025-08-27 18:09:07,839][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090624] [Batch 01304/03080] [00:16:01/00:21:49, 0.737s/it]: train_loss_raw=0.3845, running_loss=0.3196, LR=0.000100
[2025-08-27 18:09:13,991][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090632] [Batch 01312/03080] [00:16:07/00:21:44, 0.738s/it]: train_loss_raw=0.3578, running_loss=0.3227, LR=0.000100
[2025-08-27 18:09:19,595][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090640] [Batch 01320/03080] [00:16:13/00:21:37, 0.737s/it]: train_loss_raw=0.2655, running_loss=0.3224, LR=0.000100
[2025-08-27 18:09:25,545][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090648] [Batch 01328/03080] [00:16:19/00:21:31, 0.737s/it]: train_loss_raw=0.3221, running_loss=0.3230, LR=0.000100
[2025-08-27 18:09:31,066][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090656] [Batch 01336/03080] [00:16:24/00:21:25, 0.737s/it]: train_loss_raw=0.2729, running_loss=0.3209, LR=0.000100
[2025-08-27 18:09:36,900][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090664] [Batch 01344/03080] [00:16:30/00:21:19, 0.737s/it]: train_loss_raw=0.4169, running_loss=0.3213, LR=0.000100
[2025-08-27 18:09:42,841][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090672] [Batch 01352/03080] [00:16:36/00:21:13, 0.737s/it]: train_loss_raw=0.3149, running_loss=0.3222, LR=0.000100
[2025-08-27 18:09:48,226][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090680] [Batch 01360/03080] [00:16:41/00:21:07, 0.737s/it]: train_loss_raw=0.3402, running_loss=0.3211, LR=0.000100
[2025-08-27 18:09:53,849][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090688] [Batch 01368/03080] [00:16:47/00:21:00, 0.737s/it]: train_loss_raw=0.3013, running_loss=0.3218, LR=0.000100
[2025-08-27 18:09:59,934][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090696] [Batch 01376/03080] [00:16:53/00:20:55, 0.737s/it]: train_loss_raw=0.4133, running_loss=0.3232, LR=0.000100
[2025-08-27 18:10:05,939][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090704] [Batch 01384/03080] [00:16:59/00:20:49, 0.737s/it]: train_loss_raw=0.3067, running_loss=0.3228, LR=0.000100
[2025-08-27 18:10:11,683][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090712] [Batch 01392/03080] [00:17:05/00:20:43, 0.737s/it]: train_loss_raw=0.3286, running_loss=0.3213, LR=0.000100
[2025-08-27 18:10:17,187][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090720] [Batch 01400/03080] [00:17:10/00:20:37, 0.736s/it]: train_loss_raw=0.3061, running_loss=0.3216, LR=0.000100
[2025-08-27 18:10:22,868][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090728] [Batch 01408/03080] [00:17:16/00:20:31, 0.736s/it]: train_loss_raw=0.3154, running_loss=0.3223, LR=0.000100
[2025-08-27 18:10:28,668][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090736] [Batch 01416/03080] [00:17:22/00:20:25, 0.736s/it]: train_loss_raw=0.3160, running_loss=0.3223, LR=0.000100
[2025-08-27 18:10:34,184][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090744] [Batch 01424/03080] [00:17:27/00:20:18, 0.736s/it]: train_loss_raw=0.2369, running_loss=0.3198, LR=0.000100
[2025-08-27 18:10:40,207][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090752] [Batch 01432/03080] [00:17:33/00:20:12, 0.736s/it]: train_loss_raw=0.3476, running_loss=0.3204, LR=0.000100
[2025-08-27 18:10:46,108][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090760] [Batch 01440/03080] [00:17:39/00:20:07, 0.736s/it]: train_loss_raw=0.2852, running_loss=0.3223, LR=0.000100
[2025-08-27 18:10:51,902][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090768] [Batch 01448/03080] [00:17:45/00:20:01, 0.736s/it]: train_loss_raw=0.2776, running_loss=0.3231, LR=0.000100
[2025-08-27 18:10:57,901][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090776] [Batch 01456/03080] [00:17:51/00:19:55, 0.736s/it]: train_loss_raw=0.3252, running_loss=0.3237, LR=0.000100
[2025-08-27 18:11:04,209][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090784] [Batch 01464/03080] [00:17:57/00:19:49, 0.736s/it]: train_loss_raw=0.3164, running_loss=0.3248, LR=0.000100
[2025-08-27 18:11:10,117][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090792] [Batch 01472/03080] [00:18:03/00:19:44, 0.736s/it]: train_loss_raw=0.1961, running_loss=0.3241, LR=0.000100
[2025-08-27 18:11:16,147][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090800] [Batch 01480/03080] [00:18:09/00:19:38, 0.736s/it]: train_loss_raw=0.2755, running_loss=0.3226, LR=0.000100
[2025-08-27 18:11:21,579][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090808] [Batch 01488/03080] [00:18:15/00:19:31, 0.736s/it]: train_loss_raw=0.3108, running_loss=0.3231, LR=0.000100
[2025-08-27 18:11:27,060][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090816] [Batch 01496/03080] [00:18:20/00:19:25, 0.736s/it]: train_loss_raw=0.3073, running_loss=0.3216, LR=0.000100
[2025-08-27 18:11:32,475][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090824] [Batch 01504/03080] [00:18:26/00:19:19, 0.736s/it]: train_loss_raw=0.2831, running_loss=0.3194, LR=0.000100
[2025-08-27 18:11:38,150][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090832] [Batch 01512/03080] [00:18:31/00:19:13, 0.735s/it]: train_loss_raw=0.2834, running_loss=0.3190, LR=0.000100
[2025-08-27 18:11:43,763][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090840] [Batch 01520/03080] [00:18:37/00:19:06, 0.735s/it]: train_loss_raw=0.3153, running_loss=0.3203, LR=0.000100
[2025-08-27 18:11:49,486][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090848] [Batch 01528/03080] [00:18:43/00:19:00, 0.735s/it]: train_loss_raw=0.2743, running_loss=0.3206, LR=0.000100
[2025-08-27 18:11:54,904][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090856] [Batch 01536/03080] [00:18:48/00:18:54, 0.735s/it]: train_loss_raw=0.3140, running_loss=0.3192, LR=0.000100
[2025-08-27 18:12:00,445][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090864] [Batch 01544/03080] [00:18:54/00:18:48, 0.735s/it]: train_loss_raw=0.3148, running_loss=0.3196, LR=0.000100
[2025-08-27 18:12:06,222][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090872] [Batch 01552/03080] [00:18:59/00:18:42, 0.735s/it]: train_loss_raw=0.3907, running_loss=0.3175, LR=0.000100
[2025-08-27 18:12:11,932][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090880] [Batch 01560/03080] [00:19:05/00:18:36, 0.734s/it]: train_loss_raw=0.3001, running_loss=0.3189, LR=0.000100
[2025-08-27 18:12:17,379][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090888] [Batch 01568/03080] [00:19:11/00:18:30, 0.734s/it]: train_loss_raw=0.3349, running_loss=0.3211, LR=0.000100
[2025-08-27 18:12:22,702][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090896] [Batch 01576/03080] [00:19:16/00:18:23, 0.734s/it]: train_loss_raw=0.2783, running_loss=0.3196, LR=0.000100
[2025-08-27 18:12:28,801][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090904] [Batch 01584/03080] [00:19:22/00:18:17, 0.734s/it]: train_loss_raw=0.3452, running_loss=0.3206, LR=0.000100
[2025-08-27 18:12:34,664][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090912] [Batch 01592/03080] [00:19:28/00:18:12, 0.734s/it]: train_loss_raw=0.2842, running_loss=0.3202, LR=0.000100
[2025-08-27 18:12:40,346][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090920] [Batch 01600/03080] [00:19:34/00:18:06, 0.734s/it]: train_loss_raw=0.2967, running_loss=0.3177, LR=0.000100
[2025-08-27 18:12:46,401][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090928] [Batch 01608/03080] [00:19:40/00:18:00, 0.734s/it]: train_loss_raw=0.2161, running_loss=0.3178, LR=0.000100
[2025-08-27 18:12:52,121][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090936] [Batch 01616/03080] [00:19:45/00:17:54, 0.734s/it]: train_loss_raw=0.3578, running_loss=0.3183, LR=0.000100
[2025-08-27 18:12:58,111][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090944] [Batch 01624/03080] [00:19:51/00:17:48, 0.734s/it]: train_loss_raw=0.3636, running_loss=0.3188, LR=0.000100
[2025-08-27 18:13:03,710][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090952] [Batch 01632/03080] [00:19:57/00:17:42, 0.734s/it]: train_loss_raw=0.2868, running_loss=0.3194, LR=0.000100
[2025-08-27 18:13:09,564][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090960] [Batch 01640/03080] [00:20:03/00:17:36, 0.734s/it]: train_loss_raw=0.2656, running_loss=0.3203, LR=0.000100
[2025-08-27 18:13:15,004][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090968] [Batch 01648/03080] [00:20:08/00:17:30, 0.733s/it]: train_loss_raw=0.3551, running_loss=0.3204, LR=0.000100
[2025-08-27 18:13:20,621][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090976] [Batch 01656/03080] [00:20:14/00:17:24, 0.733s/it]: train_loss_raw=0.2945, running_loss=0.3207, LR=0.000100
[2025-08-27 18:13:26,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090984] [Batch 01664/03080] [00:20:20/00:17:18, 0.733s/it]: train_loss_raw=0.2687, running_loss=0.3194, LR=0.000100
[2025-08-27 18:13:32,302][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090992] [Batch 01672/03080] [00:20:26/00:17:12, 0.733s/it]: train_loss_raw=0.3234, running_loss=0.3189, LR=0.000100
[2025-08-27 18:13:38,176][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091000] [Batch 01680/03080] [00:20:31/00:17:06, 0.733s/it]: train_loss_raw=0.3502, running_loss=0.3195, LR=0.000100
[2025-08-27 18:13:43,685][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091008] [Batch 01688/03080] [00:20:37/00:17:00, 0.733s/it]: train_loss_raw=0.2814, running_loss=0.3215, LR=0.000100
[2025-08-27 18:13:49,177][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091016] [Batch 01696/03080] [00:20:42/00:16:54, 0.733s/it]: train_loss_raw=0.2816, running_loss=0.3210, LR=0.000100
[2025-08-27 18:13:54,543][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091024] [Batch 01704/03080] [00:20:48/00:16:48, 0.733s/it]: train_loss_raw=0.3706, running_loss=0.3225, LR=0.000100
[2025-08-27 18:14:00,174][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091032] [Batch 01712/03080] [00:20:53/00:16:41, 0.732s/it]: train_loss_raw=0.2773, running_loss=0.3219, LR=0.000100
[2025-08-27 18:14:05,918][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091040] [Batch 01720/03080] [00:20:59/00:16:36, 0.732s/it]: train_loss_raw=0.3531, running_loss=0.3222, LR=0.000100
[2025-08-27 18:14:11,700][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091048] [Batch 01728/03080] [00:21:05/00:16:30, 0.732s/it]: train_loss_raw=0.2928, running_loss=0.3231, LR=0.000100
[2025-08-27 18:14:17,345][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091056] [Batch 01736/03080] [00:21:11/00:16:24, 0.732s/it]: train_loss_raw=0.3002, running_loss=0.3238, LR=0.000100
[2025-08-27 18:14:22,965][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091064] [Batch 01744/03080] [00:21:16/00:16:18, 0.732s/it]: train_loss_raw=0.2518, running_loss=0.3225, LR=0.000100
[2025-08-27 18:14:28,662][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091072] [Batch 01752/03080] [00:21:22/00:16:12, 0.732s/it]: train_loss_raw=0.3854, running_loss=0.3229, LR=0.000100
[2025-08-27 18:14:34,554][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091080] [Batch 01760/03080] [00:21:28/00:16:06, 0.732s/it]: train_loss_raw=0.2721, running_loss=0.3194, LR=0.000100
[2025-08-27 18:14:39,950][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091088] [Batch 01768/03080] [00:21:33/00:16:00, 0.732s/it]: train_loss_raw=0.3124, running_loss=0.3191, LR=0.000100
[2025-08-27 18:14:45,610][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091096] [Batch 01776/03080] [00:21:39/00:15:54, 0.732s/it]: train_loss_raw=0.2761, running_loss=0.3200, LR=0.000100
[2025-08-27 18:14:51,513][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091104] [Batch 01784/03080] [00:21:45/00:15:48, 0.732s/it]: train_loss_raw=0.3444, running_loss=0.3196, LR=0.000100
[2025-08-27 18:14:57,450][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091112] [Batch 01792/03080] [00:21:51/00:15:42, 0.732s/it]: train_loss_raw=0.3478, running_loss=0.3206, LR=0.000100
[2025-08-27 18:15:03,351][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091120] [Batch 01800/03080] [00:21:57/00:15:36, 0.732s/it]: train_loss_raw=0.3016, running_loss=0.3207, LR=0.000100
[2025-08-27 18:15:09,065][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091128] [Batch 01808/03080] [00:22:02/00:15:30, 0.732s/it]: train_loss_raw=0.2981, running_loss=0.3212, LR=0.000100
[2025-08-27 18:15:14,548][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091136] [Batch 01816/03080] [00:22:08/00:15:24, 0.731s/it]: train_loss_raw=0.3595, running_loss=0.3204, LR=0.000100
[2025-08-27 18:15:20,254][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091144] [Batch 01824/03080] [00:22:14/00:15:18, 0.731s/it]: train_loss_raw=0.3492, running_loss=0.3211, LR=0.000100
[2025-08-27 18:15:26,355][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091152] [Batch 01832/03080] [00:22:20/00:15:12, 0.732s/it]: train_loss_raw=0.2430, running_loss=0.3198, LR=0.000100
[2025-08-27 18:15:32,462][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091160] [Batch 01840/03080] [00:22:26/00:15:07, 0.732s/it]: train_loss_raw=0.3933, running_loss=0.3205, LR=0.000100
[2025-08-27 18:15:38,524][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091168] [Batch 01848/03080] [00:22:32/00:15:01, 0.732s/it]: train_loss_raw=0.3005, running_loss=0.3221, LR=0.000100
[2025-08-27 18:15:44,504][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091176] [Batch 01856/03080] [00:22:38/00:14:55, 0.732s/it]: train_loss_raw=0.3310, running_loss=0.3223, LR=0.000100
[2025-08-27 18:15:50,405][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091184] [Batch 01864/03080] [00:22:44/00:14:49, 0.732s/it]: train_loss_raw=0.3786, running_loss=0.3251, LR=0.000100
[2025-08-27 18:15:56,515][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091192] [Batch 01872/03080] [00:22:50/00:14:44, 0.732s/it]: train_loss_raw=0.2598, running_loss=0.3238, LR=0.000100
[2025-08-27 18:16:02,513][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091200] [Batch 01880/03080] [00:22:56/00:14:38, 0.732s/it]: train_loss_raw=0.2965, running_loss=0.3245, LR=0.000100
[2025-08-27 18:16:08,512][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091208] [Batch 01888/03080] [00:23:02/00:14:32, 0.732s/it]: train_loss_raw=0.3137, running_loss=0.3243, LR=0.000100
[2025-08-27 18:16:14,199][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091216] [Batch 01896/03080] [00:23:07/00:14:26, 0.732s/it]: train_loss_raw=0.3399, running_loss=0.3232, LR=0.000100
[2025-08-27 18:16:19,927][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091224] [Batch 01904/03080] [00:23:13/00:14:20, 0.732s/it]: train_loss_raw=0.3520, running_loss=0.3218, LR=0.000100
[2025-08-27 18:16:25,825][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091232] [Batch 01912/03080] [00:23:19/00:14:14, 0.732s/it]: train_loss_raw=0.3168, running_loss=0.3192, LR=0.000100
[2025-08-27 18:16:31,611][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091240] [Batch 01920/03080] [00:23:25/00:14:09, 0.732s/it]: train_loss_raw=0.3642, running_loss=0.3208, LR=0.000100
[2025-08-27 18:16:37,331][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091248] [Batch 01928/03080] [00:23:31/00:14:03, 0.732s/it]: train_loss_raw=0.3403, running_loss=0.3204, LR=0.000100
[2025-08-27 18:16:43,165][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091256] [Batch 01936/03080] [00:23:36/00:13:57, 0.732s/it]: train_loss_raw=0.3254, running_loss=0.3210, LR=0.000100
[2025-08-27 18:16:48,555][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091264] [Batch 01944/03080] [00:23:42/00:13:51, 0.732s/it]: train_loss_raw=0.3403, running_loss=0.3226, LR=0.000100
[2025-08-27 18:16:54,169][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091272] [Batch 01952/03080] [00:23:47/00:13:45, 0.732s/it]: train_loss_raw=0.2930, running_loss=0.3219, LR=0.000100
[2025-08-27 18:16:59,586][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091280] [Batch 01960/03080] [00:23:53/00:13:39, 0.731s/it]: train_loss_raw=0.2528, running_loss=0.3220, LR=0.000100
[2025-08-27 18:17:05,208][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091288] [Batch 01968/03080] [00:23:58/00:13:33, 0.731s/it]: train_loss_raw=0.3370, running_loss=0.3210, LR=0.000100
[2025-08-27 18:17:11,275][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091296] [Batch 01976/03080] [00:24:05/00:13:27, 0.731s/it]: train_loss_raw=0.3128, running_loss=0.3202, LR=0.000100
[2025-08-27 18:17:17,279][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091304] [Batch 01984/03080] [00:24:11/00:13:21, 0.731s/it]: train_loss_raw=0.3115, running_loss=0.3216, LR=0.000100
[2025-08-27 18:17:23,207][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091312] [Batch 01992/03080] [00:24:16/00:13:15, 0.731s/it]: train_loss_raw=0.2860, running_loss=0.3215, LR=0.000100
[2025-08-27 18:17:28,794][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091320] [Batch 02000/03080] [00:24:22/00:13:09, 0.731s/it]: train_loss_raw=0.3581, running_loss=0.3240, LR=0.000100
[2025-08-27 18:17:34,840][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091328] [Batch 02008/03080] [00:24:28/00:13:04, 0.731s/it]: train_loss_raw=0.3009, running_loss=0.3229, LR=0.000100
[2025-08-27 18:17:40,520][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091336] [Batch 02016/03080] [00:24:34/00:12:58, 0.731s/it]: train_loss_raw=0.2827, running_loss=0.3207, LR=0.000100
[2025-08-27 18:17:46,168][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091344] [Batch 02024/03080] [00:24:39/00:12:52, 0.731s/it]: train_loss_raw=0.4092, running_loss=0.3227, LR=0.000100
[2025-08-27 18:17:51,990][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091352] [Batch 02032/03080] [00:24:45/00:12:46, 0.731s/it]: train_loss_raw=0.3603, running_loss=0.3219, LR=0.000100
[2025-08-27 18:17:57,909][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091360] [Batch 02040/03080] [00:24:51/00:12:40, 0.731s/it]: train_loss_raw=0.3383, running_loss=0.3236, LR=0.000100
[2025-08-27 18:18:03,574][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091368] [Batch 02048/03080] [00:24:57/00:12:34, 0.731s/it]: train_loss_raw=0.2972, running_loss=0.3248, LR=0.000100
[2025-08-27 18:18:09,549][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091376] [Batch 02056/03080] [00:25:03/00:12:28, 0.731s/it]: train_loss_raw=0.2805, running_loss=0.3245, LR=0.000100
[2025-08-27 18:18:15,189][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091384] [Batch 02064/03080] [00:25:08/00:12:22, 0.731s/it]: train_loss_raw=0.2682, running_loss=0.3252, LR=0.000100
[2025-08-27 18:18:21,096][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091392] [Batch 02072/03080] [00:25:14/00:12:16, 0.731s/it]: train_loss_raw=0.3309, running_loss=0.3256, LR=0.000100
[2025-08-27 18:18:26,955][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091400] [Batch 02080/03080] [00:25:20/00:12:11, 0.731s/it]: train_loss_raw=0.2901, running_loss=0.3233, LR=0.000100
[2025-08-27 18:18:32,888][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091408] [Batch 02088/03080] [00:25:26/00:12:05, 0.731s/it]: train_loss_raw=0.2646, running_loss=0.3224, LR=0.000100
[2025-08-27 18:18:38,268][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091416] [Batch 02096/03080] [00:25:32/00:11:59, 0.731s/it]: train_loss_raw=0.2307, running_loss=0.3228, LR=0.000100
[2025-08-27 18:18:43,963][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091424] [Batch 02104/03080] [00:25:37/00:11:53, 0.731s/it]: train_loss_raw=0.2773, running_loss=0.3243, LR=0.000100
[2025-08-27 18:18:49,924][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091432] [Batch 02112/03080] [00:25:43/00:11:47, 0.731s/it]: train_loss_raw=0.3536, running_loss=0.3252, LR=0.000100
[2025-08-27 18:18:55,744][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091440] [Batch 02120/03080] [00:25:49/00:11:41, 0.731s/it]: train_loss_raw=0.3249, running_loss=0.3257, LR=0.000100
[2025-08-27 18:19:01,509][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091448] [Batch 02128/03080] [00:25:55/00:11:35, 0.731s/it]: train_loss_raw=0.2885, running_loss=0.3241, LR=0.000100
[2025-08-27 18:19:07,410][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091456] [Batch 02136/03080] [00:26:01/00:11:29, 0.731s/it]: train_loss_raw=0.3527, running_loss=0.3245, LR=0.000100
[2025-08-27 18:19:12,822][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091464] [Batch 02144/03080] [00:26:06/00:11:23, 0.731s/it]: train_loss_raw=0.2725, running_loss=0.3249, LR=0.000100
[2025-08-27 18:19:18,492][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091472] [Batch 02152/03080] [00:26:12/00:11:18, 0.731s/it]: train_loss_raw=0.3112, running_loss=0.3222, LR=0.000100
[2025-08-27 18:19:24,494][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091480] [Batch 02160/03080] [00:26:18/00:11:12, 0.731s/it]: train_loss_raw=0.2842, running_loss=0.3216, LR=0.000100
[2025-08-27 18:19:30,120][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091488] [Batch 02168/03080] [00:26:23/00:11:06, 0.731s/it]: train_loss_raw=0.3673, running_loss=0.3224, LR=0.000100
[2025-08-27 18:19:35,824][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091496] [Batch 02176/03080] [00:26:29/00:11:00, 0.731s/it]: train_loss_raw=0.3573, running_loss=0.3225, LR=0.000100
[2025-08-27 18:19:41,706][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091504] [Batch 02184/03080] [00:26:35/00:10:54, 0.731s/it]: train_loss_raw=0.2997, running_loss=0.3214, LR=0.000100
[2025-08-27 18:19:47,398][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091512] [Batch 02192/03080] [00:26:41/00:10:48, 0.730s/it]: train_loss_raw=0.3287, running_loss=0.3201, LR=0.000100
[2025-08-27 18:19:53,128][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091520] [Batch 02200/03080] [00:26:46/00:10:42, 0.730s/it]: train_loss_raw=0.3923, running_loss=0.3191, LR=0.000100
[2025-08-27 18:19:58,710][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091528] [Batch 02208/03080] [00:26:52/00:10:36, 0.730s/it]: train_loss_raw=0.3186, running_loss=0.3186, LR=0.000100
[2025-08-27 18:20:04,121][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091536] [Batch 02216/03080] [00:26:57/00:10:30, 0.730s/it]: train_loss_raw=0.2617, running_loss=0.3201, LR=0.000100
[2025-08-27 18:20:10,152][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091544] [Batch 02224/03080] [00:27:03/00:10:25, 0.730s/it]: train_loss_raw=0.3668, running_loss=0.3212, LR=0.000100
[2025-08-27 18:20:15,952][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091552] [Batch 02232/03080] [00:27:09/00:10:19, 0.730s/it]: train_loss_raw=0.3320, running_loss=0.3221, LR=0.000100
[2025-08-27 18:20:21,618][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091560] [Batch 02240/03080] [00:27:15/00:10:13, 0.730s/it]: train_loss_raw=0.4195, running_loss=0.3229, LR=0.000100
[2025-08-27 18:20:27,338][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091568] [Batch 02248/03080] [00:27:21/00:10:07, 0.730s/it]: train_loss_raw=0.3804, running_loss=0.3243, LR=0.000100
[2025-08-27 18:20:33,187][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091576] [Batch 02256/03080] [00:27:26/00:10:01, 0.730s/it]: train_loss_raw=0.2641, running_loss=0.3242, LR=0.000100
[2025-08-27 18:20:39,160][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091584] [Batch 02264/03080] [00:27:32/00:09:55, 0.730s/it]: train_loss_raw=0.4434, running_loss=0.3263, LR=0.000100
[2025-08-27 18:20:44,846][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091592] [Batch 02272/03080] [00:27:38/00:09:49, 0.730s/it]: train_loss_raw=0.2862, running_loss=0.3260, LR=0.000100
[2025-08-27 18:20:50,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091600] [Batch 02280/03080] [00:27:44/00:09:44, 0.730s/it]: train_loss_raw=0.3175, running_loss=0.3266, LR=0.000100
[2025-08-27 18:20:56,668][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091608] [Batch 02288/03080] [00:27:50/00:09:38, 0.730s/it]: train_loss_raw=0.3357, running_loss=0.3271, LR=0.000100
[2025-08-27 18:21:02,867][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091616] [Batch 02296/03080] [00:27:56/00:09:32, 0.730s/it]: train_loss_raw=0.3527, running_loss=0.3257, LR=0.000100
[2025-08-27 18:21:08,663][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091624] [Batch 02304/03080] [00:28:02/00:09:26, 0.730s/it]: train_loss_raw=0.3014, running_loss=0.3245, LR=0.000100
[2025-08-27 18:21:14,371][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091632] [Batch 02312/03080] [00:28:08/00:09:20, 0.730s/it]: train_loss_raw=0.4545, running_loss=0.3251, LR=0.000100
[2025-08-27 18:21:20,473][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091640] [Batch 02320/03080] [00:28:14/00:09:15, 0.730s/it]: train_loss_raw=0.3980, running_loss=0.3273, LR=0.000100
[2025-08-27 18:21:26,262][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091648] [Batch 02328/03080] [00:28:20/00:09:09, 0.730s/it]: train_loss_raw=0.2943, running_loss=0.3261, LR=0.000100
[2025-08-27 18:21:32,290][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091656] [Batch 02336/03080] [00:28:26/00:09:03, 0.730s/it]: train_loss_raw=0.3041, running_loss=0.3258, LR=0.000100
[2025-08-27 18:21:38,062][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091664] [Batch 02344/03080] [00:28:31/00:08:57, 0.730s/it]: train_loss_raw=0.3415, running_loss=0.3237, LR=0.000100
[2025-08-27 18:21:43,677][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091672] [Batch 02352/03080] [00:28:37/00:08:51, 0.730s/it]: train_loss_raw=0.2404, running_loss=0.3209, LR=0.000100
[2025-08-27 18:21:49,397][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091680] [Batch 02360/03080] [00:28:43/00:08:45, 0.730s/it]: train_loss_raw=0.4300, running_loss=0.3226, LR=0.000100
[2025-08-27 18:21:55,034][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091688] [Batch 02368/03080] [00:28:48/00:08:39, 0.730s/it]: train_loss_raw=0.3238, running_loss=0.3234, LR=0.000100
[2025-08-27 18:22:01,157][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091696] [Batch 02376/03080] [00:28:54/00:08:34, 0.730s/it]: train_loss_raw=0.2479, running_loss=0.3225, LR=0.000100
[2025-08-27 18:22:06,985][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091704] [Batch 02384/03080] [00:29:00/00:08:28, 0.730s/it]: train_loss_raw=0.3383, running_loss=0.3223, LR=0.000100
[2025-08-27 18:22:12,580][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091712] [Batch 02392/03080] [00:29:06/00:08:22, 0.730s/it]: train_loss_raw=0.3650, running_loss=0.3232, LR=0.000100
[2025-08-27 18:22:18,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091720] [Batch 02400/03080] [00:29:12/00:08:16, 0.730s/it]: train_loss_raw=0.4141, running_loss=0.3234, LR=0.000100
[2025-08-27 18:22:24,459][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091728] [Batch 02408/03080] [00:29:18/00:08:10, 0.730s/it]: train_loss_raw=0.2982, running_loss=0.3244, LR=0.000100
[2025-08-27 18:22:30,166][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091736] [Batch 02416/03080] [00:29:23/00:08:04, 0.730s/it]: train_loss_raw=0.3448, running_loss=0.3235, LR=0.000100
[2025-08-27 18:22:35,883][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091744] [Batch 02424/03080] [00:29:29/00:07:58, 0.730s/it]: train_loss_raw=0.3243, running_loss=0.3231, LR=0.000100
[2025-08-27 18:22:41,688][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091752] [Batch 02432/03080] [00:29:35/00:07:53, 0.730s/it]: train_loss_raw=0.3321, running_loss=0.3233, LR=0.000100
[2025-08-27 18:22:47,335][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091760] [Batch 02440/03080] [00:29:41/00:07:47, 0.730s/it]: train_loss_raw=0.3269, running_loss=0.3222, LR=0.000100
[2025-08-27 18:22:52,883][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091768] [Batch 02448/03080] [00:29:46/00:07:41, 0.730s/it]: train_loss_raw=0.4189, running_loss=0.3225, LR=0.000100
[2025-08-27 18:22:58,725][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091776] [Batch 02456/03080] [00:29:52/00:07:35, 0.730s/it]: train_loss_raw=0.3563, running_loss=0.3229, LR=0.000100
[2025-08-27 18:23:04,454][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091784] [Batch 02464/03080] [00:29:58/00:07:29, 0.730s/it]: train_loss_raw=0.3437, running_loss=0.3235, LR=0.000100
[2025-08-27 18:23:09,952][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091792] [Batch 02472/03080] [00:30:03/00:07:23, 0.730s/it]: train_loss_raw=0.2703, running_loss=0.3218, LR=0.000100
[2025-08-27 18:23:15,464][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091800] [Batch 02480/03080] [00:30:09/00:07:17, 0.730s/it]: train_loss_raw=0.3420, running_loss=0.3234, LR=0.000100
[2025-08-27 18:23:20,914][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091808] [Batch 02488/03080] [00:30:14/00:07:11, 0.729s/it]: train_loss_raw=0.3393, running_loss=0.3237, LR=0.000100
[2025-08-27 18:23:26,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091816] [Batch 02496/03080] [00:30:20/00:07:05, 0.729s/it]: train_loss_raw=0.3825, running_loss=0.3242, LR=0.000100
[2025-08-27 18:23:32,663][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091824] [Batch 02504/03080] [00:30:26/00:07:00, 0.729s/it]: train_loss_raw=0.3283, running_loss=0.3244, LR=0.000100
[2025-08-27 18:23:38,577][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091832] [Batch 02512/03080] [00:30:32/00:06:54, 0.729s/it]: train_loss_raw=0.3519, running_loss=0.3237, LR=0.000100
[2025-08-27 18:23:44,268][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091840] [Batch 02520/03080] [00:30:38/00:06:48, 0.729s/it]: train_loss_raw=0.3397, running_loss=0.3232, LR=0.000100
[2025-08-27 18:23:50,189][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091848] [Batch 02528/03080] [00:30:43/00:06:42, 0.729s/it]: train_loss_raw=0.3126, running_loss=0.3233, LR=0.000100
[2025-08-27 18:23:56,106][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091856] [Batch 02536/03080] [00:30:49/00:06:36, 0.729s/it]: train_loss_raw=0.4033, running_loss=0.3266, LR=0.000100
[2025-08-27 18:24:01,615][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091864] [Batch 02544/03080] [00:30:55/00:06:30, 0.729s/it]: train_loss_raw=0.3171, running_loss=0.3248, LR=0.000100
[2025-08-27 18:24:07,427][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091872] [Batch 02552/03080] [00:31:01/00:06:25, 0.729s/it]: train_loss_raw=0.2986, running_loss=0.3249, LR=0.000100
[2025-08-27 18:24:13,460][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091880] [Batch 02560/03080] [00:31:07/00:06:19, 0.729s/it]: train_loss_raw=0.2653, running_loss=0.3239, LR=0.000100
[2025-08-27 18:24:19,606][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091888] [Batch 02568/03080] [00:31:13/00:06:13, 0.730s/it]: train_loss_raw=0.3374, running_loss=0.3258, LR=0.000100
[2025-08-27 18:24:25,114][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091896] [Batch 02576/03080] [00:31:18/00:06:07, 0.729s/it]: train_loss_raw=0.2388, running_loss=0.3252, LR=0.000100
[2025-08-27 18:24:30,796][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091904] [Batch 02584/03080] [00:31:24/00:06:01, 0.729s/it]: train_loss_raw=0.3218, running_loss=0.3261, LR=0.000100
[2025-08-27 18:24:36,455][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091912] [Batch 02592/03080] [00:31:30/00:05:55, 0.729s/it]: train_loss_raw=0.3164, running_loss=0.3266, LR=0.000100
[2025-08-27 18:24:42,078][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091920] [Batch 02600/03080] [00:31:35/00:05:50, 0.729s/it]: train_loss_raw=0.3280, running_loss=0.3271, LR=0.000100
[2025-08-27 18:24:47,962][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091928] [Batch 02608/03080] [00:31:41/00:05:44, 0.729s/it]: train_loss_raw=0.2856, running_loss=0.3254, LR=0.000100
[2025-08-27 18:24:53,794][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091936] [Batch 02616/03080] [00:31:47/00:05:38, 0.729s/it]: train_loss_raw=0.2487, running_loss=0.3248, LR=0.000100
[2025-08-27 18:24:59,713][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091944] [Batch 02624/03080] [00:31:53/00:05:32, 0.729s/it]: train_loss_raw=0.3389, running_loss=0.3240, LR=0.000100
[2025-08-27 18:25:05,447][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091952] [Batch 02632/03080] [00:31:59/00:05:26, 0.729s/it]: train_loss_raw=0.3374, running_loss=0.3210, LR=0.000100
[2025-08-27 18:25:10,869][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091960] [Batch 02640/03080] [00:32:04/00:05:20, 0.729s/it]: train_loss_raw=0.3775, running_loss=0.3211, LR=0.000100
[2025-08-27 18:25:16,783][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091968] [Batch 02648/03080] [00:32:10/00:05:14, 0.729s/it]: train_loss_raw=0.3425, running_loss=0.3201, LR=0.000100
[2025-08-27 18:25:22,830][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091976] [Batch 02656/03080] [00:32:16/00:05:09, 0.729s/it]: train_loss_raw=0.3703, running_loss=0.3207, LR=0.000100
[2025-08-27 18:25:28,752][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091984] [Batch 02664/03080] [00:32:22/00:05:03, 0.729s/it]: train_loss_raw=0.2624, running_loss=0.3197, LR=0.000100
[2025-08-27 18:25:34,675][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091992] [Batch 02672/03080] [00:32:28/00:04:57, 0.729s/it]: train_loss_raw=0.2604, running_loss=0.3192, LR=0.000100
[2025-08-27 18:25:40,237][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092000] [Batch 02680/03080] [00:32:34/00:04:51, 0.729s/it]: train_loss_raw=0.3296, running_loss=0.3208, LR=0.000100
[2025-08-27 18:25:49,793][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092008] [Batch 02688/03080] [00:32:43/00:04:46, 0.730s/it]: train_loss_raw=0.2760, running_loss=0.3197, LR=0.000100
[2025-08-27 18:25:55,632][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092016] [Batch 02696/03080] [00:32:49/00:04:40, 0.730s/it]: train_loss_raw=0.3235, running_loss=0.3201, LR=0.000100
[2025-08-27 18:26:01,173][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092024] [Batch 02704/03080] [00:32:54/00:04:34, 0.730s/it]: train_loss_raw=0.3293, running_loss=0.3185, LR=0.000100
[2025-08-27 18:26:07,056][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092032] [Batch 02712/03080] [00:33:00/00:04:28, 0.730s/it]: train_loss_raw=0.2954, running_loss=0.3178, LR=0.000100
[2025-08-27 18:26:12,899][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092040] [Batch 02720/03080] [00:33:06/00:04:22, 0.730s/it]: train_loss_raw=0.3423, running_loss=0.3160, LR=0.000100
[2025-08-27 18:26:18,437][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092048] [Batch 02728/03080] [00:33:12/00:04:17, 0.730s/it]: train_loss_raw=0.2867, running_loss=0.3171, LR=0.000100
[2025-08-27 18:26:24,363][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092056] [Batch 02736/03080] [00:33:18/00:04:11, 0.730s/it]: train_loss_raw=0.2816, running_loss=0.3176, LR=0.000100
[2025-08-27 18:26:29,749][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092064] [Batch 02744/03080] [00:33:23/00:04:05, 0.730s/it]: train_loss_raw=0.3015, running_loss=0.3163, LR=0.000100
[2025-08-27 18:26:35,365][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092072] [Batch 02752/03080] [00:33:29/00:03:59, 0.730s/it]: train_loss_raw=0.2711, running_loss=0.3162, LR=0.000100
[2025-08-27 18:26:41,247][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092080] [Batch 02760/03080] [00:33:35/00:03:53, 0.730s/it]: train_loss_raw=0.3506, running_loss=0.3171, LR=0.000100
[2025-08-27 18:26:47,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092088] [Batch 02768/03080] [00:33:41/00:03:47, 0.730s/it]: train_loss_raw=0.3336, running_loss=0.3157, LR=0.000100
[2025-08-27 18:26:53,201][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092096] [Batch 02776/03080] [00:33:46/00:03:41, 0.730s/it]: train_loss_raw=0.3547, running_loss=0.3158, LR=0.000100
[2025-08-27 18:26:58,859][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092104] [Batch 02784/03080] [00:33:52/00:03:36, 0.730s/it]: train_loss_raw=0.2589, running_loss=0.3167, LR=0.000100
[2025-08-27 18:27:04,731][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092112] [Batch 02792/03080] [00:33:58/00:03:30, 0.730s/it]: train_loss_raw=0.3637, running_loss=0.3175, LR=0.000100
[2025-08-27 18:27:10,862][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092120] [Batch 02800/03080] [00:34:04/00:03:24, 0.730s/it]: train_loss_raw=0.2944, running_loss=0.3177, LR=0.000100
[2025-08-27 18:27:16,785][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092128] [Batch 02808/03080] [00:34:10/00:03:18, 0.730s/it]: train_loss_raw=0.3088, running_loss=0.3172, LR=0.000100
[2025-08-27 18:27:22,710][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092136] [Batch 02816/03080] [00:34:16/00:03:12, 0.730s/it]: train_loss_raw=0.2767, running_loss=0.3189, LR=0.000100
[2025-08-27 18:27:28,666][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092144] [Batch 02824/03080] [00:34:22/00:03:06, 0.730s/it]: train_loss_raw=0.3682, running_loss=0.3202, LR=0.000100
[2025-08-27 18:27:34,437][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092152] [Batch 02832/03080] [00:34:28/00:03:01, 0.730s/it]: train_loss_raw=0.3037, running_loss=0.3209, LR=0.000100
[2025-08-27 18:27:40,076][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092160] [Batch 02840/03080] [00:34:33/00:02:55, 0.730s/it]: train_loss_raw=0.4331, running_loss=0.3238, LR=0.000100
[2025-08-27 18:27:46,037][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092168] [Batch 02848/03080] [00:34:39/00:02:49, 0.730s/it]: train_loss_raw=0.3413, running_loss=0.3225, LR=0.000100
[2025-08-27 18:27:51,907][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092176] [Batch 02856/03080] [00:34:45/00:02:43, 0.730s/it]: train_loss_raw=0.2706, running_loss=0.3212, LR=0.000100
[2025-08-27 18:27:57,719][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092184] [Batch 02864/03080] [00:34:51/00:02:37, 0.730s/it]: train_loss_raw=0.3148, running_loss=0.3208, LR=0.000100
[2025-08-27 18:28:03,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092192] [Batch 02872/03080] [00:34:57/00:02:31, 0.730s/it]: train_loss_raw=0.3470, running_loss=0.3208, LR=0.000100
[2025-08-27 18:28:09,042][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092200] [Batch 02880/03080] [00:35:02/00:02:26, 0.730s/it]: train_loss_raw=0.2951, running_loss=0.3204, LR=0.000100
[2025-08-27 18:28:14,940][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092208] [Batch 02888/03080] [00:35:08/00:02:20, 0.730s/it]: train_loss_raw=0.3623, running_loss=0.3205, LR=0.000100
[2025-08-27 18:28:20,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092216] [Batch 02896/03080] [00:35:14/00:02:14, 0.730s/it]: train_loss_raw=0.3480, running_loss=0.3195, LR=0.000100
[2025-08-27 18:28:26,628][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092224] [Batch 02904/03080] [00:35:20/00:02:08, 0.730s/it]: train_loss_raw=0.3170, running_loss=0.3193, LR=0.000100
[2025-08-27 18:28:32,687][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092232] [Batch 02912/03080] [00:35:26/00:02:02, 0.730s/it]: train_loss_raw=0.2523, running_loss=0.3192, LR=0.000100
[2025-08-27 18:28:38,672][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092240] [Batch 02920/03080] [00:35:32/00:01:56, 0.730s/it]: train_loss_raw=0.3003, running_loss=0.3212, LR=0.000100
[2025-08-27 18:28:44,532][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092248] [Batch 02928/03080] [00:35:38/00:01:51, 0.730s/it]: train_loss_raw=0.2665, running_loss=0.3204, LR=0.000100
[2025-08-27 18:28:50,485][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092256] [Batch 02936/03080] [00:35:44/00:01:45, 0.730s/it]: train_loss_raw=0.3160, running_loss=0.3194, LR=0.000100
[2025-08-27 18:28:56,341][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092264] [Batch 02944/03080] [00:35:50/00:01:39, 0.730s/it]: train_loss_raw=0.2641, running_loss=0.3183, LR=0.000100
[2025-08-27 18:29:02,368][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092272] [Batch 02952/03080] [00:35:56/00:01:33, 0.730s/it]: train_loss_raw=0.3258, running_loss=0.3189, LR=0.000100
[2025-08-27 18:29:08,557][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092280] [Batch 02960/03080] [00:36:02/00:01:27, 0.731s/it]: train_loss_raw=0.2739, running_loss=0.3187, LR=0.000100
[2025-08-27 18:29:14,715][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092288] [Batch 02968/03080] [00:36:08/00:01:21, 0.731s/it]: train_loss_raw=0.3713, running_loss=0.3207, LR=0.000100
[2025-08-27 18:29:20,271][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092296] [Batch 02976/03080] [00:36:14/00:01:15, 0.731s/it]: train_loss_raw=0.3129, running_loss=0.3204, LR=0.000100
[2025-08-27 18:29:26,427][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092304] [Batch 02984/03080] [00:36:20/00:01:10, 0.731s/it]: train_loss_raw=0.3633, running_loss=0.3226, LR=0.000100
[2025-08-27 18:29:32,528][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092312] [Batch 02992/03080] [00:36:26/00:01:04, 0.731s/it]: train_loss_raw=0.3485, running_loss=0.3202, LR=0.000100
[2025-08-27 18:29:38,501][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092320] [Batch 03000/03080] [00:36:32/00:00:58, 0.731s/it]: train_loss_raw=0.2349, running_loss=0.3180, LR=0.000100
[2025-08-27 18:29:44,126][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092328] [Batch 03008/03080] [00:36:37/00:00:52, 0.731s/it]: train_loss_raw=0.3557, running_loss=0.3194, LR=0.000100
[2025-08-27 18:29:49,740][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092336] [Batch 03016/03080] [00:36:43/00:00:46, 0.731s/it]: train_loss_raw=0.3330, running_loss=0.3174, LR=0.000100
[2025-08-27 18:29:55,362][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092344] [Batch 03024/03080] [00:36:49/00:00:40, 0.731s/it]: train_loss_raw=0.2598, running_loss=0.3159, LR=0.000100
[2025-08-27 18:30:01,134][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092352] [Batch 03032/03080] [00:36:54/00:00:35, 0.731s/it]: train_loss_raw=0.2687, running_loss=0.3155, LR=0.000100
[2025-08-27 18:30:06,508][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092360] [Batch 03040/03080] [00:37:00/00:00:29, 0.730s/it]: train_loss_raw=0.3523, running_loss=0.3153, LR=0.000100
[2025-08-27 18:30:11,989][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092368] [Batch 03048/03080] [00:37:05/00:00:23, 0.730s/it]: train_loss_raw=0.2812, running_loss=0.3138, LR=0.000100
[2025-08-27 18:30:17,465][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092376] [Batch 03056/03080] [00:37:11/00:00:17, 0.730s/it]: train_loss_raw=0.2745, running_loss=0.3139, LR=0.000100
[2025-08-27 18:30:22,845][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092384] [Batch 03064/03080] [00:37:16/00:00:11, 0.730s/it]: train_loss_raw=0.3297, running_loss=0.3141, LR=0.000100
[2025-08-27 18:30:28,896][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092392] [Batch 03072/03080] [00:37:22/00:00:05, 0.730s/it]: train_loss_raw=0.3062, running_loss=0.3151, LR=0.000100
[2025-08-27 18:30:39,318][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092400] [Batch 03080/03080] [00:37:33/00:00:00, 0.732s/it]: train_loss_raw=0.3414, running_loss=0.3152, LR=0.000100
[2025-08-27 18:30:39,858][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-27 18:30:51,205][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00007/00310] [00:00:11/00:07:08, 1.418s/it]
[2025-08-27 18:31:02,809][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00015/00310] [00:00:22/00:07:01, 1.434s/it]
[2025-08-27 18:31:13,729][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00023/00310] [00:00:33/00:06:43, 1.411s/it]
[2025-08-27 18:31:25,627][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00031/00310] [00:00:45/00:06:37, 1.430s/it]
[2025-08-27 18:31:37,660][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00039/00310] [00:00:57/00:06:30, 1.445s/it]
[2025-08-27 18:31:50,281][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00047/00310] [00:01:10/00:06:24, 1.467s/it]
[2025-08-27 18:32:02,271][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00055/00310] [00:01:22/00:06:13, 1.472s/it]
[2025-08-27 18:32:14,484][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00063/00310] [00:01:34/00:06:03, 1.479s/it]
[2025-08-27 18:32:26,555][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00071/00310] [00:01:46/00:05:52, 1.482s/it]
[2025-08-27 18:32:38,257][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00079/00310] [00:01:58/00:05:40, 1.480s/it]
[2025-08-27 18:32:50,000][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00087/00310] [00:02:10/00:05:28, 1.479s/it]
[2025-08-27 18:33:02,881][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00095/00310] [00:02:23/00:05:18, 1.490s/it]
[2025-08-27 18:33:14,910][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00103/00310] [00:02:35/00:05:07, 1.491s/it]
[2025-08-27 18:33:26,819][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00111/00310] [00:02:46/00:04:55, 1.491s/it]
[2025-08-27 18:33:38,677][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00119/00310] [00:02:58/00:04:43, 1.490s/it]
[2025-08-27 18:33:50,611][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00127/00310] [00:03:10/00:04:31, 1.490s/it]
[2025-08-27 18:34:02,898][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00135/00310] [00:03:23/00:04:19, 1.493s/it]
[2025-08-27 18:34:14,431][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00143/00310] [00:03:34/00:04:07, 1.490s/it]
[2025-08-27 18:34:23,927][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00151/00310] [00:03:44/00:03:52, 1.474s/it]
[2025-08-27 18:34:34,052][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00159/00310] [00:03:54/00:03:39, 1.464s/it]
[2025-08-27 18:34:46,209][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00167/00310] [00:04:06/00:03:28, 1.466s/it]
[2025-08-27 18:34:55,271][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00175/00310] [00:04:15/00:03:14, 1.451s/it]
[2025-08-27 18:35:04,748][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00183/00310] [00:04:24/00:03:01, 1.440s/it]
[2025-08-27 18:35:16,176][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00191/00310] [00:04:36/00:02:49, 1.439s/it]
[2025-08-27 18:35:27,947][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00199/00310] [00:04:48/00:02:38, 1.440s/it]
[2025-08-27 18:35:38,995][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00207/00310] [00:04:59/00:02:26, 1.438s/it]
[2025-08-27 18:35:50,268][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00215/00310] [00:05:10/00:02:15, 1.437s/it]
[2025-08-27 18:36:01,792][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00223/00310] [00:05:21/00:02:03, 1.437s/it]
[2025-08-27 18:36:13,238][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00231/00310] [00:05:33/00:01:52, 1.437s/it]
[2025-08-27 18:36:24,590][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00239/00310] [00:05:44/00:01:40, 1.436s/it]
[2025-08-27 18:36:35,299][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00247/00310] [00:05:55/00:01:28, 1.433s/it]
[2025-08-27 18:36:46,978][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00255/00310] [00:06:07/00:01:17, 1.434s/it]
[2025-08-27 18:36:58,558][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00263/00310] [00:06:18/00:01:05, 1.434s/it]
[2025-08-27 18:37:09,983][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00271/00310] [00:06:30/00:00:54, 1.434s/it]
[2025-08-27 18:37:21,790][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00279/00310] [00:06:41/00:00:43, 1.435s/it]
[2025-08-27 18:37:33,566][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00287/00310] [00:06:53/00:00:31, 1.436s/it]
[2025-08-27 18:37:44,724][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00295/00310] [00:07:04/00:00:20, 1.435s/it]
[2025-08-27 18:37:57,441][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00303/00310] [00:07:17/00:00:08, 1.439s/it]
[2025-08-27 18:38:06,980][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.31520, valid_loss=1.46936
[2025-08-27 18:38:06,980][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-27 18:38:06,980][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.480
[2025-08-27 18:38:06,981][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.158
[2025-08-27 18:38:06,981][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.163
[2025-08-27 18:38:06,981][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.088
[2025-08-27 18:38:06,991][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 23:11:20, remaining time 00:00:00, 00:46:22 per epoch
[2025-08-27 18:38:08,092][__main__][INFO] - InstaNovo training finished.
