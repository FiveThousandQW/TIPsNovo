[2025-08-26 19:24:52,405][__main__][INFO] - Initializing training.
[2025-08-26 19:24:52,405][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-26 19:24:52,405][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-26 19:24:52,405][__main__][INFO] - CUDA version: 12.1
[2025-08-26 19:24:52,410][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_trainValid_split/train/*.parquet
valid_path: /data/48/wuqian/Proteometools/part1/parquet/1461_trainValid_split/valid/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 1461high_TrainValid_split_noLazy
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 1
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: false
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-26 19:24:52,414][__main__][INFO] - Starting transformer training
[2025-08-26 19:24:52,414][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-26 19:24:52,414][__main__][INFO] - Loading data
[2025-08-26 19:25:04,094][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-26 19:25:10,314][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-26 19:25:13,573][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-26 19:25:13,573][__main__][INFO] - New residues found: 
{'O'}
[2025-08-26 19:25:13,573][__main__][INFO] - Residues supported: 
{'H', 'L', 'I', 'G', 'M[UNIMOD:35]', 'C[UNIMOD:4]', '[UNIMOD:1]', 'S', '[EOS]', 'M', 'R', 'W', '[SOS]', 'K', 'S[UNIMOD:21]', 'E', 'A', 'N[UNIMOD:7]', 'P', 'Y', 'Q[UNIMOD:7]', '[UNIMOD:5]', 'V', 'F', 'T', '[PAD]', 'T[UNIMOD:21]', 'N', 'Q', 'Y[UNIMOD:21]', 'D', 'C', '[UNIMOD:385]'}
[2025-08-26 19:25:44,701][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-26 19:25:44,701][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-26 19:26:12,512][__main__][INFO] - Data loaded: 1,182,693 training samples; 79,338 validation samples
[2025-08-26 19:26:12,741][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-26 19:26:12,772][__main__][INFO] - No data leakage!
[2025-08-26 19:26:12,772][__main__][INFO] - Model checkpointing every 0.32 epochs.
[2025-08-26 19:26:12,773][__main__][INFO] - Updates per epoch: 6,160, step_scale=0.16666666666666666
[2025-08-26 19:26:19,002][__main__][INFO] - Sample batch:
[2025-08-26 19:26:19,002][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-26 19:26:19,002][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-26 19:26:19,002][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-26 19:26:19,002][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-26 19:26:19,002][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-26 19:26:19,128][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-26 19:26:19,128][__main__][INFO] - Test forward pass:
[2025-08-26 19:26:29,096][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-26 19:26:29,967][__main__][INFO] - Model saving enabled
[2025-08-26 19:26:29,967][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-26 19:26:29,967][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-26 19:26:29,974][__main__][INFO] - InstaNovo training started.
[2025-08-26 19:26:30,652][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 19:26:42,045][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00310] [00:00:11/00:07:10, 1.424s/it]
[2025-08-26 19:26:51,620][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/03080] [00:00:05/00:35:14, 0.688s/it]: train_loss_raw=3.4976, running_loss=3.5959, LR=0.000001
[2025-08-26 19:26:57,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/03080] [00:00:11/00:36:14, 0.710s/it]: train_loss_raw=3.2088, running_loss=3.5752, LR=0.000003
[2025-08-26 19:27:03,359][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/03080] [00:00:17/00:36:35, 0.719s/it]: train_loss_raw=3.0601, running_loss=3.5389, LR=0.000005
[2025-08-26 19:27:09,258][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/03080] [00:00:23/00:36:44, 0.723s/it]: train_loss_raw=2.9882, running_loss=3.4988, LR=0.000006
[2025-08-26 19:27:15,068][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/03080] [00:00:28/00:36:40, 0.724s/it]: train_loss_raw=2.9586, running_loss=3.4585, LR=0.000008
[2025-08-26 19:27:21,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/03080] [00:00:34/00:36:48, 0.728s/it]: train_loss_raw=2.9314, running_loss=3.4191, LR=0.000010
[2025-08-26 19:27:26,923][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/03080] [00:00:40/00:36:43, 0.729s/it]: train_loss_raw=2.8961, running_loss=3.3804, LR=0.000011
[2025-08-26 19:27:32,687][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/03080] [00:00:46/00:36:34, 0.728s/it]: train_loss_raw=2.8172, running_loss=3.3389, LR=0.000013
[2025-08-26 19:27:38,642][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/03080] [00:00:52/00:36:34, 0.730s/it]: train_loss_raw=2.7490, running_loss=3.2954, LR=0.000015
[2025-08-26 19:27:44,384][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/03080] [00:00:58/00:36:25, 0.728s/it]: train_loss_raw=2.7237, running_loss=3.2532, LR=0.000016
[2025-08-26 19:27:50,271][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/03080] [00:01:04/00:36:21, 0.729s/it]: train_loss_raw=2.7324, running_loss=3.2129, LR=0.000018
[2025-08-26 19:27:56,223][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/03080] [00:01:10/00:36:19, 0.730s/it]: train_loss_raw=2.7176, running_loss=3.1751, LR=0.000020
[2025-08-26 19:28:02,175][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/03080] [00:01:16/00:36:16, 0.731s/it]: train_loss_raw=2.6885, running_loss=3.1397, LR=0.000021
[2025-08-26 19:28:08,105][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/03080] [00:01:21/00:36:12, 0.732s/it]: train_loss_raw=2.6932, running_loss=3.1067, LR=0.000023
[2025-08-26 19:28:13,992][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/03080] [00:01:27/00:36:07, 0.732s/it]: train_loss_raw=2.6985, running_loss=3.0758, LR=0.000025
[2025-08-26 19:28:19,852][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/03080] [00:01:33/00:36:01, 0.732s/it]: train_loss_raw=2.6909, running_loss=3.0462, LR=0.000026
[2025-08-26 19:28:25,675][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/03080] [00:01:39/00:35:55, 0.732s/it]: train_loss_raw=2.6772, running_loss=3.0187, LR=0.000028
[2025-08-26 19:28:31,489][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/03080] [00:01:45/00:35:48, 0.732s/it]: train_loss_raw=2.6980, running_loss=2.9930, LR=0.000030
[2025-08-26 19:28:37,287][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/03080] [00:01:51/00:35:41, 0.731s/it]: train_loss_raw=2.7013, running_loss=2.9690, LR=0.000031
[2025-08-26 19:28:42,913][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/03080] [00:01:56/00:35:31, 0.730s/it]: train_loss_raw=2.6775, running_loss=2.9465, LR=0.000033
[2025-08-26 19:28:48,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/03080] [00:02:02/00:35:25, 0.730s/it]: train_loss_raw=2.6837, running_loss=2.9256, LR=0.000035
[2025-08-26 19:28:54,618][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/03080] [00:02:08/00:35:20, 0.730s/it]: train_loss_raw=2.6767, running_loss=2.9064, LR=0.000036
[2025-08-26 19:29:00,401][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/03080] [00:02:14/00:35:13, 0.730s/it]: train_loss_raw=2.6908, running_loss=2.8882, LR=0.000038
[2025-08-26 19:29:06,321][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/03080] [00:02:20/00:35:08, 0.730s/it]: train_loss_raw=2.6651, running_loss=2.8716, LR=0.000040
[2025-08-26 19:29:12,247][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/03080] [00:02:26/00:35:04, 0.731s/it]: train_loss_raw=2.6720, running_loss=2.8566, LR=0.000041
[2025-08-26 19:29:18,130][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/03080] [00:02:32/00:34:59, 0.731s/it]: train_loss_raw=2.6434, running_loss=2.8422, LR=0.000043
[2025-08-26 19:29:23,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/03080] [00:02:37/00:34:53, 0.731s/it]: train_loss_raw=2.6880, running_loss=2.8287, LR=0.000045
[2025-08-26 19:29:29,898][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/03080] [00:02:43/00:34:48, 0.731s/it]: train_loss_raw=2.6511, running_loss=2.8161, LR=0.000046
[2025-08-26 19:29:35,687][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/03080] [00:02:49/00:34:41, 0.731s/it]: train_loss_raw=2.6614, running_loss=2.8039, LR=0.000048
[2025-08-26 19:29:41,612][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/03080] [00:02:55/00:34:36, 0.731s/it]: train_loss_raw=2.6443, running_loss=2.7930, LR=0.000050
[2025-08-26 19:29:47,458][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/03080] [00:03:01/00:34:30, 0.731s/it]: train_loss_raw=2.6852, running_loss=2.7829, LR=0.000051
[2025-08-26 19:29:53,315][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/03080] [00:03:07/00:34:25, 0.731s/it]: train_loss_raw=2.6425, running_loss=2.7734, LR=0.000053
[2025-08-26 19:29:59,213][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/03080] [00:03:13/00:34:19, 0.731s/it]: train_loss_raw=2.6527, running_loss=2.7645, LR=0.000055
[2025-08-26 19:30:05,135][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/03080] [00:03:19/00:34:14, 0.732s/it]: train_loss_raw=2.6616, running_loss=2.7564, LR=0.000056
[2025-08-26 19:30:11,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/03080] [00:03:25/00:34:10, 0.732s/it]: train_loss_raw=2.6407, running_loss=2.7482, LR=0.000058
[2025-08-26 19:30:17,230][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/03080] [00:03:31/00:34:06, 0.733s/it]: train_loss_raw=2.6606, running_loss=2.7417, LR=0.000060
[2025-08-26 19:30:23,245][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/03080] [00:03:37/00:34:02, 0.734s/it]: train_loss_raw=2.6617, running_loss=2.7349, LR=0.000061
[2025-08-26 19:30:29,170][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/03080] [00:03:43/00:33:56, 0.734s/it]: train_loss_raw=2.6772, running_loss=2.7294, LR=0.000063
[2025-08-26 19:30:35,241][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/03080] [00:03:49/00:33:52, 0.734s/it]: train_loss_raw=2.6226, running_loss=2.7225, LR=0.000065
[2025-08-26 19:30:41,140][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/03080] [00:03:55/00:33:47, 0.734s/it]: train_loss_raw=2.6548, running_loss=2.7160, LR=0.000066
[2025-08-26 19:30:47,124][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/03080] [00:04:01/00:33:42, 0.735s/it]: train_loss_raw=2.6361, running_loss=2.7104, LR=0.000068
[2025-08-26 19:30:53,014][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/03080] [00:04:06/00:33:36, 0.735s/it]: train_loss_raw=2.6092, running_loss=2.7048, LR=0.000070
[2025-08-26 19:30:58,826][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/03080] [00:04:12/00:33:29, 0.735s/it]: train_loss_raw=2.6607, running_loss=2.7009, LR=0.000071
[2025-08-26 19:31:04,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/03080] [00:04:18/00:33:23, 0.734s/it]: train_loss_raw=2.6463, running_loss=2.6967, LR=0.000073
[2025-08-26 19:31:10,379][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/03080] [00:04:24/00:33:16, 0.734s/it]: train_loss_raw=2.6109, running_loss=2.6924, LR=0.000075
[2025-08-26 19:31:16,441][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/03080] [00:04:30/00:33:12, 0.735s/it]: train_loss_raw=2.6261, running_loss=2.6881, LR=0.000076
[2025-08-26 19:31:22,381][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/03080] [00:04:36/00:33:06, 0.735s/it]: train_loss_raw=2.6469, running_loss=2.6847, LR=0.000078
[2025-08-26 19:31:28,443][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/03080] [00:04:42/00:33:02, 0.735s/it]: train_loss_raw=2.6235, running_loss=2.6803, LR=0.000080
[2025-08-26 19:31:34,437][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/03080] [00:04:48/00:32:57, 0.736s/it]: train_loss_raw=2.6373, running_loss=2.6765, LR=0.000081
[2025-08-26 19:31:40,637][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/03080] [00:04:54/00:32:53, 0.736s/it]: train_loss_raw=2.6148, running_loss=2.6733, LR=0.000083
[2025-08-26 19:31:46,877][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/03080] [00:05:00/00:32:49, 0.737s/it]: train_loss_raw=2.6586, running_loss=2.6706, LR=0.000085
[2025-08-26 19:31:52,868][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/03080] [00:05:06/00:32:44, 0.737s/it]: train_loss_raw=2.6576, running_loss=2.6682, LR=0.000086
[2025-08-26 19:31:59,063][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/03080] [00:05:12/00:32:40, 0.738s/it]: train_loss_raw=2.6656, running_loss=2.6653, LR=0.000088
[2025-08-26 19:32:05,236][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/03080] [00:05:19/00:32:36, 0.739s/it]: train_loss_raw=2.6169, running_loss=2.6620, LR=0.000090
[2025-08-26 19:32:11,459][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/03080] [00:05:25/00:32:32, 0.739s/it]: train_loss_raw=2.6422, running_loss=2.6600, LR=0.000091
[2025-08-26 19:32:17,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/03080] [00:05:31/00:32:29, 0.741s/it]: train_loss_raw=2.6119, running_loss=2.6578, LR=0.000093
[2025-08-26 19:32:23,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/03080] [00:05:37/00:32:23, 0.741s/it]: train_loss_raw=2.5918, running_loss=2.6547, LR=0.000095
[2025-08-26 19:32:30,102][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/03080] [00:05:43/00:32:19, 0.741s/it]: train_loss_raw=2.6007, running_loss=2.6519, LR=0.000096
[2025-08-26 19:32:36,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/03080] [00:05:50/00:32:15, 0.742s/it]: train_loss_raw=2.5941, running_loss=2.6491, LR=0.000098
[2025-08-26 19:32:42,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/03080] [00:05:56/00:32:10, 0.743s/it]: train_loss_raw=2.6194, running_loss=2.6465, LR=0.000100
[2025-08-26 19:32:48,856][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/03080] [00:06:02/00:32:06, 0.743s/it]: train_loss_raw=2.5957, running_loss=2.6428, LR=0.000100
[2025-08-26 19:32:55,076][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/03080] [00:06:08/00:32:02, 0.744s/it]: train_loss_raw=2.6148, running_loss=2.6401, LR=0.000100
[2025-08-26 19:33:01,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/03080] [00:06:15/00:31:58, 0.745s/it]: train_loss_raw=2.5932, running_loss=2.6365, LR=0.000100
[2025-08-26 19:33:07,533][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/03080] [00:06:21/00:31:53, 0.745s/it]: train_loss_raw=2.6275, running_loss=2.6329, LR=0.000100
[2025-08-26 19:33:13,761][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/03080] [00:06:27/00:31:48, 0.745s/it]: train_loss_raw=2.6352, running_loss=2.6307, LR=0.000100
[2025-08-26 19:33:19,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/03080] [00:06:33/00:31:43, 0.746s/it]: train_loss_raw=2.5880, running_loss=2.6280, LR=0.000100
[2025-08-26 19:33:26,091][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/03080] [00:06:39/00:31:38, 0.746s/it]: train_loss_raw=2.6104, running_loss=2.6254, LR=0.000100
[2025-08-26 19:33:32,085][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/03080] [00:06:45/00:31:32, 0.746s/it]: train_loss_raw=2.5361, running_loss=2.6218, LR=0.000100
[2025-08-26 19:33:38,348][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/03080] [00:06:52/00:31:27, 0.747s/it]: train_loss_raw=2.5856, running_loss=2.6191, LR=0.000100
[2025-08-26 19:33:44,584][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/03080] [00:06:58/00:31:23, 0.747s/it]: train_loss_raw=2.5665, running_loss=2.6163, LR=0.000100
[2025-08-26 19:33:50,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/03080] [00:07:04/00:31:18, 0.748s/it]: train_loss_raw=2.6335, running_loss=2.6137, LR=0.000100
[2025-08-26 19:33:56,998][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/03080] [00:07:10/00:31:13, 0.748s/it]: train_loss_raw=2.5405, running_loss=2.6101, LR=0.000100
[2025-08-26 19:34:03,273][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/03080] [00:07:17/00:31:08, 0.749s/it]: train_loss_raw=2.5344, running_loss=2.6064, LR=0.000100
[2025-08-26 19:34:09,479][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/03080] [00:07:23/00:31:03, 0.749s/it]: train_loss_raw=2.5890, running_loss=2.6035, LR=0.000100
[2025-08-26 19:34:15,158][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/03080] [00:07:29/00:30:56, 0.748s/it]: train_loss_raw=2.5202, running_loss=2.5993, LR=0.000100
[2025-08-26 19:34:21,331][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/03080] [00:07:35/00:30:50, 0.749s/it]: train_loss_raw=2.5642, running_loss=2.5956, LR=0.000100
[2025-08-26 19:34:27,559][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/03080] [00:07:41/00:30:45, 0.749s/it]: train_loss_raw=2.5369, running_loss=2.5925, LR=0.000100
[2025-08-26 19:34:33,661][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/03080] [00:07:47/00:30:40, 0.749s/it]: train_loss_raw=2.5311, running_loss=2.5897, LR=0.000100
[2025-08-26 19:34:39,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/03080] [00:07:53/00:30:33, 0.749s/it]: train_loss_raw=2.5491, running_loss=2.5857, LR=0.000100
[2025-08-26 19:34:45,462][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/03080] [00:07:59/00:30:27, 0.749s/it]: train_loss_raw=2.4579, running_loss=2.5838, LR=0.000100
[2025-08-26 19:34:51,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/03080] [00:08:05/00:30:21, 0.749s/it]: train_loss_raw=2.5304, running_loss=2.5801, LR=0.000100
[2025-08-26 19:34:57,294][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/03080] [00:08:11/00:30:14, 0.749s/it]: train_loss_raw=2.6380, running_loss=2.5771, LR=0.000100
[2025-08-26 19:35:03,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/03080] [00:08:17/00:30:08, 0.749s/it]: train_loss_raw=2.5618, running_loss=2.5727, LR=0.000100
[2025-08-26 19:35:09,117][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/03080] [00:08:23/00:30:02, 0.749s/it]: train_loss_raw=2.4789, running_loss=2.5681, LR=0.000100
[2025-08-26 19:35:15,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/03080] [00:08:28/00:29:56, 0.748s/it]: train_loss_raw=2.4678, running_loss=2.5626, LR=0.000100
[2025-08-26 19:35:20,775][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/03080] [00:08:34/00:29:49, 0.748s/it]: train_loss_raw=2.5637, running_loss=2.5592, LR=0.000100
[2025-08-26 19:35:26,549][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/03080] [00:08:40/00:29:42, 0.748s/it]: train_loss_raw=2.4991, running_loss=2.5548, LR=0.000100
[2025-08-26 19:35:32,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/03080] [00:08:46/00:29:36, 0.748s/it]: train_loss_raw=2.4876, running_loss=2.5502, LR=0.000100
[2025-08-26 19:35:38,712][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/03080] [00:08:52/00:29:31, 0.748s/it]: train_loss_raw=2.5133, running_loss=2.5480, LR=0.000100
[2025-08-26 19:35:44,581][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/03080] [00:08:58/00:29:24, 0.748s/it]: train_loss_raw=2.5467, running_loss=2.5457, LR=0.000100
[2025-08-26 19:35:50,556][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/03080] [00:09:04/00:29:18, 0.748s/it]: train_loss_raw=2.5065, running_loss=2.5434, LR=0.000100
[2025-08-26 19:35:56,437][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/03080] [00:09:10/00:29:12, 0.748s/it]: train_loss_raw=2.5338, running_loss=2.5407, LR=0.000100
[2025-08-26 19:36:02,438][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/03080] [00:09:16/00:29:06, 0.748s/it]: train_loss_raw=2.5155, running_loss=2.5390, LR=0.000100
[2025-08-26 19:36:08,558][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/03080] [00:09:22/00:29:01, 0.748s/it]: train_loss_raw=2.4948, running_loss=2.5353, LR=0.000100
[2025-08-26 19:36:14,658][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/03080] [00:09:28/00:28:55, 0.748s/it]: train_loss_raw=2.4966, running_loss=2.5316, LR=0.000100
[2025-08-26 19:36:20,675][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/03080] [00:09:34/00:28:49, 0.748s/it]: train_loss_raw=2.5307, running_loss=2.5284, LR=0.000100
[2025-08-26 19:36:26,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/03080] [00:09:40/00:28:43, 0.748s/it]: train_loss_raw=2.4828, running_loss=2.5246, LR=0.000100
[2025-08-26 19:36:32,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/03080] [00:09:46/00:28:37, 0.748s/it]: train_loss_raw=2.4323, running_loss=2.5222, LR=0.000100
[2025-08-26 19:36:38,663][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/03080] [00:09:52/00:28:31, 0.748s/it]: train_loss_raw=2.5052, running_loss=2.5201, LR=0.000100
[2025-08-26 19:36:44,580][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/03080] [00:09:58/00:28:25, 0.748s/it]: train_loss_raw=2.4721, running_loss=2.5173, LR=0.000100
[2025-08-26 19:36:50,487][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/03080] [00:10:04/00:28:19, 0.748s/it]: train_loss_raw=2.4873, running_loss=2.5136, LR=0.000100
[2025-08-26 19:36:56,505][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/03080] [00:10:10/00:28:13, 0.748s/it]: train_loss_raw=2.3973, running_loss=2.5107, LR=0.000100
[2025-08-26 19:37:02,175][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000824] [Batch 00824/03080] [00:10:16/00:28:06, 0.748s/it]: train_loss_raw=2.4899, running_loss=2.5082, LR=0.000100
[2025-08-26 19:37:07,837][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000832] [Batch 00832/03080] [00:10:21/00:27:59, 0.747s/it]: train_loss_raw=2.4826, running_loss=2.5047, LR=0.000100
[2025-08-26 19:37:13,907][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/03080] [00:10:27/00:27:54, 0.747s/it]: train_loss_raw=2.4518, running_loss=2.5029, LR=0.000100
[2025-08-26 19:37:19,780][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000848] [Batch 00848/03080] [00:10:33/00:27:47, 0.747s/it]: train_loss_raw=2.3791, running_loss=2.5002, LR=0.000100
[2025-08-26 19:37:25,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000856] [Batch 00856/03080] [00:10:39/00:27:41, 0.747s/it]: train_loss_raw=2.4513, running_loss=2.4973, LR=0.000100
[2025-08-26 19:37:31,346][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/03080] [00:10:45/00:27:34, 0.747s/it]: train_loss_raw=2.4866, running_loss=2.4955, LR=0.000100
[2025-08-26 19:37:37,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000872] [Batch 00872/03080] [00:10:51/00:27:28, 0.747s/it]: train_loss_raw=2.4517, running_loss=2.4937, LR=0.000100
[2025-08-26 19:37:43,135][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000880] [Batch 00880/03080] [00:10:57/00:27:22, 0.747s/it]: train_loss_raw=2.4390, running_loss=2.4920, LR=0.000100
[2025-08-26 19:37:49,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/03080] [00:11:03/00:27:16, 0.747s/it]: train_loss_raw=2.4453, running_loss=2.4901, LR=0.000100
[2025-08-26 19:37:55,027][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000896] [Batch 00896/03080] [00:11:08/00:27:10, 0.747s/it]: train_loss_raw=2.4361, running_loss=2.4889, LR=0.000100
[2025-08-26 19:38:00,822][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000904] [Batch 00904/03080] [00:11:14/00:27:04, 0.746s/it]: train_loss_raw=2.4419, running_loss=2.4861, LR=0.000100
[2025-08-26 19:38:06,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/03080] [00:11:20/00:26:57, 0.746s/it]: train_loss_raw=2.4431, running_loss=2.4843, LR=0.000100
[2025-08-26 19:38:12,665][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000920] [Batch 00920/03080] [00:11:26/00:26:51, 0.746s/it]: train_loss_raw=2.4236, running_loss=2.4820, LR=0.000100
[2025-08-26 19:38:18,333][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000928] [Batch 00928/03080] [00:11:32/00:26:45, 0.746s/it]: train_loss_raw=2.5096, running_loss=2.4809, LR=0.000100
[2025-08-26 19:38:24,285][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/03080] [00:11:38/00:26:39, 0.746s/it]: train_loss_raw=2.4544, running_loss=2.4781, LR=0.000100
[2025-08-26 19:38:30,195][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000944] [Batch 00944/03080] [00:11:44/00:26:33, 0.746s/it]: train_loss_raw=2.4457, running_loss=2.4750, LR=0.000100
[2025-08-26 19:38:36,057][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000952] [Batch 00952/03080] [00:11:49/00:26:26, 0.746s/it]: train_loss_raw=2.4627, running_loss=2.4715, LR=0.000100
[2025-08-26 19:38:42,020][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/03080] [00:11:55/00:26:20, 0.746s/it]: train_loss_raw=2.4026, running_loss=2.4693, LR=0.000100
[2025-08-26 19:38:47,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000968] [Batch 00968/03080] [00:12:01/00:26:14, 0.746s/it]: train_loss_raw=2.4515, running_loss=2.4677, LR=0.000100
[2025-08-26 19:38:53,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000976] [Batch 00976/03080] [00:12:07/00:26:08, 0.746s/it]: train_loss_raw=2.5082, running_loss=2.4648, LR=0.000100
[2025-08-26 19:38:59,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/03080] [00:12:13/00:26:02, 0.746s/it]: train_loss_raw=2.4567, running_loss=2.4628, LR=0.000100
[2025-08-26 19:39:05,760][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000992] [Batch 00992/03080] [00:12:19/00:25:56, 0.746s/it]: train_loss_raw=2.4581, running_loss=2.4607, LR=0.000100
[2025-08-26 19:39:11,651][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001000] [Batch 01000/03080] [00:12:25/00:25:50, 0.746s/it]: train_loss_raw=2.3996, running_loss=2.4571, LR=0.000100
[2025-08-26 19:39:17,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/03080] [00:12:31/00:25:44, 0.745s/it]: train_loss_raw=2.3767, running_loss=2.4547, LR=0.000100
[2025-08-26 19:39:23,447][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001016] [Batch 01016/03080] [00:12:37/00:25:38, 0.745s/it]: train_loss_raw=2.4703, running_loss=2.4542, LR=0.000100
[2025-08-26 19:39:29,369][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001024] [Batch 01024/03080] [00:12:43/00:25:32, 0.745s/it]: train_loss_raw=2.4128, running_loss=2.4533, LR=0.000100
[2025-08-26 19:39:35,245][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/03080] [00:12:49/00:25:26, 0.745s/it]: train_loss_raw=2.4414, running_loss=2.4517, LR=0.000100
[2025-08-26 19:39:41,285][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001040] [Batch 01040/03080] [00:12:55/00:25:20, 0.745s/it]: train_loss_raw=2.4449, running_loss=2.4511, LR=0.000100
[2025-08-26 19:39:47,283][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001048] [Batch 01048/03080] [00:13:01/00:25:14, 0.745s/it]: train_loss_raw=2.4132, running_loss=2.4491, LR=0.000100
[2025-08-26 19:39:53,170][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/03080] [00:13:07/00:25:08, 0.745s/it]: train_loss_raw=2.4345, running_loss=2.4463, LR=0.000100
[2025-08-26 19:39:59,128][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001064] [Batch 01064/03080] [00:13:13/00:25:02, 0.745s/it]: train_loss_raw=2.4741, running_loss=2.4450, LR=0.000100
[2025-08-26 19:40:04,950][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001072] [Batch 01072/03080] [00:13:18/00:24:56, 0.745s/it]: train_loss_raw=2.4164, running_loss=2.4447, LR=0.000100
[2025-08-26 19:40:10,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/03080] [00:13:24/00:24:50, 0.745s/it]: train_loss_raw=2.4637, running_loss=2.4429, LR=0.000100
[2025-08-26 19:40:16,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001088] [Batch 01088/03080] [00:13:30/00:24:44, 0.745s/it]: train_loss_raw=2.4487, running_loss=2.4431, LR=0.000100
[2025-08-26 19:40:22,835][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001096] [Batch 01096/03080] [00:13:36/00:24:38, 0.745s/it]: train_loss_raw=2.3645, running_loss=2.4388, LR=0.000100
[2025-08-26 19:40:28,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/03080] [00:13:42/00:24:32, 0.745s/it]: train_loss_raw=2.4238, running_loss=2.4369, LR=0.000100
[2025-08-26 19:40:34,420][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001112] [Batch 01112/03080] [00:13:48/00:24:25, 0.745s/it]: train_loss_raw=2.4227, running_loss=2.4360, LR=0.000100
[2025-08-26 19:40:40,281][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001120] [Batch 01120/03080] [00:13:54/00:24:19, 0.745s/it]: train_loss_raw=2.3918, running_loss=2.4341, LR=0.000100
[2025-08-26 19:40:46,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/03080] [00:14:00/00:24:13, 0.745s/it]: train_loss_raw=2.4034, running_loss=2.4322, LR=0.000100
[2025-08-26 19:40:51,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001136] [Batch 01136/03080] [00:14:05/00:24:07, 0.745s/it]: train_loss_raw=2.3831, running_loss=2.4310, LR=0.000100
[2025-08-26 19:40:57,831][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001144] [Batch 01144/03080] [00:14:11/00:24:01, 0.745s/it]: train_loss_raw=2.4426, running_loss=2.4311, LR=0.000100
[2025-08-26 19:41:03,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/03080] [00:14:17/00:23:55, 0.744s/it]: train_loss_raw=2.4196, running_loss=2.4294, LR=0.000100
[2025-08-26 19:41:09,540][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001160] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=2.4584, running_loss=2.4267, LR=0.000100
[2025-08-26 19:41:15,419][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001168] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=2.3859, running_loss=2.4251, LR=0.000100
[2025-08-26 19:41:21,424][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/03080] [00:14:35/00:23:37, 0.744s/it]: train_loss_raw=2.3408, running_loss=2.4213, LR=0.000100
[2025-08-26 19:41:27,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001184] [Batch 01184/03080] [00:14:41/00:23:31, 0.744s/it]: train_loss_raw=2.4210, running_loss=2.4203, LR=0.000100
[2025-08-26 19:41:33,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001192] [Batch 01192/03080] [00:14:47/00:23:25, 0.744s/it]: train_loss_raw=2.3794, running_loss=2.4204, LR=0.000100
[2025-08-26 19:41:39,275][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/03080] [00:14:53/00:23:19, 0.744s/it]: train_loss_raw=2.4590, running_loss=2.4209, LR=0.000100
[2025-08-26 19:41:45,079][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001208] [Batch 01208/03080] [00:14:58/00:23:13, 0.744s/it]: train_loss_raw=2.4589, running_loss=2.4201, LR=0.000100
[2025-08-26 19:41:50,850][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001216] [Batch 01216/03080] [00:15:04/00:23:06, 0.744s/it]: train_loss_raw=2.3870, running_loss=2.4175, LR=0.000100
[2025-08-26 19:41:56,816][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/03080] [00:15:10/00:23:00, 0.744s/it]: train_loss_raw=2.4134, running_loss=2.4173, LR=0.000100
[2025-08-26 19:42:02,802][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001232] [Batch 01232/03080] [00:15:16/00:22:55, 0.744s/it]: train_loss_raw=2.4476, running_loss=2.4160, LR=0.000100
[2025-08-26 19:42:08,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001240] [Batch 01240/03080] [00:15:22/00:22:48, 0.744s/it]: train_loss_raw=2.4185, running_loss=2.4143, LR=0.000100
[2025-08-26 19:42:14,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/03080] [00:15:28/00:22:42, 0.744s/it]: train_loss_raw=2.3500, running_loss=2.4143, LR=0.000100
[2025-08-26 19:42:20,544][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001256] [Batch 01256/03080] [00:15:34/00:22:37, 0.744s/it]: train_loss_raw=2.4775, running_loss=2.4138, LR=0.000100
[2025-08-26 19:42:26,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001264] [Batch 01264/03080] [00:15:40/00:22:31, 0.744s/it]: train_loss_raw=2.3687, running_loss=2.4120, LR=0.000100
[2025-08-26 19:42:32,413][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/03080] [00:15:46/00:22:25, 0.744s/it]: train_loss_raw=2.4475, running_loss=2.4126, LR=0.000100
[2025-08-26 19:42:38,446][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001280] [Batch 01280/03080] [00:15:52/00:22:19, 0.744s/it]: train_loss_raw=2.3450, running_loss=2.4108, LR=0.000100
[2025-08-26 19:42:44,494][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001288] [Batch 01288/03080] [00:15:58/00:22:13, 0.744s/it]: train_loss_raw=2.4323, running_loss=2.4103, LR=0.000100
[2025-08-26 19:42:50,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=2.3659, running_loss=2.4085, LR=0.000100
[2025-08-26 19:42:56,399][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001304] [Batch 01304/03080] [00:16:10/00:22:01, 0.744s/it]: train_loss_raw=2.3620, running_loss=2.4056, LR=0.000100
[2025-08-26 19:43:02,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001312] [Batch 01312/03080] [00:16:15/00:21:55, 0.744s/it]: train_loss_raw=2.4329, running_loss=2.4053, LR=0.000100
[2025-08-26 19:43:07,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/03080] [00:16:21/00:21:49, 0.744s/it]: train_loss_raw=2.4185, running_loss=2.4042, LR=0.000100
[2025-08-26 19:43:13,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001328] [Batch 01328/03080] [00:16:27/00:21:43, 0.744s/it]: train_loss_raw=2.4129, running_loss=2.4028, LR=0.000100
[2025-08-26 19:43:19,911][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001336] [Batch 01336/03080] [00:16:33/00:21:37, 0.744s/it]: train_loss_raw=2.4334, running_loss=2.4019, LR=0.000100
[2025-08-26 19:43:25,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/03080] [00:16:39/00:21:31, 0.744s/it]: train_loss_raw=2.4061, running_loss=2.4032, LR=0.000100
[2025-08-26 19:43:31,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001352] [Batch 01352/03080] [00:16:45/00:21:25, 0.744s/it]: train_loss_raw=2.3968, running_loss=2.3989, LR=0.000100
[2025-08-26 19:43:37,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001360] [Batch 01360/03080] [00:16:51/00:21:19, 0.744s/it]: train_loss_raw=2.4008, running_loss=2.3988, LR=0.000100
[2025-08-26 19:43:43,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/03080] [00:16:57/00:21:13, 0.744s/it]: train_loss_raw=2.4590, running_loss=2.3977, LR=0.000100
[2025-08-26 19:43:49,632][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001376] [Batch 01376/03080] [00:17:03/00:21:07, 0.744s/it]: train_loss_raw=2.4182, running_loss=2.3942, LR=0.000100
[2025-08-26 19:43:55,322][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001384] [Batch 01384/03080] [00:17:09/00:21:01, 0.744s/it]: train_loss_raw=2.3875, running_loss=2.3918, LR=0.000100
[2025-08-26 19:44:01,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/03080] [00:17:15/00:20:55, 0.744s/it]: train_loss_raw=2.3533, running_loss=2.3905, LR=0.000100
[2025-08-26 19:44:07,122][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001400] [Batch 01400/03080] [00:17:21/00:20:49, 0.744s/it]: train_loss_raw=2.2887, running_loss=2.3884, LR=0.000100
[2025-08-26 19:44:12,775][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001408] [Batch 01408/03080] [00:17:26/00:20:42, 0.743s/it]: train_loss_raw=2.4064, running_loss=2.3868, LR=0.000100
[2025-08-26 19:44:18,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/03080] [00:17:32/00:20:36, 0.743s/it]: train_loss_raw=2.3527, running_loss=2.3864, LR=0.000100
[2025-08-26 19:44:24,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001424] [Batch 01424/03080] [00:17:38/00:20:30, 0.743s/it]: train_loss_raw=2.3149, running_loss=2.3826, LR=0.000100
[2025-08-26 19:44:30,104][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001432] [Batch 01432/03080] [00:17:43/00:20:24, 0.743s/it]: train_loss_raw=2.3892, running_loss=2.3835, LR=0.000100
[2025-08-26 19:44:35,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/03080] [00:17:49/00:20:18, 0.743s/it]: train_loss_raw=2.3214, running_loss=2.3817, LR=0.000100
[2025-08-26 19:44:41,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001448] [Batch 01448/03080] [00:17:55/00:20:12, 0.743s/it]: train_loss_raw=2.3619, running_loss=2.3827, LR=0.000100
[2025-08-26 19:44:47,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001456] [Batch 01456/03080] [00:18:01/00:20:06, 0.743s/it]: train_loss_raw=2.4420, running_loss=2.3812, LR=0.000100
[2025-08-26 19:44:53,711][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/03080] [00:18:07/00:20:00, 0.743s/it]: train_loss_raw=2.4252, running_loss=2.3806, LR=0.000100
[2025-08-26 19:44:59,646][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001472] [Batch 01472/03080] [00:18:13/00:19:54, 0.743s/it]: train_loss_raw=2.3688, running_loss=2.3802, LR=0.000100
[2025-08-26 19:45:05,761][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001480] [Batch 01480/03080] [00:18:19/00:19:48, 0.743s/it]: train_loss_raw=2.3224, running_loss=2.3776, LR=0.000100
[2025-08-26 19:45:11,995][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/03080] [00:18:25/00:19:43, 0.743s/it]: train_loss_raw=2.3193, running_loss=2.3769, LR=0.000100
[2025-08-26 19:45:18,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001496] [Batch 01496/03080] [00:18:31/00:19:37, 0.743s/it]: train_loss_raw=2.4153, running_loss=2.3757, LR=0.000100
[2025-08-26 19:45:24,150][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001504] [Batch 01504/03080] [00:18:38/00:19:31, 0.743s/it]: train_loss_raw=2.3846, running_loss=2.3750, LR=0.000100
[2025-08-26 19:45:30,261][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/03080] [00:18:44/00:19:25, 0.743s/it]: train_loss_raw=2.3551, running_loss=2.3737, LR=0.000100
[2025-08-26 19:45:36,542][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001520] [Batch 01520/03080] [00:18:50/00:19:20, 0.744s/it]: train_loss_raw=2.3846, running_loss=2.3714, LR=0.000100
[2025-08-26 19:45:42,771][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001528] [Batch 01528/03080] [00:18:56/00:19:14, 0.744s/it]: train_loss_raw=2.1942, running_loss=2.3685, LR=0.000100
[2025-08-26 19:45:48,977][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/03080] [00:19:02/00:19:08, 0.744s/it]: train_loss_raw=2.3374, running_loss=2.3677, LR=0.000100
[2025-08-26 19:45:55,200][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001544] [Batch 01544/03080] [00:19:09/00:19:03, 0.744s/it]: train_loss_raw=2.3227, running_loss=2.3676, LR=0.000100
[2025-08-26 19:46:01,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001552] [Batch 01552/03080] [00:19:15/00:18:57, 0.744s/it]: train_loss_raw=2.3682, running_loss=2.3685, LR=0.000100
[2025-08-26 19:46:07,650][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/03080] [00:19:21/00:18:51, 0.745s/it]: train_loss_raw=2.3348, running_loss=2.3665, LR=0.000100
[2025-08-26 19:46:13,878][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001568] [Batch 01568/03080] [00:19:27/00:18:46, 0.745s/it]: train_loss_raw=2.3726, running_loss=2.3648, LR=0.000100
[2025-08-26 19:46:20,080][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001576] [Batch 01576/03080] [00:19:33/00:18:40, 0.745s/it]: train_loss_raw=2.3144, running_loss=2.3659, LR=0.000100
[2025-08-26 19:46:26,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/03080] [00:19:40/00:18:34, 0.745s/it]: train_loss_raw=2.3585, running_loss=2.3646, LR=0.000100
[2025-08-26 19:46:32,529][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001592] [Batch 01592/03080] [00:19:46/00:18:28, 0.745s/it]: train_loss_raw=2.2813, running_loss=2.3646, LR=0.000100
[2025-08-26 19:46:38,495][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001600] [Batch 01600/03080] [00:19:52/00:18:22, 0.745s/it]: train_loss_raw=2.4223, running_loss=2.3635, LR=0.000100
[2025-08-26 19:46:44,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/03080] [00:19:58/00:18:16, 0.745s/it]: train_loss_raw=2.3565, running_loss=2.3634, LR=0.000100
[2025-08-26 19:46:50,081][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001616] [Batch 01616/03080] [00:20:03/00:18:10, 0.745s/it]: train_loss_raw=2.3289, running_loss=2.3618, LR=0.000100
[2025-08-26 19:46:56,136][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001624] [Batch 01624/03080] [00:20:10/00:18:04, 0.745s/it]: train_loss_raw=2.3697, running_loss=2.3597, LR=0.000100
[2025-08-26 19:47:02,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/03080] [00:20:16/00:17:59, 0.745s/it]: train_loss_raw=2.3002, running_loss=2.3587, LR=0.000100
[2025-08-26 19:47:08,424][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001640] [Batch 01640/03080] [00:20:22/00:17:53, 0.745s/it]: train_loss_raw=2.2954, running_loss=2.3558, LR=0.000100
[2025-08-26 19:47:14,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001648] [Batch 01648/03080] [00:20:28/00:17:47, 0.745s/it]: train_loss_raw=2.3436, running_loss=2.3547, LR=0.000100
[2025-08-26 19:47:20,176][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/03080] [00:20:34/00:17:41, 0.745s/it]: train_loss_raw=2.2126, running_loss=2.3507, LR=0.000100
[2025-08-26 19:47:26,082][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001664] [Batch 01664/03080] [00:20:39/00:17:35, 0.745s/it]: train_loss_raw=2.3726, running_loss=2.3502, LR=0.000100
[2025-08-26 19:47:31,923][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001672] [Batch 01672/03080] [00:20:45/00:17:29, 0.745s/it]: train_loss_raw=2.3581, running_loss=2.3499, LR=0.000100
[2025-08-26 19:47:38,015][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/03080] [00:20:51/00:17:23, 0.745s/it]: train_loss_raw=2.3399, running_loss=2.3484, LR=0.000100
[2025-08-26 19:47:44,227][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001688] [Batch 01688/03080] [00:20:58/00:17:17, 0.745s/it]: train_loss_raw=2.4053, running_loss=2.3476, LR=0.000100
[2025-08-26 19:47:50,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001696] [Batch 01696/03080] [00:21:04/00:17:11, 0.746s/it]: train_loss_raw=2.3121, running_loss=2.3464, LR=0.000100
[2025-08-26 19:47:56,694][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/03080] [00:21:10/00:17:06, 0.746s/it]: train_loss_raw=2.3235, running_loss=2.3443, LR=0.000100
[2025-08-26 19:48:02,931][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001712] [Batch 01712/03080] [00:21:16/00:17:00, 0.746s/it]: train_loss_raw=2.3435, running_loss=2.3439, LR=0.000100
[2025-08-26 19:48:09,130][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001720] [Batch 01720/03080] [00:21:23/00:16:54, 0.746s/it]: train_loss_raw=2.3364, running_loss=2.3417, LR=0.000100
[2025-08-26 19:48:15,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/03080] [00:21:29/00:16:48, 0.746s/it]: train_loss_raw=2.3729, running_loss=2.3403, LR=0.000100
[2025-08-26 19:48:21,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001736] [Batch 01736/03080] [00:21:35/00:16:42, 0.746s/it]: train_loss_raw=2.2931, running_loss=2.3374, LR=0.000100
[2025-08-26 19:48:27,308][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001744] [Batch 01744/03080] [00:21:41/00:16:36, 0.746s/it]: train_loss_raw=2.2593, running_loss=2.3350, LR=0.000100
[2025-08-26 19:48:33,499][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/03080] [00:21:47/00:16:30, 0.746s/it]: train_loss_raw=2.3052, running_loss=2.3348, LR=0.000100
[2025-08-26 19:48:39,697][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001760] [Batch 01760/03080] [00:21:53/00:16:25, 0.746s/it]: train_loss_raw=2.3719, running_loss=2.3337, LR=0.000100
[2025-08-26 19:48:45,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001768] [Batch 01768/03080] [00:21:59/00:16:19, 0.746s/it]: train_loss_raw=2.3612, running_loss=2.3345, LR=0.000100
[2025-08-26 19:48:52,134][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/03080] [00:22:06/00:16:13, 0.747s/it]: train_loss_raw=2.3107, running_loss=2.3344, LR=0.000100
[2025-08-26 19:48:58,360][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001784] [Batch 01784/03080] [00:22:12/00:16:07, 0.747s/it]: train_loss_raw=2.3077, running_loss=2.3323, LR=0.000100
[2025-08-26 19:49:04,559][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001792] [Batch 01792/03080] [00:22:18/00:16:02, 0.747s/it]: train_loss_raw=2.3319, running_loss=2.3317, LR=0.000100
[2025-08-26 19:49:10,779][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/03080] [00:22:24/00:15:56, 0.747s/it]: train_loss_raw=2.3080, running_loss=2.3308, LR=0.000100
[2025-08-26 19:49:17,047][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001808] [Batch 01808/03080] [00:22:30/00:15:50, 0.747s/it]: train_loss_raw=2.3199, running_loss=2.3309, LR=0.000100
[2025-08-26 19:49:22,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001816] [Batch 01816/03080] [00:22:36/00:15:44, 0.747s/it]: train_loss_raw=2.3122, running_loss=2.3313, LR=0.000100
[2025-08-26 19:49:28,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/03080] [00:22:42/00:15:38, 0.747s/it]: train_loss_raw=2.1743, running_loss=2.3275, LR=0.000100
[2025-08-26 19:49:34,686][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001832] [Batch 01832/03080] [00:22:48/00:15:32, 0.747s/it]: train_loss_raw=2.3392, running_loss=2.3265, LR=0.000100
[2025-08-26 19:49:40,900][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001840] [Batch 01840/03080] [00:22:54/00:15:26, 0.747s/it]: train_loss_raw=2.2242, running_loss=2.3266, LR=0.000100
[2025-08-26 19:49:47,141][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/03080] [00:23:01/00:15:20, 0.747s/it]: train_loss_raw=2.2378, running_loss=2.3248, LR=0.000100
[2025-08-26 19:49:53,299][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001856] [Batch 01856/03080] [00:23:07/00:15:14, 0.747s/it]: train_loss_raw=2.3524, running_loss=2.3253, LR=0.000100
[2025-08-26 19:49:59,434][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001864] [Batch 01864/03080] [00:23:13/00:15:08, 0.747s/it]: train_loss_raw=2.3334, running_loss=2.3241, LR=0.000100
[2025-08-26 19:50:05,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/03080] [00:23:19/00:15:03, 0.748s/it]: train_loss_raw=2.2606, running_loss=2.3221, LR=0.000100
[2025-08-26 19:50:11,858][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001880] [Batch 01880/03080] [00:23:25/00:14:57, 0.748s/it]: train_loss_raw=2.2909, running_loss=2.3212, LR=0.000100
[2025-08-26 19:50:18,026][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001888] [Batch 01888/03080] [00:23:31/00:14:51, 0.748s/it]: train_loss_raw=2.3621, running_loss=2.3219, LR=0.000100
[2025-08-26 19:50:24,256][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/03080] [00:23:38/00:14:45, 0.748s/it]: train_loss_raw=2.3421, running_loss=2.3204, LR=0.000100
[2025-08-26 19:50:30,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001904] [Batch 01904/03080] [00:23:44/00:14:39, 0.748s/it]: train_loss_raw=2.2870, running_loss=2.3199, LR=0.000100
[2025-08-26 19:50:36,692][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001912] [Batch 01912/03080] [00:23:50/00:14:33, 0.748s/it]: train_loss_raw=2.3030, running_loss=2.3187, LR=0.000100
[2025-08-26 19:50:42,815][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=2.2997, running_loss=2.3179, LR=0.000100
[2025-08-26 19:50:48,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001928] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=2.2090, running_loss=2.3161, LR=0.000100
[2025-08-26 19:50:54,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001936] [Batch 01936/03080] [00:24:08/00:14:15, 0.748s/it]: train_loss_raw=2.2679, running_loss=2.3159, LR=0.000100
[2025-08-26 19:51:00,793][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=2.2646, running_loss=2.3142, LR=0.000100
[2025-08-26 19:51:06,927][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001952] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=2.2962, running_loss=2.3120, LR=0.000100
[2025-08-26 19:51:13,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001960] [Batch 01960/03080] [00:24:27/00:13:58, 0.749s/it]: train_loss_raw=2.3230, running_loss=2.3117, LR=0.000100
[2025-08-26 19:51:19,418][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=2.3441, running_loss=2.3111, LR=0.000100
[2025-08-26 19:51:25,664][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001976] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=2.2814, running_loss=2.3108, LR=0.000100
[2025-08-26 19:51:31,887][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001984] [Batch 01984/03080] [00:24:45/00:13:40, 0.749s/it]: train_loss_raw=2.1841, running_loss=2.3096, LR=0.000100
[2025-08-26 19:51:38,104][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=2.3533, running_loss=2.3082, LR=0.000100
[2025-08-26 19:51:44,341][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002000] [Batch 02000/03080] [00:24:58/00:13:29, 0.749s/it]: train_loss_raw=2.2776, running_loss=2.3075, LR=0.000100
[2025-08-26 19:51:55,871][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002008] [Batch 02008/03080] [00:25:09/00:13:26, 0.752s/it]: train_loss_raw=2.3394, running_loss=2.3076, LR=0.000100
[2025-08-26 19:52:02,067][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/03080] [00:25:15/00:13:20, 0.752s/it]: train_loss_raw=2.3441, running_loss=2.3063, LR=0.000100
[2025-08-26 19:52:08,271][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002024] [Batch 02024/03080] [00:25:22/00:13:14, 0.752s/it]: train_loss_raw=2.2785, running_loss=2.3063, LR=0.000100
[2025-08-26 19:52:14,472][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002032] [Batch 02032/03080] [00:25:28/00:13:08, 0.752s/it]: train_loss_raw=2.2749, running_loss=2.3055, LR=0.000100
[2025-08-26 19:52:20,739][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/03080] [00:25:34/00:13:02, 0.752s/it]: train_loss_raw=2.2251, running_loss=2.3055, LR=0.000100
[2025-08-26 19:52:27,017][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002048] [Batch 02048/03080] [00:25:40/00:12:56, 0.752s/it]: train_loss_raw=2.3241, running_loss=2.3087, LR=0.000100
[2025-08-26 19:52:33,284][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002056] [Batch 02056/03080] [00:25:47/00:12:50, 0.753s/it]: train_loss_raw=2.2896, running_loss=2.3068, LR=0.000100
[2025-08-26 19:52:39,499][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/03080] [00:25:53/00:12:44, 0.753s/it]: train_loss_raw=2.3239, running_loss=2.3065, LR=0.000100
[2025-08-26 19:52:45,738][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002072] [Batch 02072/03080] [00:25:59/00:12:38, 0.753s/it]: train_loss_raw=2.2791, running_loss=2.3054, LR=0.000100
[2025-08-26 19:52:51,877][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002080] [Batch 02080/03080] [00:26:05/00:12:32, 0.753s/it]: train_loss_raw=2.2885, running_loss=2.3049, LR=0.000100
[2025-08-26 19:52:57,651][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/03080] [00:26:11/00:12:26, 0.753s/it]: train_loss_raw=2.2430, running_loss=2.3024, LR=0.000100
[2025-08-26 19:53:03,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002096] [Batch 02096/03080] [00:26:17/00:12:20, 0.753s/it]: train_loss_raw=2.2667, running_loss=2.3007, LR=0.000100
[2025-08-26 19:53:09,650][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002104] [Batch 02104/03080] [00:26:23/00:12:14, 0.753s/it]: train_loss_raw=2.2787, running_loss=2.2998, LR=0.000100
[2025-08-26 19:53:15,861][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/03080] [00:26:29/00:12:08, 0.753s/it]: train_loss_raw=2.3551, running_loss=2.2996, LR=0.000100
[2025-08-26 19:53:22,124][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002120] [Batch 02120/03080] [00:26:36/00:12:02, 0.753s/it]: train_loss_raw=2.2074, running_loss=2.2986, LR=0.000100
[2025-08-26 19:53:28,389][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002128] [Batch 02128/03080] [00:26:42/00:11:56, 0.753s/it]: train_loss_raw=2.3688, running_loss=2.2982, LR=0.000100
[2025-08-26 19:53:34,612][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/03080] [00:26:48/00:11:50, 0.753s/it]: train_loss_raw=2.3103, running_loss=2.2965, LR=0.000100
[2025-08-26 19:53:40,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002144] [Batch 02144/03080] [00:26:54/00:11:44, 0.753s/it]: train_loss_raw=2.1927, running_loss=2.2932, LR=0.000100
[2025-08-26 19:53:47,042][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002152] [Batch 02152/03080] [00:27:00/00:11:38, 0.753s/it]: train_loss_raw=2.2666, running_loss=2.2928, LR=0.000100
[2025-08-26 19:53:53,223][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/03080] [00:27:07/00:11:33, 0.753s/it]: train_loss_raw=2.3119, running_loss=2.2921, LR=0.000100
[2025-08-26 19:53:59,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002168] [Batch 02168/03080] [00:27:13/00:11:27, 0.753s/it]: train_loss_raw=2.2092, running_loss=2.2868, LR=0.000100
[2025-08-26 19:54:05,591][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002176] [Batch 02176/03080] [00:27:19/00:11:21, 0.753s/it]: train_loss_raw=2.2516, running_loss=2.2829, LR=0.000100
[2025-08-26 19:54:11,806][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/03080] [00:27:25/00:11:15, 0.754s/it]: train_loss_raw=2.2345, running_loss=2.2816, LR=0.000100
[2025-08-26 19:54:17,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002192] [Batch 02192/03080] [00:27:31/00:11:09, 0.754s/it]: train_loss_raw=2.2246, running_loss=2.2791, LR=0.000100
[2025-08-26 19:54:24,115][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002200] [Batch 02200/03080] [00:27:38/00:11:03, 0.754s/it]: train_loss_raw=2.2901, running_loss=2.2774, LR=0.000100
[2025-08-26 19:54:30,304][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/03080] [00:27:44/00:10:57, 0.754s/it]: train_loss_raw=2.2886, running_loss=2.2777, LR=0.000100
[2025-08-26 19:54:36,555][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002216] [Batch 02216/03080] [00:27:50/00:10:51, 0.754s/it]: train_loss_raw=2.3106, running_loss=2.2774, LR=0.000100
[2025-08-26 19:54:42,750][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002224] [Batch 02224/03080] [00:27:56/00:10:45, 0.754s/it]: train_loss_raw=2.2868, running_loss=2.2756, LR=0.000100
[2025-08-26 19:54:48,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/03080] [00:28:02/00:10:39, 0.754s/it]: train_loss_raw=2.2967, running_loss=2.2763, LR=0.000100
[2025-08-26 19:54:55,079][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002240] [Batch 02240/03080] [00:28:08/00:10:33, 0.754s/it]: train_loss_raw=2.2757, running_loss=2.2753, LR=0.000100
[2025-08-26 19:55:01,325][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002248] [Batch 02248/03080] [00:28:15/00:10:27, 0.754s/it]: train_loss_raw=2.3671, running_loss=2.2749, LR=0.000100
[2025-08-26 19:55:07,553][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/03080] [00:28:21/00:10:21, 0.754s/it]: train_loss_raw=2.2861, running_loss=2.2743, LR=0.000100
[2025-08-26 19:55:13,736][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002264] [Batch 02264/03080] [00:28:27/00:10:15, 0.754s/it]: train_loss_raw=2.3205, running_loss=2.2754, LR=0.000100
[2025-08-26 19:55:19,887][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002272] [Batch 02272/03080] [00:28:33/00:10:09, 0.754s/it]: train_loss_raw=2.2192, running_loss=2.2751, LR=0.000100
[2025-08-26 19:55:26,117][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/03080] [00:28:40/00:10:03, 0.754s/it]: train_loss_raw=2.2418, running_loss=2.2739, LR=0.000100
[2025-08-26 19:55:32,335][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002288] [Batch 02288/03080] [00:28:46/00:09:57, 0.754s/it]: train_loss_raw=2.3046, running_loss=2.2747, LR=0.000100
[2025-08-26 19:55:38,541][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002296] [Batch 02296/03080] [00:28:52/00:09:51, 0.755s/it]: train_loss_raw=2.1937, running_loss=2.2714, LR=0.000100
[2025-08-26 19:55:44,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/03080] [00:28:58/00:09:45, 0.755s/it]: train_loss_raw=2.1911, running_loss=2.2712, LR=0.000100
[2025-08-26 19:55:51,136][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002312] [Batch 02312/03080] [00:29:05/00:09:39, 0.755s/it]: train_loss_raw=2.2298, running_loss=2.2711, LR=0.000100
[2025-08-26 19:55:57,174][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002320] [Batch 02320/03080] [00:29:11/00:09:33, 0.755s/it]: train_loss_raw=2.3351, running_loss=2.2721, LR=0.000100
[2025-08-26 19:56:03,354][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/03080] [00:29:17/00:09:27, 0.755s/it]: train_loss_raw=2.2999, running_loss=2.2697, LR=0.000100
[2025-08-26 19:56:09,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002336] [Batch 02336/03080] [00:29:23/00:09:21, 0.755s/it]: train_loss_raw=2.3583, running_loss=2.2688, LR=0.000100
[2025-08-26 19:56:15,796][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002344] [Batch 02344/03080] [00:29:29/00:09:15, 0.755s/it]: train_loss_raw=2.2736, running_loss=2.2674, LR=0.000100
[2025-08-26 19:56:21,843][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/03080] [00:29:35/00:09:09, 0.755s/it]: train_loss_raw=2.2763, running_loss=2.2679, LR=0.000100
[2025-08-26 19:56:28,092][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002360] [Batch 02360/03080] [00:29:41/00:09:03, 0.755s/it]: train_loss_raw=2.1188, running_loss=2.2636, LR=0.000100
[2025-08-26 19:56:34,322][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002368] [Batch 02368/03080] [00:29:48/00:08:57, 0.755s/it]: train_loss_raw=2.1930, running_loss=2.2610, LR=0.000100
[2025-08-26 19:56:40,525][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/03080] [00:29:54/00:08:51, 0.755s/it]: train_loss_raw=2.2893, running_loss=2.2599, LR=0.000100
[2025-08-26 19:56:46,782][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002384] [Batch 02384/03080] [00:30:00/00:08:45, 0.755s/it]: train_loss_raw=2.2025, running_loss=2.2567, LR=0.000100
[2025-08-26 19:56:53,016][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002392] [Batch 02392/03080] [00:30:06/00:08:39, 0.755s/it]: train_loss_raw=2.1746, running_loss=2.2563, LR=0.000100
[2025-08-26 19:56:59,212][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/03080] [00:30:13/00:08:33, 0.755s/it]: train_loss_raw=2.2176, running_loss=2.2535, LR=0.000100
[2025-08-26 19:57:05,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002408] [Batch 02408/03080] [00:30:19/00:08:27, 0.756s/it]: train_loss_raw=2.1612, running_loss=2.2533, LR=0.000100
[2025-08-26 19:57:11,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002416] [Batch 02416/03080] [00:30:25/00:08:21, 0.756s/it]: train_loss_raw=2.3246, running_loss=2.2541, LR=0.000100
[2025-08-26 19:57:17,872][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/03080] [00:30:31/00:08:15, 0.756s/it]: train_loss_raw=2.2700, running_loss=2.2516, LR=0.000100
[2025-08-26 19:57:24,104][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002432] [Batch 02432/03080] [00:30:37/00:08:09, 0.756s/it]: train_loss_raw=2.3040, running_loss=2.2531, LR=0.000100
[2025-08-26 19:57:30,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002440] [Batch 02440/03080] [00:30:44/00:08:03, 0.756s/it]: train_loss_raw=2.2667, running_loss=2.2526, LR=0.000100
[2025-08-26 19:57:36,131][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/03080] [00:30:50/00:07:57, 0.756s/it]: train_loss_raw=2.2468, running_loss=2.2527, LR=0.000100
[2025-08-26 19:57:42,121][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002456] [Batch 02456/03080] [00:30:56/00:07:51, 0.756s/it]: train_loss_raw=2.2291, running_loss=2.2516, LR=0.000100
[2025-08-26 19:57:48,071][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002464] [Batch 02464/03080] [00:31:01/00:07:45, 0.756s/it]: train_loss_raw=2.2549, running_loss=2.2503, LR=0.000100
[2025-08-26 19:57:54,303][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/03080] [00:31:08/00:07:39, 0.756s/it]: train_loss_raw=2.2892, running_loss=2.2498, LR=0.000100
[2025-08-26 19:58:00,184][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002480] [Batch 02480/03080] [00:31:14/00:07:33, 0.756s/it]: train_loss_raw=2.2464, running_loss=2.2493, LR=0.000100
[2025-08-26 19:58:06,035][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002488] [Batch 02488/03080] [00:31:19/00:07:27, 0.756s/it]: train_loss_raw=2.2621, running_loss=2.2516, LR=0.000100
[2025-08-26 19:58:11,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/03080] [00:31:25/00:07:21, 0.756s/it]: train_loss_raw=2.3592, running_loss=2.2522, LR=0.000100
[2025-08-26 19:58:18,029][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002504] [Batch 02504/03080] [00:31:31/00:07:15, 0.756s/it]: train_loss_raw=2.2547, running_loss=2.2529, LR=0.000100
[2025-08-26 19:58:24,248][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002512] [Batch 02512/03080] [00:31:38/00:07:09, 0.756s/it]: train_loss_raw=2.2889, running_loss=2.2519, LR=0.000100
[2025-08-26 19:58:30,509][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/03080] [00:31:44/00:07:03, 0.756s/it]: train_loss_raw=2.1811, running_loss=2.2504, LR=0.000100
[2025-08-26 19:58:36,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002528] [Batch 02528/03080] [00:31:50/00:06:57, 0.756s/it]: train_loss_raw=2.3428, running_loss=2.2499, LR=0.000100
[2025-08-26 19:58:42,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002536] [Batch 02536/03080] [00:31:56/00:06:51, 0.756s/it]: train_loss_raw=2.2559, running_loss=2.2486, LR=0.000100
[2025-08-26 19:58:48,890][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/03080] [00:32:02/00:06:45, 0.756s/it]: train_loss_raw=2.1852, running_loss=2.2475, LR=0.000100
[2025-08-26 19:58:54,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002552] [Batch 02552/03080] [00:32:08/00:06:39, 0.756s/it]: train_loss_raw=2.1868, running_loss=2.2456, LR=0.000100
[2025-08-26 19:59:01,128][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002560] [Batch 02560/03080] [00:32:15/00:06:33, 0.756s/it]: train_loss_raw=2.2346, running_loss=2.2442, LR=0.000100
[2025-08-26 19:59:07,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/03080] [00:32:21/00:06:27, 0.756s/it]: train_loss_raw=2.2602, running_loss=2.2452, LR=0.000100
[2025-08-26 19:59:13,592][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002576] [Batch 02576/03080] [00:32:27/00:06:21, 0.756s/it]: train_loss_raw=2.2406, running_loss=2.2435, LR=0.000100
[2025-08-26 19:59:19,462][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002584] [Batch 02584/03080] [00:32:33/00:06:14, 0.756s/it]: train_loss_raw=2.2792, running_loss=2.2440, LR=0.000100
[2025-08-26 19:59:25,458][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/03080] [00:32:39/00:06:08, 0.756s/it]: train_loss_raw=2.2093, running_loss=2.2428, LR=0.000100
[2025-08-26 19:59:31,230][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002600] [Batch 02600/03080] [00:32:45/00:06:02, 0.756s/it]: train_loss_raw=2.1553, running_loss=2.2404, LR=0.000100
[2025-08-26 19:59:37,097][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002608] [Batch 02608/03080] [00:32:50/00:05:56, 0.756s/it]: train_loss_raw=2.2198, running_loss=2.2400, LR=0.000100
[2025-08-26 19:59:43,294][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/03080] [00:32:57/00:05:50, 0.756s/it]: train_loss_raw=2.2242, running_loss=2.2403, LR=0.000100
[2025-08-26 19:59:49,488][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002624] [Batch 02624/03080] [00:33:03/00:05:44, 0.756s/it]: train_loss_raw=2.2520, running_loss=2.2404, LR=0.000100
[2025-08-26 19:59:55,690][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002632] [Batch 02632/03080] [00:33:09/00:05:38, 0.756s/it]: train_loss_raw=2.2188, running_loss=2.2393, LR=0.000100
[2025-08-26 20:00:01,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/03080] [00:33:15/00:05:32, 0.756s/it]: train_loss_raw=2.2386, running_loss=2.2379, LR=0.000100
[2025-08-26 20:00:07,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002648] [Batch 02648/03080] [00:33:21/00:05:26, 0.756s/it]: train_loss_raw=2.2347, running_loss=2.2394, LR=0.000100
[2025-08-26 20:00:13,437][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002656] [Batch 02656/03080] [00:33:27/00:05:20, 0.756s/it]: train_loss_raw=2.2365, running_loss=2.2377, LR=0.000100
[2025-08-26 20:00:19,341][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/03080] [00:33:33/00:05:14, 0.756s/it]: train_loss_raw=2.1853, running_loss=2.2344, LR=0.000100
[2025-08-26 20:00:25,097][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002672] [Batch 02672/03080] [00:33:38/00:05:08, 0.756s/it]: train_loss_raw=2.2252, running_loss=2.2339, LR=0.000100
[2025-08-26 20:00:30,972][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002680] [Batch 02680/03080] [00:33:44/00:05:02, 0.756s/it]: train_loss_raw=2.3149, running_loss=2.2357, LR=0.000100
[2025-08-26 20:00:36,983][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/03080] [00:33:50/00:04:56, 0.756s/it]: train_loss_raw=2.2711, running_loss=2.2371, LR=0.000100
[2025-08-26 20:00:42,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002696] [Batch 02696/03080] [00:33:56/00:04:50, 0.755s/it]: train_loss_raw=2.2541, running_loss=2.2367, LR=0.000100
[2025-08-26 20:00:48,998][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002704] [Batch 02704/03080] [00:34:02/00:04:44, 0.756s/it]: train_loss_raw=2.2302, running_loss=2.2361, LR=0.000100
[2025-08-26 20:00:55,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/03080] [00:34:09/00:04:38, 0.756s/it]: train_loss_raw=2.3113, running_loss=2.2344, LR=0.000100
[2025-08-26 20:01:01,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002720] [Batch 02720/03080] [00:34:15/00:04:32, 0.756s/it]: train_loss_raw=2.2556, running_loss=2.2355, LR=0.000100
[2025-08-26 20:01:07,595][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002728] [Batch 02728/03080] [00:34:21/00:04:25, 0.756s/it]: train_loss_raw=2.2569, running_loss=2.2345, LR=0.000100
[2025-08-26 20:01:13,773][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/03080] [00:34:27/00:04:19, 0.756s/it]: train_loss_raw=2.2230, running_loss=2.2356, LR=0.000100
[2025-08-26 20:01:19,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002744] [Batch 02744/03080] [00:34:33/00:04:13, 0.756s/it]: train_loss_raw=2.2019, running_loss=2.2342, LR=0.000100
[2025-08-26 20:01:25,781][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002752] [Batch 02752/03080] [00:34:39/00:04:07, 0.756s/it]: train_loss_raw=2.2042, running_loss=2.2331, LR=0.000100
[2025-08-26 20:01:31,761][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/03080] [00:34:45/00:04:01, 0.756s/it]: train_loss_raw=2.1952, running_loss=2.2318, LR=0.000100
[2025-08-26 20:01:37,831][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002768] [Batch 02768/03080] [00:34:51/00:03:55, 0.756s/it]: train_loss_raw=2.1657, running_loss=2.2293, LR=0.000100
[2025-08-26 20:01:43,592][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002776] [Batch 02776/03080] [00:34:57/00:03:49, 0.756s/it]: train_loss_raw=2.1852, running_loss=2.2254, LR=0.000100
[2025-08-26 20:01:49,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/03080] [00:35:03/00:03:43, 0.756s/it]: train_loss_raw=2.1921, running_loss=2.2253, LR=0.000100
[2025-08-26 20:01:55,412][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002792] [Batch 02792/03080] [00:35:09/00:03:37, 0.755s/it]: train_loss_raw=2.2376, running_loss=2.2229, LR=0.000100
[2025-08-26 20:02:01,305][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002800] [Batch 02800/03080] [00:35:15/00:03:31, 0.755s/it]: train_loss_raw=2.1473, running_loss=2.2224, LR=0.000100
[2025-08-26 20:02:07,439][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/03080] [00:35:21/00:03:25, 0.755s/it]: train_loss_raw=2.1309, running_loss=2.2202, LR=0.000100
[2025-08-26 20:02:13,429][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002816] [Batch 02816/03080] [00:35:27/00:03:19, 0.755s/it]: train_loss_raw=2.2054, running_loss=2.2173, LR=0.000100
[2025-08-26 20:02:19,574][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002824] [Batch 02824/03080] [00:35:33/00:03:13, 0.755s/it]: train_loss_raw=2.2996, running_loss=2.2189, LR=0.000100
[2025-08-26 20:02:25,494][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/03080] [00:35:39/00:03:07, 0.755s/it]: train_loss_raw=2.2212, running_loss=2.2181, LR=0.000100
[2025-08-26 20:02:31,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002840] [Batch 02840/03080] [00:35:45/00:03:01, 0.755s/it]: train_loss_raw=2.1840, running_loss=2.2174, LR=0.000100
[2025-08-26 20:02:37,662][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002848] [Batch 02848/03080] [00:35:51/00:02:55, 0.755s/it]: train_loss_raw=2.2513, running_loss=2.2168, LR=0.000100
[2025-08-26 20:02:43,741][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/03080] [00:35:57/00:02:49, 0.755s/it]: train_loss_raw=2.1821, running_loss=2.2156, LR=0.000100
[2025-08-26 20:02:49,434][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002864] [Batch 02864/03080] [00:36:03/00:02:43, 0.755s/it]: train_loss_raw=2.2110, running_loss=2.2140, LR=0.000100
[2025-08-26 20:02:55,403][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002872] [Batch 02872/03080] [00:36:09/00:02:37, 0.755s/it]: train_loss_raw=2.2386, running_loss=2.2133, LR=0.000100
[2025-08-26 20:03:01,427][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/03080] [00:36:15/00:02:31, 0.755s/it]: train_loss_raw=2.1823, running_loss=2.2105, LR=0.000100
[2025-08-26 20:03:07,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002888] [Batch 02888/03080] [00:36:21/00:02:25, 0.755s/it]: train_loss_raw=2.2210, running_loss=2.2100, LR=0.000100
[2025-08-26 20:03:13,827][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002896] [Batch 02896/03080] [00:36:27/00:02:18, 0.755s/it]: train_loss_raw=2.2178, running_loss=2.2110, LR=0.000100
[2025-08-26 20:03:20,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/03080] [00:36:34/00:02:12, 0.756s/it]: train_loss_raw=2.1886, running_loss=2.2094, LR=0.000100
[2025-08-26 20:03:26,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002912] [Batch 02912/03080] [00:36:40/00:02:06, 0.756s/it]: train_loss_raw=2.1689, running_loss=2.2092, LR=0.000100
[2025-08-26 20:03:32,234][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002920] [Batch 02920/03080] [00:36:46/00:02:00, 0.756s/it]: train_loss_raw=2.0957, running_loss=2.2052, LR=0.000100
[2025-08-26 20:03:38,346][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/03080] [00:36:52/00:01:54, 0.756s/it]: train_loss_raw=2.1756, running_loss=2.2023, LR=0.000100
[2025-08-26 20:03:44,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002936] [Batch 02936/03080] [00:36:58/00:01:48, 0.756s/it]: train_loss_raw=2.1195, running_loss=2.2013, LR=0.000100
[2025-08-26 20:03:50,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002944] [Batch 02944/03080] [00:37:04/00:01:42, 0.755s/it]: train_loss_raw=2.2480, running_loss=2.2029, LR=0.000100
[2025-08-26 20:03:56,191][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/03080] [00:37:10/00:01:36, 0.755s/it]: train_loss_raw=2.1943, running_loss=2.2033, LR=0.000100
[2025-08-26 20:04:02,374][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002960] [Batch 02960/03080] [00:37:16/00:01:30, 0.755s/it]: train_loss_raw=2.1570, running_loss=2.1988, LR=0.000100
[2025-08-26 20:04:08,573][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002968] [Batch 02968/03080] [00:37:22/00:01:24, 0.756s/it]: train_loss_raw=2.1455, running_loss=2.1981, LR=0.000100
[2025-08-26 20:04:14,704][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/03080] [00:37:28/00:01:18, 0.756s/it]: train_loss_raw=2.2368, running_loss=2.1980, LR=0.000100
[2025-08-26 20:04:20,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002984] [Batch 02984/03080] [00:37:34/00:01:12, 0.756s/it]: train_loss_raw=2.2395, running_loss=2.1983, LR=0.000100
[2025-08-26 20:04:27,060][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002992] [Batch 02992/03080] [00:37:40/00:01:06, 0.756s/it]: train_loss_raw=2.1397, running_loss=2.1980, LR=0.000100
[2025-08-26 20:04:33,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/03080] [00:37:47/00:01:00, 0.756s/it]: train_loss_raw=2.1886, running_loss=2.1977, LR=0.000100
[2025-08-26 20:04:39,378][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003008] [Batch 03008/03080] [00:37:53/00:00:54, 0.756s/it]: train_loss_raw=2.2703, running_loss=2.1973, LR=0.000100
[2025-08-26 20:04:45,586][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003016] [Batch 03016/03080] [00:37:59/00:00:48, 0.756s/it]: train_loss_raw=2.2848, running_loss=2.1963, LR=0.000100
[2025-08-26 20:04:51,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/03080] [00:38:05/00:00:42, 0.756s/it]: train_loss_raw=2.2121, running_loss=2.1959, LR=0.000100
[2025-08-26 20:04:58,174][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003032] [Batch 03032/03080] [00:38:12/00:00:36, 0.756s/it]: train_loss_raw=2.1111, running_loss=2.1944, LR=0.000100
[2025-08-26 20:05:04,438][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003040] [Batch 03040/03080] [00:38:18/00:00:30, 0.756s/it]: train_loss_raw=2.1845, running_loss=2.1954, LR=0.000100
[2025-08-26 20:05:10,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/03080] [00:38:24/00:00:24, 0.756s/it]: train_loss_raw=2.1712, running_loss=2.1943, LR=0.000100
[2025-08-26 20:05:16,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003056] [Batch 03056/03080] [00:38:30/00:00:18, 0.756s/it]: train_loss_raw=2.2189, running_loss=2.1949, LR=0.000100
[2025-08-26 20:05:22,988][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003064] [Batch 03064/03080] [00:38:36/00:00:12, 0.756s/it]: train_loss_raw=2.1915, running_loss=2.1959, LR=0.000100
[2025-08-26 20:05:29,180][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/03080] [00:38:43/00:00:06, 0.756s/it]: train_loss_raw=2.2289, running_loss=2.1972, LR=0.000100
[2025-08-26 20:05:35,388][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003080] [Batch 03080/03080] [00:38:49/00:00:00, 0.756s/it]: train_loss_raw=2.1785, running_loss=2.1972, LR=0.000100
[2025-08-26 20:05:35,854][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 20:05:44,428][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00015/00310] [00:00:08/00:02:37, 0.536s/it]
[2025-08-26 20:05:56,714][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00023/00310] [00:00:20/00:04:08, 0.869s/it]
[2025-08-26 20:06:09,512][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00031/00310] [00:00:33/00:04:52, 1.052s/it]
[2025-08-26 20:06:21,068][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00039/00310] [00:00:45/00:05:05, 1.130s/it]
[2025-08-26 20:06:32,380][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00047/00310] [00:00:56/00:05:08, 1.178s/it]
[2025-08-26 20:06:44,710][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00055/00310] [00:01:08/00:05:12, 1.230s/it]
[2025-08-26 20:06:56,556][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00063/00310] [00:01:20/00:05:10, 1.261s/it]
[2025-08-26 20:07:09,078][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00071/00310] [00:01:33/00:05:08, 1.295s/it]
[2025-08-26 20:07:21,761][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00079/00310] [00:01:45/00:05:04, 1.324s/it]
[2025-08-26 20:07:34,753][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00087/00310] [00:01:58/00:04:59, 1.351s/it]
[2025-08-26 20:07:47,714][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00095/00310] [00:02:11/00:04:53, 1.374s/it]
[2025-08-26 20:08:00,515][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00103/00310] [00:02:24/00:04:46, 1.391s/it]
[2025-08-26 20:08:13,373][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00111/00310] [00:02:37/00:04:38, 1.406s/it]
[2025-08-26 20:08:26,473][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00119/00310] [00:02:50/00:04:30, 1.422s/it]
[2025-08-26 20:08:38,969][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00127/00310] [00:03:03/00:04:20, 1.431s/it]
[2025-08-26 20:08:51,942][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00135/00310] [00:03:16/00:04:10, 1.442s/it]
[2025-08-26 20:09:04,767][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00143/00310] [00:03:28/00:04:00, 1.451s/it]
[2025-08-26 20:09:17,495][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00151/00310] [00:03:41/00:03:50, 1.458s/it]
[2025-08-26 20:09:29,867][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00159/00310] [00:03:54/00:03:39, 1.463s/it]
[2025-08-26 20:09:41,790][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00167/00310] [00:04:05/00:03:27, 1.464s/it]
[2025-08-26 20:09:54,481][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00175/00310] [00:04:18/00:03:16, 1.469s/it]
[2025-08-26 20:10:06,609][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00183/00310] [00:04:30/00:03:05, 1.471s/it]
[2025-08-26 20:10:18,627][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00191/00310] [00:04:42/00:02:53, 1.473s/it]
[2025-08-26 20:10:30,878][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00199/00310] [00:04:55/00:02:42, 1.475s/it]
[2025-08-26 20:10:43,203][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00207/00310] [00:05:07/00:02:30, 1.478s/it]
[2025-08-26 20:10:55,451][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00215/00310] [00:05:19/00:02:19, 1.480s/it]
[2025-08-26 20:11:07,635][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00223/00310] [00:05:31/00:02:07, 1.481s/it]
[2025-08-26 20:11:19,917][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00231/00310] [00:05:44/00:01:55, 1.483s/it]
[2025-08-26 20:11:32,455][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00239/00310] [00:05:56/00:01:44, 1.486s/it]
[2025-08-26 20:11:44,743][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00247/00310] [00:06:08/00:01:32, 1.487s/it]
[2025-08-26 20:11:57,039][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00255/00310] [00:06:21/00:01:20, 1.489s/it]
[2025-08-26 20:12:09,368][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00263/00310] [00:06:33/00:01:08, 1.491s/it]
[2025-08-26 20:12:22,024][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00271/00310] [00:06:46/00:00:56, 1.493s/it]
[2025-08-26 20:12:34,497][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00279/00310] [00:06:58/00:00:44, 1.495s/it]
[2025-08-26 20:12:46,791][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00287/00310] [00:07:10/00:00:32, 1.496s/it]
[2025-08-26 20:12:59,513][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00295/00310] [00:07:23/00:00:20, 1.499s/it]
[2025-08-26 20:13:11,954][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00303/00310] [00:07:36/00:00:09, 1.500s/it]
[2025-08-26 20:13:24,582][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00001/00310] [00:07:48/20:03:04, 234.364s/it]
[2025-08-26 20:13:37,255][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003081] [Batch 00009/00310] [00:08:01/04:00:42, 48.140s/it]
[2025-08-26 20:13:37,258][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.19716, valid_loss=2.65436
[2025-08-26 20:13:37,258][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-26 20:13:37,258][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.949
[2025-08-26 20:13:37,258][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.008
[2025-08-26 20:13:37,258][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.009
[2025-08-26 20:13:37,259][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-26 20:13:37,277][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:46:51, remaining time 22:38:43, 00:46:51 per epoch
[2025-08-26 20:13:48,477][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003088] [Batch 00008/03080] [00:00:05/00:35:35, 0.695s/it]: train_loss_raw=2.1413, running_loss=2.2152, LR=0.000100
[2025-08-26 20:13:54,506][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003096] [Batch 00016/03080] [00:00:11/00:36:59, 0.724s/it]: train_loss_raw=2.2188, running_loss=2.2160, LR=0.000100
[2025-08-26 20:14:00,356][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003104] [Batch 00024/03080] [00:00:17/00:37:00, 0.727s/it]: train_loss_raw=2.1397, running_loss=2.2121, LR=0.000100
[2025-08-26 20:14:06,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003112] [Batch 00032/03080] [00:00:23/00:37:15, 0.733s/it]: train_loss_raw=2.2119, running_loss=2.2096, LR=0.000100
[2025-08-26 20:14:12,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003120] [Batch 00040/03080] [00:00:29/00:37:54, 0.748s/it]: train_loss_raw=2.1284, running_loss=2.2048, LR=0.000100
[2025-08-26 20:14:18,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003128] [Batch 00048/03080] [00:00:35/00:37:50, 0.749s/it]: train_loss_raw=2.1187, running_loss=2.2031, LR=0.000100
[2025-08-26 20:14:24,898][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003136] [Batch 00056/03080] [00:00:41/00:37:46, 0.750s/it]: train_loss_raw=2.2110, running_loss=2.2019, LR=0.000100
[2025-08-26 20:14:30,813][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003144] [Batch 00064/03080] [00:00:47/00:37:37, 0.748s/it]: train_loss_raw=2.0822, running_loss=2.1995, LR=0.000100
[2025-08-26 20:14:36,614][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003152] [Batch 00072/03080] [00:00:53/00:37:23, 0.746s/it]: train_loss_raw=2.1989, running_loss=2.1960, LR=0.000100
[2025-08-26 20:14:42,421][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003160] [Batch 00080/03080] [00:00:59/00:37:11, 0.744s/it]: train_loss_raw=2.1807, running_loss=2.1958, LR=0.000100
[2025-08-26 20:14:48,410][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003168] [Batch 00088/03080] [00:01:05/00:37:06, 0.744s/it]: train_loss_raw=2.1824, running_loss=2.1931, LR=0.000100
[2025-08-26 20:14:54,434][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003176] [Batch 00096/03080] [00:01:11/00:37:02, 0.745s/it]: train_loss_raw=2.1219, running_loss=2.1924, LR=0.000100
[2025-08-26 20:15:00,338][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003184] [Batch 00104/03080] [00:01:17/00:36:55, 0.744s/it]: train_loss_raw=2.1693, running_loss=2.1898, LR=0.000100
[2025-08-26 20:15:06,214][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003192] [Batch 00112/03080] [00:01:23/00:36:47, 0.744s/it]: train_loss_raw=2.2181, running_loss=2.1894, LR=0.000100
[2025-08-26 20:15:12,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003200] [Batch 00120/03080] [00:01:29/00:36:38, 0.743s/it]: train_loss_raw=2.1330, running_loss=2.1893, LR=0.000100
[2025-08-26 20:15:17,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003208] [Batch 00128/03080] [00:01:34/00:36:29, 0.742s/it]: train_loss_raw=2.2126, running_loss=2.1893, LR=0.000100
[2025-08-26 20:15:23,700][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003216] [Batch 00136/03080] [00:01:40/00:36:21, 0.741s/it]: train_loss_raw=2.2270, running_loss=2.1901, LR=0.000100
[2025-08-26 20:15:29,605][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003224] [Batch 00144/03080] [00:01:46/00:36:15, 0.741s/it]: train_loss_raw=2.2275, running_loss=2.1884, LR=0.000100
[2025-08-26 20:15:35,472][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003232] [Batch 00152/03080] [00:01:52/00:36:08, 0.740s/it]: train_loss_raw=2.1391, running_loss=2.1884, LR=0.000100
[2025-08-26 20:15:41,286][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003240] [Batch 00160/03080] [00:01:58/00:36:00, 0.740s/it]: train_loss_raw=2.1637, running_loss=2.1866, LR=0.000100
[2025-08-26 20:15:47,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003248] [Batch 00168/03080] [00:02:04/00:35:53, 0.740s/it]: train_loss_raw=2.1671, running_loss=2.1866, LR=0.000100
[2025-08-26 20:15:53,253][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003256] [Batch 00176/03080] [00:02:10/00:35:50, 0.741s/it]: train_loss_raw=2.1005, running_loss=2.1841, LR=0.000100
[2025-08-26 20:15:59,185][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003264] [Batch 00184/03080] [00:02:16/00:35:44, 0.741s/it]: train_loss_raw=2.1486, running_loss=2.1826, LR=0.000100
[2025-08-26 20:16:05,117][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003272] [Batch 00192/03080] [00:02:22/00:35:38, 0.741s/it]: train_loss_raw=2.0629, running_loss=2.1807, LR=0.000100
[2025-08-26 20:16:10,911][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003280] [Batch 00200/03080] [00:02:27/00:35:31, 0.740s/it]: train_loss_raw=2.1786, running_loss=2.1810, LR=0.000100
[2025-08-26 20:16:16,860][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003288] [Batch 00208/03080] [00:02:33/00:35:25, 0.740s/it]: train_loss_raw=2.2068, running_loss=2.1818, LR=0.000100
[2025-08-26 20:16:22,845][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003296] [Batch 00216/03080] [00:02:39/00:35:20, 0.740s/it]: train_loss_raw=2.1624, running_loss=2.1812, LR=0.000100
[2025-08-26 20:16:28,828][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003304] [Batch 00224/03080] [00:02:45/00:35:15, 0.741s/it]: train_loss_raw=2.0981, running_loss=2.1790, LR=0.000100
[2025-08-26 20:16:34,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003312] [Batch 00232/03080] [00:02:51/00:35:08, 0.740s/it]: train_loss_raw=2.2089, running_loss=2.1791, LR=0.000100
[2025-08-26 20:16:40,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003320] [Batch 00240/03080] [00:02:57/00:35:01, 0.740s/it]: train_loss_raw=2.1379, running_loss=2.1759, LR=0.000100
[2025-08-26 20:16:46,442][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003328] [Batch 00248/03080] [00:03:03/00:34:55, 0.740s/it]: train_loss_raw=2.1395, running_loss=2.1767, LR=0.000100
[2025-08-26 20:16:52,249][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003336] [Batch 00256/03080] [00:03:09/00:34:48, 0.740s/it]: train_loss_raw=2.2204, running_loss=2.1762, LR=0.000100
[2025-08-26 20:16:58,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003344] [Batch 00264/03080] [00:03:15/00:34:43, 0.740s/it]: train_loss_raw=2.0673, running_loss=2.1760, LR=0.000100
[2025-08-26 20:17:04,093][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003352] [Batch 00272/03080] [00:03:21/00:34:36, 0.740s/it]: train_loss_raw=2.1462, running_loss=2.1745, LR=0.000100
[2025-08-26 20:17:09,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003360] [Batch 00280/03080] [00:03:27/00:34:30, 0.740s/it]: train_loss_raw=2.1691, running_loss=2.1740, LR=0.000100
[2025-08-26 20:17:16,063][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003368] [Batch 00288/03080] [00:03:33/00:34:26, 0.740s/it]: train_loss_raw=2.1963, running_loss=2.1732, LR=0.000100
[2025-08-26 20:17:21,976][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003376] [Batch 00296/03080] [00:03:39/00:34:20, 0.740s/it]: train_loss_raw=2.1061, running_loss=2.1734, LR=0.000100
[2025-08-26 20:17:27,926][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003384] [Batch 00304/03080] [00:03:45/00:34:14, 0.740s/it]: train_loss_raw=2.1293, running_loss=2.1725, LR=0.000100
[2025-08-26 20:17:33,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003392] [Batch 00312/03080] [00:03:50/00:34:08, 0.740s/it]: train_loss_raw=2.0572, running_loss=2.1670, LR=0.000100
[2025-08-26 20:17:39,780][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003400] [Batch 00320/03080] [00:03:56/00:34:02, 0.740s/it]: train_loss_raw=2.1981, running_loss=2.1666, LR=0.000100
[2025-08-26 20:17:45,816][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003408] [Batch 00328/03080] [00:04:02/00:33:57, 0.741s/it]: train_loss_raw=2.1057, running_loss=2.1635, LR=0.000100
[2025-08-26 20:17:51,880][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003416] [Batch 00336/03080] [00:04:08/00:33:53, 0.741s/it]: train_loss_raw=2.1604, running_loss=2.1615, LR=0.000100
[2025-08-26 20:17:57,850][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003424] [Batch 00344/03080] [00:04:14/00:33:47, 0.741s/it]: train_loss_raw=2.2347, running_loss=2.1612, LR=0.000100
[2025-08-26 20:18:03,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003432] [Batch 00352/03080] [00:04:20/00:33:42, 0.741s/it]: train_loss_raw=2.1527, running_loss=2.1618, LR=0.000100
[2025-08-26 20:18:09,860][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003440] [Batch 00360/03080] [00:04:26/00:33:36, 0.742s/it]: train_loss_raw=2.1996, running_loss=2.1622, LR=0.000100
[2025-08-26 20:18:15,866][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003448] [Batch 00368/03080] [00:04:32/00:33:31, 0.742s/it]: train_loss_raw=2.3020, running_loss=2.1614, LR=0.000100
[2025-08-26 20:18:21,895][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003456] [Batch 00376/03080] [00:04:38/00:33:26, 0.742s/it]: train_loss_raw=2.1055, running_loss=2.1601, LR=0.000100
[2025-08-26 20:18:27,912][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003464] [Batch 00384/03080] [00:04:44/00:33:20, 0.742s/it]: train_loss_raw=2.1462, running_loss=2.1609, LR=0.000100
[2025-08-26 20:18:33,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003472] [Batch 00392/03080] [00:04:51/00:33:15, 0.742s/it]: train_loss_raw=2.1936, running_loss=2.1601, LR=0.000100
[2025-08-26 20:18:39,867][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003480] [Batch 00400/03080] [00:04:56/00:33:09, 0.742s/it]: train_loss_raw=2.1675, running_loss=2.1596, LR=0.000100
[2025-08-26 20:18:45,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003488] [Batch 00408/03080] [00:05:02/00:33:03, 0.742s/it]: train_loss_raw=2.0973, running_loss=2.1583, LR=0.000100
[2025-08-26 20:18:51,431][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003496] [Batch 00416/03080] [00:05:08/00:32:55, 0.742s/it]: train_loss_raw=2.1508, running_loss=2.1576, LR=0.000100
[2025-08-26 20:18:57,362][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003504] [Batch 00424/03080] [00:05:14/00:32:49, 0.742s/it]: train_loss_raw=2.2275, running_loss=2.1575, LR=0.000100
[2025-08-26 20:19:03,267][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003512] [Batch 00432/03080] [00:05:20/00:32:43, 0.742s/it]: train_loss_raw=2.1638, running_loss=2.1557, LR=0.000100
[2025-08-26 20:19:09,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003520] [Batch 00440/03080] [00:05:26/00:32:37, 0.741s/it]: train_loss_raw=2.0558, running_loss=2.1559, LR=0.000100
[2025-08-26 20:19:14,968][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003528] [Batch 00448/03080] [00:05:32/00:32:30, 0.741s/it]: train_loss_raw=2.1261, running_loss=2.1549, LR=0.000100
[2025-08-26 20:19:20,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003536] [Batch 00456/03080] [00:05:37/00:32:24, 0.741s/it]: train_loss_raw=2.0951, running_loss=2.1540, LR=0.000100
[2025-08-26 20:19:26,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003544] [Batch 00464/03080] [00:05:43/00:32:19, 0.741s/it]: train_loss_raw=2.1195, running_loss=2.1556, LR=0.000100
[2025-08-26 20:19:32,942][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003552] [Batch 00472/03080] [00:05:50/00:32:14, 0.742s/it]: train_loss_raw=2.1304, running_loss=2.1546, LR=0.000100
[2025-08-26 20:19:38,931][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003560] [Batch 00480/03080] [00:05:56/00:32:08, 0.742s/it]: train_loss_raw=2.0707, running_loss=2.1539, LR=0.000100
[2025-08-26 20:19:45,021][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003568] [Batch 00488/03080] [00:06:02/00:32:03, 0.742s/it]: train_loss_raw=2.1170, running_loss=2.1535, LR=0.000100
[2025-08-26 20:19:51,012][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003576] [Batch 00496/03080] [00:06:08/00:31:57, 0.742s/it]: train_loss_raw=2.1570, running_loss=2.1542, LR=0.000100
[2025-08-26 20:19:57,373][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003584] [Batch 00504/03080] [00:06:14/00:31:53, 0.743s/it]: train_loss_raw=2.1198, running_loss=2.1536, LR=0.000100
[2025-08-26 20:20:03,387][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003592] [Batch 00512/03080] [00:06:20/00:31:48, 0.743s/it]: train_loss_raw=2.0762, running_loss=2.1513, LR=0.000100
[2025-08-26 20:20:09,340][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003600] [Batch 00520/03080] [00:06:26/00:31:42, 0.743s/it]: train_loss_raw=2.2030, running_loss=2.1505, LR=0.000100
[2025-08-26 20:20:15,373][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003608] [Batch 00528/03080] [00:06:32/00:31:36, 0.743s/it]: train_loss_raw=2.1837, running_loss=2.1494, LR=0.000100
[2025-08-26 20:20:21,575][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003616] [Batch 00536/03080] [00:06:38/00:31:32, 0.744s/it]: train_loss_raw=2.1738, running_loss=2.1501, LR=0.000100
[2025-08-26 20:20:27,456][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003624] [Batch 00544/03080] [00:06:44/00:31:25, 0.744s/it]: train_loss_raw=2.1797, running_loss=2.1522, LR=0.000100
[2025-08-26 20:20:33,200][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003632] [Batch 00552/03080] [00:06:50/00:31:18, 0.743s/it]: train_loss_raw=2.1112, running_loss=2.1496, LR=0.000100
[2025-08-26 20:20:38,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003640] [Batch 00560/03080] [00:06:56/00:31:12, 0.743s/it]: train_loss_raw=2.0901, running_loss=2.1490, LR=0.000100
[2025-08-26 20:20:44,854][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003648] [Batch 00568/03080] [00:07:01/00:31:06, 0.743s/it]: train_loss_raw=2.0996, running_loss=2.1469, LR=0.000100
[2025-08-26 20:20:50,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003656] [Batch 00576/03080] [00:07:07/00:31:00, 0.743s/it]: train_loss_raw=2.1496, running_loss=2.1475, LR=0.000100
[2025-08-26 20:20:56,807][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003664] [Batch 00584/03080] [00:07:13/00:30:54, 0.743s/it]: train_loss_raw=2.1144, running_loss=2.1472, LR=0.000100
[2025-08-26 20:21:02,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003672] [Batch 00592/03080] [00:07:19/00:30:48, 0.743s/it]: train_loss_raw=2.1001, running_loss=2.1459, LR=0.000100
[2025-08-26 20:21:08,763][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003680] [Batch 00600/03080] [00:07:25/00:30:42, 0.743s/it]: train_loss_raw=2.1402, running_loss=2.1440, LR=0.000100
[2025-08-26 20:21:14,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003688] [Batch 00608/03080] [00:07:31/00:30:37, 0.743s/it]: train_loss_raw=2.1655, running_loss=2.1436, LR=0.000100
[2025-08-26 20:21:20,857][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003696] [Batch 00616/03080] [00:07:37/00:30:31, 0.743s/it]: train_loss_raw=2.1406, running_loss=2.1435, LR=0.000100
[2025-08-26 20:21:26,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003704] [Batch 00624/03080] [00:07:43/00:30:25, 0.743s/it]: train_loss_raw=2.1797, running_loss=2.1421, LR=0.000100
[2025-08-26 20:21:32,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003712] [Batch 00632/03080] [00:07:49/00:30:20, 0.744s/it]: train_loss_raw=2.0661, running_loss=2.1405, LR=0.000100
[2025-08-26 20:21:38,809][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003720] [Batch 00640/03080] [00:07:55/00:30:14, 0.744s/it]: train_loss_raw=2.0946, running_loss=2.1431, LR=0.000100
[2025-08-26 20:21:44,855][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003728] [Batch 00648/03080] [00:08:01/00:30:08, 0.744s/it]: train_loss_raw=2.1960, running_loss=2.1435, LR=0.000100
[2025-08-26 20:21:50,757][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003736] [Batch 00656/03080] [00:08:07/00:30:02, 0.744s/it]: train_loss_raw=2.1286, running_loss=2.1431, LR=0.000100
[2025-08-26 20:21:56,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003744] [Batch 00664/03080] [00:08:13/00:29:56, 0.744s/it]: train_loss_raw=2.0181, running_loss=2.1376, LR=0.000100
[2025-08-26 20:22:02,718][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003752] [Batch 00672/03080] [00:08:19/00:29:50, 0.744s/it]: train_loss_raw=2.0757, running_loss=2.1345, LR=0.000100
[2025-08-26 20:22:08,751][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003760] [Batch 00680/03080] [00:08:25/00:29:45, 0.744s/it]: train_loss_raw=2.1472, running_loss=2.1335, LR=0.000100
[2025-08-26 20:22:14,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003768] [Batch 00688/03080] [00:08:31/00:29:39, 0.744s/it]: train_loss_raw=2.0552, running_loss=2.1327, LR=0.000100
[2025-08-26 20:22:20,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003776] [Batch 00696/03080] [00:08:37/00:29:33, 0.744s/it]: train_loss_raw=2.1264, running_loss=2.1318, LR=0.000100
[2025-08-26 20:22:26,748][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003784] [Batch 00704/03080] [00:08:43/00:29:27, 0.744s/it]: train_loss_raw=2.1042, running_loss=2.1286, LR=0.000100
[2025-08-26 20:22:32,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003792] [Batch 00712/03080] [00:08:49/00:29:21, 0.744s/it]: train_loss_raw=2.1506, running_loss=2.1268, LR=0.000100
[2025-08-26 20:22:38,672][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003800] [Batch 00720/03080] [00:08:55/00:29:16, 0.744s/it]: train_loss_raw=2.0978, running_loss=2.1258, LR=0.000100
[2025-08-26 20:22:44,695][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003808] [Batch 00728/03080] [00:09:01/00:29:10, 0.744s/it]: train_loss_raw=2.1302, running_loss=2.1274, LR=0.000100
[2025-08-26 20:22:50,706][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003816] [Batch 00736/03080] [00:09:07/00:29:04, 0.744s/it]: train_loss_raw=2.0981, running_loss=2.1281, LR=0.000100
[2025-08-26 20:22:56,647][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003824] [Batch 00744/03080] [00:09:13/00:28:58, 0.744s/it]: train_loss_raw=2.1362, running_loss=2.1284, LR=0.000100
[2025-08-26 20:23:02,702][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003832] [Batch 00752/03080] [00:09:19/00:28:52, 0.744s/it]: train_loss_raw=2.1554, running_loss=2.1279, LR=0.000100
[2025-08-26 20:23:08,830][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003840] [Batch 00760/03080] [00:09:25/00:28:47, 0.745s/it]: train_loss_raw=2.1189, running_loss=2.1259, LR=0.000100
[2025-08-26 20:23:14,879][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003848] [Batch 00768/03080] [00:09:31/00:28:41, 0.745s/it]: train_loss_raw=2.1042, running_loss=2.1247, LR=0.000100
[2025-08-26 20:23:20,820][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003856] [Batch 00776/03080] [00:09:37/00:28:35, 0.745s/it]: train_loss_raw=2.1048, running_loss=2.1243, LR=0.000100
[2025-08-26 20:23:26,745][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003864] [Batch 00784/03080] [00:09:43/00:28:29, 0.745s/it]: train_loss_raw=2.1168, running_loss=2.1231, LR=0.000100
[2025-08-26 20:23:32,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003872] [Batch 00792/03080] [00:09:49/00:28:23, 0.745s/it]: train_loss_raw=2.1492, running_loss=2.1236, LR=0.000100
[2025-08-26 20:23:38,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003880] [Batch 00800/03080] [00:09:55/00:28:17, 0.745s/it]: train_loss_raw=2.1319, running_loss=2.1220, LR=0.000100
[2025-08-26 20:23:44,719][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003888] [Batch 00808/03080] [00:10:01/00:28:12, 0.745s/it]: train_loss_raw=2.1100, running_loss=2.1221, LR=0.000100
[2025-08-26 20:23:50,850][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003896] [Batch 00816/03080] [00:10:07/00:28:06, 0.745s/it]: train_loss_raw=2.2026, running_loss=2.1231, LR=0.000100
[2025-08-26 20:23:56,847][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003904] [Batch 00824/03080] [00:10:13/00:28:00, 0.745s/it]: train_loss_raw=2.1500, running_loss=2.1222, LR=0.000100
[2025-08-26 20:24:02,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003912] [Batch 00832/03080] [00:10:19/00:27:54, 0.745s/it]: train_loss_raw=2.1470, running_loss=2.1215, LR=0.000100
[2025-08-26 20:24:08,838][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003920] [Batch 00840/03080] [00:10:25/00:27:49, 0.745s/it]: train_loss_raw=2.1592, running_loss=2.1241, LR=0.000100
[2025-08-26 20:24:14,724][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003928] [Batch 00848/03080] [00:10:31/00:27:42, 0.745s/it]: train_loss_raw=2.1773, running_loss=2.1250, LR=0.000100
[2025-08-26 20:24:20,719][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003936] [Batch 00856/03080] [00:10:37/00:27:37, 0.745s/it]: train_loss_raw=2.0419, running_loss=2.1241, LR=0.000100
[2025-08-26 20:24:26,661][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003944] [Batch 00864/03080] [00:10:43/00:27:31, 0.745s/it]: train_loss_raw=2.1292, running_loss=2.1242, LR=0.000100
[2025-08-26 20:24:32,668][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003952] [Batch 00872/03080] [00:10:49/00:27:25, 0.745s/it]: train_loss_raw=2.1665, running_loss=2.1247, LR=0.000100
[2025-08-26 20:24:38,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003960] [Batch 00880/03080] [00:10:55/00:27:19, 0.745s/it]: train_loss_raw=2.1388, running_loss=2.1246, LR=0.000100
[2025-08-26 20:24:44,618][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003968] [Batch 00888/03080] [00:11:01/00:27:13, 0.745s/it]: train_loss_raw=2.0706, running_loss=2.1252, LR=0.000100
[2025-08-26 20:24:50,334][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003976] [Batch 00896/03080] [00:11:07/00:27:06, 0.745s/it]: train_loss_raw=2.1358, running_loss=2.1246, LR=0.000100
[2025-08-26 20:24:56,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003984] [Batch 00904/03080] [00:11:13/00:27:00, 0.745s/it]: train_loss_raw=2.0185, running_loss=2.1219, LR=0.000100
[2025-08-26 20:25:02,135][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003992] [Batch 00912/03080] [00:11:19/00:26:54, 0.745s/it]: train_loss_raw=2.1816, running_loss=2.1213, LR=0.000100
[2025-08-26 20:25:08,033][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004000] [Batch 00920/03080] [00:11:25/00:26:48, 0.745s/it]: train_loss_raw=2.0617, running_loss=2.1200, LR=0.000100
[2025-08-26 20:25:18,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004008] [Batch 00928/03080] [00:11:35/00:26:53, 0.750s/it]: train_loss_raw=2.1319, running_loss=2.1224, LR=0.000100
[2025-08-26 20:25:24,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004016] [Batch 00936/03080] [00:11:41/00:26:46, 0.749s/it]: train_loss_raw=2.1298, running_loss=2.1208, LR=0.000100
[2025-08-26 20:25:30,340][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004024] [Batch 00944/03080] [00:11:47/00:26:40, 0.749s/it]: train_loss_raw=2.0982, running_loss=2.1211, LR=0.000100
[2025-08-26 20:25:36,306][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004032] [Batch 00952/03080] [00:11:53/00:26:34, 0.749s/it]: train_loss_raw=2.1672, running_loss=2.1207, LR=0.000100
[2025-08-26 20:25:42,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004040] [Batch 00960/03080] [00:11:59/00:26:28, 0.749s/it]: train_loss_raw=2.1335, running_loss=2.1208, LR=0.000100
[2025-08-26 20:25:48,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004048] [Batch 00968/03080] [00:12:05/00:26:22, 0.749s/it]: train_loss_raw=2.0842, running_loss=2.1175, LR=0.000100
[2025-08-26 20:25:54,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004056] [Batch 00976/03080] [00:12:11/00:26:16, 0.749s/it]: train_loss_raw=2.1397, running_loss=2.1148, LR=0.000100
[2025-08-26 20:26:00,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004064] [Batch 00984/03080] [00:12:17/00:26:10, 0.749s/it]: train_loss_raw=2.1524, running_loss=2.1158, LR=0.000100
[2025-08-26 20:26:06,101][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004072] [Batch 00992/03080] [00:12:23/00:26:04, 0.749s/it]: train_loss_raw=2.1052, running_loss=2.1132, LR=0.000100
[2025-08-26 20:26:12,088][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004080] [Batch 01000/03080] [00:12:29/00:25:58, 0.749s/it]: train_loss_raw=2.0826, running_loss=2.1135, LR=0.000100
[2025-08-26 20:26:18,130][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004088] [Batch 01008/03080] [00:12:35/00:25:52, 0.749s/it]: train_loss_raw=2.0684, running_loss=2.1141, LR=0.000100
[2025-08-26 20:26:24,147][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004096] [Batch 01016/03080] [00:12:41/00:25:46, 0.749s/it]: train_loss_raw=2.0825, running_loss=2.1135, LR=0.000100
[2025-08-26 20:26:30,136][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004104] [Batch 01024/03080] [00:12:47/00:25:40, 0.749s/it]: train_loss_raw=2.1043, running_loss=2.1135, LR=0.000100
[2025-08-26 20:26:36,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004112] [Batch 01032/03080] [00:12:53/00:25:34, 0.749s/it]: train_loss_raw=2.1400, running_loss=2.1131, LR=0.000100
[2025-08-26 20:26:42,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004120] [Batch 01040/03080] [00:12:59/00:25:28, 0.749s/it]: train_loss_raw=2.1220, running_loss=2.1145, LR=0.000100
[2025-08-26 20:26:48,072][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004128] [Batch 01048/03080] [00:13:05/00:25:22, 0.749s/it]: train_loss_raw=2.1829, running_loss=2.1139, LR=0.000100
[2025-08-26 20:26:54,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004136] [Batch 01056/03080] [00:13:11/00:25:16, 0.749s/it]: train_loss_raw=2.1115, running_loss=2.1130, LR=0.000100
[2025-08-26 20:27:00,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004144] [Batch 01064/03080] [00:13:17/00:25:10, 0.749s/it]: train_loss_raw=2.0757, running_loss=2.1120, LR=0.000100
[2025-08-26 20:27:05,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004152] [Batch 01072/03080] [00:13:23/00:25:04, 0.749s/it]: train_loss_raw=2.1368, running_loss=2.1113, LR=0.000100
[2025-08-26 20:27:11,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004160] [Batch 01080/03080] [00:13:28/00:24:58, 0.749s/it]: train_loss_raw=2.1371, running_loss=2.1094, LR=0.000100
[2025-08-26 20:27:17,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004168] [Batch 01088/03080] [00:13:34/00:24:51, 0.749s/it]: train_loss_raw=2.1033, running_loss=2.1095, LR=0.000100
[2025-08-26 20:27:23,702][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004176] [Batch 01096/03080] [00:13:40/00:24:45, 0.749s/it]: train_loss_raw=2.0514, running_loss=2.1066, LR=0.000100
[2025-08-26 20:27:29,662][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004184] [Batch 01104/03080] [00:13:46/00:24:39, 0.749s/it]: train_loss_raw=2.1023, running_loss=2.1057, LR=0.000100
[2025-08-26 20:27:35,657][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004192] [Batch 01112/03080] [00:13:52/00:24:33, 0.749s/it]: train_loss_raw=2.0649, running_loss=2.1041, LR=0.000100
[2025-08-26 20:27:41,648][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004200] [Batch 01120/03080] [00:13:58/00:24:27, 0.749s/it]: train_loss_raw=2.1007, running_loss=2.1047, LR=0.000100
[2025-08-26 20:27:47,572][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004208] [Batch 01128/03080] [00:14:04/00:24:21, 0.749s/it]: train_loss_raw=2.0319, running_loss=2.1035, LR=0.000100
[2025-08-26 20:27:53,743][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004216] [Batch 01136/03080] [00:14:10/00:24:15, 0.749s/it]: train_loss_raw=2.1100, running_loss=2.1034, LR=0.000100
[2025-08-26 20:27:59,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004224] [Batch 01144/03080] [00:14:16/00:24:09, 0.749s/it]: train_loss_raw=2.0656, running_loss=2.1043, LR=0.000100
[2025-08-26 20:28:05,637][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004232] [Batch 01152/03080] [00:14:22/00:24:03, 0.749s/it]: train_loss_raw=2.1162, running_loss=2.1044, LR=0.000100
[2025-08-26 20:28:11,651][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004240] [Batch 01160/03080] [00:14:28/00:23:57, 0.749s/it]: train_loss_raw=2.1089, running_loss=2.1033, LR=0.000100
[2025-08-26 20:28:17,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004248] [Batch 01168/03080] [00:14:34/00:23:51, 0.749s/it]: train_loss_raw=2.1095, running_loss=2.1035, LR=0.000100
[2025-08-26 20:28:23,584][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004256] [Batch 01176/03080] [00:14:40/00:23:45, 0.749s/it]: train_loss_raw=2.0677, running_loss=2.1040, LR=0.000100
[2025-08-26 20:28:29,572][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004264] [Batch 01184/03080] [00:14:46/00:23:39, 0.749s/it]: train_loss_raw=2.0466, running_loss=2.1014, LR=0.000100
[2025-08-26 20:28:35,653][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004272] [Batch 01192/03080] [00:14:52/00:23:33, 0.749s/it]: train_loss_raw=2.1224, running_loss=2.1032, LR=0.000100
[2025-08-26 20:28:41,631][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004280] [Batch 01200/03080] [00:14:58/00:23:27, 0.749s/it]: train_loss_raw=2.1270, running_loss=2.1022, LR=0.000100
[2025-08-26 20:28:47,564][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004288] [Batch 01208/03080] [00:15:04/00:23:21, 0.749s/it]: train_loss_raw=2.0977, running_loss=2.1027, LR=0.000100
[2025-08-26 20:28:53,526][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004296] [Batch 01216/03080] [00:15:10/00:23:15, 0.749s/it]: train_loss_raw=2.1597, running_loss=2.1025, LR=0.000100
[2025-08-26 20:28:59,496][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004304] [Batch 01224/03080] [00:15:16/00:23:09, 0.749s/it]: train_loss_raw=2.0897, running_loss=2.1017, LR=0.000100
[2025-08-26 20:29:05,496][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004312] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=2.0555, running_loss=2.0995, LR=0.000100
[2025-08-26 20:29:11,414][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004320] [Batch 01240/03080] [00:15:28/00:22:57, 0.749s/it]: train_loss_raw=2.1404, running_loss=2.0985, LR=0.000100
[2025-08-26 20:29:17,330][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004328] [Batch 01248/03080] [00:15:34/00:22:51, 0.749s/it]: train_loss_raw=2.1426, running_loss=2.1001, LR=0.000100
[2025-08-26 20:29:23,430][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004336] [Batch 01256/03080] [00:15:40/00:22:45, 0.749s/it]: train_loss_raw=2.0521, running_loss=2.0998, LR=0.000100
[2025-08-26 20:29:29,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004344] [Batch 01264/03080] [00:15:46/00:22:39, 0.749s/it]: train_loss_raw=2.0848, running_loss=2.1011, LR=0.000100
[2025-08-26 20:29:35,445][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004352] [Batch 01272/03080] [00:15:52/00:22:33, 0.749s/it]: train_loss_raw=2.0614, running_loss=2.0990, LR=0.000100
[2025-08-26 20:29:41,386][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004360] [Batch 01280/03080] [00:15:58/00:22:27, 0.749s/it]: train_loss_raw=2.1113, running_loss=2.1006, LR=0.000100
[2025-08-26 20:29:47,214][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004368] [Batch 01288/03080] [00:16:04/00:22:21, 0.749s/it]: train_loss_raw=2.0462, running_loss=2.0988, LR=0.000100
[2025-08-26 20:29:53,139][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004376] [Batch 01296/03080] [00:16:10/00:22:15, 0.749s/it]: train_loss_raw=2.0970, running_loss=2.0987, LR=0.000100
[2025-08-26 20:29:59,116][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004384] [Batch 01304/03080] [00:16:16/00:22:09, 0.749s/it]: train_loss_raw=2.0702, running_loss=2.0984, LR=0.000100
[2025-08-26 20:30:05,102][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004392] [Batch 01312/03080] [00:16:22/00:22:03, 0.749s/it]: train_loss_raw=2.0873, running_loss=2.0989, LR=0.000100
[2025-08-26 20:30:11,111][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004400] [Batch 01320/03080] [00:16:28/00:21:57, 0.749s/it]: train_loss_raw=2.1417, running_loss=2.0993, LR=0.000100
[2025-08-26 20:30:17,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004408] [Batch 01328/03080] [00:16:34/00:21:51, 0.749s/it]: train_loss_raw=2.0646, running_loss=2.0989, LR=0.000100
[2025-08-26 20:30:22,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004416] [Batch 01336/03080] [00:16:40/00:21:45, 0.749s/it]: train_loss_raw=2.1373, running_loss=2.0978, LR=0.000100
[2025-08-26 20:30:29,040][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004424] [Batch 01344/03080] [00:16:46/00:21:39, 0.749s/it]: train_loss_raw=1.9887, running_loss=2.0946, LR=0.000100
[2025-08-26 20:30:34,949][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004432] [Batch 01352/03080] [00:16:52/00:21:33, 0.749s/it]: train_loss_raw=2.1026, running_loss=2.0934, LR=0.000100
[2025-08-26 20:30:40,895][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004440] [Batch 01360/03080] [00:16:57/00:21:27, 0.749s/it]: train_loss_raw=2.1538, running_loss=2.0958, LR=0.000100
[2025-08-26 20:30:46,844][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004448] [Batch 01368/03080] [00:17:03/00:21:21, 0.748s/it]: train_loss_raw=2.0610, running_loss=2.0953, LR=0.000100
[2025-08-26 20:30:52,814][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004456] [Batch 01376/03080] [00:17:09/00:21:15, 0.748s/it]: train_loss_raw=2.0909, running_loss=2.0946, LR=0.000100
[2025-08-26 20:30:58,949][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004464] [Batch 01384/03080] [00:17:16/00:21:09, 0.749s/it]: train_loss_raw=2.0537, running_loss=2.0942, LR=0.000100
[2025-08-26 20:31:04,997][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004472] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=2.0903, running_loss=2.0940, LR=0.000100
[2025-08-26 20:31:10,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004480] [Batch 01400/03080] [00:17:28/00:20:57, 0.749s/it]: train_loss_raw=2.0737, running_loss=2.0927, LR=0.000100
[2025-08-26 20:31:16,906][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004488] [Batch 01408/03080] [00:17:33/00:20:51, 0.749s/it]: train_loss_raw=2.0259, running_loss=2.0929, LR=0.000100
[2025-08-26 20:31:22,756][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004496] [Batch 01416/03080] [00:17:39/00:20:45, 0.748s/it]: train_loss_raw=2.1943, running_loss=2.0942, LR=0.000100
[2025-08-26 20:31:28,688][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004504] [Batch 01424/03080] [00:17:45/00:20:39, 0.748s/it]: train_loss_raw=2.1327, running_loss=2.0946, LR=0.000100
[2025-08-26 20:31:34,617][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004512] [Batch 01432/03080] [00:17:51/00:20:33, 0.748s/it]: train_loss_raw=2.1810, running_loss=2.0949, LR=0.000100
[2025-08-26 20:31:40,536][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004520] [Batch 01440/03080] [00:17:57/00:20:27, 0.748s/it]: train_loss_raw=2.0864, running_loss=2.0925, LR=0.000100
[2025-08-26 20:31:46,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004528] [Batch 01448/03080] [00:18:03/00:20:21, 0.748s/it]: train_loss_raw=2.0999, running_loss=2.0915, LR=0.000100
[2025-08-26 20:31:52,540][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004536] [Batch 01456/03080] [00:18:09/00:20:15, 0.748s/it]: train_loss_raw=2.0022, running_loss=2.0912, LR=0.000100
[2025-08-26 20:31:58,484][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004544] [Batch 01464/03080] [00:18:15/00:20:09, 0.748s/it]: train_loss_raw=2.0876, running_loss=2.0897, LR=0.000100
[2025-08-26 20:32:04,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004552] [Batch 01472/03080] [00:18:21/00:20:03, 0.748s/it]: train_loss_raw=2.1252, running_loss=2.0890, LR=0.000100
[2025-08-26 20:32:10,356][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004560] [Batch 01480/03080] [00:18:27/00:19:57, 0.748s/it]: train_loss_raw=2.1235, running_loss=2.0877, LR=0.000100
[2025-08-26 20:32:16,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004568] [Batch 01488/03080] [00:18:33/00:19:51, 0.748s/it]: train_loss_raw=2.1520, running_loss=2.0903, LR=0.000100
[2025-08-26 20:32:22,326][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004576] [Batch 01496/03080] [00:18:39/00:19:45, 0.748s/it]: train_loss_raw=2.0784, running_loss=2.0879, LR=0.000100
[2025-08-26 20:32:28,354][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004584] [Batch 01504/03080] [00:18:45/00:19:39, 0.748s/it]: train_loss_raw=2.0446, running_loss=2.0863, LR=0.000100
[2025-08-26 20:32:34,274][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004592] [Batch 01512/03080] [00:18:51/00:19:33, 0.748s/it]: train_loss_raw=2.0305, running_loss=2.0861, LR=0.000100
[2025-08-26 20:32:40,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004600] [Batch 01520/03080] [00:18:57/00:19:27, 0.748s/it]: train_loss_raw=2.0899, running_loss=2.0843, LR=0.000100
[2025-08-26 20:32:46,265][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004608] [Batch 01528/03080] [00:19:03/00:19:21, 0.748s/it]: train_loss_raw=2.0878, running_loss=2.0825, LR=0.000100
[2025-08-26 20:32:52,211][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004616] [Batch 01536/03080] [00:19:09/00:19:15, 0.748s/it]: train_loss_raw=2.0933, running_loss=2.0825, LR=0.000100
[2025-08-26 20:32:58,167][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004624] [Batch 01544/03080] [00:19:15/00:19:09, 0.748s/it]: train_loss_raw=1.9696, running_loss=2.0812, LR=0.000100
[2025-08-26 20:33:04,128][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004632] [Batch 01552/03080] [00:19:21/00:19:03, 0.748s/it]: train_loss_raw=1.9798, running_loss=2.0809, LR=0.000100
[2025-08-26 20:33:10,084][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004640] [Batch 01560/03080] [00:19:27/00:18:57, 0.748s/it]: train_loss_raw=2.0773, running_loss=2.0795, LR=0.000100
[2025-08-26 20:33:16,031][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004648] [Batch 01568/03080] [00:19:33/00:18:51, 0.748s/it]: train_loss_raw=2.1142, running_loss=2.0828, LR=0.000100
[2025-08-26 20:33:22,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004656] [Batch 01576/03080] [00:19:39/00:18:45, 0.748s/it]: train_loss_raw=2.0005, running_loss=2.0806, LR=0.000100
[2025-08-26 20:33:27,857][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004664] [Batch 01584/03080] [00:19:44/00:18:39, 0.748s/it]: train_loss_raw=2.0630, running_loss=2.0811, LR=0.000100
[2025-08-26 20:33:33,791][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004672] [Batch 01592/03080] [00:19:50/00:18:33, 0.748s/it]: train_loss_raw=2.1563, running_loss=2.0809, LR=0.000100
[2025-08-26 20:33:39,670][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004680] [Batch 01600/03080] [00:19:56/00:18:26, 0.748s/it]: train_loss_raw=2.1232, running_loss=2.0788, LR=0.000100
[2025-08-26 20:33:45,580][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004688] [Batch 01608/03080] [00:20:02/00:18:20, 0.748s/it]: train_loss_raw=2.0517, running_loss=2.0776, LR=0.000100
[2025-08-26 20:33:51,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004696] [Batch 01616/03080] [00:20:08/00:18:14, 0.748s/it]: train_loss_raw=2.0038, running_loss=2.0768, LR=0.000100
[2025-08-26 20:33:57,422][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004704] [Batch 01624/03080] [00:20:14/00:18:08, 0.748s/it]: train_loss_raw=2.1652, running_loss=2.0783, LR=0.000100
[2025-08-26 20:34:03,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004712] [Batch 01632/03080] [00:20:20/00:18:02, 0.748s/it]: train_loss_raw=2.0515, running_loss=2.0790, LR=0.000100
[2025-08-26 20:34:09,470][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004720] [Batch 01640/03080] [00:20:26/00:17:56, 0.748s/it]: train_loss_raw=2.1401, running_loss=2.0808, LR=0.000100
[2025-08-26 20:34:15,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004728] [Batch 01648/03080] [00:20:32/00:17:51, 0.748s/it]: train_loss_raw=2.0580, running_loss=2.0814, LR=0.000100
[2025-08-26 20:34:21,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004736] [Batch 01656/03080] [00:20:38/00:17:45, 0.748s/it]: train_loss_raw=2.0538, running_loss=2.0802, LR=0.000100
[2025-08-26 20:34:27,466][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004744] [Batch 01664/03080] [00:20:44/00:17:39, 0.748s/it]: train_loss_raw=2.0392, running_loss=2.0791, LR=0.000100
[2025-08-26 20:34:33,417][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004752] [Batch 01672/03080] [00:20:50/00:17:33, 0.748s/it]: train_loss_raw=2.1050, running_loss=2.0793, LR=0.000100
[2025-08-26 20:34:39,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004760] [Batch 01680/03080] [00:20:56/00:17:27, 0.748s/it]: train_loss_raw=1.9669, running_loss=2.0789, LR=0.000100
[2025-08-26 20:34:45,313][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004768] [Batch 01688/03080] [00:21:02/00:17:21, 0.748s/it]: train_loss_raw=2.0444, running_loss=2.0785, LR=0.000100
[2025-08-26 20:34:51,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004776] [Batch 01696/03080] [00:21:08/00:17:15, 0.748s/it]: train_loss_raw=2.0693, running_loss=2.0770, LR=0.000100
[2025-08-26 20:34:57,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004784] [Batch 01704/03080] [00:21:14/00:17:08, 0.748s/it]: train_loss_raw=2.0563, running_loss=2.0769, LR=0.000100
[2025-08-26 20:35:03,082][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004792] [Batch 01712/03080] [00:21:20/00:17:02, 0.748s/it]: train_loss_raw=2.1267, running_loss=2.0771, LR=0.000100
[2025-08-26 20:35:08,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004800] [Batch 01720/03080] [00:21:26/00:16:56, 0.748s/it]: train_loss_raw=2.0823, running_loss=2.0784, LR=0.000100
[2025-08-26 20:35:14,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004808] [Batch 01728/03080] [00:21:32/00:16:50, 0.748s/it]: train_loss_raw=2.0497, running_loss=2.0785, LR=0.000100
[2025-08-26 20:35:20,840][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004816] [Batch 01736/03080] [00:21:37/00:16:44, 0.748s/it]: train_loss_raw=2.0892, running_loss=2.0758, LR=0.000100
[2025-08-26 20:35:26,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004824] [Batch 01744/03080] [00:21:43/00:16:38, 0.748s/it]: train_loss_raw=2.0356, running_loss=2.0752, LR=0.000100
[2025-08-26 20:35:32,727][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004832] [Batch 01752/03080] [00:21:49/00:16:32, 0.748s/it]: train_loss_raw=2.0789, running_loss=2.0726, LR=0.000100
[2025-08-26 20:35:38,648][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004840] [Batch 01760/03080] [00:21:55/00:16:26, 0.748s/it]: train_loss_raw=2.0252, running_loss=2.0712, LR=0.000100
[2025-08-26 20:35:44,600][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004848] [Batch 01768/03080] [00:22:01/00:16:20, 0.748s/it]: train_loss_raw=2.0511, running_loss=2.0662, LR=0.000100
[2025-08-26 20:35:50,591][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004856] [Batch 01776/03080] [00:22:07/00:16:14, 0.748s/it]: train_loss_raw=2.0036, running_loss=2.0637, LR=0.000100
[2025-08-26 20:35:56,650][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004864] [Batch 01784/03080] [00:22:13/00:16:08, 0.748s/it]: train_loss_raw=1.9973, running_loss=2.0621, LR=0.000100
[2025-08-26 20:36:02,872][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 01792/03080] [00:22:19/00:16:03, 0.748s/it]: train_loss_raw=2.0560, running_loss=2.0601, LR=0.000100
[2025-08-26 20:36:09,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004880] [Batch 01800/03080] [00:22:26/00:15:57, 0.748s/it]: train_loss_raw=2.0888, running_loss=2.0611, LR=0.000100
[2025-08-26 20:36:15,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004888] [Batch 01808/03080] [00:22:32/00:15:51, 0.748s/it]: train_loss_raw=2.1421, running_loss=2.0623, LR=0.000100
[2025-08-26 20:36:21,448][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 01816/03080] [00:22:38/00:15:45, 0.748s/it]: train_loss_raw=2.0864, running_loss=2.0645, LR=0.000100
[2025-08-26 20:36:27,572][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004904] [Batch 01824/03080] [00:22:44/00:15:39, 0.748s/it]: train_loss_raw=2.0689, running_loss=2.0633, LR=0.000100
[2025-08-26 20:36:33,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004912] [Batch 01832/03080] [00:22:50/00:15:33, 0.748s/it]: train_loss_raw=2.1610, running_loss=2.0615, LR=0.000100
[2025-08-26 20:36:39,792][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 01840/03080] [00:22:56/00:15:27, 0.748s/it]: train_loss_raw=2.0443, running_loss=2.0624, LR=0.000100
[2025-08-26 20:36:46,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004928] [Batch 01848/03080] [00:23:03/00:15:22, 0.748s/it]: train_loss_raw=2.0023, running_loss=2.0611, LR=0.000100
[2025-08-26 20:36:52,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004936] [Batch 01856/03080] [00:23:09/00:15:16, 0.749s/it]: train_loss_raw=2.1133, running_loss=2.0635, LR=0.000100
[2025-08-26 20:36:58,338][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 01864/03080] [00:23:15/00:15:10, 0.749s/it]: train_loss_raw=2.1202, running_loss=2.0617, LR=0.000100
[2025-08-26 20:37:04,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004952] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=2.0597, running_loss=2.0608, LR=0.000100
[2025-08-26 20:37:10,428][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004960] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=2.0865, running_loss=2.0585, LR=0.000100
[2025-08-26 20:37:16,398][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 01888/03080] [00:23:33/00:14:52, 0.749s/it]: train_loss_raw=1.9401, running_loss=2.0567, LR=0.000100
[2025-08-26 20:37:22,355][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004976] [Batch 01896/03080] [00:23:39/00:14:46, 0.749s/it]: train_loss_raw=2.0637, running_loss=2.0564, LR=0.000100
[2025-08-26 20:37:28,232][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004984] [Batch 01904/03080] [00:23:45/00:14:40, 0.749s/it]: train_loss_raw=2.1099, running_loss=2.0573, LR=0.000100
[2025-08-26 20:37:34,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 01912/03080] [00:23:51/00:14:34, 0.749s/it]: train_loss_raw=2.0360, running_loss=2.0589, LR=0.000100
[2025-08-26 20:37:40,337][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005000] [Batch 01920/03080] [00:23:57/00:14:28, 0.749s/it]: train_loss_raw=2.1521, running_loss=2.0609, LR=0.000100
[2025-08-26 20:37:46,180][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005008] [Batch 01928/03080] [00:24:03/00:14:22, 0.749s/it]: train_loss_raw=2.0856, running_loss=2.0603, LR=0.000100
[2025-08-26 20:37:52,153][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 01936/03080] [00:24:09/00:14:16, 0.749s/it]: train_loss_raw=2.0484, running_loss=2.0621, LR=0.000100
[2025-08-26 20:37:58,129][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005024] [Batch 01944/03080] [00:24:15/00:14:10, 0.749s/it]: train_loss_raw=2.1456, running_loss=2.0618, LR=0.000100
[2025-08-26 20:38:04,374][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005032] [Batch 01952/03080] [00:24:21/00:14:04, 0.749s/it]: train_loss_raw=2.0215, running_loss=2.0622, LR=0.000100
[2025-08-26 20:38:10,373][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 01960/03080] [00:24:27/00:13:58, 0.749s/it]: train_loss_raw=2.1150, running_loss=2.0627, LR=0.000100
[2025-08-26 20:38:16,583][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005048] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=2.1335, running_loss=2.0625, LR=0.000100
[2025-08-26 20:38:22,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005056] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=2.0589, running_loss=2.0620, LR=0.000100
[2025-08-26 20:38:28,778][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 01984/03080] [00:24:45/00:13:40, 0.749s/it]: train_loss_raw=2.0942, running_loss=2.0615, LR=0.000100
[2025-08-26 20:38:34,800][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005072] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=2.0111, running_loss=2.0627, LR=0.000100
[2025-08-26 20:38:40,820][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005080] [Batch 02000/03080] [00:24:57/00:13:28, 0.749s/it]: train_loss_raw=2.0705, running_loss=2.0622, LR=0.000100
[2025-08-26 20:38:46,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 02008/03080] [00:25:03/00:13:22, 0.749s/it]: train_loss_raw=1.9719, running_loss=2.0619, LR=0.000100
[2025-08-26 20:38:52,957][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005096] [Batch 02016/03080] [00:25:10/00:13:16, 0.749s/it]: train_loss_raw=2.0677, running_loss=2.0616, LR=0.000100
[2025-08-26 20:38:59,013][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005104] [Batch 02024/03080] [00:25:16/00:13:11, 0.749s/it]: train_loss_raw=1.9949, running_loss=2.0619, LR=0.000100
[2025-08-26 20:39:05,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 02032/03080] [00:25:22/00:13:05, 0.749s/it]: train_loss_raw=2.0322, running_loss=2.0592, LR=0.000100
[2025-08-26 20:39:10,983][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005120] [Batch 02040/03080] [00:25:28/00:12:59, 0.749s/it]: train_loss_raw=2.0265, running_loss=2.0553, LR=0.000100
[2025-08-26 20:39:17,001][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005128] [Batch 02048/03080] [00:25:34/00:12:53, 0.749s/it]: train_loss_raw=2.0141, running_loss=2.0525, LR=0.000100
[2025-08-26 20:39:22,862][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 02056/03080] [00:25:39/00:12:46, 0.749s/it]: train_loss_raw=2.0622, running_loss=2.0510, LR=0.000100
[2025-08-26 20:39:28,793][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005144] [Batch 02064/03080] [00:25:45/00:12:40, 0.749s/it]: train_loss_raw=2.0103, running_loss=2.0495, LR=0.000100
[2025-08-26 20:39:34,725][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005152] [Batch 02072/03080] [00:25:51/00:12:34, 0.749s/it]: train_loss_raw=2.0571, running_loss=2.0498, LR=0.000100
[2025-08-26 20:39:40,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 02080/03080] [00:25:57/00:12:28, 0.749s/it]: train_loss_raw=2.0780, running_loss=2.0502, LR=0.000100
[2025-08-26 20:39:46,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005168] [Batch 02088/03080] [00:26:03/00:12:22, 0.749s/it]: train_loss_raw=1.9749, running_loss=2.0501, LR=0.000100
[2025-08-26 20:39:52,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005176] [Batch 02096/03080] [00:26:09/00:12:16, 0.749s/it]: train_loss_raw=2.1093, running_loss=2.0483, LR=0.000100
[2025-08-26 20:39:58,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 02104/03080] [00:26:15/00:12:10, 0.749s/it]: train_loss_raw=2.0486, running_loss=2.0468, LR=0.000100
[2025-08-26 20:40:04,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005192] [Batch 02112/03080] [00:26:21/00:12:04, 0.749s/it]: train_loss_raw=2.0260, running_loss=2.0465, LR=0.000100
[2025-08-26 20:40:10,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005200] [Batch 02120/03080] [00:26:27/00:11:58, 0.749s/it]: train_loss_raw=1.9847, running_loss=2.0446, LR=0.000100
[2025-08-26 20:40:16,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 02128/03080] [00:26:33/00:11:53, 0.749s/it]: train_loss_raw=2.0496, running_loss=2.0449, LR=0.000100
[2025-08-26 20:40:22,612][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005216] [Batch 02136/03080] [00:26:39/00:11:46, 0.749s/it]: train_loss_raw=1.9989, running_loss=2.0470, LR=0.000100
[2025-08-26 20:40:28,526][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005224] [Batch 02144/03080] [00:26:45/00:11:40, 0.749s/it]: train_loss_raw=2.1092, running_loss=2.0470, LR=0.000100
[2025-08-26 20:40:34,467][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 02152/03080] [00:26:51/00:11:34, 0.749s/it]: train_loss_raw=2.0197, running_loss=2.0464, LR=0.000100
[2025-08-26 20:40:40,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005240] [Batch 02160/03080] [00:26:57/00:11:28, 0.749s/it]: train_loss_raw=2.0316, running_loss=2.0477, LR=0.000100
[2025-08-26 20:40:46,459][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005248] [Batch 02168/03080] [00:27:03/00:11:22, 0.749s/it]: train_loss_raw=2.0379, running_loss=2.0492, LR=0.000100
[2025-08-26 20:40:52,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 02176/03080] [00:27:09/00:11:17, 0.749s/it]: train_loss_raw=1.9360, running_loss=2.0463, LR=0.000100
[2025-08-26 20:40:58,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005264] [Batch 02184/03080] [00:27:15/00:11:11, 0.749s/it]: train_loss_raw=2.0056, running_loss=2.0449, LR=0.000100
[2025-08-26 20:41:04,442][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005272] [Batch 02192/03080] [00:27:21/00:11:04, 0.749s/it]: train_loss_raw=2.0729, running_loss=2.0457, LR=0.000100
[2025-08-26 20:41:10,352][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 02200/03080] [00:27:27/00:10:58, 0.749s/it]: train_loss_raw=2.1680, running_loss=2.0453, LR=0.000100
[2025-08-26 20:41:16,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005288] [Batch 02208/03080] [00:27:33/00:10:52, 0.749s/it]: train_loss_raw=2.0103, running_loss=2.0459, LR=0.000100
[2025-08-26 20:41:22,333][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005296] [Batch 02216/03080] [00:27:39/00:10:46, 0.749s/it]: train_loss_raw=2.0882, running_loss=2.0444, LR=0.000100
[2025-08-26 20:41:28,220][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 02224/03080] [00:27:45/00:10:40, 0.749s/it]: train_loss_raw=2.0646, running_loss=2.0440, LR=0.000100
[2025-08-26 20:41:34,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005312] [Batch 02232/03080] [00:27:51/00:10:34, 0.749s/it]: train_loss_raw=2.0041, running_loss=2.0433, LR=0.000100
[2025-08-26 20:41:40,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005320] [Batch 02240/03080] [00:27:57/00:10:29, 0.749s/it]: train_loss_raw=2.0074, running_loss=2.0426, LR=0.000100
[2025-08-26 20:41:46,213][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 02248/03080] [00:28:03/00:10:22, 0.749s/it]: train_loss_raw=2.0543, running_loss=2.0430, LR=0.000100
[2025-08-26 20:41:52,171][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005336] [Batch 02256/03080] [00:28:09/00:10:16, 0.749s/it]: train_loss_raw=1.9939, running_loss=2.0408, LR=0.000100
[2025-08-26 20:41:58,139][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005344] [Batch 02264/03080] [00:28:15/00:10:10, 0.749s/it]: train_loss_raw=2.0194, running_loss=2.0404, LR=0.000100
[2025-08-26 20:42:04,196][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 02272/03080] [00:28:21/00:10:05, 0.749s/it]: train_loss_raw=1.9999, running_loss=2.0401, LR=0.000100
[2025-08-26 20:42:10,173][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005360] [Batch 02280/03080] [00:28:27/00:09:59, 0.749s/it]: train_loss_raw=2.0319, running_loss=2.0388, LR=0.000100
[2025-08-26 20:42:16,096][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005368] [Batch 02288/03080] [00:28:33/00:09:53, 0.749s/it]: train_loss_raw=1.9932, running_loss=2.0382, LR=0.000100
[2025-08-26 20:42:22,070][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 02296/03080] [00:28:39/00:09:47, 0.749s/it]: train_loss_raw=1.9492, running_loss=2.0357, LR=0.000100
[2025-08-26 20:42:28,034][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005384] [Batch 02304/03080] [00:28:45/00:09:41, 0.749s/it]: train_loss_raw=2.0652, running_loss=2.0338, LR=0.000100
[2025-08-26 20:42:33,993][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005392] [Batch 02312/03080] [00:28:51/00:09:35, 0.749s/it]: train_loss_raw=2.0891, running_loss=2.0362, LR=0.000100
[2025-08-26 20:42:39,910][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 02320/03080] [00:28:56/00:09:29, 0.749s/it]: train_loss_raw=1.9748, running_loss=2.0361, LR=0.000100
[2025-08-26 20:42:45,884][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005408] [Batch 02328/03080] [00:29:02/00:09:23, 0.749s/it]: train_loss_raw=2.0962, running_loss=2.0346, LR=0.000100
[2025-08-26 20:42:51,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005416] [Batch 02336/03080] [00:29:08/00:09:17, 0.749s/it]: train_loss_raw=1.9904, running_loss=2.0345, LR=0.000100
[2025-08-26 20:42:57,846][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 02344/03080] [00:29:14/00:09:11, 0.749s/it]: train_loss_raw=2.0192, running_loss=2.0332, LR=0.000100
[2025-08-26 20:43:03,840][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005432] [Batch 02352/03080] [00:29:20/00:09:05, 0.749s/it]: train_loss_raw=2.0831, running_loss=2.0360, LR=0.000100
[2025-08-26 20:43:09,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005440] [Batch 02360/03080] [00:29:26/00:08:59, 0.749s/it]: train_loss_raw=2.0428, running_loss=2.0363, LR=0.000100
[2025-08-26 20:43:15,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 02368/03080] [00:29:32/00:08:53, 0.749s/it]: train_loss_raw=1.9665, running_loss=2.0362, LR=0.000100
[2025-08-26 20:43:21,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005456] [Batch 02376/03080] [00:29:38/00:08:47, 0.749s/it]: train_loss_raw=2.0489, running_loss=2.0359, LR=0.000100
[2025-08-26 20:43:27,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005464] [Batch 02384/03080] [00:29:44/00:08:41, 0.749s/it]: train_loss_raw=2.0775, running_loss=2.0358, LR=0.000100
[2025-08-26 20:43:33,687][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 02392/03080] [00:29:50/00:08:35, 0.749s/it]: train_loss_raw=1.9255, running_loss=2.0335, LR=0.000100
[2025-08-26 20:43:39,530][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005480] [Batch 02400/03080] [00:29:56/00:08:29, 0.749s/it]: train_loss_raw=2.0239, running_loss=2.0312, LR=0.000100
[2025-08-26 20:43:45,438][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005488] [Batch 02408/03080] [00:30:02/00:08:23, 0.749s/it]: train_loss_raw=2.0508, running_loss=2.0313, LR=0.000100
[2025-08-26 20:43:51,474][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 02416/03080] [00:30:08/00:08:17, 0.749s/it]: train_loss_raw=2.0474, running_loss=2.0308, LR=0.000100
[2025-08-26 20:43:57,469][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005504] [Batch 02424/03080] [00:30:14/00:08:11, 0.749s/it]: train_loss_raw=2.0924, running_loss=2.0323, LR=0.000100
[2025-08-26 20:44:03,402][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005512] [Batch 02432/03080] [00:30:20/00:08:05, 0.749s/it]: train_loss_raw=1.9982, running_loss=2.0340, LR=0.000100
[2025-08-26 20:44:09,493][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 02440/03080] [00:30:26/00:07:59, 0.749s/it]: train_loss_raw=2.0517, running_loss=2.0342, LR=0.000100
[2025-08-26 20:44:15,419][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005528] [Batch 02448/03080] [00:30:32/00:07:53, 0.749s/it]: train_loss_raw=2.0693, running_loss=2.0360, LR=0.000100
[2025-08-26 20:44:21,355][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005536] [Batch 02456/03080] [00:30:38/00:07:47, 0.749s/it]: train_loss_raw=1.9981, running_loss=2.0344, LR=0.000100
[2025-08-26 20:44:27,254][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 02464/03080] [00:30:44/00:07:41, 0.749s/it]: train_loss_raw=2.0174, running_loss=2.0341, LR=0.000100
[2025-08-26 20:44:33,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005552] [Batch 02472/03080] [00:30:50/00:07:35, 0.749s/it]: train_loss_raw=2.0109, running_loss=2.0329, LR=0.000100
[2025-08-26 20:44:39,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005560] [Batch 02480/03080] [00:30:56/00:07:29, 0.749s/it]: train_loss_raw=2.0051, running_loss=2.0321, LR=0.000100
[2025-08-26 20:44:45,242][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 02488/03080] [00:31:02/00:07:23, 0.749s/it]: train_loss_raw=2.1040, running_loss=2.0322, LR=0.000100
[2025-08-26 20:44:51,203][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005576] [Batch 02496/03080] [00:31:08/00:07:17, 0.749s/it]: train_loss_raw=2.0040, running_loss=2.0318, LR=0.000100
[2025-08-26 20:44:57,124][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005584] [Batch 02504/03080] [00:31:14/00:07:11, 0.748s/it]: train_loss_raw=2.0507, running_loss=2.0319, LR=0.000100
[2025-08-26 20:45:03,108][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 02512/03080] [00:31:20/00:07:05, 0.748s/it]: train_loss_raw=2.0309, running_loss=2.0321, LR=0.000100
[2025-08-26 20:45:09,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005600] [Batch 02520/03080] [00:31:26/00:06:59, 0.748s/it]: train_loss_raw=2.0030, running_loss=2.0319, LR=0.000100
[2025-08-26 20:45:14,980][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005608] [Batch 02528/03080] [00:31:32/00:06:53, 0.748s/it]: train_loss_raw=1.9761, running_loss=2.0304, LR=0.000100
[2025-08-26 20:45:20,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 02536/03080] [00:31:38/00:06:47, 0.748s/it]: train_loss_raw=2.0629, running_loss=2.0307, LR=0.000100
[2025-08-26 20:45:26,908][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005624] [Batch 02544/03080] [00:31:43/00:06:41, 0.748s/it]: train_loss_raw=2.0681, running_loss=2.0314, LR=0.000100
[2025-08-26 20:45:32,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005632] [Batch 02552/03080] [00:31:49/00:06:35, 0.748s/it]: train_loss_raw=2.0259, running_loss=2.0306, LR=0.000100
[2025-08-26 20:45:38,816][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 02560/03080] [00:31:55/00:06:29, 0.748s/it]: train_loss_raw=2.1175, running_loss=2.0315, LR=0.000100
[2025-08-26 20:45:44,866][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005648] [Batch 02568/03080] [00:32:01/00:06:23, 0.748s/it]: train_loss_raw=2.0315, running_loss=2.0309, LR=0.000100
[2025-08-26 20:45:50,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005656] [Batch 02576/03080] [00:32:07/00:06:17, 0.748s/it]: train_loss_raw=2.0120, running_loss=2.0302, LR=0.000100
[2025-08-26 20:45:56,831][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 02584/03080] [00:32:13/00:06:11, 0.748s/it]: train_loss_raw=1.9937, running_loss=2.0258, LR=0.000100
[2025-08-26 20:46:02,783][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005672] [Batch 02592/03080] [00:32:19/00:06:05, 0.748s/it]: train_loss_raw=2.0167, running_loss=2.0270, LR=0.000100
[2025-08-26 20:46:08,764][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005680] [Batch 02600/03080] [00:32:25/00:05:59, 0.748s/it]: train_loss_raw=2.0606, running_loss=2.0278, LR=0.000100
[2025-08-26 20:46:14,750][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 02608/03080] [00:32:31/00:05:53, 0.748s/it]: train_loss_raw=1.9934, running_loss=2.0289, LR=0.000100
[2025-08-26 20:46:20,700][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005696] [Batch 02616/03080] [00:32:37/00:05:47, 0.748s/it]: train_loss_raw=2.0077, running_loss=2.0269, LR=0.000100
[2025-08-26 20:46:26,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005704] [Batch 02624/03080] [00:32:43/00:05:41, 0.748s/it]: train_loss_raw=2.0097, running_loss=2.0260, LR=0.000100
[2025-08-26 20:46:32,586][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=2.0189, running_loss=2.0268, LR=0.000100
[2025-08-26 20:46:38,507][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005720] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.9640, running_loss=2.0260, LR=0.000100
[2025-08-26 20:46:44,446][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005728] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=1.9837, running_loss=2.0244, LR=0.000100
[2025-08-26 20:46:50,453][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=2.0396, running_loss=2.0242, LR=0.000100
[2025-08-26 20:46:56,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005744] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=2.0735, running_loss=2.0248, LR=0.000100
[2025-08-26 20:47:02,317][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005752] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=2.1556, running_loss=2.0262, LR=0.000100
[2025-08-26 20:47:08,224][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 02680/03080] [00:33:25/00:04:59, 0.748s/it]: train_loss_raw=2.0634, running_loss=2.0264, LR=0.000100
[2025-08-26 20:47:14,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005768] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=1.9306, running_loss=2.0244, LR=0.000100
[2025-08-26 20:47:20,089][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005776] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=2.1723, running_loss=2.0240, LR=0.000100
[2025-08-26 20:47:26,726][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=1.9671, running_loss=2.0237, LR=0.000100
[2025-08-26 20:47:32,690][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005792] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=2.0370, running_loss=2.0231, LR=0.000100
[2025-08-26 20:47:38,457][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005800] [Batch 02720/03080] [00:33:55/00:04:29, 0.748s/it]: train_loss_raw=1.9779, running_loss=2.0228, LR=0.000100
[2025-08-26 20:47:44,393][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 02728/03080] [00:34:01/00:04:23, 0.748s/it]: train_loss_raw=2.0744, running_loss=2.0238, LR=0.000100
[2025-08-26 20:47:50,604][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005816] [Batch 02736/03080] [00:34:07/00:04:17, 0.748s/it]: train_loss_raw=2.0674, running_loss=2.0240, LR=0.000100
[2025-08-26 20:47:56,448][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005824] [Batch 02744/03080] [00:34:13/00:04:11, 0.748s/it]: train_loss_raw=1.9701, running_loss=2.0223, LR=0.000100
[2025-08-26 20:48:02,356][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 02752/03080] [00:34:19/00:04:05, 0.748s/it]: train_loss_raw=1.9932, running_loss=2.0219, LR=0.000100
[2025-08-26 20:48:08,294][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005840] [Batch 02760/03080] [00:34:25/00:03:59, 0.748s/it]: train_loss_raw=1.9863, running_loss=2.0203, LR=0.000100
[2025-08-26 20:48:14,328][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005848] [Batch 02768/03080] [00:34:31/00:03:53, 0.748s/it]: train_loss_raw=1.9747, running_loss=2.0185, LR=0.000100
[2025-08-26 20:48:20,326][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 02776/03080] [00:34:37/00:03:47, 0.748s/it]: train_loss_raw=1.9747, running_loss=2.0171, LR=0.000100
[2025-08-26 20:48:26,374][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005864] [Batch 02784/03080] [00:34:43/00:03:41, 0.748s/it]: train_loss_raw=1.9839, running_loss=2.0140, LR=0.000100
[2025-08-26 20:48:32,228][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005872] [Batch 02792/03080] [00:34:49/00:03:35, 0.748s/it]: train_loss_raw=2.0204, running_loss=2.0133, LR=0.000100
[2025-08-26 20:48:38,171][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 02800/03080] [00:34:55/00:03:29, 0.748s/it]: train_loss_raw=1.9343, running_loss=2.0136, LR=0.000100
[2025-08-26 20:48:44,037][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005888] [Batch 02808/03080] [00:35:01/00:03:23, 0.748s/it]: train_loss_raw=2.0041, running_loss=2.0145, LR=0.000100
[2025-08-26 20:48:49,962][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005896] [Batch 02816/03080] [00:35:07/00:03:17, 0.748s/it]: train_loss_raw=1.9077, running_loss=2.0155, LR=0.000100
[2025-08-26 20:48:55,972][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 02824/03080] [00:35:13/00:03:11, 0.748s/it]: train_loss_raw=1.9947, running_loss=2.0138, LR=0.000100
[2025-08-26 20:49:01,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005912] [Batch 02832/03080] [00:35:19/00:03:05, 0.748s/it]: train_loss_raw=1.9562, running_loss=2.0134, LR=0.000100
[2025-08-26 20:49:07,831][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005920] [Batch 02840/03080] [00:35:24/00:02:59, 0.748s/it]: train_loss_raw=1.9509, running_loss=2.0147, LR=0.000100
[2025-08-26 20:49:13,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=2.0260, running_loss=2.0167, LR=0.000100
[2025-08-26 20:49:19,660][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005936] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=1.9843, running_loss=2.0169, LR=0.000100
[2025-08-26 20:49:25,609][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005944] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=2.0209, running_loss=2.0179, LR=0.000100
[2025-08-26 20:49:31,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 02872/03080] [00:35:48/00:02:35, 0.748s/it]: train_loss_raw=1.9420, running_loss=2.0171, LR=0.000100
[2025-08-26 20:49:37,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005960] [Batch 02880/03080] [00:35:54/00:02:29, 0.748s/it]: train_loss_raw=1.9759, running_loss=2.0135, LR=0.000100
[2025-08-26 20:49:43,528][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005968] [Batch 02888/03080] [00:36:00/00:02:23, 0.748s/it]: train_loss_raw=1.9527, running_loss=2.0124, LR=0.000100
[2025-08-26 20:49:49,426][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 02896/03080] [00:36:06/00:02:17, 0.748s/it]: train_loss_raw=2.0070, running_loss=2.0124, LR=0.000100
[2025-08-26 20:49:55,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005984] [Batch 02904/03080] [00:36:12/00:02:11, 0.748s/it]: train_loss_raw=2.0151, running_loss=2.0126, LR=0.000100
[2025-08-26 20:50:01,264][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005992] [Batch 02912/03080] [00:36:18/00:02:05, 0.748s/it]: train_loss_raw=2.0649, running_loss=2.0136, LR=0.000100
[2025-08-26 20:50:07,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 02920/03080] [00:36:24/00:01:59, 0.748s/it]: train_loss_raw=1.9954, running_loss=2.0120, LR=0.000100
[2025-08-26 20:50:17,721][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006008] [Batch 02928/03080] [00:36:34/00:01:53, 0.750s/it]: train_loss_raw=2.0138, running_loss=2.0111, LR=0.000100
[2025-08-26 20:50:23,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006016] [Batch 02936/03080] [00:36:40/00:01:47, 0.750s/it]: train_loss_raw=2.0053, running_loss=2.0089, LR=0.000100
[2025-08-26 20:50:29,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 02944/03080] [00:36:46/00:01:41, 0.750s/it]: train_loss_raw=1.9973, running_loss=2.0097, LR=0.000100
[2025-08-26 20:50:35,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006032] [Batch 02952/03080] [00:36:52/00:01:35, 0.750s/it]: train_loss_raw=2.0289, running_loss=2.0129, LR=0.000100
[2025-08-26 20:50:41,625][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006040] [Batch 02960/03080] [00:36:58/00:01:29, 0.750s/it]: train_loss_raw=1.9652, running_loss=2.0109, LR=0.000100
[2025-08-26 20:50:47,637][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 02968/03080] [00:37:04/00:01:23, 0.750s/it]: train_loss_raw=2.0265, running_loss=2.0127, LR=0.000100
[2025-08-26 20:50:53,589][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006056] [Batch 02976/03080] [00:37:10/00:01:17, 0.750s/it]: train_loss_raw=2.0357, running_loss=2.0121, LR=0.000100
[2025-08-26 20:50:59,567][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006064] [Batch 02984/03080] [00:37:16/00:01:11, 0.750s/it]: train_loss_raw=2.0773, running_loss=2.0121, LR=0.000100
[2025-08-26 20:51:05,562][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 02992/03080] [00:37:22/00:01:05, 0.750s/it]: train_loss_raw=2.0131, running_loss=2.0122, LR=0.000100
[2025-08-26 20:51:11,570][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006080] [Batch 03000/03080] [00:37:28/00:00:59, 0.750s/it]: train_loss_raw=2.0558, running_loss=2.0122, LR=0.000100
[2025-08-26 20:51:17,514][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006088] [Batch 03008/03080] [00:37:34/00:00:53, 0.750s/it]: train_loss_raw=2.0725, running_loss=2.0113, LR=0.000100
[2025-08-26 20:51:23,473][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 03016/03080] [00:37:40/00:00:47, 0.750s/it]: train_loss_raw=1.9474, running_loss=2.0083, LR=0.000100
[2025-08-26 20:51:29,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006104] [Batch 03024/03080] [00:37:46/00:00:41, 0.750s/it]: train_loss_raw=1.9974, running_loss=2.0093, LR=0.000100
[2025-08-26 20:51:35,433][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006112] [Batch 03032/03080] [00:37:52/00:00:35, 0.750s/it]: train_loss_raw=1.9712, running_loss=2.0067, LR=0.000100
[2025-08-26 20:51:41,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 03040/03080] [00:37:58/00:00:29, 0.749s/it]: train_loss_raw=2.1446, running_loss=2.0078, LR=0.000100
[2025-08-26 20:51:47,328][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006128] [Batch 03048/03080] [00:38:04/00:00:23, 0.749s/it]: train_loss_raw=1.8654, running_loss=2.0058, LR=0.000100
[2025-08-26 20:51:53,328][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006136] [Batch 03056/03080] [00:38:10/00:00:17, 0.749s/it]: train_loss_raw=2.0258, running_loss=2.0051, LR=0.000100
[2025-08-26 20:51:59,282][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 03064/03080] [00:38:16/00:00:11, 0.749s/it]: train_loss_raw=2.0289, running_loss=2.0044, LR=0.000100
[2025-08-26 20:52:05,238][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006152] [Batch 03072/03080] [00:38:22/00:00:05, 0.749s/it]: train_loss_raw=1.9152, running_loss=2.0007, LR=0.000100
[2025-08-26 20:52:15,883][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006160] [Batch 03080/03080] [00:38:32/00:00:00, 0.751s/it]: train_loss_raw=2.0336, running_loss=1.9997, LR=0.000100
[2025-08-26 20:52:16,403][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-26 20:52:27,844][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00007/00310] [00:00:11/00:07:11, 1.430s/it]
[2025-08-26 20:52:40,268][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00015/00310] [00:00:23/00:07:18, 1.492s/it]
[2025-08-26 20:52:52,919][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00023/00310] [00:00:36/00:07:15, 1.521s/it]
[2025-08-26 20:53:06,112][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00031/00310] [00:00:49/00:07:11, 1.553s/it]
[2025-08-26 20:53:19,290][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00039/00310] [00:01:02/00:07:04, 1.572s/it]
[2025-08-26 20:53:32,477][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00047/00310] [00:01:16/00:06:55, 1.585s/it]
[2025-08-26 20:53:45,489][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00055/00310] [00:01:29/00:06:44, 1.591s/it]
[2025-08-26 20:53:58,569][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00063/00310] [00:01:42/00:06:32, 1.596s/it]
[2025-08-26 20:54:11,637][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00071/00310] [00:01:55/00:06:20, 1.600s/it]
[2025-08-26 20:54:24,813][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00079/00310] [00:02:08/00:06:09, 1.605s/it]
[2025-08-26 20:54:37,820][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00087/00310] [00:02:21/00:05:56, 1.607s/it]
[2025-08-26 20:54:51,071][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00095/00310] [00:02:34/00:05:44, 1.611s/it]
[2025-08-26 20:55:04,199][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00103/00310] [00:02:47/00:05:32, 1.613s/it]
[2025-08-26 20:55:17,193][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00111/00310] [00:03:00/00:05:19, 1.614s/it]
[2025-08-26 20:55:29,946][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00119/00310] [00:03:13/00:05:06, 1.613s/it]
[2025-08-26 20:55:42,809][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00127/00310] [00:03:26/00:04:53, 1.613s/it]
[2025-08-26 20:55:55,569][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00135/00310] [00:03:39/00:04:40, 1.612s/it]
[2025-08-26 20:56:08,395][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00143/00310] [00:03:51/00:04:27, 1.611s/it]
[2025-08-26 20:56:20,616][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00151/00310] [00:04:04/00:04:13, 1.607s/it]
[2025-08-26 20:56:32,592][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00159/00310] [00:04:16/00:04:00, 1.601s/it]
[2025-08-26 20:56:45,317][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00167/00310] [00:04:28/00:03:47, 1.601s/it]
[2025-08-26 20:56:57,507][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00175/00310] [00:04:41/00:03:34, 1.597s/it]
[2025-08-26 20:57:09,616][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00183/00310] [00:04:53/00:03:20, 1.594s/it]
[2025-08-26 20:57:22,254][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00191/00310] [00:05:05/00:03:07, 1.593s/it]
[2025-08-26 20:57:34,615][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00199/00310] [00:05:18/00:02:55, 1.591s/it]
[2025-08-26 20:57:46,804][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00207/00310] [00:05:30/00:02:42, 1.588s/it]
[2025-08-26 20:57:58,974][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00215/00310] [00:05:42/00:02:29, 1.586s/it]
[2025-08-26 20:58:11,434][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00223/00310] [00:05:55/00:02:16, 1.585s/it]
[2025-08-26 20:58:24,037][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00231/00310] [00:06:07/00:02:03, 1.585s/it]
[2025-08-26 20:58:36,226][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00239/00310] [00:06:19/00:01:50, 1.583s/it]
[2025-08-26 20:58:48,414][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00247/00310] [00:06:32/00:01:38, 1.581s/it]
[2025-08-26 20:59:00,865][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00255/00310] [00:06:44/00:01:25, 1.580s/it]
[2025-08-26 20:59:13,647][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00263/00310] [00:06:57/00:01:12, 1.580s/it]
[2025-08-26 20:59:25,912][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00271/00310] [00:07:09/00:01:00, 1.579s/it]
[2025-08-26 20:59:38,398][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00279/00310] [00:07:21/00:00:47, 1.579s/it]
[2025-08-26 20:59:51,079][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00287/00310] [00:07:34/00:00:34, 1.579s/it]
[2025-08-26 21:00:03,341][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00295/00310] [00:07:46/00:00:22, 1.577s/it]
[2025-08-26 21:00:16,001][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 006161] [Batch 00303/00310] [00:07:59/00:00:09, 1.578s/it]
[2025-08-26 21:00:25,614][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=1.99972, valid_loss=2.52483
[2025-08-26 21:00:25,614][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-26 21:00:25,615][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.927
[2025-08-26 21:00:25,615][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.010
[2025-08-26 21:00:25,615][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.010
[2025-08-26 21:00:25,615][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-26 21:00:25,630][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:33:39, remaining time 21:51:13, 00:46:49 per epoch
[2025-08-26 21:00:32,185][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006168] [Batch 00008/03080] [00:00:05/00:34:23, 0.672s/it]: train_loss_raw=1.9171, running_loss=1.9912, LR=0.000100
[2025-08-26 21:00:38,122][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006176] [Batch 00016/03080] [00:00:11/00:36:06, 0.707s/it]: train_loss_raw=2.0060, running_loss=1.9931, LR=0.000100
[2025-08-26 21:00:44,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006184] [Batch 00024/03080] [00:00:17/00:36:38, 0.719s/it]: train_loss_raw=1.9837, running_loss=1.9935, LR=0.000100
[2025-08-26 21:00:50,078][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006192] [Batch 00032/03080] [00:00:23/00:36:56, 0.727s/it]: train_loss_raw=1.9941, running_loss=1.9939, LR=0.000100
[2025-08-26 21:00:56,025][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006200] [Batch 00040/03080] [00:00:29/00:37:00, 0.730s/it]: train_loss_raw=2.0193, running_loss=1.9931, LR=0.000100
[2025-08-26 21:01:01,985][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006208] [Batch 00048/03080] [00:00:35/00:37:01, 0.733s/it]: train_loss_raw=1.9596, running_loss=1.9912, LR=0.000100
[2025-08-26 21:01:07,847][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006216] [Batch 00056/03080] [00:00:41/00:36:55, 0.733s/it]: train_loss_raw=1.9889, running_loss=1.9911, LR=0.000100
[2025-08-26 21:01:13,784][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006224] [Batch 00064/03080] [00:00:46/00:36:53, 0.734s/it]: train_loss_raw=2.0678, running_loss=1.9940, LR=0.000100
[2025-08-26 21:01:19,773][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006232] [Batch 00072/03080] [00:00:52/00:36:52, 0.736s/it]: train_loss_raw=1.9430, running_loss=1.9929, LR=0.000100
[2025-08-26 21:01:25,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006240] [Batch 00080/03080] [00:00:58/00:36:48, 0.736s/it]: train_loss_raw=2.0444, running_loss=1.9931, LR=0.000100
[2025-08-26 21:01:31,682][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006248] [Batch 00088/03080] [00:01:04/00:36:45, 0.737s/it]: train_loss_raw=2.1105, running_loss=1.9950, LR=0.000100
[2025-08-26 21:01:37,600][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006256] [Batch 00096/03080] [00:01:10/00:36:40, 0.737s/it]: train_loss_raw=2.0693, running_loss=1.9950, LR=0.000100
[2025-08-26 21:01:43,579][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006264] [Batch 00104/03080] [00:01:16/00:36:36, 0.738s/it]: train_loss_raw=1.9852, running_loss=1.9959, LR=0.000100
[2025-08-26 21:01:49,554][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006272] [Batch 00112/03080] [00:01:22/00:36:32, 0.739s/it]: train_loss_raw=2.0269, running_loss=1.9957, LR=0.000100
[2025-08-26 21:01:55,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006280] [Batch 00120/03080] [00:01:28/00:36:31, 0.740s/it]: train_loss_raw=1.9814, running_loss=1.9932, LR=0.000100
[2025-08-26 21:02:01,580][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006288] [Batch 00128/03080] [00:01:34/00:36:25, 0.740s/it]: train_loss_raw=1.9190, running_loss=1.9900, LR=0.000100
[2025-08-26 21:02:07,506][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006296] [Batch 00136/03080] [00:01:40/00:36:19, 0.740s/it]: train_loss_raw=1.9161, running_loss=1.9866, LR=0.000100
[2025-08-26 21:02:13,423][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006304] [Batch 00144/03080] [00:01:46/00:36:13, 0.740s/it]: train_loss_raw=2.0290, running_loss=1.9865, LR=0.000100
[2025-08-26 21:02:19,333][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006312] [Batch 00152/03080] [00:01:52/00:36:07, 0.740s/it]: train_loss_raw=1.9960, running_loss=1.9867, LR=0.000100
[2025-08-26 21:02:25,383][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006320] [Batch 00160/03080] [00:01:58/00:36:03, 0.741s/it]: train_loss_raw=2.0119, running_loss=1.9879, LR=0.000100
[2025-08-26 21:02:31,331][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006328] [Batch 00168/03080] [00:02:04/00:35:58, 0.741s/it]: train_loss_raw=1.9999, running_loss=1.9850, LR=0.000100
[2025-08-26 21:02:37,348][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006336] [Batch 00176/03080] [00:02:10/00:35:53, 0.742s/it]: train_loss_raw=1.9755, running_loss=1.9857, LR=0.000100
[2025-08-26 21:02:43,359][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006344] [Batch 00184/03080] [00:02:16/00:35:49, 0.742s/it]: train_loss_raw=1.8612, running_loss=1.9857, LR=0.000100
[2025-08-26 21:02:49,300][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006352] [Batch 00192/03080] [00:02:22/00:35:43, 0.742s/it]: train_loss_raw=2.0453, running_loss=1.9888, LR=0.000100
[2025-08-26 21:02:55,302][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006360] [Batch 00200/03080] [00:02:28/00:35:38, 0.742s/it]: train_loss_raw=1.9569, running_loss=1.9890, LR=0.000100
[2025-08-26 21:03:01,332][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006368] [Batch 00208/03080] [00:02:34/00:35:33, 0.743s/it]: train_loss_raw=1.9494, running_loss=1.9879, LR=0.000100
[2025-08-26 21:03:07,311][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006376] [Batch 00216/03080] [00:02:40/00:35:28, 0.743s/it]: train_loss_raw=1.9373, running_loss=1.9881, LR=0.000100
[2025-08-26 21:03:13,298][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006384] [Batch 00224/03080] [00:02:46/00:35:22, 0.743s/it]: train_loss_raw=2.0684, running_loss=1.9893, LR=0.000100
[2025-08-26 21:03:19,309][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006392] [Batch 00232/03080] [00:02:52/00:35:17, 0.744s/it]: train_loss_raw=1.9916, running_loss=1.9893, LR=0.000100
[2025-08-26 21:03:25,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006400] [Batch 00240/03080] [00:02:58/00:35:12, 0.744s/it]: train_loss_raw=1.9197, running_loss=1.9892, LR=0.000100
[2025-08-26 21:03:31,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006408] [Batch 00248/03080] [00:03:04/00:35:06, 0.744s/it]: train_loss_raw=2.0452, running_loss=1.9903, LR=0.000100
[2025-08-26 21:03:37,287][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006416] [Batch 00256/03080] [00:03:10/00:35:01, 0.744s/it]: train_loss_raw=1.9748, running_loss=1.9904, LR=0.000100
[2025-08-26 21:03:43,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006424] [Batch 00264/03080] [00:03:16/00:34:56, 0.744s/it]: train_loss_raw=2.0520, running_loss=1.9903, LR=0.000100
[2025-08-26 21:03:49,346][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006432] [Batch 00272/03080] [00:03:22/00:34:50, 0.745s/it]: train_loss_raw=1.9479, running_loss=1.9878, LR=0.000100
[2025-08-26 21:03:55,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006440] [Batch 00280/03080] [00:03:28/00:34:44, 0.745s/it]: train_loss_raw=1.9051, running_loss=1.9870, LR=0.000100
[2025-08-26 21:04:01,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006448] [Batch 00288/03080] [00:03:34/00:34:39, 0.745s/it]: train_loss_raw=1.9114, running_loss=1.9855, LR=0.000100
[2025-08-26 21:04:07,331][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006456] [Batch 00296/03080] [00:03:40/00:34:34, 0.745s/it]: train_loss_raw=2.0050, running_loss=1.9832, LR=0.000100
[2025-08-26 21:04:13,340][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006464] [Batch 00304/03080] [00:03:46/00:34:28, 0.745s/it]: train_loss_raw=1.9918, running_loss=1.9833, LR=0.000100
[2025-08-26 21:04:19,302][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006472] [Batch 00312/03080] [00:03:52/00:34:22, 0.745s/it]: train_loss_raw=1.8612, running_loss=1.9820, LR=0.000100
[2025-08-26 21:04:25,334][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006480] [Batch 00320/03080] [00:03:58/00:34:17, 0.745s/it]: train_loss_raw=1.9462, running_loss=1.9812, LR=0.000100
[2025-08-26 21:04:31,239][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006488] [Batch 00328/03080] [00:04:04/00:34:10, 0.745s/it]: train_loss_raw=2.0794, running_loss=1.9818, LR=0.000100
[2025-08-26 21:04:37,218][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006496] [Batch 00336/03080] [00:04:10/00:34:04, 0.745s/it]: train_loss_raw=1.9234, running_loss=1.9811, LR=0.000100
[2025-08-26 21:04:43,167][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006504] [Batch 00344/03080] [00:04:16/00:33:58, 0.745s/it]: train_loss_raw=1.8873, running_loss=1.9798, LR=0.000100
[2025-08-26 21:04:49,092][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006512] [Batch 00352/03080] [00:04:22/00:33:52, 0.745s/it]: train_loss_raw=1.9444, running_loss=1.9805, LR=0.000100
[2025-08-26 21:04:55,175][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006520] [Batch 00360/03080] [00:04:28/00:33:47, 0.745s/it]: train_loss_raw=1.9534, running_loss=1.9767, LR=0.000100
[2025-08-26 21:05:01,080][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006528] [Batch 00368/03080] [00:04:34/00:33:41, 0.745s/it]: train_loss_raw=1.9954, running_loss=1.9810, LR=0.000100
[2025-08-26 21:05:07,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006536] [Batch 00376/03080] [00:04:40/00:33:36, 0.746s/it]: train_loss_raw=1.9939, running_loss=1.9796, LR=0.000100
[2025-08-26 21:05:13,029][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006544] [Batch 00384/03080] [00:04:46/00:33:29, 0.745s/it]: train_loss_raw=2.0365, running_loss=1.9828, LR=0.000100
[2025-08-26 21:05:18,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006552] [Batch 00392/03080] [00:04:52/00:33:22, 0.745s/it]: train_loss_raw=2.0568, running_loss=1.9811, LR=0.000100
[2025-08-26 21:05:24,728][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006560] [Batch 00400/03080] [00:04:57/00:33:16, 0.745s/it]: train_loss_raw=1.9200, running_loss=1.9800, LR=0.000100
[2025-08-26 21:05:30,773][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006568] [Batch 00408/03080] [00:05:03/00:33:10, 0.745s/it]: train_loss_raw=1.8963, running_loss=1.9799, LR=0.000100
[2025-08-26 21:05:36,746][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006576] [Batch 00416/03080] [00:05:09/00:33:04, 0.745s/it]: train_loss_raw=2.0014, running_loss=1.9820, LR=0.000100
[2025-08-26 21:05:42,724][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006584] [Batch 00424/03080] [00:05:15/00:32:58, 0.745s/it]: train_loss_raw=2.0015, running_loss=1.9818, LR=0.000100
[2025-08-26 21:05:48,595][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006592] [Batch 00432/03080] [00:05:21/00:32:52, 0.745s/it]: train_loss_raw=1.9518, running_loss=1.9827, LR=0.000100
[2025-08-26 21:05:54,675][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006600] [Batch 00440/03080] [00:05:27/00:32:47, 0.745s/it]: train_loss_raw=1.9960, running_loss=1.9817, LR=0.000100
[2025-08-26 21:06:00,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006608] [Batch 00448/03080] [00:05:33/00:32:41, 0.745s/it]: train_loss_raw=1.9495, running_loss=1.9790, LR=0.000100
[2025-08-26 21:06:06,653][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006616] [Batch 00456/03080] [00:05:39/00:32:35, 0.745s/it]: train_loss_raw=1.8836, running_loss=1.9793, LR=0.000100
[2025-08-26 21:06:12,665][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006624] [Batch 00464/03080] [00:05:45/00:32:29, 0.745s/it]: train_loss_raw=1.9484, running_loss=1.9775, LR=0.000100
[2025-08-26 21:06:18,550][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006632] [Batch 00472/03080] [00:05:51/00:32:23, 0.745s/it]: train_loss_raw=1.9845, running_loss=1.9776, LR=0.000100
[2025-08-26 21:06:24,592][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006640] [Batch 00480/03080] [00:05:57/00:32:17, 0.745s/it]: train_loss_raw=1.9575, running_loss=1.9760, LR=0.000100
[2025-08-26 21:06:30,615][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006648] [Batch 00488/03080] [00:06:03/00:32:12, 0.746s/it]: train_loss_raw=1.8769, running_loss=1.9740, LR=0.000100
[2025-08-26 21:06:36,584][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006656] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=1.9921, running_loss=1.9740, LR=0.000100
[2025-08-26 21:06:42,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006664] [Batch 00504/03080] [00:06:15/00:32:00, 0.745s/it]: train_loss_raw=1.9706, running_loss=1.9725, LR=0.000100
[2025-08-26 21:06:48,540][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006672] [Batch 00512/03080] [00:06:21/00:31:54, 0.746s/it]: train_loss_raw=1.9690, running_loss=1.9686, LR=0.000100
[2025-08-26 21:06:54,565][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006680] [Batch 00520/03080] [00:06:27/00:31:48, 0.746s/it]: train_loss_raw=1.9479, running_loss=1.9676, LR=0.000100
[2025-08-26 21:07:00,519][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006688] [Batch 00528/03080] [00:06:33/00:31:42, 0.746s/it]: train_loss_raw=1.9135, running_loss=1.9691, LR=0.000100
[2025-08-26 21:07:06,507][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006696] [Batch 00536/03080] [00:06:39/00:31:37, 0.746s/it]: train_loss_raw=1.9568, running_loss=1.9684, LR=0.000100
[2025-08-26 21:07:12,518][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006704] [Batch 00544/03080] [00:06:45/00:31:31, 0.746s/it]: train_loss_raw=1.9906, running_loss=1.9701, LR=0.000100
[2025-08-26 21:07:18,480][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006712] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=1.9911, running_loss=1.9687, LR=0.000100
[2025-08-26 21:07:24,596][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006720] [Batch 00560/03080] [00:06:57/00:31:20, 0.746s/it]: train_loss_raw=1.9739, running_loss=1.9685, LR=0.000100
[2025-08-26 21:07:30,585][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006728] [Batch 00568/03080] [00:07:03/00:31:14, 0.746s/it]: train_loss_raw=1.9304, running_loss=1.9671, LR=0.000100
[2025-08-26 21:07:36,559][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006736] [Batch 00576/03080] [00:07:09/00:31:08, 0.746s/it]: train_loss_raw=1.9892, running_loss=1.9688, LR=0.000100
[2025-08-26 21:07:42,513][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006744] [Batch 00584/03080] [00:07:15/00:31:02, 0.746s/it]: train_loss_raw=1.8296, running_loss=1.9671, LR=0.000100
[2025-08-26 21:07:48,487][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006752] [Batch 00592/03080] [00:07:21/00:30:56, 0.746s/it]: train_loss_raw=1.8540, running_loss=1.9632, LR=0.000100
[2025-08-26 21:07:54,483][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006760] [Batch 00600/03080] [00:07:27/00:30:50, 0.746s/it]: train_loss_raw=2.0365, running_loss=1.9644, LR=0.000100
[2025-08-26 21:08:00,459][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006768] [Batch 00608/03080] [00:07:33/00:30:44, 0.746s/it]: train_loss_raw=1.9577, running_loss=1.9648, LR=0.000100
[2025-08-26 21:08:06,447][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006776] [Batch 00616/03080] [00:07:39/00:30:38, 0.746s/it]: train_loss_raw=1.9074, running_loss=1.9641, LR=0.000100
[2025-08-26 21:08:12,411][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006784] [Batch 00624/03080] [00:07:45/00:30:32, 0.746s/it]: train_loss_raw=1.9689, running_loss=1.9635, LR=0.000100
[2025-08-26 21:08:18,498][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006792] [Batch 00632/03080] [00:07:51/00:30:27, 0.746s/it]: train_loss_raw=1.9662, running_loss=1.9626, LR=0.000100
[2025-08-26 21:08:24,416][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006800] [Batch 00640/03080] [00:07:57/00:30:20, 0.746s/it]: train_loss_raw=1.9642, running_loss=1.9635, LR=0.000100
[2025-08-26 21:08:30,398][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006808] [Batch 00648/03080] [00:08:03/00:30:14, 0.746s/it]: train_loss_raw=1.9558, running_loss=1.9623, LR=0.000100
[2025-08-26 21:08:36,348][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006816] [Batch 00656/03080] [00:08:09/00:30:08, 0.746s/it]: train_loss_raw=2.0393, running_loss=1.9607, LR=0.000100
[2025-08-26 21:08:42,294][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006824] [Batch 00664/03080] [00:08:15/00:30:02, 0.746s/it]: train_loss_raw=1.9655, running_loss=1.9624, LR=0.000100
[2025-08-26 21:08:48,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006832] [Batch 00672/03080] [00:08:21/00:29:56, 0.746s/it]: train_loss_raw=1.9579, running_loss=1.9621, LR=0.000100
[2025-08-26 21:08:54,201][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006840] [Batch 00680/03080] [00:08:27/00:29:50, 0.746s/it]: train_loss_raw=2.0548, running_loss=1.9630, LR=0.000100
[2025-08-26 21:09:00,186][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006848] [Batch 00688/03080] [00:08:33/00:29:44, 0.746s/it]: train_loss_raw=1.9843, running_loss=1.9628, LR=0.000100
[2025-08-26 21:09:05,981][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006856] [Batch 00696/03080] [00:08:39/00:29:38, 0.746s/it]: train_loss_raw=2.0587, running_loss=1.9639, LR=0.000100
[2025-08-26 21:09:11,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006864] [Batch 00704/03080] [00:08:45/00:29:32, 0.746s/it]: train_loss_raw=1.9521, running_loss=1.9633, LR=0.000100
[2025-08-26 21:09:17,949][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006872] [Batch 00712/03080] [00:08:51/00:29:26, 0.746s/it]: train_loss_raw=2.0041, running_loss=1.9641, LR=0.000100
[2025-08-26 21:09:23,925][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006880] [Batch 00720/03080] [00:08:57/00:29:20, 0.746s/it]: train_loss_raw=2.0291, running_loss=1.9630, LR=0.000100
[2025-08-26 21:09:30,063][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006888] [Batch 00728/03080] [00:09:03/00:29:15, 0.746s/it]: train_loss_raw=1.9445, running_loss=1.9637, LR=0.000100
[2025-08-26 21:09:36,105][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006896] [Batch 00736/03080] [00:09:09/00:29:09, 0.746s/it]: train_loss_raw=1.8789, running_loss=1.9640, LR=0.000100
[2025-08-26 21:09:42,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006904] [Batch 00744/03080] [00:09:15/00:29:03, 0.746s/it]: train_loss_raw=1.9941, running_loss=1.9607, LR=0.000100
[2025-08-26 21:09:47,968][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006912] [Batch 00752/03080] [00:09:21/00:28:57, 0.746s/it]: train_loss_raw=1.9063, running_loss=1.9576, LR=0.000100
[2025-08-26 21:09:53,960][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006920] [Batch 00760/03080] [00:09:27/00:28:51, 0.746s/it]: train_loss_raw=1.9856, running_loss=1.9570, LR=0.000100
[2025-08-26 21:09:59,922][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006928] [Batch 00768/03080] [00:09:33/00:28:45, 0.746s/it]: train_loss_raw=1.9677, running_loss=1.9555, LR=0.000100
[2025-08-26 21:10:05,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006936] [Batch 00776/03080] [00:09:39/00:28:39, 0.746s/it]: train_loss_raw=1.9355, running_loss=1.9558, LR=0.000100
[2025-08-26 21:10:11,824][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006944] [Batch 00784/03080] [00:09:45/00:28:33, 0.746s/it]: train_loss_raw=1.9056, running_loss=1.9553, LR=0.000100
[2025-08-26 21:10:17,840][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006952] [Batch 00792/03080] [00:09:51/00:28:27, 0.746s/it]: train_loss_raw=2.0291, running_loss=1.9554, LR=0.000100
[2025-08-26 21:10:23,775][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006960] [Batch 00800/03080] [00:09:56/00:28:21, 0.746s/it]: train_loss_raw=1.9013, running_loss=1.9546, LR=0.000100
[2025-08-26 21:10:29,669][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006968] [Batch 00808/03080] [00:10:02/00:28:15, 0.746s/it]: train_loss_raw=1.9691, running_loss=1.9516, LR=0.000100
[2025-08-26 21:10:35,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006976] [Batch 00816/03080] [00:10:08/00:28:09, 0.746s/it]: train_loss_raw=1.9784, running_loss=1.9497, LR=0.000100
[2025-08-26 21:10:41,551][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006984] [Batch 00824/03080] [00:10:14/00:28:03, 0.746s/it]: train_loss_raw=1.9044, running_loss=1.9489, LR=0.000100
[2025-08-26 21:10:47,394][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 006992] [Batch 00832/03080] [00:10:20/00:27:56, 0.746s/it]: train_loss_raw=1.9116, running_loss=1.9465, LR=0.000100
[2025-08-26 21:10:53,306][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007000] [Batch 00840/03080] [00:10:26/00:27:50, 0.746s/it]: train_loss_raw=2.0290, running_loss=1.9484, LR=0.000100
[2025-08-26 21:10:59,220][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007008] [Batch 00848/03080] [00:10:32/00:27:44, 0.746s/it]: train_loss_raw=1.9708, running_loss=1.9497, LR=0.000100
[2025-08-26 21:11:05,149][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007016] [Batch 00856/03080] [00:10:38/00:27:38, 0.746s/it]: train_loss_raw=1.9454, running_loss=1.9506, LR=0.000100
[2025-08-26 21:11:11,057][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007024] [Batch 00864/03080] [00:10:44/00:27:32, 0.746s/it]: train_loss_raw=1.9091, running_loss=1.9516, LR=0.000100
[2025-08-26 21:11:16,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007032] [Batch 00872/03080] [00:10:50/00:27:26, 0.746s/it]: train_loss_raw=1.9317, running_loss=1.9504, LR=0.000100
[2025-08-26 21:11:22,801][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007040] [Batch 00880/03080] [00:10:55/00:27:19, 0.745s/it]: train_loss_raw=1.9859, running_loss=1.9509, LR=0.000100
[2025-08-26 21:11:28,583][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007048] [Batch 00888/03080] [00:11:01/00:27:13, 0.745s/it]: train_loss_raw=1.8615, running_loss=1.9506, LR=0.000100
[2025-08-26 21:11:34,555][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007056] [Batch 00896/03080] [00:11:07/00:27:07, 0.745s/it]: train_loss_raw=1.9337, running_loss=1.9497, LR=0.000100
[2025-08-26 21:11:40,501][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007064] [Batch 00904/03080] [00:11:13/00:27:01, 0.745s/it]: train_loss_raw=2.0141, running_loss=1.9507, LR=0.000100
[2025-08-26 21:11:46,461][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007072] [Batch 00912/03080] [00:11:19/00:26:55, 0.745s/it]: train_loss_raw=1.9723, running_loss=1.9489, LR=0.000100
[2025-08-26 21:11:52,400][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007080] [Batch 00920/03080] [00:11:25/00:26:49, 0.745s/it]: train_loss_raw=1.9349, running_loss=1.9475, LR=0.000100
[2025-08-26 21:11:58,371][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007088] [Batch 00928/03080] [00:11:31/00:26:43, 0.745s/it]: train_loss_raw=1.9690, running_loss=1.9477, LR=0.000100
[2025-08-26 21:12:04,354][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007096] [Batch 00936/03080] [00:11:37/00:26:37, 0.745s/it]: train_loss_raw=1.9413, running_loss=1.9461, LR=0.000100
[2025-08-26 21:12:10,214][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007104] [Batch 00944/03080] [00:11:43/00:26:31, 0.745s/it]: train_loss_raw=1.9297, running_loss=1.9459, LR=0.000100
[2025-08-26 21:12:16,415][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007112] [Batch 00952/03080] [00:11:49/00:26:26, 0.745s/it]: train_loss_raw=2.0342, running_loss=1.9467, LR=0.000100
[2025-08-26 21:12:22,486][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007120] [Batch 00960/03080] [00:11:55/00:26:20, 0.745s/it]: train_loss_raw=1.9575, running_loss=1.9445, LR=0.000100
[2025-08-26 21:12:28,495][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007128] [Batch 00968/03080] [00:12:01/00:26:14, 0.746s/it]: train_loss_raw=1.9558, running_loss=1.9416, LR=0.000100
[2025-08-26 21:12:34,885][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007136] [Batch 00976/03080] [00:12:08/00:26:09, 0.746s/it]: train_loss_raw=1.9518, running_loss=1.9404, LR=0.000100
[2025-08-26 21:12:41,108][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007144] [Batch 00984/03080] [00:12:14/00:26:04, 0.746s/it]: train_loss_raw=1.9214, running_loss=1.9390, LR=0.000100
[2025-08-26 21:12:47,328][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007152] [Batch 00992/03080] [00:12:20/00:25:58, 0.746s/it]: train_loss_raw=1.8474, running_loss=1.9396, LR=0.000100
[2025-08-26 21:12:53,559][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007160] [Batch 01000/03080] [00:12:26/00:25:53, 0.747s/it]: train_loss_raw=1.9368, running_loss=1.9397, LR=0.000100
[2025-08-26 21:12:59,941][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007168] [Batch 01008/03080] [00:12:33/00:25:48, 0.747s/it]: train_loss_raw=1.9005, running_loss=1.9379, LR=0.000100
[2025-08-26 21:13:06,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007176] [Batch 01016/03080] [00:12:39/00:25:42, 0.747s/it]: train_loss_raw=1.8888, running_loss=1.9367, LR=0.000100
[2025-08-26 21:13:12,500][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007184] [Batch 01024/03080] [00:12:45/00:25:37, 0.748s/it]: train_loss_raw=2.0631, running_loss=1.9381, LR=0.000100
[2025-08-26 21:13:18,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007192] [Batch 01032/03080] [00:12:51/00:25:31, 0.748s/it]: train_loss_raw=1.8406, running_loss=1.9370, LR=0.000100
[2025-08-26 21:13:24,435][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007200] [Batch 01040/03080] [00:12:57/00:25:25, 0.748s/it]: train_loss_raw=1.9098, running_loss=1.9378, LR=0.000100
[2025-08-26 21:13:30,461][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007208] [Batch 01048/03080] [00:13:03/00:25:19, 0.748s/it]: train_loss_raw=1.9190, running_loss=1.9361, LR=0.000100
[2025-08-26 21:13:36,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007216] [Batch 01056/03080] [00:13:09/00:25:14, 0.748s/it]: train_loss_raw=1.9341, running_loss=1.9335, LR=0.000100
[2025-08-26 21:13:42,758][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007224] [Batch 01064/03080] [00:13:15/00:25:08, 0.748s/it]: train_loss_raw=1.9344, running_loss=1.9366, LR=0.000100
[2025-08-26 21:13:49,029][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007232] [Batch 01072/03080] [00:13:22/00:25:02, 0.748s/it]: train_loss_raw=1.8703, running_loss=1.9371, LR=0.000100
[2025-08-26 21:13:55,266][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007240] [Batch 01080/03080] [00:13:28/00:24:57, 0.749s/it]: train_loss_raw=1.9066, running_loss=1.9364, LR=0.000100
[2025-08-26 21:14:01,672][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007248] [Batch 01088/03080] [00:13:34/00:24:51, 0.749s/it]: train_loss_raw=2.0100, running_loss=1.9384, LR=0.000100
[2025-08-26 21:14:07,854][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007256] [Batch 01096/03080] [00:13:41/00:24:46, 0.749s/it]: train_loss_raw=1.9810, running_loss=1.9370, LR=0.000100
[2025-08-26 21:14:14,009][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007264] [Batch 01104/03080] [00:13:47/00:24:40, 0.749s/it]: train_loss_raw=1.8234, running_loss=1.9341, LR=0.000100
[2025-08-26 21:14:19,998][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007272] [Batch 01112/03080] [00:13:53/00:24:34, 0.749s/it]: train_loss_raw=2.0224, running_loss=1.9338, LR=0.000100
[2025-08-26 21:14:26,208][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007280] [Batch 01120/03080] [00:13:59/00:24:28, 0.749s/it]: train_loss_raw=1.9658, running_loss=1.9358, LR=0.000100
[2025-08-26 21:14:32,094][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007288] [Batch 01128/03080] [00:14:05/00:24:22, 0.749s/it]: train_loss_raw=1.9853, running_loss=1.9338, LR=0.000100
[2025-08-26 21:14:38,047][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007296] [Batch 01136/03080] [00:14:11/00:24:16, 0.749s/it]: train_loss_raw=2.0235, running_loss=1.9352, LR=0.000100
[2025-08-26 21:14:43,954][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007304] [Batch 01144/03080] [00:14:17/00:24:10, 0.749s/it]: train_loss_raw=1.8757, running_loss=1.9332, LR=0.000100
[2025-08-26 21:14:49,881][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007312] [Batch 01152/03080] [00:14:23/00:24:04, 0.749s/it]: train_loss_raw=1.9895, running_loss=1.9339, LR=0.000100
[2025-08-26 21:14:55,761][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007320] [Batch 01160/03080] [00:14:28/00:23:58, 0.749s/it]: train_loss_raw=1.9664, running_loss=1.9350, LR=0.000100
[2025-08-26 21:15:01,664][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007328] [Batch 01168/03080] [00:14:34/00:23:52, 0.749s/it]: train_loss_raw=1.8389, running_loss=1.9320, LR=0.000100
[2025-08-26 21:15:07,599][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007336] [Batch 01176/03080] [00:14:40/00:23:46, 0.749s/it]: train_loss_raw=1.9600, running_loss=1.9316, LR=0.000100
[2025-08-26 21:15:13,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007344] [Batch 01184/03080] [00:14:46/00:23:39, 0.749s/it]: train_loss_raw=1.9851, running_loss=1.9339, LR=0.000100
[2025-08-26 21:15:19,305][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007352] [Batch 01192/03080] [00:14:52/00:23:33, 0.749s/it]: train_loss_raw=2.0052, running_loss=1.9367, LR=0.000100
[2025-08-26 21:15:25,265][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007360] [Batch 01200/03080] [00:14:58/00:23:27, 0.749s/it]: train_loss_raw=1.9425, running_loss=1.9378, LR=0.000100
[2025-08-26 21:15:31,252][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007368] [Batch 01208/03080] [00:15:04/00:23:21, 0.749s/it]: train_loss_raw=1.9424, running_loss=1.9368, LR=0.000100
[2025-08-26 21:15:37,383][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007376] [Batch 01216/03080] [00:15:10/00:23:15, 0.749s/it]: train_loss_raw=1.9691, running_loss=1.9354, LR=0.000100
[2025-08-26 21:15:43,346][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007384] [Batch 01224/03080] [00:15:16/00:23:09, 0.749s/it]: train_loss_raw=1.9162, running_loss=1.9320, LR=0.000100
[2025-08-26 21:15:49,254][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007392] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=1.8665, running_loss=1.9311, LR=0.000100
[2025-08-26 21:15:55,227][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007400] [Batch 01240/03080] [00:15:28/00:22:57, 0.749s/it]: train_loss_raw=1.9421, running_loss=1.9317, LR=0.000100
[2025-08-26 21:16:01,223][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007408] [Batch 01248/03080] [00:15:34/00:22:51, 0.749s/it]: train_loss_raw=1.8850, running_loss=1.9297, LR=0.000100
[2025-08-26 21:16:07,263][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007416] [Batch 01256/03080] [00:15:40/00:22:45, 0.749s/it]: train_loss_raw=1.7969, running_loss=1.9286, LR=0.000100
[2025-08-26 21:16:13,214][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007424] [Batch 01264/03080] [00:15:46/00:22:39, 0.749s/it]: train_loss_raw=2.0056, running_loss=1.9301, LR=0.000100
[2025-08-26 21:16:19,348][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007432] [Batch 01272/03080] [00:15:52/00:22:33, 0.749s/it]: train_loss_raw=1.8995, running_loss=1.9285, LR=0.000100
[2025-08-26 21:16:25,292][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007440] [Batch 01280/03080] [00:15:58/00:22:27, 0.749s/it]: train_loss_raw=1.8875, running_loss=1.9292, LR=0.000100
[2025-08-26 21:16:31,277][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007448] [Batch 01288/03080] [00:16:04/00:22:21, 0.749s/it]: train_loss_raw=1.9050, running_loss=1.9309, LR=0.000100
[2025-08-26 21:16:37,366][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007456] [Batch 01296/03080] [00:16:10/00:22:16, 0.749s/it]: train_loss_raw=1.8935, running_loss=1.9305, LR=0.000100
[2025-08-26 21:16:43,345][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007464] [Batch 01304/03080] [00:16:16/00:22:10, 0.749s/it]: train_loss_raw=1.9079, running_loss=1.9288, LR=0.000100
[2025-08-26 21:16:49,443][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007472] [Batch 01312/03080] [00:16:22/00:22:04, 0.749s/it]: train_loss_raw=1.8628, running_loss=1.9255, LR=0.000100
[2025-08-26 21:16:55,442][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007480] [Batch 01320/03080] [00:16:28/00:21:58, 0.749s/it]: train_loss_raw=1.9265, running_loss=1.9254, LR=0.000100
[2025-08-26 21:17:01,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007488] [Batch 01328/03080] [00:16:34/00:21:52, 0.749s/it]: train_loss_raw=1.8857, running_loss=1.9253, LR=0.000100
[2025-08-26 21:17:07,336][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007496] [Batch 01336/03080] [00:16:40/00:21:46, 0.749s/it]: train_loss_raw=1.9378, running_loss=1.9237, LR=0.000100
[2025-08-26 21:17:13,333][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007504] [Batch 01344/03080] [00:16:46/00:21:40, 0.749s/it]: train_loss_raw=1.9693, running_loss=1.9230, LR=0.000100
[2025-08-26 21:17:19,238][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007512] [Batch 01352/03080] [00:16:52/00:21:33, 0.749s/it]: train_loss_raw=1.8915, running_loss=1.9236, LR=0.000100
[2025-08-26 21:17:25,142][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007520] [Batch 01360/03080] [00:16:58/00:21:27, 0.749s/it]: train_loss_raw=1.8743, running_loss=1.9249, LR=0.000100
[2025-08-26 21:17:31,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007528] [Batch 01368/03080] [00:17:04/00:21:21, 0.749s/it]: train_loss_raw=1.8283, running_loss=1.9233, LR=0.000100
[2025-08-26 21:17:37,031][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007536] [Batch 01376/03080] [00:17:10/00:21:15, 0.749s/it]: train_loss_raw=1.8703, running_loss=1.9243, LR=0.000100
[2025-08-26 21:17:43,012][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007544] [Batch 01384/03080] [00:17:16/00:21:09, 0.749s/it]: train_loss_raw=1.8385, running_loss=1.9238, LR=0.000100
[2025-08-26 21:17:49,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007552] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=1.9632, running_loss=1.9228, LR=0.000100
[2025-08-26 21:17:54,934][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007560] [Batch 01400/03080] [00:17:28/00:20:57, 0.749s/it]: train_loss_raw=1.9469, running_loss=1.9234, LR=0.000100
[2025-08-26 21:18:01,051][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007568] [Batch 01408/03080] [00:17:34/00:20:51, 0.749s/it]: train_loss_raw=1.9773, running_loss=1.9239, LR=0.000100
[2025-08-26 21:18:07,041][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007576] [Batch 01416/03080] [00:17:40/00:20:45, 0.749s/it]: train_loss_raw=2.0014, running_loss=1.9238, LR=0.000100
[2025-08-26 21:18:12,891][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007584] [Batch 01424/03080] [00:17:46/00:20:39, 0.749s/it]: train_loss_raw=1.9575, running_loss=1.9246, LR=0.000100
[2025-08-26 21:18:18,886][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007592] [Batch 01432/03080] [00:17:52/00:20:33, 0.749s/it]: train_loss_raw=1.9457, running_loss=1.9256, LR=0.000100
[2025-08-26 21:18:24,831][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007600] [Batch 01440/03080] [00:17:58/00:20:27, 0.749s/it]: train_loss_raw=1.8727, running_loss=1.9230, LR=0.000100
[2025-08-26 21:18:30,852][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007608] [Batch 01448/03080] [00:18:04/00:20:21, 0.749s/it]: train_loss_raw=1.9455, running_loss=1.9224, LR=0.000100
[2025-08-26 21:18:36,844][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007616] [Batch 01456/03080] [00:18:10/00:20:15, 0.749s/it]: train_loss_raw=1.8617, running_loss=1.9227, LR=0.000100
[2025-08-26 21:18:42,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007624] [Batch 01464/03080] [00:18:16/00:20:09, 0.749s/it]: train_loss_raw=1.8591, running_loss=1.9202, LR=0.000100
[2025-08-26 21:18:48,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007632] [Batch 01472/03080] [00:18:22/00:20:03, 0.749s/it]: train_loss_raw=1.8975, running_loss=1.9188, LR=0.000100
[2025-08-26 21:18:54,951][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007640] [Batch 01480/03080] [00:18:28/00:19:57, 0.749s/it]: train_loss_raw=1.8277, running_loss=1.9162, LR=0.000100
[2025-08-26 21:19:00,927][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007648] [Batch 01488/03080] [00:18:34/00:19:51, 0.749s/it]: train_loss_raw=1.9372, running_loss=1.9163, LR=0.000100
[2025-08-26 21:19:06,819][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007656] [Batch 01496/03080] [00:18:40/00:19:45, 0.749s/it]: train_loss_raw=1.9161, running_loss=1.9156, LR=0.000100
[2025-08-26 21:19:12,738][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007664] [Batch 01504/03080] [00:18:45/00:19:39, 0.749s/it]: train_loss_raw=1.8383, running_loss=1.9154, LR=0.000100
[2025-08-26 21:19:18,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007672] [Batch 01512/03080] [00:18:51/00:19:33, 0.749s/it]: train_loss_raw=1.8193, running_loss=1.9147, LR=0.000100
[2025-08-26 21:19:24,643][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007680] [Batch 01520/03080] [00:18:57/00:19:27, 0.749s/it]: train_loss_raw=1.9512, running_loss=1.9147, LR=0.000100
[2025-08-26 21:19:30,597][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007688] [Batch 01528/03080] [00:19:03/00:19:21, 0.749s/it]: train_loss_raw=1.9617, running_loss=1.9159, LR=0.000100
[2025-08-26 21:19:36,524][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007696] [Batch 01536/03080] [00:19:09/00:19:15, 0.749s/it]: train_loss_raw=1.9608, running_loss=1.9176, LR=0.000100
[2025-08-26 21:19:42,545][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007704] [Batch 01544/03080] [00:19:15/00:19:09, 0.749s/it]: train_loss_raw=1.8763, running_loss=1.9156, LR=0.000100
[2025-08-26 21:19:48,529][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007712] [Batch 01552/03080] [00:19:21/00:19:03, 0.749s/it]: train_loss_raw=1.8931, running_loss=1.9148, LR=0.000100
[2025-08-26 21:19:54,532][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007720] [Batch 01560/03080] [00:19:27/00:18:57, 0.749s/it]: train_loss_raw=1.9500, running_loss=1.9129, LR=0.000100
[2025-08-26 21:20:00,467][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007728] [Batch 01568/03080] [00:19:33/00:18:51, 0.749s/it]: train_loss_raw=1.8451, running_loss=1.9129, LR=0.000100
[2025-08-26 21:20:06,413][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007736] [Batch 01576/03080] [00:19:39/00:18:45, 0.748s/it]: train_loss_raw=1.8249, running_loss=1.9115, LR=0.000100
[2025-08-26 21:20:12,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007744] [Batch 01584/03080] [00:19:45/00:18:39, 0.748s/it]: train_loss_raw=1.8469, running_loss=1.9125, LR=0.000100
[2025-08-26 21:20:18,305][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007752] [Batch 01592/03080] [00:19:51/00:18:33, 0.748s/it]: train_loss_raw=1.8150, running_loss=1.9112, LR=0.000100
[2025-08-26 21:20:24,280][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007760] [Batch 01600/03080] [00:19:57/00:18:27, 0.748s/it]: train_loss_raw=1.8703, running_loss=1.9126, LR=0.000100
[2025-08-26 21:20:30,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007768] [Batch 01608/03080] [00:20:03/00:18:21, 0.748s/it]: train_loss_raw=1.9302, running_loss=1.9126, LR=0.000100
[2025-08-26 21:20:36,168][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007776] [Batch 01616/03080] [00:20:09/00:18:15, 0.748s/it]: train_loss_raw=1.9303, running_loss=1.9110, LR=0.000100
[2025-08-26 21:20:42,074][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007784] [Batch 01624/03080] [00:20:15/00:18:09, 0.748s/it]: train_loss_raw=1.9667, running_loss=1.9102, LR=0.000100
[2025-08-26 21:20:47,963][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007792] [Batch 01632/03080] [00:20:21/00:18:03, 0.748s/it]: train_loss_raw=1.8468, running_loss=1.9081, LR=0.000100
[2025-08-26 21:20:54,042][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007800] [Batch 01640/03080] [00:20:27/00:17:57, 0.748s/it]: train_loss_raw=1.8866, running_loss=1.9074, LR=0.000100
[2025-08-26 21:20:59,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007808] [Batch 01648/03080] [00:20:33/00:17:51, 0.748s/it]: train_loss_raw=1.9033, running_loss=1.9086, LR=0.000100
[2025-08-26 21:21:05,978][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007816] [Batch 01656/03080] [00:20:39/00:17:45, 0.748s/it]: train_loss_raw=1.9419, running_loss=1.9080, LR=0.000100
[2025-08-26 21:21:12,011][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007824] [Batch 01664/03080] [00:20:45/00:17:39, 0.748s/it]: train_loss_raw=1.8880, running_loss=1.9069, LR=0.000100
[2025-08-26 21:21:17,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007832] [Batch 01672/03080] [00:20:51/00:17:33, 0.748s/it]: train_loss_raw=1.9348, running_loss=1.9072, LR=0.000100
[2025-08-26 21:21:23,942][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007840] [Batch 01680/03080] [00:20:57/00:17:27, 0.748s/it]: train_loss_raw=1.9222, running_loss=1.9085, LR=0.000100
[2025-08-26 21:21:29,827][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007848] [Batch 01688/03080] [00:21:03/00:17:21, 0.748s/it]: train_loss_raw=1.9210, running_loss=1.9080, LR=0.000100
[2025-08-26 21:21:35,762][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007856] [Batch 01696/03080] [00:21:08/00:17:15, 0.748s/it]: train_loss_raw=2.0017, running_loss=1.9058, LR=0.000100
[2025-08-26 21:21:41,722][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007864] [Batch 01704/03080] [00:21:14/00:17:09, 0.748s/it]: train_loss_raw=1.8589, running_loss=1.9055, LR=0.000100
[2025-08-26 21:21:47,731][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007872] [Batch 01712/03080] [00:21:20/00:17:03, 0.748s/it]: train_loss_raw=1.9237, running_loss=1.9073, LR=0.000100
[2025-08-26 21:21:53,627][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007880] [Batch 01720/03080] [00:21:26/00:16:57, 0.748s/it]: train_loss_raw=1.8848, running_loss=1.9065, LR=0.000100
[2025-08-26 21:21:59,561][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007888] [Batch 01728/03080] [00:21:32/00:16:51, 0.748s/it]: train_loss_raw=1.9221, running_loss=1.9063, LR=0.000100
[2025-08-26 21:22:05,551][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007896] [Batch 01736/03080] [00:21:38/00:16:45, 0.748s/it]: train_loss_raw=1.9234, running_loss=1.9066, LR=0.000100
[2025-08-26 21:22:11,473][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007904] [Batch 01744/03080] [00:21:44/00:16:39, 0.748s/it]: train_loss_raw=1.8591, running_loss=1.9053, LR=0.000100
[2025-08-26 21:22:17,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007912] [Batch 01752/03080] [00:21:50/00:16:33, 0.748s/it]: train_loss_raw=1.9666, running_loss=1.9042, LR=0.000100
[2025-08-26 21:22:23,590][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007920] [Batch 01760/03080] [00:21:56/00:16:27, 0.748s/it]: train_loss_raw=1.9754, running_loss=1.9048, LR=0.000100
[2025-08-26 21:22:29,510][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007928] [Batch 01768/03080] [00:22:02/00:16:21, 0.748s/it]: train_loss_raw=1.9151, running_loss=1.9044, LR=0.000100
[2025-08-26 21:22:35,483][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007936] [Batch 01776/03080] [00:22:08/00:16:15, 0.748s/it]: train_loss_raw=1.9609, running_loss=1.9051, LR=0.000100
[2025-08-26 21:22:41,470][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007944] [Batch 01784/03080] [00:22:14/00:16:09, 0.748s/it]: train_loss_raw=1.8566, running_loss=1.9042, LR=0.000100
[2025-08-26 21:22:47,364][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007952] [Batch 01792/03080] [00:22:20/00:16:03, 0.748s/it]: train_loss_raw=1.9804, running_loss=1.9034, LR=0.000100
[2025-08-26 21:22:53,335][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007960] [Batch 01800/03080] [00:22:26/00:15:57, 0.748s/it]: train_loss_raw=1.8732, running_loss=1.9018, LR=0.000100
[2025-08-26 21:22:59,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007968] [Batch 01808/03080] [00:22:32/00:15:51, 0.748s/it]: train_loss_raw=2.0356, running_loss=1.9021, LR=0.000100
[2025-08-26 21:23:05,123][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007976] [Batch 01816/03080] [00:22:38/00:15:45, 0.748s/it]: train_loss_raw=1.7808, running_loss=1.9014, LR=0.000100
[2025-08-26 21:23:10,912][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007984] [Batch 01824/03080] [00:22:44/00:15:39, 0.748s/it]: train_loss_raw=1.9389, running_loss=1.9026, LR=0.000100
[2025-08-26 21:23:16,682][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007992] [Batch 01832/03080] [00:22:49/00:15:33, 0.748s/it]: train_loss_raw=1.8670, running_loss=1.9029, LR=0.000100
[2025-08-26 21:23:22,694][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008000] [Batch 01840/03080] [00:22:55/00:15:27, 0.748s/it]: train_loss_raw=1.8870, running_loss=1.9023, LR=0.000100
[2025-08-26 21:23:33,170][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008008] [Batch 01848/03080] [00:23:06/00:15:24, 0.750s/it]: train_loss_raw=1.9412, running_loss=1.9026, LR=0.000100
[2025-08-26 21:23:39,162][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008016] [Batch 01856/03080] [00:23:12/00:15:18, 0.750s/it]: train_loss_raw=1.8350, running_loss=1.8999, LR=0.000100
[2025-08-26 21:23:44,994][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008024] [Batch 01864/03080] [00:23:18/00:15:12, 0.750s/it]: train_loss_raw=1.8230, running_loss=1.9000, LR=0.000100
[2025-08-26 21:23:50,939][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008032] [Batch 01872/03080] [00:23:24/00:15:06, 0.750s/it]: train_loss_raw=1.9371, running_loss=1.8993, LR=0.000100
[2025-08-26 21:23:57,010][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008040] [Batch 01880/03080] [00:23:30/00:15:00, 0.750s/it]: train_loss_raw=1.9137, running_loss=1.8985, LR=0.000100
[2025-08-26 21:24:03,005][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008048] [Batch 01888/03080] [00:23:36/00:14:54, 0.750s/it]: train_loss_raw=1.9155, running_loss=1.8993, LR=0.000100
[2025-08-26 21:24:08,997][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008056] [Batch 01896/03080] [00:23:42/00:14:48, 0.750s/it]: train_loss_raw=1.8754, running_loss=1.8960, LR=0.000100
[2025-08-26 21:24:14,980][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008064] [Batch 01904/03080] [00:23:48/00:14:42, 0.750s/it]: train_loss_raw=1.8252, running_loss=1.8951, LR=0.000100
[2025-08-26 21:24:20,917][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008072] [Batch 01912/03080] [00:23:54/00:14:36, 0.750s/it]: train_loss_raw=1.8582, running_loss=1.8953, LR=0.000100
[2025-08-26 21:24:26,878][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008080] [Batch 01920/03080] [00:24:00/00:14:30, 0.750s/it]: train_loss_raw=1.8810, running_loss=1.8935, LR=0.000100
[2025-08-26 21:24:32,811][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008088] [Batch 01928/03080] [00:24:06/00:14:24, 0.750s/it]: train_loss_raw=1.8277, running_loss=1.8938, LR=0.000100
[2025-08-26 21:24:38,774][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008096] [Batch 01936/03080] [00:24:11/00:14:17, 0.750s/it]: train_loss_raw=1.9426, running_loss=1.8947, LR=0.000100
[2025-08-26 21:24:44,701][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008104] [Batch 01944/03080] [00:24:17/00:14:11, 0.750s/it]: train_loss_raw=1.9065, running_loss=1.8972, LR=0.000100
[2025-08-26 21:24:50,567][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008112] [Batch 01952/03080] [00:24:23/00:14:05, 0.750s/it]: train_loss_raw=1.9231, running_loss=1.8983, LR=0.000100
[2025-08-26 21:24:56,534][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008120] [Batch 01960/03080] [00:24:29/00:13:59, 0.750s/it]: train_loss_raw=1.9767, running_loss=1.8974, LR=0.000100
[2025-08-26 21:25:02,531][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008128] [Batch 01968/03080] [00:24:35/00:13:53, 0.750s/it]: train_loss_raw=1.9365, running_loss=1.8952, LR=0.000100
[2025-08-26 21:25:08,487][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008136] [Batch 01976/03080] [00:24:41/00:13:47, 0.750s/it]: train_loss_raw=1.7683, running_loss=1.8939, LR=0.000100
[2025-08-26 21:25:14,465][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008144] [Batch 01984/03080] [00:24:47/00:13:41, 0.750s/it]: train_loss_raw=1.9072, running_loss=1.8921, LR=0.000100
[2025-08-26 21:25:20,454][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008152] [Batch 01992/03080] [00:24:53/00:13:35, 0.750s/it]: train_loss_raw=1.9386, running_loss=1.8924, LR=0.000100
[2025-08-26 21:25:26,418][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008160] [Batch 02000/03080] [00:24:59/00:13:29, 0.750s/it]: train_loss_raw=1.9370, running_loss=1.8932, LR=0.000100
[2025-08-26 21:25:32,420][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008168] [Batch 02008/03080] [00:25:05/00:13:23, 0.750s/it]: train_loss_raw=1.7770, running_loss=1.8917, LR=0.000100
[2025-08-26 21:25:38,433][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008176] [Batch 02016/03080] [00:25:11/00:13:17, 0.750s/it]: train_loss_raw=1.8913, running_loss=1.8903, LR=0.000100
[2025-08-26 21:25:44,402][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008184] [Batch 02024/03080] [00:25:17/00:13:11, 0.750s/it]: train_loss_raw=1.9005, running_loss=1.8895, LR=0.000100
[2025-08-26 21:25:50,397][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008192] [Batch 02032/03080] [00:25:23/00:13:05, 0.750s/it]: train_loss_raw=1.8167, running_loss=1.8869, LR=0.000100
[2025-08-26 21:25:56,311][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008200] [Batch 02040/03080] [00:25:29/00:12:59, 0.750s/it]: train_loss_raw=1.9435, running_loss=1.8863, LR=0.000100
[2025-08-26 21:26:02,178][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008208] [Batch 02048/03080] [00:25:35/00:12:53, 0.750s/it]: train_loss_raw=1.9119, running_loss=1.8884, LR=0.000100
[2025-08-26 21:26:08,206][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008216] [Batch 02056/03080] [00:25:41/00:12:47, 0.750s/it]: train_loss_raw=1.7827, running_loss=1.8879, LR=0.000100
[2025-08-26 21:26:14,103][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008224] [Batch 02064/03080] [00:25:47/00:12:41, 0.750s/it]: train_loss_raw=1.9793, running_loss=1.8893, LR=0.000100
[2025-08-26 21:26:20,029][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008232] [Batch 02072/03080] [00:25:53/00:12:35, 0.750s/it]: train_loss_raw=1.9027, running_loss=1.8872, LR=0.000100
[2025-08-26 21:26:25,940][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008240] [Batch 02080/03080] [00:25:59/00:12:29, 0.750s/it]: train_loss_raw=1.8522, running_loss=1.8861, LR=0.000100
[2025-08-26 21:26:31,958][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008248] [Batch 02088/03080] [00:26:05/00:12:23, 0.750s/it]: train_loss_raw=1.8639, running_loss=1.8860, LR=0.000100
[2025-08-26 21:26:37,950][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008256] [Batch 02096/03080] [00:26:11/00:12:17, 0.750s/it]: train_loss_raw=1.9105, running_loss=1.8867, LR=0.000100
[2025-08-26 21:26:43,851][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008264] [Batch 02104/03080] [00:26:17/00:12:11, 0.750s/it]: train_loss_raw=1.8646, running_loss=1.8861, LR=0.000100
[2025-08-26 21:26:49,718][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008272] [Batch 02112/03080] [00:26:22/00:12:05, 0.749s/it]: train_loss_raw=1.7629, running_loss=1.8828, LR=0.000100
[2025-08-26 21:26:55,662][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008280] [Batch 02120/03080] [00:26:28/00:11:59, 0.749s/it]: train_loss_raw=1.8069, running_loss=1.8818, LR=0.000100
[2025-08-26 21:27:01,691][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008288] [Batch 02128/03080] [00:26:34/00:11:53, 0.749s/it]: train_loss_raw=1.8956, running_loss=1.8820, LR=0.000100
[2025-08-26 21:27:07,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008296] [Batch 02136/03080] [00:26:41/00:11:47, 0.750s/it]: train_loss_raw=1.9960, running_loss=1.8819, LR=0.000100
[2025-08-26 21:27:13,774][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008304] [Batch 02144/03080] [00:26:46/00:11:41, 0.750s/it]: train_loss_raw=1.8418, running_loss=1.8795, LR=0.000100
[2025-08-26 21:27:19,733][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008312] [Batch 02152/03080] [00:26:52/00:11:35, 0.749s/it]: train_loss_raw=1.8893, running_loss=1.8779, LR=0.000100
[2025-08-26 21:27:25,616][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008320] [Batch 02160/03080] [00:26:58/00:11:29, 0.749s/it]: train_loss_raw=1.8623, running_loss=1.8782, LR=0.000100
[2025-08-26 21:27:31,644][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008328] [Batch 02168/03080] [00:27:04/00:11:23, 0.749s/it]: train_loss_raw=1.9374, running_loss=1.8773, LR=0.000100
[2025-08-26 21:27:37,927][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008336] [Batch 02176/03080] [00:27:11/00:11:17, 0.750s/it]: train_loss_raw=1.8979, running_loss=1.8781, LR=0.000100
[2025-08-26 21:27:43,841][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008344] [Batch 02184/03080] [00:27:17/00:11:11, 0.750s/it]: train_loss_raw=1.8550, running_loss=1.8773, LR=0.000100
[2025-08-26 21:27:49,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008352] [Batch 02192/03080] [00:27:22/00:11:05, 0.750s/it]: train_loss_raw=1.9150, running_loss=1.8775, LR=0.000100
[2025-08-26 21:27:55,928][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008360] [Batch 02200/03080] [00:27:29/00:10:59, 0.750s/it]: train_loss_raw=1.9459, running_loss=1.8798, LR=0.000100
[2025-08-26 21:28:01,852][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008368] [Batch 02208/03080] [00:27:35/00:10:53, 0.750s/it]: train_loss_raw=1.9495, running_loss=1.8778, LR=0.000100
[2025-08-26 21:28:07,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008376] [Batch 02216/03080] [00:27:40/00:10:47, 0.750s/it]: train_loss_raw=1.9543, running_loss=1.8778, LR=0.000100
[2025-08-26 21:28:13,476][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008384] [Batch 02224/03080] [00:27:46/00:10:41, 0.749s/it]: train_loss_raw=1.9711, running_loss=1.8791, LR=0.000100
[2025-08-26 21:28:19,402][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008392] [Batch 02232/03080] [00:27:52/00:10:35, 0.749s/it]: train_loss_raw=1.9689, running_loss=1.8820, LR=0.000100
[2025-08-26 21:28:25,353][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008400] [Batch 02240/03080] [00:27:58/00:10:29, 0.749s/it]: train_loss_raw=1.8191, running_loss=1.8815, LR=0.000100
[2025-08-26 21:28:31,355][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008408] [Batch 02248/03080] [00:28:04/00:10:23, 0.749s/it]: train_loss_raw=1.8506, running_loss=1.8817, LR=0.000100
[2025-08-26 21:28:37,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008416] [Batch 02256/03080] [00:28:10/00:10:17, 0.749s/it]: train_loss_raw=1.8720, running_loss=1.8821, LR=0.000100
[2025-08-26 21:28:43,108][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008424] [Batch 02264/03080] [00:28:16/00:10:11, 0.749s/it]: train_loss_raw=1.8517, running_loss=1.8792, LR=0.000100
[2025-08-26 21:28:49,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008432] [Batch 02272/03080] [00:28:22/00:10:05, 0.749s/it]: train_loss_raw=1.8284, running_loss=1.8758, LR=0.000100
[2025-08-26 21:28:54,937][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008440] [Batch 02280/03080] [00:28:28/00:09:59, 0.749s/it]: train_loss_raw=1.9213, running_loss=1.8753, LR=0.000100
[2025-08-26 21:29:00,948][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008448] [Batch 02288/03080] [00:28:34/00:09:53, 0.749s/it]: train_loss_raw=1.8419, running_loss=1.8745, LR=0.000100
[2025-08-26 21:29:06,836][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008456] [Batch 02296/03080] [00:28:40/00:09:47, 0.749s/it]: train_loss_raw=1.9040, running_loss=1.8729, LR=0.000100
[2025-08-26 21:29:12,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008464] [Batch 02304/03080] [00:28:45/00:09:41, 0.749s/it]: train_loss_raw=1.7932, running_loss=1.8719, LR=0.000100
[2025-08-26 21:29:18,749][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008472] [Batch 02312/03080] [00:28:51/00:09:35, 0.749s/it]: train_loss_raw=1.8254, running_loss=1.8704, LR=0.000100
[2025-08-26 21:29:24,586][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008480] [Batch 02320/03080] [00:28:57/00:09:29, 0.749s/it]: train_loss_raw=1.8173, running_loss=1.8702, LR=0.000100
[2025-08-26 21:29:30,523][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008488] [Batch 02328/03080] [00:29:03/00:09:23, 0.749s/it]: train_loss_raw=1.8902, running_loss=1.8723, LR=0.000100
[2025-08-26 21:29:36,411][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008496] [Batch 02336/03080] [00:29:09/00:09:17, 0.749s/it]: train_loss_raw=1.8581, running_loss=1.8716, LR=0.000100
[2025-08-26 21:29:42,302][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008504] [Batch 02344/03080] [00:29:15/00:09:11, 0.749s/it]: train_loss_raw=1.9114, running_loss=1.8708, LR=0.000100
[2025-08-26 21:29:48,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008512] [Batch 02352/03080] [00:29:21/00:09:05, 0.749s/it]: train_loss_raw=1.9035, running_loss=1.8699, LR=0.000100
[2025-08-26 21:29:54,163][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008520] [Batch 02360/03080] [00:29:27/00:08:59, 0.749s/it]: train_loss_raw=1.7982, running_loss=1.8676, LR=0.000100
[2025-08-26 21:30:00,052][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008528] [Batch 02368/03080] [00:29:33/00:08:53, 0.749s/it]: train_loss_raw=1.8643, running_loss=1.8671, LR=0.000100
[2025-08-26 21:30:05,959][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008536] [Batch 02376/03080] [00:29:39/00:08:47, 0.749s/it]: train_loss_raw=1.7871, running_loss=1.8667, LR=0.000100
[2025-08-26 21:30:11,803][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008544] [Batch 02384/03080] [00:29:44/00:08:41, 0.749s/it]: train_loss_raw=1.8025, running_loss=1.8643, LR=0.000100
[2025-08-26 21:30:17,713][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008552] [Batch 02392/03080] [00:29:50/00:08:35, 0.749s/it]: train_loss_raw=1.8951, running_loss=1.8636, LR=0.000100
[2025-08-26 21:30:23,674][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008560] [Batch 02400/03080] [00:29:56/00:08:29, 0.749s/it]: train_loss_raw=1.8278, running_loss=1.8606, LR=0.000100
[2025-08-26 21:30:29,740][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008568] [Batch 02408/03080] [00:30:02/00:08:23, 0.749s/it]: train_loss_raw=1.8605, running_loss=1.8612, LR=0.000100
[2025-08-26 21:30:35,712][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008576] [Batch 02416/03080] [00:30:08/00:08:17, 0.749s/it]: train_loss_raw=1.8850, running_loss=1.8606, LR=0.000100
[2025-08-26 21:30:41,562][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008584] [Batch 02424/03080] [00:30:14/00:08:11, 0.749s/it]: train_loss_raw=1.8112, running_loss=1.8595, LR=0.000100
[2025-08-26 21:30:47,462][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008592] [Batch 02432/03080] [00:30:20/00:08:05, 0.749s/it]: train_loss_raw=1.8982, running_loss=1.8586, LR=0.000100
[2025-08-26 21:30:53,781][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008600] [Batch 02440/03080] [00:30:26/00:07:59, 0.749s/it]: train_loss_raw=1.8684, running_loss=1.8585, LR=0.000100
[2025-08-26 21:30:59,795][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008608] [Batch 02448/03080] [00:30:32/00:07:53, 0.749s/it]: train_loss_raw=1.9211, running_loss=1.8580, LR=0.000100
[2025-08-26 21:31:06,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008616] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.8519, running_loss=1.8591, LR=0.000100
[2025-08-26 21:31:12,139][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008624] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.8302, running_loss=1.8602, LR=0.000100
[2025-08-26 21:31:18,275][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008632] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.8771, running_loss=1.8608, LR=0.000100
[2025-08-26 21:31:24,559][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008640] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.8778, running_loss=1.8604, LR=0.000100
[2025-08-26 21:31:30,709][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008648] [Batch 02488/03080] [00:31:03/00:07:23, 0.749s/it]: train_loss_raw=1.8690, running_loss=1.8610, LR=0.000100
[2025-08-26 21:31:36,899][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008656] [Batch 02496/03080] [00:31:10/00:07:17, 0.749s/it]: train_loss_raw=1.7682, running_loss=1.8587, LR=0.000100
[2025-08-26 21:31:42,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008664] [Batch 02504/03080] [00:31:16/00:07:11, 0.749s/it]: train_loss_raw=1.8911, running_loss=1.8603, LR=0.000100
[2025-08-26 21:31:49,033][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008672] [Batch 02512/03080] [00:31:22/00:07:05, 0.749s/it]: train_loss_raw=1.8598, running_loss=1.8591, LR=0.000100
[2025-08-26 21:31:55,321][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008680] [Batch 02520/03080] [00:31:28/00:06:59, 0.749s/it]: train_loss_raw=1.8854, running_loss=1.8598, LR=0.000100
[2025-08-26 21:32:01,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008688] [Batch 02528/03080] [00:31:34/00:06:53, 0.749s/it]: train_loss_raw=1.8114, running_loss=1.8602, LR=0.000100
[2025-08-26 21:32:07,520][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008696] [Batch 02536/03080] [00:31:40/00:06:47, 0.749s/it]: train_loss_raw=1.8217, running_loss=1.8604, LR=0.000100
[2025-08-26 21:32:13,549][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008704] [Batch 02544/03080] [00:31:46/00:06:41, 0.750s/it]: train_loss_raw=1.8119, running_loss=1.8605, LR=0.000100
[2025-08-26 21:32:19,257][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008712] [Batch 02552/03080] [00:31:52/00:06:35, 0.749s/it]: train_loss_raw=1.8261, running_loss=1.8605, LR=0.000100
[2025-08-26 21:32:24,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008720] [Batch 02560/03080] [00:31:58/00:06:29, 0.749s/it]: train_loss_raw=1.9312, running_loss=1.8601, LR=0.000100
[2025-08-26 21:32:30,598][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008728] [Batch 02568/03080] [00:32:03/00:06:23, 0.749s/it]: train_loss_raw=1.8224, running_loss=1.8603, LR=0.000100
[2025-08-26 21:32:36,470][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008736] [Batch 02576/03080] [00:32:09/00:06:17, 0.749s/it]: train_loss_raw=1.8198, running_loss=1.8583, LR=0.000100
[2025-08-26 21:32:42,284][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008744] [Batch 02584/03080] [00:32:15/00:06:11, 0.749s/it]: train_loss_raw=1.8530, running_loss=1.8566, LR=0.000100
[2025-08-26 21:32:47,864][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008752] [Batch 02592/03080] [00:32:21/00:06:05, 0.749s/it]: train_loss_raw=1.7996, running_loss=1.8557, LR=0.000100
[2025-08-26 21:32:53,406][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008760] [Batch 02600/03080] [00:32:26/00:05:59, 0.749s/it]: train_loss_raw=1.9067, running_loss=1.8560, LR=0.000100
[2025-08-26 21:32:58,937][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008768] [Batch 02608/03080] [00:32:32/00:05:53, 0.749s/it]: train_loss_raw=1.8221, running_loss=1.8545, LR=0.000100
[2025-08-26 21:33:04,701][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008776] [Batch 02616/03080] [00:32:37/00:05:47, 0.748s/it]: train_loss_raw=1.8376, running_loss=1.8532, LR=0.000100
[2025-08-26 21:33:10,449][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008784] [Batch 02624/03080] [00:32:43/00:05:41, 0.748s/it]: train_loss_raw=1.8197, running_loss=1.8517, LR=0.000100
[2025-08-26 21:33:16,224][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008792] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=1.8805, running_loss=1.8520, LR=0.000100
[2025-08-26 21:33:22,280][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008800] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.9192, running_loss=1.8521, LR=0.000100
[2025-08-26 21:33:28,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008808] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=1.8889, running_loss=1.8535, LR=0.000100
[2025-08-26 21:33:34,287][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008816] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=1.7630, running_loss=1.8510, LR=0.000100
[2025-08-26 21:33:40,250][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008824] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=1.7455, running_loss=1.8483, LR=0.000100
[2025-08-26 21:33:46,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008832] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=1.9095, running_loss=1.8473, LR=0.000100
[2025-08-26 21:33:53,431][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008840] [Batch 02680/03080] [00:33:26/00:04:59, 0.749s/it]: train_loss_raw=1.8550, running_loss=1.8469, LR=0.000100
[2025-08-26 21:34:00,033][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008848] [Batch 02688/03080] [00:33:33/00:04:53, 0.749s/it]: train_loss_raw=1.8012, running_loss=1.8451, LR=0.000100
[2025-08-26 21:34:06,624][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008856] [Batch 02696/03080] [00:33:39/00:04:47, 0.749s/it]: train_loss_raw=1.8341, running_loss=1.8452, LR=0.000100
[2025-08-26 21:34:13,224][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008864] [Batch 02704/03080] [00:33:46/00:04:41, 0.749s/it]: train_loss_raw=1.9551, running_loss=1.8459, LR=0.000100
[2025-08-26 21:34:19,867][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008872] [Batch 02712/03080] [00:33:53/00:04:35, 0.750s/it]: train_loss_raw=1.7833, running_loss=1.8456, LR=0.000100
[2025-08-26 21:34:26,446][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008880] [Batch 02720/03080] [00:33:59/00:04:29, 0.750s/it]: train_loss_raw=1.8558, running_loss=1.8469, LR=0.000100
[2025-08-26 21:34:33,047][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008888] [Batch 02728/03080] [00:34:06/00:04:24, 0.750s/it]: train_loss_raw=1.7665, running_loss=1.8448, LR=0.000100
[2025-08-26 21:34:39,649][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008896] [Batch 02736/03080] [00:34:12/00:04:18, 0.750s/it]: train_loss_raw=1.8397, running_loss=1.8434, LR=0.000100
[2025-08-26 21:34:46,272][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008904] [Batch 02744/03080] [00:34:19/00:04:12, 0.751s/it]: train_loss_raw=1.9423, running_loss=1.8412, LR=0.000100
[2025-08-26 21:34:52,913][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008912] [Batch 02752/03080] [00:34:26/00:04:06, 0.751s/it]: train_loss_raw=1.8376, running_loss=1.8418, LR=0.000100
[2025-08-26 21:34:59,575][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008920] [Batch 02760/03080] [00:34:32/00:04:00, 0.751s/it]: train_loss_raw=1.7956, running_loss=1.8395, LR=0.000100
[2025-08-26 21:35:06,175][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008928] [Batch 02768/03080] [00:34:39/00:03:54, 0.751s/it]: train_loss_raw=1.8306, running_loss=1.8393, LR=0.000100
[2025-08-26 21:35:12,839][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008936] [Batch 02776/03080] [00:34:46/00:03:48, 0.751s/it]: train_loss_raw=1.8741, running_loss=1.8401, LR=0.000100
[2025-08-26 21:35:19,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008944] [Batch 02784/03080] [00:34:52/00:03:42, 0.752s/it]: train_loss_raw=1.8534, running_loss=1.8419, LR=0.000100
[2025-08-26 21:35:26,055][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008952] [Batch 02792/03080] [00:34:59/00:03:36, 0.752s/it]: train_loss_raw=1.6845, running_loss=1.8392, LR=0.000100
[2025-08-26 21:35:32,695][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008960] [Batch 02800/03080] [00:35:05/00:03:30, 0.752s/it]: train_loss_raw=1.7397, running_loss=1.8413, LR=0.000100
[2025-08-26 21:35:39,321][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008968] [Batch 02808/03080] [00:35:12/00:03:24, 0.752s/it]: train_loss_raw=1.9314, running_loss=1.8416, LR=0.000100
[2025-08-26 21:35:45,805][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008976] [Batch 02816/03080] [00:35:18/00:03:18, 0.752s/it]: train_loss_raw=1.9794, running_loss=1.8422, LR=0.000100
[2025-08-26 21:35:52,455][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008984] [Batch 02824/03080] [00:35:25/00:03:12, 0.753s/it]: train_loss_raw=1.8569, running_loss=1.8430, LR=0.000100
[2025-08-26 21:35:58,966][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008992] [Batch 02832/03080] [00:35:32/00:03:06, 0.753s/it]: train_loss_raw=1.7951, running_loss=1.8431, LR=0.000100
[2025-08-26 21:36:05,429][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009000] [Batch 02840/03080] [00:35:38/00:03:00, 0.753s/it]: train_loss_raw=1.8130, running_loss=1.8417, LR=0.000100
[2025-08-26 21:36:11,534][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009008] [Batch 02848/03080] [00:35:44/00:02:54, 0.753s/it]: train_loss_raw=1.7682, running_loss=1.8398, LR=0.000100
[2025-08-26 21:36:18,045][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009016] [Batch 02856/03080] [00:35:51/00:02:48, 0.753s/it]: train_loss_raw=1.8348, running_loss=1.8393, LR=0.000100
[2025-08-26 21:36:24,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009024] [Batch 02864/03080] [00:35:57/00:02:42, 0.753s/it]: train_loss_raw=1.7924, running_loss=1.8380, LR=0.000100
[2025-08-26 21:36:31,131][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009032] [Batch 02872/03080] [00:36:04/00:02:36, 0.754s/it]: train_loss_raw=1.8802, running_loss=1.8419, LR=0.000100
[2025-08-26 21:36:37,717][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009040] [Batch 02880/03080] [00:36:10/00:02:30, 0.754s/it]: train_loss_raw=1.8906, running_loss=1.8427, LR=0.000100
[2025-08-26 21:36:44,144][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009048] [Batch 02888/03080] [00:36:17/00:02:24, 0.754s/it]: train_loss_raw=1.8671, running_loss=1.8421, LR=0.000100
[2025-08-26 21:36:50,323][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009056] [Batch 02896/03080] [00:36:23/00:02:18, 0.754s/it]: train_loss_raw=1.7726, running_loss=1.8400, LR=0.000100
[2025-08-26 21:36:56,898][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009064] [Batch 02904/03080] [00:36:30/00:02:12, 0.754s/it]: train_loss_raw=1.9207, running_loss=1.8365, LR=0.000100
[2025-08-26 21:37:03,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009072] [Batch 02912/03080] [00:36:36/00:02:06, 0.754s/it]: train_loss_raw=1.8313, running_loss=1.8380, LR=0.000100
[2025-08-26 21:37:10,184][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009080] [Batch 02920/03080] [00:36:43/00:02:00, 0.755s/it]: train_loss_raw=1.8263, running_loss=1.8382, LR=0.000100
[2025-08-26 21:37:16,719][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009088] [Batch 02928/03080] [00:36:49/00:01:54, 0.755s/it]: train_loss_raw=1.9121, running_loss=1.8398, LR=0.000100
[2025-08-26 21:37:23,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009096] [Batch 02936/03080] [00:36:56/00:01:48, 0.755s/it]: train_loss_raw=1.8486, running_loss=1.8400, LR=0.000100
[2025-08-26 21:37:29,741][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009104] [Batch 02944/03080] [00:37:02/00:01:42, 0.755s/it]: train_loss_raw=1.8792, running_loss=1.8392, LR=0.000100
[2025-08-26 21:37:36,005][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009112] [Batch 02952/03080] [00:37:09/00:01:36, 0.755s/it]: train_loss_raw=1.8172, running_loss=1.8367, LR=0.000100
[2025-08-26 21:37:42,586][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009120] [Batch 02960/03080] [00:37:15/00:01:30, 0.755s/it]: train_loss_raw=1.8900, running_loss=1.8367, LR=0.000100
[2025-08-26 21:37:49,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009128] [Batch 02968/03080] [00:37:22/00:01:24, 0.755s/it]: train_loss_raw=1.7821, running_loss=1.8377, LR=0.000100
[2025-08-26 21:37:55,568][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009136] [Batch 02976/03080] [00:37:28/00:01:18, 0.756s/it]: train_loss_raw=1.8614, running_loss=1.8371, LR=0.000100
[2025-08-26 21:38:02,196][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009144] [Batch 02984/03080] [00:37:35/00:01:12, 0.756s/it]: train_loss_raw=1.8734, running_loss=1.8347, LR=0.000100
[2025-08-26 21:38:08,737][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009152] [Batch 02992/03080] [00:37:41/00:01:06, 0.756s/it]: train_loss_raw=1.8547, running_loss=1.8351, LR=0.000100
[2025-08-26 21:38:15,360][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009160] [Batch 03000/03080] [00:37:48/00:01:00, 0.756s/it]: train_loss_raw=1.8930, running_loss=1.8368, LR=0.000100
[2025-08-26 21:38:21,939][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009168] [Batch 03008/03080] [00:37:55/00:00:54, 0.756s/it]: train_loss_raw=1.9383, running_loss=1.8375, LR=0.000100
[2025-08-26 21:38:28,576][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009176] [Batch 03016/03080] [00:38:01/00:00:48, 0.757s/it]: train_loss_raw=1.7127, running_loss=1.8344, LR=0.000100
[2025-08-26 21:38:35,262][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009184] [Batch 03024/03080] [00:38:08/00:00:42, 0.757s/it]: train_loss_raw=1.8115, running_loss=1.8366, LR=0.000100
[2025-08-26 21:38:42,053][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009192] [Batch 03032/03080] [00:38:15/00:00:36, 0.757s/it]: train_loss_raw=1.8087, running_loss=1.8357, LR=0.000100
[2025-08-26 21:38:48,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009200] [Batch 03040/03080] [00:38:21/00:00:30, 0.757s/it]: train_loss_raw=1.8741, running_loss=1.8332, LR=0.000100
[2025-08-26 21:38:55,261][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009208] [Batch 03048/03080] [00:38:28/00:00:24, 0.757s/it]: train_loss_raw=1.8106, running_loss=1.8341, LR=0.000100
[2025-08-26 21:39:02,011][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009216] [Batch 03056/03080] [00:38:35/00:00:18, 0.758s/it]: train_loss_raw=1.7826, running_loss=1.8323, LR=0.000100
[2025-08-26 21:39:08,656][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009224] [Batch 03064/03080] [00:38:41/00:00:12, 0.758s/it]: train_loss_raw=1.9522, running_loss=1.8311, LR=0.000100
[2025-08-26 21:39:15,277][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009232] [Batch 03072/03080] [00:38:48/00:00:06, 0.758s/it]: train_loss_raw=1.7719, running_loss=1.8308, LR=0.000100
[2025-08-26 21:39:21,640][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009240] [Batch 03080/03080] [00:38:54/00:00:00, 0.758s/it]: train_loss_raw=1.7544, running_loss=1.8296, LR=0.000100
[2025-08-26 21:39:22,171][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-26 21:39:34,324][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00007/00310] [00:00:12/00:07:38, 1.519s/it]
[2025-08-26 21:39:46,885][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00015/00310] [00:00:24/00:07:34, 1.545s/it]
[2025-08-26 21:40:00,005][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00023/00310] [00:00:37/00:07:30, 1.576s/it]
[2025-08-26 21:40:13,754][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00031/00310] [00:00:51/00:07:28, 1.612s/it]
[2025-08-26 21:40:27,652][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00039/00310] [00:01:05/00:07:21, 1.637s/it]
[2025-08-26 21:40:40,861][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00047/00310] [00:01:18/00:07:09, 1.639s/it]
[2025-08-26 21:40:54,364][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00055/00310] [00:01:32/00:06:58, 1.646s/it]
[2025-08-26 21:41:08,032][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00063/00310] [00:01:45/00:06:46, 1.654s/it]
[2025-08-26 21:41:21,714][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00071/00310] [00:01:59/00:06:35, 1.660s/it]
[2025-08-26 21:41:35,578][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00079/00310] [00:02:13/00:06:23, 1.668s/it]
[2025-08-26 21:41:49,029][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00087/00310] [00:02:26/00:06:10, 1.669s/it]
[2025-08-26 21:42:02,885][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00095/00310] [00:02:40/00:05:58, 1.674s/it]
[2025-08-26 21:42:16,629][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00103/00310] [00:02:54/00:05:45, 1.677s/it]
[2025-08-26 21:42:30,295][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00111/00310] [00:03:08/00:05:32, 1.680s/it]
[2025-08-26 21:42:44,154][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00119/00310] [00:03:21/00:05:19, 1.683s/it]
[2025-08-26 21:42:57,980][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00127/00310] [00:03:35/00:05:06, 1.686s/it]
[2025-08-26 21:43:11,273][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00135/00310] [00:03:49/00:04:53, 1.685s/it]
[2025-08-26 21:43:24,939][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00143/00310] [00:04:02/00:04:39, 1.686s/it]
[2025-08-26 21:43:37,666][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00151/00310] [00:04:15/00:04:25, 1.681s/it]
[2025-08-26 21:43:50,509][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00159/00310] [00:04:28/00:04:11, 1.677s/it]
[2025-08-26 21:44:03,730][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00167/00310] [00:04:41/00:03:57, 1.676s/it]
[2025-08-26 21:44:16,271][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00175/00310] [00:04:54/00:03:43, 1.671s/it]
[2025-08-26 21:44:29,132][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00183/00310] [00:05:06/00:03:30, 1.668s/it]
[2025-08-26 21:44:42,332][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00191/00310] [00:05:20/00:03:16, 1.668s/it]
[2025-08-26 21:44:55,966][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00199/00310] [00:05:33/00:03:03, 1.669s/it]
[2025-08-26 21:45:08,785][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00207/00310] [00:05:46/00:02:49, 1.666s/it]
[2025-08-26 21:45:21,484][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00215/00310] [00:05:59/00:02:36, 1.663s/it]
[2025-08-26 21:45:35,001][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00223/00310] [00:06:12/00:02:23, 1.664s/it]
[2025-08-26 21:45:48,613][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00231/00310] [00:06:26/00:02:09, 1.666s/it]
[2025-08-26 21:46:01,757][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00239/00310] [00:06:39/00:01:56, 1.665s/it]
[2025-08-26 21:46:14,219][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00247/00310] [00:06:52/00:01:43, 1.661s/it]
[2025-08-26 21:46:27,053][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00255/00310] [00:07:04/00:01:29, 1.660s/it]
[2025-08-26 21:46:40,731][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00263/00310] [00:07:18/00:01:16, 1.661s/it]
[2025-08-26 21:46:53,994][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00271/00310] [00:07:31/00:01:03, 1.661s/it]
[2025-08-26 21:47:07,546][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00279/00310] [00:07:45/00:00:49, 1.662s/it]
[2025-08-26 21:47:21,301][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00287/00310] [00:07:59/00:00:36, 1.664s/it]
[2025-08-26 21:47:34,579][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00295/00310] [00:08:12/00:00:23, 1.664s/it]
[2025-08-26 21:47:48,629][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 009241] [Batch 00303/00310] [00:08:26/00:00:09, 1.666s/it]
[2025-08-26 21:47:58,856][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.82957, valid_loss=2.39882
[2025-08-26 21:47:58,857][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-26 21:47:58,857][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.936
[2025-08-26 21:47:58,858][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.012
[2025-08-26 21:47:58,858][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.014
[2025-08-26 21:47:58,858][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.000
[2025-08-26 21:47:58,878][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 02:21:12, remaining time 21:10:54, 00:47:04 per epoch
[2025-08-26 21:48:05,895][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009248] [Batch 00008/03080] [00:00:05/00:37:21, 0.730s/it]: train_loss_raw=1.8286, running_loss=1.8531, LR=0.000100
[2025-08-26 21:48:12,372][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009256] [Batch 00016/03080] [00:00:12/00:39:18, 0.770s/it]: train_loss_raw=1.8289, running_loss=1.8506, LR=0.000100
[2025-08-26 21:48:18,593][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009264] [Batch 00024/03080] [00:00:18/00:39:20, 0.772s/it]: train_loss_raw=1.8203, running_loss=1.8494, LR=0.000100
[2025-08-26 21:48:24,893][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009272] [Batch 00032/03080] [00:00:24/00:39:25, 0.776s/it]: train_loss_raw=1.8796, running_loss=1.8459, LR=0.000100
[2025-08-26 21:48:31,495][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009280] [Batch 00040/03080] [00:00:31/00:39:49, 0.786s/it]: train_loss_raw=1.8209, running_loss=1.8423, LR=0.000100
[2025-08-26 21:48:38,183][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009288] [Batch 00048/03080] [00:00:38/00:40:08, 0.794s/it]: train_loss_raw=1.7484, running_loss=1.8422, LR=0.000100
[2025-08-26 21:48:44,836][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009296] [Batch 00056/03080] [00:00:44/00:40:18, 0.800s/it]: train_loss_raw=1.8149, running_loss=1.8446, LR=0.000100
[2025-08-26 21:48:51,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009304] [Batch 00064/03080] [00:00:51/00:40:13, 0.800s/it]: train_loss_raw=1.8555, running_loss=1.8431, LR=0.000100
[2025-08-26 21:48:57,389][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009312] [Batch 00072/03080] [00:00:57/00:39:55, 0.796s/it]: train_loss_raw=1.8031, running_loss=1.8413, LR=0.000100
[2025-08-26 21:49:03,523][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009320] [Batch 00080/03080] [00:01:03/00:39:39, 0.793s/it]: train_loss_raw=1.8318, running_loss=1.8384, LR=0.000100
[2025-08-26 21:49:09,691][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009328] [Batch 00088/03080] [00:01:09/00:39:27, 0.791s/it]: train_loss_raw=1.8918, running_loss=1.8371, LR=0.000100
[2025-08-26 21:49:15,847][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009336] [Batch 00096/03080] [00:01:15/00:39:15, 0.789s/it]: train_loss_raw=1.8430, running_loss=1.8367, LR=0.000100
[2025-08-26 21:49:22,337][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009344] [Batch 00104/03080] [00:01:22/00:39:14, 0.791s/it]: train_loss_raw=1.8038, running_loss=1.8351, LR=0.000100
[2025-08-26 21:49:28,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009352] [Batch 00112/03080] [00:01:28/00:39:15, 0.794s/it]: train_loss_raw=1.8731, running_loss=1.8339, LR=0.000100
[2025-08-26 21:49:35,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009360] [Batch 00120/03080] [00:01:35/00:39:14, 0.796s/it]: train_loss_raw=1.8624, running_loss=1.8325, LR=0.000100
[2025-08-26 21:49:41,714][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009368] [Batch 00128/03080] [00:01:41/00:39:04, 0.794s/it]: train_loss_raw=1.7007, running_loss=1.8302, LR=0.000100
[2025-08-26 21:49:47,855][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009376] [Batch 00136/03080] [00:01:47/00:38:53, 0.793s/it]: train_loss_raw=1.8558, running_loss=1.8276, LR=0.000100
[2025-08-26 21:49:54,019][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009384] [Batch 00144/03080] [00:01:53/00:38:43, 0.791s/it]: train_loss_raw=1.8833, running_loss=1.8273, LR=0.000100
[2025-08-26 21:50:00,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009392] [Batch 00152/03080] [00:02:00/00:38:36, 0.791s/it]: train_loss_raw=1.7704, running_loss=1.8262, LR=0.000100
[2025-08-26 21:50:06,969][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009400] [Batch 00160/03080] [00:02:06/00:38:36, 0.793s/it]: train_loss_raw=1.8104, running_loss=1.8244, LR=0.000100
[2025-08-26 21:50:13,653][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009408] [Batch 00168/03080] [00:02:13/00:38:35, 0.795s/it]: train_loss_raw=1.8633, running_loss=1.8267, LR=0.000100
[2025-08-26 21:50:20,361][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009416] [Batch 00176/03080] [00:02:20/00:38:35, 0.797s/it]: train_loss_raw=1.8279, running_loss=1.8284, LR=0.000100
[2025-08-26 21:50:26,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009424] [Batch 00184/03080] [00:02:26/00:38:30, 0.798s/it]: train_loss_raw=1.7667, running_loss=1.8256, LR=0.000100
[2025-08-26 21:50:33,250][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009432] [Batch 00192/03080] [00:02:33/00:38:24, 0.798s/it]: train_loss_raw=1.7944, running_loss=1.8229, LR=0.000100
[2025-08-26 21:50:39,448][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009440] [Batch 00200/03080] [00:02:39/00:38:15, 0.797s/it]: train_loss_raw=1.8798, running_loss=1.8208, LR=0.000100
[2025-08-26 21:50:45,698][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009448] [Batch 00208/03080] [00:02:45/00:38:07, 0.796s/it]: train_loss_raw=1.7854, running_loss=1.8212, LR=0.000100
[2025-08-26 21:50:52,036][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009456] [Batch 00216/03080] [00:02:51/00:38:00, 0.796s/it]: train_loss_raw=1.7372, running_loss=1.8207, LR=0.000100
[2025-08-26 21:50:58,483][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009464] [Batch 00224/03080] [00:02:58/00:37:54, 0.797s/it]: train_loss_raw=1.7597, running_loss=1.8183, LR=0.000100
[2025-08-26 21:51:04,802][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009472] [Batch 00232/03080] [00:03:04/00:37:47, 0.796s/it]: train_loss_raw=1.8852, running_loss=1.8162, LR=0.000100
[2025-08-26 21:51:11,079][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009480] [Batch 00240/03080] [00:03:11/00:37:40, 0.796s/it]: train_loss_raw=1.8346, running_loss=1.8154, LR=0.000100
[2025-08-26 21:51:17,334][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009488] [Batch 00248/03080] [00:03:17/00:37:32, 0.795s/it]: train_loss_raw=1.8420, running_loss=1.8149, LR=0.000100
[2025-08-26 21:51:23,950][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009496] [Batch 00256/03080] [00:03:23/00:37:29, 0.796s/it]: train_loss_raw=1.8616, running_loss=1.8131, LR=0.000100
[2025-08-26 21:51:30,533][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009504] [Batch 00264/03080] [00:03:30/00:37:25, 0.797s/it]: train_loss_raw=1.8369, running_loss=1.8109, LR=0.000100
[2025-08-26 21:51:37,083][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009512] [Batch 00272/03080] [00:03:37/00:37:20, 0.798s/it]: train_loss_raw=1.7963, running_loss=1.8096, LR=0.000100
[2025-08-26 21:51:43,736][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009520] [Batch 00280/03080] [00:03:43/00:37:16, 0.799s/it]: train_loss_raw=1.7361, running_loss=1.8100, LR=0.000100
[2025-08-26 21:51:50,421][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009528] [Batch 00288/03080] [00:03:50/00:37:13, 0.800s/it]: train_loss_raw=1.7665, running_loss=1.8083, LR=0.000100
[2025-08-26 21:51:57,115][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009536] [Batch 00296/03080] [00:03:57/00:37:09, 0.801s/it]: train_loss_raw=1.8844, running_loss=1.8087, LR=0.000100
[2025-08-26 21:52:03,740][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009544] [Batch 00304/03080] [00:04:03/00:37:05, 0.802s/it]: train_loss_raw=1.8005, running_loss=1.8065, LR=0.000100
[2025-08-26 21:52:10,418][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009552] [Batch 00312/03080] [00:04:10/00:37:01, 0.802s/it]: train_loss_raw=1.9101, running_loss=1.8082, LR=0.000100
[2025-08-26 21:52:17,073][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009560] [Batch 00320/03080] [00:04:17/00:36:56, 0.803s/it]: train_loss_raw=1.7913, running_loss=1.8082, LR=0.000100
[2025-08-26 21:52:23,458][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009568] [Batch 00328/03080] [00:04:23/00:36:50, 0.803s/it]: train_loss_raw=1.7833, running_loss=1.8101, LR=0.000100
[2025-08-26 21:52:29,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009576] [Batch 00336/03080] [00:04:29/00:36:43, 0.803s/it]: train_loss_raw=1.7875, running_loss=1.8091, LR=0.000100
[2025-08-26 21:52:35,926][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009584] [Batch 00344/03080] [00:04:35/00:36:34, 0.802s/it]: train_loss_raw=1.7870, running_loss=1.8084, LR=0.000100
[2025-08-26 21:52:41,815][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009592] [Batch 00352/03080] [00:04:41/00:36:23, 0.800s/it]: train_loss_raw=1.8551, running_loss=1.8120, LR=0.000100
[2025-08-26 21:52:47,708][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009600] [Batch 00360/03080] [00:04:47/00:36:13, 0.799s/it]: train_loss_raw=1.6950, running_loss=1.8105, LR=0.000100
[2025-08-26 21:52:53,924][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009608] [Batch 00368/03080] [00:04:53/00:36:05, 0.799s/it]: train_loss_raw=1.7041, running_loss=1.8078, LR=0.000100
[2025-08-26 21:53:00,529][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009616] [Batch 00376/03080] [00:05:00/00:36:00, 0.799s/it]: train_loss_raw=1.8936, running_loss=1.8091, LR=0.000100
[2025-08-26 21:53:07,061][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009624] [Batch 00384/03080] [00:05:07/00:35:55, 0.799s/it]: train_loss_raw=1.8219, running_loss=1.8104, LR=0.000100
[2025-08-26 21:53:13,421][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009632] [Batch 00392/03080] [00:05:13/00:35:48, 0.799s/it]: train_loss_raw=1.6728, running_loss=1.8076, LR=0.000100
[2025-08-26 21:53:19,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009640] [Batch 00400/03080] [00:05:19/00:35:40, 0.799s/it]: train_loss_raw=1.7132, running_loss=1.8061, LR=0.000100
[2025-08-26 21:53:25,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009648] [Batch 00408/03080] [00:05:25/00:35:32, 0.798s/it]: train_loss_raw=1.8155, running_loss=1.8069, LR=0.000100
[2025-08-26 21:53:31,922][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009656] [Batch 00416/03080] [00:05:31/00:35:25, 0.798s/it]: train_loss_raw=1.8008, running_loss=1.8042, LR=0.000100
[2025-08-26 21:53:38,017][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009664] [Batch 00424/03080] [00:05:37/00:35:17, 0.797s/it]: train_loss_raw=1.8504, running_loss=1.8032, LR=0.000100
[2025-08-26 21:53:44,135][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009672] [Batch 00432/03080] [00:05:44/00:35:09, 0.796s/it]: train_loss_raw=1.8143, running_loss=1.8019, LR=0.000100
[2025-08-26 21:53:50,329][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009680] [Batch 00440/03080] [00:05:50/00:35:01, 0.796s/it]: train_loss_raw=1.7553, running_loss=1.8024, LR=0.000100
[2025-08-26 21:53:56,478][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009688] [Batch 00448/03080] [00:05:56/00:34:53, 0.796s/it]: train_loss_raw=1.8374, running_loss=1.8016, LR=0.000100
[2025-08-26 21:54:02,638][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009696] [Batch 00456/03080] [00:06:02/00:34:46, 0.795s/it]: train_loss_raw=1.7591, running_loss=1.8008, LR=0.000100
[2025-08-26 21:54:08,840][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009704] [Batch 00464/03080] [00:06:08/00:34:39, 0.795s/it]: train_loss_raw=1.7684, running_loss=1.7998, LR=0.000100
[2025-08-26 21:54:15,006][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009712] [Batch 00472/03080] [00:06:14/00:34:31, 0.794s/it]: train_loss_raw=1.7706, running_loss=1.7981, LR=0.000100
[2025-08-26 21:54:21,284][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009720] [Batch 00480/03080] [00:06:21/00:34:24, 0.794s/it]: train_loss_raw=1.8040, running_loss=1.8005, LR=0.000100
[2025-08-26 21:54:27,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009728] [Batch 00488/03080] [00:06:27/00:34:18, 0.794s/it]: train_loss_raw=1.8425, running_loss=1.7989, LR=0.000100
[2025-08-26 21:54:33,657][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009736] [Batch 00496/03080] [00:06:33/00:34:10, 0.794s/it]: train_loss_raw=1.7816, running_loss=1.7998, LR=0.000100
[2025-08-26 21:54:39,861][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009744] [Batch 00504/03080] [00:06:39/00:34:03, 0.793s/it]: train_loss_raw=1.8139, running_loss=1.7987, LR=0.000100
[2025-08-26 21:54:45,998][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009752] [Batch 00512/03080] [00:06:45/00:33:56, 0.793s/it]: train_loss_raw=1.7885, running_loss=1.7946, LR=0.000100
[2025-08-26 21:54:52,232][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009760] [Batch 00520/03080] [00:06:52/00:33:49, 0.793s/it]: train_loss_raw=1.7668, running_loss=1.7940, LR=0.000100
[2025-08-26 21:54:59,102][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009768] [Batch 00528/03080] [00:06:59/00:33:45, 0.794s/it]: train_loss_raw=1.8058, running_loss=1.7939, LR=0.000100
[2025-08-26 21:55:05,968][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009776] [Batch 00536/03080] [00:07:05/00:33:41, 0.795s/it]: train_loss_raw=1.8119, running_loss=1.7945, LR=0.000100
[2025-08-26 21:55:13,033][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009784] [Batch 00544/03080] [00:07:12/00:33:38, 0.796s/it]: train_loss_raw=1.7540, running_loss=1.7963, LR=0.000100
[2025-08-26 21:55:19,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009792] [Batch 00552/03080] [00:07:19/00:33:33, 0.797s/it]: train_loss_raw=1.7052, running_loss=1.7956, LR=0.000100
[2025-08-26 21:55:26,898][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009800] [Batch 00560/03080] [00:07:26/00:33:30, 0.798s/it]: train_loss_raw=1.6882, running_loss=1.7944, LR=0.000100
[2025-08-26 21:55:33,539][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009808] [Batch 00568/03080] [00:07:33/00:33:25, 0.798s/it]: train_loss_raw=1.7246, running_loss=1.7924, LR=0.000100
[2025-08-26 21:55:40,293][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009816] [Batch 00576/03080] [00:07:40/00:33:20, 0.799s/it]: train_loss_raw=1.7528, running_loss=1.7918, LR=0.000100
[2025-08-26 21:55:46,861][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009824] [Batch 00584/03080] [00:07:46/00:33:15, 0.799s/it]: train_loss_raw=1.8364, running_loss=1.7922, LR=0.000100
[2025-08-26 21:55:53,373][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009832] [Batch 00592/03080] [00:07:53/00:33:09, 0.800s/it]: train_loss_raw=1.7623, running_loss=1.7919, LR=0.000100
[2025-08-26 21:55:59,903][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009840] [Batch 00600/03080] [00:07:59/00:33:03, 0.800s/it]: train_loss_raw=1.7746, running_loss=1.7915, LR=0.000100
[2025-08-26 21:56:06,416][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009848] [Batch 00608/03080] [00:08:06/00:32:57, 0.800s/it]: train_loss_raw=1.8320, running_loss=1.7928, LR=0.000100
[2025-08-26 21:56:12,965][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009856] [Batch 00616/03080] [00:08:12/00:32:51, 0.800s/it]: train_loss_raw=1.7598, running_loss=1.7912, LR=0.000100
[2025-08-26 21:56:19,612][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009864] [Batch 00624/03080] [00:08:19/00:32:46, 0.801s/it]: train_loss_raw=1.8591, running_loss=1.7910, LR=0.000100
[2025-08-26 21:56:26,159][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009872] [Batch 00632/03080] [00:08:26/00:32:40, 0.801s/it]: train_loss_raw=1.8245, running_loss=1.7901, LR=0.000100
[2025-08-26 21:56:32,764][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009880] [Batch 00640/03080] [00:08:32/00:32:34, 0.801s/it]: train_loss_raw=1.7620, running_loss=1.7897, LR=0.000100
[2025-08-26 21:56:39,297][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009888] [Batch 00648/03080] [00:08:39/00:32:28, 0.801s/it]: train_loss_raw=1.7970, running_loss=1.7879, LR=0.000100
[2025-08-26 21:56:45,913][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009896] [Batch 00656/03080] [00:08:45/00:32:23, 0.802s/it]: train_loss_raw=1.7262, running_loss=1.7875, LR=0.000100
[2025-08-26 21:56:52,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009904] [Batch 00664/03080] [00:08:52/00:32:17, 0.802s/it]: train_loss_raw=1.7374, running_loss=1.7876, LR=0.000100
[2025-08-26 21:56:59,038][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009912] [Batch 00672/03080] [00:08:58/00:32:11, 0.802s/it]: train_loss_raw=1.6882, running_loss=1.7873, LR=0.000100
[2025-08-26 21:57:05,539][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009920] [Batch 00680/03080] [00:09:05/00:32:05, 0.802s/it]: train_loss_raw=1.7525, running_loss=1.7883, LR=0.000100
[2025-08-26 21:57:12,163][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009928] [Batch 00688/03080] [00:09:12/00:31:59, 0.802s/it]: train_loss_raw=1.8710, running_loss=1.7895, LR=0.000100
[2025-08-26 21:57:18,725][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009936] [Batch 00696/03080] [00:09:18/00:31:53, 0.803s/it]: train_loss_raw=1.7828, running_loss=1.7876, LR=0.000100
[2025-08-26 21:57:25,301][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009944] [Batch 00704/03080] [00:09:25/00:31:47, 0.803s/it]: train_loss_raw=1.8447, running_loss=1.7867, LR=0.000100
[2025-08-26 21:57:31,907][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009952] [Batch 00712/03080] [00:09:31/00:31:41, 0.803s/it]: train_loss_raw=1.7084, running_loss=1.7857, LR=0.000100
[2025-08-26 21:57:38,475][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009960] [Batch 00720/03080] [00:09:38/00:31:35, 0.803s/it]: train_loss_raw=1.7463, running_loss=1.7864, LR=0.000100
[2025-08-26 21:57:45,021][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009968] [Batch 00728/03080] [00:09:44/00:31:29, 0.804s/it]: train_loss_raw=1.8073, running_loss=1.7870, LR=0.000100
[2025-08-26 21:57:51,628][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009976] [Batch 00736/03080] [00:09:51/00:31:24, 0.804s/it]: train_loss_raw=1.7943, running_loss=1.7864, LR=0.000100
[2025-08-26 21:57:58,226][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009984] [Batch 00744/03080] [00:09:58/00:31:18, 0.804s/it]: train_loss_raw=1.7429, running_loss=1.7871, LR=0.000100
[2025-08-26 21:58:04,823][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 009992] [Batch 00752/03080] [00:10:04/00:31:12, 0.804s/it]: train_loss_raw=1.8686, running_loss=1.7832, LR=0.000100
[2025-08-26 21:58:11,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010000] [Batch 00760/03080] [00:10:11/00:31:06, 0.804s/it]: train_loss_raw=1.8154, running_loss=1.7824, LR=0.000100
[2025-08-26 21:58:23,869][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010008] [Batch 00768/03080] [00:10:23/00:31:17, 0.812s/it]: train_loss_raw=1.8412, running_loss=1.7824, LR=0.000100
[2025-08-26 21:58:30,391][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010016] [Batch 00776/03080] [00:10:30/00:31:11, 0.812s/it]: train_loss_raw=1.7750, running_loss=1.7816, LR=0.000100
[2025-08-26 21:58:36,975][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010024] [Batch 00784/03080] [00:10:36/00:31:05, 0.812s/it]: train_loss_raw=1.8666, running_loss=1.7838, LR=0.000100
[2025-08-26 21:58:43,584][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010032] [Batch 00792/03080] [00:10:43/00:30:59, 0.813s/it]: train_loss_raw=1.7005, running_loss=1.7841, LR=0.000100
[2025-08-26 21:58:50,180][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010040] [Batch 00800/03080] [00:10:50/00:30:52, 0.813s/it]: train_loss_raw=1.8407, running_loss=1.7845, LR=0.000100
[2025-08-26 21:58:56,731][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010048] [Batch 00808/03080] [00:10:56/00:30:46, 0.813s/it]: train_loss_raw=1.7758, running_loss=1.7859, LR=0.000100
[2025-08-26 21:59:03,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010056] [Batch 00816/03080] [00:11:03/00:30:40, 0.813s/it]: train_loss_raw=1.7387, running_loss=1.7836, LR=0.000100
[2025-08-26 21:59:09,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010064] [Batch 00824/03080] [00:11:09/00:30:33, 0.813s/it]: train_loss_raw=1.8423, running_loss=1.7819, LR=0.000100
[2025-08-26 21:59:16,388][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010072] [Batch 00832/03080] [00:11:16/00:30:27, 0.813s/it]: train_loss_raw=1.6714, running_loss=1.7813, LR=0.000100
[2025-08-26 21:59:22,954][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010080] [Batch 00840/03080] [00:11:22/00:30:21, 0.813s/it]: train_loss_raw=1.8019, running_loss=1.7806, LR=0.000100
[2025-08-26 21:59:29,517][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010088] [Batch 00848/03080] [00:11:29/00:30:14, 0.813s/it]: train_loss_raw=1.7931, running_loss=1.7808, LR=0.000100
[2025-08-26 21:59:36,037][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010096] [Batch 00856/03080] [00:11:35/00:30:08, 0.813s/it]: train_loss_raw=1.7173, running_loss=1.7796, LR=0.000100
[2025-08-26 21:59:42,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010104] [Batch 00864/03080] [00:11:42/00:30:01, 0.813s/it]: train_loss_raw=1.7019, running_loss=1.7781, LR=0.000100
[2025-08-26 21:59:49,137][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010112] [Batch 00872/03080] [00:11:49/00:29:55, 0.813s/it]: train_loss_raw=1.7288, running_loss=1.7777, LR=0.000100
[2025-08-26 21:59:55,621][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010120] [Batch 00880/03080] [00:11:55/00:29:48, 0.813s/it]: train_loss_raw=1.7766, running_loss=1.7776, LR=0.000100
[2025-08-26 22:00:02,174][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010128] [Batch 00888/03080] [00:12:02/00:29:42, 0.813s/it]: train_loss_raw=1.7088, running_loss=1.7762, LR=0.000100
[2025-08-26 22:00:08,726][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010136] [Batch 00896/03080] [00:12:08/00:29:36, 0.813s/it]: train_loss_raw=1.7580, running_loss=1.7757, LR=0.000100
[2025-08-26 22:00:15,328][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010144] [Batch 00904/03080] [00:12:15/00:29:29, 0.813s/it]: train_loss_raw=1.7363, running_loss=1.7740, LR=0.000100
[2025-08-26 22:00:21,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010152] [Batch 00912/03080] [00:12:21/00:29:23, 0.813s/it]: train_loss_raw=1.7686, running_loss=1.7761, LR=0.000100
[2025-08-26 22:00:28,459][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010160] [Batch 00920/03080] [00:12:28/00:29:17, 0.813s/it]: train_loss_raw=1.8382, running_loss=1.7771, LR=0.000100
[2025-08-26 22:00:34,946][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010168] [Batch 00928/03080] [00:12:34/00:29:10, 0.813s/it]: train_loss_raw=1.7057, running_loss=1.7753, LR=0.000100
[2025-08-26 22:00:41,076][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010176] [Batch 00936/03080] [00:12:41/00:29:03, 0.813s/it]: train_loss_raw=1.8170, running_loss=1.7757, LR=0.000100
[2025-08-26 22:00:47,144][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010184] [Batch 00944/03080] [00:12:47/00:28:55, 0.813s/it]: train_loss_raw=1.7138, running_loss=1.7761, LR=0.000100
[2025-08-26 22:00:53,294][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010192] [Batch 00952/03080] [00:12:53/00:28:48, 0.812s/it]: train_loss_raw=1.7389, running_loss=1.7760, LR=0.000100
[2025-08-26 22:00:59,482][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010200] [Batch 00960/03080] [00:12:59/00:28:41, 0.812s/it]: train_loss_raw=1.8016, running_loss=1.7749, LR=0.000100
[2025-08-26 22:01:05,605][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010208] [Batch 00968/03080] [00:13:05/00:28:33, 0.812s/it]: train_loss_raw=1.7268, running_loss=1.7719, LR=0.000100
[2025-08-26 22:01:11,736][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010216] [Batch 00976/03080] [00:13:11/00:28:26, 0.811s/it]: train_loss_raw=1.7498, running_loss=1.7718, LR=0.000100
[2025-08-26 22:01:17,853][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010224] [Batch 00984/03080] [00:13:17/00:28:19, 0.811s/it]: train_loss_raw=1.8156, running_loss=1.7735, LR=0.000100
[2025-08-26 22:01:23,997][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010232] [Batch 00992/03080] [00:13:23/00:28:12, 0.810s/it]: train_loss_raw=1.6862, running_loss=1.7730, LR=0.000100
[2025-08-26 22:01:30,273][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010240] [Batch 01000/03080] [00:13:30/00:28:05, 0.810s/it]: train_loss_raw=1.7229, running_loss=1.7716, LR=0.000100
[2025-08-26 22:01:36,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010248] [Batch 01008/03080] [00:13:36/00:27:58, 0.810s/it]: train_loss_raw=1.7200, running_loss=1.7698, LR=0.000100
[2025-08-26 22:01:43,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010256] [Batch 01016/03080] [00:13:43/00:27:52, 0.810s/it]: train_loss_raw=1.7283, running_loss=1.7669, LR=0.000100
[2025-08-26 22:01:49,898][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010264] [Batch 01024/03080] [00:13:49/00:27:46, 0.810s/it]: train_loss_raw=1.7979, running_loss=1.7678, LR=0.000100
[2025-08-26 22:01:56,575][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010272] [Batch 01032/03080] [00:13:56/00:27:40, 0.811s/it]: train_loss_raw=1.6390, running_loss=1.7674, LR=0.000100
[2025-08-26 22:02:03,283][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010280] [Batch 01040/03080] [00:14:03/00:27:34, 0.811s/it]: train_loss_raw=1.7347, running_loss=1.7662, LR=0.000100
[2025-08-26 22:02:09,883][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010288] [Batch 01048/03080] [00:14:09/00:27:27, 0.811s/it]: train_loss_raw=1.7993, running_loss=1.7648, LR=0.000100
[2025-08-26 22:02:16,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010296] [Batch 01056/03080] [00:14:16/00:27:21, 0.811s/it]: train_loss_raw=1.8246, running_loss=1.7645, LR=0.000100
[2025-08-26 22:02:23,001][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010304] [Batch 01064/03080] [00:14:22/00:27:15, 0.811s/it]: train_loss_raw=1.7732, running_loss=1.7633, LR=0.000100
[2025-08-26 22:02:29,547][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010312] [Batch 01072/03080] [00:14:29/00:27:08, 0.811s/it]: train_loss_raw=1.7507, running_loss=1.7628, LR=0.000100
[2025-08-26 22:02:36,160][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010320] [Batch 01080/03080] [00:14:36/00:27:02, 0.811s/it]: train_loss_raw=1.7507, running_loss=1.7638, LR=0.000100
[2025-08-26 22:02:42,679][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010328] [Batch 01088/03080] [00:14:42/00:26:55, 0.811s/it]: train_loss_raw=1.7346, running_loss=1.7638, LR=0.000100
[2025-08-26 22:02:49,247][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010336] [Batch 01096/03080] [00:14:49/00:26:49, 0.811s/it]: train_loss_raw=1.7778, running_loss=1.7641, LR=0.000100
[2025-08-26 22:02:55,900][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010344] [Batch 01104/03080] [00:14:55/00:26:43, 0.811s/it]: train_loss_raw=1.6981, running_loss=1.7614, LR=0.000100
[2025-08-26 22:03:02,461][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010352] [Batch 01112/03080] [00:15:02/00:26:37, 0.812s/it]: train_loss_raw=1.6607, running_loss=1.7586, LR=0.000100
[2025-08-26 22:03:08,914][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010360] [Batch 01120/03080] [00:15:08/00:26:30, 0.811s/it]: train_loss_raw=1.6881, running_loss=1.7581, LR=0.000100
[2025-08-26 22:03:15,316][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010368] [Batch 01128/03080] [00:15:15/00:26:23, 0.811s/it]: train_loss_raw=1.6600, running_loss=1.7561, LR=0.000100
[2025-08-26 22:03:21,490][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010376] [Batch 01136/03080] [00:15:21/00:26:16, 0.811s/it]: train_loss_raw=1.8241, running_loss=1.7581, LR=0.000100
[2025-08-26 22:03:27,620][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010384] [Batch 01144/03080] [00:15:27/00:26:09, 0.811s/it]: train_loss_raw=1.8084, running_loss=1.7573, LR=0.000100
[2025-08-26 22:03:33,734][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010392] [Batch 01152/03080] [00:15:33/00:26:02, 0.810s/it]: train_loss_raw=1.7567, running_loss=1.7578, LR=0.000100
[2025-08-26 22:03:39,976][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010400] [Batch 01160/03080] [00:15:39/00:25:55, 0.810s/it]: train_loss_raw=1.7867, running_loss=1.7570, LR=0.000100
[2025-08-26 22:03:46,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010408] [Batch 01168/03080] [00:15:46/00:25:48, 0.810s/it]: train_loss_raw=1.7153, running_loss=1.7561, LR=0.000100
[2025-08-26 22:03:52,274][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010416] [Batch 01176/03080] [00:15:52/00:25:41, 0.810s/it]: train_loss_raw=1.6708, running_loss=1.7566, LR=0.000100
[2025-08-26 22:03:58,383][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010424] [Batch 01184/03080] [00:15:58/00:25:34, 0.809s/it]: train_loss_raw=1.6705, running_loss=1.7551, LR=0.000100
[2025-08-26 22:04:04,599][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010432] [Batch 01192/03080] [00:16:04/00:25:27, 0.809s/it]: train_loss_raw=1.8547, running_loss=1.7557, LR=0.000100
[2025-08-26 22:04:10,786][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010440] [Batch 01200/03080] [00:16:10/00:25:20, 0.809s/it]: train_loss_raw=1.7357, running_loss=1.7543, LR=0.000100
[2025-08-26 22:04:17,067][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010448] [Batch 01208/03080] [00:16:17/00:25:14, 0.809s/it]: train_loss_raw=1.7253, running_loss=1.7511, LR=0.000100
[2025-08-26 22:04:23,317][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010456] [Batch 01216/03080] [00:16:23/00:25:07, 0.809s/it]: train_loss_raw=1.6767, running_loss=1.7512, LR=0.000100
[2025-08-26 22:04:29,417][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010464] [Batch 01224/03080] [00:16:29/00:25:00, 0.808s/it]: train_loss_raw=1.6739, running_loss=1.7524, LR=0.000100
[2025-08-26 22:04:35,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010472] [Batch 01232/03080] [00:16:35/00:24:53, 0.808s/it]: train_loss_raw=1.8151, running_loss=1.7543, LR=0.000100
[2025-08-26 22:04:41,670][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010480] [Batch 01240/03080] [00:16:41/00:24:46, 0.808s/it]: train_loss_raw=1.7697, running_loss=1.7538, LR=0.000100
[2025-08-26 22:04:47,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010488] [Batch 01248/03080] [00:16:47/00:24:39, 0.808s/it]: train_loss_raw=1.7420, running_loss=1.7542, LR=0.000100
[2025-08-26 22:04:54,174][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010496] [Batch 01256/03080] [00:16:54/00:24:32, 0.807s/it]: train_loss_raw=1.7755, running_loss=1.7530, LR=0.000100
[2025-08-26 22:05:00,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010504] [Batch 01264/03080] [00:17:00/00:24:26, 0.807s/it]: train_loss_raw=1.7300, running_loss=1.7531, LR=0.000100
[2025-08-26 22:05:06,699][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010512] [Batch 01272/03080] [00:17:06/00:24:19, 0.807s/it]: train_loss_raw=1.6979, running_loss=1.7542, LR=0.000100
[2025-08-26 22:05:12,855][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010520] [Batch 01280/03080] [00:17:12/00:24:12, 0.807s/it]: train_loss_raw=1.7087, running_loss=1.7550, LR=0.000100
[2025-08-26 22:05:19,052][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010528] [Batch 01288/03080] [00:17:18/00:24:05, 0.807s/it]: train_loss_raw=1.7966, running_loss=1.7544, LR=0.000100
[2025-08-26 22:05:25,166][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010536] [Batch 01296/03080] [00:17:25/00:23:58, 0.806s/it]: train_loss_raw=1.8187, running_loss=1.7531, LR=0.000100
[2025-08-26 22:05:31,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010544] [Batch 01304/03080] [00:17:31/00:23:51, 0.806s/it]: train_loss_raw=1.6140, running_loss=1.7521, LR=0.000100
[2025-08-26 22:05:37,903][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010552] [Batch 01312/03080] [00:17:37/00:23:45, 0.806s/it]: train_loss_raw=1.7336, running_loss=1.7502, LR=0.000100
[2025-08-26 22:05:44,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010560] [Batch 01320/03080] [00:17:44/00:23:39, 0.806s/it]: train_loss_raw=1.7228, running_loss=1.7473, LR=0.000100
[2025-08-26 22:05:51,246][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010568] [Batch 01328/03080] [00:17:51/00:23:33, 0.807s/it]: train_loss_raw=1.7182, running_loss=1.7473, LR=0.000100
[2025-08-26 22:05:58,543][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010576] [Batch 01336/03080] [00:17:58/00:23:27, 0.807s/it]: train_loss_raw=1.8446, running_loss=1.7494, LR=0.000100
[2025-08-26 22:06:05,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010584] [Batch 01344/03080] [00:18:05/00:23:21, 0.807s/it]: train_loss_raw=1.7255, running_loss=1.7498, LR=0.000100
[2025-08-26 22:06:11,661][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010592] [Batch 01352/03080] [00:18:11/00:23:15, 0.807s/it]: train_loss_raw=1.7286, running_loss=1.7501, LR=0.000100
[2025-08-26 22:06:18,322][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010600] [Batch 01360/03080] [00:18:18/00:23:08, 0.808s/it]: train_loss_raw=1.6901, running_loss=1.7489, LR=0.000100
[2025-08-26 22:06:25,053][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010608] [Batch 01368/03080] [00:18:24/00:23:02, 0.808s/it]: train_loss_raw=1.7382, running_loss=1.7482, LR=0.000100
[2025-08-26 22:06:31,602][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010616] [Batch 01376/03080] [00:18:31/00:22:56, 0.808s/it]: train_loss_raw=1.6490, running_loss=1.7458, LR=0.000100
[2025-08-26 22:06:37,776][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010624] [Batch 01384/03080] [00:18:37/00:22:49, 0.808s/it]: train_loss_raw=1.7115, running_loss=1.7451, LR=0.000100
[2025-08-26 22:06:43,951][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010632] [Batch 01392/03080] [00:18:43/00:22:42, 0.807s/it]: train_loss_raw=1.8333, running_loss=1.7460, LR=0.000100
[2025-08-26 22:06:50,149][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010640] [Batch 01400/03080] [00:18:50/00:22:36, 0.807s/it]: train_loss_raw=1.8072, running_loss=1.7454, LR=0.000100
[2025-08-26 22:06:56,240][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010648] [Batch 01408/03080] [00:18:56/00:22:29, 0.807s/it]: train_loss_raw=1.7535, running_loss=1.7450, LR=0.000100
[2025-08-26 22:07:02,369][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010656] [Batch 01416/03080] [00:19:02/00:22:22, 0.807s/it]: train_loss_raw=1.7647, running_loss=1.7467, LR=0.000100
[2025-08-26 22:07:08,502][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010664] [Batch 01424/03080] [00:19:08/00:22:15, 0.806s/it]: train_loss_raw=1.8323, running_loss=1.7479, LR=0.000100
[2025-08-26 22:07:14,597][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010672] [Batch 01432/03080] [00:19:14/00:22:08, 0.806s/it]: train_loss_raw=1.7253, running_loss=1.7470, LR=0.000100
[2025-08-26 22:07:20,753][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010680] [Batch 01440/03080] [00:19:20/00:22:01, 0.806s/it]: train_loss_raw=1.8427, running_loss=1.7474, LR=0.000100
[2025-08-26 22:07:26,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010688] [Batch 01448/03080] [00:19:26/00:21:55, 0.806s/it]: train_loss_raw=1.7482, running_loss=1.7487, LR=0.000100
[2025-08-26 22:07:33,085][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010696] [Batch 01456/03080] [00:19:33/00:21:48, 0.806s/it]: train_loss_raw=1.6903, running_loss=1.7485, LR=0.000100
[2025-08-26 22:07:39,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010704] [Batch 01464/03080] [00:19:39/00:21:41, 0.805s/it]: train_loss_raw=1.7267, running_loss=1.7484, LR=0.000100
[2025-08-26 22:07:45,321][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010712] [Batch 01472/03080] [00:19:45/00:21:34, 0.805s/it]: train_loss_raw=1.6038, running_loss=1.7457, LR=0.000100
[2025-08-26 22:07:51,485][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010720] [Batch 01480/03080] [00:19:51/00:21:28, 0.805s/it]: train_loss_raw=1.8150, running_loss=1.7452, LR=0.000100
[2025-08-26 22:07:57,646][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010728] [Batch 01488/03080] [00:19:57/00:21:21, 0.805s/it]: train_loss_raw=1.7112, running_loss=1.7447, LR=0.000100
[2025-08-26 22:08:04,078][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010736] [Batch 01496/03080] [00:20:04/00:21:14, 0.805s/it]: train_loss_raw=1.7410, running_loss=1.7449, LR=0.000100
[2025-08-26 22:08:10,663][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010744] [Batch 01504/03080] [00:20:10/00:21:08, 0.805s/it]: train_loss_raw=1.7481, running_loss=1.7432, LR=0.000100
[2025-08-26 22:08:17,306][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010752] [Batch 01512/03080] [00:20:17/00:21:02, 0.805s/it]: train_loss_raw=1.8508, running_loss=1.7441, LR=0.000100
[2025-08-26 22:08:23,813][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010760] [Batch 01520/03080] [00:20:23/00:20:55, 0.805s/it]: train_loss_raw=1.8021, running_loss=1.7426, LR=0.000100
[2025-08-26 22:08:30,416][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010768] [Batch 01528/03080] [00:20:30/00:20:49, 0.805s/it]: train_loss_raw=1.8058, running_loss=1.7434, LR=0.000100
[2025-08-26 22:08:37,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010776] [Batch 01536/03080] [00:20:36/00:20:43, 0.805s/it]: train_loss_raw=1.7260, running_loss=1.7424, LR=0.000100
[2025-08-26 22:08:43,623][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010784] [Batch 01544/03080] [00:20:43/00:20:37, 0.805s/it]: train_loss_raw=1.6531, running_loss=1.7407, LR=0.000100
[2025-08-26 22:08:50,279][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010792] [Batch 01552/03080] [00:20:50/00:20:30, 0.806s/it]: train_loss_raw=1.7217, running_loss=1.7403, LR=0.000100
[2025-08-26 22:08:56,867][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010800] [Batch 01560/03080] [00:20:56/00:20:24, 0.806s/it]: train_loss_raw=1.6784, running_loss=1.7412, LR=0.000100
[2025-08-26 22:09:03,424][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010808] [Batch 01568/03080] [00:21:03/00:20:18, 0.806s/it]: train_loss_raw=1.6930, running_loss=1.7414, LR=0.000100
[2025-08-26 22:09:10,229][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010816] [Batch 01576/03080] [00:21:10/00:20:12, 0.806s/it]: train_loss_raw=1.7714, running_loss=1.7375, LR=0.000100
[2025-08-26 22:09:16,822][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010824] [Batch 01584/03080] [00:21:16/00:20:05, 0.806s/it]: train_loss_raw=1.6997, running_loss=1.7383, LR=0.000100
[2025-08-26 22:09:23,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010832] [Batch 01592/03080] [00:21:23/00:19:59, 0.806s/it]: train_loss_raw=1.7910, running_loss=1.7385, LR=0.000100
[2025-08-26 22:09:30,260][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010840] [Batch 01600/03080] [00:21:30/00:19:53, 0.806s/it]: train_loss_raw=1.8109, running_loss=1.7398, LR=0.000100
[2025-08-26 22:09:37,058][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010848] [Batch 01608/03080] [00:21:37/00:19:47, 0.807s/it]: train_loss_raw=1.7676, running_loss=1.7408, LR=0.000100
[2025-08-26 22:09:43,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010856] [Batch 01616/03080] [00:21:43/00:19:41, 0.807s/it]: train_loss_raw=1.7162, running_loss=1.7400, LR=0.000100
[2025-08-26 22:09:50,565][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010864] [Batch 01624/03080] [00:21:50/00:19:34, 0.807s/it]: train_loss_raw=1.7557, running_loss=1.7390, LR=0.000100
[2025-08-26 22:09:57,278][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010872] [Batch 01632/03080] [00:21:57/00:19:28, 0.807s/it]: train_loss_raw=1.7378, running_loss=1.7372, LR=0.000100
[2025-08-26 22:10:04,089][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010880] [Batch 01640/03080] [00:22:04/00:19:22, 0.807s/it]: train_loss_raw=1.7884, running_loss=1.7370, LR=0.000100
[2025-08-26 22:10:10,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010888] [Batch 01648/03080] [00:22:10/00:19:16, 0.808s/it]: train_loss_raw=1.7049, running_loss=1.7364, LR=0.000100
[2025-08-26 22:10:17,552][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010896] [Batch 01656/03080] [00:22:17/00:19:10, 0.808s/it]: train_loss_raw=1.7658, running_loss=1.7377, LR=0.000100
[2025-08-26 22:10:24,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010904] [Batch 01664/03080] [00:22:24/00:19:03, 0.808s/it]: train_loss_raw=1.6425, running_loss=1.7375, LR=0.000100
[2025-08-26 22:10:31,075][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010912] [Batch 01672/03080] [00:22:31/00:18:57, 0.808s/it]: train_loss_raw=1.8009, running_loss=1.7393, LR=0.000100
[2025-08-26 22:10:37,705][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010920] [Batch 01680/03080] [00:22:37/00:18:51, 0.808s/it]: train_loss_raw=1.7929, running_loss=1.7409, LR=0.000100
[2025-08-26 22:10:44,348][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010928] [Batch 01688/03080] [00:22:44/00:18:45, 0.808s/it]: train_loss_raw=1.6294, running_loss=1.7413, LR=0.000100
[2025-08-26 22:10:50,970][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010936] [Batch 01696/03080] [00:22:50/00:18:38, 0.808s/it]: train_loss_raw=1.7292, running_loss=1.7432, LR=0.000100
[2025-08-26 22:10:57,860][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010944] [Batch 01704/03080] [00:22:57/00:18:32, 0.809s/it]: train_loss_raw=1.7245, running_loss=1.7408, LR=0.000100
[2025-08-26 22:11:04,097][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010952] [Batch 01712/03080] [00:23:04/00:18:25, 0.808s/it]: train_loss_raw=1.7440, running_loss=1.7394, LR=0.000100
[2025-08-26 22:11:10,251][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010960] [Batch 01720/03080] [00:23:10/00:18:19, 0.808s/it]: train_loss_raw=1.7187, running_loss=1.7356, LR=0.000100
[2025-08-26 22:11:16,459][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010968] [Batch 01728/03080] [00:23:16/00:18:12, 0.808s/it]: train_loss_raw=1.7586, running_loss=1.7358, LR=0.000100
[2025-08-26 22:11:22,778][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010976] [Batch 01736/03080] [00:23:22/00:18:05, 0.808s/it]: train_loss_raw=1.7342, running_loss=1.7327, LR=0.000100
[2025-08-26 22:11:29,142][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010984] [Batch 01744/03080] [00:23:29/00:17:59, 0.808s/it]: train_loss_raw=1.7845, running_loss=1.7311, LR=0.000100
[2025-08-26 22:11:35,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 010992] [Batch 01752/03080] [00:23:35/00:17:52, 0.808s/it]: train_loss_raw=1.6734, running_loss=1.7317, LR=0.000100
[2025-08-26 22:11:41,662][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011000] [Batch 01760/03080] [00:23:41/00:17:46, 0.808s/it]: train_loss_raw=1.7444, running_loss=1.7315, LR=0.000100
[2025-08-26 22:11:48,125][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011008] [Batch 01768/03080] [00:23:48/00:17:39, 0.808s/it]: train_loss_raw=1.6109, running_loss=1.7317, LR=0.000100
[2025-08-26 22:11:54,720][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011016] [Batch 01776/03080] [00:23:54/00:17:33, 0.808s/it]: train_loss_raw=1.6666, running_loss=1.7333, LR=0.000100
[2025-08-26 22:12:01,468][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011024] [Batch 01784/03080] [00:24:01/00:17:27, 0.808s/it]: train_loss_raw=1.6904, running_loss=1.7312, LR=0.000100
[2025-08-26 22:12:08,029][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011032] [Batch 01792/03080] [00:24:07/00:17:20, 0.808s/it]: train_loss_raw=1.7361, running_loss=1.7305, LR=0.000100
[2025-08-26 22:12:14,606][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011040] [Batch 01800/03080] [00:24:14/00:17:14, 0.808s/it]: train_loss_raw=1.6733, running_loss=1.7290, LR=0.000100
[2025-08-26 22:12:21,109][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011048] [Batch 01808/03080] [00:24:21/00:17:07, 0.808s/it]: train_loss_raw=1.7478, running_loss=1.7280, LR=0.000100
[2025-08-26 22:12:27,718][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011056] [Batch 01816/03080] [00:24:27/00:17:01, 0.808s/it]: train_loss_raw=1.7683, running_loss=1.7295, LR=0.000100
[2025-08-26 22:12:34,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011064] [Batch 01824/03080] [00:24:33/00:16:54, 0.808s/it]: train_loss_raw=1.8250, running_loss=1.7315, LR=0.000100
[2025-08-26 22:12:40,334][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011072] [Batch 01832/03080] [00:24:40/00:16:48, 0.808s/it]: train_loss_raw=1.6531, running_loss=1.7281, LR=0.000100
[2025-08-26 22:12:47,018][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011080] [Batch 01840/03080] [00:24:46/00:16:42, 0.808s/it]: train_loss_raw=1.7777, running_loss=1.7280, LR=0.000100
[2025-08-26 22:12:53,682][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011088] [Batch 01848/03080] [00:24:53/00:16:35, 0.808s/it]: train_loss_raw=1.6984, running_loss=1.7279, LR=0.000100
[2025-08-26 22:12:59,944][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011096] [Batch 01856/03080] [00:24:59/00:16:29, 0.808s/it]: train_loss_raw=1.6694, running_loss=1.7272, LR=0.000100
[2025-08-26 22:13:06,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011104] [Batch 01864/03080] [00:25:06/00:16:22, 0.808s/it]: train_loss_raw=1.6843, running_loss=1.7278, LR=0.000100
[2025-08-26 22:13:12,792][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011112] [Batch 01872/03080] [00:25:12/00:16:16, 0.808s/it]: train_loss_raw=1.6545, running_loss=1.7270, LR=0.000100
[2025-08-26 22:13:19,469][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011120] [Batch 01880/03080] [00:25:19/00:16:09, 0.808s/it]: train_loss_raw=1.7238, running_loss=1.7291, LR=0.000100
[2025-08-26 22:13:25,964][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011128] [Batch 01888/03080] [00:25:25/00:16:03, 0.808s/it]: train_loss_raw=1.7039, running_loss=1.7258, LR=0.000100
[2025-08-26 22:13:32,624][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011136] [Batch 01896/03080] [00:25:32/00:15:57, 0.808s/it]: train_loss_raw=1.6705, running_loss=1.7256, LR=0.000100
[2025-08-26 22:13:39,303][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011144] [Batch 01904/03080] [00:25:39/00:15:50, 0.808s/it]: train_loss_raw=1.6867, running_loss=1.7259, LR=0.000100
[2025-08-26 22:13:45,696][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011152] [Batch 01912/03080] [00:25:45/00:15:44, 0.808s/it]: train_loss_raw=1.7067, running_loss=1.7230, LR=0.000100
[2025-08-26 22:13:51,834][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011160] [Batch 01920/03080] [00:25:51/00:15:37, 0.808s/it]: train_loss_raw=1.7021, running_loss=1.7237, LR=0.000100
[2025-08-26 22:13:57,998][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011168] [Batch 01928/03080] [00:25:57/00:15:30, 0.808s/it]: train_loss_raw=1.6695, running_loss=1.7202, LR=0.000100
[2025-08-26 22:14:04,259][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011176] [Batch 01936/03080] [00:26:04/00:15:24, 0.808s/it]: train_loss_raw=1.6834, running_loss=1.7170, LR=0.000100
[2025-08-26 22:14:10,829][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011184] [Batch 01944/03080] [00:26:10/00:15:17, 0.808s/it]: train_loss_raw=1.6926, running_loss=1.7150, LR=0.000100
[2025-08-26 22:14:17,413][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011192] [Batch 01952/03080] [00:26:17/00:15:11, 0.808s/it]: train_loss_raw=1.6940, running_loss=1.7146, LR=0.000100
[2025-08-26 22:14:24,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011200] [Batch 01960/03080] [00:26:23/00:15:05, 0.808s/it]: train_loss_raw=1.6675, running_loss=1.7128, LR=0.000100
[2025-08-26 22:14:30,258][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011208] [Batch 01968/03080] [00:26:30/00:14:58, 0.808s/it]: train_loss_raw=1.6408, running_loss=1.7140, LR=0.000100
[2025-08-26 22:14:36,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011216] [Batch 01976/03080] [00:26:36/00:14:52, 0.808s/it]: train_loss_raw=1.6877, running_loss=1.7137, LR=0.000100
[2025-08-26 22:14:43,441][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011224] [Batch 01984/03080] [00:26:43/00:14:45, 0.808s/it]: train_loss_raw=1.7151, running_loss=1.7151, LR=0.000100
[2025-08-26 22:14:50,053][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011232] [Batch 01992/03080] [00:26:49/00:14:39, 0.808s/it]: train_loss_raw=1.7648, running_loss=1.7158, LR=0.000100
[2025-08-26 22:14:56,687][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011240] [Batch 02000/03080] [00:26:56/00:14:32, 0.808s/it]: train_loss_raw=1.7456, running_loss=1.7159, LR=0.000100
[2025-08-26 22:15:03,129][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011248] [Batch 02008/03080] [00:27:03/00:14:26, 0.808s/it]: train_loss_raw=1.6426, running_loss=1.7155, LR=0.000100
[2025-08-26 22:15:09,420][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011256] [Batch 02016/03080] [00:27:09/00:14:19, 0.808s/it]: train_loss_raw=1.8168, running_loss=1.7159, LR=0.000100
[2025-08-26 22:15:16,072][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011264] [Batch 02024/03080] [00:27:16/00:14:13, 0.808s/it]: train_loss_raw=1.7755, running_loss=1.7140, LR=0.000100
[2025-08-26 22:15:22,652][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011272] [Batch 02032/03080] [00:27:22/00:14:07, 0.808s/it]: train_loss_raw=1.6835, running_loss=1.7116, LR=0.000100
[2025-08-26 22:15:29,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011280] [Batch 02040/03080] [00:27:29/00:14:00, 0.808s/it]: train_loss_raw=1.7536, running_loss=1.7140, LR=0.000100
[2025-08-26 22:15:35,856][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011288] [Batch 02048/03080] [00:27:35/00:13:54, 0.808s/it]: train_loss_raw=1.7248, running_loss=1.7145, LR=0.000100
[2025-08-26 22:15:42,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011296] [Batch 02056/03080] [00:27:42/00:13:47, 0.809s/it]: train_loss_raw=1.6409, running_loss=1.7144, LR=0.000100
[2025-08-26 22:15:48,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011304] [Batch 02064/03080] [00:27:48/00:13:41, 0.809s/it]: train_loss_raw=1.7518, running_loss=1.7159, LR=0.000100
[2025-08-26 22:15:55,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011312] [Batch 02072/03080] [00:27:55/00:13:35, 0.809s/it]: train_loss_raw=1.7296, running_loss=1.7163, LR=0.000100
[2025-08-26 22:16:02,208][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011320] [Batch 02080/03080] [00:28:02/00:13:28, 0.809s/it]: train_loss_raw=1.6315, running_loss=1.7154, LR=0.000100
[2025-08-26 22:16:08,859][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011328] [Batch 02088/03080] [00:28:08/00:13:22, 0.809s/it]: train_loss_raw=1.6367, running_loss=1.7136, LR=0.000100
[2025-08-26 22:16:15,598][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011336] [Batch 02096/03080] [00:28:15/00:13:15, 0.809s/it]: train_loss_raw=1.7244, running_loss=1.7125, LR=0.000100
[2025-08-26 22:16:22,172][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011344] [Batch 02104/03080] [00:28:22/00:13:09, 0.809s/it]: train_loss_raw=1.7569, running_loss=1.7115, LR=0.000100
[2025-08-26 22:16:28,825][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011352] [Batch 02112/03080] [00:28:28/00:13:03, 0.809s/it]: train_loss_raw=1.5593, running_loss=1.7095, LR=0.000100
[2025-08-26 22:16:35,520][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011360] [Batch 02120/03080] [00:28:35/00:12:56, 0.809s/it]: train_loss_raw=1.6842, running_loss=1.7078, LR=0.000100
[2025-08-26 22:16:42,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011368] [Batch 02128/03080] [00:28:42/00:12:50, 0.809s/it]: train_loss_raw=1.7301, running_loss=1.7070, LR=0.000100
[2025-08-26 22:16:48,890][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011376] [Batch 02136/03080] [00:28:48/00:12:44, 0.809s/it]: train_loss_raw=1.6866, running_loss=1.7074, LR=0.000100
[2025-08-26 22:16:55,537][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011384] [Batch 02144/03080] [00:28:55/00:12:37, 0.809s/it]: train_loss_raw=1.6486, running_loss=1.7073, LR=0.000100
[2025-08-26 22:17:02,191][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011392] [Batch 02152/03080] [00:29:02/00:12:31, 0.810s/it]: train_loss_raw=1.6062, running_loss=1.7072, LR=0.000100
[2025-08-26 22:17:08,734][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011400] [Batch 02160/03080] [00:29:08/00:12:24, 0.810s/it]: train_loss_raw=1.7495, running_loss=1.7050, LR=0.000100
[2025-08-26 22:17:15,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011408] [Batch 02168/03080] [00:29:15/00:12:18, 0.810s/it]: train_loss_raw=1.5672, running_loss=1.7036, LR=0.000100
[2025-08-26 22:17:21,982][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011416] [Batch 02176/03080] [00:29:21/00:12:11, 0.810s/it]: train_loss_raw=1.6671, running_loss=1.7056, LR=0.000100
[2025-08-26 22:17:28,344][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011424] [Batch 02184/03080] [00:29:28/00:12:05, 0.810s/it]: train_loss_raw=1.7170, running_loss=1.7066, LR=0.000100
[2025-08-26 22:17:34,761][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011432] [Batch 02192/03080] [00:29:34/00:11:58, 0.810s/it]: train_loss_raw=1.6215, running_loss=1.7046, LR=0.000100
[2025-08-26 22:17:41,415][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011440] [Batch 02200/03080] [00:29:41/00:11:52, 0.810s/it]: train_loss_raw=1.7903, running_loss=1.7056, LR=0.000100
[2025-08-26 22:17:48,079][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011448] [Batch 02208/03080] [00:29:48/00:11:46, 0.810s/it]: train_loss_raw=1.7170, running_loss=1.7066, LR=0.000100
[2025-08-26 22:17:54,658][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011456] [Batch 02216/03080] [00:29:54/00:11:39, 0.810s/it]: train_loss_raw=1.7414, running_loss=1.7083, LR=0.000100
[2025-08-26 22:18:01,276][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011464] [Batch 02224/03080] [00:30:01/00:11:33, 0.810s/it]: train_loss_raw=1.7320, running_loss=1.7074, LR=0.000100
[2025-08-26 22:18:08,203][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011472] [Batch 02232/03080] [00:30:08/00:11:26, 0.810s/it]: train_loss_raw=1.7540, running_loss=1.7077, LR=0.000100
[2025-08-26 22:18:15,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011480] [Batch 02240/03080] [00:30:15/00:11:20, 0.810s/it]: train_loss_raw=1.6978, running_loss=1.7110, LR=0.000100
[2025-08-26 22:18:22,106][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011488] [Batch 02248/03080] [00:30:22/00:11:14, 0.811s/it]: train_loss_raw=1.7665, running_loss=1.7105, LR=0.000100
[2025-08-26 22:18:28,871][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011496] [Batch 02256/03080] [00:30:28/00:11:07, 0.811s/it]: train_loss_raw=1.7826, running_loss=1.7096, LR=0.000100
[2025-08-26 22:18:35,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011504] [Batch 02264/03080] [00:30:35/00:11:01, 0.811s/it]: train_loss_raw=1.7021, running_loss=1.7064, LR=0.000100
[2025-08-26 22:18:42,693][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011512] [Batch 02272/03080] [00:30:42/00:10:55, 0.811s/it]: train_loss_raw=1.7806, running_loss=1.7083, LR=0.000100
[2025-08-26 22:18:49,349][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011520] [Batch 02280/03080] [00:30:49/00:10:48, 0.811s/it]: train_loss_raw=1.6993, running_loss=1.7054, LR=0.000100
[2025-08-26 22:18:56,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011528] [Batch 02288/03080] [00:30:56/00:10:42, 0.811s/it]: train_loss_raw=1.7450, running_loss=1.7063, LR=0.000100
[2025-08-26 22:19:03,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011536] [Batch 02296/03080] [00:31:02/00:10:36, 0.811s/it]: train_loss_raw=1.5849, running_loss=1.7036, LR=0.000100
[2025-08-26 22:19:09,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011544] [Batch 02304/03080] [00:31:09/00:10:29, 0.812s/it]: train_loss_raw=1.6690, running_loss=1.7014, LR=0.000100
[2025-08-26 22:19:16,576][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011552] [Batch 02312/03080] [00:31:16/00:10:23, 0.812s/it]: train_loss_raw=1.7040, running_loss=1.7024, LR=0.000100
[2025-08-26 22:19:23,470][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011560] [Batch 02320/03080] [00:31:23/00:10:16, 0.812s/it]: train_loss_raw=1.7147, running_loss=1.7001, LR=0.000100
[2025-08-26 22:19:30,178][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011568] [Batch 02328/03080] [00:31:30/00:10:10, 0.812s/it]: train_loss_raw=1.7788, running_loss=1.6977, LR=0.000100
[2025-08-26 22:19:36,957][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011576] [Batch 02336/03080] [00:31:36/00:10:04, 0.812s/it]: train_loss_raw=1.7978, running_loss=1.6992, LR=0.000100
[2025-08-26 22:19:43,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011584] [Batch 02344/03080] [00:31:43/00:09:57, 0.812s/it]: train_loss_raw=1.6656, running_loss=1.6998, LR=0.000100
[2025-08-26 22:19:50,354][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011592] [Batch 02352/03080] [00:31:50/00:09:51, 0.812s/it]: train_loss_raw=1.7148, running_loss=1.6989, LR=0.000100
[2025-08-26 22:19:56,976][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011600] [Batch 02360/03080] [00:31:56/00:09:44, 0.812s/it]: train_loss_raw=1.7026, running_loss=1.6986, LR=0.000100
[2025-08-26 22:20:03,586][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011608] [Batch 02368/03080] [00:32:03/00:09:38, 0.812s/it]: train_loss_raw=1.6686, running_loss=1.6985, LR=0.000100
[2025-08-26 22:20:10,144][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011616] [Batch 02376/03080] [00:32:10/00:09:31, 0.812s/it]: train_loss_raw=1.7061, running_loss=1.6966, LR=0.000100
[2025-08-26 22:20:16,772][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011624] [Batch 02384/03080] [00:32:16/00:09:25, 0.812s/it]: train_loss_raw=1.7327, running_loss=1.6965, LR=0.000100
[2025-08-26 22:20:23,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011632] [Batch 02392/03080] [00:32:23/00:09:18, 0.812s/it]: train_loss_raw=1.6993, running_loss=1.6972, LR=0.000100
[2025-08-26 22:20:30,094][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011640] [Batch 02400/03080] [00:32:30/00:09:12, 0.813s/it]: train_loss_raw=1.6993, running_loss=1.6990, LR=0.000100
[2025-08-26 22:20:36,734][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011648] [Batch 02408/03080] [00:32:36/00:09:06, 0.813s/it]: train_loss_raw=1.8396, running_loss=1.7013, LR=0.000100
[2025-08-26 22:20:43,377][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011656] [Batch 02416/03080] [00:32:43/00:08:59, 0.813s/it]: train_loss_raw=1.7780, running_loss=1.6985, LR=0.000100
[2025-08-26 22:20:50,023][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011664] [Batch 02424/03080] [00:32:49/00:08:53, 0.813s/it]: train_loss_raw=1.6856, running_loss=1.6964, LR=0.000100
[2025-08-26 22:20:56,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011672] [Batch 02432/03080] [00:32:56/00:08:46, 0.813s/it]: train_loss_raw=1.7807, running_loss=1.7003, LR=0.000100
[2025-08-26 22:21:03,155][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011680] [Batch 02440/03080] [00:33:03/00:08:40, 0.813s/it]: train_loss_raw=1.7761, running_loss=1.7009, LR=0.000100
[2025-08-26 22:21:09,706][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011688] [Batch 02448/03080] [00:33:09/00:08:33, 0.813s/it]: train_loss_raw=1.6480, running_loss=1.7010, LR=0.000100
[2025-08-26 22:21:16,285][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011696] [Batch 02456/03080] [00:33:16/00:08:27, 0.813s/it]: train_loss_raw=1.6534, running_loss=1.6987, LR=0.000100
[2025-08-26 22:21:22,936][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011704] [Batch 02464/03080] [00:33:22/00:08:20, 0.813s/it]: train_loss_raw=1.7063, running_loss=1.6995, LR=0.000100
[2025-08-26 22:21:29,649][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011712] [Batch 02472/03080] [00:33:29/00:08:14, 0.813s/it]: train_loss_raw=1.6594, running_loss=1.6999, LR=0.000100
[2025-08-26 22:21:36,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011720] [Batch 02480/03080] [00:33:36/00:08:07, 0.813s/it]: train_loss_raw=1.7135, running_loss=1.7005, LR=0.000100
[2025-08-26 22:21:42,930][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011728] [Batch 02488/03080] [00:33:42/00:08:01, 0.813s/it]: train_loss_raw=1.6098, running_loss=1.6983, LR=0.000100
[2025-08-26 22:21:49,509][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011736] [Batch 02496/03080] [00:33:49/00:07:54, 0.813s/it]: train_loss_raw=1.7913, running_loss=1.7000, LR=0.000100
[2025-08-26 22:21:55,994][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011744] [Batch 02504/03080] [00:33:55/00:07:48, 0.813s/it]: train_loss_raw=1.7597, running_loss=1.6991, LR=0.000100
[2025-08-26 22:22:02,636][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011752] [Batch 02512/03080] [00:34:02/00:07:41, 0.813s/it]: train_loss_raw=1.6607, running_loss=1.6960, LR=0.000100
[2025-08-26 22:22:09,246][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011760] [Batch 02520/03080] [00:34:09/00:07:35, 0.813s/it]: train_loss_raw=1.6272, running_loss=1.6939, LR=0.000100
[2025-08-26 22:22:15,944][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011768] [Batch 02528/03080] [00:34:15/00:07:28, 0.813s/it]: train_loss_raw=1.6872, running_loss=1.6934, LR=0.000100
[2025-08-26 22:22:22,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011776] [Batch 02536/03080] [00:34:22/00:07:22, 0.813s/it]: train_loss_raw=1.6936, running_loss=1.6923, LR=0.000100
[2025-08-26 22:22:29,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011784] [Batch 02544/03080] [00:34:29/00:07:15, 0.813s/it]: train_loss_raw=1.6087, running_loss=1.6915, LR=0.000100
[2025-08-26 22:22:35,858][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011792] [Batch 02552/03080] [00:34:35/00:07:09, 0.813s/it]: train_loss_raw=1.5976, running_loss=1.6914, LR=0.000100
[2025-08-26 22:22:42,478][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011800] [Batch 02560/03080] [00:34:42/00:07:02, 0.813s/it]: train_loss_raw=1.6815, running_loss=1.6910, LR=0.000100
[2025-08-26 22:22:49,098][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011808] [Batch 02568/03080] [00:34:49/00:06:56, 0.813s/it]: train_loss_raw=1.7764, running_loss=1.6917, LR=0.000100
[2025-08-26 22:22:55,708][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011816] [Batch 02576/03080] [00:34:55/00:06:50, 0.814s/it]: train_loss_raw=1.6505, running_loss=1.6914, LR=0.000100
[2025-08-26 22:23:02,346][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011824] [Batch 02584/03080] [00:35:02/00:06:43, 0.814s/it]: train_loss_raw=1.6928, running_loss=1.6921, LR=0.000100
[2025-08-26 22:23:08,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011832] [Batch 02592/03080] [00:35:08/00:06:37, 0.814s/it]: train_loss_raw=1.7129, running_loss=1.6934, LR=0.000100
[2025-08-26 22:23:15,535][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011840] [Batch 02600/03080] [00:35:15/00:06:30, 0.814s/it]: train_loss_raw=1.6614, running_loss=1.6924, LR=0.000100
[2025-08-26 22:23:22,128][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011848] [Batch 02608/03080] [00:35:22/00:06:24, 0.814s/it]: train_loss_raw=1.6551, running_loss=1.6930, LR=0.000100
[2025-08-26 22:23:28,702][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011856] [Batch 02616/03080] [00:35:28/00:06:17, 0.814s/it]: train_loss_raw=1.6215, running_loss=1.6946, LR=0.000100
[2025-08-26 22:23:35,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011864] [Batch 02624/03080] [00:35:35/00:06:11, 0.814s/it]: train_loss_raw=1.6390, running_loss=1.6938, LR=0.000100
[2025-08-26 22:23:41,940][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011872] [Batch 02632/03080] [00:35:41/00:06:04, 0.814s/it]: train_loss_raw=1.6502, running_loss=1.6927, LR=0.000100
[2025-08-26 22:23:48,659][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011880] [Batch 02640/03080] [00:35:48/00:05:58, 0.814s/it]: train_loss_raw=1.6236, running_loss=1.6910, LR=0.000100
[2025-08-26 22:23:55,241][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011888] [Batch 02648/03080] [00:35:55/00:05:51, 0.814s/it]: train_loss_raw=1.7126, running_loss=1.6917, LR=0.000100
[2025-08-26 22:24:01,873][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011896] [Batch 02656/03080] [00:36:01/00:05:45, 0.814s/it]: train_loss_raw=1.6806, running_loss=1.6904, LR=0.000100
[2025-08-26 22:24:08,562][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011904] [Batch 02664/03080] [00:36:08/00:05:38, 0.814s/it]: train_loss_raw=1.5968, running_loss=1.6913, LR=0.000100
[2025-08-26 22:24:15,231][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011912] [Batch 02672/03080] [00:36:15/00:05:32, 0.814s/it]: train_loss_raw=1.7052, running_loss=1.6897, LR=0.000100
[2025-08-26 22:24:21,832][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011920] [Batch 02680/03080] [00:36:21/00:05:25, 0.814s/it]: train_loss_raw=1.6818, running_loss=1.6901, LR=0.000100
[2025-08-26 22:24:28,442][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011928] [Batch 02688/03080] [00:36:28/00:05:19, 0.814s/it]: train_loss_raw=1.6168, running_loss=1.6900, LR=0.000100
[2025-08-26 22:24:35,056][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011936] [Batch 02696/03080] [00:36:34/00:05:12, 0.814s/it]: train_loss_raw=1.7046, running_loss=1.6921, LR=0.000100
[2025-08-26 22:24:41,687][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011944] [Batch 02704/03080] [00:36:41/00:05:06, 0.814s/it]: train_loss_raw=1.6580, running_loss=1.6925, LR=0.000100
[2025-08-26 22:24:48,273][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011952] [Batch 02712/03080] [00:36:48/00:04:59, 0.814s/it]: train_loss_raw=1.5875, running_loss=1.6891, LR=0.000100
[2025-08-26 22:24:54,929][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011960] [Batch 02720/03080] [00:36:54/00:04:53, 0.814s/it]: train_loss_raw=1.7449, running_loss=1.6913, LR=0.000100
[2025-08-26 22:25:01,559][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011968] [Batch 02728/03080] [00:37:01/00:04:46, 0.814s/it]: train_loss_raw=1.6771, running_loss=1.6893, LR=0.000100
[2025-08-26 22:25:08,188][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011976] [Batch 02736/03080] [00:37:08/00:04:40, 0.814s/it]: train_loss_raw=1.6546, running_loss=1.6851, LR=0.000100
[2025-08-26 22:25:14,751][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011984] [Batch 02744/03080] [00:37:14/00:04:33, 0.814s/it]: train_loss_raw=1.5506, running_loss=1.6853, LR=0.000100
[2025-08-26 22:25:21,423][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011992] [Batch 02752/03080] [00:37:21/00:04:27, 0.814s/it]: train_loss_raw=1.5964, running_loss=1.6838, LR=0.000100
[2025-08-26 22:25:28,069][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012000] [Batch 02760/03080] [00:37:28/00:04:20, 0.814s/it]: train_loss_raw=1.7568, running_loss=1.6832, LR=0.000100
[2025-08-26 22:25:40,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012008] [Batch 02768/03080] [00:37:40/00:04:14, 0.817s/it]: train_loss_raw=1.7312, running_loss=1.6827, LR=0.000100
[2025-08-26 22:25:47,400][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012016] [Batch 02776/03080] [00:37:47/00:04:08, 0.817s/it]: train_loss_raw=1.6760, running_loss=1.6847, LR=0.000100
[2025-08-26 22:25:54,091][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012024] [Batch 02784/03080] [00:37:54/00:04:01, 0.817s/it]: train_loss_raw=1.7526, running_loss=1.6870, LR=0.000100
[2025-08-26 22:26:00,673][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012032] [Batch 02792/03080] [00:38:00/00:03:55, 0.817s/it]: train_loss_raw=1.5915, running_loss=1.6840, LR=0.000100
[2025-08-26 22:26:07,307][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012040] [Batch 02800/03080] [00:38:07/00:03:48, 0.817s/it]: train_loss_raw=1.6618, running_loss=1.6826, LR=0.000100
[2025-08-26 22:26:13,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012048] [Batch 02808/03080] [00:38:13/00:03:42, 0.817s/it]: train_loss_raw=1.6704, running_loss=1.6849, LR=0.000100
[2025-08-26 22:26:20,508][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012056] [Batch 02816/03080] [00:38:20/00:03:35, 0.817s/it]: train_loss_raw=1.6403, running_loss=1.6830, LR=0.000100
[2025-08-26 22:26:27,078][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012064] [Batch 02824/03080] [00:38:27/00:03:29, 0.817s/it]: train_loss_raw=1.5969, running_loss=1.6841, LR=0.000100
[2025-08-26 22:26:33,636][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012072] [Batch 02832/03080] [00:38:33/00:03:22, 0.817s/it]: train_loss_raw=1.6530, running_loss=1.6840, LR=0.000100
[2025-08-26 22:26:40,289][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012080] [Batch 02840/03080] [00:38:40/00:03:16, 0.817s/it]: train_loss_raw=1.7182, running_loss=1.6860, LR=0.000100
[2025-08-26 22:26:46,867][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012088] [Batch 02848/03080] [00:38:46/00:03:09, 0.817s/it]: train_loss_raw=1.6447, running_loss=1.6849, LR=0.000100
[2025-08-26 22:26:53,476][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012096] [Batch 02856/03080] [00:38:53/00:03:03, 0.817s/it]: train_loss_raw=1.7192, running_loss=1.6852, LR=0.000100
[2025-08-26 22:27:00,017][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012104] [Batch 02864/03080] [00:38:59/00:02:56, 0.817s/it]: train_loss_raw=1.6770, running_loss=1.6862, LR=0.000100
[2025-08-26 22:27:06,674][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012112] [Batch 02872/03080] [00:39:06/00:02:49, 0.817s/it]: train_loss_raw=1.7608, running_loss=1.6886, LR=0.000100
[2025-08-26 22:27:13,280][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012120] [Batch 02880/03080] [00:39:13/00:02:43, 0.817s/it]: train_loss_raw=1.7205, running_loss=1.6888, LR=0.000100
[2025-08-26 22:27:19,892][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012128] [Batch 02888/03080] [00:39:19/00:02:36, 0.817s/it]: train_loss_raw=1.6173, running_loss=1.6856, LR=0.000100
[2025-08-26 22:27:26,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012136] [Batch 02896/03080] [00:39:26/00:02:30, 0.817s/it]: train_loss_raw=1.6179, running_loss=1.6853, LR=0.000100
[2025-08-26 22:27:33,010][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012144] [Batch 02904/03080] [00:39:32/00:02:23, 0.817s/it]: train_loss_raw=1.6586, running_loss=1.6810, LR=0.000100
[2025-08-26 22:27:39,628][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012152] [Batch 02912/03080] [00:39:39/00:02:17, 0.817s/it]: train_loss_raw=1.6558, running_loss=1.6792, LR=0.000100
[2025-08-26 22:27:46,235][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012160] [Batch 02920/03080] [00:39:46/00:02:10, 0.817s/it]: train_loss_raw=1.5578, running_loss=1.6773, LR=0.000100
[2025-08-26 22:27:52,791][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012168] [Batch 02928/03080] [00:39:52/00:02:04, 0.817s/it]: train_loss_raw=1.7431, running_loss=1.6771, LR=0.000100
[2025-08-26 22:27:59,420][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012176] [Batch 02936/03080] [00:39:59/00:01:57, 0.817s/it]: train_loss_raw=1.7470, running_loss=1.6766, LR=0.000100
[2025-08-26 22:28:06,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012184] [Batch 02944/03080] [00:40:05/00:01:51, 0.817s/it]: train_loss_raw=1.6780, running_loss=1.6763, LR=0.000100
[2025-08-26 22:28:12,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012192] [Batch 02952/03080] [00:40:12/00:01:44, 0.817s/it]: train_loss_raw=1.6728, running_loss=1.6762, LR=0.000100
[2025-08-26 22:28:19,255][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012200] [Batch 02960/03080] [00:40:19/00:01:38, 0.817s/it]: train_loss_raw=1.6445, running_loss=1.6748, LR=0.000100
[2025-08-26 22:28:25,927][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012208] [Batch 02968/03080] [00:40:25/00:01:31, 0.817s/it]: train_loss_raw=1.6903, running_loss=1.6748, LR=0.000100
[2025-08-26 22:28:32,586][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012216] [Batch 02976/03080] [00:40:32/00:01:25, 0.817s/it]: train_loss_raw=1.6260, running_loss=1.6728, LR=0.000100
[2025-08-26 22:28:39,235][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012224] [Batch 02984/03080] [00:40:39/00:01:18, 0.817s/it]: train_loss_raw=1.7536, running_loss=1.6755, LR=0.000100
[2025-08-26 22:28:45,867][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012232] [Batch 02992/03080] [00:40:45/00:01:11, 0.817s/it]: train_loss_raw=1.6795, running_loss=1.6736, LR=0.000100
[2025-08-26 22:28:52,519][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012240] [Batch 03000/03080] [00:40:52/00:01:05, 0.817s/it]: train_loss_raw=1.6646, running_loss=1.6716, LR=0.000100
[2025-08-26 22:28:59,133][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012248] [Batch 03008/03080] [00:40:59/00:00:58, 0.818s/it]: train_loss_raw=1.6724, running_loss=1.6676, LR=0.000100
[2025-08-26 22:29:05,756][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012256] [Batch 03016/03080] [00:41:05/00:00:52, 0.818s/it]: train_loss_raw=1.7057, running_loss=1.6686, LR=0.000100
[2025-08-26 22:29:12,430][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012264] [Batch 03024/03080] [00:41:12/00:00:45, 0.818s/it]: train_loss_raw=1.6906, running_loss=1.6670, LR=0.000100
[2025-08-26 22:29:19,051][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012272] [Batch 03032/03080] [00:41:18/00:00:39, 0.818s/it]: train_loss_raw=1.7054, running_loss=1.6691, LR=0.000100
[2025-08-26 22:29:25,735][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012280] [Batch 03040/03080] [00:41:25/00:00:32, 0.818s/it]: train_loss_raw=1.7412, running_loss=1.6697, LR=0.000100
[2025-08-26 22:29:32,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012288] [Batch 03048/03080] [00:41:32/00:00:26, 0.818s/it]: train_loss_raw=1.6141, running_loss=1.6708, LR=0.000100
[2025-08-26 22:29:38,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012296] [Batch 03056/03080] [00:41:38/00:00:19, 0.818s/it]: train_loss_raw=1.6639, running_loss=1.6705, LR=0.000100
[2025-08-26 22:29:45,612][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012304] [Batch 03064/03080] [00:41:45/00:00:13, 0.818s/it]: train_loss_raw=1.5652, running_loss=1.6679, LR=0.000100
[2025-08-26 22:29:52,295][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012312] [Batch 03072/03080] [00:41:52/00:00:06, 0.818s/it]: train_loss_raw=1.7442, running_loss=1.6682, LR=0.000100
[2025-08-26 22:30:04,210][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012320] [Batch 03080/03080] [00:42:04/00:00:00, 0.820s/it]: train_loss_raw=1.6935, running_loss=1.6672, LR=0.000100
[2025-08-26 22:30:04,795][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-26 22:30:17,106][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00007/00310] [00:00:12/00:07:44, 1.539s/it]
[2025-08-26 22:30:29,789][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00015/00310] [00:00:24/00:07:39, 1.562s/it]
[2025-08-26 22:30:42,900][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00023/00310] [00:00:38/00:07:34, 1.588s/it]
[2025-08-26 22:30:56,612][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00031/00310] [00:00:51/00:07:30, 1.619s/it]
[2025-08-26 22:31:10,425][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00039/00310] [00:01:05/00:07:22, 1.641s/it]
[2025-08-26 22:31:23,891][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00047/00310] [00:01:19/00:07:11, 1.648s/it]
[2025-08-26 22:31:37,687][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00055/00310] [00:01:32/00:07:01, 1.659s/it]
[2025-08-26 22:31:51,192][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00063/00310] [00:01:46/00:06:48, 1.662s/it]
[2025-08-26 22:32:04,849][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00071/00310] [00:02:00/00:06:36, 1.667s/it]
[2025-08-26 22:32:18,676][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00079/00310] [00:02:13/00:06:24, 1.674s/it]
[2025-08-26 22:32:32,486][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00087/00310] [00:02:27/00:06:12, 1.678s/it]
[2025-08-26 22:32:46,023][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00095/00310] [00:02:41/00:05:59, 1.679s/it]
[2025-08-26 22:33:00,050][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00103/00310] [00:02:55/00:05:47, 1.685s/it]
[2025-08-26 22:33:13,457][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00111/00310] [00:03:08/00:05:33, 1.684s/it]
[2025-08-26 22:33:27,140][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00119/00310] [00:03:22/00:05:20, 1.686s/it]
[2025-08-26 22:33:40,783][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00127/00310] [00:03:35/00:05:07, 1.687s/it]
[2025-08-26 22:33:54,449][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00135/00310] [00:03:49/00:04:53, 1.689s/it]
[2025-08-26 22:34:08,162][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00143/00310] [00:04:03/00:04:40, 1.690s/it]
[2025-08-26 22:34:21,160][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00151/00310] [00:04:16/00:04:26, 1.687s/it]
[2025-08-26 22:34:33,815][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00159/00310] [00:04:29/00:04:12, 1.681s/it]
[2025-08-26 22:34:47,377][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00167/00310] [00:04:42/00:03:58, 1.682s/it]
[2025-08-26 22:35:00,093][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00175/00310] [00:04:55/00:03:44, 1.678s/it]
[2025-08-26 22:35:12,936][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00183/00310] [00:05:08/00:03:31, 1.675s/it]
[2025-08-26 22:35:26,272][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00191/00310] [00:05:21/00:03:17, 1.674s/it]
[2025-08-26 22:35:39,429][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00199/00310] [00:05:34/00:03:04, 1.673s/it]
[2025-08-26 22:35:52,415][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00207/00310] [00:05:47/00:02:50, 1.671s/it]
[2025-08-26 22:36:05,312][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00215/00310] [00:06:00/00:02:36, 1.669s/it]
[2025-08-26 22:36:18,700][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00223/00310] [00:06:13/00:02:23, 1.669s/it]
[2025-08-26 22:36:32,367][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00231/00310] [00:06:27/00:02:10, 1.671s/it]
[2025-08-26 22:36:45,517][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00239/00310] [00:06:40/00:01:56, 1.670s/it]
[2025-08-26 22:36:58,519][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00247/00310] [00:06:53/00:01:43, 1.668s/it]
[2025-08-26 22:37:12,117][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00255/00310] [00:07:07/00:01:30, 1.669s/it]
[2025-08-26 22:37:25,754][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00263/00310] [00:07:20/00:01:16, 1.670s/it]
[2025-08-26 22:37:39,108][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00271/00310] [00:07:34/00:01:03, 1.670s/it]
[2025-08-26 22:37:52,473][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00279/00310] [00:07:47/00:00:50, 1.670s/it]
[2025-08-26 22:38:06,157][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00287/00310] [00:08:01/00:00:36, 1.671s/it]
[2025-08-26 22:38:19,375][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00295/00310] [00:08:14/00:00:23, 1.671s/it]
[2025-08-26 22:38:32,807][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 012321] [Batch 00303/00310] [00:08:28/00:00:10, 1.671s/it]
[2025-08-26 22:38:42,373][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.66721, valid_loss=2.30656
[2025-08-26 22:38:42,373][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-26 22:38:42,374][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.860
[2025-08-26 22:38:42,374][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.016
[2025-08-26 22:38:42,374][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.017
[2025-08-26 22:38:42,374][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.001
[2025-08-26 22:38:42,395][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 03:11:56, remaining time 20:47:35, 00:47:59 per epoch
[2025-08-26 22:38:49,083][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012328] [Batch 00008/03080] [00:00:05/00:35:44, 0.698s/it]: train_loss_raw=1.7420, running_loss=1.6378, LR=0.000100
[2025-08-26 22:38:55,560][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012336] [Batch 00016/03080] [00:00:12/00:38:30, 0.754s/it]: train_loss_raw=1.7042, running_loss=1.6415, LR=0.000100
[2025-08-26 22:39:02,072][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012344] [Batch 00024/03080] [00:00:18/00:39:25, 0.774s/it]: train_loss_raw=1.7276, running_loss=1.6436, LR=0.000100
[2025-08-26 22:39:08,655][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012352] [Batch 00032/03080] [00:00:25/00:39:56, 0.786s/it]: train_loss_raw=1.6353, running_loss=1.6450, LR=0.000100
[2025-08-26 22:39:15,239][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012360] [Batch 00040/03080] [00:00:31/00:40:12, 0.794s/it]: train_loss_raw=1.6640, running_loss=1.6457, LR=0.000100
[2025-08-26 22:39:21,757][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012368] [Batch 00048/03080] [00:00:38/00:40:16, 0.797s/it]: train_loss_raw=1.7004, running_loss=1.6479, LR=0.000100
[2025-08-26 22:39:28,328][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012376] [Batch 00056/03080] [00:00:44/00:40:20, 0.801s/it]: train_loss_raw=1.6995, running_loss=1.6464, LR=0.000100
[2025-08-26 22:39:34,934][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012384] [Batch 00064/03080] [00:00:51/00:40:23, 0.804s/it]: train_loss_raw=1.6381, running_loss=1.6462, LR=0.000100
[2025-08-26 22:39:41,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012392] [Batch 00072/03080] [00:00:57/00:40:22, 0.805s/it]: train_loss_raw=1.6054, running_loss=1.6470, LR=0.000100
[2025-08-26 22:39:48,148][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012400] [Batch 00080/03080] [00:01:04/00:40:24, 0.808s/it]: train_loss_raw=1.7843, running_loss=1.6486, LR=0.000100
[2025-08-26 22:39:54,694][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012408] [Batch 00088/03080] [00:01:11/00:40:20, 0.809s/it]: train_loss_raw=1.7164, running_loss=1.6479, LR=0.000100
[2025-08-26 22:40:01,468][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012416] [Batch 00096/03080] [00:01:17/00:40:23, 0.812s/it]: train_loss_raw=1.6934, running_loss=1.6489, LR=0.000100
[2025-08-26 22:40:08,063][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012424] [Batch 00104/03080] [00:01:24/00:40:19, 0.813s/it]: train_loss_raw=1.6144, running_loss=1.6480, LR=0.000100
[2025-08-26 22:40:14,719][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012432] [Batch 00112/03080] [00:01:31/00:40:17, 0.814s/it]: train_loss_raw=1.6661, running_loss=1.6495, LR=0.000100
[2025-08-26 22:40:21,364][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012440] [Batch 00120/03080] [00:01:37/00:40:14, 0.816s/it]: train_loss_raw=1.6081, running_loss=1.6517, LR=0.000100
[2025-08-26 22:40:28,033][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012448] [Batch 00128/03080] [00:01:44/00:40:10, 0.817s/it]: train_loss_raw=1.6867, running_loss=1.6520, LR=0.000100
[2025-08-26 22:40:34,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012456] [Batch 00136/03080] [00:01:51/00:40:04, 0.817s/it]: train_loss_raw=1.5644, running_loss=1.6486, LR=0.000100
[2025-08-26 22:40:41,109][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012464] [Batch 00144/03080] [00:01:57/00:39:57, 0.817s/it]: train_loss_raw=1.7147, running_loss=1.6506, LR=0.000100
[2025-08-26 22:40:47,609][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012472] [Batch 00152/03080] [00:02:04/00:39:50, 0.817s/it]: train_loss_raw=1.6493, running_loss=1.6523, LR=0.000100
[2025-08-26 22:40:54,151][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012480] [Batch 00160/03080] [00:02:10/00:39:44, 0.817s/it]: train_loss_raw=1.7928, running_loss=1.6551, LR=0.000100
[2025-08-26 22:41:00,703][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012488] [Batch 00168/03080] [00:02:17/00:39:38, 0.817s/it]: train_loss_raw=1.5960, running_loss=1.6545, LR=0.000100
[2025-08-26 22:41:07,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012496] [Batch 00176/03080] [00:02:23/00:39:31, 0.817s/it]: train_loss_raw=1.7655, running_loss=1.6546, LR=0.000100
[2025-08-26 22:41:13,803][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012504] [Batch 00184/03080] [00:02:30/00:39:25, 0.817s/it]: train_loss_raw=1.5803, running_loss=1.6559, LR=0.000100
[2025-08-26 22:41:20,355][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012512] [Batch 00192/03080] [00:02:36/00:39:19, 0.817s/it]: train_loss_raw=1.6231, running_loss=1.6556, LR=0.000100
[2025-08-26 22:41:26,469][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012520] [Batch 00200/03080] [00:02:42/00:39:06, 0.815s/it]: train_loss_raw=1.6102, running_loss=1.6566, LR=0.000100
[2025-08-26 22:41:32,685][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012528] [Batch 00208/03080] [00:02:49/00:38:56, 0.813s/it]: train_loss_raw=1.5897, running_loss=1.6539, LR=0.000100
[2025-08-26 22:41:39,186][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012536] [Batch 00216/03080] [00:02:55/00:38:49, 0.813s/it]: train_loss_raw=1.6157, running_loss=1.6544, LR=0.000100
[2025-08-26 22:41:45,702][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012544] [Batch 00224/03080] [00:03:02/00:38:43, 0.813s/it]: train_loss_raw=1.6203, running_loss=1.6533, LR=0.000100
[2025-08-26 22:41:51,939][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012552] [Batch 00232/03080] [00:03:08/00:38:33, 0.812s/it]: train_loss_raw=1.6966, running_loss=1.6570, LR=0.000100
[2025-08-26 22:41:58,003][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012560] [Batch 00240/03080] [00:03:14/00:38:21, 0.810s/it]: train_loss_raw=1.6418, running_loss=1.6539, LR=0.000100
[2025-08-26 22:42:04,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012568] [Batch 00248/03080] [00:03:20/00:38:11, 0.809s/it]: train_loss_raw=1.6574, running_loss=1.6519, LR=0.000100
[2025-08-26 22:42:10,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012576] [Batch 00256/03080] [00:03:26/00:38:02, 0.808s/it]: train_loss_raw=1.6451, running_loss=1.6508, LR=0.000100
[2025-08-26 22:42:16,512][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012584] [Batch 00264/03080] [00:03:33/00:37:52, 0.807s/it]: train_loss_raw=1.5661, running_loss=1.6480, LR=0.000100
[2025-08-26 22:42:22,657][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012592] [Batch 00272/03080] [00:03:39/00:37:42, 0.806s/it]: train_loss_raw=1.6038, running_loss=1.6447, LR=0.000100
[2025-08-26 22:42:28,755][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012600] [Batch 00280/03080] [00:03:45/00:37:32, 0.804s/it]: train_loss_raw=1.5508, running_loss=1.6441, LR=0.000100
[2025-08-26 22:42:35,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012608] [Batch 00288/03080] [00:03:51/00:37:25, 0.804s/it]: train_loss_raw=1.6423, running_loss=1.6445, LR=0.000100
[2025-08-26 22:42:41,875][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012616] [Batch 00296/03080] [00:03:58/00:37:22, 0.805s/it]: train_loss_raw=1.5784, running_loss=1.6463, LR=0.000100
[2025-08-26 22:42:48,448][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012624] [Batch 00304/03080] [00:04:04/00:37:16, 0.806s/it]: train_loss_raw=1.6546, running_loss=1.6463, LR=0.000100
[2025-08-26 22:42:55,034][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012632] [Batch 00312/03080] [00:04:11/00:37:11, 0.806s/it]: train_loss_raw=1.7858, running_loss=1.6482, LR=0.000100
[2025-08-26 22:43:01,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012640] [Batch 00320/03080] [00:04:18/00:37:06, 0.807s/it]: train_loss_raw=1.5796, running_loss=1.6455, LR=0.000100
[2025-08-26 22:43:07,966][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012648] [Batch 00328/03080] [00:04:24/00:36:58, 0.806s/it]: train_loss_raw=1.6435, running_loss=1.6456, LR=0.000100
[2025-08-26 22:43:14,187][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012656] [Batch 00336/03080] [00:04:30/00:36:50, 0.806s/it]: train_loss_raw=1.7641, running_loss=1.6453, LR=0.000100
[2025-08-26 22:43:20,541][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012664] [Batch 00344/03080] [00:04:37/00:36:43, 0.805s/it]: train_loss_raw=1.6550, running_loss=1.6454, LR=0.000100
[2025-08-26 22:43:26,730][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012672] [Batch 00352/03080] [00:04:43/00:36:35, 0.805s/it]: train_loss_raw=1.6901, running_loss=1.6471, LR=0.000100
[2025-08-26 22:43:32,839][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012680] [Batch 00360/03080] [00:04:49/00:36:26, 0.804s/it]: train_loss_raw=1.6360, running_loss=1.6430, LR=0.000100
[2025-08-26 22:43:38,951][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012688] [Batch 00368/03080] [00:04:55/00:36:17, 0.803s/it]: train_loss_raw=1.5756, running_loss=1.6407, LR=0.000100
[2025-08-26 22:43:45,000][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012696] [Batch 00376/03080] [00:05:01/00:36:08, 0.802s/it]: train_loss_raw=1.6629, running_loss=1.6405, LR=0.000100
[2025-08-26 22:43:51,158][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012704] [Batch 00384/03080] [00:05:07/00:36:00, 0.801s/it]: train_loss_raw=1.6529, running_loss=1.6426, LR=0.000100
[2025-08-26 22:43:57,307][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012712] [Batch 00392/03080] [00:05:13/00:35:51, 0.801s/it]: train_loss_raw=1.6843, running_loss=1.6427, LR=0.000100
[2025-08-26 22:44:03,796][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012720] [Batch 00400/03080] [00:05:20/00:35:45, 0.801s/it]: train_loss_raw=1.7025, running_loss=1.6430, LR=0.000100
[2025-08-26 22:44:10,350][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012728] [Batch 00408/03080] [00:05:26/00:35:40, 0.801s/it]: train_loss_raw=1.6652, running_loss=1.6426, LR=0.000100
[2025-08-26 22:44:16,859][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012736] [Batch 00416/03080] [00:05:33/00:35:34, 0.801s/it]: train_loss_raw=1.6520, running_loss=1.6432, LR=0.000100
[2025-08-26 22:44:23,013][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012744] [Batch 00424/03080] [00:05:39/00:35:26, 0.801s/it]: train_loss_raw=1.5747, running_loss=1.6408, LR=0.000100
[2025-08-26 22:44:29,393][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012752] [Batch 00432/03080] [00:05:45/00:35:20, 0.801s/it]: train_loss_raw=1.6272, running_loss=1.6382, LR=0.000100
[2025-08-26 22:44:35,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012760] [Batch 00440/03080] [00:05:52/00:35:14, 0.801s/it]: train_loss_raw=1.6988, running_loss=1.6390, LR=0.000100
[2025-08-26 22:44:42,591][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012768] [Batch 00448/03080] [00:05:59/00:35:09, 0.802s/it]: train_loss_raw=1.4895, running_loss=1.6377, LR=0.000100
[2025-08-26 22:44:49,124][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012776] [Batch 00456/03080] [00:06:05/00:35:03, 0.802s/it]: train_loss_raw=1.6397, running_loss=1.6346, LR=0.000100
[2025-08-26 22:44:55,968][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012784] [Batch 00464/03080] [00:06:12/00:34:59, 0.803s/it]: train_loss_raw=1.5983, running_loss=1.6313, LR=0.000100
[2025-08-26 22:45:02,855][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012792] [Batch 00472/03080] [00:06:19/00:34:56, 0.804s/it]: train_loss_raw=1.6332, running_loss=1.6320, LR=0.000100
[2025-08-26 22:45:09,771][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012800] [Batch 00480/03080] [00:06:26/00:34:52, 0.805s/it]: train_loss_raw=1.6594, running_loss=1.6345, LR=0.000100
[2025-08-26 22:45:16,448][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012808] [Batch 00488/03080] [00:06:32/00:34:47, 0.805s/it]: train_loss_raw=1.5930, running_loss=1.6369, LR=0.000100
[2025-08-26 22:45:23,011][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012816] [Batch 00496/03080] [00:06:39/00:34:41, 0.805s/it]: train_loss_raw=1.6792, running_loss=1.6381, LR=0.000100
[2025-08-26 22:45:29,900][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012824] [Batch 00504/03080] [00:06:46/00:34:37, 0.806s/it]: train_loss_raw=1.6412, running_loss=1.6379, LR=0.000100
[2025-08-26 22:45:36,841][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012832] [Batch 00512/03080] [00:06:53/00:34:33, 0.807s/it]: train_loss_raw=1.6655, running_loss=1.6395, LR=0.000100
[2025-08-26 22:45:43,317][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012840] [Batch 00520/03080] [00:06:59/00:34:26, 0.807s/it]: train_loss_raw=1.5901, running_loss=1.6392, LR=0.000100
[2025-08-26 22:45:50,183][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012848] [Batch 00528/03080] [00:07:06/00:34:22, 0.808s/it]: train_loss_raw=1.6572, running_loss=1.6393, LR=0.000100
[2025-08-26 22:45:57,048][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012856] [Batch 00536/03080] [00:07:13/00:34:17, 0.809s/it]: train_loss_raw=1.7198, running_loss=1.6399, LR=0.000100
[2025-08-26 22:46:03,998][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012864] [Batch 00544/03080] [00:07:20/00:34:13, 0.810s/it]: train_loss_raw=1.5987, running_loss=1.6403, LR=0.000100
[2025-08-26 22:46:10,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012872] [Batch 00552/03080] [00:07:27/00:34:07, 0.810s/it]: train_loss_raw=1.7950, running_loss=1.6417, LR=0.000100
[2025-08-26 22:46:17,399][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012880] [Batch 00560/03080] [00:07:33/00:34:02, 0.811s/it]: train_loss_raw=1.6709, running_loss=1.6411, LR=0.000100
[2025-08-26 22:46:24,162][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012888] [Batch 00568/03080] [00:07:40/00:33:57, 0.811s/it]: train_loss_raw=1.6040, running_loss=1.6388, LR=0.000100
[2025-08-26 22:46:30,833][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012896] [Batch 00576/03080] [00:07:47/00:33:51, 0.811s/it]: train_loss_raw=1.6146, running_loss=1.6398, LR=0.000100
[2025-08-26 22:46:37,592][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012904] [Batch 00584/03080] [00:07:54/00:33:46, 0.812s/it]: train_loss_raw=1.6342, running_loss=1.6395, LR=0.000100
[2025-08-26 22:46:45,062][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012912] [Batch 00592/03080] [00:08:01/00:33:43, 0.813s/it]: train_loss_raw=1.5525, running_loss=1.6374, LR=0.000100
[2025-08-26 22:46:51,803][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012920] [Batch 00600/03080] [00:08:08/00:33:38, 0.814s/it]: train_loss_raw=1.5680, running_loss=1.6389, LR=0.000100
[2025-08-26 22:46:58,994][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012928] [Batch 00608/03080] [00:08:15/00:33:34, 0.815s/it]: train_loss_raw=1.5555, running_loss=1.6369, LR=0.000100
[2025-08-26 22:47:05,631][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012936] [Batch 00616/03080] [00:08:22/00:33:28, 0.815s/it]: train_loss_raw=1.6014, running_loss=1.6370, LR=0.000100
[2025-08-26 22:47:12,147][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012944] [Batch 00624/03080] [00:08:28/00:33:21, 0.815s/it]: train_loss_raw=1.6176, running_loss=1.6364, LR=0.000100
[2025-08-26 22:47:18,727][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012952] [Batch 00632/03080] [00:08:35/00:33:15, 0.815s/it]: train_loss_raw=1.6869, running_loss=1.6379, LR=0.000100
[2025-08-26 22:47:25,270][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012960] [Batch 00640/03080] [00:08:41/00:33:09, 0.815s/it]: train_loss_raw=1.6756, running_loss=1.6393, LR=0.000100
[2025-08-26 22:47:31,793][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012968] [Batch 00648/03080] [00:08:48/00:33:02, 0.815s/it]: train_loss_raw=1.7276, running_loss=1.6403, LR=0.000100
[2025-08-26 22:47:38,285][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012976] [Batch 00656/03080] [00:08:54/00:32:56, 0.815s/it]: train_loss_raw=1.5534, running_loss=1.6409, LR=0.000100
[2025-08-26 22:47:44,783][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012984] [Batch 00664/03080] [00:09:01/00:32:49, 0.815s/it]: train_loss_raw=1.6300, running_loss=1.6433, LR=0.000100
[2025-08-26 22:47:51,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 012992] [Batch 00672/03080] [00:09:07/00:32:42, 0.815s/it]: train_loss_raw=1.6895, running_loss=1.6424, LR=0.000100
[2025-08-26 22:47:57,907][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013000] [Batch 00680/03080] [00:09:14/00:32:36, 0.815s/it]: train_loss_raw=1.7190, running_loss=1.6442, LR=0.000100
[2025-08-26 22:48:04,422][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013008] [Batch 00688/03080] [00:09:20/00:32:30, 0.815s/it]: train_loss_raw=1.5947, running_loss=1.6431, LR=0.000100
[2025-08-26 22:48:10,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013016] [Batch 00696/03080] [00:09:27/00:32:23, 0.815s/it]: train_loss_raw=1.6142, running_loss=1.6432, LR=0.000100
[2025-08-26 22:48:17,393][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013024] [Batch 00704/03080] [00:09:33/00:32:16, 0.815s/it]: train_loss_raw=1.5650, running_loss=1.6404, LR=0.000100
[2025-08-26 22:48:23,851][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013032] [Batch 00712/03080] [00:09:40/00:32:10, 0.815s/it]: train_loss_raw=1.5570, running_loss=1.6390, LR=0.000100
[2025-08-26 22:48:30,441][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013040] [Batch 00720/03080] [00:09:46/00:32:03, 0.815s/it]: train_loss_raw=1.6129, running_loss=1.6382, LR=0.000100
[2025-08-26 22:48:36,966][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013048] [Batch 00728/03080] [00:09:53/00:31:57, 0.815s/it]: train_loss_raw=1.6344, running_loss=1.6359, LR=0.000100
[2025-08-26 22:48:43,554][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013056] [Batch 00736/03080] [00:10:00/00:31:51, 0.815s/it]: train_loss_raw=1.5760, running_loss=1.6362, LR=0.000100
[2025-08-26 22:48:50,079][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013064] [Batch 00744/03080] [00:10:06/00:31:44, 0.815s/it]: train_loss_raw=1.6559, running_loss=1.6372, LR=0.000100
[2025-08-26 22:48:56,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013072] [Batch 00752/03080] [00:10:13/00:31:38, 0.815s/it]: train_loss_raw=1.6184, running_loss=1.6328, LR=0.000100
[2025-08-26 22:49:03,139][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013080] [Batch 00760/03080] [00:10:19/00:31:31, 0.815s/it]: train_loss_raw=1.7185, running_loss=1.6314, LR=0.000100
[2025-08-26 22:49:09,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013088] [Batch 00768/03080] [00:10:26/00:31:24, 0.815s/it]: train_loss_raw=1.6156, running_loss=1.6316, LR=0.000100
[2025-08-26 22:49:16,146][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013096] [Batch 00776/03080] [00:10:32/00:31:18, 0.815s/it]: train_loss_raw=1.5357, running_loss=1.6299, LR=0.000100
[2025-08-26 22:49:22,743][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013104] [Batch 00784/03080] [00:10:39/00:31:12, 0.815s/it]: train_loss_raw=1.4480, running_loss=1.6265, LR=0.000100
[2025-08-26 22:49:29,260][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013112] [Batch 00792/03080] [00:10:45/00:31:05, 0.815s/it]: train_loss_raw=1.6241, running_loss=1.6238, LR=0.000100
[2025-08-26 22:49:35,904][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013120] [Batch 00800/03080] [00:10:52/00:30:59, 0.816s/it]: train_loss_raw=1.6149, running_loss=1.6265, LR=0.000100
[2025-08-26 22:49:42,440][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013128] [Batch 00808/03080] [00:10:58/00:30:52, 0.816s/it]: train_loss_raw=1.6177, running_loss=1.6259, LR=0.000100
[2025-08-26 22:49:48,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013136] [Batch 00816/03080] [00:11:05/00:30:46, 0.815s/it]: train_loss_raw=1.5792, running_loss=1.6248, LR=0.000100
[2025-08-26 22:49:55,377][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013144] [Batch 00824/03080] [00:11:11/00:30:39, 0.815s/it]: train_loss_raw=1.5892, running_loss=1.6233, LR=0.000100
[2025-08-26 22:50:01,948][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013152] [Batch 00832/03080] [00:11:18/00:30:33, 0.815s/it]: train_loss_raw=1.6686, running_loss=1.6231, LR=0.000100
[2025-08-26 22:50:08,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013160] [Batch 00840/03080] [00:11:24/00:30:26, 0.815s/it]: train_loss_raw=1.7068, running_loss=1.6233, LR=0.000100
[2025-08-26 22:50:14,992][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013168] [Batch 00848/03080] [00:11:31/00:30:20, 0.815s/it]: train_loss_raw=1.6649, running_loss=1.6239, LR=0.000100
[2025-08-26 22:50:21,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013176] [Batch 00856/03080] [00:11:38/00:30:13, 0.815s/it]: train_loss_raw=1.6451, running_loss=1.6248, LR=0.000100
[2025-08-26 22:50:28,017][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013184] [Batch 00864/03080] [00:11:44/00:30:06, 0.815s/it]: train_loss_raw=1.7111, running_loss=1.6255, LR=0.000100
[2025-08-26 22:50:34,511][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013192] [Batch 00872/03080] [00:11:51/00:30:00, 0.815s/it]: train_loss_raw=1.6307, running_loss=1.6231, LR=0.000100
[2025-08-26 22:50:41,122][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013200] [Batch 00880/03080] [00:11:57/00:29:54, 0.815s/it]: train_loss_raw=1.6798, running_loss=1.6237, LR=0.000100
[2025-08-26 22:50:47,711][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013208] [Batch 00888/03080] [00:12:04/00:29:47, 0.816s/it]: train_loss_raw=1.6547, running_loss=1.6250, LR=0.000100
[2025-08-26 22:50:54,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013216] [Batch 00896/03080] [00:12:10/00:29:41, 0.816s/it]: train_loss_raw=1.6686, running_loss=1.6256, LR=0.000100
[2025-08-26 22:51:00,791][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013224] [Batch 00904/03080] [00:12:17/00:29:34, 0.816s/it]: train_loss_raw=1.5304, running_loss=1.6255, LR=0.000100
[2025-08-26 22:51:07,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013232] [Batch 00912/03080] [00:12:23/00:29:28, 0.816s/it]: train_loss_raw=1.6143, running_loss=1.6257, LR=0.000100
[2025-08-26 22:51:13,869][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013240] [Batch 00920/03080] [00:12:30/00:29:21, 0.816s/it]: train_loss_raw=1.6396, running_loss=1.6241, LR=0.000100
[2025-08-26 22:51:20,433][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013248] [Batch 00928/03080] [00:12:36/00:29:15, 0.816s/it]: train_loss_raw=1.6212, running_loss=1.6258, LR=0.000100
[2025-08-26 22:51:26,949][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013256] [Batch 00936/03080] [00:12:43/00:29:08, 0.816s/it]: train_loss_raw=1.5943, running_loss=1.6258, LR=0.000100
[2025-08-26 22:51:33,499][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013264] [Batch 00944/03080] [00:12:50/00:29:02, 0.816s/it]: train_loss_raw=1.5707, running_loss=1.6240, LR=0.000100
[2025-08-26 22:51:40,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013272] [Batch 00952/03080] [00:12:56/00:28:55, 0.816s/it]: train_loss_raw=1.6451, running_loss=1.6219, LR=0.000100
[2025-08-26 22:51:46,594][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013280] [Batch 00960/03080] [00:13:03/00:28:49, 0.816s/it]: train_loss_raw=1.6105, running_loss=1.6223, LR=0.000100
[2025-08-26 22:51:53,132][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013288] [Batch 00968/03080] [00:13:09/00:28:42, 0.816s/it]: train_loss_raw=1.5028, running_loss=1.6201, LR=0.000100
[2025-08-26 22:51:59,763][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013296] [Batch 00976/03080] [00:13:16/00:28:36, 0.816s/it]: train_loss_raw=1.6229, running_loss=1.6220, LR=0.000100
[2025-08-26 22:52:06,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013304] [Batch 00984/03080] [00:13:22/00:28:29, 0.816s/it]: train_loss_raw=1.6505, running_loss=1.6236, LR=0.000100
[2025-08-26 22:52:12,764][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013312] [Batch 00992/03080] [00:13:29/00:28:23, 0.816s/it]: train_loss_raw=1.5598, running_loss=1.6229, LR=0.000100
[2025-08-26 22:52:19,334][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013320] [Batch 01000/03080] [00:13:35/00:28:16, 0.816s/it]: train_loss_raw=1.6129, running_loss=1.6238, LR=0.000100
[2025-08-26 22:52:25,885][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013328] [Batch 01008/03080] [00:13:42/00:28:10, 0.816s/it]: train_loss_raw=1.6592, running_loss=1.6239, LR=0.000100
[2025-08-26 22:52:32,446][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013336] [Batch 01016/03080] [00:13:48/00:28:04, 0.816s/it]: train_loss_raw=1.6388, running_loss=1.6217, LR=0.000100
[2025-08-26 22:52:38,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013344] [Batch 01024/03080] [00:13:55/00:27:57, 0.816s/it]: train_loss_raw=1.6208, running_loss=1.6228, LR=0.000100
[2025-08-26 22:52:45,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013352] [Batch 01032/03080] [00:14:02/00:27:51, 0.816s/it]: train_loss_raw=1.6471, running_loss=1.6225, LR=0.000100
[2025-08-26 22:52:52,160][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013360] [Batch 01040/03080] [00:14:08/00:27:44, 0.816s/it]: train_loss_raw=1.6583, running_loss=1.6237, LR=0.000100
[2025-08-26 22:52:58,678][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013368] [Batch 01048/03080] [00:14:15/00:27:38, 0.816s/it]: train_loss_raw=1.6033, running_loss=1.6234, LR=0.000100
[2025-08-26 22:53:05,223][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013376] [Batch 01056/03080] [00:14:21/00:27:31, 0.816s/it]: train_loss_raw=1.6288, running_loss=1.6235, LR=0.000100
[2025-08-26 22:53:11,757][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013384] [Batch 01064/03080] [00:14:28/00:27:25, 0.816s/it]: train_loss_raw=1.6272, running_loss=1.6208, LR=0.000100
[2025-08-26 22:53:18,322][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013392] [Batch 01072/03080] [00:14:34/00:27:18, 0.816s/it]: train_loss_raw=1.5962, running_loss=1.6215, LR=0.000100
[2025-08-26 22:53:24,904][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013400] [Batch 01080/03080] [00:14:41/00:27:12, 0.816s/it]: train_loss_raw=1.5458, running_loss=1.6230, LR=0.000100
[2025-08-26 22:53:31,483][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013408] [Batch 01088/03080] [00:14:47/00:27:05, 0.816s/it]: train_loss_raw=1.6530, running_loss=1.6210, LR=0.000100
[2025-08-26 22:53:37,996][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013416] [Batch 01096/03080] [00:14:54/00:26:59, 0.816s/it]: train_loss_raw=1.6055, running_loss=1.6196, LR=0.000100
[2025-08-26 22:53:44,583][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013424] [Batch 01104/03080] [00:15:01/00:26:52, 0.816s/it]: train_loss_raw=1.6283, running_loss=1.6203, LR=0.000100
[2025-08-26 22:53:51,100][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013432] [Batch 01112/03080] [00:15:07/00:26:46, 0.816s/it]: train_loss_raw=1.6873, running_loss=1.6217, LR=0.000100
[2025-08-26 22:53:57,660][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013440] [Batch 01120/03080] [00:15:14/00:26:39, 0.816s/it]: train_loss_raw=1.6541, running_loss=1.6203, LR=0.000100
[2025-08-26 22:54:04,186][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013448] [Batch 01128/03080] [00:15:20/00:26:33, 0.816s/it]: train_loss_raw=1.6356, running_loss=1.6214, LR=0.000100
[2025-08-26 22:54:10,828][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013456] [Batch 01136/03080] [00:15:27/00:26:26, 0.816s/it]: train_loss_raw=1.6727, running_loss=1.6243, LR=0.000100
[2025-08-26 22:54:17,346][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013464] [Batch 01144/03080] [00:15:33/00:26:20, 0.816s/it]: train_loss_raw=1.6783, running_loss=1.6248, LR=0.000100
[2025-08-26 22:54:23,833][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013472] [Batch 01152/03080] [00:15:40/00:26:13, 0.816s/it]: train_loss_raw=1.5781, running_loss=1.6201, LR=0.000100
[2025-08-26 22:54:30,395][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013480] [Batch 01160/03080] [00:15:46/00:26:07, 0.816s/it]: train_loss_raw=1.6298, running_loss=1.6214, LR=0.000100
[2025-08-26 22:54:36,914][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013488] [Batch 01168/03080] [00:15:53/00:26:00, 0.816s/it]: train_loss_raw=1.6545, running_loss=1.6214, LR=0.000100
[2025-08-26 22:54:43,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013496] [Batch 01176/03080] [00:16:00/00:25:54, 0.816s/it]: train_loss_raw=1.7400, running_loss=1.6194, LR=0.000100
[2025-08-26 22:54:49,957][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013504] [Batch 01184/03080] [00:16:06/00:25:47, 0.816s/it]: train_loss_raw=1.6294, running_loss=1.6178, LR=0.000100
[2025-08-26 22:54:56,533][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013512] [Batch 01192/03080] [00:16:13/00:25:41, 0.816s/it]: train_loss_raw=1.7278, running_loss=1.6177, LR=0.000100
[2025-08-26 22:55:03,116][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013520] [Batch 01200/03080] [00:16:19/00:25:34, 0.816s/it]: train_loss_raw=1.5662, running_loss=1.6179, LR=0.000100
[2025-08-26 22:55:09,663][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013528] [Batch 01208/03080] [00:16:26/00:25:28, 0.816s/it]: train_loss_raw=1.5591, running_loss=1.6163, LR=0.000100
[2025-08-26 22:55:16,210][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013536] [Batch 01216/03080] [00:16:32/00:25:21, 0.816s/it]: train_loss_raw=1.6679, running_loss=1.6132, LR=0.000100
[2025-08-26 22:55:22,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013544] [Batch 01224/03080] [00:16:39/00:25:15, 0.816s/it]: train_loss_raw=1.5108, running_loss=1.6110, LR=0.000100
[2025-08-26 22:55:29,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013552] [Batch 01232/03080] [00:16:45/00:25:08, 0.816s/it]: train_loss_raw=1.5743, running_loss=1.6080, LR=0.000100
[2025-08-26 22:55:35,832][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013560] [Batch 01240/03080] [00:16:52/00:25:02, 0.816s/it]: train_loss_raw=1.5269, running_loss=1.6080, LR=0.000100
[2025-08-26 22:55:42,367][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013568] [Batch 01248/03080] [00:16:58/00:24:55, 0.816s/it]: train_loss_raw=1.7118, running_loss=1.6068, LR=0.000100
[2025-08-26 22:55:48,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013576] [Batch 01256/03080] [00:17:05/00:24:49, 0.816s/it]: train_loss_raw=1.5677, running_loss=1.6103, LR=0.000100
[2025-08-26 22:55:55,475][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013584] [Batch 01264/03080] [00:17:11/00:24:42, 0.816s/it]: train_loss_raw=1.6129, running_loss=1.6095, LR=0.000100
[2025-08-26 22:56:02,011][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013592] [Batch 01272/03080] [00:17:18/00:24:36, 0.816s/it]: train_loss_raw=1.5142, running_loss=1.6105, LR=0.000100
[2025-08-26 22:56:08,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013600] [Batch 01280/03080] [00:17:25/00:24:29, 0.816s/it]: train_loss_raw=1.7460, running_loss=1.6117, LR=0.000100
[2025-08-26 22:56:15,199][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013608] [Batch 01288/03080] [00:17:31/00:24:23, 0.817s/it]: train_loss_raw=1.5956, running_loss=1.6121, LR=0.000100
[2025-08-26 22:56:21,738][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013616] [Batch 01296/03080] [00:17:38/00:24:16, 0.817s/it]: train_loss_raw=1.6217, running_loss=1.6112, LR=0.000100
[2025-08-26 22:56:28,318][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013624] [Batch 01304/03080] [00:17:44/00:24:10, 0.817s/it]: train_loss_raw=1.4626, running_loss=1.6098, LR=0.000100
[2025-08-26 22:56:34,882][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013632] [Batch 01312/03080] [00:17:51/00:24:03, 0.817s/it]: train_loss_raw=1.5019, running_loss=1.6079, LR=0.000100
[2025-08-26 22:56:41,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013640] [Batch 01320/03080] [00:17:57/00:23:57, 0.817s/it]: train_loss_raw=1.5780, running_loss=1.6060, LR=0.000100
[2025-08-26 22:56:47,943][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013648] [Batch 01328/03080] [00:18:04/00:23:50, 0.817s/it]: train_loss_raw=1.5531, running_loss=1.6058, LR=0.000100
[2025-08-26 22:56:54,518][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013656] [Batch 01336/03080] [00:18:11/00:23:44, 0.817s/it]: train_loss_raw=1.5948, running_loss=1.6040, LR=0.000100
[2025-08-26 22:57:01,103][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013664] [Batch 01344/03080] [00:18:17/00:23:37, 0.817s/it]: train_loss_raw=1.6302, running_loss=1.6046, LR=0.000100
[2025-08-26 22:57:07,686][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013672] [Batch 01352/03080] [00:18:24/00:23:31, 0.817s/it]: train_loss_raw=1.6102, running_loss=1.6043, LR=0.000100
[2025-08-26 22:57:14,237][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013680] [Batch 01360/03080] [00:18:30/00:23:24, 0.817s/it]: train_loss_raw=1.5300, running_loss=1.6040, LR=0.000100
[2025-08-26 22:57:20,806][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013688] [Batch 01368/03080] [00:18:37/00:23:18, 0.817s/it]: train_loss_raw=1.6598, running_loss=1.6060, LR=0.000100
[2025-08-26 22:57:27,401][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013696] [Batch 01376/03080] [00:18:43/00:23:11, 0.817s/it]: train_loss_raw=1.6145, running_loss=1.6047, LR=0.000100
[2025-08-26 22:57:33,982][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013704] [Batch 01384/03080] [00:18:50/00:23:05, 0.817s/it]: train_loss_raw=1.6336, running_loss=1.6051, LR=0.000100
[2025-08-26 22:57:40,596][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013712] [Batch 01392/03080] [00:18:57/00:22:58, 0.817s/it]: train_loss_raw=1.6461, running_loss=1.6060, LR=0.000100
[2025-08-26 22:57:47,195][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013720] [Batch 01400/03080] [00:19:03/00:22:52, 0.817s/it]: train_loss_raw=1.7583, running_loss=1.6083, LR=0.000100
[2025-08-26 22:57:53,772][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013728] [Batch 01408/03080] [00:19:10/00:22:45, 0.817s/it]: train_loss_raw=1.5523, running_loss=1.6033, LR=0.000100
[2025-08-26 22:58:00,396][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013736] [Batch 01416/03080] [00:19:16/00:22:39, 0.817s/it]: train_loss_raw=1.6638, running_loss=1.6036, LR=0.000100
[2025-08-26 22:58:06,994][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013744] [Batch 01424/03080] [00:19:23/00:22:33, 0.817s/it]: train_loss_raw=1.6177, running_loss=1.6017, LR=0.000100
[2025-08-26 22:58:13,653][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013752] [Batch 01432/03080] [00:19:30/00:22:26, 0.817s/it]: train_loss_raw=1.6173, running_loss=1.6050, LR=0.000100
[2025-08-26 22:58:20,252][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013760] [Batch 01440/03080] [00:19:36/00:22:20, 0.817s/it]: train_loss_raw=1.5894, running_loss=1.6051, LR=0.000100
[2025-08-26 22:58:26,828][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013768] [Batch 01448/03080] [00:19:43/00:22:13, 0.817s/it]: train_loss_raw=1.5149, running_loss=1.6038, LR=0.000100
[2025-08-26 22:58:33,463][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013776] [Batch 01456/03080] [00:19:49/00:22:07, 0.817s/it]: train_loss_raw=1.6493, running_loss=1.6048, LR=0.000100
[2025-08-26 22:58:40,086][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013784] [Batch 01464/03080] [00:19:56/00:22:00, 0.817s/it]: train_loss_raw=1.5827, running_loss=1.6039, LR=0.000100
[2025-08-26 22:58:46,698][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013792] [Batch 01472/03080] [00:20:03/00:21:54, 0.817s/it]: train_loss_raw=1.5673, running_loss=1.6017, LR=0.000100
[2025-08-26 22:58:53,346][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013800] [Batch 01480/03080] [00:20:09/00:21:47, 0.817s/it]: train_loss_raw=1.7401, running_loss=1.6039, LR=0.000100
[2025-08-26 22:58:59,898][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013808] [Batch 01488/03080] [00:20:16/00:21:41, 0.817s/it]: train_loss_raw=1.5208, running_loss=1.6019, LR=0.000100
[2025-08-26 22:59:06,487][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013816] [Batch 01496/03080] [00:20:22/00:21:34, 0.818s/it]: train_loss_raw=1.6126, running_loss=1.6022, LR=0.000100
[2025-08-26 22:59:13,111][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013824] [Batch 01504/03080] [00:20:29/00:21:28, 0.818s/it]: train_loss_raw=1.5596, running_loss=1.5995, LR=0.000100
[2025-08-26 22:59:19,706][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013832] [Batch 01512/03080] [00:20:36/00:21:21, 0.818s/it]: train_loss_raw=1.5821, running_loss=1.5997, LR=0.000100
[2025-08-26 22:59:26,330][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013840] [Batch 01520/03080] [00:20:42/00:21:15, 0.818s/it]: train_loss_raw=1.6757, running_loss=1.5982, LR=0.000100
[2025-08-26 22:59:33,015][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013848] [Batch 01528/03080] [00:20:49/00:21:09, 0.818s/it]: train_loss_raw=1.6070, running_loss=1.6019, LR=0.000100
[2025-08-26 22:59:39,565][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013856] [Batch 01536/03080] [00:20:56/00:21:02, 0.818s/it]: train_loss_raw=1.5456, running_loss=1.6021, LR=0.000100
[2025-08-26 22:59:46,101][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013864] [Batch 01544/03080] [00:21:02/00:20:56, 0.818s/it]: train_loss_raw=1.5780, running_loss=1.6008, LR=0.000100
[2025-08-26 22:59:52,740][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013872] [Batch 01552/03080] [00:21:09/00:20:49, 0.818s/it]: train_loss_raw=1.5477, running_loss=1.5995, LR=0.000100
[2025-08-26 22:59:59,340][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013880] [Batch 01560/03080] [00:21:15/00:20:43, 0.818s/it]: train_loss_raw=1.5709, running_loss=1.5970, LR=0.000100
[2025-08-26 23:00:06,012][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013888] [Batch 01568/03080] [00:21:22/00:20:36, 0.818s/it]: train_loss_raw=1.6404, running_loss=1.5980, LR=0.000100
[2025-08-26 23:00:12,627][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013896] [Batch 01576/03080] [00:21:29/00:20:30, 0.818s/it]: train_loss_raw=1.5978, running_loss=1.5986, LR=0.000100
[2025-08-26 23:00:19,292][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013904] [Batch 01584/03080] [00:21:35/00:20:23, 0.818s/it]: train_loss_raw=1.5576, running_loss=1.6011, LR=0.000100
[2025-08-26 23:00:25,974][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013912] [Batch 01592/03080] [00:21:42/00:20:17, 0.818s/it]: train_loss_raw=1.5650, running_loss=1.6033, LR=0.000100
[2025-08-26 23:00:32,615][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013920] [Batch 01600/03080] [00:21:49/00:20:10, 0.818s/it]: train_loss_raw=1.6233, running_loss=1.6061, LR=0.000100
[2025-08-26 23:00:39,223][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013928] [Batch 01608/03080] [00:21:55/00:20:04, 0.818s/it]: train_loss_raw=1.5560, running_loss=1.6049, LR=0.000100
[2025-08-26 23:00:45,837][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013936] [Batch 01616/03080] [00:22:02/00:19:57, 0.818s/it]: train_loss_raw=1.6094, running_loss=1.6056, LR=0.000100
[2025-08-26 23:00:52,531][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013944] [Batch 01624/03080] [00:22:09/00:19:51, 0.818s/it]: train_loss_raw=1.5468, running_loss=1.6049, LR=0.000100
[2025-08-26 23:00:59,149][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013952] [Batch 01632/03080] [00:22:15/00:19:45, 0.818s/it]: train_loss_raw=1.5809, running_loss=1.6044, LR=0.000100
[2025-08-26 23:01:05,721][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013960] [Batch 01640/03080] [00:22:22/00:19:38, 0.818s/it]: train_loss_raw=1.6042, running_loss=1.6031, LR=0.000100
[2025-08-26 23:01:12,381][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013968] [Batch 01648/03080] [00:22:28/00:19:32, 0.818s/it]: train_loss_raw=1.6511, running_loss=1.6032, LR=0.000100
[2025-08-26 23:01:18,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013976] [Batch 01656/03080] [00:22:35/00:19:25, 0.819s/it]: train_loss_raw=1.6008, running_loss=1.6024, LR=0.000100
[2025-08-26 23:01:25,600][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013984] [Batch 01664/03080] [00:22:42/00:19:19, 0.819s/it]: train_loss_raw=1.5692, running_loss=1.6024, LR=0.000100
[2025-08-26 23:01:32,134][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 013992] [Batch 01672/03080] [00:22:48/00:19:12, 0.819s/it]: train_loss_raw=1.6041, running_loss=1.6054, LR=0.000100
[2025-08-26 23:01:38,725][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014000] [Batch 01680/03080] [00:22:55/00:19:06, 0.819s/it]: train_loss_raw=1.6195, running_loss=1.6036, LR=0.000100
[2025-08-26 23:01:50,999][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014008] [Batch 01688/03080] [00:23:07/00:19:04, 0.822s/it]: train_loss_raw=1.6448, running_loss=1.6065, LR=0.000100
[2025-08-26 23:01:57,567][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014016] [Batch 01696/03080] [00:23:14/00:18:57, 0.822s/it]: train_loss_raw=1.5671, running_loss=1.6069, LR=0.000100
[2025-08-26 23:02:04,144][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014024] [Batch 01704/03080] [00:23:20/00:18:51, 0.822s/it]: train_loss_raw=1.6653, running_loss=1.6106, LR=0.000100
[2025-08-26 23:02:10,770][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014032] [Batch 01712/03080] [00:23:27/00:18:44, 0.822s/it]: train_loss_raw=1.6152, running_loss=1.6068, LR=0.000100
[2025-08-26 23:02:17,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014040] [Batch 01720/03080] [00:23:33/00:18:37, 0.822s/it]: train_loss_raw=1.6283, running_loss=1.6068, LR=0.000100
[2025-08-26 23:02:23,950][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014048] [Batch 01728/03080] [00:23:40/00:18:31, 0.822s/it]: train_loss_raw=1.5798, running_loss=1.6071, LR=0.000100
[2025-08-26 23:02:30,625][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014056] [Batch 01736/03080] [00:23:47/00:18:24, 0.822s/it]: train_loss_raw=1.6100, running_loss=1.6081, LR=0.000100
[2025-08-26 23:02:37,209][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014064] [Batch 01744/03080] [00:23:53/00:18:18, 0.822s/it]: train_loss_raw=1.6252, running_loss=1.6067, LR=0.000100
[2025-08-26 23:02:43,810][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014072] [Batch 01752/03080] [00:24:00/00:18:11, 0.822s/it]: train_loss_raw=1.5523, running_loss=1.6043, LR=0.000100
[2025-08-26 23:02:50,399][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014080] [Batch 01760/03080] [00:24:06/00:18:05, 0.822s/it]: train_loss_raw=1.5853, running_loss=1.6034, LR=0.000100
[2025-08-26 23:02:56,984][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014088] [Batch 01768/03080] [00:24:13/00:17:58, 0.822s/it]: train_loss_raw=1.6065, running_loss=1.6019, LR=0.000100
[2025-08-26 23:03:03,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014096] [Batch 01776/03080] [00:24:20/00:17:52, 0.822s/it]: train_loss_raw=1.5668, running_loss=1.6017, LR=0.000100
[2025-08-26 23:03:10,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014104] [Batch 01784/03080] [00:24:26/00:17:45, 0.822s/it]: train_loss_raw=1.5782, running_loss=1.6013, LR=0.000100
[2025-08-26 23:03:16,945][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014112] [Batch 01792/03080] [00:24:33/00:17:39, 0.822s/it]: train_loss_raw=1.6745, running_loss=1.5999, LR=0.000100
[2025-08-26 23:03:23,548][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014120] [Batch 01800/03080] [00:24:40/00:17:32, 0.822s/it]: train_loss_raw=1.5556, running_loss=1.6005, LR=0.000100
[2025-08-26 23:03:30,204][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014128] [Batch 01808/03080] [00:24:46/00:17:25, 0.822s/it]: train_loss_raw=1.5749, running_loss=1.5995, LR=0.000100
[2025-08-26 23:03:36,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014136] [Batch 01816/03080] [00:24:53/00:17:19, 0.822s/it]: train_loss_raw=1.7206, running_loss=1.6009, LR=0.000100
[2025-08-26 23:03:43,297][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014144] [Batch 01824/03080] [00:24:59/00:17:12, 0.822s/it]: train_loss_raw=1.6298, running_loss=1.6007, LR=0.000100
[2025-08-26 23:03:49,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014152] [Batch 01832/03080] [00:25:06/00:17:06, 0.822s/it]: train_loss_raw=1.6175, running_loss=1.6017, LR=0.000100
[2025-08-26 23:03:56,596][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014160] [Batch 01840/03080] [00:25:13/00:16:59, 0.822s/it]: train_loss_raw=1.5344, running_loss=1.6034, LR=0.000100
[2025-08-26 23:04:03,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014168] [Batch 01848/03080] [00:25:19/00:16:53, 0.822s/it]: train_loss_raw=1.5254, running_loss=1.6037, LR=0.000100
[2025-08-26 23:04:09,831][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014176] [Batch 01856/03080] [00:25:26/00:16:46, 0.822s/it]: train_loss_raw=1.6229, running_loss=1.6034, LR=0.000100
[2025-08-26 23:04:16,467][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014184] [Batch 01864/03080] [00:25:32/00:16:40, 0.822s/it]: train_loss_raw=1.5083, running_loss=1.5973, LR=0.000100
[2025-08-26 23:04:23,117][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014192] [Batch 01872/03080] [00:25:39/00:16:33, 0.822s/it]: train_loss_raw=1.5343, running_loss=1.5969, LR=0.000100
[2025-08-26 23:04:29,763][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014200] [Batch 01880/03080] [00:25:46/00:16:26, 0.822s/it]: train_loss_raw=1.6812, running_loss=1.5978, LR=0.000100
[2025-08-26 23:04:36,394][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014208] [Batch 01888/03080] [00:25:52/00:16:20, 0.823s/it]: train_loss_raw=1.6382, running_loss=1.5979, LR=0.000100
[2025-08-26 23:04:43,059][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014216] [Batch 01896/03080] [00:25:59/00:16:13, 0.823s/it]: train_loss_raw=1.5833, running_loss=1.5988, LR=0.000100
[2025-08-26 23:04:49,646][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014224] [Batch 01904/03080] [00:26:06/00:16:07, 0.823s/it]: train_loss_raw=1.5291, running_loss=1.5971, LR=0.000100
[2025-08-26 23:04:56,200][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014232] [Batch 01912/03080] [00:26:12/00:16:00, 0.823s/it]: train_loss_raw=1.6050, running_loss=1.5971, LR=0.000100
[2025-08-26 23:05:02,853][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014240] [Batch 01920/03080] [00:26:19/00:15:54, 0.823s/it]: train_loss_raw=1.5766, running_loss=1.5971, LR=0.000100
[2025-08-26 23:05:09,511][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014248] [Batch 01928/03080] [00:26:26/00:15:47, 0.823s/it]: train_loss_raw=1.5677, running_loss=1.5967, LR=0.000100
[2025-08-26 23:05:16,094][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014256] [Batch 01936/03080] [00:26:32/00:15:41, 0.823s/it]: train_loss_raw=1.5829, running_loss=1.5975, LR=0.000100
[2025-08-26 23:05:22,722][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014264] [Batch 01944/03080] [00:26:39/00:15:34, 0.823s/it]: train_loss_raw=1.5863, running_loss=1.5980, LR=0.000100
[2025-08-26 23:05:29,397][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014272] [Batch 01952/03080] [00:26:45/00:15:27, 0.823s/it]: train_loss_raw=1.6051, running_loss=1.5950, LR=0.000100
[2025-08-26 23:05:36,009][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014280] [Batch 01960/03080] [00:26:52/00:15:21, 0.823s/it]: train_loss_raw=1.6324, running_loss=1.5969, LR=0.000100
[2025-08-26 23:05:42,642][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014288] [Batch 01968/03080] [00:26:59/00:15:14, 0.823s/it]: train_loss_raw=1.5161, running_loss=1.5943, LR=0.000100
[2025-08-26 23:05:49,168][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014296] [Batch 01976/03080] [00:27:05/00:15:08, 0.823s/it]: train_loss_raw=1.5702, running_loss=1.5924, LR=0.000100
[2025-08-26 23:05:55,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014304] [Batch 01984/03080] [00:27:12/00:15:01, 0.823s/it]: train_loss_raw=1.6226, running_loss=1.5916, LR=0.000100
[2025-08-26 23:06:02,313][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014312] [Batch 01992/03080] [00:27:18/00:14:55, 0.823s/it]: train_loss_raw=1.6133, running_loss=1.5904, LR=0.000100
[2025-08-26 23:06:08,942][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014320] [Batch 02000/03080] [00:27:25/00:14:48, 0.823s/it]: train_loss_raw=1.6432, running_loss=1.5899, LR=0.000100
[2025-08-26 23:06:15,510][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014328] [Batch 02008/03080] [00:27:32/00:14:41, 0.823s/it]: train_loss_raw=1.5638, running_loss=1.5887, LR=0.000100
[2025-08-26 23:06:22,171][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014336] [Batch 02016/03080] [00:27:38/00:14:35, 0.823s/it]: train_loss_raw=1.6045, running_loss=1.5886, LR=0.000100
[2025-08-26 23:06:28,757][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014344] [Batch 02024/03080] [00:27:45/00:14:28, 0.823s/it]: train_loss_raw=1.6483, running_loss=1.5902, LR=0.000100
[2025-08-26 23:06:35,335][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014352] [Batch 02032/03080] [00:27:51/00:14:22, 0.823s/it]: train_loss_raw=1.5807, running_loss=1.5890, LR=0.000100
[2025-08-26 23:06:42,022][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014360] [Batch 02040/03080] [00:27:58/00:14:15, 0.823s/it]: train_loss_raw=1.6128, running_loss=1.5882, LR=0.000100
[2025-08-26 23:06:48,605][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014368] [Batch 02048/03080] [00:28:05/00:14:09, 0.823s/it]: train_loss_raw=1.5197, running_loss=1.5870, LR=0.000100
[2025-08-26 23:06:55,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014376] [Batch 02056/03080] [00:28:11/00:14:02, 0.823s/it]: train_loss_raw=1.5378, running_loss=1.5874, LR=0.000100
[2025-08-26 23:07:01,875][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014384] [Batch 02064/03080] [00:28:18/00:13:56, 0.823s/it]: train_loss_raw=1.6589, running_loss=1.5880, LR=0.000100
[2025-08-26 23:07:08,539][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014392] [Batch 02072/03080] [00:28:25/00:13:49, 0.823s/it]: train_loss_raw=1.4174, running_loss=1.5859, LR=0.000100
[2025-08-26 23:07:15,123][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014400] [Batch 02080/03080] [00:28:31/00:13:42, 0.823s/it]: train_loss_raw=1.6610, running_loss=1.5868, LR=0.000100
[2025-08-26 23:07:21,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014408] [Batch 02088/03080] [00:28:38/00:13:36, 0.823s/it]: train_loss_raw=1.4673, running_loss=1.5836, LR=0.000100
[2025-08-26 23:07:28,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014416] [Batch 02096/03080] [00:28:44/00:13:29, 0.823s/it]: train_loss_raw=1.5264, running_loss=1.5833, LR=0.000100
[2025-08-26 23:07:34,948][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014424] [Batch 02104/03080] [00:28:51/00:13:23, 0.823s/it]: train_loss_raw=1.5347, running_loss=1.5838, LR=0.000100
[2025-08-26 23:07:41,472][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014432] [Batch 02112/03080] [00:28:57/00:13:16, 0.823s/it]: train_loss_raw=1.5009, running_loss=1.5806, LR=0.000100
[2025-08-26 23:07:47,951][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014440] [Batch 02120/03080] [00:29:04/00:13:09, 0.823s/it]: train_loss_raw=1.5233, running_loss=1.5802, LR=0.000100
[2025-08-26 23:07:54,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014448] [Batch 02128/03080] [00:29:10/00:13:03, 0.823s/it]: train_loss_raw=1.6576, running_loss=1.5814, LR=0.000100
[2025-08-26 23:08:00,466][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014456] [Batch 02136/03080] [00:29:16/00:12:56, 0.823s/it]: train_loss_raw=1.7306, running_loss=1.5812, LR=0.000100
[2025-08-26 23:08:06,432][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014464] [Batch 02144/03080] [00:29:22/00:12:49, 0.822s/it]: train_loss_raw=1.5956, running_loss=1.5805, LR=0.000100
[2025-08-26 23:08:12,564][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014472] [Batch 02152/03080] [00:29:29/00:12:42, 0.822s/it]: train_loss_raw=1.6553, running_loss=1.5829, LR=0.000100
[2025-08-26 23:08:18,708][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014480] [Batch 02160/03080] [00:29:35/00:12:36, 0.822s/it]: train_loss_raw=1.5794, running_loss=1.5818, LR=0.000100
[2025-08-26 23:08:24,814][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014488] [Batch 02168/03080] [00:29:41/00:12:29, 0.822s/it]: train_loss_raw=1.5587, running_loss=1.5814, LR=0.000100
[2025-08-26 23:08:30,950][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014496] [Batch 02176/03080] [00:29:47/00:12:22, 0.821s/it]: train_loss_raw=1.5761, running_loss=1.5811, LR=0.000100
[2025-08-26 23:08:36,900][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014504] [Batch 02184/03080] [00:29:53/00:12:15, 0.821s/it]: train_loss_raw=1.6022, running_loss=1.5797, LR=0.000100
[2025-08-26 23:08:42,889][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014512] [Batch 02192/03080] [00:29:59/00:12:08, 0.821s/it]: train_loss_raw=1.6861, running_loss=1.5816, LR=0.000100
[2025-08-26 23:08:48,930][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014520] [Batch 02200/03080] [00:30:05/00:12:02, 0.821s/it]: train_loss_raw=1.5757, running_loss=1.5800, LR=0.000100
[2025-08-26 23:08:54,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014528] [Batch 02208/03080] [00:30:11/00:11:55, 0.820s/it]: train_loss_raw=1.5243, running_loss=1.5771, LR=0.000100
[2025-08-26 23:09:00,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014536] [Batch 02216/03080] [00:30:17/00:11:48, 0.820s/it]: train_loss_raw=1.5289, running_loss=1.5774, LR=0.000100
[2025-08-26 23:09:07,169][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014544] [Batch 02224/03080] [00:30:23/00:11:41, 0.820s/it]: train_loss_raw=1.4952, running_loss=1.5757, LR=0.000100
[2025-08-26 23:09:13,178][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014552] [Batch 02232/03080] [00:30:29/00:11:35, 0.820s/it]: train_loss_raw=1.5991, running_loss=1.5769, LR=0.000100
[2025-08-26 23:09:19,285][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014560] [Batch 02240/03080] [00:30:35/00:11:28, 0.820s/it]: train_loss_raw=1.7017, running_loss=1.5783, LR=0.000100
[2025-08-26 23:09:25,401][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014568] [Batch 02248/03080] [00:30:41/00:11:21, 0.819s/it]: train_loss_raw=1.5883, running_loss=1.5801, LR=0.000100
[2025-08-26 23:09:31,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014576] [Batch 02256/03080] [00:30:47/00:11:14, 0.819s/it]: train_loss_raw=1.5395, running_loss=1.5796, LR=0.000100
[2025-08-26 23:09:37,132][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014584] [Batch 02264/03080] [00:30:53/00:11:08, 0.819s/it]: train_loss_raw=1.5179, running_loss=1.5820, LR=0.000100
[2025-08-26 23:09:43,221][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014592] [Batch 02272/03080] [00:30:59/00:11:01, 0.819s/it]: train_loss_raw=1.6358, running_loss=1.5819, LR=0.000100
[2025-08-26 23:09:49,366][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014600] [Batch 02280/03080] [00:31:05/00:10:54, 0.818s/it]: train_loss_raw=1.6142, running_loss=1.5821, LR=0.000100
[2025-08-26 23:09:55,400][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014608] [Batch 02288/03080] [00:31:11/00:10:47, 0.818s/it]: train_loss_raw=1.6038, running_loss=1.5854, LR=0.000100
[2025-08-26 23:10:01,311][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014616] [Batch 02296/03080] [00:31:17/00:10:41, 0.818s/it]: train_loss_raw=1.5880, running_loss=1.5864, LR=0.000100
[2025-08-26 23:10:07,273][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014624] [Batch 02304/03080] [00:31:23/00:10:34, 0.818s/it]: train_loss_raw=1.5764, running_loss=1.5840, LR=0.000100
[2025-08-26 23:10:13,341][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014632] [Batch 02312/03080] [00:31:29/00:10:27, 0.817s/it]: train_loss_raw=1.5007, running_loss=1.5817, LR=0.000100
[2025-08-26 23:10:19,360][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014640] [Batch 02320/03080] [00:31:35/00:10:21, 0.817s/it]: train_loss_raw=1.5366, running_loss=1.5817, LR=0.000100
[2025-08-26 23:10:25,259][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014648] [Batch 02328/03080] [00:31:41/00:10:14, 0.817s/it]: train_loss_raw=1.5601, running_loss=1.5797, LR=0.000100
[2025-08-26 23:10:31,084][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014656] [Batch 02336/03080] [00:31:47/00:10:07, 0.817s/it]: train_loss_raw=1.5596, running_loss=1.5789, LR=0.000100
[2025-08-26 23:10:36,842][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014664] [Batch 02344/03080] [00:31:53/00:10:00, 0.816s/it]: train_loss_raw=1.5331, running_loss=1.5786, LR=0.000100
[2025-08-26 23:10:42,720][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014672] [Batch 02352/03080] [00:31:59/00:09:54, 0.816s/it]: train_loss_raw=1.6053, running_loss=1.5795, LR=0.000100
[2025-08-26 23:10:48,683][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014680] [Batch 02360/03080] [00:32:05/00:09:47, 0.816s/it]: train_loss_raw=1.5257, running_loss=1.5777, LR=0.000100
[2025-08-26 23:10:54,645][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014688] [Batch 02368/03080] [00:32:11/00:09:40, 0.816s/it]: train_loss_raw=1.5251, running_loss=1.5748, LR=0.000100
[2025-08-26 23:11:00,736][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014696] [Batch 02376/03080] [00:32:17/00:09:33, 0.815s/it]: train_loss_raw=1.5315, running_loss=1.5760, LR=0.000100
[2025-08-26 23:11:06,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014704] [Batch 02384/03080] [00:32:23/00:09:27, 0.815s/it]: train_loss_raw=1.6548, running_loss=1.5736, LR=0.000100
[2025-08-26 23:11:12,716][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014712] [Batch 02392/03080] [00:32:29/00:09:20, 0.815s/it]: train_loss_raw=1.5255, running_loss=1.5728, LR=0.000100
[2025-08-26 23:11:18,382][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014720] [Batch 02400/03080] [00:32:34/00:09:13, 0.815s/it]: train_loss_raw=1.5457, running_loss=1.5711, LR=0.000100
[2025-08-26 23:11:24,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014728] [Batch 02408/03080] [00:32:40/00:09:07, 0.814s/it]: train_loss_raw=1.5719, running_loss=1.5708, LR=0.000100
[2025-08-26 23:11:30,019][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014736] [Batch 02416/03080] [00:32:46/00:09:00, 0.814s/it]: train_loss_raw=1.6512, running_loss=1.5706, LR=0.000100
[2025-08-26 23:11:35,701][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014744] [Batch 02424/03080] [00:32:52/00:08:53, 0.814s/it]: train_loss_raw=1.5602, running_loss=1.5681, LR=0.000100
[2025-08-26 23:11:41,517][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014752] [Batch 02432/03080] [00:32:58/00:08:47, 0.813s/it]: train_loss_raw=1.5692, running_loss=1.5651, LR=0.000100
[2025-08-26 23:11:47,336][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014760] [Batch 02440/03080] [00:33:03/00:08:40, 0.813s/it]: train_loss_raw=1.5390, running_loss=1.5636, LR=0.000100
[2025-08-26 23:11:53,295][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014768] [Batch 02448/03080] [00:33:09/00:08:33, 0.813s/it]: train_loss_raw=1.5769, running_loss=1.5625, LR=0.000100
[2025-08-26 23:11:59,044][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014776] [Batch 02456/03080] [00:33:15/00:08:27, 0.813s/it]: train_loss_raw=1.5352, running_loss=1.5602, LR=0.000100
[2025-08-26 23:12:04,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014784] [Batch 02464/03080] [00:33:21/00:08:20, 0.812s/it]: train_loss_raw=1.6099, running_loss=1.5602, LR=0.000100
[2025-08-26 23:12:10,496][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014792] [Batch 02472/03080] [00:33:26/00:08:13, 0.812s/it]: train_loss_raw=1.5886, running_loss=1.5620, LR=0.000100
[2025-08-26 23:12:16,371][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014800] [Batch 02480/03080] [00:33:32/00:08:06, 0.812s/it]: train_loss_raw=1.6077, running_loss=1.5651, LR=0.000100
[2025-08-26 23:12:22,185][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014808] [Batch 02488/03080] [00:33:38/00:08:00, 0.811s/it]: train_loss_raw=1.5031, running_loss=1.5644, LR=0.000100
[2025-08-26 23:12:27,973][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014816] [Batch 02496/03080] [00:33:44/00:07:53, 0.811s/it]: train_loss_raw=1.6049, running_loss=1.5659, LR=0.000100
[2025-08-26 23:12:34,045][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014824] [Batch 02504/03080] [00:33:50/00:07:47, 0.811s/it]: train_loss_raw=1.5678, running_loss=1.5657, LR=0.000100
[2025-08-26 23:12:39,922][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014832] [Batch 02512/03080] [00:33:56/00:07:40, 0.811s/it]: train_loss_raw=1.5897, running_loss=1.5628, LR=0.000100
[2025-08-26 23:12:45,854][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014840] [Batch 02520/03080] [00:34:02/00:07:33, 0.810s/it]: train_loss_raw=1.4792, running_loss=1.5624, LR=0.000100
[2025-08-26 23:12:51,502][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014848] [Batch 02528/03080] [00:34:08/00:07:27, 0.810s/it]: train_loss_raw=1.5279, running_loss=1.5621, LR=0.000100
[2025-08-26 23:12:57,529][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014856] [Batch 02536/03080] [00:34:14/00:07:20, 0.810s/it]: train_loss_raw=1.6222, running_loss=1.5640, LR=0.000100
[2025-08-26 23:13:03,565][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014864] [Batch 02544/03080] [00:34:20/00:07:14, 0.810s/it]: train_loss_raw=1.5636, running_loss=1.5624, LR=0.000100
[2025-08-26 23:13:09,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014872] [Batch 02552/03080] [00:34:25/00:07:07, 0.810s/it]: train_loss_raw=1.5924, running_loss=1.5657, LR=0.000100
[2025-08-26 23:13:15,106][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014880] [Batch 02560/03080] [00:34:31/00:07:00, 0.809s/it]: train_loss_raw=1.5866, running_loss=1.5664, LR=0.000100
[2025-08-26 23:13:20,851][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014888] [Batch 02568/03080] [00:34:37/00:06:54, 0.809s/it]: train_loss_raw=1.6372, running_loss=1.5667, LR=0.000100
[2025-08-26 23:13:26,581][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014896] [Batch 02576/03080] [00:34:43/00:06:47, 0.809s/it]: train_loss_raw=1.5944, running_loss=1.5640, LR=0.000100
[2025-08-26 23:13:32,482][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014904] [Batch 02584/03080] [00:34:48/00:06:40, 0.808s/it]: train_loss_raw=1.4986, running_loss=1.5629, LR=0.000100
[2025-08-26 23:13:38,681][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014912] [Batch 02592/03080] [00:34:55/00:06:34, 0.808s/it]: train_loss_raw=1.5378, running_loss=1.5607, LR=0.000100
[2025-08-26 23:13:44,470][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014920] [Batch 02600/03080] [00:35:00/00:06:27, 0.808s/it]: train_loss_raw=1.5109, running_loss=1.5588, LR=0.000100
[2025-08-26 23:13:50,447][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014928] [Batch 02608/03080] [00:35:06/00:06:21, 0.808s/it]: train_loss_raw=1.6746, running_loss=1.5617, LR=0.000100
[2025-08-26 23:13:56,346][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014936] [Batch 02616/03080] [00:35:12/00:06:14, 0.808s/it]: train_loss_raw=1.5840, running_loss=1.5603, LR=0.000100
[2025-08-26 23:14:02,347][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014944] [Batch 02624/03080] [00:35:18/00:06:08, 0.807s/it]: train_loss_raw=1.5706, running_loss=1.5647, LR=0.000100
[2025-08-26 23:14:08,380][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014952] [Batch 02632/03080] [00:35:24/00:06:01, 0.807s/it]: train_loss_raw=1.4235, running_loss=1.5613, LR=0.000100
[2025-08-26 23:14:14,287][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014960] [Batch 02640/03080] [00:35:30/00:05:55, 0.807s/it]: train_loss_raw=1.6089, running_loss=1.5609, LR=0.000100
[2025-08-26 23:14:20,053][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014968] [Batch 02648/03080] [00:35:36/00:05:48, 0.807s/it]: train_loss_raw=1.6080, running_loss=1.5606, LR=0.000100
[2025-08-26 23:14:25,823][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014976] [Batch 02656/03080] [00:35:42/00:05:41, 0.807s/it]: train_loss_raw=1.7216, running_loss=1.5632, LR=0.000100
[2025-08-26 23:14:31,889][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014984] [Batch 02664/03080] [00:35:48/00:05:35, 0.806s/it]: train_loss_raw=1.6586, running_loss=1.5638, LR=0.000100
[2025-08-26 23:14:37,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014992] [Batch 02672/03080] [00:35:54/00:05:28, 0.806s/it]: train_loss_raw=1.5827, running_loss=1.5639, LR=0.000100
[2025-08-26 23:14:43,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015000] [Batch 02680/03080] [00:36:00/00:05:22, 0.806s/it]: train_loss_raw=1.5153, running_loss=1.5629, LR=0.000100
[2025-08-26 23:14:49,541][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015008] [Batch 02688/03080] [00:36:06/00:05:15, 0.806s/it]: train_loss_raw=1.6081, running_loss=1.5596, LR=0.000100
[2025-08-26 23:14:55,553][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015016] [Batch 02696/03080] [00:36:12/00:05:09, 0.806s/it]: train_loss_raw=1.6847, running_loss=1.5583, LR=0.000100
[2025-08-26 23:15:01,480][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015024] [Batch 02704/03080] [00:36:17/00:05:02, 0.805s/it]: train_loss_raw=1.4888, running_loss=1.5588, LR=0.000100
[2025-08-26 23:15:07,363][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015032] [Batch 02712/03080] [00:36:23/00:04:56, 0.805s/it]: train_loss_raw=1.5649, running_loss=1.5571, LR=0.000100
[2025-08-26 23:15:13,256][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015040] [Batch 02720/03080] [00:36:29/00:04:49, 0.805s/it]: train_loss_raw=1.5484, running_loss=1.5568, LR=0.000100
[2025-08-26 23:15:19,066][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015048] [Batch 02728/03080] [00:36:35/00:04:43, 0.805s/it]: train_loss_raw=1.5952, running_loss=1.5563, LR=0.000100
[2025-08-26 23:15:25,028][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015056] [Batch 02736/03080] [00:36:41/00:04:36, 0.805s/it]: train_loss_raw=1.5017, running_loss=1.5551, LR=0.000100
[2025-08-26 23:15:30,823][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015064] [Batch 02744/03080] [00:36:47/00:04:30, 0.804s/it]: train_loss_raw=1.6158, running_loss=1.5541, LR=0.000100
[2025-08-26 23:15:36,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015072] [Batch 02752/03080] [00:36:53/00:04:23, 0.804s/it]: train_loss_raw=1.5213, running_loss=1.5535, LR=0.000100
[2025-08-26 23:15:42,468][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015080] [Batch 02760/03080] [00:36:58/00:04:17, 0.804s/it]: train_loss_raw=1.5441, running_loss=1.5511, LR=0.000100
[2025-08-26 23:15:48,491][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015088] [Batch 02768/03080] [00:37:04/00:04:10, 0.804s/it]: train_loss_raw=1.5408, running_loss=1.5520, LR=0.000100
[2025-08-26 23:15:54,530][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015096] [Batch 02776/03080] [00:37:11/00:04:04, 0.804s/it]: train_loss_raw=1.6257, running_loss=1.5547, LR=0.000100
[2025-08-26 23:16:00,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015104] [Batch 02784/03080] [00:37:17/00:03:57, 0.804s/it]: train_loss_raw=1.5786, running_loss=1.5552, LR=0.000100
[2025-08-26 23:16:06,368][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015112] [Batch 02792/03080] [00:37:22/00:03:51, 0.803s/it]: train_loss_raw=1.5988, running_loss=1.5568, LR=0.000100
[2025-08-26 23:16:12,165][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015120] [Batch 02800/03080] [00:37:28/00:03:44, 0.803s/it]: train_loss_raw=1.5402, running_loss=1.5562, LR=0.000100
[2025-08-26 23:16:18,018][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015128] [Batch 02808/03080] [00:37:34/00:03:38, 0.803s/it]: train_loss_raw=1.4188, running_loss=1.5563, LR=0.000100
[2025-08-26 23:16:23,903][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015136] [Batch 02816/03080] [00:37:40/00:03:31, 0.803s/it]: train_loss_raw=1.4108, running_loss=1.5550, LR=0.000100
[2025-08-26 23:16:29,850][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015144] [Batch 02824/03080] [00:37:46/00:03:25, 0.803s/it]: train_loss_raw=1.5979, running_loss=1.5567, LR=0.000100
[2025-08-26 23:16:35,726][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015152] [Batch 02832/03080] [00:37:52/00:03:18, 0.802s/it]: train_loss_raw=1.5632, running_loss=1.5581, LR=0.000100
[2025-08-26 23:16:41,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015160] [Batch 02840/03080] [00:37:58/00:03:12, 0.802s/it]: train_loss_raw=1.4923, running_loss=1.5570, LR=0.000100
[2025-08-26 23:16:47,428][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015168] [Batch 02848/03080] [00:38:03/00:03:06, 0.802s/it]: train_loss_raw=1.5089, running_loss=1.5544, LR=0.000100
[2025-08-26 23:16:53,460][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015176] [Batch 02856/03080] [00:38:09/00:02:59, 0.802s/it]: train_loss_raw=1.4799, running_loss=1.5543, LR=0.000100
[2025-08-26 23:16:59,560][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015184] [Batch 02864/03080] [00:38:16/00:02:53, 0.802s/it]: train_loss_raw=1.5192, running_loss=1.5549, LR=0.000100
[2025-08-26 23:17:05,433][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015192] [Batch 02872/03080] [00:38:21/00:02:46, 0.802s/it]: train_loss_raw=1.5959, running_loss=1.5564, LR=0.000100
[2025-08-26 23:17:11,330][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015200] [Batch 02880/03080] [00:38:27/00:02:40, 0.801s/it]: train_loss_raw=1.5614, running_loss=1.5548, LR=0.000100
[2025-08-26 23:17:17,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015208] [Batch 02888/03080] [00:38:33/00:02:33, 0.801s/it]: train_loss_raw=1.5444, running_loss=1.5539, LR=0.000100
[2025-08-26 23:17:23,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015216] [Batch 02896/03080] [00:38:39/00:02:27, 0.801s/it]: train_loss_raw=1.5415, running_loss=1.5543, LR=0.000100
[2025-08-26 23:17:29,120][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015224] [Batch 02904/03080] [00:38:45/00:02:20, 0.801s/it]: train_loss_raw=1.4764, running_loss=1.5522, LR=0.000100
[2025-08-26 23:17:35,111][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015232] [Batch 02912/03080] [00:38:51/00:02:14, 0.801s/it]: train_loss_raw=1.5998, running_loss=1.5509, LR=0.000100
[2025-08-26 23:17:40,913][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015240] [Batch 02920/03080] [00:38:57/00:02:08, 0.800s/it]: train_loss_raw=1.5368, running_loss=1.5537, LR=0.000100
[2025-08-26 23:17:46,854][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015248] [Batch 02928/03080] [00:39:03/00:02:01, 0.800s/it]: train_loss_raw=1.6280, running_loss=1.5536, LR=0.000100
[2025-08-26 23:17:53,158][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015256] [Batch 02936/03080] [00:39:09/00:01:55, 0.800s/it]: train_loss_raw=1.5293, running_loss=1.5501, LR=0.000100
[2025-08-26 23:17:59,105][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015264] [Batch 02944/03080] [00:39:15/00:01:48, 0.800s/it]: train_loss_raw=1.5787, running_loss=1.5483, LR=0.000100
[2025-08-26 23:18:05,084][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015272] [Batch 02952/03080] [00:39:21/00:01:42, 0.800s/it]: train_loss_raw=1.6024, running_loss=1.5452, LR=0.000100
[2025-08-26 23:18:10,856][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015280] [Batch 02960/03080] [00:39:27/00:01:35, 0.800s/it]: train_loss_raw=1.6135, running_loss=1.5443, LR=0.000100
[2025-08-26 23:18:16,551][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015288] [Batch 02968/03080] [00:39:33/00:01:29, 0.800s/it]: train_loss_raw=1.5123, running_loss=1.5441, LR=0.000100
[2025-08-26 23:18:22,193][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015296] [Batch 02976/03080] [00:39:38/00:01:23, 0.799s/it]: train_loss_raw=1.4789, running_loss=1.5456, LR=0.000100
[2025-08-26 23:18:28,005][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015304] [Batch 02984/03080] [00:39:44/00:01:16, 0.799s/it]: train_loss_raw=1.4653, running_loss=1.5436, LR=0.000100
[2025-08-26 23:18:34,151][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015312] [Batch 02992/03080] [00:39:50/00:01:10, 0.799s/it]: train_loss_raw=1.5603, running_loss=1.5438, LR=0.000100
[2025-08-26 23:18:40,178][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015320] [Batch 03000/03080] [00:39:56/00:01:03, 0.799s/it]: train_loss_raw=1.5096, running_loss=1.5421, LR=0.000100
[2025-08-26 23:18:46,272][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015328] [Batch 03008/03080] [00:40:02/00:00:57, 0.799s/it]: train_loss_raw=1.5957, running_loss=1.5425, LR=0.000100
[2025-08-26 23:18:52,081][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015336] [Batch 03016/03080] [00:40:08/00:00:51, 0.799s/it]: train_loss_raw=1.4814, running_loss=1.5440, LR=0.000100
[2025-08-26 23:18:57,895][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015344] [Batch 03024/03080] [00:40:14/00:00:44, 0.798s/it]: train_loss_raw=1.4452, running_loss=1.5430, LR=0.000100
[2025-08-26 23:19:03,997][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015352] [Batch 03032/03080] [00:40:20/00:00:38, 0.798s/it]: train_loss_raw=1.4795, running_loss=1.5414, LR=0.000100
[2025-08-26 23:19:09,759][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015360] [Batch 03040/03080] [00:40:26/00:00:31, 0.798s/it]: train_loss_raw=1.6924, running_loss=1.5429, LR=0.000100
[2025-08-26 23:19:15,686][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015368] [Batch 03048/03080] [00:40:32/00:00:25, 0.798s/it]: train_loss_raw=1.5439, running_loss=1.5429, LR=0.000100
[2025-08-26 23:19:21,869][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015376] [Batch 03056/03080] [00:40:38/00:00:19, 0.798s/it]: train_loss_raw=1.5963, running_loss=1.5452, LR=0.000100
[2025-08-26 23:19:27,709][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015384] [Batch 03064/03080] [00:40:44/00:00:12, 0.798s/it]: train_loss_raw=1.4595, running_loss=1.5425, LR=0.000100
[2025-08-26 23:19:33,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015392] [Batch 03072/03080] [00:40:50/00:00:06, 0.798s/it]: train_loss_raw=1.5079, running_loss=1.5427, LR=0.000100
[2025-08-26 23:19:39,821][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015400] [Batch 03080/03080] [00:40:56/00:00:00, 0.798s/it]: train_loss_raw=1.5086, running_loss=1.5432, LR=0.000100
[2025-08-26 23:19:40,294][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-26 23:19:51,347][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00007/00310] [00:00:11/00:06:57, 1.382s/it]
[2025-08-26 23:20:03,759][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00015/00310] [00:00:23/00:07:11, 1.467s/it]
[2025-08-26 23:20:16,380][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00023/00310] [00:00:36/00:07:10, 1.504s/it]
[2025-08-26 23:20:28,587][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00031/00310] [00:00:48/00:06:59, 1.509s/it]
[2025-08-26 23:20:41,026][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00039/00310] [00:01:00/00:06:49, 1.518s/it]
[2025-08-26 23:20:53,318][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00047/00310] [00:01:13/00:06:38, 1.521s/it]
[2025-08-26 23:21:06,030][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00055/00310] [00:01:25/00:06:28, 1.531s/it]
[2025-08-26 23:21:18,767][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00063/00310] [00:01:38/00:06:18, 1.539s/it]
[2025-08-26 23:21:31,186][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00071/00310] [00:01:50/00:06:06, 1.540s/it]
[2025-08-26 23:21:43,839][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00079/00310] [00:02:03/00:05:55, 1.544s/it]
[2025-08-26 23:21:56,502][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00087/00310] [00:02:16/00:05:43, 1.548s/it]
[2025-08-26 23:22:08,942][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00095/00310] [00:02:28/00:05:31, 1.548s/it]
[2025-08-26 23:22:21,397][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00103/00310] [00:02:41/00:05:19, 1.549s/it]
[2025-08-26 23:22:34,033][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00111/00310] [00:02:53/00:05:07, 1.551s/it]
[2025-08-26 23:22:46,545][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00119/00310] [00:03:06/00:04:54, 1.552s/it]
[2025-08-26 23:22:58,986][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00127/00310] [00:03:18/00:04:42, 1.552s/it]
[2025-08-26 23:23:11,363][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00135/00310] [00:03:31/00:04:30, 1.552s/it]
[2025-08-26 23:23:24,035][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00143/00310] [00:03:43/00:04:17, 1.554s/it]
[2025-08-26 23:23:35,839][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00151/00310] [00:03:55/00:04:04, 1.550s/it]
[2025-08-26 23:23:47,657][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00159/00310] [00:04:07/00:03:51, 1.546s/it]
[2025-08-26 23:24:00,226][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00167/00310] [00:04:19/00:03:39, 1.547s/it]
[2025-08-26 23:24:12,202][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00175/00310] [00:04:31/00:03:27, 1.545s/it]
[2025-08-26 23:24:23,885][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00183/00310] [00:04:43/00:03:14, 1.541s/it]
[2025-08-26 23:24:36,735][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00191/00310] [00:04:56/00:03:02, 1.544s/it]
[2025-08-26 23:24:48,367][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00199/00310] [00:05:08/00:02:49, 1.540s/it]
[2025-08-26 23:25:00,527][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00207/00310] [00:05:20/00:02:37, 1.540s/it]
[2025-08-26 23:25:12,779][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00215/00310] [00:05:32/00:02:24, 1.539s/it]
[2025-08-26 23:25:25,026][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00223/00310] [00:05:44/00:02:12, 1.539s/it]
[2025-08-26 23:25:37,805][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00231/00310] [00:05:57/00:02:00, 1.541s/it]
[2025-08-26 23:25:50,032][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00239/00310] [00:06:09/00:01:47, 1.541s/it]
[2025-08-26 23:26:01,964][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00247/00310] [00:06:21/00:01:35, 1.539s/it]
[2025-08-26 23:26:14,147][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00255/00310] [00:06:33/00:01:23, 1.538s/it]
[2025-08-26 23:26:26,754][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00263/00310] [00:06:46/00:01:10, 1.540s/it]
[2025-08-26 23:26:38,802][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00271/00310] [00:06:58/00:00:58, 1.539s/it]
[2025-08-26 23:26:50,977][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00279/00310] [00:07:10/00:00:46, 1.538s/it]
[2025-08-26 23:27:03,313][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00287/00310] [00:07:23/00:00:33, 1.538s/it]
[2025-08-26 23:27:15,403][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00295/00310] [00:07:35/00:00:21, 1.538s/it]
[2025-08-26 23:27:27,907][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 015401] [Batch 00303/00310] [00:07:47/00:00:09, 1.538s/it]
[2025-08-26 23:27:37,310][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.54316, valid_loss=2.19764
[2025-08-26 23:27:37,310][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-26 23:27:37,311][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.821
[2025-08-26 23:27:37,311][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.021
[2025-08-26 23:27:37,311][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.022
[2025-08-26 23:27:37,311][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.002
[2025-08-26 23:27:37,328][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 04:00:51, remaining time 20:04:16, 00:48:10 per epoch
[2025-08-26 23:27:44,026][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015408] [Batch 00008/03080] [00:00:05/00:36:01, 0.703s/it]: train_loss_raw=1.6116, running_loss=1.5964, LR=0.000100
[2025-08-26 23:27:49,980][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015416] [Batch 00016/03080] [00:00:11/00:36:57, 0.724s/it]: train_loss_raw=1.5391, running_loss=1.5897, LR=0.000100
[2025-08-26 23:27:56,119][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015424] [Batch 00024/03080] [00:00:17/00:37:36, 0.738s/it]: train_loss_raw=1.5768, running_loss=1.5846, LR=0.000100
[2025-08-26 23:28:02,092][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015432] [Batch 00032/03080] [00:00:23/00:37:36, 0.740s/it]: train_loss_raw=1.5689, running_loss=1.5818, LR=0.000100
[2025-08-26 23:28:08,119][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015440] [Batch 00040/03080] [00:00:29/00:37:38, 0.743s/it]: train_loss_raw=1.5676, running_loss=1.5788, LR=0.000100
[2025-08-26 23:28:14,393][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015448] [Batch 00048/03080] [00:00:35/00:37:53, 0.750s/it]: train_loss_raw=1.5362, running_loss=1.5760, LR=0.000100
[2025-08-26 23:28:20,696][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015456] [Batch 00056/03080] [00:00:42/00:38:04, 0.755s/it]: train_loss_raw=1.5671, running_loss=1.5725, LR=0.000100
[2025-08-26 23:28:26,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015464] [Batch 00064/03080] [00:00:48/00:37:53, 0.754s/it]: train_loss_raw=1.5669, running_loss=1.5674, LR=0.000100
[2025-08-26 23:28:32,671][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015472] [Batch 00072/03080] [00:00:54/00:37:47, 0.754s/it]: train_loss_raw=1.5165, running_loss=1.5650, LR=0.000100
[2025-08-26 23:28:39,087][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015480] [Batch 00080/03080] [00:01:00/00:37:55, 0.759s/it]: train_loss_raw=1.5702, running_loss=1.5617, LR=0.000100
[2025-08-26 23:28:45,304][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015488] [Batch 00088/03080] [00:01:06/00:37:54, 0.760s/it]: train_loss_raw=1.5930, running_loss=1.5618, LR=0.000100
[2025-08-26 23:28:51,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015496] [Batch 00096/03080] [00:01:13/00:37:49, 0.761s/it]: train_loss_raw=1.4246, running_loss=1.5580, LR=0.000100
[2025-08-26 23:28:57,442][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015504] [Batch 00104/03080] [00:01:19/00:37:41, 0.760s/it]: train_loss_raw=1.6147, running_loss=1.5612, LR=0.000100
[2025-08-26 23:29:03,206][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015512] [Batch 00112/03080] [00:01:24/00:37:27, 0.757s/it]: train_loss_raw=1.6193, running_loss=1.5581, LR=0.000100
[2025-08-26 23:29:09,003][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015520] [Batch 00120/03080] [00:01:30/00:37:14, 0.755s/it]: train_loss_raw=1.4777, running_loss=1.5564, LR=0.000100
[2025-08-26 23:29:14,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015528] [Batch 00128/03080] [00:01:36/00:37:03, 0.753s/it]: train_loss_raw=1.5343, running_loss=1.5561, LR=0.000100
[2025-08-26 23:29:20,803][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015536] [Batch 00136/03080] [00:01:42/00:36:56, 0.753s/it]: train_loss_raw=1.5652, running_loss=1.5534, LR=0.000100
[2025-08-26 23:29:26,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015544] [Batch 00144/03080] [00:01:48/00:36:48, 0.752s/it]: train_loss_raw=1.4429, running_loss=1.5545, LR=0.000100
[2025-08-26 23:29:32,553][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015552] [Batch 00152/03080] [00:01:54/00:36:38, 0.751s/it]: train_loss_raw=1.5753, running_loss=1.5566, LR=0.000100
[2025-08-26 23:29:38,456][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015560] [Batch 00160/03080] [00:02:00/00:36:31, 0.750s/it]: train_loss_raw=1.5661, running_loss=1.5556, LR=0.000100
[2025-08-26 23:29:44,511][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015568] [Batch 00168/03080] [00:02:06/00:36:25, 0.751s/it]: train_loss_raw=1.4180, running_loss=1.5527, LR=0.000100
[2025-08-26 23:29:50,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015576] [Batch 00176/03080] [00:02:12/00:36:18, 0.750s/it]: train_loss_raw=1.5805, running_loss=1.5545, LR=0.000100
[2025-08-26 23:29:56,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015584] [Batch 00184/03080] [00:02:17/00:36:11, 0.750s/it]: train_loss_raw=1.6452, running_loss=1.5525, LR=0.000100
[2025-08-26 23:30:02,275][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015592] [Batch 00192/03080] [00:02:23/00:36:04, 0.749s/it]: train_loss_raw=1.5408, running_loss=1.5493, LR=0.000100
[2025-08-26 23:30:08,240][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015600] [Batch 00200/03080] [00:02:29/00:35:57, 0.749s/it]: train_loss_raw=1.4399, running_loss=1.5456, LR=0.000100
[2025-08-26 23:30:14,200][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015608] [Batch 00208/03080] [00:02:35/00:35:51, 0.749s/it]: train_loss_raw=1.4522, running_loss=1.5405, LR=0.000100
[2025-08-26 23:30:20,360][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015616] [Batch 00216/03080] [00:02:41/00:35:47, 0.750s/it]: train_loss_raw=1.4966, running_loss=1.5399, LR=0.000100
[2025-08-26 23:30:26,358][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015624] [Batch 00224/03080] [00:02:47/00:35:41, 0.750s/it]: train_loss_raw=1.5729, running_loss=1.5406, LR=0.000100
[2025-08-26 23:30:32,494][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015632] [Batch 00232/03080] [00:02:54/00:35:37, 0.750s/it]: train_loss_raw=1.5181, running_loss=1.5403, LR=0.000100
[2025-08-26 23:30:38,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015640] [Batch 00240/03080] [00:02:59/00:35:29, 0.750s/it]: train_loss_raw=1.5308, running_loss=1.5389, LR=0.000100
[2025-08-26 23:30:44,243][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015648] [Batch 00248/03080] [00:03:05/00:35:22, 0.749s/it]: train_loss_raw=1.6336, running_loss=1.5388, LR=0.000100
[2025-08-26 23:30:49,967][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015656] [Batch 00256/03080] [00:03:11/00:35:13, 0.748s/it]: train_loss_raw=1.4647, running_loss=1.5366, LR=0.000100
[2025-08-26 23:30:56,080][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015664] [Batch 00264/03080] [00:03:17/00:35:08, 0.749s/it]: train_loss_raw=1.6124, running_loss=1.5379, LR=0.000100
[2025-08-26 23:31:02,383][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015672] [Batch 00272/03080] [00:03:23/00:35:05, 0.750s/it]: train_loss_raw=1.4840, running_loss=1.5380, LR=0.000100
[2025-08-26 23:31:08,373][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015680] [Batch 00280/03080] [00:03:29/00:34:59, 0.750s/it]: train_loss_raw=1.4990, running_loss=1.5359, LR=0.000100
[2025-08-26 23:31:14,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015688] [Batch 00288/03080] [00:03:36/00:34:54, 0.750s/it]: train_loss_raw=1.4696, running_loss=1.5323, LR=0.000100
[2025-08-26 23:31:20,393][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015696] [Batch 00296/03080] [00:03:41/00:34:47, 0.750s/it]: train_loss_raw=1.6474, running_loss=1.5318, LR=0.000100
[2025-08-26 23:31:26,377][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015704] [Batch 00304/03080] [00:03:47/00:34:41, 0.750s/it]: train_loss_raw=1.4803, running_loss=1.5311, LR=0.000100
[2025-08-26 23:31:32,290][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015712] [Batch 00312/03080] [00:03:53/00:34:35, 0.750s/it]: train_loss_raw=1.5523, running_loss=1.5309, LR=0.000100
[2025-08-26 23:31:38,312][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015720] [Batch 00320/03080] [00:03:59/00:34:29, 0.750s/it]: train_loss_raw=1.6053, running_loss=1.5309, LR=0.000100
[2025-08-26 23:31:44,124][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015728] [Batch 00328/03080] [00:04:05/00:34:21, 0.749s/it]: train_loss_raw=1.4367, running_loss=1.5319, LR=0.000100
[2025-08-26 23:31:50,285][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015736] [Batch 00336/03080] [00:04:11/00:34:17, 0.750s/it]: train_loss_raw=1.5509, running_loss=1.5313, LR=0.000100
[2025-08-26 23:31:56,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015744] [Batch 00344/03080] [00:04:18/00:34:12, 0.750s/it]: train_loss_raw=1.5482, running_loss=1.5310, LR=0.000100
[2025-08-26 23:32:02,637][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015752] [Batch 00352/03080] [00:04:24/00:34:07, 0.751s/it]: train_loss_raw=1.4983, running_loss=1.5313, LR=0.000100
[2025-08-26 23:32:08,715][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015760] [Batch 00360/03080] [00:04:30/00:34:02, 0.751s/it]: train_loss_raw=1.5339, running_loss=1.5306, LR=0.000100
[2025-08-26 23:32:14,670][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015768] [Batch 00368/03080] [00:04:36/00:33:56, 0.751s/it]: train_loss_raw=1.4294, running_loss=1.5297, LR=0.000100
[2025-08-26 23:32:20,708][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015776] [Batch 00376/03080] [00:04:42/00:33:50, 0.751s/it]: train_loss_raw=1.5395, running_loss=1.5294, LR=0.000100
[2025-08-26 23:32:26,893][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015784] [Batch 00384/03080] [00:04:48/00:33:45, 0.751s/it]: train_loss_raw=1.4154, running_loss=1.5289, LR=0.000100
[2025-08-26 23:32:32,717][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015792] [Batch 00392/03080] [00:04:54/00:33:38, 0.751s/it]: train_loss_raw=1.4580, running_loss=1.5267, LR=0.000100
[2025-08-26 23:32:38,589][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015800] [Batch 00400/03080] [00:05:00/00:33:31, 0.750s/it]: train_loss_raw=1.4716, running_loss=1.5251, LR=0.000100
[2025-08-26 23:32:44,614][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015808] [Batch 00408/03080] [00:05:06/00:33:25, 0.751s/it]: train_loss_raw=1.6422, running_loss=1.5270, LR=0.000100
[2025-08-26 23:32:50,694][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015816] [Batch 00416/03080] [00:05:12/00:33:19, 0.751s/it]: train_loss_raw=1.5081, running_loss=1.5267, LR=0.000100
[2025-08-26 23:32:56,833][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015824] [Batch 00424/03080] [00:05:18/00:33:14, 0.751s/it]: train_loss_raw=1.5329, running_loss=1.5270, LR=0.000100
[2025-08-26 23:33:02,912][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015832] [Batch 00432/03080] [00:05:24/00:33:09, 0.751s/it]: train_loss_raw=1.5097, running_loss=1.5287, LR=0.000100
[2025-08-26 23:33:09,014][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015840] [Batch 00440/03080] [00:05:30/00:33:03, 0.751s/it]: train_loss_raw=1.4062, running_loss=1.5279, LR=0.000100
[2025-08-26 23:33:15,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015848] [Batch 00448/03080] [00:05:36/00:32:58, 0.752s/it]: train_loss_raw=1.5965, running_loss=1.5270, LR=0.000100
[2025-08-26 23:33:21,028][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015856] [Batch 00456/03080] [00:05:42/00:32:51, 0.751s/it]: train_loss_raw=1.4969, running_loss=1.5268, LR=0.000100
[2025-08-26 23:33:26,927][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015864] [Batch 00464/03080] [00:05:48/00:32:44, 0.751s/it]: train_loss_raw=1.6206, running_loss=1.5276, LR=0.000100
[2025-08-26 23:33:33,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015872] [Batch 00472/03080] [00:05:54/00:32:39, 0.751s/it]: train_loss_raw=1.4025, running_loss=1.5265, LR=0.000100
[2025-08-26 23:33:38,839][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015880] [Batch 00480/03080] [00:06:00/00:32:32, 0.751s/it]: train_loss_raw=1.4704, running_loss=1.5263, LR=0.000100
[2025-08-26 23:33:44,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015888] [Batch 00488/03080] [00:06:06/00:32:25, 0.751s/it]: train_loss_raw=1.5196, running_loss=1.5275, LR=0.000100
[2025-08-26 23:33:50,864][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015896] [Batch 00496/03080] [00:06:12/00:32:20, 0.751s/it]: train_loss_raw=1.5208, running_loss=1.5264, LR=0.000100
[2025-08-26 23:33:56,854][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015904] [Batch 00504/03080] [00:06:18/00:32:14, 0.751s/it]: train_loss_raw=1.5959, running_loss=1.5260, LR=0.000100
[2025-08-26 23:34:02,800][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015912] [Batch 00512/03080] [00:06:24/00:32:08, 0.751s/it]: train_loss_raw=1.4640, running_loss=1.5256, LR=0.000100
[2025-08-26 23:34:08,762][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015920] [Batch 00520/03080] [00:06:30/00:32:01, 0.751s/it]: train_loss_raw=1.5672, running_loss=1.5264, LR=0.000100
[2025-08-26 23:34:14,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015928] [Batch 00528/03080] [00:06:36/00:31:55, 0.751s/it]: train_loss_raw=1.5552, running_loss=1.5272, LR=0.000100
[2025-08-26 23:34:20,815][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015936] [Batch 00536/03080] [00:06:42/00:31:49, 0.751s/it]: train_loss_raw=1.4661, running_loss=1.5249, LR=0.000100
[2025-08-26 23:34:26,911][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015944] [Batch 00544/03080] [00:06:48/00:31:44, 0.751s/it]: train_loss_raw=1.5121, running_loss=1.5250, LR=0.000100
[2025-08-26 23:34:33,122][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015952] [Batch 00552/03080] [00:06:54/00:31:39, 0.751s/it]: train_loss_raw=1.5009, running_loss=1.5250, LR=0.000100
[2025-08-26 23:34:38,821][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015960] [Batch 00560/03080] [00:07:00/00:31:31, 0.751s/it]: train_loss_raw=1.3796, running_loss=1.5229, LR=0.000100
[2025-08-26 23:34:44,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015968] [Batch 00568/03080] [00:07:06/00:31:25, 0.750s/it]: train_loss_raw=1.5160, running_loss=1.5248, LR=0.000100
[2025-08-26 23:34:50,640][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015976] [Batch 00576/03080] [00:07:12/00:31:19, 0.750s/it]: train_loss_raw=1.4077, running_loss=1.5208, LR=0.000100
[2025-08-26 23:34:56,743][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015984] [Batch 00584/03080] [00:07:18/00:31:13, 0.751s/it]: train_loss_raw=1.5750, running_loss=1.5235, LR=0.000100
[2025-08-26 23:35:02,493][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 015992] [Batch 00592/03080] [00:07:24/00:31:06, 0.750s/it]: train_loss_raw=1.5135, running_loss=1.5224, LR=0.000100
[2025-08-26 23:35:08,350][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016000] [Batch 00600/03080] [00:07:29/00:30:59, 0.750s/it]: train_loss_raw=1.5418, running_loss=1.5229, LR=0.000100
[2025-08-26 23:35:18,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016008] [Batch 00608/03080] [00:07:40/00:31:11, 0.757s/it]: train_loss_raw=1.5023, running_loss=1.5246, LR=0.000100
[2025-08-26 23:35:24,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016016] [Batch 00616/03080] [00:07:46/00:31:05, 0.757s/it]: train_loss_raw=1.4273, running_loss=1.5227, LR=0.000100
[2025-08-26 23:35:30,749][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016024] [Batch 00624/03080] [00:07:52/00:30:59, 0.757s/it]: train_loss_raw=1.5299, running_loss=1.5245, LR=0.000100
[2025-08-26 23:35:36,912][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016032] [Batch 00632/03080] [00:07:58/00:30:53, 0.757s/it]: train_loss_raw=1.4741, running_loss=1.5233, LR=0.000100
[2025-08-26 23:35:42,731][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016040] [Batch 00640/03080] [00:08:04/00:30:46, 0.757s/it]: train_loss_raw=1.4811, running_loss=1.5222, LR=0.000100
[2025-08-26 23:35:48,512][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016048] [Batch 00648/03080] [00:08:10/00:30:39, 0.756s/it]: train_loss_raw=1.4734, running_loss=1.5247, LR=0.000100
[2025-08-26 23:35:54,302][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016056] [Batch 00656/03080] [00:08:15/00:30:32, 0.756s/it]: train_loss_raw=1.5022, running_loss=1.5244, LR=0.000100
[2025-08-26 23:36:00,027][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016064] [Batch 00664/03080] [00:08:21/00:30:25, 0.755s/it]: train_loss_raw=1.5844, running_loss=1.5226, LR=0.000100
[2025-08-26 23:36:05,851][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016072] [Batch 00672/03080] [00:08:27/00:30:18, 0.755s/it]: train_loss_raw=1.4831, running_loss=1.5215, LR=0.000100
[2025-08-26 23:36:11,620][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016080] [Batch 00680/03080] [00:08:33/00:30:11, 0.755s/it]: train_loss_raw=1.5278, running_loss=1.5209, LR=0.000100
[2025-08-26 23:36:17,812][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016088] [Batch 00688/03080] [00:08:39/00:30:05, 0.755s/it]: train_loss_raw=1.5028, running_loss=1.5218, LR=0.000100
[2025-08-26 23:36:23,616][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016096] [Batch 00696/03080] [00:08:45/00:29:59, 0.755s/it]: train_loss_raw=1.4487, running_loss=1.5204, LR=0.000100
[2025-08-26 23:36:29,508][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016104] [Batch 00704/03080] [00:08:51/00:29:52, 0.754s/it]: train_loss_raw=1.5556, running_loss=1.5179, LR=0.000100
[2025-08-26 23:36:35,651][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016112] [Batch 00712/03080] [00:08:57/00:29:46, 0.755s/it]: train_loss_raw=1.5054, running_loss=1.5157, LR=0.000100
[2025-08-26 23:36:41,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016120] [Batch 00720/03080] [00:09:03/00:29:40, 0.754s/it]: train_loss_raw=1.5177, running_loss=1.5156, LR=0.000100
[2025-08-26 23:36:47,598][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016128] [Batch 00728/03080] [00:09:09/00:29:34, 0.754s/it]: train_loss_raw=1.5198, running_loss=1.5178, LR=0.000100
[2025-08-26 23:36:53,517][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016136] [Batch 00736/03080] [00:09:15/00:29:27, 0.754s/it]: train_loss_raw=1.6217, running_loss=1.5171, LR=0.000100
[2025-08-26 23:36:59,553][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016144] [Batch 00744/03080] [00:09:21/00:29:21, 0.754s/it]: train_loss_raw=1.4141, running_loss=1.5175, LR=0.000100
[2025-08-26 23:37:05,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016152] [Batch 00752/03080] [00:09:27/00:29:15, 0.754s/it]: train_loss_raw=1.4924, running_loss=1.5158, LR=0.000100
[2025-08-26 23:37:11,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016160] [Batch 00760/03080] [00:09:33/00:29:10, 0.754s/it]: train_loss_raw=1.5297, running_loss=1.5139, LR=0.000100
[2025-08-26 23:37:17,621][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016168] [Batch 00768/03080] [00:09:39/00:29:03, 0.754s/it]: train_loss_raw=1.5616, running_loss=1.5165, LR=0.000100
[2025-08-26 23:37:23,490][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016176] [Batch 00776/03080] [00:09:45/00:28:57, 0.754s/it]: train_loss_raw=1.4780, running_loss=1.5171, LR=0.000100
[2025-08-26 23:37:29,483][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016184] [Batch 00784/03080] [00:09:51/00:28:51, 0.754s/it]: train_loss_raw=1.5974, running_loss=1.5165, LR=0.000100
[2025-08-26 23:37:35,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016192] [Batch 00792/03080] [00:09:57/00:28:45, 0.754s/it]: train_loss_raw=1.5871, running_loss=1.5159, LR=0.000100
[2025-08-26 23:37:41,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016200] [Batch 00800/03080] [00:10:03/00:28:39, 0.754s/it]: train_loss_raw=1.5619, running_loss=1.5166, LR=0.000100
[2025-08-26 23:37:47,799][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016208] [Batch 00808/03080] [00:10:09/00:28:33, 0.754s/it]: train_loss_raw=1.6009, running_loss=1.5194, LR=0.000100
[2025-08-26 23:37:53,878][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016216] [Batch 00816/03080] [00:10:15/00:28:27, 0.754s/it]: train_loss_raw=1.5199, running_loss=1.5188, LR=0.000100
[2025-08-26 23:38:00,047][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016224] [Batch 00824/03080] [00:10:21/00:28:21, 0.754s/it]: train_loss_raw=1.5433, running_loss=1.5180, LR=0.000100
[2025-08-26 23:38:06,088][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016232] [Batch 00832/03080] [00:10:27/00:28:15, 0.754s/it]: train_loss_raw=1.5218, running_loss=1.5180, LR=0.000100
[2025-08-26 23:38:12,078][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016240] [Batch 00840/03080] [00:10:33/00:28:09, 0.754s/it]: train_loss_raw=1.5795, running_loss=1.5154, LR=0.000100
[2025-08-26 23:38:18,037][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016248] [Batch 00848/03080] [00:10:39/00:28:03, 0.754s/it]: train_loss_raw=1.5787, running_loss=1.5151, LR=0.000100
[2025-08-26 23:38:23,967][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016256] [Batch 00856/03080] [00:10:45/00:27:57, 0.754s/it]: train_loss_raw=1.5698, running_loss=1.5158, LR=0.000100
[2025-08-26 23:38:29,906][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016264] [Batch 00864/03080] [00:10:51/00:27:50, 0.754s/it]: train_loss_raw=1.4298, running_loss=1.5106, LR=0.000100
[2025-08-26 23:38:35,556][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016272] [Batch 00872/03080] [00:10:57/00:27:43, 0.754s/it]: train_loss_raw=1.5344, running_loss=1.5117, LR=0.000100
[2025-08-26 23:38:41,313][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016280] [Batch 00880/03080] [00:11:02/00:27:37, 0.753s/it]: train_loss_raw=1.5631, running_loss=1.5115, LR=0.000100
[2025-08-26 23:38:47,266][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016288] [Batch 00888/03080] [00:11:08/00:27:31, 0.753s/it]: train_loss_raw=1.5175, running_loss=1.5118, LR=0.000100
[2025-08-26 23:38:52,977][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016296] [Batch 00896/03080] [00:11:14/00:27:24, 0.753s/it]: train_loss_raw=1.5558, running_loss=1.5099, LR=0.000100
[2025-08-26 23:38:58,756][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016304] [Batch 00904/03080] [00:11:20/00:27:17, 0.753s/it]: train_loss_raw=1.5073, running_loss=1.5105, LR=0.000100
[2025-08-26 23:39:04,719][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016312] [Batch 00912/03080] [00:11:26/00:27:11, 0.753s/it]: train_loss_raw=1.5288, running_loss=1.5113, LR=0.000100
[2025-08-26 23:39:10,698][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016320] [Batch 00920/03080] [00:11:32/00:27:05, 0.753s/it]: train_loss_raw=1.4450, running_loss=1.5092, LR=0.000100
[2025-08-26 23:39:16,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016328] [Batch 00928/03080] [00:11:38/00:26:59, 0.752s/it]: train_loss_raw=1.4971, running_loss=1.5095, LR=0.000100
[2025-08-26 23:39:22,711][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016336] [Batch 00936/03080] [00:11:44/00:26:53, 0.752s/it]: train_loss_raw=1.4355, running_loss=1.5088, LR=0.000100
[2025-08-26 23:39:28,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016344] [Batch 00944/03080] [00:11:50/00:26:46, 0.752s/it]: train_loss_raw=1.5174, running_loss=1.5055, LR=0.000100
[2025-08-26 23:39:34,518][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016352] [Batch 00952/03080] [00:11:56/00:26:40, 0.752s/it]: train_loss_raw=1.4411, running_loss=1.5072, LR=0.000100
[2025-08-26 23:39:40,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016360] [Batch 00960/03080] [00:12:02/00:26:34, 0.752s/it]: train_loss_raw=1.5722, running_loss=1.5043, LR=0.000100
[2025-08-26 23:39:46,101][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016368] [Batch 00968/03080] [00:12:07/00:26:27, 0.752s/it]: train_loss_raw=1.5148, running_loss=1.5040, LR=0.000100
[2025-08-26 23:39:52,044][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016376] [Batch 00976/03080] [00:12:13/00:26:21, 0.752s/it]: train_loss_raw=1.5449, running_loss=1.5041, LR=0.000100
[2025-08-26 23:39:58,052][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016384] [Batch 00984/03080] [00:12:19/00:26:15, 0.752s/it]: train_loss_raw=1.4850, running_loss=1.5032, LR=0.000100
[2025-08-26 23:40:03,927][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016392] [Batch 00992/03080] [00:12:25/00:26:09, 0.752s/it]: train_loss_raw=1.4343, running_loss=1.5032, LR=0.000100
[2025-08-26 23:40:09,823][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016400] [Batch 01000/03080] [00:12:31/00:26:02, 0.751s/it]: train_loss_raw=1.4170, running_loss=1.5012, LR=0.000100
[2025-08-26 23:40:15,932][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016408] [Batch 01008/03080] [00:12:37/00:25:57, 0.752s/it]: train_loss_raw=1.4452, running_loss=1.5013, LR=0.000100
[2025-08-26 23:40:22,029][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016416] [Batch 01016/03080] [00:12:43/00:25:51, 0.752s/it]: train_loss_raw=1.4654, running_loss=1.5018, LR=0.000100
[2025-08-26 23:40:28,198][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016424] [Batch 01024/03080] [00:12:49/00:25:45, 0.752s/it]: train_loss_raw=1.4832, running_loss=1.5008, LR=0.000100
[2025-08-26 23:40:34,057][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016432] [Batch 01032/03080] [00:12:55/00:25:39, 0.752s/it]: train_loss_raw=1.4837, running_loss=1.4995, LR=0.000100
[2025-08-26 23:40:39,926][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016440] [Batch 01040/03080] [00:13:01/00:25:32, 0.751s/it]: train_loss_raw=1.5263, running_loss=1.5010, LR=0.000100
[2025-08-26 23:40:45,880][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016448] [Batch 01048/03080] [00:13:07/00:25:26, 0.751s/it]: train_loss_raw=1.4969, running_loss=1.5034, LR=0.000100
[2025-08-26 23:40:51,761][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016456] [Batch 01056/03080] [00:13:13/00:25:20, 0.751s/it]: train_loss_raw=1.5049, running_loss=1.5038, LR=0.000100
[2025-08-26 23:40:57,661][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016464] [Batch 01064/03080] [00:13:19/00:25:14, 0.751s/it]: train_loss_raw=1.4393, running_loss=1.5040, LR=0.000100
[2025-08-26 23:41:03,564][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016472] [Batch 01072/03080] [00:13:25/00:25:08, 0.751s/it]: train_loss_raw=1.3917, running_loss=1.5044, LR=0.000100
[2025-08-26 23:41:09,319][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016480] [Batch 01080/03080] [00:13:30/00:25:01, 0.751s/it]: train_loss_raw=1.5634, running_loss=1.5038, LR=0.000100
[2025-08-26 23:41:15,067][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016488] [Batch 01088/03080] [00:13:36/00:24:55, 0.751s/it]: train_loss_raw=1.5597, running_loss=1.5055, LR=0.000100
[2025-08-26 23:41:21,015][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016496] [Batch 01096/03080] [00:13:42/00:24:49, 0.751s/it]: train_loss_raw=1.5144, running_loss=1.5034, LR=0.000100
[2025-08-26 23:41:26,906][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016504] [Batch 01104/03080] [00:13:48/00:24:42, 0.750s/it]: train_loss_raw=1.5191, running_loss=1.5062, LR=0.000100
[2025-08-26 23:41:32,899][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016512] [Batch 01112/03080] [00:13:54/00:24:36, 0.750s/it]: train_loss_raw=1.4479, running_loss=1.5076, LR=0.000100
[2025-08-26 23:41:38,855][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016520] [Batch 01120/03080] [00:14:00/00:24:30, 0.750s/it]: train_loss_raw=1.4491, running_loss=1.5068, LR=0.000100
[2025-08-26 23:41:44,865][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016528] [Batch 01128/03080] [00:14:06/00:24:24, 0.750s/it]: train_loss_raw=1.5556, running_loss=1.5080, LR=0.000100
[2025-08-26 23:41:50,659][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016536] [Batch 01136/03080] [00:14:12/00:24:18, 0.750s/it]: train_loss_raw=1.4847, running_loss=1.5078, LR=0.000100
[2025-08-26 23:41:56,656][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016544] [Batch 01144/03080] [00:14:18/00:24:12, 0.750s/it]: train_loss_raw=1.4536, running_loss=1.5059, LR=0.000100
[2025-08-26 23:42:02,668][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016552] [Batch 01152/03080] [00:14:24/00:24:06, 0.750s/it]: train_loss_raw=1.4174, running_loss=1.5060, LR=0.000100
[2025-08-26 23:42:08,625][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016560] [Batch 01160/03080] [00:14:30/00:24:00, 0.750s/it]: train_loss_raw=1.3184, running_loss=1.5016, LR=0.000100
[2025-08-26 23:42:14,550][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016568] [Batch 01168/03080] [00:14:36/00:23:54, 0.750s/it]: train_loss_raw=1.3985, running_loss=1.5032, LR=0.000100
[2025-08-26 23:42:20,440][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016576] [Batch 01176/03080] [00:14:42/00:23:48, 0.750s/it]: train_loss_raw=1.4023, running_loss=1.4979, LR=0.000100
[2025-08-26 23:42:26,442][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016584] [Batch 01184/03080] [00:14:48/00:23:42, 0.750s/it]: train_loss_raw=1.5110, running_loss=1.4961, LR=0.000100
[2025-08-26 23:42:32,461][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016592] [Batch 01192/03080] [00:14:54/00:23:36, 0.750s/it]: train_loss_raw=1.4476, running_loss=1.4957, LR=0.000100
[2025-08-26 23:42:38,341][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016600] [Batch 01200/03080] [00:14:59/00:23:29, 0.750s/it]: train_loss_raw=1.5571, running_loss=1.4928, LR=0.000100
[2025-08-26 23:42:44,271][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016608] [Batch 01208/03080] [00:15:05/00:23:23, 0.750s/it]: train_loss_raw=1.5463, running_loss=1.4937, LR=0.000100
[2025-08-26 23:42:50,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016616] [Batch 01216/03080] [00:15:11/00:23:17, 0.750s/it]: train_loss_raw=1.4156, running_loss=1.4919, LR=0.000100
[2025-08-26 23:42:56,181][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016624] [Batch 01224/03080] [00:15:17/00:23:11, 0.750s/it]: train_loss_raw=1.5041, running_loss=1.4916, LR=0.000100
[2025-08-26 23:43:02,000][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016632] [Batch 01232/03080] [00:15:23/00:23:05, 0.750s/it]: train_loss_raw=1.4306, running_loss=1.4920, LR=0.000100
[2025-08-26 23:43:07,999][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016640] [Batch 01240/03080] [00:15:29/00:22:59, 0.750s/it]: train_loss_raw=1.4873, running_loss=1.4951, LR=0.000100
[2025-08-26 23:43:13,898][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016648] [Batch 01248/03080] [00:15:35/00:22:53, 0.750s/it]: train_loss_raw=1.4180, running_loss=1.4977, LR=0.000100
[2025-08-26 23:43:19,918][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016656] [Batch 01256/03080] [00:15:41/00:22:47, 0.750s/it]: train_loss_raw=1.5285, running_loss=1.4976, LR=0.000100
[2025-08-26 23:43:25,804][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016664] [Batch 01264/03080] [00:15:47/00:22:41, 0.750s/it]: train_loss_raw=1.6102, running_loss=1.4980, LR=0.000100
[2025-08-26 23:43:31,730][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016672] [Batch 01272/03080] [00:15:53/00:22:35, 0.749s/it]: train_loss_raw=1.4926, running_loss=1.4995, LR=0.000100
[2025-08-26 23:43:37,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016680] [Batch 01280/03080] [00:15:59/00:22:28, 0.749s/it]: train_loss_raw=1.4516, running_loss=1.4964, LR=0.000100
[2025-08-26 23:43:43,586][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016688] [Batch 01288/03080] [00:16:05/00:22:22, 0.749s/it]: train_loss_raw=1.5227, running_loss=1.4954, LR=0.000100
[2025-08-26 23:43:49,541][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016696] [Batch 01296/03080] [00:16:11/00:22:16, 0.749s/it]: train_loss_raw=1.5609, running_loss=1.4987, LR=0.000100
[2025-08-26 23:43:55,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016704] [Batch 01304/03080] [00:16:16/00:22:10, 0.749s/it]: train_loss_raw=1.5148, running_loss=1.4983, LR=0.000100
[2025-08-26 23:44:01,131][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016712] [Batch 01312/03080] [00:16:22/00:22:04, 0.749s/it]: train_loss_raw=1.4982, running_loss=1.4941, LR=0.000100
[2025-08-26 23:44:07,072][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016720] [Batch 01320/03080] [00:16:28/00:21:58, 0.749s/it]: train_loss_raw=1.6048, running_loss=1.4944, LR=0.000100
[2025-08-26 23:44:12,875][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016728] [Batch 01328/03080] [00:16:34/00:21:51, 0.749s/it]: train_loss_raw=1.5633, running_loss=1.4958, LR=0.000100
[2025-08-26 23:44:18,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016736] [Batch 01336/03080] [00:16:40/00:21:45, 0.749s/it]: train_loss_raw=1.5246, running_loss=1.4948, LR=0.000100
[2025-08-26 23:44:24,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016744] [Batch 01344/03080] [00:16:46/00:21:39, 0.749s/it]: train_loss_raw=1.4892, running_loss=1.4958, LR=0.000100
[2025-08-26 23:44:30,380][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016752] [Batch 01352/03080] [00:16:51/00:21:33, 0.749s/it]: train_loss_raw=1.4933, running_loss=1.4954, LR=0.000100
[2025-08-26 23:44:36,322][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016760] [Batch 01360/03080] [00:16:57/00:21:27, 0.748s/it]: train_loss_raw=1.5015, running_loss=1.4954, LR=0.000100
[2025-08-26 23:44:42,214][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016768] [Batch 01368/03080] [00:17:03/00:21:21, 0.748s/it]: train_loss_raw=1.4152, running_loss=1.4928, LR=0.000100
[2025-08-26 23:44:48,307][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016776] [Batch 01376/03080] [00:17:09/00:21:15, 0.748s/it]: train_loss_raw=1.4498, running_loss=1.4905, LR=0.000100
[2025-08-26 23:44:54,322][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016784] [Batch 01384/03080] [00:17:15/00:21:09, 0.748s/it]: train_loss_raw=1.4342, running_loss=1.4895, LR=0.000100
[2025-08-26 23:45:00,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016792] [Batch 01392/03080] [00:17:22/00:21:03, 0.749s/it]: train_loss_raw=1.5286, running_loss=1.4892, LR=0.000100
[2025-08-26 23:45:06,774][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016800] [Batch 01400/03080] [00:17:28/00:20:58, 0.749s/it]: train_loss_raw=1.3229, running_loss=1.4884, LR=0.000100
[2025-08-26 23:45:13,083][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016808] [Batch 01408/03080] [00:17:34/00:20:52, 0.749s/it]: train_loss_raw=1.5805, running_loss=1.4905, LR=0.000100
[2025-08-26 23:45:19,020][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016816] [Batch 01416/03080] [00:17:40/00:20:46, 0.749s/it]: train_loss_raw=1.5033, running_loss=1.4915, LR=0.000100
[2025-08-26 23:45:24,970][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016824] [Batch 01424/03080] [00:17:46/00:20:40, 0.749s/it]: train_loss_raw=1.4557, running_loss=1.4917, LR=0.000100
[2025-08-26 23:45:30,898][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016832] [Batch 01432/03080] [00:17:52/00:20:34, 0.749s/it]: train_loss_raw=1.6093, running_loss=1.4930, LR=0.000100
[2025-08-26 23:45:36,953][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016840] [Batch 01440/03080] [00:17:58/00:20:28, 0.749s/it]: train_loss_raw=1.4318, running_loss=1.4941, LR=0.000100
[2025-08-26 23:45:42,911][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016848] [Batch 01448/03080] [00:18:04/00:20:22, 0.749s/it]: train_loss_raw=1.5469, running_loss=1.4962, LR=0.000100
[2025-08-26 23:45:48,936][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016856] [Batch 01456/03080] [00:18:10/00:20:16, 0.749s/it]: train_loss_raw=1.5016, running_loss=1.4953, LR=0.000100
[2025-08-26 23:45:54,992][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016864] [Batch 01464/03080] [00:18:16/00:20:10, 0.749s/it]: train_loss_raw=1.5369, running_loss=1.4959, LR=0.000100
[2025-08-26 23:46:01,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016872] [Batch 01472/03080] [00:18:22/00:20:04, 0.749s/it]: train_loss_raw=1.4914, running_loss=1.4966, LR=0.000100
[2025-08-26 23:46:07,447][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016880] [Batch 01480/03080] [00:18:29/00:19:58, 0.749s/it]: train_loss_raw=1.4072, running_loss=1.4975, LR=0.000100
[2025-08-26 23:46:13,450][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016888] [Batch 01488/03080] [00:18:35/00:19:52, 0.749s/it]: train_loss_raw=1.3034, running_loss=1.4957, LR=0.000100
[2025-08-26 23:46:19,226][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016896] [Batch 01496/03080] [00:18:40/00:19:46, 0.749s/it]: train_loss_raw=1.5334, running_loss=1.4938, LR=0.000100
[2025-08-26 23:46:25,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016904] [Batch 01504/03080] [00:18:46/00:19:40, 0.749s/it]: train_loss_raw=1.5165, running_loss=1.4938, LR=0.000100
[2025-08-26 23:46:31,206][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016912] [Batch 01512/03080] [00:18:52/00:19:34, 0.749s/it]: train_loss_raw=1.3431, running_loss=1.4925, LR=0.000100
[2025-08-26 23:46:37,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016920] [Batch 01520/03080] [00:18:58/00:19:28, 0.749s/it]: train_loss_raw=1.5356, running_loss=1.4933, LR=0.000100
[2025-08-26 23:46:43,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016928] [Batch 01528/03080] [00:19:04/00:19:22, 0.749s/it]: train_loss_raw=1.5358, running_loss=1.4930, LR=0.000100
[2025-08-26 23:46:49,075][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016936] [Batch 01536/03080] [00:19:10/00:19:16, 0.749s/it]: train_loss_raw=1.4618, running_loss=1.4934, LR=0.000100
[2025-08-26 23:46:54,814][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016944] [Batch 01544/03080] [00:19:16/00:19:10, 0.749s/it]: train_loss_raw=1.4503, running_loss=1.4919, LR=0.000100
[2025-08-26 23:47:00,667][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016952] [Batch 01552/03080] [00:19:22/00:19:04, 0.749s/it]: train_loss_raw=1.4607, running_loss=1.4905, LR=0.000100
[2025-08-26 23:47:06,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016960] [Batch 01560/03080] [00:19:28/00:18:58, 0.749s/it]: train_loss_raw=1.4786, running_loss=1.4879, LR=0.000100
[2025-08-26 23:47:12,648][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016968] [Batch 01568/03080] [00:19:34/00:18:52, 0.749s/it]: train_loss_raw=1.4460, running_loss=1.4854, LR=0.000100
[2025-08-26 23:47:18,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016976] [Batch 01576/03080] [00:19:40/00:18:46, 0.749s/it]: train_loss_raw=1.4435, running_loss=1.4842, LR=0.000100
[2025-08-26 23:47:24,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016984] [Batch 01584/03080] [00:19:46/00:18:40, 0.749s/it]: train_loss_raw=1.3988, running_loss=1.4834, LR=0.000100
[2025-08-26 23:47:31,032][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 016992] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=1.4902, running_loss=1.4813, LR=0.000100
[2025-08-26 23:47:36,962][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017000] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=1.5089, running_loss=1.4855, LR=0.000100
[2025-08-26 23:47:43,148][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017008] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=1.4140, running_loss=1.4863, LR=0.000100
[2025-08-26 23:47:49,274][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017016] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=1.5003, running_loss=1.4841, LR=0.000100
[2025-08-26 23:47:55,525][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017024] [Batch 01624/03080] [00:20:17/00:18:11, 0.749s/it]: train_loss_raw=1.5810, running_loss=1.4843, LR=0.000100
[2025-08-26 23:48:01,767][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017032] [Batch 01632/03080] [00:20:23/00:18:05, 0.750s/it]: train_loss_raw=1.4232, running_loss=1.4834, LR=0.000100
[2025-08-26 23:48:07,687][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017040] [Batch 01640/03080] [00:20:29/00:17:59, 0.750s/it]: train_loss_raw=1.4990, running_loss=1.4815, LR=0.000100
[2025-08-26 23:48:13,663][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017048] [Batch 01648/03080] [00:20:35/00:17:53, 0.750s/it]: train_loss_raw=1.5078, running_loss=1.4790, LR=0.000100
[2025-08-26 23:48:19,684][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017056] [Batch 01656/03080] [00:20:41/00:17:47, 0.750s/it]: train_loss_raw=1.4682, running_loss=1.4785, LR=0.000100
[2025-08-26 23:48:25,609][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017064] [Batch 01664/03080] [00:20:47/00:17:41, 0.750s/it]: train_loss_raw=1.4453, running_loss=1.4797, LR=0.000100
[2025-08-26 23:48:31,570][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017072] [Batch 01672/03080] [00:20:53/00:17:35, 0.750s/it]: train_loss_raw=1.4820, running_loss=1.4798, LR=0.000100
[2025-08-26 23:48:37,525][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017080] [Batch 01680/03080] [00:20:59/00:17:29, 0.749s/it]: train_loss_raw=1.4001, running_loss=1.4808, LR=0.000100
[2025-08-26 23:48:43,480][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017088] [Batch 01688/03080] [00:21:05/00:17:23, 0.749s/it]: train_loss_raw=1.4125, running_loss=1.4809, LR=0.000100
[2025-08-26 23:48:49,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017096] [Batch 01696/03080] [00:21:11/00:17:17, 0.749s/it]: train_loss_raw=1.5038, running_loss=1.4803, LR=0.000100
[2025-08-26 23:48:55,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017104] [Batch 01704/03080] [00:21:17/00:17:11, 0.749s/it]: train_loss_raw=1.4614, running_loss=1.4766, LR=0.000100
[2025-08-26 23:49:01,390][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017112] [Batch 01712/03080] [00:21:22/00:17:05, 0.749s/it]: train_loss_raw=1.4740, running_loss=1.4753, LR=0.000100
[2025-08-26 23:49:07,197][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017120] [Batch 01720/03080] [00:21:28/00:16:59, 0.749s/it]: train_loss_raw=1.4660, running_loss=1.4753, LR=0.000100
[2025-08-26 23:49:12,998][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017128] [Batch 01728/03080] [00:21:34/00:16:52, 0.749s/it]: train_loss_raw=1.4837, running_loss=1.4761, LR=0.000100
[2025-08-26 23:49:18,714][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017136] [Batch 01736/03080] [00:21:40/00:16:46, 0.749s/it]: train_loss_raw=1.4018, running_loss=1.4736, LR=0.000100
[2025-08-26 23:49:24,597][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017144] [Batch 01744/03080] [00:21:46/00:16:40, 0.749s/it]: train_loss_raw=1.5127, running_loss=1.4726, LR=0.000100
[2025-08-26 23:49:30,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017152] [Batch 01752/03080] [00:21:52/00:16:34, 0.749s/it]: train_loss_raw=1.4864, running_loss=1.4747, LR=0.000100
[2025-08-26 23:49:36,210][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017160] [Batch 01760/03080] [00:21:57/00:16:28, 0.749s/it]: train_loss_raw=1.6026, running_loss=1.4728, LR=0.000100
[2025-08-26 23:49:42,268][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017168] [Batch 01768/03080] [00:22:03/00:16:22, 0.749s/it]: train_loss_raw=1.4948, running_loss=1.4745, LR=0.000100
[2025-08-26 23:49:48,315][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017176] [Batch 01776/03080] [00:22:09/00:16:16, 0.749s/it]: train_loss_raw=1.5747, running_loss=1.4801, LR=0.000100
[2025-08-26 23:49:54,289][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017184] [Batch 01784/03080] [00:22:15/00:16:10, 0.749s/it]: train_loss_raw=1.4991, running_loss=1.4782, LR=0.000100
[2025-08-26 23:50:00,343][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017192] [Batch 01792/03080] [00:22:21/00:16:04, 0.749s/it]: train_loss_raw=1.4827, running_loss=1.4764, LR=0.000100
[2025-08-26 23:50:06,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017200] [Batch 01800/03080] [00:22:28/00:15:58, 0.749s/it]: train_loss_raw=1.4291, running_loss=1.4737, LR=0.000100
[2025-08-26 23:50:12,303][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017208] [Batch 01808/03080] [00:22:33/00:15:52, 0.749s/it]: train_loss_raw=1.4631, running_loss=1.4726, LR=0.000100
[2025-08-26 23:50:18,018][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017216] [Batch 01816/03080] [00:22:39/00:15:46, 0.749s/it]: train_loss_raw=1.4512, running_loss=1.4712, LR=0.000100
[2025-08-26 23:50:23,851][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017224] [Batch 01824/03080] [00:22:45/00:15:40, 0.749s/it]: train_loss_raw=1.4817, running_loss=1.4709, LR=0.000100
[2025-08-26 23:50:29,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017232] [Batch 01832/03080] [00:22:51/00:15:34, 0.749s/it]: train_loss_raw=1.4361, running_loss=1.4727, LR=0.000100
[2025-08-26 23:50:35,513][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017240] [Batch 01840/03080] [00:22:57/00:15:28, 0.748s/it]: train_loss_raw=1.4231, running_loss=1.4704, LR=0.000100
[2025-08-26 23:50:41,515][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017248] [Batch 01848/03080] [00:23:03/00:15:22, 0.748s/it]: train_loss_raw=1.5740, running_loss=1.4712, LR=0.000100
[2025-08-26 23:50:47,331][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017256] [Batch 01856/03080] [00:23:08/00:15:15, 0.748s/it]: train_loss_raw=1.5371, running_loss=1.4722, LR=0.000100
[2025-08-26 23:50:53,541][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017264] [Batch 01864/03080] [00:23:15/00:15:10, 0.748s/it]: train_loss_raw=1.4805, running_loss=1.4718, LR=0.000100
[2025-08-26 23:50:59,824][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017272] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=1.5980, running_loss=1.4759, LR=0.000100
[2025-08-26 23:51:05,964][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017280] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=1.4338, running_loss=1.4763, LR=0.000100
[2025-08-26 23:51:11,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017288] [Batch 01888/03080] [00:23:33/00:14:52, 0.749s/it]: train_loss_raw=1.4276, running_loss=1.4776, LR=0.000100
[2025-08-26 23:51:17,431][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017296] [Batch 01896/03080] [00:23:39/00:14:46, 0.748s/it]: train_loss_raw=1.4518, running_loss=1.4783, LR=0.000100
[2025-08-26 23:51:23,367][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017304] [Batch 01904/03080] [00:23:44/00:14:40, 0.748s/it]: train_loss_raw=1.3524, running_loss=1.4744, LR=0.000100
[2025-08-26 23:51:29,490][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017312] [Batch 01912/03080] [00:23:51/00:14:34, 0.748s/it]: train_loss_raw=1.3832, running_loss=1.4724, LR=0.000100
[2025-08-26 23:51:35,254][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017320] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=1.4226, running_loss=1.4737, LR=0.000100
[2025-08-26 23:51:41,176][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017328] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=1.5937, running_loss=1.4762, LR=0.000100
[2025-08-26 23:51:47,162][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017336] [Batch 01936/03080] [00:24:08/00:14:16, 0.748s/it]: train_loss_raw=1.4294, running_loss=1.4752, LR=0.000100
[2025-08-26 23:51:53,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017344] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=1.4219, running_loss=1.4775, LR=0.000100
[2025-08-26 23:51:59,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017352] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=1.4574, running_loss=1.4773, LR=0.000100
[2025-08-26 23:52:05,152][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017360] [Batch 01960/03080] [00:24:26/00:13:58, 0.748s/it]: train_loss_raw=1.3829, running_loss=1.4765, LR=0.000100
[2025-08-26 23:52:11,374][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017368] [Batch 01968/03080] [00:24:32/00:13:52, 0.748s/it]: train_loss_raw=1.4585, running_loss=1.4737, LR=0.000100
[2025-08-26 23:52:17,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017376] [Batch 01976/03080] [00:24:38/00:13:46, 0.748s/it]: train_loss_raw=1.4018, running_loss=1.4743, LR=0.000100
[2025-08-26 23:52:23,382][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017384] [Batch 01984/03080] [00:24:44/00:13:40, 0.748s/it]: train_loss_raw=1.5168, running_loss=1.4745, LR=0.000100
[2025-08-26 23:52:29,412][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017392] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=1.3510, running_loss=1.4740, LR=0.000100
[2025-08-26 23:52:35,264][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017400] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=1.5310, running_loss=1.4763, LR=0.000100
[2025-08-26 23:52:41,377][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017408] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=1.4316, running_loss=1.4749, LR=0.000100
[2025-08-26 23:52:47,484][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017416] [Batch 02016/03080] [00:25:09/00:13:16, 0.749s/it]: train_loss_raw=1.5554, running_loss=1.4723, LR=0.000100
[2025-08-26 23:52:53,520][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017424] [Batch 02024/03080] [00:25:15/00:13:10, 0.749s/it]: train_loss_raw=1.5547, running_loss=1.4723, LR=0.000100
[2025-08-26 23:52:59,586][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017432] [Batch 02032/03080] [00:25:21/00:13:04, 0.749s/it]: train_loss_raw=1.5754, running_loss=1.4722, LR=0.000100
[2025-08-26 23:53:05,523][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017440] [Batch 02040/03080] [00:25:27/00:12:58, 0.749s/it]: train_loss_raw=1.4369, running_loss=1.4711, LR=0.000100
[2025-08-26 23:53:11,490][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017448] [Batch 02048/03080] [00:25:33/00:12:52, 0.749s/it]: train_loss_raw=1.4175, running_loss=1.4702, LR=0.000100
[2025-08-26 23:53:17,746][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017456] [Batch 02056/03080] [00:25:39/00:12:46, 0.749s/it]: train_loss_raw=1.4378, running_loss=1.4706, LR=0.000100
[2025-08-26 23:53:23,779][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017464] [Batch 02064/03080] [00:25:45/00:12:40, 0.749s/it]: train_loss_raw=1.5081, running_loss=1.4721, LR=0.000100
[2025-08-26 23:53:29,786][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017472] [Batch 02072/03080] [00:25:51/00:12:34, 0.749s/it]: train_loss_raw=1.5502, running_loss=1.4726, LR=0.000100
[2025-08-26 23:53:35,833][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017480] [Batch 02080/03080] [00:25:57/00:12:28, 0.749s/it]: train_loss_raw=1.4812, running_loss=1.4714, LR=0.000100
[2025-08-26 23:53:41,864][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017488] [Batch 02088/03080] [00:26:03/00:12:22, 0.749s/it]: train_loss_raw=1.4611, running_loss=1.4722, LR=0.000100
[2025-08-26 23:53:47,751][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017496] [Batch 02096/03080] [00:26:09/00:12:16, 0.749s/it]: train_loss_raw=1.5257, running_loss=1.4720, LR=0.000100
[2025-08-26 23:53:53,579][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017504] [Batch 02104/03080] [00:26:15/00:12:10, 0.749s/it]: train_loss_raw=1.4531, running_loss=1.4709, LR=0.000100
[2025-08-26 23:53:59,658][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017512] [Batch 02112/03080] [00:26:21/00:12:04, 0.749s/it]: train_loss_raw=1.4712, running_loss=1.4692, LR=0.000100
[2025-08-26 23:54:05,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017520] [Batch 02120/03080] [00:26:27/00:11:58, 0.749s/it]: train_loss_raw=1.4521, running_loss=1.4695, LR=0.000100
[2025-08-26 23:54:11,574][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017528] [Batch 02128/03080] [00:26:33/00:11:52, 0.749s/it]: train_loss_raw=1.4329, running_loss=1.4689, LR=0.000100
[2025-08-26 23:54:17,563][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017536] [Batch 02136/03080] [00:26:39/00:11:46, 0.749s/it]: train_loss_raw=1.5385, running_loss=1.4686, LR=0.000100
[2025-08-26 23:54:23,750][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017544] [Batch 02144/03080] [00:26:45/00:11:40, 0.749s/it]: train_loss_raw=1.3703, running_loss=1.4656, LR=0.000100
[2025-08-26 23:54:29,958][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017552] [Batch 02152/03080] [00:26:51/00:11:34, 0.749s/it]: train_loss_raw=1.4474, running_loss=1.4659, LR=0.000100
[2025-08-26 23:54:35,975][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017560] [Batch 02160/03080] [00:26:57/00:11:28, 0.749s/it]: train_loss_raw=1.4119, running_loss=1.4665, LR=0.000100
[2025-08-26 23:54:41,881][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017568] [Batch 02168/03080] [00:27:03/00:11:22, 0.749s/it]: train_loss_raw=1.4366, running_loss=1.4655, LR=0.000100
[2025-08-26 23:54:47,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017576] [Batch 02176/03080] [00:27:09/00:11:16, 0.749s/it]: train_loss_raw=1.5064, running_loss=1.4679, LR=0.000100
[2025-08-26 23:54:53,679][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017584] [Batch 02184/03080] [00:27:15/00:11:10, 0.749s/it]: train_loss_raw=1.5180, running_loss=1.4672, LR=0.000100
[2025-08-26 23:54:59,883][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017592] [Batch 02192/03080] [00:27:21/00:11:04, 0.749s/it]: train_loss_raw=1.5432, running_loss=1.4691, LR=0.000100
[2025-08-26 23:55:06,243][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017600] [Batch 02200/03080] [00:27:27/00:10:59, 0.749s/it]: train_loss_raw=1.3830, running_loss=1.4664, LR=0.000100
[2025-08-26 23:55:12,437][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017608] [Batch 02208/03080] [00:27:34/00:10:53, 0.749s/it]: train_loss_raw=1.5023, running_loss=1.4663, LR=0.000100
[2025-08-26 23:55:18,577][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017616] [Batch 02216/03080] [00:27:40/00:10:47, 0.749s/it]: train_loss_raw=1.5137, running_loss=1.4666, LR=0.000100
[2025-08-26 23:55:24,471][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017624] [Batch 02224/03080] [00:27:46/00:10:41, 0.749s/it]: train_loss_raw=1.5091, running_loss=1.4684, LR=0.000100
[2025-08-26 23:55:30,324][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017632] [Batch 02232/03080] [00:27:51/00:10:35, 0.749s/it]: train_loss_raw=1.4886, running_loss=1.4664, LR=0.000100
[2025-08-26 23:55:36,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017640] [Batch 02240/03080] [00:27:58/00:10:29, 0.749s/it]: train_loss_raw=1.4425, running_loss=1.4657, LR=0.000100
[2025-08-26 23:55:42,405][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017648] [Batch 02248/03080] [00:28:04/00:10:23, 0.749s/it]: train_loss_raw=1.4747, running_loss=1.4656, LR=0.000100
[2025-08-26 23:55:48,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017656] [Batch 02256/03080] [00:28:09/00:10:17, 0.749s/it]: train_loss_raw=1.3831, running_loss=1.4652, LR=0.000100
[2025-08-26 23:55:54,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017664] [Batch 02264/03080] [00:28:15/00:10:11, 0.749s/it]: train_loss_raw=1.3729, running_loss=1.4654, LR=0.000100
[2025-08-26 23:56:00,138][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017672] [Batch 02272/03080] [00:28:21/00:10:05, 0.749s/it]: train_loss_raw=1.4104, running_loss=1.4633, LR=0.000100
[2025-08-26 23:56:06,132][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017680] [Batch 02280/03080] [00:28:27/00:09:59, 0.749s/it]: train_loss_raw=1.5074, running_loss=1.4624, LR=0.000100
[2025-08-26 23:56:12,071][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017688] [Batch 02288/03080] [00:28:33/00:09:53, 0.749s/it]: train_loss_raw=1.5451, running_loss=1.4645, LR=0.000100
[2025-08-26 23:56:18,144][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017696] [Batch 02296/03080] [00:28:39/00:09:47, 0.749s/it]: train_loss_raw=1.4523, running_loss=1.4629, LR=0.000100
[2025-08-26 23:56:24,181][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017704] [Batch 02304/03080] [00:28:45/00:09:41, 0.749s/it]: train_loss_raw=1.5221, running_loss=1.4672, LR=0.000100
[2025-08-26 23:56:30,104][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017712] [Batch 02312/03080] [00:28:51/00:09:35, 0.749s/it]: train_loss_raw=1.4626, running_loss=1.4655, LR=0.000100
[2025-08-26 23:56:36,143][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017720] [Batch 02320/03080] [00:28:57/00:09:29, 0.749s/it]: train_loss_raw=1.4450, running_loss=1.4623, LR=0.000100
[2025-08-26 23:56:42,792][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017728] [Batch 02328/03080] [00:29:04/00:09:23, 0.749s/it]: train_loss_raw=1.4275, running_loss=1.4602, LR=0.000100
[2025-08-26 23:56:48,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017736] [Batch 02336/03080] [00:29:10/00:09:17, 0.749s/it]: train_loss_raw=1.4646, running_loss=1.4580, LR=0.000100
[2025-08-26 23:56:54,297][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017744] [Batch 02344/03080] [00:29:15/00:09:11, 0.749s/it]: train_loss_raw=1.4990, running_loss=1.4586, LR=0.000100
[2025-08-26 23:57:00,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017752] [Batch 02352/03080] [00:29:21/00:09:05, 0.749s/it]: train_loss_raw=1.4855, running_loss=1.4594, LR=0.000100
[2025-08-26 23:57:06,207][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017760] [Batch 02360/03080] [00:29:27/00:08:59, 0.749s/it]: train_loss_raw=1.5105, running_loss=1.4587, LR=0.000100
[2025-08-26 23:57:12,536][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017768] [Batch 02368/03080] [00:29:34/00:08:53, 0.749s/it]: train_loss_raw=1.3792, running_loss=1.4565, LR=0.000100
[2025-08-26 23:57:18,397][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017776] [Batch 02376/03080] [00:29:39/00:08:47, 0.749s/it]: train_loss_raw=1.5450, running_loss=1.4559, LR=0.000100
[2025-08-26 23:57:24,248][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017784] [Batch 02384/03080] [00:29:45/00:08:41, 0.749s/it]: train_loss_raw=1.4083, running_loss=1.4559, LR=0.000100
[2025-08-26 23:57:30,077][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017792] [Batch 02392/03080] [00:29:51/00:08:35, 0.749s/it]: train_loss_raw=1.4336, running_loss=1.4577, LR=0.000100
[2025-08-26 23:57:36,199][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017800] [Batch 02400/03080] [00:29:57/00:08:29, 0.749s/it]: train_loss_raw=1.5932, running_loss=1.4591, LR=0.000100
[2025-08-26 23:57:42,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017808] [Batch 02408/03080] [00:30:03/00:08:23, 0.749s/it]: train_loss_raw=1.4631, running_loss=1.4582, LR=0.000100
[2025-08-26 23:57:47,981][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017816] [Batch 02416/03080] [00:30:09/00:08:17, 0.749s/it]: train_loss_raw=1.4307, running_loss=1.4606, LR=0.000100
[2025-08-26 23:57:53,824][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017824] [Batch 02424/03080] [00:30:15/00:08:11, 0.749s/it]: train_loss_raw=1.4292, running_loss=1.4631, LR=0.000100
[2025-08-26 23:57:59,687][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017832] [Batch 02432/03080] [00:30:21/00:08:05, 0.749s/it]: train_loss_raw=1.5393, running_loss=1.4618, LR=0.000100
[2025-08-26 23:58:05,584][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017840] [Batch 02440/03080] [00:30:27/00:07:59, 0.749s/it]: train_loss_raw=1.4029, running_loss=1.4597, LR=0.000100
[2025-08-26 23:58:11,637][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017848] [Batch 02448/03080] [00:30:33/00:07:53, 0.749s/it]: train_loss_raw=1.3201, running_loss=1.4568, LR=0.000100
[2025-08-26 23:58:17,864][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017856] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.5204, running_loss=1.4579, LR=0.000100
[2025-08-26 23:58:23,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017864] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.5328, running_loss=1.4583, LR=0.000100
[2025-08-26 23:58:29,966][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017872] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.4823, running_loss=1.4566, LR=0.000100
[2025-08-26 23:58:35,546][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017880] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.4506, running_loss=1.4590, LR=0.000100
[2025-08-26 23:58:41,177][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017888] [Batch 02488/03080] [00:31:02/00:07:23, 0.749s/it]: train_loss_raw=1.3397, running_loss=1.4573, LR=0.000100
[2025-08-26 23:58:47,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017896] [Batch 02496/03080] [00:31:08/00:07:17, 0.749s/it]: train_loss_raw=1.5407, running_loss=1.4547, LR=0.000100
[2025-08-26 23:58:52,873][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017904] [Batch 02504/03080] [00:31:14/00:07:11, 0.749s/it]: train_loss_raw=1.3658, running_loss=1.4534, LR=0.000100
[2025-08-26 23:58:58,732][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017912] [Batch 02512/03080] [00:31:20/00:07:05, 0.749s/it]: train_loss_raw=1.5453, running_loss=1.4547, LR=0.000100
[2025-08-26 23:59:04,602][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017920] [Batch 02520/03080] [00:31:26/00:06:59, 0.748s/it]: train_loss_raw=1.5046, running_loss=1.4564, LR=0.000100
[2025-08-26 23:59:10,336][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017928] [Batch 02528/03080] [00:31:31/00:06:53, 0.748s/it]: train_loss_raw=1.4333, running_loss=1.4545, LR=0.000100
[2025-08-26 23:59:16,064][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017936] [Batch 02536/03080] [00:31:37/00:06:47, 0.748s/it]: train_loss_raw=1.4274, running_loss=1.4540, LR=0.000100
[2025-08-26 23:59:21,951][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017944] [Batch 02544/03080] [00:31:43/00:06:41, 0.748s/it]: train_loss_raw=1.5076, running_loss=1.4553, LR=0.000100
[2025-08-26 23:59:28,211][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017952] [Batch 02552/03080] [00:31:49/00:06:35, 0.748s/it]: train_loss_raw=1.4265, running_loss=1.4556, LR=0.000100
[2025-08-26 23:59:33,939][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017960] [Batch 02560/03080] [00:31:55/00:06:29, 0.748s/it]: train_loss_raw=1.3688, running_loss=1.4531, LR=0.000100
[2025-08-26 23:59:39,794][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017968] [Batch 02568/03080] [00:32:01/00:06:23, 0.748s/it]: train_loss_raw=1.4439, running_loss=1.4544, LR=0.000100
[2025-08-26 23:59:45,404][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017976] [Batch 02576/03080] [00:32:07/00:06:17, 0.748s/it]: train_loss_raw=1.3906, running_loss=1.4527, LR=0.000100
[2025-08-26 23:59:50,922][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017984] [Batch 02584/03080] [00:32:12/00:06:10, 0.748s/it]: train_loss_raw=1.4969, running_loss=1.4518, LR=0.000100
[2025-08-26 23:59:56,822][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 017992] [Batch 02592/03080] [00:32:18/00:06:04, 0.748s/it]: train_loss_raw=1.4736, running_loss=1.4517, LR=0.000100
[2025-08-27 00:00:02,846][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018000] [Batch 02600/03080] [00:32:24/00:05:58, 0.748s/it]: train_loss_raw=1.3913, running_loss=1.4519, LR=0.000100
[2025-08-27 00:00:12,550][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018008] [Batch 02608/03080] [00:32:34/00:05:53, 0.749s/it]: train_loss_raw=1.4931, running_loss=1.4543, LR=0.000100
[2025-08-27 00:00:18,334][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018016] [Batch 02616/03080] [00:32:39/00:05:47, 0.749s/it]: train_loss_raw=1.4300, running_loss=1.4576, LR=0.000100
[2025-08-27 00:00:24,052][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018024] [Batch 02624/03080] [00:32:45/00:05:41, 0.749s/it]: train_loss_raw=1.4418, running_loss=1.4558, LR=0.000100
[2025-08-27 00:00:29,795][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018032] [Batch 02632/03080] [00:32:51/00:05:35, 0.749s/it]: train_loss_raw=1.4850, running_loss=1.4558, LR=0.000100
[2025-08-27 00:00:35,636][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018040] [Batch 02640/03080] [00:32:57/00:05:29, 0.749s/it]: train_loss_raw=1.5700, running_loss=1.4555, LR=0.000100
[2025-08-27 00:00:41,617][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018048] [Batch 02648/03080] [00:33:03/00:05:23, 0.749s/it]: train_loss_raw=1.4434, running_loss=1.4534, LR=0.000100
[2025-08-27 00:00:47,262][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018056] [Batch 02656/03080] [00:33:08/00:05:17, 0.749s/it]: train_loss_raw=1.5175, running_loss=1.4566, LR=0.000100
[2025-08-27 00:00:53,059][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018064] [Batch 02664/03080] [00:33:14/00:05:11, 0.749s/it]: train_loss_raw=1.4204, running_loss=1.4561, LR=0.000100
[2025-08-27 00:00:58,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018072] [Batch 02672/03080] [00:33:20/00:05:05, 0.749s/it]: train_loss_raw=1.4561, running_loss=1.4553, LR=0.000100
[2025-08-27 00:01:04,658][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018080] [Batch 02680/03080] [00:33:26/00:04:59, 0.749s/it]: train_loss_raw=1.4501, running_loss=1.4561, LR=0.000100
[2025-08-27 00:01:10,408][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018088] [Batch 02688/03080] [00:33:32/00:04:53, 0.749s/it]: train_loss_raw=1.4399, running_loss=1.4580, LR=0.000100
[2025-08-27 00:01:16,119][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018096] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=1.5185, running_loss=1.4572, LR=0.000100
[2025-08-27 00:01:21,848][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018104] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=1.3953, running_loss=1.4558, LR=0.000100
[2025-08-27 00:01:27,513][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018112] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=1.3784, running_loss=1.4549, LR=0.000100
[2025-08-27 00:01:33,277][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018120] [Batch 02720/03080] [00:33:54/00:04:29, 0.748s/it]: train_loss_raw=1.5355, running_loss=1.4566, LR=0.000100
[2025-08-27 00:01:39,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018128] [Batch 02728/03080] [00:34:00/00:04:23, 0.748s/it]: train_loss_raw=1.5038, running_loss=1.4565, LR=0.000100
[2025-08-27 00:01:44,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018136] [Batch 02736/03080] [00:34:06/00:04:17, 0.748s/it]: train_loss_raw=1.4494, running_loss=1.4544, LR=0.000100
[2025-08-27 00:01:50,784][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018144] [Batch 02744/03080] [00:34:12/00:04:11, 0.748s/it]: train_loss_raw=1.4611, running_loss=1.4521, LR=0.000100
[2025-08-27 00:01:56,693][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018152] [Batch 02752/03080] [00:34:18/00:04:05, 0.748s/it]: train_loss_raw=1.3781, running_loss=1.4502, LR=0.000100
[2025-08-27 00:02:02,568][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018160] [Batch 02760/03080] [00:34:24/00:03:59, 0.748s/it]: train_loss_raw=1.3940, running_loss=1.4501, LR=0.000100
[2025-08-27 00:02:08,538][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018168] [Batch 02768/03080] [00:34:30/00:03:53, 0.748s/it]: train_loss_raw=1.4999, running_loss=1.4486, LR=0.000100
[2025-08-27 00:02:14,451][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018176] [Batch 02776/03080] [00:34:36/00:03:47, 0.748s/it]: train_loss_raw=1.4136, running_loss=1.4465, LR=0.000100
[2025-08-27 00:02:20,197][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018184] [Batch 02784/03080] [00:34:41/00:03:41, 0.748s/it]: train_loss_raw=1.3882, running_loss=1.4454, LR=0.000100
[2025-08-27 00:02:26,031][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018192] [Batch 02792/03080] [00:34:47/00:03:35, 0.748s/it]: train_loss_raw=1.3957, running_loss=1.4415, LR=0.000100
[2025-08-27 00:02:31,651][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018200] [Batch 02800/03080] [00:34:53/00:03:29, 0.748s/it]: train_loss_raw=1.4778, running_loss=1.4419, LR=0.000100
[2025-08-27 00:02:37,252][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018208] [Batch 02808/03080] [00:34:58/00:03:23, 0.747s/it]: train_loss_raw=1.3704, running_loss=1.4436, LR=0.000100
[2025-08-27 00:02:43,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018216] [Batch 02816/03080] [00:35:04/00:03:17, 0.747s/it]: train_loss_raw=1.4967, running_loss=1.4435, LR=0.000100
[2025-08-27 00:02:48,708][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018224] [Batch 02824/03080] [00:35:10/00:03:11, 0.747s/it]: train_loss_raw=1.4355, running_loss=1.4442, LR=0.000100
[2025-08-27 00:02:54,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018232] [Batch 02832/03080] [00:35:16/00:03:05, 0.747s/it]: train_loss_raw=1.3450, running_loss=1.4444, LR=0.000100
[2025-08-27 00:03:00,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018240] [Batch 02840/03080] [00:35:21/00:02:59, 0.747s/it]: train_loss_raw=1.4882, running_loss=1.4461, LR=0.000100
[2025-08-27 00:03:05,921][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018248] [Batch 02848/03080] [00:35:27/00:02:53, 0.747s/it]: train_loss_raw=1.3722, running_loss=1.4429, LR=0.000100
[2025-08-27 00:03:11,640][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018256] [Batch 02856/03080] [00:35:33/00:02:47, 0.747s/it]: train_loss_raw=1.5226, running_loss=1.4431, LR=0.000100
[2025-08-27 00:03:17,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018264] [Batch 02864/03080] [00:35:39/00:02:41, 0.747s/it]: train_loss_raw=1.4395, running_loss=1.4455, LR=0.000100
[2025-08-27 00:03:23,192][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018272] [Batch 02872/03080] [00:35:44/00:02:35, 0.747s/it]: train_loss_raw=1.3975, running_loss=1.4410, LR=0.000100
[2025-08-27 00:03:29,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018280] [Batch 02880/03080] [00:35:50/00:02:29, 0.747s/it]: train_loss_raw=1.4326, running_loss=1.4406, LR=0.000100
[2025-08-27 00:03:35,116][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018288] [Batch 02888/03080] [00:35:56/00:02:23, 0.747s/it]: train_loss_raw=1.4416, running_loss=1.4410, LR=0.000100
[2025-08-27 00:03:41,139][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018296] [Batch 02896/03080] [00:36:02/00:02:17, 0.747s/it]: train_loss_raw=1.5426, running_loss=1.4414, LR=0.000100
[2025-08-27 00:03:47,080][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018304] [Batch 02904/03080] [00:36:08/00:02:11, 0.747s/it]: train_loss_raw=1.5519, running_loss=1.4393, LR=0.000100
[2025-08-27 00:03:53,053][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018312] [Batch 02912/03080] [00:36:14/00:02:05, 0.747s/it]: train_loss_raw=1.3820, running_loss=1.4387, LR=0.000100
[2025-08-27 00:03:58,883][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018320] [Batch 02920/03080] [00:36:20/00:01:59, 0.747s/it]: train_loss_raw=1.3515, running_loss=1.4358, LR=0.000100
[2025-08-27 00:04:04,715][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018328] [Batch 02928/03080] [00:36:26/00:01:53, 0.747s/it]: train_loss_raw=1.3406, running_loss=1.4354, LR=0.000100
[2025-08-27 00:04:10,840][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018336] [Batch 02936/03080] [00:36:32/00:01:47, 0.747s/it]: train_loss_raw=1.4076, running_loss=1.4362, LR=0.000100
[2025-08-27 00:04:16,852][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018344] [Batch 02944/03080] [00:36:38/00:01:41, 0.747s/it]: train_loss_raw=1.4450, running_loss=1.4342, LR=0.000100
[2025-08-27 00:04:22,837][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018352] [Batch 02952/03080] [00:36:44/00:01:35, 0.747s/it]: train_loss_raw=1.3837, running_loss=1.4354, LR=0.000100
[2025-08-27 00:04:28,869][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018360] [Batch 02960/03080] [00:36:50/00:01:29, 0.747s/it]: train_loss_raw=1.5191, running_loss=1.4402, LR=0.000100
[2025-08-27 00:04:35,052][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018368] [Batch 02968/03080] [00:36:56/00:01:23, 0.747s/it]: train_loss_raw=1.3991, running_loss=1.4397, LR=0.000100
[2025-08-27 00:04:41,038][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018376] [Batch 02976/03080] [00:37:02/00:01:17, 0.747s/it]: train_loss_raw=1.3995, running_loss=1.4385, LR=0.000100
[2025-08-27 00:04:46,865][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018384] [Batch 02984/03080] [00:37:08/00:01:11, 0.747s/it]: train_loss_raw=1.5295, running_loss=1.4373, LR=0.000100
[2025-08-27 00:04:52,729][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018392] [Batch 02992/03080] [00:37:14/00:01:05, 0.747s/it]: train_loss_raw=1.4198, running_loss=1.4356, LR=0.000100
[2025-08-27 00:04:58,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018400] [Batch 03000/03080] [00:37:20/00:00:59, 0.747s/it]: train_loss_raw=1.4401, running_loss=1.4347, LR=0.000100
[2025-08-27 00:05:04,527][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018408] [Batch 03008/03080] [00:37:26/00:00:53, 0.747s/it]: train_loss_raw=1.5054, running_loss=1.4386, LR=0.000100
[2025-08-27 00:05:11,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018416] [Batch 03016/03080] [00:37:32/00:00:47, 0.747s/it]: train_loss_raw=1.4834, running_loss=1.4388, LR=0.000100
[2025-08-27 00:05:17,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018424] [Batch 03024/03080] [00:37:39/00:00:41, 0.747s/it]: train_loss_raw=1.5203, running_loss=1.4392, LR=0.000100
[2025-08-27 00:05:24,002][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018432] [Batch 03032/03080] [00:37:45/00:00:35, 0.747s/it]: train_loss_raw=1.4823, running_loss=1.4384, LR=0.000100
[2025-08-27 00:05:30,234][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018440] [Batch 03040/03080] [00:37:51/00:00:29, 0.747s/it]: train_loss_raw=1.4422, running_loss=1.4412, LR=0.000100
[2025-08-27 00:05:36,149][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018448] [Batch 03048/03080] [00:37:57/00:00:23, 0.747s/it]: train_loss_raw=1.4938, running_loss=1.4413, LR=0.000100
[2025-08-27 00:05:42,222][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018456] [Batch 03056/03080] [00:38:03/00:00:17, 0.747s/it]: train_loss_raw=1.4770, running_loss=1.4411, LR=0.000100
[2025-08-27 00:05:48,358][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018464] [Batch 03064/03080] [00:38:09/00:00:11, 0.747s/it]: train_loss_raw=1.4455, running_loss=1.4405, LR=0.000100
[2025-08-27 00:05:54,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018472] [Batch 03072/03080] [00:38:15/00:00:05, 0.747s/it]: train_loss_raw=1.4661, running_loss=1.4426, LR=0.000100
[2025-08-27 00:06:04,753][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018480] [Batch 03080/03080] [00:38:26/00:00:00, 0.749s/it]: train_loss_raw=1.4370, running_loss=1.4394, LR=0.000100
[2025-08-27 00:06:05,229][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-27 00:06:16,744][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00007/00310] [00:00:11/00:07:14, 1.439s/it]
[2025-08-27 00:06:29,209][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00015/00310] [00:00:23/00:07:20, 1.499s/it]
[2025-08-27 00:06:41,829][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00023/00310] [00:00:36/00:07:16, 1.525s/it]
[2025-08-27 00:06:54,595][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00031/00310] [00:00:49/00:07:08, 1.543s/it]
[2025-08-27 00:07:07,099][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00039/00310] [00:01:01/00:06:57, 1.547s/it]
[2025-08-27 00:07:19,753][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00047/00310] [00:01:14/00:06:46, 1.553s/it]
[2025-08-27 00:07:32,645][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00055/00310] [00:01:27/00:06:36, 1.561s/it]
[2025-08-27 00:07:45,125][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00063/00310] [00:01:39/00:06:23, 1.561s/it]
[2025-08-27 00:07:57,574][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00071/00310] [00:01:52/00:06:11, 1.560s/it]
[2025-08-27 00:08:10,371][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00079/00310] [00:02:05/00:05:59, 1.564s/it]
[2025-08-27 00:08:23,081][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00087/00310] [00:02:17/00:05:47, 1.566s/it]
[2025-08-27 00:08:35,733][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00095/00310] [00:02:30/00:05:35, 1.568s/it]
[2025-08-27 00:08:48,120][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00103/00310] [00:02:42/00:05:22, 1.566s/it]
[2025-08-27 00:08:59,618][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00111/00310] [00:02:54/00:05:08, 1.557s/it]
[2025-08-27 00:09:11,770][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00119/00310] [00:03:06/00:04:55, 1.555s/it]
[2025-08-27 00:09:25,085][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00127/00310] [00:03:19/00:04:44, 1.561s/it]
[2025-08-27 00:09:37,380][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00135/00310] [00:03:32/00:04:31, 1.560s/it]
[2025-08-27 00:09:50,565][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00143/00310] [00:03:45/00:04:19, 1.565s/it]
[2025-08-27 00:10:01,190][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00151/00310] [00:03:55/00:04:05, 1.552s/it]
[2025-08-27 00:10:12,454][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00159/00310] [00:04:07/00:03:51, 1.545s/it]
[2025-08-27 00:10:24,888][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00167/00310] [00:04:19/00:03:39, 1.546s/it]
[2025-08-27 00:10:36,389][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00175/00310] [00:04:31/00:03:26, 1.541s/it]
[2025-08-27 00:10:47,505][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00183/00310] [00:04:42/00:03:13, 1.534s/it]
[2025-08-27 00:10:59,374][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00191/00310] [00:04:54/00:03:00, 1.532s/it]
[2025-08-27 00:11:10,758][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00199/00310] [00:05:05/00:02:48, 1.528s/it]
[2025-08-27 00:11:21,719][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00207/00310] [00:05:16/00:02:35, 1.522s/it]
[2025-08-27 00:11:32,611][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00215/00310] [00:05:27/00:02:22, 1.516s/it]
[2025-08-27 00:11:44,754][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00223/00310] [00:05:39/00:02:10, 1.516s/it]
[2025-08-27 00:11:56,861][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00231/00310] [00:05:51/00:01:58, 1.516s/it]
[2025-08-27 00:12:09,404][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00239/00310] [00:06:04/00:01:46, 1.517s/it]
[2025-08-27 00:12:20,900][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00247/00310] [00:06:15/00:01:33, 1.515s/it]
[2025-08-27 00:12:33,154][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00255/00310] [00:06:27/00:01:21, 1.515s/it]
[2025-08-27 00:12:45,690][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00263/00310] [00:06:40/00:01:09, 1.517s/it]
[2025-08-27 00:12:57,622][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00271/00310] [00:06:52/00:00:57, 1.516s/it]
[2025-08-27 00:13:09,565][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00279/00310] [00:07:04/00:00:45, 1.515s/it]
[2025-08-27 00:13:22,286][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00287/00310] [00:07:17/00:00:33, 1.518s/it]
[2025-08-27 00:13:33,247][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00295/00310] [00:07:28/00:00:21, 1.514s/it]
[2025-08-27 00:13:44,874][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 018481] [Batch 00303/00310] [00:07:39/00:00:09, 1.512s/it]
[2025-08-27 00:13:54,256][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.43936, valid_loss=2.09565
[2025-08-27 00:13:54,257][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-27 00:13:54,257][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.788
[2025-08-27 00:13:54,257][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.026
[2025-08-27 00:13:54,257][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.027
[2025-08-27 00:13:54,257][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.004
[2025-08-27 00:13:54,277][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 04:47:08, remaining time 19:08:32, 00:47:51 per epoch
[2025-08-27 00:14:06,880][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018488] [Batch 00008/03080] [00:00:05/00:34:32, 0.675s/it]: train_loss_raw=1.4376, running_loss=1.4616, LR=0.000100
[2025-08-27 00:14:12,845][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018496] [Batch 00016/03080] [00:00:11/00:36:16, 0.710s/it]: train_loss_raw=1.4137, running_loss=1.4564, LR=0.000100
[2025-08-27 00:14:18,798][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018504] [Batch 00024/03080] [00:00:17/00:36:44, 0.722s/it]: train_loss_raw=1.3779, running_loss=1.4542, LR=0.000100
[2025-08-27 00:14:24,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018512] [Batch 00032/03080] [00:00:23/00:36:49, 0.725s/it]: train_loss_raw=1.4551, running_loss=1.4533, LR=0.000100
[2025-08-27 00:14:30,609][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018520] [Batch 00040/03080] [00:00:29/00:36:53, 0.728s/it]: train_loss_raw=1.5337, running_loss=1.4499, LR=0.000100
[2025-08-27 00:14:36,274][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018528] [Batch 00048/03080] [00:00:34/00:36:37, 0.725s/it]: train_loss_raw=1.3570, running_loss=1.4458, LR=0.000100
[2025-08-27 00:14:41,979][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018536] [Batch 00056/03080] [00:00:40/00:36:26, 0.723s/it]: train_loss_raw=1.3462, running_loss=1.4420, LR=0.000100
[2025-08-27 00:14:47,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018544] [Batch 00064/03080] [00:00:46/00:36:24, 0.724s/it]: train_loss_raw=1.4536, running_loss=1.4414, LR=0.000100
[2025-08-27 00:14:53,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018552] [Batch 00072/03080] [00:00:52/00:36:26, 0.727s/it]: train_loss_raw=1.4989, running_loss=1.4417, LR=0.000100
[2025-08-27 00:14:59,506][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018560] [Batch 00080/03080] [00:00:58/00:36:15, 0.725s/it]: train_loss_raw=1.3815, running_loss=1.4404, LR=0.000100
[2025-08-27 00:15:05,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018568] [Batch 00088/03080] [00:01:03/00:36:12, 0.726s/it]: train_loss_raw=1.3403, running_loss=1.4400, LR=0.000100
[2025-08-27 00:15:10,959][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018576] [Batch 00096/03080] [00:01:09/00:35:59, 0.724s/it]: train_loss_raw=1.3431, running_loss=1.4365, LR=0.000100
[2025-08-27 00:15:16,735][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018584] [Batch 00104/03080] [00:01:15/00:35:53, 0.724s/it]: train_loss_raw=1.3291, running_loss=1.4360, LR=0.000100
[2025-08-27 00:15:22,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018592] [Batch 00112/03080] [00:01:21/00:35:49, 0.724s/it]: train_loss_raw=1.4803, running_loss=1.4340, LR=0.000100
[2025-08-27 00:15:28,351][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018600] [Batch 00120/03080] [00:01:26/00:35:42, 0.724s/it]: train_loss_raw=1.4596, running_loss=1.4316, LR=0.000100
[2025-08-27 00:15:34,220][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018608] [Batch 00128/03080] [00:01:32/00:35:38, 0.725s/it]: train_loss_raw=1.4109, running_loss=1.4280, LR=0.000100
[2025-08-27 00:15:39,842][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018616] [Batch 00136/03080] [00:01:38/00:35:29, 0.723s/it]: train_loss_raw=1.3892, running_loss=1.4274, LR=0.000100
[2025-08-27 00:15:45,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018624] [Batch 00144/03080] [00:01:44/00:35:23, 0.723s/it]: train_loss_raw=1.3422, running_loss=1.4265, LR=0.000100
[2025-08-27 00:15:51,503][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018632] [Batch 00152/03080] [00:01:50/00:35:19, 0.724s/it]: train_loss_raw=1.3900, running_loss=1.4255, LR=0.000100
[2025-08-27 00:15:57,323][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018640] [Batch 00160/03080] [00:01:55/00:35:14, 0.724s/it]: train_loss_raw=1.3543, running_loss=1.4241, LR=0.000100
[2025-08-27 00:16:03,120][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018648] [Batch 00168/03080] [00:02:01/00:35:08, 0.724s/it]: train_loss_raw=1.4490, running_loss=1.4221, LR=0.000100
[2025-08-27 00:16:09,066][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018656] [Batch 00176/03080] [00:02:07/00:35:05, 0.725s/it]: train_loss_raw=1.3810, running_loss=1.4218, LR=0.000100
[2025-08-27 00:16:14,833][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018664] [Batch 00184/03080] [00:02:13/00:34:58, 0.725s/it]: train_loss_raw=1.3537, running_loss=1.4180, LR=0.000100
[2025-08-27 00:16:20,599][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018672] [Batch 00192/03080] [00:02:19/00:34:52, 0.725s/it]: train_loss_raw=1.4122, running_loss=1.4165, LR=0.000100
[2025-08-27 00:16:26,591][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018680] [Batch 00200/03080] [00:02:25/00:34:49, 0.726s/it]: train_loss_raw=1.3767, running_loss=1.4153, LR=0.000100
[2025-08-27 00:16:32,616][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018688] [Batch 00208/03080] [00:02:31/00:34:46, 0.727s/it]: train_loss_raw=1.5093, running_loss=1.4179, LR=0.000100
[2025-08-27 00:16:38,506][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018696] [Batch 00216/03080] [00:02:37/00:34:42, 0.727s/it]: train_loss_raw=1.3436, running_loss=1.4149, LR=0.000100
[2025-08-27 00:16:44,332][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018704] [Batch 00224/03080] [00:02:42/00:34:36, 0.727s/it]: train_loss_raw=1.3583, running_loss=1.4149, LR=0.000100
[2025-08-27 00:16:50,290][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018712] [Batch 00232/03080] [00:02:48/00:34:32, 0.728s/it]: train_loss_raw=1.4023, running_loss=1.4121, LR=0.000100
[2025-08-27 00:16:56,261][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018720] [Batch 00240/03080] [00:02:54/00:34:28, 0.728s/it]: train_loss_raw=1.3629, running_loss=1.4113, LR=0.000100
[2025-08-27 00:17:02,270][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018728] [Batch 00248/03080] [00:03:00/00:34:24, 0.729s/it]: train_loss_raw=1.3125, running_loss=1.4121, LR=0.000100
[2025-08-27 00:17:08,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018736] [Batch 00256/03080] [00:03:06/00:34:22, 0.730s/it]: train_loss_raw=1.3610, running_loss=1.4120, LR=0.000100
[2025-08-27 00:17:14,313][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018744] [Batch 00264/03080] [00:03:12/00:34:16, 0.730s/it]: train_loss_raw=1.4084, running_loss=1.4113, LR=0.000100
[2025-08-27 00:17:20,206][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018752] [Batch 00272/03080] [00:03:18/00:34:11, 0.731s/it]: train_loss_raw=1.3550, running_loss=1.4095, LR=0.000100
[2025-08-27 00:17:26,024][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018760] [Batch 00280/03080] [00:03:24/00:34:05, 0.731s/it]: train_loss_raw=1.4557, running_loss=1.4081, LR=0.000100
[2025-08-27 00:17:31,695][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018768] [Batch 00288/03080] [00:03:30/00:33:57, 0.730s/it]: train_loss_raw=1.4341, running_loss=1.4078, LR=0.000100
[2025-08-27 00:17:37,460][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018776] [Batch 00296/03080] [00:03:35/00:33:51, 0.730s/it]: train_loss_raw=1.4244, running_loss=1.4081, LR=0.000100
[2025-08-27 00:17:43,404][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018784] [Batch 00304/03080] [00:03:41/00:33:46, 0.730s/it]: train_loss_raw=1.4227, running_loss=1.4062, LR=0.000100
[2025-08-27 00:17:49,392][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018792] [Batch 00312/03080] [00:03:47/00:33:41, 0.730s/it]: train_loss_raw=1.3169, running_loss=1.4085, LR=0.000100
[2025-08-27 00:17:55,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018800] [Batch 00320/03080] [00:03:53/00:33:36, 0.731s/it]: train_loss_raw=1.3625, running_loss=1.4050, LR=0.000100
[2025-08-27 00:18:01,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018808] [Batch 00328/03080] [00:03:59/00:33:29, 0.730s/it]: train_loss_raw=1.3805, running_loss=1.4044, LR=0.000100
[2025-08-27 00:18:06,825][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018816] [Batch 00336/03080] [00:04:05/00:33:23, 0.730s/it]: train_loss_raw=1.3231, running_loss=1.4024, LR=0.000100
[2025-08-27 00:18:12,534][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018824] [Batch 00344/03080] [00:04:11/00:33:16, 0.730s/it]: train_loss_raw=1.4038, running_loss=1.3996, LR=0.000100
[2025-08-27 00:18:18,209][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018832] [Batch 00352/03080] [00:04:16/00:33:09, 0.729s/it]: train_loss_raw=1.4010, running_loss=1.4020, LR=0.000100
[2025-08-27 00:18:23,800][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018840] [Batch 00360/03080] [00:04:22/00:33:01, 0.729s/it]: train_loss_raw=1.3407, running_loss=1.4011, LR=0.000100
[2025-08-27 00:18:29,606][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018848] [Batch 00368/03080] [00:04:28/00:32:55, 0.729s/it]: train_loss_raw=1.3809, running_loss=1.4003, LR=0.000100
[2025-08-27 00:18:35,455][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018856] [Batch 00376/03080] [00:04:33/00:32:50, 0.729s/it]: train_loss_raw=1.4561, running_loss=1.4027, LR=0.000100
[2025-08-27 00:18:41,297][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018864] [Batch 00384/03080] [00:04:39/00:32:44, 0.729s/it]: train_loss_raw=1.3970, running_loss=1.4021, LR=0.000100
[2025-08-27 00:18:46,984][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018872] [Batch 00392/03080] [00:04:45/00:32:37, 0.728s/it]: train_loss_raw=1.4344, running_loss=1.3989, LR=0.000100
[2025-08-27 00:18:52,955][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018880] [Batch 00400/03080] [00:04:51/00:32:32, 0.729s/it]: train_loss_raw=1.4733, running_loss=1.4016, LR=0.000100
[2025-08-27 00:18:58,845][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018888] [Batch 00408/03080] [00:04:57/00:32:27, 0.729s/it]: train_loss_raw=1.3661, running_loss=1.4009, LR=0.000100
[2025-08-27 00:19:04,861][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018896] [Batch 00416/03080] [00:05:03/00:32:22, 0.729s/it]: train_loss_raw=1.4208, running_loss=1.4012, LR=0.000100
[2025-08-27 00:19:10,954][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018904] [Batch 00424/03080] [00:05:09/00:32:18, 0.730s/it]: train_loss_raw=1.3393, running_loss=1.4004, LR=0.000100
[2025-08-27 00:19:16,882][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018912] [Batch 00432/03080] [00:05:15/00:32:13, 0.730s/it]: train_loss_raw=1.3601, running_loss=1.4002, LR=0.000100
[2025-08-27 00:19:22,673][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018920] [Batch 00440/03080] [00:05:21/00:32:07, 0.730s/it]: train_loss_raw=1.4285, running_loss=1.4001, LR=0.000100
[2025-08-27 00:19:28,459][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018928] [Batch 00448/03080] [00:05:26/00:32:00, 0.730s/it]: train_loss_raw=1.4578, running_loss=1.3995, LR=0.000100
[2025-08-27 00:19:34,239][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018936] [Batch 00456/03080] [00:05:32/00:31:54, 0.730s/it]: train_loss_raw=1.3939, running_loss=1.4000, LR=0.000100
[2025-08-27 00:19:40,354][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018944] [Batch 00464/03080] [00:05:38/00:31:50, 0.730s/it]: train_loss_raw=1.2514, running_loss=1.3983, LR=0.000100
[2025-08-27 00:19:46,266][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018952] [Batch 00472/03080] [00:05:44/00:31:45, 0.730s/it]: train_loss_raw=1.4120, running_loss=1.3960, LR=0.000100
[2025-08-27 00:19:52,000][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018960] [Batch 00480/03080] [00:05:50/00:31:38, 0.730s/it]: train_loss_raw=1.4222, running_loss=1.3951, LR=0.000100
[2025-08-27 00:19:58,002][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018968] [Batch 00488/03080] [00:05:56/00:31:33, 0.731s/it]: train_loss_raw=1.4881, running_loss=1.3972, LR=0.000100
[2025-08-27 00:20:04,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018976] [Batch 00496/03080] [00:06:02/00:31:28, 0.731s/it]: train_loss_raw=1.4265, running_loss=1.3976, LR=0.000100
[2025-08-27 00:20:09,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018984] [Batch 00504/03080] [00:06:08/00:31:21, 0.730s/it]: train_loss_raw=1.3372, running_loss=1.3967, LR=0.000100
[2025-08-27 00:20:15,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 018992] [Batch 00512/03080] [00:06:13/00:31:15, 0.730s/it]: train_loss_raw=1.3037, running_loss=1.3955, LR=0.000100
[2025-08-27 00:20:21,301][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019000] [Batch 00520/03080] [00:06:19/00:31:09, 0.730s/it]: train_loss_raw=1.3422, running_loss=1.3941, LR=0.000100
[2025-08-27 00:20:27,151][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019008] [Batch 00528/03080] [00:06:25/00:31:04, 0.730s/it]: train_loss_raw=1.3574, running_loss=1.3940, LR=0.000100
[2025-08-27 00:20:33,156][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019016] [Batch 00536/03080] [00:06:31/00:30:58, 0.731s/it]: train_loss_raw=1.3338, running_loss=1.3961, LR=0.000100
[2025-08-27 00:20:38,974][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019024] [Batch 00544/03080] [00:06:37/00:30:53, 0.731s/it]: train_loss_raw=1.3622, running_loss=1.3960, LR=0.000100
[2025-08-27 00:20:44,938][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019032] [Batch 00552/03080] [00:06:43/00:30:47, 0.731s/it]: train_loss_raw=1.4316, running_loss=1.4005, LR=0.000100
[2025-08-27 00:20:50,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019040] [Batch 00560/03080] [00:06:49/00:30:42, 0.731s/it]: train_loss_raw=1.3233, running_loss=1.4003, LR=0.000100
[2025-08-27 00:20:56,850][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019048] [Batch 00568/03080] [00:06:55/00:30:36, 0.731s/it]: train_loss_raw=1.5057, running_loss=1.4042, LR=0.000100
[2025-08-27 00:21:03,064][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019056] [Batch 00576/03080] [00:07:01/00:30:32, 0.732s/it]: train_loss_raw=1.4254, running_loss=1.4043, LR=0.000100
[2025-08-27 00:21:09,168][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019064] [Batch 00584/03080] [00:07:07/00:30:27, 0.732s/it]: train_loss_raw=1.4269, running_loss=1.4044, LR=0.000100
[2025-08-27 00:21:15,283][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019072] [Batch 00592/03080] [00:07:13/00:30:23, 0.733s/it]: train_loss_raw=1.4310, running_loss=1.4040, LR=0.000100
[2025-08-27 00:21:21,415][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019080] [Batch 00600/03080] [00:07:19/00:30:18, 0.733s/it]: train_loss_raw=1.3919, running_loss=1.4012, LR=0.000100
[2025-08-27 00:21:27,155][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019088] [Batch 00608/03080] [00:07:25/00:30:12, 0.733s/it]: train_loss_raw=1.4386, running_loss=1.4017, LR=0.000100
[2025-08-27 00:21:32,988][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019096] [Batch 00616/03080] [00:07:31/00:30:06, 0.733s/it]: train_loss_raw=1.4151, running_loss=1.4017, LR=0.000100
[2025-08-27 00:21:38,889][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019104] [Batch 00624/03080] [00:07:37/00:30:00, 0.733s/it]: train_loss_raw=1.3181, running_loss=1.4005, LR=0.000100
[2025-08-27 00:21:44,668][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019112] [Batch 00632/03080] [00:07:43/00:29:54, 0.733s/it]: train_loss_raw=1.4320, running_loss=1.4022, LR=0.000100
[2025-08-27 00:21:50,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019120] [Batch 00640/03080] [00:07:49/00:29:49, 0.733s/it]: train_loss_raw=1.3766, running_loss=1.4025, LR=0.000100
[2025-08-27 00:21:56,756][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019128] [Batch 00648/03080] [00:07:55/00:29:43, 0.733s/it]: train_loss_raw=1.3484, running_loss=1.3991, LR=0.000100
[2025-08-27 00:22:02,794][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019136] [Batch 00656/03080] [00:08:01/00:29:38, 0.734s/it]: train_loss_raw=1.4686, running_loss=1.3997, LR=0.000100
[2025-08-27 00:22:08,765][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019144] [Batch 00664/03080] [00:08:07/00:29:33, 0.734s/it]: train_loss_raw=1.4659, running_loss=1.4004, LR=0.000100
[2025-08-27 00:22:14,712][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019152] [Batch 00672/03080] [00:08:13/00:29:27, 0.734s/it]: train_loss_raw=1.4248, running_loss=1.4004, LR=0.000100
[2025-08-27 00:22:20,698][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019160] [Batch 00680/03080] [00:08:19/00:29:21, 0.734s/it]: train_loss_raw=1.4223, running_loss=1.3999, LR=0.000100
[2025-08-27 00:22:26,600][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019168] [Batch 00688/03080] [00:08:25/00:29:16, 0.734s/it]: train_loss_raw=1.4798, running_loss=1.3995, LR=0.000100
[2025-08-27 00:22:32,258][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019176] [Batch 00696/03080] [00:08:30/00:29:09, 0.734s/it]: train_loss_raw=1.4802, running_loss=1.3996, LR=0.000100
[2025-08-27 00:22:37,993][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019184] [Batch 00704/03080] [00:08:36/00:29:03, 0.734s/it]: train_loss_raw=1.3763, running_loss=1.4020, LR=0.000100
[2025-08-27 00:22:43,748][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019192] [Batch 00712/03080] [00:08:42/00:28:56, 0.734s/it]: train_loss_raw=1.3267, running_loss=1.4004, LR=0.000100
[2025-08-27 00:22:49,471][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019200] [Batch 00720/03080] [00:08:47/00:28:50, 0.733s/it]: train_loss_raw=1.3452, running_loss=1.3974, LR=0.000100
[2025-08-27 00:22:55,506][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019208] [Batch 00728/03080] [00:08:54/00:28:45, 0.734s/it]: train_loss_raw=1.3153, running_loss=1.3963, LR=0.000100
[2025-08-27 00:23:01,580][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019216] [Batch 00736/03080] [00:09:00/00:28:40, 0.734s/it]: train_loss_raw=1.4054, running_loss=1.3995, LR=0.000100
[2025-08-27 00:23:07,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019224] [Batch 00744/03080] [00:09:06/00:28:34, 0.734s/it]: train_loss_raw=1.4328, running_loss=1.4021, LR=0.000100
[2025-08-27 00:23:13,479][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019232] [Batch 00752/03080] [00:09:11/00:28:28, 0.734s/it]: train_loss_raw=1.3139, running_loss=1.4017, LR=0.000100
[2025-08-27 00:23:19,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019240] [Batch 00760/03080] [00:09:17/00:28:23, 0.734s/it]: train_loss_raw=1.4302, running_loss=1.4021, LR=0.000100
[2025-08-27 00:23:25,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019248] [Batch 00768/03080] [00:09:23/00:28:17, 0.734s/it]: train_loss_raw=1.4188, running_loss=1.4011, LR=0.000100
[2025-08-27 00:23:31,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019256] [Batch 00776/03080] [00:09:29/00:28:11, 0.734s/it]: train_loss_raw=1.3742, running_loss=1.4034, LR=0.000100
[2025-08-27 00:23:36,720][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019264] [Batch 00784/03080] [00:09:35/00:28:04, 0.734s/it]: train_loss_raw=1.3829, running_loss=1.4032, LR=0.000100
[2025-08-27 00:23:42,707][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019272] [Batch 00792/03080] [00:09:41/00:27:59, 0.734s/it]: train_loss_raw=1.4221, running_loss=1.4035, LR=0.000100
[2025-08-27 00:23:48,803][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019280] [Batch 00800/03080] [00:09:47/00:27:53, 0.734s/it]: train_loss_raw=1.5245, running_loss=1.4030, LR=0.000100
[2025-08-27 00:23:54,683][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019288] [Batch 00808/03080] [00:09:53/00:27:48, 0.734s/it]: train_loss_raw=1.3841, running_loss=1.4035, LR=0.000100
[2025-08-27 00:24:00,330][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019296] [Batch 00816/03080] [00:09:58/00:27:41, 0.734s/it]: train_loss_raw=1.3424, running_loss=1.4038, LR=0.000100
[2025-08-27 00:24:06,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019304] [Batch 00824/03080] [00:10:04/00:27:35, 0.734s/it]: train_loss_raw=1.3768, running_loss=1.4052, LR=0.000100
[2025-08-27 00:24:12,267][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019312] [Batch 00832/03080] [00:10:10/00:27:30, 0.734s/it]: train_loss_raw=1.4223, running_loss=1.4024, LR=0.000100
[2025-08-27 00:24:18,142][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019320] [Batch 00840/03080] [00:10:16/00:27:24, 0.734s/it]: train_loss_raw=1.3279, running_loss=1.3992, LR=0.000100
[2025-08-27 00:24:23,870][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019328] [Batch 00848/03080] [00:10:22/00:27:18, 0.734s/it]: train_loss_raw=1.3462, running_loss=1.3975, LR=0.000100
[2025-08-27 00:24:29,663][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019336] [Batch 00856/03080] [00:10:28/00:27:12, 0.734s/it]: train_loss_raw=1.4177, running_loss=1.3954, LR=0.000100
[2025-08-27 00:24:35,568][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019344] [Batch 00864/03080] [00:10:34/00:27:06, 0.734s/it]: train_loss_raw=1.3222, running_loss=1.3955, LR=0.000100
[2025-08-27 00:24:41,465][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019352] [Batch 00872/03080] [00:10:39/00:27:00, 0.734s/it]: train_loss_raw=1.3904, running_loss=1.3951, LR=0.000100
[2025-08-27 00:24:47,304][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019360] [Batch 00880/03080] [00:10:45/00:26:54, 0.734s/it]: train_loss_raw=1.3901, running_loss=1.3934, LR=0.000100
[2025-08-27 00:24:53,179][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019368] [Batch 00888/03080] [00:10:51/00:26:48, 0.734s/it]: train_loss_raw=1.4412, running_loss=1.3915, LR=0.000100
[2025-08-27 00:24:58,990][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019376] [Batch 00896/03080] [00:10:57/00:26:42, 0.734s/it]: train_loss_raw=1.4387, running_loss=1.3921, LR=0.000100
[2025-08-27 00:25:04,971][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019384] [Batch 00904/03080] [00:11:03/00:26:37, 0.734s/it]: train_loss_raw=1.2136, running_loss=1.3920, LR=0.000100
[2025-08-27 00:25:10,786][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019392] [Batch 00912/03080] [00:11:09/00:26:31, 0.734s/it]: train_loss_raw=1.4145, running_loss=1.3899, LR=0.000100
[2025-08-27 00:25:16,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019400] [Batch 00920/03080] [00:11:15/00:26:25, 0.734s/it]: train_loss_raw=1.4003, running_loss=1.3924, LR=0.000100
[2025-08-27 00:25:22,501][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019408] [Batch 00928/03080] [00:11:21/00:26:19, 0.734s/it]: train_loss_raw=1.4182, running_loss=1.3943, LR=0.000100
[2025-08-27 00:25:28,259][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019416] [Batch 00936/03080] [00:11:26/00:26:13, 0.734s/it]: train_loss_raw=1.3321, running_loss=1.3956, LR=0.000100
[2025-08-27 00:25:33,961][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019424] [Batch 00944/03080] [00:11:32/00:26:06, 0.734s/it]: train_loss_raw=1.3197, running_loss=1.3956, LR=0.000100
[2025-08-27 00:25:39,581][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019432] [Batch 00952/03080] [00:11:38/00:26:00, 0.733s/it]: train_loss_raw=1.3344, running_loss=1.3936, LR=0.000100
[2025-08-27 00:25:45,209][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019440] [Batch 00960/03080] [00:11:43/00:25:54, 0.733s/it]: train_loss_raw=1.3453, running_loss=1.3940, LR=0.000100
[2025-08-27 00:25:51,262][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019448] [Batch 00968/03080] [00:11:49/00:25:48, 0.733s/it]: train_loss_raw=1.4800, running_loss=1.3954, LR=0.000100
[2025-08-27 00:25:57,181][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019456] [Batch 00976/03080] [00:11:55/00:25:42, 0.733s/it]: train_loss_raw=1.3501, running_loss=1.3952, LR=0.000100
[2025-08-27 00:26:03,066][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019464] [Batch 00984/03080] [00:12:01/00:25:37, 0.733s/it]: train_loss_raw=1.3301, running_loss=1.3946, LR=0.000100
[2025-08-27 00:26:08,995][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019472] [Batch 00992/03080] [00:12:07/00:25:31, 0.733s/it]: train_loss_raw=1.4070, running_loss=1.3952, LR=0.000100
[2025-08-27 00:26:14,827][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019480] [Batch 01000/03080] [00:12:13/00:25:25, 0.733s/it]: train_loss_raw=1.3848, running_loss=1.3946, LR=0.000100
[2025-08-27 00:26:20,827][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019488] [Batch 01008/03080] [00:12:19/00:25:19, 0.733s/it]: train_loss_raw=1.3092, running_loss=1.3907, LR=0.000100
[2025-08-27 00:26:26,450][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019496] [Batch 01016/03080] [00:12:24/00:25:13, 0.733s/it]: train_loss_raw=1.4700, running_loss=1.3937, LR=0.000100
[2025-08-27 00:26:32,207][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019504] [Batch 01024/03080] [00:12:30/00:25:07, 0.733s/it]: train_loss_raw=1.3755, running_loss=1.3936, LR=0.000100
[2025-08-27 00:26:38,160][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019512] [Batch 01032/03080] [00:12:36/00:25:01, 0.733s/it]: train_loss_raw=1.3084, running_loss=1.3913, LR=0.000100
[2025-08-27 00:26:44,175][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019520] [Batch 01040/03080] [00:12:42/00:24:56, 0.733s/it]: train_loss_raw=1.3865, running_loss=1.3924, LR=0.000100
[2025-08-27 00:26:50,093][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019528] [Batch 01048/03080] [00:12:48/00:24:50, 0.733s/it]: train_loss_raw=1.3785, running_loss=1.3929, LR=0.000100
[2025-08-27 00:26:56,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019536] [Batch 01056/03080] [00:12:54/00:24:44, 0.733s/it]: train_loss_raw=1.4622, running_loss=1.3940, LR=0.000100
[2025-08-27 00:27:01,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019544] [Batch 01064/03080] [00:13:00/00:24:38, 0.733s/it]: train_loss_raw=1.4394, running_loss=1.3936, LR=0.000100
[2025-08-27 00:27:07,947][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019552] [Batch 01072/03080] [00:13:06/00:24:33, 0.734s/it]: train_loss_raw=1.3014, running_loss=1.3916, LR=0.000100
[2025-08-27 00:27:13,909][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019560] [Batch 01080/03080] [00:13:12/00:24:27, 0.734s/it]: train_loss_raw=1.5445, running_loss=1.3903, LR=0.000100
[2025-08-27 00:27:20,000][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019568] [Batch 01088/03080] [00:13:18/00:24:21, 0.734s/it]: train_loss_raw=1.3656, running_loss=1.3903, LR=0.000100
[2025-08-27 00:27:25,701][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019576] [Batch 01096/03080] [00:13:24/00:24:15, 0.734s/it]: train_loss_raw=1.3394, running_loss=1.3930, LR=0.000100
[2025-08-27 00:27:31,977][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019584] [Batch 01104/03080] [00:13:30/00:24:10, 0.734s/it]: train_loss_raw=1.3428, running_loss=1.3921, LR=0.000100
[2025-08-27 00:27:38,125][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019592] [Batch 01112/03080] [00:13:36/00:24:05, 0.734s/it]: train_loss_raw=1.5012, running_loss=1.3920, LR=0.000100
[2025-08-27 00:27:43,822][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019600] [Batch 01120/03080] [00:13:42/00:23:59, 0.734s/it]: train_loss_raw=1.2567, running_loss=1.3896, LR=0.000100
[2025-08-27 00:27:49,478][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019608] [Batch 01128/03080] [00:13:47/00:23:52, 0.734s/it]: train_loss_raw=1.4534, running_loss=1.3896, LR=0.000100
[2025-08-27 00:27:55,298][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019616] [Batch 01136/03080] [00:13:53/00:23:46, 0.734s/it]: train_loss_raw=1.3655, running_loss=1.3912, LR=0.000100
[2025-08-27 00:28:01,011][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019624] [Batch 01144/03080] [00:13:59/00:23:40, 0.734s/it]: train_loss_raw=1.3297, running_loss=1.3920, LR=0.000100
[2025-08-27 00:28:07,078][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019632] [Batch 01152/03080] [00:14:05/00:23:35, 0.734s/it]: train_loss_raw=1.3341, running_loss=1.3893, LR=0.000100
[2025-08-27 00:28:12,779][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019640] [Batch 01160/03080] [00:14:11/00:23:29, 0.734s/it]: train_loss_raw=1.4326, running_loss=1.3902, LR=0.000100
[2025-08-27 00:28:18,571][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019648] [Batch 01168/03080] [00:14:17/00:23:23, 0.734s/it]: train_loss_raw=1.3309, running_loss=1.3890, LR=0.000100
[2025-08-27 00:28:24,623][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019656] [Batch 01176/03080] [00:14:23/00:23:17, 0.734s/it]: train_loss_raw=1.3728, running_loss=1.3894, LR=0.000100
[2025-08-27 00:28:30,809][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019664] [Batch 01184/03080] [00:14:29/00:23:12, 0.734s/it]: train_loss_raw=1.3776, running_loss=1.3916, LR=0.000100
[2025-08-27 00:28:36,847][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019672] [Batch 01192/03080] [00:14:35/00:23:06, 0.734s/it]: train_loss_raw=1.3649, running_loss=1.3931, LR=0.000100
[2025-08-27 00:28:42,736][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019680] [Batch 01200/03080] [00:14:41/00:23:00, 0.734s/it]: train_loss_raw=1.3940, running_loss=1.3897, LR=0.000100
[2025-08-27 00:28:48,971][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019688] [Batch 01208/03080] [00:14:47/00:22:55, 0.735s/it]: train_loss_raw=1.5448, running_loss=1.3915, LR=0.000100
[2025-08-27 00:28:54,745][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019696] [Batch 01216/03080] [00:14:53/00:22:49, 0.735s/it]: train_loss_raw=1.3712, running_loss=1.3904, LR=0.000100
[2025-08-27 00:29:00,849][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019704] [Batch 01224/03080] [00:14:59/00:22:43, 0.735s/it]: train_loss_raw=1.4134, running_loss=1.3927, LR=0.000100
[2025-08-27 00:29:06,867][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019712] [Batch 01232/03080] [00:15:05/00:22:38, 0.735s/it]: train_loss_raw=1.3119, running_loss=1.3895, LR=0.000100
[2025-08-27 00:29:12,753][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019720] [Batch 01240/03080] [00:15:11/00:22:32, 0.735s/it]: train_loss_raw=1.4554, running_loss=1.3893, LR=0.000100
[2025-08-27 00:29:18,642][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019728] [Batch 01248/03080] [00:15:17/00:22:26, 0.735s/it]: train_loss_raw=1.3872, running_loss=1.3879, LR=0.000100
[2025-08-27 00:29:24,361][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019736] [Batch 01256/03080] [00:15:22/00:22:20, 0.735s/it]: train_loss_raw=1.3995, running_loss=1.3882, LR=0.000100
[2025-08-27 00:29:30,220][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019744] [Batch 01264/03080] [00:15:28/00:22:14, 0.735s/it]: train_loss_raw=1.3681, running_loss=1.3872, LR=0.000100
[2025-08-27 00:29:36,066][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019752] [Batch 01272/03080] [00:15:34/00:22:08, 0.735s/it]: train_loss_raw=1.4118, running_loss=1.3884, LR=0.000100
[2025-08-27 00:29:41,852][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019760] [Batch 01280/03080] [00:15:40/00:22:02, 0.735s/it]: train_loss_raw=1.2937, running_loss=1.3884, LR=0.000100
[2025-08-27 00:29:47,665][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019768] [Batch 01288/03080] [00:15:46/00:21:56, 0.735s/it]: train_loss_raw=1.2770, running_loss=1.3872, LR=0.000100
[2025-08-27 00:29:53,528][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019776] [Batch 01296/03080] [00:15:52/00:21:50, 0.735s/it]: train_loss_raw=1.2573, running_loss=1.3849, LR=0.000100
[2025-08-27 00:29:59,458][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019784] [Batch 01304/03080] [00:15:57/00:21:44, 0.735s/it]: train_loss_raw=1.4894, running_loss=1.3859, LR=0.000100
[2025-08-27 00:30:05,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019792] [Batch 01312/03080] [00:16:03/00:21:38, 0.735s/it]: train_loss_raw=1.4043, running_loss=1.3833, LR=0.000100
[2025-08-27 00:30:10,956][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019800] [Batch 01320/03080] [00:16:09/00:21:32, 0.734s/it]: train_loss_raw=1.4123, running_loss=1.3852, LR=0.000100
[2025-08-27 00:30:16,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019808] [Batch 01328/03080] [00:16:15/00:21:26, 0.734s/it]: train_loss_raw=1.2388, running_loss=1.3853, LR=0.000100
[2025-08-27 00:30:22,542][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019816] [Batch 01336/03080] [00:16:21/00:21:20, 0.734s/it]: train_loss_raw=1.3561, running_loss=1.3852, LR=0.000100
[2025-08-27 00:30:28,293][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019824] [Batch 01344/03080] [00:16:26/00:21:14, 0.734s/it]: train_loss_raw=1.4864, running_loss=1.3858, LR=0.000100
[2025-08-27 00:30:34,376][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019832] [Batch 01352/03080] [00:16:32/00:21:09, 0.734s/it]: train_loss_raw=1.4079, running_loss=1.3875, LR=0.000100
[2025-08-27 00:30:40,258][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019840] [Batch 01360/03080] [00:16:38/00:21:03, 0.734s/it]: train_loss_raw=1.3712, running_loss=1.3880, LR=0.000100
[2025-08-27 00:30:45,980][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019848] [Batch 01368/03080] [00:16:44/00:20:57, 0.734s/it]: train_loss_raw=1.3649, running_loss=1.3863, LR=0.000100
[2025-08-27 00:30:51,897][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019856] [Batch 01376/03080] [00:16:50/00:20:51, 0.734s/it]: train_loss_raw=1.3677, running_loss=1.3848, LR=0.000100
[2025-08-27 00:30:57,940][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019864] [Batch 01384/03080] [00:16:56/00:20:45, 0.734s/it]: train_loss_raw=1.3280, running_loss=1.3870, LR=0.000100
[2025-08-27 00:31:03,703][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019872] [Batch 01392/03080] [00:17:02/00:20:39, 0.734s/it]: train_loss_raw=1.3677, running_loss=1.3851, LR=0.000100
[2025-08-27 00:31:09,486][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019880] [Batch 01400/03080] [00:17:08/00:20:33, 0.734s/it]: train_loss_raw=1.4703, running_loss=1.3842, LR=0.000100
[2025-08-27 00:31:15,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019888] [Batch 01408/03080] [00:17:13/00:20:27, 0.734s/it]: train_loss_raw=1.2925, running_loss=1.3821, LR=0.000100
[2025-08-27 00:31:21,056][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019896] [Batch 01416/03080] [00:17:19/00:20:21, 0.734s/it]: train_loss_raw=1.4416, running_loss=1.3831, LR=0.000100
[2025-08-27 00:31:26,825][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019904] [Batch 01424/03080] [00:17:25/00:20:15, 0.734s/it]: train_loss_raw=1.3317, running_loss=1.3835, LR=0.000100
[2025-08-27 00:31:32,712][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019912] [Batch 01432/03080] [00:17:31/00:20:09, 0.734s/it]: train_loss_raw=1.3597, running_loss=1.3812, LR=0.000100
[2025-08-27 00:31:38,603][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019920] [Batch 01440/03080] [00:17:37/00:20:03, 0.734s/it]: train_loss_raw=1.3199, running_loss=1.3817, LR=0.000100
[2025-08-27 00:31:44,559][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019928] [Batch 01448/03080] [00:17:43/00:19:58, 0.734s/it]: train_loss_raw=1.3842, running_loss=1.3852, LR=0.000100
[2025-08-27 00:31:50,423][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019936] [Batch 01456/03080] [00:17:48/00:19:52, 0.734s/it]: train_loss_raw=1.3645, running_loss=1.3848, LR=0.000100
[2025-08-27 00:31:56,380][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019944] [Batch 01464/03080] [00:17:54/00:19:46, 0.734s/it]: train_loss_raw=1.4027, running_loss=1.3840, LR=0.000100
[2025-08-27 00:32:02,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019952] [Batch 01472/03080] [00:18:00/00:19:40, 0.734s/it]: train_loss_raw=1.3715, running_loss=1.3810, LR=0.000100
[2025-08-27 00:32:08,372][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019960] [Batch 01480/03080] [00:18:06/00:19:35, 0.734s/it]: train_loss_raw=1.3724, running_loss=1.3818, LR=0.000100
[2025-08-27 00:32:14,583][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019968] [Batch 01488/03080] [00:18:13/00:19:29, 0.735s/it]: train_loss_raw=1.3103, running_loss=1.3821, LR=0.000100
[2025-08-27 00:32:20,840][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019976] [Batch 01496/03080] [00:18:19/00:19:24, 0.735s/it]: train_loss_raw=1.3564, running_loss=1.3826, LR=0.000100
[2025-08-27 00:32:27,039][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019984] [Batch 01504/03080] [00:18:25/00:19:18, 0.735s/it]: train_loss_raw=1.3531, running_loss=1.3840, LR=0.000100
[2025-08-27 00:32:32,969][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 019992] [Batch 01512/03080] [00:18:31/00:19:12, 0.735s/it]: train_loss_raw=1.3276, running_loss=1.3826, LR=0.000100
[2025-08-27 00:32:39,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020000] [Batch 01520/03080] [00:18:37/00:19:06, 0.735s/it]: train_loss_raw=1.3743, running_loss=1.3813, LR=0.000100
[2025-08-27 00:32:48,674][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020008] [Batch 01528/03080] [00:18:47/00:19:04, 0.738s/it]: train_loss_raw=1.4950, running_loss=1.3818, LR=0.000100
[2025-08-27 00:32:54,479][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020016] [Batch 01536/03080] [00:18:52/00:18:58, 0.738s/it]: train_loss_raw=1.4203, running_loss=1.3800, LR=0.000100
[2025-08-27 00:33:00,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020024] [Batch 01544/03080] [00:18:58/00:18:52, 0.738s/it]: train_loss_raw=1.2371, running_loss=1.3774, LR=0.000100
[2025-08-27 00:33:06,170][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020032] [Batch 01552/03080] [00:19:04/00:18:46, 0.738s/it]: train_loss_raw=1.3961, running_loss=1.3764, LR=0.000100
[2025-08-27 00:33:12,413][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020040] [Batch 01560/03080] [00:19:10/00:18:41, 0.738s/it]: train_loss_raw=1.1703, running_loss=1.3721, LR=0.000100
[2025-08-27 00:33:18,531][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020048] [Batch 01568/03080] [00:19:17/00:18:35, 0.738s/it]: train_loss_raw=1.2303, running_loss=1.3681, LR=0.000100
[2025-08-27 00:33:24,621][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020056] [Batch 01576/03080] [00:19:23/00:18:30, 0.738s/it]: train_loss_raw=1.3664, running_loss=1.3691, LR=0.000100
[2025-08-27 00:33:30,761][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020064] [Batch 01584/03080] [00:19:29/00:18:24, 0.738s/it]: train_loss_raw=1.3011, running_loss=1.3711, LR=0.000100
[2025-08-27 00:33:36,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020072] [Batch 01592/03080] [00:19:35/00:18:18, 0.738s/it]: train_loss_raw=1.4444, running_loss=1.3723, LR=0.000100
[2025-08-27 00:33:42,339][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020080] [Batch 01600/03080] [00:19:40/00:18:12, 0.738s/it]: train_loss_raw=1.3424, running_loss=1.3731, LR=0.000100
[2025-08-27 00:33:48,083][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020088] [Batch 01608/03080] [00:19:46/00:18:06, 0.738s/it]: train_loss_raw=1.3525, running_loss=1.3732, LR=0.000100
[2025-08-27 00:33:53,813][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020096] [Batch 01616/03080] [00:19:52/00:18:00, 0.738s/it]: train_loss_raw=1.4265, running_loss=1.3732, LR=0.000100
[2025-08-27 00:33:59,523][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020104] [Batch 01624/03080] [00:19:58/00:17:54, 0.738s/it]: train_loss_raw=1.3371, running_loss=1.3717, LR=0.000100
[2025-08-27 00:34:05,352][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020112] [Batch 01632/03080] [00:20:03/00:17:48, 0.738s/it]: train_loss_raw=1.5191, running_loss=1.3742, LR=0.000100
[2025-08-27 00:34:11,227][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020120] [Batch 01640/03080] [00:20:09/00:17:42, 0.738s/it]: train_loss_raw=1.3897, running_loss=1.3716, LR=0.000100
[2025-08-27 00:34:17,082][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020128] [Batch 01648/03080] [00:20:15/00:17:36, 0.738s/it]: train_loss_raw=1.3730, running_loss=1.3710, LR=0.000100
[2025-08-27 00:34:22,975][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020136] [Batch 01656/03080] [00:20:21/00:17:30, 0.738s/it]: train_loss_raw=1.4059, running_loss=1.3733, LR=0.000100
[2025-08-27 00:34:28,946][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020144] [Batch 01664/03080] [00:20:27/00:17:24, 0.738s/it]: train_loss_raw=1.4052, running_loss=1.3737, LR=0.000100
[2025-08-27 00:34:34,840][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020152] [Batch 01672/03080] [00:20:33/00:17:18, 0.738s/it]: train_loss_raw=1.5003, running_loss=1.3753, LR=0.000100
[2025-08-27 00:34:40,586][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020160] [Batch 01680/03080] [00:20:39/00:17:12, 0.738s/it]: train_loss_raw=1.2397, running_loss=1.3727, LR=0.000100
[2025-08-27 00:34:46,358][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020168] [Batch 01688/03080] [00:20:44/00:17:06, 0.737s/it]: train_loss_raw=1.3337, running_loss=1.3702, LR=0.000100
[2025-08-27 00:34:52,337][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020176] [Batch 01696/03080] [00:20:50/00:17:00, 0.738s/it]: train_loss_raw=1.3542, running_loss=1.3706, LR=0.000100
[2025-08-27 00:34:58,116][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020184] [Batch 01704/03080] [00:20:56/00:16:54, 0.737s/it]: train_loss_raw=1.4016, running_loss=1.3668, LR=0.000100
[2025-08-27 00:35:04,220][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020192] [Batch 01712/03080] [00:21:02/00:16:49, 0.738s/it]: train_loss_raw=1.4329, running_loss=1.3671, LR=0.000100
[2025-08-27 00:35:10,130][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020200] [Batch 01720/03080] [00:21:08/00:16:43, 0.738s/it]: train_loss_raw=1.3332, running_loss=1.3659, LR=0.000100
[2025-08-27 00:35:16,018][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020208] [Batch 01728/03080] [00:21:14/00:16:37, 0.738s/it]: train_loss_raw=1.3736, running_loss=1.3662, LR=0.000100
[2025-08-27 00:35:21,924][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020216] [Batch 01736/03080] [00:21:20/00:16:31, 0.738s/it]: train_loss_raw=1.2777, running_loss=1.3631, LR=0.000100
[2025-08-27 00:35:27,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020224] [Batch 01744/03080] [00:21:26/00:16:25, 0.738s/it]: train_loss_raw=1.4674, running_loss=1.3625, LR=0.000100
[2025-08-27 00:35:33,823][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020232] [Batch 01752/03080] [00:21:32/00:16:19, 0.738s/it]: train_loss_raw=1.3857, running_loss=1.3651, LR=0.000100
[2025-08-27 00:35:39,579][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020240] [Batch 01760/03080] [00:21:38/00:16:13, 0.738s/it]: train_loss_raw=1.4397, running_loss=1.3655, LR=0.000100
[2025-08-27 00:35:45,385][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020248] [Batch 01768/03080] [00:21:43/00:16:07, 0.738s/it]: train_loss_raw=1.4118, running_loss=1.3667, LR=0.000100
[2025-08-27 00:35:51,247][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020256] [Batch 01776/03080] [00:21:49/00:16:01, 0.737s/it]: train_loss_raw=1.4849, running_loss=1.3673, LR=0.000100
[2025-08-27 00:35:57,184][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020264] [Batch 01784/03080] [00:21:55/00:15:55, 0.738s/it]: train_loss_raw=1.2360, running_loss=1.3670, LR=0.000100
[2025-08-27 00:36:03,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020272] [Batch 01792/03080] [00:22:01/00:15:49, 0.738s/it]: train_loss_raw=1.2638, running_loss=1.3651, LR=0.000100
[2025-08-27 00:36:09,140][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020280] [Batch 01800/03080] [00:22:07/00:15:44, 0.738s/it]: train_loss_raw=1.2922, running_loss=1.3640, LR=0.000100
[2025-08-27 00:36:15,143][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020288] [Batch 01808/03080] [00:22:13/00:15:38, 0.738s/it]: train_loss_raw=1.3846, running_loss=1.3661, LR=0.000100
[2025-08-27 00:36:20,926][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020296] [Batch 01816/03080] [00:22:19/00:15:32, 0.738s/it]: train_loss_raw=1.2748, running_loss=1.3653, LR=0.000100
[2025-08-27 00:36:26,840][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020304] [Batch 01824/03080] [00:22:25/00:15:26, 0.738s/it]: train_loss_raw=1.2747, running_loss=1.3660, LR=0.000100
[2025-08-27 00:36:32,846][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020312] [Batch 01832/03080] [00:22:31/00:15:20, 0.738s/it]: train_loss_raw=1.3933, running_loss=1.3646, LR=0.000100
[2025-08-27 00:36:38,730][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020320] [Batch 01840/03080] [00:22:37/00:15:14, 0.738s/it]: train_loss_raw=1.4337, running_loss=1.3672, LR=0.000100
[2025-08-27 00:36:44,536][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020328] [Batch 01848/03080] [00:22:43/00:15:08, 0.738s/it]: train_loss_raw=1.3288, running_loss=1.3658, LR=0.000100
[2025-08-27 00:36:50,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020336] [Batch 01856/03080] [00:22:49/00:15:02, 0.738s/it]: train_loss_raw=1.3855, running_loss=1.3644, LR=0.000100
[2025-08-27 00:36:56,371][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020344] [Batch 01864/03080] [00:22:54/00:14:56, 0.738s/it]: train_loss_raw=1.3920, running_loss=1.3652, LR=0.000100
[2025-08-27 00:37:02,097][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020352] [Batch 01872/03080] [00:23:00/00:14:50, 0.738s/it]: train_loss_raw=1.3358, running_loss=1.3639, LR=0.000100
[2025-08-27 00:37:07,854][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020360] [Batch 01880/03080] [00:23:06/00:14:44, 0.737s/it]: train_loss_raw=1.3507, running_loss=1.3631, LR=0.000100
[2025-08-27 00:37:13,546][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020368] [Batch 01888/03080] [00:23:12/00:14:38, 0.737s/it]: train_loss_raw=1.4043, running_loss=1.3615, LR=0.000100
[2025-08-27 00:37:19,272][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020376] [Batch 01896/03080] [00:23:17/00:14:32, 0.737s/it]: train_loss_raw=1.4424, running_loss=1.3635, LR=0.000100
[2025-08-27 00:37:25,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020384] [Batch 01904/03080] [00:23:23/00:14:26, 0.737s/it]: train_loss_raw=1.4016, running_loss=1.3642, LR=0.000100
[2025-08-27 00:37:30,913][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020392] [Batch 01912/03080] [00:23:29/00:14:20, 0.737s/it]: train_loss_raw=1.3871, running_loss=1.3652, LR=0.000100
[2025-08-27 00:37:36,884][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020400] [Batch 01920/03080] [00:23:35/00:14:15, 0.737s/it]: train_loss_raw=1.2225, running_loss=1.3628, LR=0.000100
[2025-08-27 00:37:42,779][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020408] [Batch 01928/03080] [00:23:41/00:14:09, 0.737s/it]: train_loss_raw=1.3528, running_loss=1.3624, LR=0.000100
[2025-08-27 00:37:48,638][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020416] [Batch 01936/03080] [00:23:47/00:14:03, 0.737s/it]: train_loss_raw=1.3719, running_loss=1.3639, LR=0.000100
[2025-08-27 00:37:54,420][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020424] [Batch 01944/03080] [00:23:52/00:13:57, 0.737s/it]: train_loss_raw=1.3560, running_loss=1.3631, LR=0.000100
[2025-08-27 00:38:00,213][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020432] [Batch 01952/03080] [00:23:58/00:13:51, 0.737s/it]: train_loss_raw=1.3883, running_loss=1.3638, LR=0.000100
[2025-08-27 00:38:05,998][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020440] [Batch 01960/03080] [00:24:04/00:13:45, 0.737s/it]: train_loss_raw=1.3690, running_loss=1.3634, LR=0.000100
[2025-08-27 00:38:11,753][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020448] [Batch 01968/03080] [00:24:10/00:13:39, 0.737s/it]: train_loss_raw=1.3271, running_loss=1.3624, LR=0.000100
[2025-08-27 00:38:17,428][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020456] [Batch 01976/03080] [00:24:15/00:13:33, 0.737s/it]: train_loss_raw=1.4067, running_loss=1.3620, LR=0.000100
[2025-08-27 00:38:22,915][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020464] [Batch 01984/03080] [00:24:21/00:13:27, 0.737s/it]: train_loss_raw=1.2994, running_loss=1.3611, LR=0.000100
[2025-08-27 00:38:28,578][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020472] [Batch 01992/03080] [00:24:27/00:13:21, 0.736s/it]: train_loss_raw=1.3813, running_loss=1.3601, LR=0.000100
[2025-08-27 00:38:34,253][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020480] [Batch 02000/03080] [00:24:32/00:13:15, 0.736s/it]: train_loss_raw=1.3642, running_loss=1.3594, LR=0.000100
[2025-08-27 00:38:40,094][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020488] [Batch 02008/03080] [00:24:38/00:13:09, 0.736s/it]: train_loss_raw=1.3181, running_loss=1.3563, LR=0.000100
[2025-08-27 00:38:45,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020496] [Batch 02016/03080] [00:24:44/00:13:03, 0.736s/it]: train_loss_raw=1.3676, running_loss=1.3552, LR=0.000100
[2025-08-27 00:38:51,906][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020504] [Batch 02024/03080] [00:24:50/00:12:57, 0.736s/it]: train_loss_raw=1.3799, running_loss=1.3542, LR=0.000100
[2025-08-27 00:38:57,938][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020512] [Batch 02032/03080] [00:24:56/00:12:51, 0.736s/it]: train_loss_raw=1.3668, running_loss=1.3533, LR=0.000100
[2025-08-27 00:39:03,797][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020520] [Batch 02040/03080] [00:25:02/00:12:45, 0.736s/it]: train_loss_raw=1.3221, running_loss=1.3541, LR=0.000100
[2025-08-27 00:39:09,789][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020528] [Batch 02048/03080] [00:25:08/00:12:40, 0.736s/it]: train_loss_raw=1.4234, running_loss=1.3538, LR=0.000100
[2025-08-27 00:39:15,595][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020536] [Batch 02056/03080] [00:25:14/00:12:34, 0.736s/it]: train_loss_raw=1.3964, running_loss=1.3548, LR=0.000100
[2025-08-27 00:39:21,332][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020544] [Batch 02064/03080] [00:25:19/00:12:28, 0.736s/it]: train_loss_raw=1.4498, running_loss=1.3523, LR=0.000100
[2025-08-27 00:39:27,055][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020552] [Batch 02072/03080] [00:25:25/00:12:22, 0.736s/it]: train_loss_raw=1.3585, running_loss=1.3548, LR=0.000100
[2025-08-27 00:39:32,862][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020560] [Batch 02080/03080] [00:25:31/00:12:16, 0.736s/it]: train_loss_raw=1.3469, running_loss=1.3546, LR=0.000100
[2025-08-27 00:39:38,560][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020568] [Batch 02088/03080] [00:25:37/00:12:10, 0.736s/it]: train_loss_raw=1.2815, running_loss=1.3529, LR=0.000100
[2025-08-27 00:39:44,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020576] [Batch 02096/03080] [00:25:42/00:12:04, 0.736s/it]: train_loss_raw=1.3376, running_loss=1.3541, LR=0.000100
[2025-08-27 00:39:50,389][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020584] [Batch 02104/03080] [00:25:48/00:11:58, 0.736s/it]: train_loss_raw=1.4127, running_loss=1.3562, LR=0.000100
[2025-08-27 00:39:56,395][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020592] [Batch 02112/03080] [00:25:54/00:11:52, 0.736s/it]: train_loss_raw=1.3868, running_loss=1.3561, LR=0.000100
[2025-08-27 00:40:02,241][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020600] [Batch 02120/03080] [00:26:00/00:11:46, 0.736s/it]: train_loss_raw=1.3115, running_loss=1.3513, LR=0.000100
[2025-08-27 00:40:07,888][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020608] [Batch 02128/03080] [00:26:06/00:11:40, 0.736s/it]: train_loss_raw=1.3824, running_loss=1.3512, LR=0.000100
[2025-08-27 00:40:13,569][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020616] [Batch 02136/03080] [00:26:12/00:11:34, 0.736s/it]: train_loss_raw=1.3936, running_loss=1.3493, LR=0.000100
[2025-08-27 00:40:19,362][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020624] [Batch 02144/03080] [00:26:17/00:11:28, 0.736s/it]: train_loss_raw=1.3557, running_loss=1.3472, LR=0.000100
[2025-08-27 00:40:25,055][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020632] [Batch 02152/03080] [00:26:23/00:11:22, 0.736s/it]: train_loss_raw=1.2970, running_loss=1.3468, LR=0.000100
[2025-08-27 00:40:30,899][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020640] [Batch 02160/03080] [00:26:29/00:11:16, 0.736s/it]: train_loss_raw=1.3529, running_loss=1.3462, LR=0.000100
[2025-08-27 00:40:37,235][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020648] [Batch 02168/03080] [00:26:35/00:11:11, 0.736s/it]: train_loss_raw=1.3874, running_loss=1.3483, LR=0.000100
[2025-08-27 00:40:43,318][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020656] [Batch 02176/03080] [00:26:41/00:11:05, 0.736s/it]: train_loss_raw=1.2931, running_loss=1.3466, LR=0.000100
[2025-08-27 00:40:49,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020664] [Batch 02184/03080] [00:26:47/00:10:59, 0.736s/it]: train_loss_raw=1.3524, running_loss=1.3472, LR=0.000100
[2025-08-27 00:40:55,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020672] [Batch 02192/03080] [00:26:53/00:10:53, 0.736s/it]: train_loss_raw=1.4339, running_loss=1.3472, LR=0.000100
[2025-08-27 00:41:01,185][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020680] [Batch 02200/03080] [00:26:59/00:10:47, 0.736s/it]: train_loss_raw=1.3495, running_loss=1.3481, LR=0.000100
[2025-08-27 00:41:06,934][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020688] [Batch 02208/03080] [00:27:05/00:10:41, 0.736s/it]: train_loss_raw=1.3101, running_loss=1.3472, LR=0.000100
[2025-08-27 00:41:12,666][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020696] [Batch 02216/03080] [00:27:11/00:10:35, 0.736s/it]: train_loss_raw=1.3398, running_loss=1.3477, LR=0.000100
[2025-08-27 00:41:18,354][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020704] [Batch 02224/03080] [00:27:16/00:10:30, 0.736s/it]: train_loss_raw=1.2198, running_loss=1.3444, LR=0.000100
[2025-08-27 00:41:24,050][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020712] [Batch 02232/03080] [00:27:22/00:10:24, 0.736s/it]: train_loss_raw=1.3983, running_loss=1.3476, LR=0.000100
[2025-08-27 00:41:29,791][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020720] [Batch 02240/03080] [00:27:28/00:10:18, 0.736s/it]: train_loss_raw=1.2941, running_loss=1.3484, LR=0.000100
[2025-08-27 00:41:35,627][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020728] [Batch 02248/03080] [00:27:34/00:10:12, 0.736s/it]: train_loss_raw=1.4431, running_loss=1.3499, LR=0.000100
[2025-08-27 00:41:41,335][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020736] [Batch 02256/03080] [00:27:39/00:10:06, 0.736s/it]: train_loss_raw=1.4273, running_loss=1.3525, LR=0.000100
[2025-08-27 00:41:47,037][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020744] [Batch 02264/03080] [00:27:45/00:10:00, 0.736s/it]: train_loss_raw=1.2491, running_loss=1.3497, LR=0.000100
[2025-08-27 00:41:52,918][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020752] [Batch 02272/03080] [00:27:51/00:09:54, 0.736s/it]: train_loss_raw=1.3122, running_loss=1.3521, LR=0.000100
[2025-08-27 00:41:58,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020760] [Batch 02280/03080] [00:27:57/00:09:48, 0.736s/it]: train_loss_raw=1.3721, running_loss=1.3519, LR=0.000100
[2025-08-27 00:42:04,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020768] [Batch 02288/03080] [00:28:03/00:09:42, 0.736s/it]: train_loss_raw=1.2519, running_loss=1.3497, LR=0.000100
[2025-08-27 00:42:10,507][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020776] [Batch 02296/03080] [00:28:09/00:09:36, 0.736s/it]: train_loss_raw=1.3122, running_loss=1.3499, LR=0.000100
[2025-08-27 00:42:16,330][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020784] [Batch 02304/03080] [00:28:14/00:09:30, 0.736s/it]: train_loss_raw=1.3210, running_loss=1.3500, LR=0.000100
[2025-08-27 00:42:22,134][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020792] [Batch 02312/03080] [00:28:20/00:09:24, 0.736s/it]: train_loss_raw=1.4269, running_loss=1.3485, LR=0.000100
[2025-08-27 00:42:28,052][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020800] [Batch 02320/03080] [00:28:26/00:09:19, 0.736s/it]: train_loss_raw=1.3772, running_loss=1.3480, LR=0.000100
[2025-08-27 00:42:34,183][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020808] [Batch 02328/03080] [00:28:32/00:09:13, 0.736s/it]: train_loss_raw=1.2246, running_loss=1.3466, LR=0.000100
[2025-08-27 00:42:40,284][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020816] [Batch 02336/03080] [00:28:38/00:09:07, 0.736s/it]: train_loss_raw=1.3260, running_loss=1.3487, LR=0.000100
[2025-08-27 00:42:46,166][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020824] [Batch 02344/03080] [00:28:44/00:09:01, 0.736s/it]: train_loss_raw=1.4173, running_loss=1.3494, LR=0.000100
[2025-08-27 00:42:52,129][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020832] [Batch 02352/03080] [00:28:50/00:08:55, 0.736s/it]: train_loss_raw=1.3550, running_loss=1.3503, LR=0.000100
[2025-08-27 00:42:57,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020840] [Batch 02360/03080] [00:28:56/00:08:49, 0.736s/it]: train_loss_raw=1.4038, running_loss=1.3506, LR=0.000100
[2025-08-27 00:43:03,812][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020848] [Batch 02368/03080] [00:29:02/00:08:43, 0.736s/it]: train_loss_raw=1.2957, running_loss=1.3492, LR=0.000100
[2025-08-27 00:43:09,537][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020856] [Batch 02376/03080] [00:29:08/00:08:37, 0.736s/it]: train_loss_raw=1.1908, running_loss=1.3486, LR=0.000100
[2025-08-27 00:43:15,138][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020864] [Batch 02384/03080] [00:29:13/00:08:31, 0.736s/it]: train_loss_raw=1.3402, running_loss=1.3476, LR=0.000100
[2025-08-27 00:43:20,940][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020872] [Batch 02392/03080] [00:29:19/00:08:26, 0.736s/it]: train_loss_raw=1.3963, running_loss=1.3505, LR=0.000100
[2025-08-27 00:43:26,709][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020880] [Batch 02400/03080] [00:29:25/00:08:20, 0.736s/it]: train_loss_raw=1.3354, running_loss=1.3510, LR=0.000100
[2025-08-27 00:43:32,536][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020888] [Batch 02408/03080] [00:29:31/00:08:14, 0.735s/it]: train_loss_raw=1.3190, running_loss=1.3504, LR=0.000100
[2025-08-27 00:43:38,396][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020896] [Batch 02416/03080] [00:29:36/00:08:08, 0.735s/it]: train_loss_raw=1.3408, running_loss=1.3479, LR=0.000100
[2025-08-27 00:43:44,380][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020904] [Batch 02424/03080] [00:29:42/00:08:02, 0.736s/it]: train_loss_raw=1.3287, running_loss=1.3489, LR=0.000100
[2025-08-27 00:43:50,086][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020912] [Batch 02432/03080] [00:29:48/00:07:56, 0.735s/it]: train_loss_raw=1.3341, running_loss=1.3466, LR=0.000100
[2025-08-27 00:43:55,744][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020920] [Batch 02440/03080] [00:29:54/00:07:50, 0.735s/it]: train_loss_raw=1.2247, running_loss=1.3435, LR=0.000100
[2025-08-27 00:44:01,666][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020928] [Batch 02448/03080] [00:30:00/00:07:44, 0.735s/it]: train_loss_raw=1.3251, running_loss=1.3445, LR=0.000100
[2025-08-27 00:44:07,489][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020936] [Batch 02456/03080] [00:30:06/00:07:38, 0.735s/it]: train_loss_raw=1.2912, running_loss=1.3459, LR=0.000100
[2025-08-27 00:44:13,183][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020944] [Batch 02464/03080] [00:30:11/00:07:32, 0.735s/it]: train_loss_raw=1.3368, running_loss=1.3462, LR=0.000100
[2025-08-27 00:44:19,243][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020952] [Batch 02472/03080] [00:30:17/00:07:27, 0.735s/it]: train_loss_raw=1.4554, running_loss=1.3482, LR=0.000100
[2025-08-27 00:44:25,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020960] [Batch 02480/03080] [00:30:23/00:07:21, 0.735s/it]: train_loss_raw=1.4918, running_loss=1.3498, LR=0.000100
[2025-08-27 00:44:30,987][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020968] [Batch 02488/03080] [00:30:29/00:07:15, 0.735s/it]: train_loss_raw=1.3899, running_loss=1.3491, LR=0.000100
[2025-08-27 00:44:36,863][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020976] [Batch 02496/03080] [00:30:35/00:07:09, 0.735s/it]: train_loss_raw=1.3696, running_loss=1.3507, LR=0.000100
[2025-08-27 00:44:42,737][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020984] [Batch 02504/03080] [00:30:41/00:07:03, 0.735s/it]: train_loss_raw=1.3153, running_loss=1.3493, LR=0.000100
[2025-08-27 00:44:48,677][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 020992] [Batch 02512/03080] [00:30:47/00:06:57, 0.735s/it]: train_loss_raw=1.3278, running_loss=1.3474, LR=0.000100
[2025-08-27 00:44:54,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021000] [Batch 02520/03080] [00:30:53/00:06:51, 0.735s/it]: train_loss_raw=1.2387, running_loss=1.3468, LR=0.000100
[2025-08-27 00:45:00,602][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021008] [Batch 02528/03080] [00:30:59/00:06:45, 0.735s/it]: train_loss_raw=1.3985, running_loss=1.3478, LR=0.000100
[2025-08-27 00:45:06,654][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021016] [Batch 02536/03080] [00:31:05/00:06:40, 0.735s/it]: train_loss_raw=1.3271, running_loss=1.3492, LR=0.000100
[2025-08-27 00:45:12,455][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021024] [Batch 02544/03080] [00:31:10/00:06:34, 0.735s/it]: train_loss_raw=1.3316, running_loss=1.3494, LR=0.000100
[2025-08-27 00:45:18,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021032] [Batch 02552/03080] [00:31:17/00:06:28, 0.736s/it]: train_loss_raw=1.3547, running_loss=1.3513, LR=0.000100
[2025-08-27 00:45:24,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021040] [Batch 02560/03080] [00:31:23/00:06:22, 0.736s/it]: train_loss_raw=1.4191, running_loss=1.3513, LR=0.000100
[2025-08-27 00:45:30,751][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021048] [Batch 02568/03080] [00:31:29/00:06:16, 0.736s/it]: train_loss_raw=1.4056, running_loss=1.3485, LR=0.000100
[2025-08-27 00:45:36,729][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021056] [Batch 02576/03080] [00:31:35/00:06:10, 0.736s/it]: train_loss_raw=1.3869, running_loss=1.3504, LR=0.000100
[2025-08-27 00:45:42,574][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021064] [Batch 02584/03080] [00:31:41/00:06:04, 0.736s/it]: train_loss_raw=1.2949, running_loss=1.3483, LR=0.000100
[2025-08-27 00:45:48,636][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021072] [Batch 02592/03080] [00:31:47/00:05:59, 0.736s/it]: train_loss_raw=1.3694, running_loss=1.3484, LR=0.000100
[2025-08-27 00:45:54,610][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021080] [Batch 02600/03080] [00:31:53/00:05:53, 0.736s/it]: train_loss_raw=1.3734, running_loss=1.3490, LR=0.000100
[2025-08-27 00:46:00,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021088] [Batch 02608/03080] [00:31:59/00:05:47, 0.736s/it]: train_loss_raw=1.2246, running_loss=1.3469, LR=0.000100
[2025-08-27 00:46:06,729][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021096] [Batch 02616/03080] [00:32:05/00:05:41, 0.736s/it]: train_loss_raw=1.4605, running_loss=1.3512, LR=0.000100
[2025-08-27 00:46:12,955][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021104] [Batch 02624/03080] [00:32:11/00:05:35, 0.736s/it]: train_loss_raw=1.3243, running_loss=1.3517, LR=0.000100
[2025-08-27 00:46:18,865][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021112] [Batch 02632/03080] [00:32:17/00:05:29, 0.736s/it]: train_loss_raw=1.2459, running_loss=1.3505, LR=0.000100
[2025-08-27 00:46:25,087][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021120] [Batch 02640/03080] [00:32:23/00:05:23, 0.736s/it]: train_loss_raw=1.3048, running_loss=1.3461, LR=0.000100
[2025-08-27 00:46:31,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021128] [Batch 02648/03080] [00:32:29/00:05:18, 0.736s/it]: train_loss_raw=1.3263, running_loss=1.3459, LR=0.000100
[2025-08-27 00:46:36,934][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021136] [Batch 02656/03080] [00:32:35/00:05:12, 0.736s/it]: train_loss_raw=1.4237, running_loss=1.3464, LR=0.000100
[2025-08-27 00:46:42,783][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021144] [Batch 02664/03080] [00:32:41/00:05:06, 0.736s/it]: train_loss_raw=1.2707, running_loss=1.3441, LR=0.000100
[2025-08-27 00:46:48,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021152] [Batch 02672/03080] [00:32:47/00:05:00, 0.736s/it]: train_loss_raw=1.3391, running_loss=1.3435, LR=0.000100
[2025-08-27 00:46:55,078][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021160] [Batch 02680/03080] [00:32:53/00:04:54, 0.736s/it]: train_loss_raw=1.4150, running_loss=1.3455, LR=0.000100
[2025-08-27 00:47:01,060][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021168] [Batch 02688/03080] [00:32:59/00:04:48, 0.736s/it]: train_loss_raw=1.2463, running_loss=1.3433, LR=0.000100
[2025-08-27 00:47:07,169][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021176] [Batch 02696/03080] [00:33:05/00:04:42, 0.737s/it]: train_loss_raw=1.3296, running_loss=1.3437, LR=0.000100
[2025-08-27 00:47:13,075][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021184] [Batch 02704/03080] [00:33:11/00:04:36, 0.737s/it]: train_loss_raw=1.4067, running_loss=1.3448, LR=0.000100
[2025-08-27 00:47:19,027][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021192] [Batch 02712/03080] [00:33:17/00:04:31, 0.737s/it]: train_loss_raw=1.3518, running_loss=1.3418, LR=0.000100
[2025-08-27 00:47:24,852][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021200] [Batch 02720/03080] [00:33:23/00:04:25, 0.737s/it]: train_loss_raw=1.3291, running_loss=1.3417, LR=0.000100
[2025-08-27 00:47:30,680][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021208] [Batch 02728/03080] [00:33:29/00:04:19, 0.737s/it]: train_loss_raw=1.2477, running_loss=1.3402, LR=0.000100
[2025-08-27 00:47:36,582][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021216] [Batch 02736/03080] [00:33:35/00:04:13, 0.737s/it]: train_loss_raw=1.2772, running_loss=1.3370, LR=0.000100
[2025-08-27 00:47:42,626][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021224] [Batch 02744/03080] [00:33:41/00:04:07, 0.737s/it]: train_loss_raw=1.3372, running_loss=1.3389, LR=0.000100
[2025-08-27 00:47:48,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021232] [Batch 02752/03080] [00:33:47/00:04:01, 0.737s/it]: train_loss_raw=1.2713, running_loss=1.3394, LR=0.000100
[2025-08-27 00:47:54,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021240] [Batch 02760/03080] [00:33:52/00:03:55, 0.737s/it]: train_loss_raw=1.3180, running_loss=1.3368, LR=0.000100
[2025-08-27 00:48:00,273][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021248] [Batch 02768/03080] [00:33:58/00:03:49, 0.737s/it]: train_loss_raw=1.3257, running_loss=1.3362, LR=0.000100
[2025-08-27 00:48:06,127][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021256] [Batch 02776/03080] [00:34:04/00:03:43, 0.737s/it]: train_loss_raw=1.4174, running_loss=1.3369, LR=0.000100
[2025-08-27 00:48:12,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021264] [Batch 02784/03080] [00:34:10/00:03:38, 0.737s/it]: train_loss_raw=1.2494, running_loss=1.3360, LR=0.000100
[2025-08-27 00:48:17,957][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021272] [Batch 02792/03080] [00:34:16/00:03:32, 0.737s/it]: train_loss_raw=1.4036, running_loss=1.3363, LR=0.000100
[2025-08-27 00:48:23,843][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021280] [Batch 02800/03080] [00:34:22/00:03:26, 0.737s/it]: train_loss_raw=1.4150, running_loss=1.3356, LR=0.000100
[2025-08-27 00:48:29,861][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021288] [Batch 02808/03080] [00:34:28/00:03:20, 0.737s/it]: train_loss_raw=1.3083, running_loss=1.3364, LR=0.000100
[2025-08-27 00:48:35,899][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021296] [Batch 02816/03080] [00:34:34/00:03:14, 0.737s/it]: train_loss_raw=1.3865, running_loss=1.3393, LR=0.000100
[2025-08-27 00:48:42,115][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021304] [Batch 02824/03080] [00:34:40/00:03:08, 0.737s/it]: train_loss_raw=1.3406, running_loss=1.3397, LR=0.000100
[2025-08-27 00:48:48,064][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021312] [Batch 02832/03080] [00:34:46/00:03:02, 0.737s/it]: train_loss_raw=1.3915, running_loss=1.3401, LR=0.000100
[2025-08-27 00:48:53,956][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021320] [Batch 02840/03080] [00:34:52/00:02:56, 0.737s/it]: train_loss_raw=1.3354, running_loss=1.3399, LR=0.000100
[2025-08-27 00:48:59,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021328] [Batch 02848/03080] [00:34:58/00:02:50, 0.737s/it]: train_loss_raw=1.2491, running_loss=1.3402, LR=0.000100
[2025-08-27 00:49:05,889][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021336] [Batch 02856/03080] [00:35:04/00:02:45, 0.737s/it]: train_loss_raw=1.3216, running_loss=1.3384, LR=0.000100
[2025-08-27 00:49:11,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021344] [Batch 02864/03080] [00:35:10/00:02:39, 0.737s/it]: train_loss_raw=1.3382, running_loss=1.3405, LR=0.000100
[2025-08-27 00:49:17,392][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021352] [Batch 02872/03080] [00:35:15/00:02:33, 0.737s/it]: train_loss_raw=1.2499, running_loss=1.3395, LR=0.000100
[2025-08-27 00:49:23,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021360] [Batch 02880/03080] [00:35:21/00:02:27, 0.737s/it]: train_loss_raw=1.3912, running_loss=1.3388, LR=0.000100
[2025-08-27 00:49:29,298][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021368] [Batch 02888/03080] [00:35:27/00:02:21, 0.737s/it]: train_loss_raw=1.2904, running_loss=1.3370, LR=0.000100
[2025-08-27 00:49:35,011][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021376] [Batch 02896/03080] [00:35:33/00:02:15, 0.737s/it]: train_loss_raw=1.2518, running_loss=1.3344, LR=0.000100
[2025-08-27 00:49:41,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021384] [Batch 02904/03080] [00:35:39/00:02:09, 0.737s/it]: train_loss_raw=1.2131, running_loss=1.3370, LR=0.000100
[2025-08-27 00:49:46,931][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021392] [Batch 02912/03080] [00:35:45/00:02:03, 0.737s/it]: train_loss_raw=1.3452, running_loss=1.3347, LR=0.000100
[2025-08-27 00:49:52,821][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021400] [Batch 02920/03080] [00:35:51/00:01:57, 0.737s/it]: train_loss_raw=1.3365, running_loss=1.3344, LR=0.000100
[2025-08-27 00:49:58,653][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021408] [Batch 02928/03080] [00:35:57/00:01:51, 0.737s/it]: train_loss_raw=1.3648, running_loss=1.3366, LR=0.000100
[2025-08-27 00:50:04,593][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021416] [Batch 02936/03080] [00:36:03/00:01:46, 0.737s/it]: train_loss_raw=1.3003, running_loss=1.3334, LR=0.000100
[2025-08-27 00:50:10,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021424] [Batch 02944/03080] [00:36:09/00:01:40, 0.737s/it]: train_loss_raw=1.3520, running_loss=1.3333, LR=0.000100
[2025-08-27 00:50:16,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021432] [Batch 02952/03080] [00:36:14/00:01:34, 0.737s/it]: train_loss_raw=1.2873, running_loss=1.3362, LR=0.000100
[2025-08-27 00:50:22,383][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021440] [Batch 02960/03080] [00:36:20/00:01:28, 0.737s/it]: train_loss_raw=1.3603, running_loss=1.3355, LR=0.000100
[2025-08-27 00:50:28,286][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021448] [Batch 02968/03080] [00:36:26/00:01:22, 0.737s/it]: train_loss_raw=1.3193, running_loss=1.3328, LR=0.000100
[2025-08-27 00:50:34,174][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021456] [Batch 02976/03080] [00:36:32/00:01:16, 0.737s/it]: train_loss_raw=1.3187, running_loss=1.3349, LR=0.000100
[2025-08-27 00:50:40,201][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021464] [Batch 02984/03080] [00:36:38/00:01:10, 0.737s/it]: train_loss_raw=1.3554, running_loss=1.3343, LR=0.000100
[2025-08-27 00:50:46,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021472] [Batch 02992/03080] [00:36:44/00:01:04, 0.737s/it]: train_loss_raw=1.3174, running_loss=1.3343, LR=0.000100
[2025-08-27 00:50:51,900][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021480] [Batch 03000/03080] [00:36:50/00:00:58, 0.737s/it]: train_loss_raw=1.2530, running_loss=1.3350, LR=0.000100
[2025-08-27 00:50:57,940][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021488] [Batch 03008/03080] [00:36:56/00:00:53, 0.737s/it]: train_loss_raw=1.4411, running_loss=1.3356, LR=0.000100
[2025-08-27 00:51:03,683][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021496] [Batch 03016/03080] [00:37:02/00:00:47, 0.737s/it]: train_loss_raw=1.3582, running_loss=1.3370, LR=0.000100
[2025-08-27 00:51:09,408][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021504] [Batch 03024/03080] [00:37:07/00:00:41, 0.737s/it]: train_loss_raw=1.3521, running_loss=1.3375, LR=0.000100
[2025-08-27 00:51:15,166][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021512] [Batch 03032/03080] [00:37:13/00:00:35, 0.737s/it]: train_loss_raw=1.2676, running_loss=1.3358, LR=0.000100
[2025-08-27 00:51:20,919][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021520] [Batch 03040/03080] [00:37:19/00:00:29, 0.737s/it]: train_loss_raw=1.3312, running_loss=1.3329, LR=0.000100
[2025-08-27 00:51:26,637][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021528] [Batch 03048/03080] [00:37:25/00:00:23, 0.737s/it]: train_loss_raw=1.4234, running_loss=1.3335, LR=0.000100
[2025-08-27 00:51:32,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021536] [Batch 03056/03080] [00:37:31/00:00:17, 0.737s/it]: train_loss_raw=1.4199, running_loss=1.3335, LR=0.000100
[2025-08-27 00:51:38,405][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021544] [Batch 03064/03080] [00:37:36/00:00:11, 0.737s/it]: train_loss_raw=1.1919, running_loss=1.3319, LR=0.000100
[2025-08-27 00:51:44,268][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021552] [Batch 03072/03080] [00:37:42/00:00:05, 0.737s/it]: train_loss_raw=1.3014, running_loss=1.3311, LR=0.000100
[2025-08-27 00:51:50,208][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 021560] [Batch 03080/03080] [00:37:48/00:00:00, 0.737s/it]: train_loss_raw=1.2958, running_loss=1.3317, LR=0.000100
[2025-08-27 00:51:50,680][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-27 00:52:02,649][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00007/00310] [00:00:11/00:07:31, 1.496s/it]
[2025-08-27 00:52:14,323][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00015/00310] [00:00:23/00:07:14, 1.478s/it]
[2025-08-27 00:52:26,635][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00023/00310] [00:00:35/00:07:08, 1.498s/it]
[2025-08-27 00:52:39,705][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00031/00310] [00:00:49/00:07:05, 1.532s/it]
[2025-08-27 00:52:52,388][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00039/00310] [00:01:01/00:06:56, 1.543s/it]
[2025-08-27 00:53:04,924][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00047/00310] [00:01:14/00:06:45, 1.547s/it]
[2025-08-27 00:53:17,814][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00055/00310] [00:01:27/00:06:35, 1.556s/it]
[2025-08-27 00:53:30,891][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00063/00310] [00:01:40/00:06:25, 1.566s/it]
[2025-08-27 00:53:43,753][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00071/00310] [00:01:53/00:06:13, 1.570s/it]
[2025-08-27 00:53:56,509][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00079/00310] [00:02:05/00:06:01, 1.573s/it]
[2025-08-27 00:54:08,532][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00087/00310] [00:02:17/00:05:47, 1.566s/it]
[2025-08-27 00:54:21,560][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00095/00310] [00:02:30/00:05:36, 1.572s/it]
[2025-08-27 00:54:34,300][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00103/00310] [00:02:43/00:05:24, 1.573s/it]
[2025-08-27 00:54:46,981][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00111/00310] [00:02:56/00:05:11, 1.574s/it]
[2025-08-27 00:54:59,885][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00119/00310] [00:03:09/00:04:59, 1.577s/it]
[2025-08-27 00:55:12,971][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00127/00310] [00:03:22/00:04:47, 1.580s/it]
[2025-08-27 00:55:26,111][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00135/00310] [00:03:35/00:04:35, 1.584s/it]
[2025-08-27 00:55:39,485][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00143/00310] [00:03:48/00:04:23, 1.589s/it]
[2025-08-27 00:55:51,187][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00151/00310] [00:04:00/00:04:10, 1.582s/it]
[2025-08-27 00:56:02,810][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00159/00310] [00:04:12/00:03:56, 1.576s/it]
[2025-08-27 00:56:15,689][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00167/00310] [00:04:25/00:03:43, 1.577s/it]
[2025-08-27 00:56:27,372][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00175/00310] [00:04:36/00:03:30, 1.572s/it]
[2025-08-27 00:56:39,307][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00183/00310] [00:04:48/00:03:17, 1.569s/it]
[2025-08-27 00:56:51,747][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00191/00310] [00:05:01/00:03:05, 1.568s/it]
[2025-08-27 00:57:04,348][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00199/00310] [00:05:13/00:02:52, 1.568s/it]
[2025-08-27 00:57:16,710][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00207/00310] [00:05:26/00:02:39, 1.567s/it]
[2025-08-27 00:57:28,867][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00215/00310] [00:05:38/00:02:27, 1.566s/it]
[2025-08-27 00:57:41,770][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00223/00310] [00:05:51/00:02:14, 1.567s/it]
[2025-08-27 00:57:54,311][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00231/00310] [00:06:03/00:02:02, 1.567s/it]
[2025-08-27 00:58:06,997][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00239/00310] [00:06:16/00:01:49, 1.568s/it]
[2025-08-27 00:58:19,099][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00247/00310] [00:06:28/00:01:37, 1.566s/it]
[2025-08-27 00:58:31,411][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00255/00310] [00:06:40/00:01:24, 1.565s/it]
[2025-08-27 00:58:44,035][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00263/00310] [00:06:53/00:01:12, 1.566s/it]
[2025-08-27 00:58:56,692][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00271/00310] [00:07:06/00:00:59, 1.566s/it]
[2025-08-27 00:59:08,710][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00279/00310] [00:07:18/00:00:46, 1.564s/it]
[2025-08-27 00:59:21,113][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00287/00310] [00:07:30/00:00:34, 1.564s/it]
[2025-08-27 00:59:33,335][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00295/00310] [00:07:42/00:00:21, 1.563s/it]
[2025-08-27 00:59:46,628][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 021561] [Batch 00303/00310] [00:07:55/00:00:09, 1.566s/it]
[2025-08-27 00:59:56,157][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.33175, valid_loss=2.02103
[2025-08-27 00:59:56,157][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-27 00:59:56,157][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.769
[2025-08-27 00:59:56,157][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.031
[2025-08-27 00:59:56,158][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.032
[2025-08-27 00:59:56,158][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.006
[2025-08-27 00:59:56,168][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 05:33:10, remaining time 18:14:41, 00:47:35 per epoch
[2025-08-27 01:00:02,945][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021568] [Batch 00008/03080] [00:00:05/00:36:10, 0.706s/it]: train_loss_raw=1.3450, running_loss=1.3386, LR=0.000100
[2025-08-27 01:00:09,140][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021576] [Batch 00016/03080] [00:00:11/00:37:48, 0.740s/it]: train_loss_raw=1.4221, running_loss=1.3385, LR=0.000100
[2025-08-27 01:00:15,274][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021584] [Batch 00024/03080] [00:00:17/00:38:09, 0.749s/it]: train_loss_raw=1.3532, running_loss=1.3373, LR=0.000100
[2025-08-27 01:00:20,934][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021592] [Batch 00032/03080] [00:00:23/00:37:31, 0.739s/it]: train_loss_raw=1.2726, running_loss=1.3366, LR=0.000100
[2025-08-27 01:00:26,998][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021600] [Batch 00040/03080] [00:00:29/00:37:37, 0.743s/it]: train_loss_raw=1.3379, running_loss=1.3362, LR=0.000100
[2025-08-27 01:00:32,843][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021608] [Batch 00048/03080] [00:00:35/00:37:25, 0.741s/it]: train_loss_raw=1.3812, running_loss=1.3391, LR=0.000100
[2025-08-27 01:00:38,716][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021616] [Batch 00056/03080] [00:00:41/00:37:16, 0.740s/it]: train_loss_raw=1.4160, running_loss=1.3400, LR=0.000100
[2025-08-27 01:00:44,544][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021624] [Batch 00064/03080] [00:00:47/00:37:06, 0.738s/it]: train_loss_raw=1.3571, running_loss=1.3403, LR=0.000100
[2025-08-27 01:00:50,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021632] [Batch 00072/03080] [00:00:53/00:37:11, 0.742s/it]: train_loss_raw=1.4108, running_loss=1.3402, LR=0.000100
[2025-08-27 01:00:56,470][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021640] [Batch 00080/03080] [00:00:59/00:36:59, 0.740s/it]: train_loss_raw=1.4127, running_loss=1.3421, LR=0.000100
[2025-08-27 01:01:02,536][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021648] [Batch 00088/03080] [00:01:05/00:36:58, 0.741s/it]: train_loss_raw=1.4040, running_loss=1.3400, LR=0.000100
[2025-08-27 01:01:08,273][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021656] [Batch 00096/03080] [00:01:10/00:36:46, 0.739s/it]: train_loss_raw=1.3350, running_loss=1.3389, LR=0.000100
[2025-08-27 01:01:14,259][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021664] [Batch 00104/03080] [00:01:16/00:36:42, 0.740s/it]: train_loss_raw=1.3025, running_loss=1.3388, LR=0.000100
[2025-08-27 01:01:20,129][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021672] [Batch 00112/03080] [00:01:22/00:36:35, 0.740s/it]: train_loss_raw=1.3232, running_loss=1.3400, LR=0.000100
[2025-08-27 01:01:26,318][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021680] [Batch 00120/03080] [00:01:29/00:36:35, 0.742s/it]: train_loss_raw=1.3072, running_loss=1.3372, LR=0.000100
[2025-08-27 01:01:32,259][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021688] [Batch 00128/03080] [00:01:34/00:36:30, 0.742s/it]: train_loss_raw=1.4336, running_loss=1.3375, LR=0.000100
[2025-08-27 01:01:38,229][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021696] [Batch 00136/03080] [00:01:40/00:36:24, 0.742s/it]: train_loss_raw=1.3235, running_loss=1.3352, LR=0.000100
[2025-08-27 01:01:43,997][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021704] [Batch 00144/03080] [00:01:46/00:36:15, 0.741s/it]: train_loss_raw=1.3486, running_loss=1.3348, LR=0.000100
[2025-08-27 01:01:49,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021712] [Batch 00152/03080] [00:01:52/00:36:07, 0.740s/it]: train_loss_raw=1.2492, running_loss=1.3312, LR=0.000100
[2025-08-27 01:01:55,577][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021720] [Batch 00160/03080] [00:01:58/00:35:58, 0.739s/it]: train_loss_raw=1.2270, running_loss=1.3297, LR=0.000100
[2025-08-27 01:02:01,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021728] [Batch 00168/03080] [00:02:04/00:35:51, 0.739s/it]: train_loss_raw=1.3104, running_loss=1.3318, LR=0.000100
[2025-08-27 01:02:07,526][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021736] [Batch 00176/03080] [00:02:10/00:35:48, 0.740s/it]: train_loss_raw=1.2806, running_loss=1.3322, LR=0.000100
[2025-08-27 01:02:13,685][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021744] [Batch 00184/03080] [00:02:16/00:35:46, 0.741s/it]: train_loss_raw=1.2637, running_loss=1.3273, LR=0.000100
[2025-08-27 01:02:19,873][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021752] [Batch 00192/03080] [00:02:22/00:35:44, 0.743s/it]: train_loss_raw=1.3680, running_loss=1.3260, LR=0.000100
[2025-08-27 01:02:25,903][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021760] [Batch 00200/03080] [00:02:28/00:35:39, 0.743s/it]: train_loss_raw=1.2964, running_loss=1.3253, LR=0.000100
[2025-08-27 01:02:31,748][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021768] [Batch 00208/03080] [00:02:34/00:35:32, 0.743s/it]: train_loss_raw=1.3624, running_loss=1.3260, LR=0.000100
[2025-08-27 01:02:37,497][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021776] [Batch 00216/03080] [00:02:40/00:35:24, 0.742s/it]: train_loss_raw=1.3328, running_loss=1.3259, LR=0.000100
[2025-08-27 01:02:43,308][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021784] [Batch 00224/03080] [00:02:46/00:35:16, 0.741s/it]: train_loss_raw=1.2530, running_loss=1.3260, LR=0.000100
[2025-08-27 01:02:49,107][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021792] [Batch 00232/03080] [00:02:51/00:35:09, 0.741s/it]: train_loss_raw=1.2806, running_loss=1.3246, LR=0.000100
[2025-08-27 01:02:54,963][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021800] [Batch 00240/03080] [00:02:57/00:35:02, 0.740s/it]: train_loss_raw=1.2769, running_loss=1.3242, LR=0.000100
[2025-08-27 01:03:00,950][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021808] [Batch 00248/03080] [00:03:03/00:34:57, 0.741s/it]: train_loss_raw=1.3802, running_loss=1.3239, LR=0.000100
[2025-08-27 01:03:06,759][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021816] [Batch 00256/03080] [00:03:09/00:34:50, 0.740s/it]: train_loss_raw=1.3767, running_loss=1.3240, LR=0.000100
[2025-08-27 01:03:12,622][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021824] [Batch 00264/03080] [00:03:15/00:34:43, 0.740s/it]: train_loss_raw=1.3012, running_loss=1.3209, LR=0.000100
[2025-08-27 01:03:18,614][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021832] [Batch 00272/03080] [00:03:21/00:34:38, 0.740s/it]: train_loss_raw=1.2557, running_loss=1.3176, LR=0.000100
[2025-08-27 01:03:24,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021840] [Batch 00280/03080] [00:03:27/00:34:30, 0.739s/it]: train_loss_raw=1.3211, running_loss=1.3168, LR=0.000100
[2025-08-27 01:03:30,285][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021848] [Batch 00288/03080] [00:03:32/00:34:24, 0.740s/it]: train_loss_raw=1.2770, running_loss=1.3177, LR=0.000100
[2025-08-27 01:03:36,249][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021856] [Batch 00296/03080] [00:03:38/00:34:19, 0.740s/it]: train_loss_raw=1.4947, running_loss=1.3202, LR=0.000100
[2025-08-27 01:03:42,066][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021864] [Batch 00304/03080] [00:03:44/00:34:12, 0.739s/it]: train_loss_raw=1.3834, running_loss=1.3191, LR=0.000100
[2025-08-27 01:03:47,966][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021872] [Batch 00312/03080] [00:03:50/00:34:06, 0.739s/it]: train_loss_raw=1.2287, running_loss=1.3146, LR=0.000100
[2025-08-27 01:03:53,914][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021880] [Batch 00320/03080] [00:03:56/00:34:00, 0.739s/it]: train_loss_raw=1.3294, running_loss=1.3137, LR=0.000100
[2025-08-27 01:03:59,757][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021888] [Batch 00328/03080] [00:04:02/00:33:54, 0.739s/it]: train_loss_raw=1.2856, running_loss=1.3093, LR=0.000100
[2025-08-27 01:04:05,572][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021896] [Batch 00336/03080] [00:04:08/00:33:47, 0.739s/it]: train_loss_raw=1.3566, running_loss=1.3123, LR=0.000100
[2025-08-27 01:04:11,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021904] [Batch 00344/03080] [00:04:14/00:33:41, 0.739s/it]: train_loss_raw=1.3965, running_loss=1.3139, LR=0.000100
[2025-08-27 01:04:17,122][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021912] [Batch 00352/03080] [00:04:19/00:33:33, 0.738s/it]: train_loss_raw=1.3516, running_loss=1.3161, LR=0.000100
[2025-08-27 01:04:22,951][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021920] [Batch 00360/03080] [00:04:25/00:33:27, 0.738s/it]: train_loss_raw=1.4169, running_loss=1.3141, LR=0.000100
[2025-08-27 01:04:28,710][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021928] [Batch 00368/03080] [00:04:31/00:33:20, 0.738s/it]: train_loss_raw=1.3017, running_loss=1.3133, LR=0.000100
[2025-08-27 01:04:34,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021936] [Batch 00376/03080] [00:04:37/00:33:15, 0.738s/it]: train_loss_raw=1.3724, running_loss=1.3137, LR=0.000100
[2025-08-27 01:04:40,721][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021944] [Batch 00384/03080] [00:04:43/00:33:09, 0.738s/it]: train_loss_raw=1.2165, running_loss=1.3140, LR=0.000100
[2025-08-27 01:04:46,614][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021952] [Batch 00392/03080] [00:04:49/00:33:03, 0.738s/it]: train_loss_raw=1.3544, running_loss=1.3159, LR=0.000100
[2025-08-27 01:04:52,294][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021960] [Batch 00400/03080] [00:04:55/00:32:56, 0.738s/it]: train_loss_raw=1.2981, running_loss=1.3157, LR=0.000100
[2025-08-27 01:04:58,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021968] [Batch 00408/03080] [00:05:00/00:32:50, 0.737s/it]: train_loss_raw=1.2879, running_loss=1.3137, LR=0.000100
[2025-08-27 01:05:03,868][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021976] [Batch 00416/03080] [00:05:06/00:32:43, 0.737s/it]: train_loss_raw=1.2144, running_loss=1.3138, LR=0.000100
[2025-08-27 01:05:09,641][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021984] [Batch 00424/03080] [00:05:12/00:32:36, 0.737s/it]: train_loss_raw=1.2783, running_loss=1.3132, LR=0.000100
[2025-08-27 01:05:15,338][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 021992] [Batch 00432/03080] [00:05:18/00:32:29, 0.736s/it]: train_loss_raw=1.2807, running_loss=1.3105, LR=0.000100
[2025-08-27 01:05:21,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022000] [Batch 00440/03080] [00:05:24/00:32:24, 0.736s/it]: train_loss_raw=1.2923, running_loss=1.3118, LR=0.000100
[2025-08-27 01:05:31,223][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022008] [Batch 00448/03080] [00:05:33/00:32:41, 0.745s/it]: train_loss_raw=1.4424, running_loss=1.3148, LR=0.000100
[2025-08-27 01:05:37,098][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022016] [Batch 00456/03080] [00:05:39/00:32:35, 0.745s/it]: train_loss_raw=1.3309, running_loss=1.3150, LR=0.000100
[2025-08-27 01:05:43,118][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022024] [Batch 00464/03080] [00:05:45/00:32:29, 0.745s/it]: train_loss_raw=1.2925, running_loss=1.3148, LR=0.000100
[2025-08-27 01:05:49,020][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022032] [Batch 00472/03080] [00:05:51/00:32:23, 0.745s/it]: train_loss_raw=1.3252, running_loss=1.3115, LR=0.000100
[2025-08-27 01:05:54,866][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022040] [Batch 00480/03080] [00:05:57/00:32:16, 0.745s/it]: train_loss_raw=1.4267, running_loss=1.3125, LR=0.000100
[2025-08-27 01:06:01,218][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022048] [Batch 00488/03080] [00:06:03/00:32:12, 0.746s/it]: train_loss_raw=1.2204, running_loss=1.3157, LR=0.000100
[2025-08-27 01:06:07,179][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022056] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=1.3160, running_loss=1.3164, LR=0.000100
[2025-08-27 01:06:13,226][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022064] [Batch 00504/03080] [00:06:15/00:32:01, 0.746s/it]: train_loss_raw=1.3811, running_loss=1.3157, LR=0.000100
[2025-08-27 01:06:18,980][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022072] [Batch 00512/03080] [00:06:21/00:31:54, 0.745s/it]: train_loss_raw=1.3364, running_loss=1.3169, LR=0.000100
[2025-08-27 01:06:24,761][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022080] [Batch 00520/03080] [00:06:27/00:31:47, 0.745s/it]: train_loss_raw=1.2845, running_loss=1.3153, LR=0.000100
[2025-08-27 01:06:30,652][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022088] [Batch 00528/03080] [00:06:33/00:31:41, 0.745s/it]: train_loss_raw=1.2382, running_loss=1.3145, LR=0.000100
[2025-08-27 01:06:36,948][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022096] [Batch 00536/03080] [00:06:39/00:31:36, 0.746s/it]: train_loss_raw=1.2845, running_loss=1.3159, LR=0.000100
[2025-08-27 01:06:43,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022104] [Batch 00544/03080] [00:06:45/00:31:31, 0.746s/it]: train_loss_raw=1.3242, running_loss=1.3159, LR=0.000100
[2025-08-27 01:06:49,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022112] [Batch 00552/03080] [00:06:51/00:31:25, 0.746s/it]: train_loss_raw=1.3034, running_loss=1.3152, LR=0.000100
[2025-08-27 01:06:55,198][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022120] [Batch 00560/03080] [00:06:57/00:31:20, 0.746s/it]: train_loss_raw=1.3391, running_loss=1.3140, LR=0.000100
[2025-08-27 01:07:01,029][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022128] [Batch 00568/03080] [00:07:03/00:31:13, 0.746s/it]: train_loss_raw=1.2953, running_loss=1.3128, LR=0.000100
[2025-08-27 01:07:07,003][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022136] [Batch 00576/03080] [00:07:09/00:31:08, 0.746s/it]: train_loss_raw=1.2180, running_loss=1.3105, LR=0.000100
[2025-08-27 01:07:13,133][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022144] [Batch 00584/03080] [00:07:15/00:31:02, 0.746s/it]: train_loss_raw=1.3360, running_loss=1.3126, LR=0.000100
[2025-08-27 01:07:19,464][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022152] [Batch 00592/03080] [00:07:22/00:30:58, 0.747s/it]: train_loss_raw=1.2895, running_loss=1.3124, LR=0.000100
[2025-08-27 01:07:25,424][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022160] [Batch 00600/03080] [00:07:28/00:30:52, 0.747s/it]: train_loss_raw=1.3208, running_loss=1.3120, LR=0.000100
[2025-08-27 01:07:31,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022168] [Batch 00608/03080] [00:07:33/00:30:45, 0.747s/it]: train_loss_raw=1.3265, running_loss=1.3142, LR=0.000100
[2025-08-27 01:07:37,132][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022176] [Batch 00616/03080] [00:07:39/00:30:39, 0.746s/it]: train_loss_raw=1.2071, running_loss=1.3123, LR=0.000100
[2025-08-27 01:07:43,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022184] [Batch 00624/03080] [00:07:46/00:30:34, 0.747s/it]: train_loss_raw=1.2765, running_loss=1.3140, LR=0.000100
[2025-08-27 01:07:48,961][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022192] [Batch 00632/03080] [00:07:51/00:30:26, 0.746s/it]: train_loss_raw=1.1874, running_loss=1.3123, LR=0.000100
[2025-08-27 01:07:54,630][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022200] [Batch 00640/03080] [00:07:57/00:30:19, 0.746s/it]: train_loss_raw=1.2759, running_loss=1.3128, LR=0.000100
[2025-08-27 01:08:00,329][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022208] [Batch 00648/03080] [00:08:03/00:30:12, 0.745s/it]: train_loss_raw=1.4543, running_loss=1.3118, LR=0.000100
[2025-08-27 01:08:06,049][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022216] [Batch 00656/03080] [00:08:08/00:30:06, 0.745s/it]: train_loss_raw=1.3839, running_loss=1.3167, LR=0.000100
[2025-08-27 01:08:11,658][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022224] [Batch 00664/03080] [00:08:14/00:29:58, 0.745s/it]: train_loss_raw=1.2612, running_loss=1.3151, LR=0.000100
[2025-08-27 01:08:17,463][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022232] [Batch 00672/03080] [00:08:20/00:29:52, 0.744s/it]: train_loss_raw=1.2745, running_loss=1.3162, LR=0.000100
[2025-08-27 01:08:23,322][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022240] [Batch 00680/03080] [00:08:26/00:29:45, 0.744s/it]: train_loss_raw=1.3635, running_loss=1.3185, LR=0.000100
[2025-08-27 01:08:29,198][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022248] [Batch 00688/03080] [00:08:31/00:29:39, 0.744s/it]: train_loss_raw=1.3804, running_loss=1.3172, LR=0.000100
[2025-08-27 01:08:34,937][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022256] [Batch 00696/03080] [00:08:37/00:29:33, 0.744s/it]: train_loss_raw=1.2312, running_loss=1.3151, LR=0.000100
[2025-08-27 01:08:40,780][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022264] [Batch 00704/03080] [00:08:43/00:29:26, 0.744s/it]: train_loss_raw=1.2763, running_loss=1.3127, LR=0.000100
[2025-08-27 01:08:46,675][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022272] [Batch 00712/03080] [00:08:49/00:29:20, 0.744s/it]: train_loss_raw=1.2089, running_loss=1.3111, LR=0.000100
[2025-08-27 01:08:52,601][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022280] [Batch 00720/03080] [00:08:55/00:29:14, 0.743s/it]: train_loss_raw=1.2372, running_loss=1.3087, LR=0.000100
[2025-08-27 01:08:58,717][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022288] [Batch 00728/03080] [00:09:01/00:29:09, 0.744s/it]: train_loss_raw=1.3483, running_loss=1.3101, LR=0.000100
[2025-08-27 01:09:04,680][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022296] [Batch 00736/03080] [00:09:07/00:29:03, 0.744s/it]: train_loss_raw=1.3443, running_loss=1.3083, LR=0.000100
[2025-08-27 01:09:10,604][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022304] [Batch 00744/03080] [00:09:13/00:28:57, 0.744s/it]: train_loss_raw=1.3021, running_loss=1.3102, LR=0.000100
[2025-08-27 01:09:16,298][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022312] [Batch 00752/03080] [00:09:19/00:28:50, 0.743s/it]: train_loss_raw=1.1692, running_loss=1.3095, LR=0.000100
[2025-08-27 01:09:22,059][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022320] [Batch 00760/03080] [00:09:24/00:28:44, 0.743s/it]: train_loss_raw=1.3240, running_loss=1.3091, LR=0.000100
[2025-08-27 01:09:28,025][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022328] [Batch 00768/03080] [00:09:30/00:28:38, 0.743s/it]: train_loss_raw=1.2974, running_loss=1.3046, LR=0.000100
[2025-08-27 01:09:34,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022336] [Batch 00776/03080] [00:09:36/00:28:32, 0.743s/it]: train_loss_raw=1.4300, running_loss=1.3081, LR=0.000100
[2025-08-27 01:09:39,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022344] [Batch 00784/03080] [00:09:42/00:28:26, 0.743s/it]: train_loss_raw=1.3936, running_loss=1.3078, LR=0.000100
[2025-08-27 01:09:45,913][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022352] [Batch 00792/03080] [00:09:48/00:28:20, 0.743s/it]: train_loss_raw=1.2448, running_loss=1.3086, LR=0.000100
[2025-08-27 01:09:52,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022360] [Batch 00800/03080] [00:09:54/00:28:15, 0.743s/it]: train_loss_raw=1.2919, running_loss=1.3100, LR=0.000100
[2025-08-27 01:09:58,020][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022368] [Batch 00808/03080] [00:10:00/00:28:09, 0.743s/it]: train_loss_raw=1.3028, running_loss=1.3108, LR=0.000100
[2025-08-27 01:10:03,897][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022376] [Batch 00816/03080] [00:10:06/00:28:03, 0.743s/it]: train_loss_raw=1.3127, running_loss=1.3085, LR=0.000100
[2025-08-27 01:10:09,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022384] [Batch 00824/03080] [00:10:12/00:27:56, 0.743s/it]: train_loss_raw=1.3405, running_loss=1.3081, LR=0.000100
[2025-08-27 01:10:15,590][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022392] [Batch 00832/03080] [00:10:18/00:27:50, 0.743s/it]: train_loss_raw=1.2694, running_loss=1.3052, LR=0.000100
[2025-08-27 01:10:21,449][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022400] [Batch 00840/03080] [00:10:24/00:27:44, 0.743s/it]: train_loss_raw=1.2745, running_loss=1.3060, LR=0.000100
[2025-08-27 01:10:27,389][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022408] [Batch 00848/03080] [00:10:30/00:27:38, 0.743s/it]: train_loss_raw=1.3692, running_loss=1.3061, LR=0.000100
[2025-08-27 01:10:33,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022416] [Batch 00856/03080] [00:10:36/00:27:32, 0.743s/it]: train_loss_raw=1.2670, running_loss=1.3062, LR=0.000100
[2025-08-27 01:10:39,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022424] [Batch 00864/03080] [00:10:41/00:27:26, 0.743s/it]: train_loss_raw=1.2720, running_loss=1.3049, LR=0.000100
[2025-08-27 01:10:45,114][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022432] [Batch 00872/03080] [00:10:47/00:27:20, 0.743s/it]: train_loss_raw=1.3140, running_loss=1.3023, LR=0.000100
[2025-08-27 01:10:50,980][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022440] [Batch 00880/03080] [00:10:53/00:27:14, 0.743s/it]: train_loss_raw=1.2122, running_loss=1.3000, LR=0.000100
[2025-08-27 01:10:56,691][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022448] [Batch 00888/03080] [00:10:59/00:27:07, 0.743s/it]: train_loss_raw=1.3333, running_loss=1.2992, LR=0.000100
[2025-08-27 01:11:02,551][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022456] [Batch 00896/03080] [00:11:05/00:27:01, 0.742s/it]: train_loss_raw=1.3157, running_loss=1.2989, LR=0.000100
[2025-08-27 01:11:08,701][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022464] [Batch 00904/03080] [00:11:11/00:26:56, 0.743s/it]: train_loss_raw=1.2748, running_loss=1.3025, LR=0.000100
[2025-08-27 01:11:14,477][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022472] [Batch 00912/03080] [00:11:17/00:26:49, 0.743s/it]: train_loss_raw=1.3727, running_loss=1.3035, LR=0.000100
[2025-08-27 01:11:20,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022480] [Batch 00920/03080] [00:11:22/00:26:43, 0.742s/it]: train_loss_raw=1.2864, running_loss=1.3005, LR=0.000100
[2025-08-27 01:11:26,233][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022488] [Batch 00928/03080] [00:11:28/00:26:37, 0.742s/it]: train_loss_raw=1.3288, running_loss=1.3023, LR=0.000100
[2025-08-27 01:11:32,191][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022496] [Batch 00936/03080] [00:11:34/00:26:31, 0.742s/it]: train_loss_raw=1.2302, running_loss=1.3032, LR=0.000100
[2025-08-27 01:11:38,054][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022504] [Batch 00944/03080] [00:11:40/00:26:25, 0.742s/it]: train_loss_raw=1.2924, running_loss=1.3042, LR=0.000100
[2025-08-27 01:11:43,986][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022512] [Batch 00952/03080] [00:11:46/00:26:19, 0.742s/it]: train_loss_raw=1.1809, running_loss=1.3002, LR=0.000100
[2025-08-27 01:11:49,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022520] [Batch 00960/03080] [00:11:52/00:26:13, 0.742s/it]: train_loss_raw=1.3149, running_loss=1.2989, LR=0.000100
[2025-08-27 01:11:56,041][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022528] [Batch 00968/03080] [00:11:58/00:26:08, 0.743s/it]: train_loss_raw=1.2799, running_loss=1.2995, LR=0.000100
[2025-08-27 01:12:01,991][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022536] [Batch 00976/03080] [00:12:04/00:26:02, 0.743s/it]: train_loss_raw=1.2522, running_loss=1.3003, LR=0.000100
[2025-08-27 01:12:07,853][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022544] [Batch 00984/03080] [00:12:10/00:25:56, 0.742s/it]: train_loss_raw=1.2943, running_loss=1.3025, LR=0.000100
[2025-08-27 01:12:13,873][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022552] [Batch 00992/03080] [00:12:16/00:25:50, 0.743s/it]: train_loss_raw=1.2271, running_loss=1.3010, LR=0.000100
[2025-08-27 01:12:19,931][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022560] [Batch 01000/03080] [00:12:22/00:25:44, 0.743s/it]: train_loss_raw=1.2762, running_loss=1.3013, LR=0.000100
[2025-08-27 01:12:25,934][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022568] [Batch 01008/03080] [00:12:28/00:25:38, 0.743s/it]: train_loss_raw=1.3180, running_loss=1.3029, LR=0.000100
[2025-08-27 01:12:31,856][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022576] [Batch 01016/03080] [00:12:34/00:25:32, 0.743s/it]: train_loss_raw=1.1986, running_loss=1.3010, LR=0.000100
[2025-08-27 01:12:37,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022584] [Batch 01024/03080] [00:12:40/00:25:26, 0.743s/it]: train_loss_raw=1.3215, running_loss=1.3009, LR=0.000100
[2025-08-27 01:12:43,723][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022592] [Batch 01032/03080] [00:12:46/00:25:20, 0.743s/it]: train_loss_raw=1.2936, running_loss=1.3006, LR=0.000100
[2025-08-27 01:12:49,555][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022600] [Batch 01040/03080] [00:12:52/00:25:14, 0.743s/it]: train_loss_raw=1.2237, running_loss=1.3005, LR=0.000100
[2025-08-27 01:12:55,278][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022608] [Batch 01048/03080] [00:12:57/00:25:08, 0.742s/it]: train_loss_raw=1.2942, running_loss=1.2988, LR=0.000100
[2025-08-27 01:13:01,106][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022616] [Batch 01056/03080] [00:13:03/00:25:02, 0.742s/it]: train_loss_raw=1.3228, running_loss=1.2984, LR=0.000100
[2025-08-27 01:13:06,874][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022624] [Batch 01064/03080] [00:13:09/00:24:56, 0.742s/it]: train_loss_raw=1.2654, running_loss=1.2975, LR=0.000100
[2025-08-27 01:13:12,900][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022632] [Batch 01072/03080] [00:13:15/00:24:50, 0.742s/it]: train_loss_raw=1.2880, running_loss=1.2988, LR=0.000100
[2025-08-27 01:13:18,692][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022640] [Batch 01080/03080] [00:13:21/00:24:44, 0.742s/it]: train_loss_raw=1.3809, running_loss=1.2973, LR=0.000100
[2025-08-27 01:13:24,631][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022648] [Batch 01088/03080] [00:13:27/00:24:38, 0.742s/it]: train_loss_raw=1.2509, running_loss=1.2960, LR=0.000100
[2025-08-27 01:13:30,474][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022656] [Batch 01096/03080] [00:13:33/00:24:32, 0.742s/it]: train_loss_raw=1.3061, running_loss=1.2958, LR=0.000100
[2025-08-27 01:13:36,201][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022664] [Batch 01104/03080] [00:13:38/00:24:25, 0.742s/it]: train_loss_raw=1.3742, running_loss=1.2978, LR=0.000100
[2025-08-27 01:13:42,133][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022672] [Batch 01112/03080] [00:13:44/00:24:19, 0.742s/it]: train_loss_raw=1.2385, running_loss=1.2940, LR=0.000100
[2025-08-27 01:13:48,028][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022680] [Batch 01120/03080] [00:13:50/00:24:13, 0.742s/it]: train_loss_raw=1.2605, running_loss=1.2963, LR=0.000100
[2025-08-27 01:13:53,931][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022688] [Batch 01128/03080] [00:13:56/00:24:07, 0.742s/it]: train_loss_raw=1.2898, running_loss=1.2934, LR=0.000100
[2025-08-27 01:13:59,872][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022696] [Batch 01136/03080] [00:14:02/00:24:01, 0.742s/it]: train_loss_raw=1.2149, running_loss=1.2922, LR=0.000100
[2025-08-27 01:14:05,676][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022704] [Batch 01144/03080] [00:14:08/00:23:55, 0.742s/it]: train_loss_raw=1.2571, running_loss=1.2944, LR=0.000100
[2025-08-27 01:14:11,571][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022712] [Batch 01152/03080] [00:14:14/00:23:49, 0.742s/it]: train_loss_raw=1.2348, running_loss=1.2949, LR=0.000100
[2025-08-27 01:14:17,390][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022720] [Batch 01160/03080] [00:14:20/00:23:43, 0.741s/it]: train_loss_raw=1.2993, running_loss=1.2975, LR=0.000100
[2025-08-27 01:14:23,277][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022728] [Batch 01168/03080] [00:14:25/00:23:37, 0.741s/it]: train_loss_raw=1.3318, running_loss=1.2955, LR=0.000100
[2025-08-27 01:14:29,482][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022736] [Batch 01176/03080] [00:14:32/00:23:32, 0.742s/it]: train_loss_raw=1.3820, running_loss=1.2972, LR=0.000100
[2025-08-27 01:14:35,440][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022744] [Batch 01184/03080] [00:14:38/00:23:26, 0.742s/it]: train_loss_raw=1.2649, running_loss=1.2924, LR=0.000100
[2025-08-27 01:14:41,566][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022752] [Batch 01192/03080] [00:14:44/00:23:20, 0.742s/it]: train_loss_raw=1.2929, running_loss=1.2917, LR=0.000100
[2025-08-27 01:14:47,507][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022760] [Batch 01200/03080] [00:14:50/00:23:14, 0.742s/it]: train_loss_raw=1.3509, running_loss=1.2930, LR=0.000100
[2025-08-27 01:14:53,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022768] [Batch 01208/03080] [00:14:56/00:23:08, 0.742s/it]: train_loss_raw=1.3177, running_loss=1.2926, LR=0.000100
[2025-08-27 01:14:59,410][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022776] [Batch 01216/03080] [00:15:02/00:23:02, 0.742s/it]: train_loss_raw=1.3090, running_loss=1.2958, LR=0.000100
[2025-08-27 01:15:05,518][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022784] [Batch 01224/03080] [00:15:08/00:22:57, 0.742s/it]: train_loss_raw=1.2798, running_loss=1.2933, LR=0.000100
[2025-08-27 01:15:11,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022792] [Batch 01232/03080] [00:15:14/00:22:51, 0.742s/it]: train_loss_raw=1.3443, running_loss=1.2927, LR=0.000100
[2025-08-27 01:15:17,383][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022800] [Batch 01240/03080] [00:15:20/00:22:45, 0.742s/it]: train_loss_raw=1.2636, running_loss=1.2898, LR=0.000100
[2025-08-27 01:15:23,484][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022808] [Batch 01248/03080] [00:15:26/00:22:39, 0.742s/it]: train_loss_raw=1.3555, running_loss=1.2895, LR=0.000100
[2025-08-27 01:15:29,217][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022816] [Batch 01256/03080] [00:15:31/00:22:33, 0.742s/it]: train_loss_raw=1.3836, running_loss=1.2905, LR=0.000100
[2025-08-27 01:15:34,804][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022824] [Batch 01264/03080] [00:15:37/00:22:26, 0.742s/it]: train_loss_raw=1.2944, running_loss=1.2916, LR=0.000100
[2025-08-27 01:15:40,573][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022832] [Batch 01272/03080] [00:15:43/00:22:20, 0.742s/it]: train_loss_raw=1.3005, running_loss=1.2925, LR=0.000100
[2025-08-27 01:15:46,459][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022840] [Batch 01280/03080] [00:15:49/00:22:14, 0.742s/it]: train_loss_raw=1.2708, running_loss=1.2905, LR=0.000100
[2025-08-27 01:15:52,490][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022848] [Batch 01288/03080] [00:15:55/00:22:08, 0.742s/it]: train_loss_raw=1.1801, running_loss=1.2906, LR=0.000100
[2025-08-27 01:15:58,358][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022856] [Batch 01296/03080] [00:16:01/00:22:02, 0.742s/it]: train_loss_raw=1.2983, running_loss=1.2903, LR=0.000100
[2025-08-27 01:16:04,304][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022864] [Batch 01304/03080] [00:16:07/00:21:57, 0.742s/it]: train_loss_raw=1.2296, running_loss=1.2893, LR=0.000100
[2025-08-27 01:16:10,244][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022872] [Batch 01312/03080] [00:16:12/00:21:51, 0.742s/it]: train_loss_raw=1.4516, running_loss=1.2894, LR=0.000100
[2025-08-27 01:16:16,348][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022880] [Batch 01320/03080] [00:16:19/00:21:45, 0.742s/it]: train_loss_raw=1.2812, running_loss=1.2902, LR=0.000100
[2025-08-27 01:16:22,353][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022888] [Batch 01328/03080] [00:16:25/00:21:39, 0.742s/it]: train_loss_raw=1.3334, running_loss=1.2931, LR=0.000100
[2025-08-27 01:16:28,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022896] [Batch 01336/03080] [00:16:30/00:21:33, 0.742s/it]: train_loss_raw=1.2328, running_loss=1.2940, LR=0.000100
[2025-08-27 01:16:34,237][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022904] [Batch 01344/03080] [00:16:36/00:21:27, 0.742s/it]: train_loss_raw=1.2211, running_loss=1.2940, LR=0.000100
[2025-08-27 01:16:40,108][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022912] [Batch 01352/03080] [00:16:42/00:21:21, 0.742s/it]: train_loss_raw=1.2918, running_loss=1.2960, LR=0.000100
[2025-08-27 01:16:46,139][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022920] [Batch 01360/03080] [00:16:48/00:21:15, 0.742s/it]: train_loss_raw=1.2965, running_loss=1.2985, LR=0.000100
[2025-08-27 01:16:52,045][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022928] [Batch 01368/03080] [00:16:54/00:21:09, 0.742s/it]: train_loss_raw=1.2969, running_loss=1.2977, LR=0.000100
[2025-08-27 01:16:58,033][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022936] [Batch 01376/03080] [00:17:00/00:21:04, 0.742s/it]: train_loss_raw=1.2896, running_loss=1.3002, LR=0.000100
[2025-08-27 01:17:03,899][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022944] [Batch 01384/03080] [00:17:06/00:20:58, 0.742s/it]: train_loss_raw=1.2470, running_loss=1.2988, LR=0.000100
[2025-08-27 01:17:09,768][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022952] [Batch 01392/03080] [00:17:12/00:20:52, 0.742s/it]: train_loss_raw=1.2927, running_loss=1.2991, LR=0.000100
[2025-08-27 01:17:15,691][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022960] [Batch 01400/03080] [00:17:18/00:20:46, 0.742s/it]: train_loss_raw=1.3969, running_loss=1.3002, LR=0.000100
[2025-08-27 01:17:21,590][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022968] [Batch 01408/03080] [00:17:24/00:20:40, 0.742s/it]: train_loss_raw=1.3253, running_loss=1.2999, LR=0.000100
[2025-08-27 01:17:27,601][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022976] [Batch 01416/03080] [00:17:30/00:20:34, 0.742s/it]: train_loss_raw=1.2143, running_loss=1.2991, LR=0.000100
[2025-08-27 01:17:33,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022984] [Batch 01424/03080] [00:17:36/00:20:28, 0.742s/it]: train_loss_raw=1.2847, running_loss=1.2961, LR=0.000100
[2025-08-27 01:17:40,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 022992] [Batch 01432/03080] [00:17:42/00:20:23, 0.742s/it]: train_loss_raw=1.2265, running_loss=1.2910, LR=0.000100
[2025-08-27 01:17:46,230][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023000] [Batch 01440/03080] [00:17:48/00:20:17, 0.742s/it]: train_loss_raw=1.2622, running_loss=1.2911, LR=0.000100
[2025-08-27 01:17:52,237][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023008] [Batch 01448/03080] [00:17:54/00:20:11, 0.742s/it]: train_loss_raw=1.2064, running_loss=1.2889, LR=0.000100
[2025-08-27 01:17:58,253][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023016] [Batch 01456/03080] [00:18:00/00:20:05, 0.742s/it]: train_loss_raw=1.2499, running_loss=1.2896, LR=0.000100
[2025-08-27 01:18:04,221][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023024] [Batch 01464/03080] [00:18:06/00:19:59, 0.742s/it]: train_loss_raw=1.2313, running_loss=1.2877, LR=0.000100
[2025-08-27 01:18:10,091][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023032] [Batch 01472/03080] [00:18:12/00:19:53, 0.742s/it]: train_loss_raw=1.2962, running_loss=1.2877, LR=0.000100
[2025-08-27 01:18:16,235][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023040] [Batch 01480/03080] [00:18:18/00:19:48, 0.743s/it]: train_loss_raw=1.2611, running_loss=1.2852, LR=0.000100
[2025-08-27 01:18:22,142][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023048] [Batch 01488/03080] [00:18:24/00:19:42, 0.743s/it]: train_loss_raw=1.2313, running_loss=1.2845, LR=0.000100
[2025-08-27 01:18:27,791][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023056] [Batch 01496/03080] [00:18:30/00:19:35, 0.742s/it]: train_loss_raw=1.3981, running_loss=1.2893, LR=0.000100
[2025-08-27 01:18:33,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023064] [Batch 01504/03080] [00:18:36/00:19:29, 0.742s/it]: train_loss_raw=1.3568, running_loss=1.2899, LR=0.000100
[2025-08-27 01:18:39,868][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023072] [Batch 01512/03080] [00:18:42/00:19:24, 0.742s/it]: train_loss_raw=1.2498, running_loss=1.2912, LR=0.000100
[2025-08-27 01:18:45,885][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023080] [Batch 01520/03080] [00:18:48/00:19:18, 0.742s/it]: train_loss_raw=1.2395, running_loss=1.2939, LR=0.000100
[2025-08-27 01:18:51,903][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023088] [Batch 01528/03080] [00:18:54/00:19:12, 0.743s/it]: train_loss_raw=1.2817, running_loss=1.2933, LR=0.000100
[2025-08-27 01:18:57,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023096] [Batch 01536/03080] [00:19:00/00:19:06, 0.742s/it]: train_loss_raw=1.2827, running_loss=1.2919, LR=0.000100
[2025-08-27 01:19:03,870][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023104] [Batch 01544/03080] [00:19:06/00:19:00, 0.743s/it]: train_loss_raw=1.2671, running_loss=1.2916, LR=0.000100
[2025-08-27 01:19:09,781][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023112] [Batch 01552/03080] [00:19:12/00:18:54, 0.743s/it]: train_loss_raw=1.1686, running_loss=1.2893, LR=0.000100
[2025-08-27 01:19:15,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023120] [Batch 01560/03080] [00:19:18/00:18:48, 0.743s/it]: train_loss_raw=1.2685, running_loss=1.2887, LR=0.000100
[2025-08-27 01:19:22,015][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023128] [Batch 01568/03080] [00:19:24/00:18:43, 0.743s/it]: train_loss_raw=1.4090, running_loss=1.2927, LR=0.000100
[2025-08-27 01:19:27,680][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023136] [Batch 01576/03080] [00:19:30/00:18:36, 0.743s/it]: train_loss_raw=1.2545, running_loss=1.2887, LR=0.000100
[2025-08-27 01:19:33,377][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023144] [Batch 01584/03080] [00:19:36/00:18:30, 0.742s/it]: train_loss_raw=1.2934, running_loss=1.2883, LR=0.000100
[2025-08-27 01:19:39,214][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023152] [Batch 01592/03080] [00:19:41/00:18:24, 0.742s/it]: train_loss_raw=1.2781, running_loss=1.2875, LR=0.000100
[2025-08-27 01:19:45,107][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023160] [Batch 01600/03080] [00:19:47/00:18:18, 0.742s/it]: train_loss_raw=1.2025, running_loss=1.2869, LR=0.000100
[2025-08-27 01:19:50,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023168] [Batch 01608/03080] [00:19:53/00:18:12, 0.742s/it]: train_loss_raw=1.2026, running_loss=1.2855, LR=0.000100
[2025-08-27 01:19:56,806][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023176] [Batch 01616/03080] [00:19:59/00:18:06, 0.742s/it]: train_loss_raw=1.2419, running_loss=1.2843, LR=0.000100
[2025-08-27 01:20:02,567][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023184] [Batch 01624/03080] [00:20:05/00:18:00, 0.742s/it]: train_loss_raw=1.3013, running_loss=1.2856, LR=0.000100
[2025-08-27 01:20:08,355][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023192] [Batch 01632/03080] [00:20:11/00:17:54, 0.742s/it]: train_loss_raw=1.3181, running_loss=1.2841, LR=0.000100
[2025-08-27 01:20:14,072][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023200] [Batch 01640/03080] [00:20:16/00:17:48, 0.742s/it]: train_loss_raw=1.3064, running_loss=1.2826, LR=0.000100
[2025-08-27 01:20:19,846][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023208] [Batch 01648/03080] [00:20:22/00:17:42, 0.742s/it]: train_loss_raw=1.1563, running_loss=1.2780, LR=0.000100
[2025-08-27 01:20:25,726][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023216] [Batch 01656/03080] [00:20:28/00:17:36, 0.742s/it]: train_loss_raw=1.2639, running_loss=1.2776, LR=0.000100
[2025-08-27 01:20:31,578][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023224] [Batch 01664/03080] [00:20:34/00:17:30, 0.742s/it]: train_loss_raw=1.2265, running_loss=1.2759, LR=0.000100
[2025-08-27 01:20:37,495][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023232] [Batch 01672/03080] [00:20:40/00:17:24, 0.742s/it]: train_loss_raw=1.2898, running_loss=1.2766, LR=0.000100
[2025-08-27 01:20:43,521][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023240] [Batch 01680/03080] [00:20:46/00:17:18, 0.742s/it]: train_loss_raw=1.2860, running_loss=1.2776, LR=0.000100
[2025-08-27 01:20:49,603][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023248] [Batch 01688/03080] [00:20:52/00:17:12, 0.742s/it]: train_loss_raw=1.2955, running_loss=1.2800, LR=0.000100
[2025-08-27 01:20:55,530][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023256] [Batch 01696/03080] [00:20:58/00:17:06, 0.742s/it]: train_loss_raw=1.1931, running_loss=1.2791, LR=0.000100
[2025-08-27 01:21:01,451][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023264] [Batch 01704/03080] [00:21:04/00:17:00, 0.742s/it]: train_loss_raw=1.3190, running_loss=1.2745, LR=0.000100
[2025-08-27 01:21:07,471][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023272] [Batch 01712/03080] [00:21:10/00:16:54, 0.742s/it]: train_loss_raw=1.1361, running_loss=1.2737, LR=0.000100
[2025-08-27 01:21:13,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023280] [Batch 01720/03080] [00:21:16/00:16:49, 0.742s/it]: train_loss_raw=1.2357, running_loss=1.2769, LR=0.000100
[2025-08-27 01:21:19,520][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023288] [Batch 01728/03080] [00:21:22/00:16:43, 0.742s/it]: train_loss_raw=1.3176, running_loss=1.2767, LR=0.000100
[2025-08-27 01:21:25,437][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023296] [Batch 01736/03080] [00:21:28/00:16:37, 0.742s/it]: train_loss_raw=1.3290, running_loss=1.2790, LR=0.000100
[2025-08-27 01:21:31,333][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023304] [Batch 01744/03080] [00:21:34/00:16:31, 0.742s/it]: train_loss_raw=1.2258, running_loss=1.2814, LR=0.000100
[2025-08-27 01:21:37,136][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023312] [Batch 01752/03080] [00:21:39/00:16:25, 0.742s/it]: train_loss_raw=1.2970, running_loss=1.2806, LR=0.000100
[2025-08-27 01:21:42,949][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023320] [Batch 01760/03080] [00:21:45/00:16:19, 0.742s/it]: train_loss_raw=1.2319, running_loss=1.2795, LR=0.000100
[2025-08-27 01:21:49,110][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023328] [Batch 01768/03080] [00:21:51/00:16:13, 0.742s/it]: train_loss_raw=1.3311, running_loss=1.2800, LR=0.000100
[2025-08-27 01:21:55,040][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023336] [Batch 01776/03080] [00:21:57/00:16:07, 0.742s/it]: train_loss_raw=1.2636, running_loss=1.2792, LR=0.000100
[2025-08-27 01:22:00,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023344] [Batch 01784/03080] [00:22:03/00:16:01, 0.742s/it]: train_loss_raw=1.2314, running_loss=1.2778, LR=0.000100
[2025-08-27 01:22:06,738][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023352] [Batch 01792/03080] [00:22:09/00:15:55, 0.742s/it]: train_loss_raw=1.2308, running_loss=1.2776, LR=0.000100
[2025-08-27 01:22:12,694][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023360] [Batch 01800/03080] [00:22:15/00:15:49, 0.742s/it]: train_loss_raw=1.2724, running_loss=1.2767, LR=0.000100
[2025-08-27 01:22:18,537][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023368] [Batch 01808/03080] [00:22:21/00:15:43, 0.742s/it]: train_loss_raw=1.3847, running_loss=1.2803, LR=0.000100
[2025-08-27 01:22:24,276][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023376] [Batch 01816/03080] [00:22:26/00:15:37, 0.742s/it]: train_loss_raw=1.2467, running_loss=1.2800, LR=0.000100
[2025-08-27 01:22:30,217][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023384] [Batch 01824/03080] [00:22:32/00:15:31, 0.742s/it]: train_loss_raw=1.3102, running_loss=1.2810, LR=0.000100
[2025-08-27 01:22:36,055][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023392] [Batch 01832/03080] [00:22:38/00:15:25, 0.742s/it]: train_loss_raw=1.2205, running_loss=1.2783, LR=0.000100
[2025-08-27 01:22:42,003][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023400] [Batch 01840/03080] [00:22:44/00:15:19, 0.742s/it]: train_loss_raw=1.2824, running_loss=1.2784, LR=0.000100
[2025-08-27 01:22:47,738][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023408] [Batch 01848/03080] [00:22:50/00:15:13, 0.742s/it]: train_loss_raw=1.2049, running_loss=1.2757, LR=0.000100
[2025-08-27 01:22:53,494][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023416] [Batch 01856/03080] [00:22:56/00:15:07, 0.741s/it]: train_loss_raw=1.3246, running_loss=1.2760, LR=0.000100
[2025-08-27 01:22:59,308][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023424] [Batch 01864/03080] [00:23:02/00:15:01, 0.741s/it]: train_loss_raw=1.2064, running_loss=1.2750, LR=0.000100
[2025-08-27 01:23:05,132][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023432] [Batch 01872/03080] [00:23:07/00:14:55, 0.741s/it]: train_loss_raw=1.3047, running_loss=1.2748, LR=0.000100
[2025-08-27 01:23:10,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023440] [Batch 01880/03080] [00:23:13/00:14:49, 0.741s/it]: train_loss_raw=1.2169, running_loss=1.2713, LR=0.000100
[2025-08-27 01:23:16,959][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023448] [Batch 01888/03080] [00:23:19/00:14:43, 0.741s/it]: train_loss_raw=1.2915, running_loss=1.2688, LR=0.000100
[2025-08-27 01:23:23,233][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023456] [Batch 01896/03080] [00:23:25/00:14:37, 0.742s/it]: train_loss_raw=1.3013, running_loss=1.2672, LR=0.000100
[2025-08-27 01:23:28,996][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023464] [Batch 01904/03080] [00:23:31/00:14:31, 0.741s/it]: train_loss_raw=1.3386, running_loss=1.2651, LR=0.000100
[2025-08-27 01:23:34,929][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023472] [Batch 01912/03080] [00:23:37/00:14:26, 0.741s/it]: train_loss_raw=1.2960, running_loss=1.2662, LR=0.000100
[2025-08-27 01:23:40,674][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023480] [Batch 01920/03080] [00:23:43/00:14:19, 0.741s/it]: train_loss_raw=1.2642, running_loss=1.2634, LR=0.000100
[2025-08-27 01:23:46,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023488] [Batch 01928/03080] [00:23:49/00:14:13, 0.741s/it]: train_loss_raw=1.3569, running_loss=1.2647, LR=0.000100
[2025-08-27 01:23:52,228][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023496] [Batch 01936/03080] [00:23:54/00:14:07, 0.741s/it]: train_loss_raw=1.3508, running_loss=1.2637, LR=0.000100
[2025-08-27 01:23:58,494][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023504] [Batch 01944/03080] [00:24:01/00:14:02, 0.741s/it]: train_loss_raw=1.3058, running_loss=1.2651, LR=0.000100
[2025-08-27 01:24:04,409][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023512] [Batch 01952/03080] [00:24:07/00:13:56, 0.741s/it]: train_loss_raw=1.2651, running_loss=1.2673, LR=0.000100
[2025-08-27 01:24:10,183][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023520] [Batch 01960/03080] [00:24:12/00:13:50, 0.741s/it]: train_loss_raw=1.1443, running_loss=1.2652, LR=0.000100
[2025-08-27 01:24:15,981][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023528] [Batch 01968/03080] [00:24:18/00:13:44, 0.741s/it]: train_loss_raw=1.2697, running_loss=1.2644, LR=0.000100
[2025-08-27 01:24:22,201][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023536] [Batch 01976/03080] [00:24:24/00:13:38, 0.741s/it]: train_loss_raw=1.3065, running_loss=1.2671, LR=0.000100
[2025-08-27 01:24:28,264][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023544] [Batch 01984/03080] [00:24:30/00:13:32, 0.741s/it]: train_loss_raw=1.2956, running_loss=1.2705, LR=0.000100
[2025-08-27 01:24:34,264][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023552] [Batch 01992/03080] [00:24:36/00:13:26, 0.741s/it]: train_loss_raw=1.0988, running_loss=1.2694, LR=0.000100
[2025-08-27 01:24:40,192][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023560] [Batch 02000/03080] [00:24:42/00:13:20, 0.741s/it]: train_loss_raw=1.3641, running_loss=1.2699, LR=0.000100
[2025-08-27 01:24:46,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023568] [Batch 02008/03080] [00:24:48/00:13:14, 0.741s/it]: train_loss_raw=1.2337, running_loss=1.2688, LR=0.000100
[2025-08-27 01:24:52,160][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023576] [Batch 02016/03080] [00:24:54/00:13:08, 0.742s/it]: train_loss_raw=1.3499, running_loss=1.2687, LR=0.000100
[2025-08-27 01:24:57,975][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023584] [Batch 02024/03080] [00:25:00/00:13:02, 0.741s/it]: train_loss_raw=1.2991, running_loss=1.2682, LR=0.000100
[2025-08-27 01:25:03,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023592] [Batch 02032/03080] [00:25:06/00:12:56, 0.741s/it]: train_loss_raw=1.2586, running_loss=1.2682, LR=0.000100
[2025-08-27 01:25:09,754][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023600] [Batch 02040/03080] [00:25:12/00:12:51, 0.741s/it]: train_loss_raw=1.1794, running_loss=1.2661, LR=0.000100
[2025-08-27 01:25:15,654][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023608] [Batch 02048/03080] [00:25:18/00:12:45, 0.741s/it]: train_loss_raw=1.2259, running_loss=1.2680, LR=0.000100
[2025-08-27 01:25:21,380][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023616] [Batch 02056/03080] [00:25:24/00:12:39, 0.741s/it]: train_loss_raw=1.3694, running_loss=1.2678, LR=0.000100
[2025-08-27 01:25:27,289][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023624] [Batch 02064/03080] [00:25:29/00:12:33, 0.741s/it]: train_loss_raw=1.3338, running_loss=1.2670, LR=0.000100
[2025-08-27 01:25:33,073][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023632] [Batch 02072/03080] [00:25:35/00:12:27, 0.741s/it]: train_loss_raw=1.2075, running_loss=1.2636, LR=0.000100
[2025-08-27 01:25:38,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023640] [Batch 02080/03080] [00:25:41/00:12:21, 0.741s/it]: train_loss_raw=1.1449, running_loss=1.2609, LR=0.000100
[2025-08-27 01:25:45,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023648] [Batch 02088/03080] [00:25:47/00:12:15, 0.741s/it]: train_loss_raw=1.2797, running_loss=1.2599, LR=0.000100
[2025-08-27 01:25:50,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023656] [Batch 02096/03080] [00:25:53/00:12:09, 0.741s/it]: train_loss_raw=1.3583, running_loss=1.2587, LR=0.000100
[2025-08-27 01:25:56,714][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023664] [Batch 02104/03080] [00:25:59/00:12:03, 0.741s/it]: train_loss_raw=1.3452, running_loss=1.2601, LR=0.000100
[2025-08-27 01:26:02,464][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023672] [Batch 02112/03080] [00:26:05/00:11:57, 0.741s/it]: train_loss_raw=1.3591, running_loss=1.2627, LR=0.000100
[2025-08-27 01:26:08,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023680] [Batch 02120/03080] [00:26:11/00:11:51, 0.741s/it]: train_loss_raw=1.2142, running_loss=1.2614, LR=0.000100
[2025-08-27 01:26:14,359][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023688] [Batch 02128/03080] [00:26:17/00:11:45, 0.741s/it]: train_loss_raw=1.1788, running_loss=1.2615, LR=0.000100
[2025-08-27 01:26:20,035][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023696] [Batch 02136/03080] [00:26:22/00:11:39, 0.741s/it]: train_loss_raw=1.3013, running_loss=1.2625, LR=0.000100
[2025-08-27 01:26:25,812][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023704] [Batch 02144/03080] [00:26:28/00:11:33, 0.741s/it]: train_loss_raw=1.2796, running_loss=1.2631, LR=0.000100
[2025-08-27 01:26:31,677][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023712] [Batch 02152/03080] [00:26:34/00:11:27, 0.741s/it]: train_loss_raw=1.2875, running_loss=1.2623, LR=0.000100
[2025-08-27 01:26:37,568][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023720] [Batch 02160/03080] [00:26:40/00:11:21, 0.741s/it]: train_loss_raw=1.2772, running_loss=1.2627, LR=0.000100
[2025-08-27 01:26:43,445][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023728] [Batch 02168/03080] [00:26:46/00:11:15, 0.741s/it]: train_loss_raw=1.2892, running_loss=1.2625, LR=0.000100
[2025-08-27 01:26:49,357][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023736] [Batch 02176/03080] [00:26:52/00:11:09, 0.741s/it]: train_loss_raw=1.2292, running_loss=1.2630, LR=0.000100
[2025-08-27 01:26:55,215][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023744] [Batch 02184/03080] [00:26:57/00:11:03, 0.741s/it]: train_loss_raw=1.2167, running_loss=1.2620, LR=0.000100
[2025-08-27 01:27:01,138][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023752] [Batch 02192/03080] [00:27:03/00:10:57, 0.741s/it]: train_loss_raw=1.2682, running_loss=1.2608, LR=0.000100
[2025-08-27 01:27:07,149][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023760] [Batch 02200/03080] [00:27:09/00:10:51, 0.741s/it]: train_loss_raw=1.2999, running_loss=1.2610, LR=0.000100
[2025-08-27 01:27:13,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023768] [Batch 02208/03080] [00:27:16/00:10:46, 0.741s/it]: train_loss_raw=1.3191, running_loss=1.2638, LR=0.000100
[2025-08-27 01:27:19,580][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023776] [Batch 02216/03080] [00:27:22/00:10:40, 0.741s/it]: train_loss_raw=1.2658, running_loss=1.2654, LR=0.000100
[2025-08-27 01:27:25,545][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023784] [Batch 02224/03080] [00:27:28/00:10:34, 0.741s/it]: train_loss_raw=1.1321, running_loss=1.2632, LR=0.000100
[2025-08-27 01:27:31,643][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023792] [Batch 02232/03080] [00:27:34/00:10:28, 0.741s/it]: train_loss_raw=1.2071, running_loss=1.2612, LR=0.000100
[2025-08-27 01:27:37,621][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023800] [Batch 02240/03080] [00:27:40/00:10:22, 0.741s/it]: train_loss_raw=1.3485, running_loss=1.2615, LR=0.000100
[2025-08-27 01:27:43,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023808] [Batch 02248/03080] [00:27:46/00:10:16, 0.741s/it]: train_loss_raw=1.2819, running_loss=1.2599, LR=0.000100
[2025-08-27 01:27:49,596][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023816] [Batch 02256/03080] [00:27:52/00:10:10, 0.741s/it]: train_loss_raw=1.2208, running_loss=1.2616, LR=0.000100
[2025-08-27 01:27:55,479][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023824] [Batch 02264/03080] [00:27:58/00:10:04, 0.741s/it]: train_loss_raw=1.1886, running_loss=1.2630, LR=0.000100
[2025-08-27 01:28:01,239][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023832] [Batch 02272/03080] [00:28:03/00:09:58, 0.741s/it]: train_loss_raw=1.2364, running_loss=1.2630, LR=0.000100
[2025-08-27 01:28:07,102][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023840] [Batch 02280/03080] [00:28:09/00:09:52, 0.741s/it]: train_loss_raw=1.2726, running_loss=1.2634, LR=0.000100
[2025-08-27 01:28:12,853][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023848] [Batch 02288/03080] [00:28:15/00:09:46, 0.741s/it]: train_loss_raw=1.2239, running_loss=1.2652, LR=0.000100
[2025-08-27 01:28:18,764][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023856] [Batch 02296/03080] [00:28:21/00:09:40, 0.741s/it]: train_loss_raw=1.2543, running_loss=1.2638, LR=0.000100
[2025-08-27 01:28:24,650][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023864] [Batch 02304/03080] [00:28:27/00:09:35, 0.741s/it]: train_loss_raw=1.2833, running_loss=1.2638, LR=0.000100
[2025-08-27 01:28:30,608][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023872] [Batch 02312/03080] [00:28:33/00:09:29, 0.741s/it]: train_loss_raw=1.2947, running_loss=1.2637, LR=0.000100
[2025-08-27 01:28:36,774][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023880] [Batch 02320/03080] [00:28:39/00:09:23, 0.741s/it]: train_loss_raw=1.1942, running_loss=1.2602, LR=0.000100
[2025-08-27 01:28:42,641][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023888] [Batch 02328/03080] [00:28:45/00:09:17, 0.741s/it]: train_loss_raw=1.3200, running_loss=1.2617, LR=0.000100
[2025-08-27 01:28:48,501][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023896] [Batch 02336/03080] [00:28:51/00:09:11, 0.741s/it]: train_loss_raw=1.1429, running_loss=1.2606, LR=0.000100
[2025-08-27 01:28:54,510][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023904] [Batch 02344/03080] [00:28:57/00:09:05, 0.741s/it]: train_loss_raw=1.2823, running_loss=1.2597, LR=0.000100
[2025-08-27 01:29:00,164][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023912] [Batch 02352/03080] [00:29:02/00:08:59, 0.741s/it]: train_loss_raw=1.2304, running_loss=1.2629, LR=0.000100
[2025-08-27 01:29:06,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023920] [Batch 02360/03080] [00:29:08/00:08:53, 0.741s/it]: train_loss_raw=1.2087, running_loss=1.2638, LR=0.000100
[2025-08-27 01:29:12,147][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023928] [Batch 02368/03080] [00:29:14/00:08:47, 0.741s/it]: train_loss_raw=1.2574, running_loss=1.2626, LR=0.000100
[2025-08-27 01:29:18,431][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023936] [Batch 02376/03080] [00:29:21/00:08:41, 0.741s/it]: train_loss_raw=1.2757, running_loss=1.2610, LR=0.000100
[2025-08-27 01:29:24,302][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023944] [Batch 02384/03080] [00:29:27/00:08:35, 0.741s/it]: train_loss_raw=1.3103, running_loss=1.2601, LR=0.000100
[2025-08-27 01:29:30,034][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023952] [Batch 02392/03080] [00:29:32/00:08:29, 0.741s/it]: train_loss_raw=1.2556, running_loss=1.2630, LR=0.000100
[2025-08-27 01:29:35,875][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023960] [Batch 02400/03080] [00:29:38/00:08:23, 0.741s/it]: train_loss_raw=1.2862, running_loss=1.2626, LR=0.000100
[2025-08-27 01:29:41,576][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023968] [Batch 02408/03080] [00:29:44/00:08:17, 0.741s/it]: train_loss_raw=1.2925, running_loss=1.2635, LR=0.000100
[2025-08-27 01:29:47,211][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023976] [Batch 02416/03080] [00:29:49/00:08:11, 0.741s/it]: train_loss_raw=1.3000, running_loss=1.2662, LR=0.000100
[2025-08-27 01:29:52,935][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023984] [Batch 02424/03080] [00:29:55/00:08:05, 0.741s/it]: train_loss_raw=1.2249, running_loss=1.2670, LR=0.000100
[2025-08-27 01:29:58,675][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 023992] [Batch 02432/03080] [00:30:01/00:07:59, 0.741s/it]: train_loss_raw=1.1482, running_loss=1.2660, LR=0.000100
[2025-08-27 01:30:04,411][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024000] [Batch 02440/03080] [00:30:07/00:07:53, 0.741s/it]: train_loss_raw=1.2779, running_loss=1.2657, LR=0.000100
[2025-08-27 01:30:15,184][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024008] [Batch 02448/03080] [00:30:17/00:07:49, 0.743s/it]: train_loss_raw=1.3447, running_loss=1.2650, LR=0.000100
[2025-08-27 01:30:21,152][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024016] [Batch 02456/03080] [00:30:23/00:07:43, 0.743s/it]: train_loss_raw=1.2813, running_loss=1.2668, LR=0.000100
[2025-08-27 01:30:27,074][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024024] [Batch 02464/03080] [00:30:29/00:07:37, 0.743s/it]: train_loss_raw=1.3311, running_loss=1.2661, LR=0.000100
[2025-08-27 01:30:32,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024032] [Batch 02472/03080] [00:30:35/00:07:31, 0.743s/it]: train_loss_raw=1.2306, running_loss=1.2639, LR=0.000100
[2025-08-27 01:30:38,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024040] [Batch 02480/03080] [00:30:41/00:07:25, 0.743s/it]: train_loss_raw=1.2876, running_loss=1.2655, LR=0.000100
[2025-08-27 01:30:44,763][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024048] [Batch 02488/03080] [00:30:47/00:07:19, 0.743s/it]: train_loss_raw=1.2932, running_loss=1.2666, LR=0.000100
[2025-08-27 01:30:50,724][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024056] [Batch 02496/03080] [00:30:53/00:07:13, 0.743s/it]: train_loss_raw=1.2498, running_loss=1.2675, LR=0.000100
[2025-08-27 01:30:57,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024064] [Batch 02504/03080] [00:30:59/00:07:07, 0.743s/it]: train_loss_raw=1.2414, running_loss=1.2660, LR=0.000100
[2025-08-27 01:31:03,163][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024072] [Batch 02512/03080] [00:31:05/00:07:01, 0.743s/it]: train_loss_raw=1.3415, running_loss=1.2625, LR=0.000100
[2025-08-27 01:31:08,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024080] [Batch 02520/03080] [00:31:11/00:06:55, 0.743s/it]: train_loss_raw=1.2870, running_loss=1.2650, LR=0.000100
[2025-08-27 01:31:14,835][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024088] [Batch 02528/03080] [00:31:17/00:06:49, 0.743s/it]: train_loss_raw=1.1681, running_loss=1.2668, LR=0.000100
[2025-08-27 01:31:20,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024096] [Batch 02536/03080] [00:31:23/00:06:44, 0.743s/it]: train_loss_raw=1.1672, running_loss=1.2647, LR=0.000100
[2025-08-27 01:31:26,943][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024104] [Batch 02544/03080] [00:31:29/00:06:38, 0.743s/it]: train_loss_raw=1.2115, running_loss=1.2657, LR=0.000100
[2025-08-27 01:31:32,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024112] [Batch 02552/03080] [00:31:35/00:06:32, 0.743s/it]: train_loss_raw=1.2338, running_loss=1.2650, LR=0.000100
[2025-08-27 01:31:38,730][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024120] [Batch 02560/03080] [00:31:41/00:06:26, 0.743s/it]: train_loss_raw=1.2226, running_loss=1.2640, LR=0.000100
[2025-08-27 01:31:44,653][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024128] [Batch 02568/03080] [00:31:47/00:06:20, 0.743s/it]: train_loss_raw=1.3593, running_loss=1.2620, LR=0.000100
[2025-08-27 01:31:50,500][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024136] [Batch 02576/03080] [00:31:53/00:06:14, 0.743s/it]: train_loss_raw=1.3590, running_loss=1.2604, LR=0.000100
[2025-08-27 01:31:56,473][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024144] [Batch 02584/03080] [00:31:59/00:06:08, 0.743s/it]: train_loss_raw=1.2505, running_loss=1.2615, LR=0.000100
[2025-08-27 01:32:02,633][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024152] [Batch 02592/03080] [00:32:05/00:06:02, 0.743s/it]: train_loss_raw=1.1925, running_loss=1.2623, LR=0.000100
[2025-08-27 01:32:08,444][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024160] [Batch 02600/03080] [00:32:11/00:05:56, 0.743s/it]: train_loss_raw=1.1597, running_loss=1.2606, LR=0.000100
[2025-08-27 01:32:14,192][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024168] [Batch 02608/03080] [00:32:16/00:05:50, 0.743s/it]: train_loss_raw=1.2858, running_loss=1.2588, LR=0.000100
[2025-08-27 01:32:19,906][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024176] [Batch 02616/03080] [00:32:22/00:05:44, 0.743s/it]: train_loss_raw=1.3408, running_loss=1.2583, LR=0.000100
[2025-08-27 01:32:25,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024184] [Batch 02624/03080] [00:32:28/00:05:38, 0.742s/it]: train_loss_raw=1.1633, running_loss=1.2578, LR=0.000100
[2025-08-27 01:32:31,368][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024192] [Batch 02632/03080] [00:32:34/00:05:32, 0.742s/it]: train_loss_raw=1.2986, running_loss=1.2569, LR=0.000100
[2025-08-27 01:32:37,142][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024200] [Batch 02640/03080] [00:32:39/00:05:26, 0.742s/it]: train_loss_raw=1.2326, running_loss=1.2585, LR=0.000100
[2025-08-27 01:32:43,123][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024208] [Batch 02648/03080] [00:32:45/00:05:20, 0.742s/it]: train_loss_raw=1.2774, running_loss=1.2601, LR=0.000100
[2025-08-27 01:32:49,289][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024216] [Batch 02656/03080] [00:32:51/00:05:14, 0.742s/it]: train_loss_raw=1.1778, running_loss=1.2576, LR=0.000100
[2025-08-27 01:32:55,482][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024224] [Batch 02664/03080] [00:32:58/00:05:08, 0.743s/it]: train_loss_raw=1.2612, running_loss=1.2600, LR=0.000100
[2025-08-27 01:33:01,173][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024232] [Batch 02672/03080] [00:33:03/00:05:02, 0.742s/it]: train_loss_raw=1.3030, running_loss=1.2607, LR=0.000100
[2025-08-27 01:33:07,301][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024240] [Batch 02680/03080] [00:33:10/00:04:57, 0.743s/it]: train_loss_raw=1.2024, running_loss=1.2586, LR=0.000100
[2025-08-27 01:33:13,218][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024248] [Batch 02688/03080] [00:33:15/00:04:51, 0.743s/it]: train_loss_raw=1.2534, running_loss=1.2586, LR=0.000100
[2025-08-27 01:33:19,415][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024256] [Batch 02696/03080] [00:33:22/00:04:45, 0.743s/it]: train_loss_raw=1.3461, running_loss=1.2598, LR=0.000100
[2025-08-27 01:33:25,370][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024264] [Batch 02704/03080] [00:33:28/00:04:39, 0.743s/it]: train_loss_raw=1.1441, running_loss=1.2533, LR=0.000100
[2025-08-27 01:33:31,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024272] [Batch 02712/03080] [00:33:34/00:04:33, 0.743s/it]: train_loss_raw=1.2188, running_loss=1.2536, LR=0.000100
[2025-08-27 01:33:37,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024280] [Batch 02720/03080] [00:33:40/00:04:27, 0.743s/it]: train_loss_raw=1.2425, running_loss=1.2533, LR=0.000100
[2025-08-27 01:33:43,527][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024288] [Batch 02728/03080] [00:33:46/00:04:21, 0.743s/it]: train_loss_raw=1.2502, running_loss=1.2556, LR=0.000100
[2025-08-27 01:33:49,417][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024296] [Batch 02736/03080] [00:33:52/00:04:15, 0.743s/it]: train_loss_raw=1.2586, running_loss=1.2539, LR=0.000100
[2025-08-27 01:33:55,229][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024304] [Batch 02744/03080] [00:33:57/00:04:09, 0.743s/it]: train_loss_raw=1.2319, running_loss=1.2520, LR=0.000100
[2025-08-27 01:34:01,322][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024312] [Batch 02752/03080] [00:34:04/00:04:03, 0.743s/it]: train_loss_raw=1.2602, running_loss=1.2538, LR=0.000100
[2025-08-27 01:34:07,503][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024320] [Batch 02760/03080] [00:34:10/00:03:57, 0.743s/it]: train_loss_raw=1.2066, running_loss=1.2554, LR=0.000100
[2025-08-27 01:34:13,612][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024328] [Batch 02768/03080] [00:34:16/00:03:51, 0.743s/it]: train_loss_raw=1.2535, running_loss=1.2560, LR=0.000100
[2025-08-27 01:34:19,605][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024336] [Batch 02776/03080] [00:34:22/00:03:45, 0.743s/it]: train_loss_raw=1.1106, running_loss=1.2525, LR=0.000100
[2025-08-27 01:34:25,415][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024344] [Batch 02784/03080] [00:34:28/00:03:39, 0.743s/it]: train_loss_raw=1.3097, running_loss=1.2531, LR=0.000100
[2025-08-27 01:34:31,313][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024352] [Batch 02792/03080] [00:34:34/00:03:33, 0.743s/it]: train_loss_raw=1.2613, running_loss=1.2528, LR=0.000100
[2025-08-27 01:34:37,316][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024360] [Batch 02800/03080] [00:34:40/00:03:28, 0.743s/it]: train_loss_raw=1.3333, running_loss=1.2548, LR=0.000100
[2025-08-27 01:34:43,357][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024368] [Batch 02808/03080] [00:34:46/00:03:22, 0.743s/it]: train_loss_raw=1.2488, running_loss=1.2561, LR=0.000100
[2025-08-27 01:34:48,895][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024376] [Batch 02816/03080] [00:34:51/00:03:16, 0.743s/it]: train_loss_raw=1.2369, running_loss=1.2569, LR=0.000100
[2025-08-27 01:34:54,851][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024384] [Batch 02824/03080] [00:34:57/00:03:10, 0.743s/it]: train_loss_raw=1.2810, running_loss=1.2569, LR=0.000100
[2025-08-27 01:35:00,626][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024392] [Batch 02832/03080] [00:35:03/00:03:04, 0.743s/it]: train_loss_raw=1.1656, running_loss=1.2545, LR=0.000100
[2025-08-27 01:35:06,555][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024400] [Batch 02840/03080] [00:35:09/00:02:58, 0.743s/it]: train_loss_raw=1.3580, running_loss=1.2562, LR=0.000100
[2025-08-27 01:35:12,525][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024408] [Batch 02848/03080] [00:35:15/00:02:52, 0.743s/it]: train_loss_raw=1.1434, running_loss=1.2568, LR=0.000100
[2025-08-27 01:35:18,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024416] [Batch 02856/03080] [00:35:21/00:02:46, 0.743s/it]: train_loss_raw=1.3087, running_loss=1.2567, LR=0.000100
[2025-08-27 01:35:24,599][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024424] [Batch 02864/03080] [00:35:27/00:02:40, 0.743s/it]: train_loss_raw=1.2051, running_loss=1.2550, LR=0.000100
[2025-08-27 01:35:30,589][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024432] [Batch 02872/03080] [00:35:33/00:02:34, 0.743s/it]: train_loss_raw=1.1733, running_loss=1.2531, LR=0.000100
[2025-08-27 01:35:36,830][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024440] [Batch 02880/03080] [00:35:39/00:02:28, 0.743s/it]: train_loss_raw=1.2745, running_loss=1.2505, LR=0.000100
[2025-08-27 01:35:42,918][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024448] [Batch 02888/03080] [00:35:45/00:02:22, 0.743s/it]: train_loss_raw=1.2141, running_loss=1.2465, LR=0.000100
[2025-08-27 01:35:48,846][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024456] [Batch 02896/03080] [00:35:51/00:02:16, 0.743s/it]: train_loss_raw=1.1472, running_loss=1.2467, LR=0.000100
[2025-08-27 01:35:54,946][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024464] [Batch 02904/03080] [00:35:57/00:02:10, 0.743s/it]: train_loss_raw=1.2591, running_loss=1.2480, LR=0.000100
[2025-08-27 01:36:00,872][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024472] [Batch 02912/03080] [00:36:03/00:02:04, 0.743s/it]: train_loss_raw=1.1060, running_loss=1.2483, LR=0.000100
[2025-08-27 01:36:06,676][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024480] [Batch 02920/03080] [00:36:09/00:01:58, 0.743s/it]: train_loss_raw=1.3540, running_loss=1.2506, LR=0.000100
[2025-08-27 01:36:12,583][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024488] [Batch 02928/03080] [00:36:15/00:01:52, 0.743s/it]: train_loss_raw=1.1816, running_loss=1.2508, LR=0.000100
[2025-08-27 01:36:18,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024496] [Batch 02936/03080] [00:36:21/00:01:46, 0.743s/it]: train_loss_raw=1.1649, running_loss=1.2509, LR=0.000100
[2025-08-27 01:36:24,108][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024504] [Batch 02944/03080] [00:36:26/00:01:41, 0.743s/it]: train_loss_raw=1.2171, running_loss=1.2517, LR=0.000100
[2025-08-27 01:36:29,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024512] [Batch 02952/03080] [00:36:32/00:01:35, 0.743s/it]: train_loss_raw=1.2302, running_loss=1.2531, LR=0.000100
[2025-08-27 01:36:35,841][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024520] [Batch 02960/03080] [00:36:38/00:01:29, 0.743s/it]: train_loss_raw=1.3323, running_loss=1.2548, LR=0.000100
[2025-08-27 01:36:41,634][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024528] [Batch 02968/03080] [00:36:44/00:01:23, 0.743s/it]: train_loss_raw=1.2105, running_loss=1.2517, LR=0.000100
[2025-08-27 01:36:47,810][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024536] [Batch 02976/03080] [00:36:50/00:01:17, 0.743s/it]: train_loss_raw=1.3106, running_loss=1.2542, LR=0.000100
[2025-08-27 01:36:53,875][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024544] [Batch 02984/03080] [00:36:56/00:01:11, 0.743s/it]: train_loss_raw=1.3430, running_loss=1.2544, LR=0.000100
[2025-08-27 01:36:59,868][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024552] [Batch 02992/03080] [00:37:02/00:01:05, 0.743s/it]: train_loss_raw=1.2141, running_loss=1.2527, LR=0.000100
[2025-08-27 01:37:05,628][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024560] [Batch 03000/03080] [00:37:08/00:00:59, 0.743s/it]: train_loss_raw=1.2173, running_loss=1.2544, LR=0.000100
[2025-08-27 01:37:11,495][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024568] [Batch 03008/03080] [00:37:14/00:00:53, 0.743s/it]: train_loss_raw=1.4084, running_loss=1.2555, LR=0.000100
[2025-08-27 01:37:17,519][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024576] [Batch 03016/03080] [00:37:20/00:00:47, 0.743s/it]: train_loss_raw=1.3380, running_loss=1.2517, LR=0.000100
[2025-08-27 01:37:23,453][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024584] [Batch 03024/03080] [00:37:26/00:00:41, 0.743s/it]: train_loss_raw=1.2359, running_loss=1.2514, LR=0.000100
[2025-08-27 01:37:29,543][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024592] [Batch 03032/03080] [00:37:32/00:00:35, 0.743s/it]: train_loss_raw=1.3009, running_loss=1.2530, LR=0.000100
[2025-08-27 01:37:35,619][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024600] [Batch 03040/03080] [00:37:38/00:00:29, 0.743s/it]: train_loss_raw=1.2927, running_loss=1.2528, LR=0.000100
[2025-08-27 01:37:41,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024608] [Batch 03048/03080] [00:37:44/00:00:23, 0.743s/it]: train_loss_raw=1.3618, running_loss=1.2523, LR=0.000100
[2025-08-27 01:37:47,340][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024616] [Batch 03056/03080] [00:37:50/00:00:17, 0.743s/it]: train_loss_raw=1.2374, running_loss=1.2494, LR=0.000100
[2025-08-27 01:37:53,143][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024624] [Batch 03064/03080] [00:37:55/00:00:11, 0.743s/it]: train_loss_raw=1.1737, running_loss=1.2463, LR=0.000100
[2025-08-27 01:37:58,887][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024632] [Batch 03072/03080] [00:38:01/00:00:05, 0.743s/it]: train_loss_raw=1.2627, running_loss=1.2449, LR=0.000100
[2025-08-27 01:38:10,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 024640] [Batch 03080/03080] [00:38:12/00:00:00, 0.744s/it]: train_loss_raw=1.2394, running_loss=1.2437, LR=0.000100
[2025-08-27 01:38:10,582][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-27 01:38:22,481][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00007/00310] [00:00:11/00:07:29, 1.487s/it]
[2025-08-27 01:38:34,762][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00015/00310] [00:00:24/00:07:24, 1.511s/it]
[2025-08-27 01:38:47,314][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00023/00310] [00:00:36/00:07:17, 1.530s/it]
[2025-08-27 01:38:59,802][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00031/00310] [00:00:49/00:07:07, 1.538s/it]
[2025-08-27 01:39:12,606][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00039/00310] [00:01:02/00:06:58, 1.551s/it]
[2025-08-27 01:39:25,692][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00047/00310] [00:01:15/00:06:49, 1.565s/it]
[2025-08-27 01:39:38,505][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00055/00310] [00:01:27/00:06:38, 1.570s/it]
[2025-08-27 01:39:50,931][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00063/00310] [00:01:40/00:06:25, 1.568s/it]
[2025-08-27 01:40:03,631][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00071/00310] [00:01:53/00:06:13, 1.570s/it]
[2025-08-27 01:40:16,486][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00079/00310] [00:02:05/00:06:01, 1.574s/it]
[2025-08-27 01:40:28,924][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00087/00310] [00:02:18/00:05:48, 1.572s/it]
[2025-08-27 01:40:41,522][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00095/00310] [00:02:30/00:05:36, 1.572s/it]
[2025-08-27 01:40:54,277][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00103/00310] [00:02:43/00:05:24, 1.574s/it]
[2025-08-27 01:41:07,103][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00111/00310] [00:02:56/00:05:12, 1.576s/it]
[2025-08-27 01:41:19,999][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00119/00310] [00:03:09/00:04:59, 1.578s/it]
[2025-08-27 01:41:32,680][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00127/00310] [00:03:22/00:04:47, 1.579s/it]
[2025-08-27 01:41:45,778][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00135/00310] [00:03:35/00:04:35, 1.582s/it]
[2025-08-27 01:41:58,482][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00143/00310] [00:03:47/00:04:22, 1.583s/it]
[2025-08-27 01:42:10,080][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00151/00310] [00:03:59/00:04:08, 1.576s/it]
[2025-08-27 01:42:21,904][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00159/00310] [00:04:11/00:03:55, 1.571s/it]
[2025-08-27 01:42:34,820][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00167/00310] [00:04:24/00:03:43, 1.573s/it]
[2025-08-27 01:42:46,285][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00175/00310] [00:04:35/00:03:29, 1.566s/it]
[2025-08-27 01:42:58,151][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00183/00310] [00:04:47/00:03:16, 1.563s/it]
[2025-08-27 01:43:11,110][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00191/00310] [00:05:00/00:03:04, 1.565s/it]
[2025-08-27 01:43:22,842][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00199/00310] [00:05:12/00:02:51, 1.561s/it]
[2025-08-27 01:43:35,423][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00207/00310] [00:05:24/00:02:39, 1.562s/it]
[2025-08-27 01:43:47,326][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00215/00310] [00:05:36/00:02:26, 1.559s/it]
[2025-08-27 01:43:59,266][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00223/00310] [00:05:48/00:02:13, 1.557s/it]
[2025-08-27 01:44:11,858][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00231/00310] [00:06:01/00:02:01, 1.557s/it]
[2025-08-27 01:44:24,166][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00239/00310] [00:06:13/00:01:48, 1.557s/it]
[2025-08-27 01:44:36,010][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00247/00310] [00:06:25/00:01:36, 1.554s/it]
[2025-08-27 01:44:48,633][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00255/00310] [00:06:38/00:01:23, 1.555s/it]
[2025-08-27 01:45:01,711][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00263/00310] [00:06:51/00:01:11, 1.557s/it]
[2025-08-27 01:45:14,376][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00271/00310] [00:07:03/00:00:59, 1.558s/it]
[2025-08-27 01:45:26,503][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00279/00310] [00:07:15/00:00:46, 1.557s/it]
[2025-08-27 01:45:39,460][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00287/00310] [00:07:28/00:00:34, 1.559s/it]
[2025-08-27 01:45:51,232][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00295/00310] [00:07:40/00:00:21, 1.556s/it]
[2025-08-27 01:46:03,835][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 024641] [Batch 00303/00310] [00:07:53/00:00:09, 1.557s/it]
[2025-08-27 01:46:12,881][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.24365, valid_loss=1.95423
[2025-08-27 01:46:12,882][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-27 01:46:12,882][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.745
[2025-08-27 01:46:12,882][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.036
[2025-08-27 01:46:12,882][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.037
[2025-08-27 01:46:12,883][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.009
[2025-08-27 01:46:12,901][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 06:19:26, remaining time 17:23:28, 00:47:25 per epoch
[2025-08-27 01:46:18,941][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024648] [Batch 00008/03080] [00:00:05/00:36:27, 0.712s/it]: train_loss_raw=1.2532, running_loss=1.3738, LR=0.000100
[2025-08-27 01:46:24,988][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024656] [Batch 00016/03080] [00:00:11/00:37:28, 0.734s/it]: train_loss_raw=1.2606, running_loss=1.3632, LR=0.000100
[2025-08-27 01:46:30,765][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024664] [Batch 00024/03080] [00:00:17/00:37:10, 0.730s/it]: train_loss_raw=1.1807, running_loss=1.3531, LR=0.000100
[2025-08-27 01:46:36,838][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024672] [Batch 00032/03080] [00:00:23/00:37:27, 0.737s/it]: train_loss_raw=1.2580, running_loss=1.3439, LR=0.000100
[2025-08-27 01:46:42,758][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024680] [Batch 00040/03080] [00:00:29/00:37:22, 0.738s/it]: train_loss_raw=1.2392, running_loss=1.3342, LR=0.000100
[2025-08-27 01:46:48,581][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024688] [Batch 00048/03080] [00:00:35/00:37:12, 0.736s/it]: train_loss_raw=1.2229, running_loss=1.3244, LR=0.000100
[2025-08-27 01:46:54,682][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024696] [Batch 00056/03080] [00:00:41/00:37:17, 0.740s/it]: train_loss_raw=1.1794, running_loss=1.3170, LR=0.000100
[2025-08-27 01:47:00,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024704] [Batch 00064/03080] [00:00:47/00:37:19, 0.743s/it]: train_loss_raw=1.2340, running_loss=1.3113, LR=0.000100
[2025-08-27 01:47:06,735][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024712] [Batch 00072/03080] [00:00:53/00:37:14, 0.743s/it]: train_loss_raw=1.2779, running_loss=1.3026, LR=0.000100
[2025-08-27 01:47:12,841][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024720] [Batch 00080/03080] [00:00:59/00:37:14, 0.745s/it]: train_loss_raw=1.1885, running_loss=1.2965, LR=0.000100
[2025-08-27 01:47:18,862][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024728] [Batch 00088/03080] [00:01:05/00:37:10, 0.746s/it]: train_loss_raw=1.2475, running_loss=1.2894, LR=0.000100
[2025-08-27 01:47:24,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024736] [Batch 00096/03080] [00:01:11/00:37:06, 0.746s/it]: train_loss_raw=1.3656, running_loss=1.2860, LR=0.000100
[2025-08-27 01:47:30,773][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024744] [Batch 00104/03080] [00:01:17/00:36:58, 0.745s/it]: train_loss_raw=1.1868, running_loss=1.2776, LR=0.000100
[2025-08-27 01:47:36,670][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024752] [Batch 00112/03080] [00:01:23/00:36:50, 0.745s/it]: train_loss_raw=1.2447, running_loss=1.2726, LR=0.000100
[2025-08-27 01:47:42,709][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024760] [Batch 00120/03080] [00:01:29/00:36:46, 0.746s/it]: train_loss_raw=1.3254, running_loss=1.2679, LR=0.000100
[2025-08-27 01:47:48,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024768] [Batch 00128/03080] [00:01:35/00:36:43, 0.746s/it]: train_loss_raw=1.3796, running_loss=1.2657, LR=0.000100
[2025-08-27 01:47:54,786][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024776] [Batch 00136/03080] [00:01:41/00:36:38, 0.747s/it]: train_loss_raw=1.2239, running_loss=1.2590, LR=0.000100
[2025-08-27 01:48:00,710][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024784] [Batch 00144/03080] [00:01:47/00:36:31, 0.746s/it]: train_loss_raw=1.1699, running_loss=1.2557, LR=0.000100
[2025-08-27 01:48:06,898][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024792] [Batch 00152/03080] [00:01:53/00:36:29, 0.748s/it]: train_loss_raw=1.1443, running_loss=1.2525, LR=0.000100
[2025-08-27 01:48:12,791][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024800] [Batch 00160/03080] [00:01:59/00:36:21, 0.747s/it]: train_loss_raw=1.3661, running_loss=1.2532, LR=0.000100
[2025-08-27 01:48:18,799][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024808] [Batch 00168/03080] [00:02:05/00:36:16, 0.747s/it]: train_loss_raw=1.3086, running_loss=1.2517, LR=0.000100
[2025-08-27 01:48:24,733][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024816] [Batch 00176/03080] [00:02:11/00:36:09, 0.747s/it]: train_loss_raw=1.2073, running_loss=1.2522, LR=0.000100
[2025-08-27 01:48:30,758][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024824] [Batch 00184/03080] [00:02:17/00:36:04, 0.747s/it]: train_loss_raw=1.2685, running_loss=1.2498, LR=0.000100
[2025-08-27 01:48:36,816][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024832] [Batch 00192/03080] [00:02:23/00:35:59, 0.748s/it]: train_loss_raw=1.2768, running_loss=1.2510, LR=0.000100
[2025-08-27 01:48:42,700][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024840] [Batch 00200/03080] [00:02:29/00:35:52, 0.747s/it]: train_loss_raw=1.1619, running_loss=1.2452, LR=0.000100
[2025-08-27 01:48:48,830][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024848] [Batch 00208/03080] [00:02:35/00:35:48, 0.748s/it]: train_loss_raw=1.3426, running_loss=1.2436, LR=0.000100
[2025-08-27 01:48:54,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024856] [Batch 00216/03080] [00:02:41/00:35:42, 0.748s/it]: train_loss_raw=1.2171, running_loss=1.2416, LR=0.000100
[2025-08-27 01:49:00,858][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024864] [Batch 00224/03080] [00:02:47/00:35:37, 0.748s/it]: train_loss_raw=1.2457, running_loss=1.2421, LR=0.000100
[2025-08-27 01:49:06,982][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024872] [Batch 00232/03080] [00:02:53/00:35:32, 0.749s/it]: train_loss_raw=1.3169, running_loss=1.2427, LR=0.000100
[2025-08-27 01:49:13,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024880] [Batch 00240/03080] [00:02:59/00:35:28, 0.749s/it]: train_loss_raw=1.2955, running_loss=1.2401, LR=0.000100
[2025-08-27 01:49:18,823][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024888] [Batch 00248/03080] [00:03:05/00:35:19, 0.748s/it]: train_loss_raw=1.3048, running_loss=1.2415, LR=0.000100
[2025-08-27 01:49:24,739][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024896] [Batch 00256/03080] [00:03:11/00:35:12, 0.748s/it]: train_loss_raw=1.1471, running_loss=1.2387, LR=0.000100
[2025-08-27 01:49:30,619][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024904] [Batch 00264/03080] [00:03:17/00:35:05, 0.748s/it]: train_loss_raw=1.3426, running_loss=1.2369, LR=0.000100
[2025-08-27 01:49:36,603][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024912] [Batch 00272/03080] [00:03:23/00:34:59, 0.748s/it]: train_loss_raw=1.3345, running_loss=1.2344, LR=0.000100
[2025-08-27 01:49:42,391][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024920] [Batch 00280/03080] [00:03:29/00:34:51, 0.747s/it]: train_loss_raw=1.2665, running_loss=1.2323, LR=0.000100
[2025-08-27 01:49:48,205][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024928] [Batch 00288/03080] [00:03:34/00:34:43, 0.746s/it]: train_loss_raw=1.3212, running_loss=1.2298, LR=0.000100
[2025-08-27 01:49:53,943][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024936] [Batch 00296/03080] [00:03:40/00:34:35, 0.746s/it]: train_loss_raw=1.2101, running_loss=1.2285, LR=0.000100
[2025-08-27 01:49:59,990][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024944] [Batch 00304/03080] [00:03:46/00:34:30, 0.746s/it]: train_loss_raw=1.2780, running_loss=1.2272, LR=0.000100
[2025-08-27 01:50:06,029][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024952] [Batch 00312/03080] [00:03:52/00:34:25, 0.746s/it]: train_loss_raw=1.1721, running_loss=1.2232, LR=0.000100
[2025-08-27 01:50:11,742][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024960] [Batch 00320/03080] [00:03:58/00:34:17, 0.745s/it]: train_loss_raw=1.2533, running_loss=1.2220, LR=0.000100
[2025-08-27 01:50:17,561][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024968] [Batch 00328/03080] [00:04:04/00:34:09, 0.745s/it]: train_loss_raw=1.2358, running_loss=1.2218, LR=0.000100
[2025-08-27 01:50:23,291][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024976] [Batch 00336/03080] [00:04:10/00:34:02, 0.744s/it]: train_loss_raw=1.2192, running_loss=1.2224, LR=0.000100
[2025-08-27 01:50:29,031][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024984] [Batch 00344/03080] [00:04:15/00:33:54, 0.744s/it]: train_loss_raw=1.1880, running_loss=1.2250, LR=0.000100
[2025-08-27 01:50:35,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 024992] [Batch 00352/03080] [00:04:21/00:33:49, 0.744s/it]: train_loss_raw=1.1418, running_loss=1.2252, LR=0.000100
[2025-08-27 01:50:40,867][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025000] [Batch 00360/03080] [00:04:27/00:33:42, 0.743s/it]: train_loss_raw=1.1635, running_loss=1.2218, LR=0.000100
[2025-08-27 01:50:46,610][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025008] [Batch 00368/03080] [00:04:33/00:33:34, 0.743s/it]: train_loss_raw=1.1943, running_loss=1.2247, LR=0.000100
[2025-08-27 01:50:52,338][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025016] [Batch 00376/03080] [00:04:39/00:33:27, 0.742s/it]: train_loss_raw=1.1841, running_loss=1.2231, LR=0.000100
[2025-08-27 01:50:58,094][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025024] [Batch 00384/03080] [00:04:44/00:33:19, 0.742s/it]: train_loss_raw=1.2474, running_loss=1.2238, LR=0.000100
[2025-08-27 01:51:03,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025032] [Batch 00392/03080] [00:04:50/00:33:13, 0.742s/it]: train_loss_raw=1.1823, running_loss=1.2233, LR=0.000100
[2025-08-27 01:51:09,845][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025040] [Batch 00400/03080] [00:04:56/00:33:07, 0.741s/it]: train_loss_raw=1.2473, running_loss=1.2251, LR=0.000100
[2025-08-27 01:51:15,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025048] [Batch 00408/03080] [00:05:02/00:33:00, 0.741s/it]: train_loss_raw=1.2748, running_loss=1.2236, LR=0.000100
[2025-08-27 01:51:21,755][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025056] [Batch 00416/03080] [00:05:08/00:32:55, 0.742s/it]: train_loss_raw=1.3316, running_loss=1.2258, LR=0.000100
[2025-08-27 01:51:27,597][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025064] [Batch 00424/03080] [00:05:14/00:32:49, 0.741s/it]: train_loss_raw=1.1502, running_loss=1.2235, LR=0.000100
[2025-08-27 01:51:33,534][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025072] [Batch 00432/03080] [00:05:20/00:32:43, 0.741s/it]: train_loss_raw=1.2396, running_loss=1.2223, LR=0.000100
[2025-08-27 01:51:39,472][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025080] [Batch 00440/03080] [00:05:26/00:32:37, 0.741s/it]: train_loss_raw=1.2706, running_loss=1.2231, LR=0.000100
[2025-08-27 01:51:45,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025088] [Batch 00448/03080] [00:05:31/00:32:30, 0.741s/it]: train_loss_raw=1.3043, running_loss=1.2257, LR=0.000100
[2025-08-27 01:51:51,096][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025096] [Batch 00456/03080] [00:05:37/00:32:24, 0.741s/it]: train_loss_raw=1.2602, running_loss=1.2281, LR=0.000100
[2025-08-27 01:51:56,990][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025104] [Batch 00464/03080] [00:05:43/00:32:18, 0.741s/it]: train_loss_raw=1.1723, running_loss=1.2268, LR=0.000100
[2025-08-27 01:52:02,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025112] [Batch 00472/03080] [00:05:49/00:32:11, 0.741s/it]: train_loss_raw=1.1782, running_loss=1.2255, LR=0.000100
[2025-08-27 01:52:08,711][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025120] [Batch 00480/03080] [00:05:55/00:32:05, 0.741s/it]: train_loss_raw=1.1310, running_loss=1.2233, LR=0.000100
[2025-08-27 01:52:14,697][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025128] [Batch 00488/03080] [00:06:01/00:31:59, 0.741s/it]: train_loss_raw=1.2421, running_loss=1.2218, LR=0.000100
[2025-08-27 01:52:20,321][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025136] [Batch 00496/03080] [00:06:07/00:31:52, 0.740s/it]: train_loss_raw=1.2693, running_loss=1.2210, LR=0.000100
[2025-08-27 01:52:26,178][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025144] [Batch 00504/03080] [00:06:12/00:31:46, 0.740s/it]: train_loss_raw=1.2031, running_loss=1.2213, LR=0.000100
[2025-08-27 01:52:32,110][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025152] [Batch 00512/03080] [00:06:18/00:31:40, 0.740s/it]: train_loss_raw=1.1547, running_loss=1.2221, LR=0.000100
[2025-08-27 01:52:38,148][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025160] [Batch 00520/03080] [00:06:24/00:31:34, 0.740s/it]: train_loss_raw=1.1234, running_loss=1.2217, LR=0.000100
[2025-08-27 01:52:44,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025168] [Batch 00528/03080] [00:06:30/00:31:29, 0.740s/it]: train_loss_raw=1.2143, running_loss=1.2227, LR=0.000100
[2025-08-27 01:52:50,196][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025176] [Batch 00536/03080] [00:06:36/00:31:24, 0.741s/it]: train_loss_raw=1.2130, running_loss=1.2215, LR=0.000100
[2025-08-27 01:52:56,254][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025184] [Batch 00544/03080] [00:06:43/00:31:18, 0.741s/it]: train_loss_raw=1.0849, running_loss=1.2177, LR=0.000100
[2025-08-27 01:53:02,108][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025192] [Batch 00552/03080] [00:06:48/00:31:12, 0.741s/it]: train_loss_raw=1.1584, running_loss=1.2165, LR=0.000100
[2025-08-27 01:53:08,224][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025200] [Batch 00560/03080] [00:06:54/00:31:07, 0.741s/it]: train_loss_raw=1.2718, running_loss=1.2182, LR=0.000100
[2025-08-27 01:53:14,163][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025208] [Batch 00568/03080] [00:07:00/00:31:01, 0.741s/it]: train_loss_raw=1.3423, running_loss=1.2164, LR=0.000100
[2025-08-27 01:53:20,251][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025216] [Batch 00576/03080] [00:07:07/00:30:56, 0.741s/it]: train_loss_raw=1.2009, running_loss=1.2175, LR=0.000100
[2025-08-27 01:53:26,113][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025224] [Batch 00584/03080] [00:07:12/00:30:50, 0.741s/it]: train_loss_raw=1.2342, running_loss=1.2177, LR=0.000100
[2025-08-27 01:53:31,904][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025232] [Batch 00592/03080] [00:07:18/00:30:43, 0.741s/it]: train_loss_raw=1.1195, running_loss=1.2174, LR=0.000100
[2025-08-27 01:53:37,670][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025240] [Batch 00600/03080] [00:07:24/00:30:36, 0.741s/it]: train_loss_raw=1.2458, running_loss=1.2179, LR=0.000100
[2025-08-27 01:53:43,580][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025248] [Batch 00608/03080] [00:07:30/00:30:30, 0.741s/it]: train_loss_raw=1.1702, running_loss=1.2162, LR=0.000100
[2025-08-27 01:53:49,708][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025256] [Batch 00616/03080] [00:07:36/00:30:25, 0.741s/it]: train_loss_raw=1.3418, running_loss=1.2170, LR=0.000100
[2025-08-27 01:53:55,495][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025264] [Batch 00624/03080] [00:07:42/00:30:19, 0.741s/it]: train_loss_raw=1.1038, running_loss=1.2128, LR=0.000100
[2025-08-27 01:54:01,553][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025272] [Batch 00632/03080] [00:07:48/00:30:13, 0.741s/it]: train_loss_raw=1.2731, running_loss=1.2116, LR=0.000100
[2025-08-27 01:54:07,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025280] [Batch 00640/03080] [00:07:54/00:30:07, 0.741s/it]: train_loss_raw=1.2324, running_loss=1.2160, LR=0.000100
[2025-08-27 01:54:13,104][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025288] [Batch 00648/03080] [00:07:59/00:30:00, 0.741s/it]: train_loss_raw=1.2288, running_loss=1.2162, LR=0.000100
[2025-08-27 01:54:18,861][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025296] [Batch 00656/03080] [00:08:05/00:29:54, 0.740s/it]: train_loss_raw=1.2152, running_loss=1.2154, LR=0.000100
[2025-08-27 01:54:24,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025304] [Batch 00664/03080] [00:08:11/00:29:48, 0.740s/it]: train_loss_raw=1.2796, running_loss=1.2146, LR=0.000100
[2025-08-27 01:54:30,695][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025312] [Batch 00672/03080] [00:08:17/00:29:42, 0.740s/it]: train_loss_raw=1.2848, running_loss=1.2163, LR=0.000100
[2025-08-27 01:54:36,808][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025320] [Batch 00680/03080] [00:08:23/00:29:37, 0.741s/it]: train_loss_raw=1.2003, running_loss=1.2177, LR=0.000100
[2025-08-27 01:54:42,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025328] [Batch 00688/03080] [00:08:29/00:29:31, 0.741s/it]: train_loss_raw=1.1477, running_loss=1.2173, LR=0.000100
[2025-08-27 01:54:48,881][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025336] [Batch 00696/03080] [00:08:35/00:29:26, 0.741s/it]: train_loss_raw=1.0764, running_loss=1.2165, LR=0.000100
[2025-08-27 01:54:54,915][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025344] [Batch 00704/03080] [00:08:41/00:29:20, 0.741s/it]: train_loss_raw=1.2256, running_loss=1.2159, LR=0.000100
[2025-08-27 01:55:00,851][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025352] [Batch 00712/03080] [00:08:47/00:29:14, 0.741s/it]: train_loss_raw=1.2769, running_loss=1.2160, LR=0.000100
[2025-08-27 01:55:06,783][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025360] [Batch 00720/03080] [00:08:53/00:29:08, 0.741s/it]: train_loss_raw=1.2190, running_loss=1.2156, LR=0.000100
[2025-08-27 01:55:12,616][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025368] [Batch 00728/03080] [00:08:59/00:29:02, 0.741s/it]: train_loss_raw=1.2907, running_loss=1.2146, LR=0.000100
[2025-08-27 01:55:18,595][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025376] [Batch 00736/03080] [00:09:05/00:28:56, 0.741s/it]: train_loss_raw=1.1619, running_loss=1.2148, LR=0.000100
[2025-08-27 01:55:24,621][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025384] [Batch 00744/03080] [00:09:11/00:28:51, 0.741s/it]: train_loss_raw=1.3135, running_loss=1.2179, LR=0.000100
[2025-08-27 01:55:30,524][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025392] [Batch 00752/03080] [00:09:17/00:28:45, 0.741s/it]: train_loss_raw=1.1330, running_loss=1.2164, LR=0.000100
[2025-08-27 01:55:36,414][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025400] [Batch 00760/03080] [00:09:23/00:28:39, 0.741s/it]: train_loss_raw=1.3276, running_loss=1.2178, LR=0.000100
[2025-08-27 01:55:42,267][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025408] [Batch 00768/03080] [00:09:29/00:28:32, 0.741s/it]: train_loss_raw=1.1991, running_loss=1.2185, LR=0.000100
[2025-08-27 01:55:48,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025416] [Batch 00776/03080] [00:09:34/00:28:26, 0.741s/it]: train_loss_raw=1.2092, running_loss=1.2190, LR=0.000100
[2025-08-27 01:55:54,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025424] [Batch 00784/03080] [00:09:40/00:28:20, 0.741s/it]: train_loss_raw=1.2148, running_loss=1.2150, LR=0.000100
[2025-08-27 01:56:00,136][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025432] [Batch 00792/03080] [00:09:46/00:28:15, 0.741s/it]: train_loss_raw=1.2426, running_loss=1.2190, LR=0.000100
[2025-08-27 01:56:06,042][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025440] [Batch 00800/03080] [00:09:52/00:28:09, 0.741s/it]: train_loss_raw=1.1537, running_loss=1.2170, LR=0.000100
[2025-08-27 01:56:11,956][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025448] [Batch 00808/03080] [00:09:58/00:28:03, 0.741s/it]: train_loss_raw=1.3014, running_loss=1.2179, LR=0.000100
[2025-08-27 01:56:17,864][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025456] [Batch 00816/03080] [00:10:04/00:27:57, 0.741s/it]: train_loss_raw=1.2671, running_loss=1.2200, LR=0.000100
[2025-08-27 01:56:23,665][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025464] [Batch 00824/03080] [00:10:10/00:27:51, 0.741s/it]: train_loss_raw=1.3126, running_loss=1.2178, LR=0.000100
[2025-08-27 01:56:29,639][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025472] [Batch 00832/03080] [00:10:16/00:27:45, 0.741s/it]: train_loss_raw=1.2022, running_loss=1.2145, LR=0.000100
[2025-08-27 01:56:35,698][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025480] [Batch 00840/03080] [00:10:22/00:27:39, 0.741s/it]: train_loss_raw=1.1539, running_loss=1.2138, LR=0.000100
[2025-08-27 01:56:41,543][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025488] [Batch 00848/03080] [00:10:28/00:27:33, 0.741s/it]: train_loss_raw=1.1156, running_loss=1.2126, LR=0.000100
[2025-08-27 01:56:47,571][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025496] [Batch 00856/03080] [00:10:34/00:27:28, 0.741s/it]: train_loss_raw=1.2791, running_loss=1.2153, LR=0.000100
[2025-08-27 01:56:53,504][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025504] [Batch 00864/03080] [00:10:40/00:27:22, 0.741s/it]: train_loss_raw=1.2079, running_loss=1.2151, LR=0.000100
[2025-08-27 01:56:59,361][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025512] [Batch 00872/03080] [00:10:46/00:27:16, 0.741s/it]: train_loss_raw=1.1607, running_loss=1.2156, LR=0.000100
[2025-08-27 01:57:05,082][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025520] [Batch 00880/03080] [00:10:51/00:27:09, 0.741s/it]: train_loss_raw=1.2441, running_loss=1.2133, LR=0.000100
[2025-08-27 01:57:10,985][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025528] [Batch 00888/03080] [00:10:57/00:27:03, 0.741s/it]: train_loss_raw=1.2918, running_loss=1.2139, LR=0.000100
[2025-08-27 01:57:16,848][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025536] [Batch 00896/03080] [00:11:03/00:26:57, 0.741s/it]: train_loss_raw=1.2192, running_loss=1.2149, LR=0.000100
[2025-08-27 01:57:23,000][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025544] [Batch 00904/03080] [00:11:09/00:26:52, 0.741s/it]: train_loss_raw=1.3505, running_loss=1.2181, LR=0.000100
[2025-08-27 01:57:28,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025552] [Batch 00912/03080] [00:11:15/00:26:45, 0.741s/it]: train_loss_raw=1.2302, running_loss=1.2170, LR=0.000100
[2025-08-27 01:57:34,528][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025560] [Batch 00920/03080] [00:11:21/00:26:39, 0.741s/it]: train_loss_raw=1.1698, running_loss=1.2141, LR=0.000100
[2025-08-27 01:57:40,136][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025568] [Batch 00928/03080] [00:11:26/00:26:32, 0.740s/it]: train_loss_raw=1.2568, running_loss=1.2153, LR=0.000100
[2025-08-27 01:57:45,881][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025576] [Batch 00936/03080] [00:11:32/00:26:26, 0.740s/it]: train_loss_raw=1.1807, running_loss=1.2132, LR=0.000100
[2025-08-27 01:57:51,851][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025584] [Batch 00944/03080] [00:11:38/00:26:20, 0.740s/it]: train_loss_raw=1.1625, running_loss=1.2132, LR=0.000100
[2025-08-27 01:57:57,678][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025592] [Batch 00952/03080] [00:11:44/00:26:14, 0.740s/it]: train_loss_raw=1.1920, running_loss=1.2121, LR=0.000100
[2025-08-27 01:58:03,674][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025600] [Batch 00960/03080] [00:11:50/00:26:08, 0.740s/it]: train_loss_raw=1.1533, running_loss=1.2116, LR=0.000100
[2025-08-27 01:58:09,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025608] [Batch 00968/03080] [00:11:56/00:26:03, 0.740s/it]: train_loss_raw=1.2447, running_loss=1.2115, LR=0.000100
[2025-08-27 01:58:15,585][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025616] [Batch 00976/03080] [00:12:02/00:25:57, 0.740s/it]: train_loss_raw=1.2288, running_loss=1.2104, LR=0.000100
[2025-08-27 01:58:21,389][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025624] [Batch 00984/03080] [00:12:08/00:25:51, 0.740s/it]: train_loss_raw=1.1332, running_loss=1.2113, LR=0.000100
[2025-08-27 01:58:27,349][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025632] [Batch 00992/03080] [00:12:14/00:25:45, 0.740s/it]: train_loss_raw=1.1100, running_loss=1.2107, LR=0.000100
[2025-08-27 01:58:33,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025640] [Batch 01000/03080] [00:12:19/00:25:38, 0.740s/it]: train_loss_raw=1.2200, running_loss=1.2086, LR=0.000100
[2025-08-27 01:58:38,910][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025648] [Batch 01008/03080] [00:12:25/00:25:32, 0.740s/it]: train_loss_raw=1.1835, running_loss=1.2092, LR=0.000100
[2025-08-27 01:58:44,851][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025656] [Batch 01016/03080] [00:12:31/00:25:26, 0.740s/it]: train_loss_raw=1.2825, running_loss=1.2116, LR=0.000100
[2025-08-27 01:58:50,809][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025664] [Batch 01024/03080] [00:12:37/00:25:21, 0.740s/it]: train_loss_raw=1.1899, running_loss=1.2113, LR=0.000100
[2025-08-27 01:58:56,934][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025672] [Batch 01032/03080] [00:12:43/00:25:15, 0.740s/it]: train_loss_raw=1.2367, running_loss=1.2130, LR=0.000100
[2025-08-27 01:59:03,033][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025680] [Batch 01040/03080] [00:12:49/00:25:09, 0.740s/it]: train_loss_raw=1.2922, running_loss=1.2158, LR=0.000100
[2025-08-27 01:59:09,053][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025688] [Batch 01048/03080] [00:12:55/00:25:04, 0.740s/it]: train_loss_raw=1.1852, running_loss=1.2149, LR=0.000100
[2025-08-27 01:59:14,963][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025696] [Batch 01056/03080] [00:13:01/00:24:58, 0.740s/it]: train_loss_raw=1.1350, running_loss=1.2093, LR=0.000100
[2025-08-27 01:59:20,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025704] [Batch 01064/03080] [00:13:07/00:24:51, 0.740s/it]: train_loss_raw=1.1895, running_loss=1.2081, LR=0.000100
[2025-08-27 01:59:26,562][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025712] [Batch 01072/03080] [00:13:13/00:24:45, 0.740s/it]: train_loss_raw=1.2094, running_loss=1.2102, LR=0.000100
[2025-08-27 01:59:32,450][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025720] [Batch 01080/03080] [00:13:19/00:24:40, 0.740s/it]: train_loss_raw=1.3232, running_loss=1.2084, LR=0.000100
[2025-08-27 01:59:38,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025728] [Batch 01088/03080] [00:13:25/00:24:34, 0.740s/it]: train_loss_raw=1.3182, running_loss=1.2065, LR=0.000100
[2025-08-27 01:59:44,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025736] [Batch 01096/03080] [00:13:30/00:24:27, 0.740s/it]: train_loss_raw=1.2225, running_loss=1.2083, LR=0.000100
[2025-08-27 01:59:49,786][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025744] [Batch 01104/03080] [00:13:36/00:24:21, 0.740s/it]: train_loss_raw=1.1811, running_loss=1.2064, LR=0.000100
[2025-08-27 01:59:55,759][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025752] [Batch 01112/03080] [00:13:42/00:24:15, 0.740s/it]: train_loss_raw=1.1405, running_loss=1.2064, LR=0.000100
[2025-08-27 02:00:01,624][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025760] [Batch 01120/03080] [00:13:48/00:24:09, 0.740s/it]: train_loss_raw=1.1918, running_loss=1.2050, LR=0.000100
[2025-08-27 02:00:07,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025768] [Batch 01128/03080] [00:13:54/00:24:03, 0.740s/it]: train_loss_raw=1.1546, running_loss=1.2039, LR=0.000100
[2025-08-27 02:00:13,539][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025776] [Batch 01136/03080] [00:14:00/00:23:57, 0.740s/it]: train_loss_raw=1.2080, running_loss=1.2048, LR=0.000100
[2025-08-27 02:00:19,682][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025784] [Batch 01144/03080] [00:14:06/00:23:52, 0.740s/it]: train_loss_raw=1.2563, running_loss=1.2037, LR=0.000100
[2025-08-27 02:00:25,619][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025792] [Batch 01152/03080] [00:14:12/00:23:46, 0.740s/it]: train_loss_raw=1.1659, running_loss=1.2053, LR=0.000100
[2025-08-27 02:00:31,644][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025800] [Batch 01160/03080] [00:14:18/00:23:40, 0.740s/it]: train_loss_raw=1.1848, running_loss=1.2050, LR=0.000100
[2025-08-27 02:00:37,597][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025808] [Batch 01168/03080] [00:14:24/00:23:34, 0.740s/it]: train_loss_raw=1.0648, running_loss=1.2032, LR=0.000100
[2025-08-27 02:00:43,476][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025816] [Batch 01176/03080] [00:14:30/00:23:28, 0.740s/it]: train_loss_raw=1.1730, running_loss=1.2042, LR=0.000100
[2025-08-27 02:00:49,615][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025824] [Batch 01184/03080] [00:14:36/00:23:23, 0.740s/it]: train_loss_raw=1.1733, running_loss=1.2054, LR=0.000100
[2025-08-27 02:00:55,369][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025832] [Batch 01192/03080] [00:14:42/00:23:17, 0.740s/it]: train_loss_raw=1.2164, running_loss=1.2069, LR=0.000100
[2025-08-27 02:01:01,132][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025840] [Batch 01200/03080] [00:14:47/00:23:11, 0.740s/it]: train_loss_raw=1.2149, running_loss=1.2059, LR=0.000100
[2025-08-27 02:01:07,068][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025848] [Batch 01208/03080] [00:14:53/00:23:05, 0.740s/it]: train_loss_raw=1.1406, running_loss=1.2067, LR=0.000100
[2025-08-27 02:01:13,037][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025856] [Batch 01216/03080] [00:14:59/00:22:59, 0.740s/it]: train_loss_raw=1.2110, running_loss=1.2091, LR=0.000100
[2025-08-27 02:01:19,112][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025864] [Batch 01224/03080] [00:15:05/00:22:53, 0.740s/it]: train_loss_raw=1.1939, running_loss=1.2086, LR=0.000100
[2025-08-27 02:01:25,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025872] [Batch 01232/03080] [00:15:11/00:22:47, 0.740s/it]: train_loss_raw=1.1861, running_loss=1.2105, LR=0.000100
[2025-08-27 02:01:31,184][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025880] [Batch 01240/03080] [00:15:17/00:22:42, 0.740s/it]: train_loss_raw=1.2173, running_loss=1.2093, LR=0.000100
[2025-08-27 02:01:37,277][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025888] [Batch 01248/03080] [00:15:24/00:22:36, 0.740s/it]: train_loss_raw=1.1738, running_loss=1.2059, LR=0.000100
[2025-08-27 02:01:43,278][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025896] [Batch 01256/03080] [00:15:30/00:22:30, 0.740s/it]: train_loss_raw=1.1821, running_loss=1.2030, LR=0.000100
[2025-08-27 02:01:49,426][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025904] [Batch 01264/03080] [00:15:36/00:22:25, 0.741s/it]: train_loss_raw=1.1181, running_loss=1.2024, LR=0.000100
[2025-08-27 02:01:55,659][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025912] [Batch 01272/03080] [00:15:42/00:22:19, 0.741s/it]: train_loss_raw=1.2146, running_loss=1.2015, LR=0.000100
[2025-08-27 02:02:01,844][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025920] [Batch 01280/03080] [00:15:48/00:22:13, 0.741s/it]: train_loss_raw=1.2182, running_loss=1.2018, LR=0.000100
[2025-08-27 02:02:07,793][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025928] [Batch 01288/03080] [00:15:54/00:22:08, 0.741s/it]: train_loss_raw=1.1955, running_loss=1.2050, LR=0.000100
[2025-08-27 02:02:13,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025936] [Batch 01296/03080] [00:16:00/00:22:01, 0.741s/it]: train_loss_raw=1.1733, running_loss=1.2023, LR=0.000100
[2025-08-27 02:02:19,370][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025944] [Batch 01304/03080] [00:16:06/00:21:55, 0.741s/it]: train_loss_raw=1.0821, running_loss=1.2045, LR=0.000100
[2025-08-27 02:02:25,153][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025952] [Batch 01312/03080] [00:16:11/00:21:49, 0.741s/it]: train_loss_raw=1.0202, running_loss=1.2005, LR=0.000100
[2025-08-27 02:02:30,892][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025960] [Batch 01320/03080] [00:16:17/00:21:43, 0.741s/it]: train_loss_raw=1.2309, running_loss=1.2006, LR=0.000100
[2025-08-27 02:02:36,669][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025968] [Batch 01328/03080] [00:16:23/00:21:37, 0.741s/it]: train_loss_raw=1.2082, running_loss=1.2035, LR=0.000100
[2025-08-27 02:02:42,625][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025976] [Batch 01336/03080] [00:16:29/00:21:31, 0.741s/it]: train_loss_raw=1.3409, running_loss=1.2056, LR=0.000100
[2025-08-27 02:02:48,556][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025984] [Batch 01344/03080] [00:16:35/00:21:25, 0.741s/it]: train_loss_raw=1.1800, running_loss=1.2054, LR=0.000100
[2025-08-27 02:02:54,659][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 025992] [Batch 01352/03080] [00:16:41/00:21:19, 0.741s/it]: train_loss_raw=1.1499, running_loss=1.2032, LR=0.000100
[2025-08-27 02:03:00,722][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026000] [Batch 01360/03080] [00:16:47/00:21:14, 0.741s/it]: train_loss_raw=1.2354, running_loss=1.2056, LR=0.000100
[2025-08-27 02:03:11,346][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026008] [Batch 01368/03080] [00:16:58/00:21:14, 0.744s/it]: train_loss_raw=1.2858, running_loss=1.2023, LR=0.000100
[2025-08-27 02:03:17,362][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026016] [Batch 01376/03080] [00:17:04/00:21:08, 0.744s/it]: train_loss_raw=1.2700, running_loss=1.2031, LR=0.000100
[2025-08-27 02:03:23,306][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026024] [Batch 01384/03080] [00:17:10/00:21:02, 0.744s/it]: train_loss_raw=1.2903, running_loss=1.2047, LR=0.000100
[2025-08-27 02:03:29,191][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026032] [Batch 01392/03080] [00:17:15/00:20:56, 0.744s/it]: train_loss_raw=1.1607, running_loss=1.2045, LR=0.000100
[2025-08-27 02:03:35,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026040] [Batch 01400/03080] [00:17:21/00:20:50, 0.744s/it]: train_loss_raw=1.1457, running_loss=1.2045, LR=0.000100
[2025-08-27 02:03:41,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026048] [Batch 01408/03080] [00:17:28/00:20:44, 0.744s/it]: train_loss_raw=1.1752, running_loss=1.2003, LR=0.000100
[2025-08-27 02:03:47,346][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026056] [Batch 01416/03080] [00:17:34/00:20:38, 0.744s/it]: train_loss_raw=1.2136, running_loss=1.1998, LR=0.000100
[2025-08-27 02:03:53,412][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026064] [Batch 01424/03080] [00:17:40/00:20:32, 0.744s/it]: train_loss_raw=1.1231, running_loss=1.1988, LR=0.000100
[2025-08-27 02:03:59,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026072] [Batch 01432/03080] [00:17:46/00:20:27, 0.745s/it]: train_loss_raw=1.0772, running_loss=1.1974, LR=0.000100
[2025-08-27 02:04:05,766][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026080] [Batch 01440/03080] [00:17:52/00:20:21, 0.745s/it]: train_loss_raw=1.0881, running_loss=1.1967, LR=0.000100
[2025-08-27 02:04:11,939][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026088] [Batch 01448/03080] [00:17:58/00:20:15, 0.745s/it]: train_loss_raw=1.2852, running_loss=1.1965, LR=0.000100
[2025-08-27 02:04:17,942][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026096] [Batch 01456/03080] [00:18:04/00:20:09, 0.745s/it]: train_loss_raw=1.2440, running_loss=1.1980, LR=0.000100
[2025-08-27 02:04:23,814][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026104] [Batch 01464/03080] [00:18:10/00:20:03, 0.745s/it]: train_loss_raw=1.2077, running_loss=1.1951, LR=0.000100
[2025-08-27 02:04:29,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026112] [Batch 01472/03080] [00:18:16/00:19:57, 0.745s/it]: train_loss_raw=1.1602, running_loss=1.1932, LR=0.000100
[2025-08-27 02:04:35,844][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026120] [Batch 01480/03080] [00:18:22/00:19:51, 0.745s/it]: train_loss_raw=1.1761, running_loss=1.1932, LR=0.000100
[2025-08-27 02:04:41,735][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026128] [Batch 01488/03080] [00:18:28/00:19:45, 0.745s/it]: train_loss_raw=1.3243, running_loss=1.1928, LR=0.000100
[2025-08-27 02:04:47,946][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026136] [Batch 01496/03080] [00:18:34/00:19:40, 0.745s/it]: train_loss_raw=1.1988, running_loss=1.1951, LR=0.000100
[2025-08-27 02:04:53,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026144] [Batch 01504/03080] [00:18:40/00:19:34, 0.745s/it]: train_loss_raw=1.1893, running_loss=1.1957, LR=0.000100
[2025-08-27 02:04:59,866][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026152] [Batch 01512/03080] [00:18:46/00:19:28, 0.745s/it]: train_loss_raw=1.1108, running_loss=1.1961, LR=0.000100
[2025-08-27 02:05:06,107][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026160] [Batch 01520/03080] [00:18:52/00:19:22, 0.745s/it]: train_loss_raw=1.2716, running_loss=1.1989, LR=0.000100
[2025-08-27 02:05:12,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026168] [Batch 01528/03080] [00:18:58/00:19:16, 0.745s/it]: train_loss_raw=1.2396, running_loss=1.2013, LR=0.000100
[2025-08-27 02:05:17,725][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026176] [Batch 01536/03080] [00:19:04/00:19:10, 0.745s/it]: train_loss_raw=1.1382, running_loss=1.1997, LR=0.000100
[2025-08-27 02:05:23,843][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026184] [Batch 01544/03080] [00:19:10/00:19:04, 0.745s/it]: train_loss_raw=1.2644, running_loss=1.2023, LR=0.000100
[2025-08-27 02:05:30,025][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026192] [Batch 01552/03080] [00:19:16/00:18:58, 0.745s/it]: train_loss_raw=1.1841, running_loss=1.2008, LR=0.000100
[2025-08-27 02:05:35,828][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026200] [Batch 01560/03080] [00:19:22/00:18:52, 0.745s/it]: train_loss_raw=1.2168, running_loss=1.1989, LR=0.000100
[2025-08-27 02:05:41,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026208] [Batch 01568/03080] [00:19:28/00:18:46, 0.745s/it]: train_loss_raw=1.2303, running_loss=1.2003, LR=0.000100
[2025-08-27 02:05:47,332][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026216] [Batch 01576/03080] [00:19:34/00:18:40, 0.745s/it]: train_loss_raw=1.1579, running_loss=1.1999, LR=0.000100
[2025-08-27 02:05:53,295][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026224] [Batch 01584/03080] [00:19:40/00:18:34, 0.745s/it]: train_loss_raw=1.1360, running_loss=1.1998, LR=0.000100
[2025-08-27 02:05:59,341][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026232] [Batch 01592/03080] [00:19:46/00:18:28, 0.745s/it]: train_loss_raw=1.2967, running_loss=1.2030, LR=0.000100
[2025-08-27 02:06:05,261][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026240] [Batch 01600/03080] [00:19:52/00:18:22, 0.745s/it]: train_loss_raw=1.2486, running_loss=1.2030, LR=0.000100
[2025-08-27 02:06:11,031][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026248] [Batch 01608/03080] [00:19:57/00:18:16, 0.745s/it]: train_loss_raw=1.2672, running_loss=1.2025, LR=0.000100
[2025-08-27 02:06:16,786][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026256] [Batch 01616/03080] [00:20:03/00:18:10, 0.745s/it]: train_loss_raw=1.2540, running_loss=1.2046, LR=0.000100
[2025-08-27 02:06:22,678][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026264] [Batch 01624/03080] [00:20:09/00:18:04, 0.745s/it]: train_loss_raw=1.2137, running_loss=1.2047, LR=0.000100
[2025-08-27 02:06:28,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026272] [Batch 01632/03080] [00:20:15/00:17:58, 0.745s/it]: train_loss_raw=1.0923, running_loss=1.2042, LR=0.000100
[2025-08-27 02:06:34,792][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026280] [Batch 01640/03080] [00:20:21/00:17:52, 0.745s/it]: train_loss_raw=1.2571, running_loss=1.2048, LR=0.000100
[2025-08-27 02:06:40,633][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026288] [Batch 01648/03080] [00:20:27/00:17:46, 0.745s/it]: train_loss_raw=1.2387, running_loss=1.2076, LR=0.000100
[2025-08-27 02:06:46,490][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026296] [Batch 01656/03080] [00:20:33/00:17:40, 0.745s/it]: train_loss_raw=1.0962, running_loss=1.2035, LR=0.000100
[2025-08-27 02:06:52,226][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026304] [Batch 01664/03080] [00:20:38/00:17:34, 0.745s/it]: train_loss_raw=1.2005, running_loss=1.2063, LR=0.000100
[2025-08-27 02:06:58,239][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026312] [Batch 01672/03080] [00:20:44/00:17:28, 0.745s/it]: train_loss_raw=1.1540, running_loss=1.2039, LR=0.000100
[2025-08-27 02:07:04,150][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026320] [Batch 01680/03080] [00:20:50/00:17:22, 0.745s/it]: train_loss_raw=1.2903, running_loss=1.2053, LR=0.000100
[2025-08-27 02:07:10,128][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026328] [Batch 01688/03080] [00:20:56/00:17:16, 0.745s/it]: train_loss_raw=1.1709, running_loss=1.2045, LR=0.000100
[2025-08-27 02:07:16,031][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026336] [Batch 01696/03080] [00:21:02/00:17:10, 0.745s/it]: train_loss_raw=1.1223, running_loss=1.2023, LR=0.000100
[2025-08-27 02:07:22,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026344] [Batch 01704/03080] [00:21:08/00:17:04, 0.745s/it]: train_loss_raw=1.2326, running_loss=1.2021, LR=0.000100
[2025-08-27 02:07:28,248][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026352] [Batch 01712/03080] [00:21:15/00:16:58, 0.745s/it]: train_loss_raw=1.1926, running_loss=1.2031, LR=0.000100
[2025-08-27 02:07:34,057][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026360] [Batch 01720/03080] [00:21:20/00:16:52, 0.745s/it]: train_loss_raw=1.2111, running_loss=1.2068, LR=0.000100
[2025-08-27 02:07:39,991][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026368] [Batch 01728/03080] [00:21:26/00:16:46, 0.745s/it]: train_loss_raw=1.1562, running_loss=1.2043, LR=0.000100
[2025-08-27 02:07:45,936][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026376] [Batch 01736/03080] [00:21:32/00:16:40, 0.745s/it]: train_loss_raw=1.2151, running_loss=1.2033, LR=0.000100
[2025-08-27 02:07:51,820][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026384] [Batch 01744/03080] [00:21:38/00:16:34, 0.745s/it]: train_loss_raw=1.0561, running_loss=1.2032, LR=0.000100
[2025-08-27 02:07:57,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026392] [Batch 01752/03080] [00:21:44/00:16:28, 0.745s/it]: train_loss_raw=1.2802, running_loss=1.2051, LR=0.000100
[2025-08-27 02:08:03,806][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026400] [Batch 01760/03080] [00:21:50/00:16:22, 0.745s/it]: train_loss_raw=1.1648, running_loss=1.2047, LR=0.000100
[2025-08-27 02:08:09,918][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026408] [Batch 01768/03080] [00:21:56/00:16:17, 0.745s/it]: train_loss_raw=1.2758, running_loss=1.2056, LR=0.000100
[2025-08-27 02:08:16,101][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026416] [Batch 01776/03080] [00:22:02/00:16:11, 0.745s/it]: train_loss_raw=1.2133, running_loss=1.2074, LR=0.000100
[2025-08-27 02:08:22,324][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026424] [Batch 01784/03080] [00:22:09/00:16:05, 0.745s/it]: train_loss_raw=1.0833, running_loss=1.2051, LR=0.000100
[2025-08-27 02:08:28,582][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026432] [Batch 01792/03080] [00:22:15/00:15:59, 0.745s/it]: train_loss_raw=1.1112, running_loss=1.1992, LR=0.000100
[2025-08-27 02:08:34,612][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026440] [Batch 01800/03080] [00:22:21/00:15:53, 0.745s/it]: train_loss_raw=1.2528, running_loss=1.2021, LR=0.000100
[2025-08-27 02:08:40,662][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026448] [Batch 01808/03080] [00:22:27/00:15:47, 0.745s/it]: train_loss_raw=1.2768, running_loss=1.2019, LR=0.000100
[2025-08-27 02:08:46,535][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026456] [Batch 01816/03080] [00:22:33/00:15:41, 0.745s/it]: train_loss_raw=1.0928, running_loss=1.2016, LR=0.000100
[2025-08-27 02:08:52,377][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026464] [Batch 01824/03080] [00:22:39/00:15:35, 0.745s/it]: train_loss_raw=1.2013, running_loss=1.1995, LR=0.000100
[2025-08-27 02:08:58,288][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026472] [Batch 01832/03080] [00:22:45/00:15:29, 0.745s/it]: train_loss_raw=1.2323, running_loss=1.1976, LR=0.000100
[2025-08-27 02:09:04,267][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026480] [Batch 01840/03080] [00:22:51/00:15:23, 0.745s/it]: train_loss_raw=1.0928, running_loss=1.1917, LR=0.000100
[2025-08-27 02:09:09,992][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026488] [Batch 01848/03080] [00:22:56/00:15:17, 0.745s/it]: train_loss_raw=1.2447, running_loss=1.1933, LR=0.000100
[2025-08-27 02:09:15,807][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026496] [Batch 01856/03080] [00:23:02/00:15:11, 0.745s/it]: train_loss_raw=1.1275, running_loss=1.1941, LR=0.000100
[2025-08-27 02:09:21,599][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026504] [Batch 01864/03080] [00:23:08/00:15:05, 0.745s/it]: train_loss_raw=1.2774, running_loss=1.1936, LR=0.000100
[2025-08-27 02:09:27,673][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026512] [Batch 01872/03080] [00:23:14/00:14:59, 0.745s/it]: train_loss_raw=1.2306, running_loss=1.1962, LR=0.000100
[2025-08-27 02:09:33,769][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026520] [Batch 01880/03080] [00:23:20/00:14:53, 0.745s/it]: train_loss_raw=1.2273, running_loss=1.1968, LR=0.000100
[2025-08-27 02:09:39,762][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026528] [Batch 01888/03080] [00:23:26/00:14:48, 0.745s/it]: train_loss_raw=1.2402, running_loss=1.1958, LR=0.000100
[2025-08-27 02:09:45,686][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026536] [Batch 01896/03080] [00:23:32/00:14:42, 0.745s/it]: train_loss_raw=1.2645, running_loss=1.1998, LR=0.000100
[2025-08-27 02:09:51,715][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026544] [Batch 01904/03080] [00:23:38/00:14:36, 0.745s/it]: train_loss_raw=1.1133, running_loss=1.1975, LR=0.000100
[2025-08-27 02:09:57,776][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026552] [Batch 01912/03080] [00:23:44/00:14:30, 0.745s/it]: train_loss_raw=1.0962, running_loss=1.1987, LR=0.000100
[2025-08-27 02:10:03,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026560] [Batch 01920/03080] [00:23:50/00:14:24, 0.745s/it]: train_loss_raw=1.1864, running_loss=1.2007, LR=0.000100
[2025-08-27 02:10:09,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026568] [Batch 01928/03080] [00:23:56/00:14:18, 0.745s/it]: train_loss_raw=1.1749, running_loss=1.1991, LR=0.000100
[2025-08-27 02:10:15,465][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026576] [Batch 01936/03080] [00:24:02/00:14:12, 0.745s/it]: train_loss_raw=1.2713, running_loss=1.1989, LR=0.000100
[2025-08-27 02:10:21,619][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026584] [Batch 01944/03080] [00:24:08/00:14:06, 0.745s/it]: train_loss_raw=1.3486, running_loss=1.1994, LR=0.000100
[2025-08-27 02:10:27,710][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026592] [Batch 01952/03080] [00:24:14/00:14:00, 0.745s/it]: train_loss_raw=1.1215, running_loss=1.1974, LR=0.000100
[2025-08-27 02:10:33,633][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026600] [Batch 01960/03080] [00:24:20/00:13:54, 0.745s/it]: train_loss_raw=1.1588, running_loss=1.1968, LR=0.000100
[2025-08-27 02:10:39,763][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026608] [Batch 01968/03080] [00:24:26/00:13:48, 0.745s/it]: train_loss_raw=1.2313, running_loss=1.1964, LR=0.000100
[2025-08-27 02:10:45,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026616] [Batch 01976/03080] [00:24:32/00:13:42, 0.745s/it]: train_loss_raw=1.2301, running_loss=1.1954, LR=0.000100
[2025-08-27 02:10:51,893][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026624] [Batch 01984/03080] [00:24:38/00:13:36, 0.745s/it]: train_loss_raw=1.2623, running_loss=1.1946, LR=0.000100
[2025-08-27 02:10:57,964][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026632] [Batch 01992/03080] [00:24:44/00:13:30, 0.745s/it]: train_loss_raw=1.1787, running_loss=1.1942, LR=0.000100
[2025-08-27 02:11:04,037][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026640] [Batch 02000/03080] [00:24:50/00:13:25, 0.745s/it]: train_loss_raw=1.2697, running_loss=1.1943, LR=0.000100
[2025-08-27 02:11:10,015][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026648] [Batch 02008/03080] [00:24:56/00:13:19, 0.745s/it]: train_loss_raw=1.0917, running_loss=1.1908, LR=0.000100
[2025-08-27 02:11:15,786][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026656] [Batch 02016/03080] [00:25:02/00:13:13, 0.745s/it]: train_loss_raw=1.2168, running_loss=1.1915, LR=0.000100
[2025-08-27 02:11:21,942][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026664] [Batch 02024/03080] [00:25:08/00:13:07, 0.745s/it]: train_loss_raw=1.1923, running_loss=1.1911, LR=0.000100
[2025-08-27 02:11:28,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026672] [Batch 02032/03080] [00:25:14/00:13:01, 0.745s/it]: train_loss_raw=1.1268, running_loss=1.1920, LR=0.000100
[2025-08-27 02:11:34,079][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026680] [Batch 02040/03080] [00:25:20/00:12:55, 0.746s/it]: train_loss_raw=1.0884, running_loss=1.1924, LR=0.000100
[2025-08-27 02:11:40,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026688] [Batch 02048/03080] [00:25:26/00:12:49, 0.746s/it]: train_loss_raw=1.1621, running_loss=1.1915, LR=0.000100
[2025-08-27 02:11:45,922][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026696] [Batch 02056/03080] [00:25:32/00:12:43, 0.745s/it]: train_loss_raw=1.2139, running_loss=1.1918, LR=0.000100
[2025-08-27 02:11:51,891][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026704] [Batch 02064/03080] [00:25:38/00:12:37, 0.745s/it]: train_loss_raw=1.1765, running_loss=1.1920, LR=0.000100
[2025-08-27 02:11:57,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026712] [Batch 02072/03080] [00:25:44/00:12:31, 0.745s/it]: train_loss_raw=1.1536, running_loss=1.1915, LR=0.000100
[2025-08-27 02:12:03,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026720] [Batch 02080/03080] [00:25:50/00:12:25, 0.745s/it]: train_loss_raw=1.0638, running_loss=1.1889, LR=0.000100
[2025-08-27 02:12:09,681][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026728] [Batch 02088/03080] [00:25:56/00:12:19, 0.745s/it]: train_loss_raw=1.1861, running_loss=1.1879, LR=0.000100
[2025-08-27 02:12:15,664][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026736] [Batch 02096/03080] [00:26:02/00:12:13, 0.745s/it]: train_loss_raw=1.2519, running_loss=1.1894, LR=0.000100
[2025-08-27 02:12:21,776][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026744] [Batch 02104/03080] [00:26:08/00:12:07, 0.745s/it]: train_loss_raw=1.1169, running_loss=1.1887, LR=0.000100
[2025-08-27 02:12:27,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026752] [Batch 02112/03080] [00:26:14/00:12:01, 0.746s/it]: train_loss_raw=1.3020, running_loss=1.1897, LR=0.000100
[2025-08-27 02:12:33,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026760] [Batch 02120/03080] [00:26:20/00:11:55, 0.746s/it]: train_loss_raw=1.1983, running_loss=1.1878, LR=0.000100
[2025-08-27 02:12:39,635][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026768] [Batch 02128/03080] [00:26:26/00:11:49, 0.745s/it]: train_loss_raw=1.1685, running_loss=1.1881, LR=0.000100
[2025-08-27 02:12:45,761][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026776] [Batch 02136/03080] [00:26:32/00:11:43, 0.746s/it]: train_loss_raw=1.1737, running_loss=1.1893, LR=0.000100
[2025-08-27 02:12:51,865][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026784] [Batch 02144/03080] [00:26:38/00:11:37, 0.746s/it]: train_loss_raw=1.3028, running_loss=1.1899, LR=0.000100
[2025-08-27 02:12:57,746][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026792] [Batch 02152/03080] [00:26:44/00:11:31, 0.746s/it]: train_loss_raw=1.1111, running_loss=1.1877, LR=0.000100
[2025-08-27 02:13:03,804][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026800] [Batch 02160/03080] [00:26:50/00:11:25, 0.746s/it]: train_loss_raw=1.1631, running_loss=1.1859, LR=0.000100
[2025-08-27 02:13:10,114][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026808] [Batch 02168/03080] [00:26:56/00:11:20, 0.746s/it]: train_loss_raw=1.2431, running_loss=1.1874, LR=0.000100
[2025-08-27 02:13:16,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026816] [Batch 02176/03080] [00:27:02/00:11:14, 0.746s/it]: train_loss_raw=1.1024, running_loss=1.1873, LR=0.000100
[2025-08-27 02:13:22,152][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026824] [Batch 02184/03080] [00:27:08/00:11:08, 0.746s/it]: train_loss_raw=1.2492, running_loss=1.1895, LR=0.000100
[2025-08-27 02:13:28,334][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026832] [Batch 02192/03080] [00:27:15/00:11:02, 0.746s/it]: train_loss_raw=1.1314, running_loss=1.1914, LR=0.000100
[2025-08-27 02:13:34,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026840] [Batch 02200/03080] [00:27:21/00:10:56, 0.746s/it]: train_loss_raw=1.3044, running_loss=1.1919, LR=0.000100
[2025-08-27 02:13:40,438][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026848] [Batch 02208/03080] [00:27:27/00:10:50, 0.746s/it]: train_loss_raw=1.0682, running_loss=1.1916, LR=0.000100
[2025-08-27 02:13:46,632][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026856] [Batch 02216/03080] [00:27:33/00:10:44, 0.746s/it]: train_loss_raw=1.0926, running_loss=1.1907, LR=0.000100
[2025-08-27 02:13:52,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026864] [Batch 02224/03080] [00:27:39/00:10:38, 0.746s/it]: train_loss_raw=1.1200, running_loss=1.1854, LR=0.000100
[2025-08-27 02:13:58,914][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026872] [Batch 02232/03080] [00:27:45/00:10:32, 0.746s/it]: train_loss_raw=1.2311, running_loss=1.1820, LR=0.000100
[2025-08-27 02:14:04,820][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026880] [Batch 02240/03080] [00:27:51/00:10:26, 0.746s/it]: train_loss_raw=1.1579, running_loss=1.1817, LR=0.000100
[2025-08-27 02:14:10,797][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026888] [Batch 02248/03080] [00:27:57/00:10:20, 0.746s/it]: train_loss_raw=1.0647, running_loss=1.1811, LR=0.000100
[2025-08-27 02:14:16,892][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026896] [Batch 02256/03080] [00:28:03/00:10:14, 0.746s/it]: train_loss_raw=1.1416, running_loss=1.1794, LR=0.000100
[2025-08-27 02:14:23,054][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026904] [Batch 02264/03080] [00:28:09/00:10:09, 0.746s/it]: train_loss_raw=1.1312, running_loss=1.1794, LR=0.000100
[2025-08-27 02:14:29,095][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026912] [Batch 02272/03080] [00:28:15/00:10:03, 0.746s/it]: train_loss_raw=1.1902, running_loss=1.1802, LR=0.000100
[2025-08-27 02:14:35,144][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026920] [Batch 02280/03080] [00:28:21/00:09:57, 0.746s/it]: train_loss_raw=1.2086, running_loss=1.1810, LR=0.000100
[2025-08-27 02:14:40,950][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026928] [Batch 02288/03080] [00:28:27/00:09:51, 0.746s/it]: train_loss_raw=1.2480, running_loss=1.1836, LR=0.000100
[2025-08-27 02:14:46,814][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026936] [Batch 02296/03080] [00:28:33/00:09:45, 0.746s/it]: train_loss_raw=1.0005, running_loss=1.1822, LR=0.000100
[2025-08-27 02:14:52,812][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026944] [Batch 02304/03080] [00:28:39/00:09:39, 0.746s/it]: train_loss_raw=1.2312, running_loss=1.1855, LR=0.000100
[2025-08-27 02:14:58,654][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026952] [Batch 02312/03080] [00:28:45/00:09:33, 0.746s/it]: train_loss_raw=1.2271, running_loss=1.1863, LR=0.000100
[2025-08-27 02:15:04,575][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026960] [Batch 02320/03080] [00:28:51/00:09:27, 0.746s/it]: train_loss_raw=1.2296, running_loss=1.1871, LR=0.000100
[2025-08-27 02:15:10,471][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026968] [Batch 02328/03080] [00:28:57/00:09:21, 0.746s/it]: train_loss_raw=1.2868, running_loss=1.1895, LR=0.000100
[2025-08-27 02:15:16,377][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026976] [Batch 02336/03080] [00:29:03/00:09:15, 0.746s/it]: train_loss_raw=1.2321, running_loss=1.1892, LR=0.000100
[2025-08-27 02:15:22,454][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026984] [Batch 02344/03080] [00:29:09/00:09:09, 0.746s/it]: train_loss_raw=1.1311, running_loss=1.1920, LR=0.000100
[2025-08-27 02:15:28,458][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 026992] [Batch 02352/03080] [00:29:15/00:09:03, 0.746s/it]: train_loss_raw=1.2457, running_loss=1.1905, LR=0.000100
[2025-08-27 02:15:34,243][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027000] [Batch 02360/03080] [00:29:20/00:08:57, 0.746s/it]: train_loss_raw=1.1215, running_loss=1.1892, LR=0.000100
[2025-08-27 02:15:39,977][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027008] [Batch 02368/03080] [00:29:26/00:08:51, 0.746s/it]: train_loss_raw=1.1317, running_loss=1.1878, LR=0.000100
[2025-08-27 02:15:46,184][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027016] [Batch 02376/03080] [00:29:32/00:08:45, 0.746s/it]: train_loss_raw=1.1582, running_loss=1.1863, LR=0.000100
[2025-08-27 02:15:52,327][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027024] [Batch 02384/03080] [00:29:39/00:08:39, 0.746s/it]: train_loss_raw=1.1669, running_loss=1.1872, LR=0.000100
[2025-08-27 02:15:58,513][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027032] [Batch 02392/03080] [00:29:45/00:08:33, 0.746s/it]: train_loss_raw=1.2954, running_loss=1.1878, LR=0.000100
[2025-08-27 02:16:04,752][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027040] [Batch 02400/03080] [00:29:51/00:08:27, 0.746s/it]: train_loss_raw=1.1883, running_loss=1.1846, LR=0.000100
[2025-08-27 02:16:10,827][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027048] [Batch 02408/03080] [00:29:57/00:08:21, 0.747s/it]: train_loss_raw=1.2478, running_loss=1.1798, LR=0.000100
[2025-08-27 02:16:16,900][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027056] [Batch 02416/03080] [00:30:03/00:08:15, 0.747s/it]: train_loss_raw=1.1081, running_loss=1.1782, LR=0.000100
[2025-08-27 02:16:22,889][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027064] [Batch 02424/03080] [00:30:09/00:08:09, 0.747s/it]: train_loss_raw=1.0604, running_loss=1.1788, LR=0.000100
[2025-08-27 02:16:28,949][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027072] [Batch 02432/03080] [00:30:15/00:08:03, 0.747s/it]: train_loss_raw=1.0898, running_loss=1.1761, LR=0.000100
[2025-08-27 02:16:34,776][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027080] [Batch 02440/03080] [00:30:21/00:07:57, 0.747s/it]: train_loss_raw=1.1326, running_loss=1.1770, LR=0.000100
[2025-08-27 02:16:40,669][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027088] [Batch 02448/03080] [00:30:27/00:07:51, 0.746s/it]: train_loss_raw=1.1681, running_loss=1.1770, LR=0.000100
[2025-08-27 02:16:46,698][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027096] [Batch 02456/03080] [00:30:33/00:07:45, 0.747s/it]: train_loss_raw=1.2106, running_loss=1.1805, LR=0.000100
[2025-08-27 02:16:52,746][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027104] [Batch 02464/03080] [00:30:39/00:07:39, 0.747s/it]: train_loss_raw=1.2396, running_loss=1.1828, LR=0.000100
[2025-08-27 02:16:58,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027112] [Batch 02472/03080] [00:30:45/00:07:33, 0.747s/it]: train_loss_raw=1.2361, running_loss=1.1822, LR=0.000100
[2025-08-27 02:17:05,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027120] [Batch 02480/03080] [00:30:51/00:07:28, 0.747s/it]: train_loss_raw=1.3236, running_loss=1.1845, LR=0.000100
[2025-08-27 02:17:11,281][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027128] [Batch 02488/03080] [00:30:58/00:07:22, 0.747s/it]: train_loss_raw=1.1433, running_loss=1.1843, LR=0.000100
[2025-08-27 02:17:17,543][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027136] [Batch 02496/03080] [00:31:04/00:07:16, 0.747s/it]: train_loss_raw=1.0654, running_loss=1.1841, LR=0.000100
[2025-08-27 02:17:23,690][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027144] [Batch 02504/03080] [00:31:10/00:07:10, 0.747s/it]: train_loss_raw=1.3094, running_loss=1.1857, LR=0.000100
[2025-08-27 02:17:29,591][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027152] [Batch 02512/03080] [00:31:16/00:07:04, 0.747s/it]: train_loss_raw=1.1726, running_loss=1.1824, LR=0.000100
[2025-08-27 02:17:35,339][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027160] [Batch 02520/03080] [00:31:22/00:06:58, 0.747s/it]: train_loss_raw=1.1720, running_loss=1.1831, LR=0.000100
[2025-08-27 02:17:41,036][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027168] [Batch 02528/03080] [00:31:27/00:06:52, 0.747s/it]: train_loss_raw=1.2145, running_loss=1.1830, LR=0.000100
[2025-08-27 02:17:47,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027176] [Batch 02536/03080] [00:31:33/00:06:46, 0.747s/it]: train_loss_raw=1.2127, running_loss=1.1828, LR=0.000100
[2025-08-27 02:17:53,284][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027184] [Batch 02544/03080] [00:31:40/00:06:40, 0.747s/it]: train_loss_raw=1.2418, running_loss=1.1846, LR=0.000100
[2025-08-27 02:17:59,423][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027192] [Batch 02552/03080] [00:31:46/00:06:34, 0.747s/it]: train_loss_raw=1.2087, running_loss=1.1844, LR=0.000100
[2025-08-27 02:18:05,643][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027200] [Batch 02560/03080] [00:31:52/00:06:28, 0.747s/it]: train_loss_raw=1.0857, running_loss=1.1826, LR=0.000100
[2025-08-27 02:18:11,744][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027208] [Batch 02568/03080] [00:31:58/00:06:22, 0.747s/it]: train_loss_raw=1.2167, running_loss=1.1805, LR=0.000100
[2025-08-27 02:18:17,753][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027216] [Batch 02576/03080] [00:32:04/00:06:16, 0.747s/it]: train_loss_raw=1.1265, running_loss=1.1805, LR=0.000100
[2025-08-27 02:18:23,851][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027224] [Batch 02584/03080] [00:32:10/00:06:10, 0.747s/it]: train_loss_raw=1.1138, running_loss=1.1774, LR=0.000100
[2025-08-27 02:18:29,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027232] [Batch 02592/03080] [00:32:16/00:06:04, 0.747s/it]: train_loss_raw=1.2811, running_loss=1.1775, LR=0.000100
[2025-08-27 02:18:35,947][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027240] [Batch 02600/03080] [00:32:22/00:05:58, 0.747s/it]: train_loss_raw=1.1542, running_loss=1.1800, LR=0.000100
[2025-08-27 02:18:41,955][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027248] [Batch 02608/03080] [00:32:28/00:05:52, 0.747s/it]: train_loss_raw=1.1670, running_loss=1.1801, LR=0.000100
[2025-08-27 02:18:48,055][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027256] [Batch 02616/03080] [00:32:34/00:05:46, 0.747s/it]: train_loss_raw=1.0790, running_loss=1.1812, LR=0.000100
[2025-08-27 02:18:53,977][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027264] [Batch 02624/03080] [00:32:40/00:05:40, 0.747s/it]: train_loss_raw=1.0629, running_loss=1.1796, LR=0.000100
[2025-08-27 02:19:00,026][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027272] [Batch 02632/03080] [00:32:46/00:05:34, 0.747s/it]: train_loss_raw=1.1383, running_loss=1.1788, LR=0.000100
[2025-08-27 02:19:06,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027280] [Batch 02640/03080] [00:32:52/00:05:28, 0.747s/it]: train_loss_raw=1.1836, running_loss=1.1822, LR=0.000100
[2025-08-27 02:19:12,091][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027288] [Batch 02648/03080] [00:32:58/00:05:22, 0.747s/it]: train_loss_raw=1.1762, running_loss=1.1811, LR=0.000100
[2025-08-27 02:19:18,125][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027296] [Batch 02656/03080] [00:33:04/00:05:16, 0.747s/it]: train_loss_raw=1.2713, running_loss=1.1820, LR=0.000100
[2025-08-27 02:19:24,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027304] [Batch 02664/03080] [00:33:10/00:05:10, 0.747s/it]: train_loss_raw=1.2002, running_loss=1.1810, LR=0.000100
[2025-08-27 02:19:30,048][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027312] [Batch 02672/03080] [00:33:16/00:05:04, 0.747s/it]: train_loss_raw=1.2246, running_loss=1.1816, LR=0.000100
[2025-08-27 02:19:35,996][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027320] [Batch 02680/03080] [00:33:22/00:04:58, 0.747s/it]: train_loss_raw=1.1892, running_loss=1.1801, LR=0.000100
[2025-08-27 02:19:42,117][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027328] [Batch 02688/03080] [00:33:28/00:04:52, 0.747s/it]: train_loss_raw=1.1944, running_loss=1.1790, LR=0.000100
[2025-08-27 02:19:47,969][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027336] [Batch 02696/03080] [00:33:34/00:04:46, 0.747s/it]: train_loss_raw=1.2688, running_loss=1.1805, LR=0.000100
[2025-08-27 02:19:53,893][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027344] [Batch 02704/03080] [00:33:40/00:04:40, 0.747s/it]: train_loss_raw=1.0968, running_loss=1.1803, LR=0.000100
[2025-08-27 02:19:59,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027352] [Batch 02712/03080] [00:33:46/00:04:35, 0.747s/it]: train_loss_raw=1.1744, running_loss=1.1804, LR=0.000100
[2025-08-27 02:20:06,106][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027360] [Batch 02720/03080] [00:33:52/00:04:29, 0.747s/it]: train_loss_raw=1.1665, running_loss=1.1785, LR=0.000100
[2025-08-27 02:20:12,247][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027368] [Batch 02728/03080] [00:33:59/00:04:23, 0.747s/it]: train_loss_raw=1.1089, running_loss=1.1786, LR=0.000100
[2025-08-27 02:20:18,129][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027376] [Batch 02736/03080] [00:34:04/00:04:17, 0.747s/it]: train_loss_raw=1.1236, running_loss=1.1753, LR=0.000100
[2025-08-27 02:20:23,913][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027384] [Batch 02744/03080] [00:34:10/00:04:11, 0.747s/it]: train_loss_raw=1.2417, running_loss=1.1756, LR=0.000100
[2025-08-27 02:20:29,775][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027392] [Batch 02752/03080] [00:34:16/00:04:05, 0.747s/it]: train_loss_raw=1.1238, running_loss=1.1751, LR=0.000100
[2025-08-27 02:20:35,621][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027400] [Batch 02760/03080] [00:34:22/00:03:59, 0.747s/it]: train_loss_raw=1.2331, running_loss=1.1751, LR=0.000100
[2025-08-27 02:20:41,558][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027408] [Batch 02768/03080] [00:34:28/00:03:53, 0.747s/it]: train_loss_raw=1.2773, running_loss=1.1782, LR=0.000100
[2025-08-27 02:20:47,550][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027416] [Batch 02776/03080] [00:34:34/00:03:47, 0.747s/it]: train_loss_raw=1.1581, running_loss=1.1780, LR=0.000100
[2025-08-27 02:20:53,552][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027424] [Batch 02784/03080] [00:34:40/00:03:41, 0.747s/it]: train_loss_raw=1.1549, running_loss=1.1787, LR=0.000100
[2025-08-27 02:20:59,456][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027432] [Batch 02792/03080] [00:34:46/00:03:35, 0.747s/it]: train_loss_raw=1.1385, running_loss=1.1790, LR=0.000100
[2025-08-27 02:21:05,440][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027440] [Batch 02800/03080] [00:34:52/00:03:29, 0.747s/it]: train_loss_raw=1.1913, running_loss=1.1767, LR=0.000100
[2025-08-27 02:21:11,480][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027448] [Batch 02808/03080] [00:34:58/00:03:23, 0.747s/it]: train_loss_raw=1.1737, running_loss=1.1787, LR=0.000100
[2025-08-27 02:21:17,641][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027456] [Batch 02816/03080] [00:35:04/00:03:17, 0.747s/it]: train_loss_raw=1.1971, running_loss=1.1768, LR=0.000100
[2025-08-27 02:21:23,631][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027464] [Batch 02824/03080] [00:35:10/00:03:11, 0.747s/it]: train_loss_raw=1.0855, running_loss=1.1781, LR=0.000100
[2025-08-27 02:21:29,404][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027472] [Batch 02832/03080] [00:35:16/00:03:05, 0.747s/it]: train_loss_raw=1.1906, running_loss=1.1787, LR=0.000100
[2025-08-27 02:21:35,259][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027480] [Batch 02840/03080] [00:35:22/00:02:59, 0.747s/it]: train_loss_raw=1.0273, running_loss=1.1812, LR=0.000100
[2025-08-27 02:21:41,013][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027488] [Batch 02848/03080] [00:35:27/00:02:53, 0.747s/it]: train_loss_raw=1.1390, running_loss=1.1814, LR=0.000100
[2025-08-27 02:21:47,173][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027496] [Batch 02856/03080] [00:35:33/00:02:47, 0.747s/it]: train_loss_raw=1.2060, running_loss=1.1810, LR=0.000100
[2025-08-27 02:21:53,407][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027504] [Batch 02864/03080] [00:35:40/00:02:41, 0.747s/it]: train_loss_raw=1.1579, running_loss=1.1791, LR=0.000100
[2025-08-27 02:21:59,156][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027512] [Batch 02872/03080] [00:35:45/00:02:35, 0.747s/it]: train_loss_raw=1.2518, running_loss=1.1785, LR=0.000100
[2025-08-27 02:22:05,293][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027520] [Batch 02880/03080] [00:35:52/00:02:29, 0.747s/it]: train_loss_raw=1.0468, running_loss=1.1804, LR=0.000100
[2025-08-27 02:22:11,436][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027528] [Batch 02888/03080] [00:35:58/00:02:23, 0.747s/it]: train_loss_raw=1.2259, running_loss=1.1773, LR=0.000100
[2025-08-27 02:22:17,456][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027536] [Batch 02896/03080] [00:36:04/00:02:17, 0.747s/it]: train_loss_raw=1.1381, running_loss=1.1768, LR=0.000100
[2025-08-27 02:22:23,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027544] [Batch 02904/03080] [00:36:10/00:02:11, 0.747s/it]: train_loss_raw=1.2198, running_loss=1.1777, LR=0.000100
[2025-08-27 02:22:29,614][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027552] [Batch 02912/03080] [00:36:16/00:02:05, 0.747s/it]: train_loss_raw=1.1625, running_loss=1.1763, LR=0.000100
[2025-08-27 02:22:35,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027560] [Batch 02920/03080] [00:36:22/00:01:59, 0.747s/it]: train_loss_raw=1.1331, running_loss=1.1766, LR=0.000100
[2025-08-27 02:22:41,620][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027568] [Batch 02928/03080] [00:36:28/00:01:53, 0.747s/it]: train_loss_raw=1.1908, running_loss=1.1759, LR=0.000100
[2025-08-27 02:22:47,791][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027576] [Batch 02936/03080] [00:36:34/00:01:47, 0.747s/it]: train_loss_raw=1.2736, running_loss=1.1769, LR=0.000100
[2025-08-27 02:22:53,651][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027584] [Batch 02944/03080] [00:36:40/00:01:41, 0.747s/it]: train_loss_raw=1.2177, running_loss=1.1777, LR=0.000100
[2025-08-27 02:22:59,879][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027592] [Batch 02952/03080] [00:36:46/00:01:35, 0.748s/it]: train_loss_raw=1.2001, running_loss=1.1789, LR=0.000100
[2025-08-27 02:23:06,114][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027600] [Batch 02960/03080] [00:36:52/00:01:29, 0.748s/it]: train_loss_raw=1.1381, running_loss=1.1795, LR=0.000100
[2025-08-27 02:23:12,201][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027608] [Batch 02968/03080] [00:36:58/00:01:23, 0.748s/it]: train_loss_raw=1.1194, running_loss=1.1776, LR=0.000100
[2025-08-27 02:23:18,190][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027616] [Batch 02976/03080] [00:37:04/00:01:17, 0.748s/it]: train_loss_raw=1.1979, running_loss=1.1775, LR=0.000100
[2025-08-27 02:23:24,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027624] [Batch 02984/03080] [00:37:11/00:01:11, 0.748s/it]: train_loss_raw=1.1101, running_loss=1.1761, LR=0.000100
[2025-08-27 02:23:30,486][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027632] [Batch 02992/03080] [00:37:17/00:01:05, 0.748s/it]: train_loss_raw=1.1126, running_loss=1.1739, LR=0.000100
[2025-08-27 02:23:36,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027640] [Batch 03000/03080] [00:37:23/00:00:59, 0.748s/it]: train_loss_raw=1.2264, running_loss=1.1708, LR=0.000100
[2025-08-27 02:23:42,542][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027648] [Batch 03008/03080] [00:37:29/00:00:53, 0.748s/it]: train_loss_raw=1.1910, running_loss=1.1734, LR=0.000100
[2025-08-27 02:23:48,464][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027656] [Batch 03016/03080] [00:37:35/00:00:47, 0.748s/it]: train_loss_raw=1.1371, running_loss=1.1707, LR=0.000100
[2025-08-27 02:23:54,302][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027664] [Batch 03024/03080] [00:37:41/00:00:41, 0.748s/it]: train_loss_raw=1.1430, running_loss=1.1674, LR=0.000100
[2025-08-27 02:24:00,436][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027672] [Batch 03032/03080] [00:37:47/00:00:35, 0.748s/it]: train_loss_raw=1.1840, running_loss=1.1654, LR=0.000100
[2025-08-27 02:24:06,468][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027680] [Batch 03040/03080] [00:37:53/00:00:29, 0.748s/it]: train_loss_raw=1.1406, running_loss=1.1637, LR=0.000100
[2025-08-27 02:24:12,216][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027688] [Batch 03048/03080] [00:37:58/00:00:23, 0.748s/it]: train_loss_raw=1.1147, running_loss=1.1652, LR=0.000100
[2025-08-27 02:24:18,158][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027696] [Batch 03056/03080] [00:38:04/00:00:17, 0.748s/it]: train_loss_raw=1.1313, running_loss=1.1641, LR=0.000100
[2025-08-27 02:24:24,301][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027704] [Batch 03064/03080] [00:38:11/00:00:11, 0.748s/it]: train_loss_raw=1.1864, running_loss=1.1663, LR=0.000100
[2025-08-27 02:24:30,340][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027712] [Batch 03072/03080] [00:38:17/00:00:05, 0.748s/it]: train_loss_raw=1.1501, running_loss=1.1684, LR=0.000100
[2025-08-27 02:24:36,244][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 027720] [Batch 03080/03080] [00:38:22/00:00:00, 0.748s/it]: train_loss_raw=1.0808, running_loss=1.1708, LR=0.000100
[2025-08-27 02:24:36,729][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-27 02:24:47,721][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00007/00310] [00:00:10/00:06:54, 1.374s/it]
[2025-08-27 02:25:00,244][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00015/00310] [00:00:23/00:07:12, 1.470s/it]
[2025-08-27 02:25:12,710][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00023/00310] [00:00:35/00:07:08, 1.499s/it]
[2025-08-27 02:25:25,253][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00031/00310] [00:00:48/00:07:01, 1.516s/it]
[2025-08-27 02:25:38,250][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00039/00310] [00:01:01/00:06:55, 1.538s/it]
[2025-08-27 02:25:51,037][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00047/00310] [00:01:14/00:06:45, 1.548s/it]
[2025-08-27 02:26:03,771][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00055/00310] [00:01:27/00:06:34, 1.554s/it]
[2025-08-27 02:26:16,015][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00063/00310] [00:01:39/00:06:21, 1.551s/it]
[2025-08-27 02:26:28,645][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00071/00310] [00:01:51/00:06:09, 1.554s/it]
[2025-08-27 02:26:41,173][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00079/00310] [00:02:04/00:05:57, 1.556s/it]
[2025-08-27 02:26:54,707][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00087/00310] [00:02:17/00:05:48, 1.568s/it]
[2025-08-27 02:27:07,265][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00095/00310] [00:02:30/00:05:35, 1.568s/it]
[2025-08-27 02:27:20,016][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00103/00310] [00:02:43/00:05:23, 1.570s/it]
[2025-08-27 02:27:32,692][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00111/00310] [00:02:55/00:05:11, 1.571s/it]
[2025-08-27 02:27:45,422][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00119/00310] [00:03:08/00:04:58, 1.572s/it]
[2025-08-27 02:27:58,178][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00127/00310] [00:03:21/00:04:46, 1.574s/it]
[2025-08-27 02:28:11,159][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00135/00310] [00:03:34/00:04:34, 1.577s/it]
[2025-08-27 02:28:23,605][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00143/00310] [00:03:46/00:04:21, 1.576s/it]
[2025-08-27 02:28:35,565][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00151/00310] [00:03:58/00:04:08, 1.571s/it]
[2025-08-27 02:28:47,035][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00159/00310] [00:04:10/00:03:54, 1.564s/it]
[2025-08-27 02:28:59,827][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00167/00310] [00:04:23/00:03:42, 1.566s/it]
[2025-08-27 02:29:11,728][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00175/00310] [00:04:34/00:03:29, 1.562s/it]
[2025-08-27 02:29:23,599][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00183/00310] [00:04:46/00:03:16, 1.559s/it]
[2025-08-27 02:29:35,950][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00191/00310] [00:04:59/00:03:03, 1.558s/it]
[2025-08-27 02:29:48,191][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00199/00310] [00:05:11/00:02:51, 1.557s/it]
[2025-08-27 02:30:00,083][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00207/00310] [00:05:23/00:02:38, 1.555s/it]
[2025-08-27 02:30:11,814][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00215/00310] [00:05:35/00:02:25, 1.551s/it]
[2025-08-27 02:30:24,588][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00223/00310] [00:05:47/00:02:13, 1.553s/it]
[2025-08-27 02:30:37,027][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00231/00310] [00:06:00/00:02:01, 1.553s/it]
[2025-08-27 02:30:49,071][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00239/00310] [00:06:12/00:01:48, 1.551s/it]
[2025-08-27 02:31:01,078][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00247/00310] [00:06:24/00:01:36, 1.550s/it]
[2025-08-27 02:31:13,587][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00255/00310] [00:06:36/00:01:23, 1.550s/it]
[2025-08-27 02:31:26,428][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00263/00310] [00:06:49/00:01:11, 1.552s/it]
[2025-08-27 02:31:38,535][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00271/00310] [00:07:01/00:00:58, 1.551s/it]
[2025-08-27 02:31:50,933][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00279/00310] [00:07:14/00:00:46, 1.551s/it]
[2025-08-27 02:32:04,000][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00287/00310] [00:07:27/00:00:34, 1.553s/it]
[2025-08-27 02:32:16,256][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00295/00310] [00:07:39/00:00:21, 1.552s/it]
[2025-08-27 02:32:29,414][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 027721] [Batch 00303/00310] [00:07:52/00:00:09, 1.555s/it]
[2025-08-27 02:32:39,353][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.17077, valid_loss=1.91981
[2025-08-27 02:32:39,353][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-27 02:32:39,353][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.733
[2025-08-27 02:32:39,353][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.039
[2025-08-27 02:32:39,355][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.041
[2025-08-27 02:32:39,355][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.012
[2025-08-27 02:32:39,375][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 07:05:53, remaining time 16:33:44, 00:47:19 per epoch
[2025-08-27 02:32:46,100][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027728] [Batch 00008/03080] [00:00:05/00:35:16, 0.689s/it]: train_loss_raw=1.1024, running_loss=1.1549, LR=0.000100
[2025-08-27 02:32:52,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027736] [Batch 00016/03080] [00:00:11/00:37:05, 0.726s/it]: train_loss_raw=1.1516, running_loss=1.1537, LR=0.000100
[2025-08-27 02:32:58,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027744] [Batch 00024/03080] [00:00:17/00:37:44, 0.741s/it]: train_loss_raw=1.1548, running_loss=1.1538, LR=0.000100
[2025-08-27 02:33:04,299][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027752] [Batch 00032/03080] [00:00:23/00:37:38, 0.741s/it]: train_loss_raw=1.1935, running_loss=1.1537, LR=0.000100
[2025-08-27 02:33:10,379][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027760] [Batch 00040/03080] [00:00:29/00:37:44, 0.745s/it]: train_loss_raw=1.1021, running_loss=1.1548, LR=0.000100
[2025-08-27 02:33:16,457][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027768] [Batch 00048/03080] [00:00:35/00:37:45, 0.747s/it]: train_loss_raw=1.0787, running_loss=1.1541, LR=0.000100
[2025-08-27 02:33:22,526][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027776] [Batch 00056/03080] [00:00:41/00:37:44, 0.749s/it]: train_loss_raw=1.1257, running_loss=1.1555, LR=0.000100
[2025-08-27 02:33:28,691][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027784] [Batch 00064/03080] [00:00:48/00:37:46, 0.752s/it]: train_loss_raw=1.1283, running_loss=1.1561, LR=0.000100
[2025-08-27 02:33:34,871][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027792] [Batch 00072/03080] [00:00:54/00:37:47, 0.754s/it]: train_loss_raw=1.1862, running_loss=1.1579, LR=0.000100
[2025-08-27 02:33:40,885][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027800] [Batch 00080/03080] [00:01:00/00:37:41, 0.754s/it]: train_loss_raw=1.1452, running_loss=1.1583, LR=0.000100
[2025-08-27 02:33:47,034][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027808] [Batch 00088/03080] [00:01:06/00:37:39, 0.755s/it]: train_loss_raw=1.2493, running_loss=1.1604, LR=0.000100
[2025-08-27 02:33:53,046][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027816] [Batch 00096/03080] [00:01:12/00:37:32, 0.755s/it]: train_loss_raw=1.1882, running_loss=1.1617, LR=0.000100
[2025-08-27 02:33:59,124][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027824] [Batch 00104/03080] [00:01:18/00:37:27, 0.755s/it]: train_loss_raw=1.1126, running_loss=1.1620, LR=0.000100
[2025-08-27 02:34:05,301][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027832] [Batch 00112/03080] [00:01:24/00:37:24, 0.756s/it]: train_loss_raw=1.0427, running_loss=1.1586, LR=0.000100
[2025-08-27 02:34:11,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027840] [Batch 00120/03080] [00:01:30/00:37:12, 0.754s/it]: train_loss_raw=1.0160, running_loss=1.1536, LR=0.000100
[2025-08-27 02:34:16,931][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027848] [Batch 00128/03080] [00:01:36/00:37:01, 0.753s/it]: train_loss_raw=1.2498, running_loss=1.1555, LR=0.000100
[2025-08-27 02:34:22,824][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027856] [Batch 00136/03080] [00:01:42/00:36:53, 0.752s/it]: train_loss_raw=1.2468, running_loss=1.1539, LR=0.000100
[2025-08-27 02:34:28,760][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027864] [Batch 00144/03080] [00:01:48/00:36:45, 0.751s/it]: train_loss_raw=1.1777, running_loss=1.1572, LR=0.000100
[2025-08-27 02:34:34,917][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027872] [Batch 00152/03080] [00:01:54/00:36:42, 0.752s/it]: train_loss_raw=1.2071, running_loss=1.1601, LR=0.000100
[2025-08-27 02:34:40,874][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027880] [Batch 00160/03080] [00:02:00/00:36:35, 0.752s/it]: train_loss_raw=1.0954, running_loss=1.1589, LR=0.000100
[2025-08-27 02:34:46,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027888] [Batch 00168/03080] [00:02:06/00:36:27, 0.751s/it]: train_loss_raw=1.0924, running_loss=1.1611, LR=0.000100
[2025-08-27 02:34:52,680][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027896] [Batch 00176/03080] [00:02:12/00:36:19, 0.751s/it]: train_loss_raw=1.1500, running_loss=1.1607, LR=0.000100
[2025-08-27 02:34:58,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027904] [Batch 00184/03080] [00:02:18/00:36:13, 0.750s/it]: train_loss_raw=1.1980, running_loss=1.1595, LR=0.000100
[2025-08-27 02:35:04,587][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027912] [Batch 00192/03080] [00:02:23/00:36:05, 0.750s/it]: train_loss_raw=1.0541, running_loss=1.1602, LR=0.000100
[2025-08-27 02:35:10,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027920] [Batch 00200/03080] [00:02:29/00:35:59, 0.750s/it]: train_loss_raw=1.1741, running_loss=1.1626, LR=0.000100
[2025-08-27 02:35:16,436][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027928] [Batch 00208/03080] [00:02:35/00:35:51, 0.749s/it]: train_loss_raw=1.0419, running_loss=1.1642, LR=0.000100
[2025-08-27 02:35:22,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027936] [Batch 00216/03080] [00:02:41/00:35:45, 0.749s/it]: train_loss_raw=1.2531, running_loss=1.1663, LR=0.000100
[2025-08-27 02:35:28,345][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027944] [Batch 00224/03080] [00:02:47/00:35:38, 0.749s/it]: train_loss_raw=1.1236, running_loss=1.1666, LR=0.000100
[2025-08-27 02:35:34,443][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027952] [Batch 00232/03080] [00:02:53/00:35:34, 0.749s/it]: train_loss_raw=1.1536, running_loss=1.1670, LR=0.000100
[2025-08-27 02:35:40,432][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027960] [Batch 00240/03080] [00:02:59/00:35:28, 0.749s/it]: train_loss_raw=1.0752, running_loss=1.1637, LR=0.000100
[2025-08-27 02:35:46,457][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027968] [Batch 00248/03080] [00:03:05/00:35:22, 0.749s/it]: train_loss_raw=1.2742, running_loss=1.1632, LR=0.000100
[2025-08-27 02:35:52,392][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027976] [Batch 00256/03080] [00:03:11/00:35:15, 0.749s/it]: train_loss_raw=1.2165, running_loss=1.1645, LR=0.000100
[2025-08-27 02:35:58,139][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027984] [Batch 00264/03080] [00:03:17/00:35:07, 0.748s/it]: train_loss_raw=1.2463, running_loss=1.1662, LR=0.000100
[2025-08-27 02:36:04,224][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 027992] [Batch 00272/03080] [00:03:23/00:35:02, 0.749s/it]: train_loss_raw=1.1497, running_loss=1.1650, LR=0.000100
[2025-08-27 02:36:10,235][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028000] [Batch 00280/03080] [00:03:29/00:34:56, 0.749s/it]: train_loss_raw=1.1584, running_loss=1.1643, LR=0.000100
[2025-08-27 02:36:21,094][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028008] [Batch 00288/03080] [00:03:40/00:35:37, 0.766s/it]: train_loss_raw=1.1494, running_loss=1.1621, LR=0.000100
[2025-08-27 02:36:27,246][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028016] [Batch 00296/03080] [00:03:46/00:35:31, 0.766s/it]: train_loss_raw=1.2836, running_loss=1.1613, LR=0.000100
[2025-08-27 02:36:33,428][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028024] [Batch 00304/03080] [00:03:52/00:35:26, 0.766s/it]: train_loss_raw=1.1577, running_loss=1.1629, LR=0.000100
[2025-08-27 02:36:39,551][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028032] [Batch 00312/03080] [00:03:58/00:35:20, 0.766s/it]: train_loss_raw=1.0699, running_loss=1.1597, LR=0.000100
[2025-08-27 02:36:45,554][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028040] [Batch 00320/03080] [00:04:04/00:35:12, 0.766s/it]: train_loss_raw=1.1404, running_loss=1.1568, LR=0.000100
[2025-08-27 02:36:51,498][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028048] [Batch 00328/03080] [00:04:10/00:35:05, 0.765s/it]: train_loss_raw=1.0935, running_loss=1.1590, LR=0.000100
[2025-08-27 02:36:57,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028056] [Batch 00336/03080] [00:04:16/00:34:55, 0.764s/it]: train_loss_raw=1.1345, running_loss=1.1563, LR=0.000100
[2025-08-27 02:37:02,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028064] [Batch 00344/03080] [00:04:22/00:34:46, 0.762s/it]: train_loss_raw=1.1853, running_loss=1.1550, LR=0.000100
[2025-08-27 02:37:08,909][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028072] [Batch 00352/03080] [00:04:28/00:34:39, 0.762s/it]: train_loss_raw=1.2272, running_loss=1.1568, LR=0.000100
[2025-08-27 02:37:14,865][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028080] [Batch 00360/03080] [00:04:34/00:34:32, 0.762s/it]: train_loss_raw=1.2125, running_loss=1.1594, LR=0.000100
[2025-08-27 02:37:20,993][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028088] [Batch 00368/03080] [00:04:40/00:34:26, 0.762s/it]: train_loss_raw=1.2315, running_loss=1.1608, LR=0.000100
[2025-08-27 02:37:27,149][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028096] [Batch 00376/03080] [00:04:46/00:34:20, 0.762s/it]: train_loss_raw=1.0497, running_loss=1.1611, LR=0.000100
[2025-08-27 02:37:33,425][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028104] [Batch 00384/03080] [00:04:52/00:34:15, 0.763s/it]: train_loss_raw=1.0717, running_loss=1.1594, LR=0.000100
[2025-08-27 02:37:39,639][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028112] [Batch 00392/03080] [00:04:59/00:34:10, 0.763s/it]: train_loss_raw=1.1497, running_loss=1.1615, LR=0.000100
[2025-08-27 02:37:45,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028120] [Batch 00400/03080] [00:05:05/00:34:04, 0.763s/it]: train_loss_raw=1.1717, running_loss=1.1607, LR=0.000100
[2025-08-27 02:37:51,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028128] [Batch 00408/03080] [00:05:11/00:33:57, 0.762s/it]: train_loss_raw=1.1218, running_loss=1.1631, LR=0.000100
[2025-08-27 02:37:57,808][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028136] [Batch 00416/03080] [00:05:17/00:33:51, 0.763s/it]: train_loss_raw=1.2223, running_loss=1.1633, LR=0.000100
[2025-08-27 02:38:04,070][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028144] [Batch 00424/03080] [00:05:23/00:33:46, 0.763s/it]: train_loss_raw=1.2920, running_loss=1.1624, LR=0.000100
[2025-08-27 02:38:10,258][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028152] [Batch 00432/03080] [00:05:29/00:33:40, 0.763s/it]: train_loss_raw=1.2056, running_loss=1.1630, LR=0.000100
[2025-08-27 02:38:16,066][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028160] [Batch 00440/03080] [00:05:35/00:33:32, 0.762s/it]: train_loss_raw=1.2900, running_loss=1.1657, LR=0.000100
[2025-08-27 02:38:22,138][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028168] [Batch 00448/03080] [00:05:41/00:33:26, 0.762s/it]: train_loss_raw=1.2089, running_loss=1.1667, LR=0.000100
[2025-08-27 02:38:28,182][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028176] [Batch 00456/03080] [00:05:47/00:33:20, 0.762s/it]: train_loss_raw=1.1917, running_loss=1.1649, LR=0.000100
[2025-08-27 02:38:34,421][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028184] [Batch 00464/03080] [00:05:53/00:33:14, 0.763s/it]: train_loss_raw=1.1054, running_loss=1.1632, LR=0.000100
[2025-08-27 02:38:40,644][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028192] [Batch 00472/03080] [00:06:00/00:33:09, 0.763s/it]: train_loss_raw=1.1101, running_loss=1.1650, LR=0.000100
[2025-08-27 02:38:46,736][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028200] [Batch 00480/03080] [00:06:06/00:33:03, 0.763s/it]: train_loss_raw=1.1892, running_loss=1.1625, LR=0.000100
[2025-08-27 02:38:52,820][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028208] [Batch 00488/03080] [00:06:12/00:32:57, 0.763s/it]: train_loss_raw=1.1122, running_loss=1.1617, LR=0.000100
[2025-08-27 02:38:58,963][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028216] [Batch 00496/03080] [00:06:18/00:32:51, 0.763s/it]: train_loss_raw=1.1887, running_loss=1.1613, LR=0.000100
[2025-08-27 02:39:05,181][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028224] [Batch 00504/03080] [00:06:24/00:32:45, 0.763s/it]: train_loss_raw=1.2836, running_loss=1.1603, LR=0.000100
[2025-08-27 02:39:11,168][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028232] [Batch 00512/03080] [00:06:30/00:32:38, 0.763s/it]: train_loss_raw=1.1466, running_loss=1.1600, LR=0.000100
[2025-08-27 02:39:17,362][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028240] [Batch 00520/03080] [00:06:36/00:32:33, 0.763s/it]: train_loss_raw=1.1716, running_loss=1.1607, LR=0.000100
[2025-08-27 02:39:23,495][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028248] [Batch 00528/03080] [00:06:42/00:32:27, 0.763s/it]: train_loss_raw=1.1967, running_loss=1.1619, LR=0.000100
[2025-08-27 02:39:29,487][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028256] [Batch 00536/03080] [00:06:48/00:32:20, 0.763s/it]: train_loss_raw=1.1187, running_loss=1.1621, LR=0.000100
[2025-08-27 02:39:35,660][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028264] [Batch 00544/03080] [00:06:55/00:32:14, 0.763s/it]: train_loss_raw=1.0841, running_loss=1.1620, LR=0.000100
[2025-08-27 02:39:41,729][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028272] [Batch 00552/03080] [00:07:01/00:32:08, 0.763s/it]: train_loss_raw=1.1810, running_loss=1.1611, LR=0.000100
[2025-08-27 02:39:47,545][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028280] [Batch 00560/03080] [00:07:06/00:32:01, 0.762s/it]: train_loss_raw=1.2426, running_loss=1.1577, LR=0.000100
[2025-08-27 02:39:53,447][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028288] [Batch 00568/03080] [00:07:12/00:31:54, 0.762s/it]: train_loss_raw=1.2215, running_loss=1.1573, LR=0.000100
[2025-08-27 02:39:59,349][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028296] [Batch 00576/03080] [00:07:18/00:31:47, 0.762s/it]: train_loss_raw=1.2951, running_loss=1.1562, LR=0.000100
[2025-08-27 02:40:05,141][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028304] [Batch 00584/03080] [00:07:24/00:31:40, 0.761s/it]: train_loss_raw=1.2616, running_loss=1.1591, LR=0.000100
[2025-08-27 02:40:11,053][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028312] [Batch 00592/03080] [00:07:30/00:31:33, 0.761s/it]: train_loss_raw=1.1908, running_loss=1.1586, LR=0.000100
[2025-08-27 02:40:16,987][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028320] [Batch 00600/03080] [00:07:36/00:31:26, 0.761s/it]: train_loss_raw=1.1624, running_loss=1.1570, LR=0.000100
[2025-08-27 02:40:22,886][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028328] [Batch 00608/03080] [00:07:42/00:31:19, 0.760s/it]: train_loss_raw=1.1357, running_loss=1.1542, LR=0.000100
[2025-08-27 02:40:28,864][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028336] [Batch 00616/03080] [00:07:48/00:31:13, 0.760s/it]: train_loss_raw=1.0810, running_loss=1.1529, LR=0.000100
[2025-08-27 02:40:34,775][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028344] [Batch 00624/03080] [00:07:54/00:31:06, 0.760s/it]: train_loss_raw=1.2018, running_loss=1.1584, LR=0.000100
[2025-08-27 02:40:40,759][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028352] [Batch 00632/03080] [00:08:00/00:30:59, 0.760s/it]: train_loss_raw=1.1090, running_loss=1.1582, LR=0.000100
[2025-08-27 02:40:46,625][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028360] [Batch 00640/03080] [00:08:06/00:30:53, 0.759s/it]: train_loss_raw=1.1583, running_loss=1.1577, LR=0.000100
[2025-08-27 02:40:52,733][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028368] [Batch 00648/03080] [00:08:12/00:30:47, 0.759s/it]: train_loss_raw=1.1489, running_loss=1.1559, LR=0.000100
[2025-08-27 02:40:58,712][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028376] [Batch 00656/03080] [00:08:18/00:30:40, 0.759s/it]: train_loss_raw=1.1725, running_loss=1.1542, LR=0.000100
[2025-08-27 02:41:04,805][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028384] [Batch 00664/03080] [00:08:24/00:30:34, 0.759s/it]: train_loss_raw=1.1430, running_loss=1.1550, LR=0.000100
[2025-08-27 02:41:10,842][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028392] [Batch 00672/03080] [00:08:30/00:30:28, 0.759s/it]: train_loss_raw=1.1814, running_loss=1.1586, LR=0.000100
[2025-08-27 02:41:17,059][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028400] [Batch 00680/03080] [00:08:36/00:30:22, 0.760s/it]: train_loss_raw=1.1407, running_loss=1.1571, LR=0.000100
[2025-08-27 02:41:22,952][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028408] [Batch 00688/03080] [00:08:42/00:30:16, 0.759s/it]: train_loss_raw=1.2283, running_loss=1.1577, LR=0.000100
[2025-08-27 02:41:28,708][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028416] [Batch 00696/03080] [00:08:48/00:30:08, 0.759s/it]: train_loss_raw=1.0580, running_loss=1.1562, LR=0.000100
[2025-08-27 02:41:34,620][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028424] [Batch 00704/03080] [00:08:54/00:30:02, 0.759s/it]: train_loss_raw=1.2123, running_loss=1.1534, LR=0.000100
[2025-08-27 02:41:40,669][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028432] [Batch 00712/03080] [00:09:00/00:29:56, 0.759s/it]: train_loss_raw=1.0510, running_loss=1.1517, LR=0.000100
[2025-08-27 02:41:46,882][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028440] [Batch 00720/03080] [00:09:06/00:29:50, 0.759s/it]: train_loss_raw=1.1975, running_loss=1.1509, LR=0.000100
[2025-08-27 02:41:52,950][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028448] [Batch 00728/03080] [00:09:12/00:29:44, 0.759s/it]: train_loss_raw=1.0719, running_loss=1.1537, LR=0.000100
[2025-08-27 02:41:58,755][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028456] [Batch 00736/03080] [00:09:18/00:29:37, 0.758s/it]: train_loss_raw=1.1419, running_loss=1.1551, LR=0.000100
[2025-08-27 02:42:04,664][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028464] [Batch 00744/03080] [00:09:24/00:29:31, 0.758s/it]: train_loss_raw=1.1138, running_loss=1.1560, LR=0.000100
[2025-08-27 02:42:10,809][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028472] [Batch 00752/03080] [00:09:30/00:29:25, 0.758s/it]: train_loss_raw=1.0621, running_loss=1.1552, LR=0.000100
[2025-08-27 02:42:16,701][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028480] [Batch 00760/03080] [00:09:36/00:29:18, 0.758s/it]: train_loss_raw=1.0861, running_loss=1.1545, LR=0.000100
[2025-08-27 02:42:22,415][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028488] [Batch 00768/03080] [00:09:41/00:29:11, 0.758s/it]: train_loss_raw=1.1378, running_loss=1.1538, LR=0.000100
[2025-08-27 02:42:28,170][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028496] [Batch 00776/03080] [00:09:47/00:29:04, 0.757s/it]: train_loss_raw=1.1890, running_loss=1.1529, LR=0.000100
[2025-08-27 02:42:34,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028504] [Batch 00784/03080] [00:09:53/00:28:58, 0.757s/it]: train_loss_raw=1.0460, running_loss=1.1505, LR=0.000100
[2025-08-27 02:42:40,104][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028512] [Batch 00792/03080] [00:09:59/00:28:51, 0.757s/it]: train_loss_raw=1.1154, running_loss=1.1485, LR=0.000100
[2025-08-27 02:42:45,999][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028520] [Batch 00800/03080] [00:10:05/00:28:45, 0.757s/it]: train_loss_raw=1.2030, running_loss=1.1512, LR=0.000100
[2025-08-27 02:42:51,908][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028528] [Batch 00808/03080] [00:10:11/00:28:38, 0.757s/it]: train_loss_raw=1.0900, running_loss=1.1511, LR=0.000100
[2025-08-27 02:42:58,116][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028536] [Batch 00816/03080] [00:10:17/00:28:33, 0.757s/it]: train_loss_raw=1.1931, running_loss=1.1532, LR=0.000100
[2025-08-27 02:43:04,181][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028544] [Batch 00824/03080] [00:10:23/00:28:27, 0.757s/it]: train_loss_raw=1.0097, running_loss=1.1519, LR=0.000100
[2025-08-27 02:43:10,188][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028552] [Batch 00832/03080] [00:10:29/00:28:21, 0.757s/it]: train_loss_raw=1.2381, running_loss=1.1530, LR=0.000100
[2025-08-27 02:43:15,904][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028560] [Batch 00840/03080] [00:10:35/00:28:14, 0.756s/it]: train_loss_raw=1.0315, running_loss=1.1517, LR=0.000100
[2025-08-27 02:43:21,854][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028568] [Batch 00848/03080] [00:10:41/00:28:07, 0.756s/it]: train_loss_raw=1.1982, running_loss=1.1522, LR=0.000100
[2025-08-27 02:43:27,699][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028576] [Batch 00856/03080] [00:10:47/00:28:01, 0.756s/it]: train_loss_raw=1.2506, running_loss=1.1551, LR=0.000100
[2025-08-27 02:43:33,661][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028584] [Batch 00864/03080] [00:10:53/00:27:55, 0.756s/it]: train_loss_raw=1.3339, running_loss=1.1566, LR=0.000100
[2025-08-27 02:43:39,463][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028592] [Batch 00872/03080] [00:10:58/00:27:48, 0.756s/it]: train_loss_raw=1.1890, running_loss=1.1570, LR=0.000100
[2025-08-27 02:43:45,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028600] [Batch 00880/03080] [00:11:04/00:27:41, 0.755s/it]: train_loss_raw=1.1438, running_loss=1.1559, LR=0.000100
[2025-08-27 02:43:51,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028608] [Batch 00888/03080] [00:11:10/00:27:35, 0.755s/it]: train_loss_raw=1.1466, running_loss=1.1540, LR=0.000100
[2025-08-27 02:43:57,478][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028616] [Batch 00896/03080] [00:11:16/00:27:29, 0.755s/it]: train_loss_raw=1.1637, running_loss=1.1510, LR=0.000100
[2025-08-27 02:44:03,290][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028624] [Batch 00904/03080] [00:11:22/00:27:23, 0.755s/it]: train_loss_raw=1.1505, running_loss=1.1552, LR=0.000100
[2025-08-27 02:44:09,120][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028632] [Batch 00912/03080] [00:11:28/00:27:16, 0.755s/it]: train_loss_raw=1.3218, running_loss=1.1542, LR=0.000100
[2025-08-27 02:44:15,013][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028640] [Batch 00920/03080] [00:11:34/00:27:10, 0.755s/it]: train_loss_raw=1.0935, running_loss=1.1520, LR=0.000100
[2025-08-27 02:44:20,772][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028648] [Batch 00928/03080] [00:11:40/00:27:03, 0.755s/it]: train_loss_raw=1.1661, running_loss=1.1518, LR=0.000100
[2025-08-27 02:44:26,550][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028656] [Batch 00936/03080] [00:11:45/00:26:57, 0.754s/it]: train_loss_raw=1.0617, running_loss=1.1505, LR=0.000100
[2025-08-27 02:44:32,381][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028664] [Batch 00944/03080] [00:11:51/00:26:50, 0.754s/it]: train_loss_raw=1.1080, running_loss=1.1510, LR=0.000100
[2025-08-27 02:44:38,354][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028672] [Batch 00952/03080] [00:11:57/00:26:44, 0.754s/it]: train_loss_raw=1.2096, running_loss=1.1513, LR=0.000100
[2025-08-27 02:44:44,283][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028680] [Batch 00960/03080] [00:12:03/00:26:38, 0.754s/it]: train_loss_raw=1.2245, running_loss=1.1538, LR=0.000100
[2025-08-27 02:44:50,176][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028688] [Batch 00968/03080] [00:12:09/00:26:31, 0.754s/it]: train_loss_raw=1.1578, running_loss=1.1524, LR=0.000100
[2025-08-27 02:44:56,091][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028696] [Batch 00976/03080] [00:12:15/00:26:25, 0.754s/it]: train_loss_raw=1.1426, running_loss=1.1522, LR=0.000100
[2025-08-27 02:45:01,956][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028704] [Batch 00984/03080] [00:12:21/00:26:19, 0.753s/it]: train_loss_raw=1.1769, running_loss=1.1517, LR=0.000100
[2025-08-27 02:45:07,836][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028712] [Batch 00992/03080] [00:12:27/00:26:12, 0.753s/it]: train_loss_raw=1.2412, running_loss=1.1519, LR=0.000100
[2025-08-27 02:45:13,783][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028720] [Batch 01000/03080] [00:12:33/00:26:06, 0.753s/it]: train_loss_raw=1.1587, running_loss=1.1531, LR=0.000100
[2025-08-27 02:45:19,658][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028728] [Batch 01008/03080] [00:12:39/00:26:00, 0.753s/it]: train_loss_raw=1.2236, running_loss=1.1523, LR=0.000100
[2025-08-27 02:45:25,576][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028736] [Batch 01016/03080] [00:12:44/00:25:54, 0.753s/it]: train_loss_raw=1.1539, running_loss=1.1529, LR=0.000100
[2025-08-27 02:45:31,473][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028744] [Batch 01024/03080] [00:12:50/00:25:47, 0.753s/it]: train_loss_raw=1.1922, running_loss=1.1554, LR=0.000100
[2025-08-27 02:45:37,364][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028752] [Batch 01032/03080] [00:12:56/00:25:41, 0.753s/it]: train_loss_raw=1.2811, running_loss=1.1591, LR=0.000100
[2025-08-27 02:45:43,263][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028760] [Batch 01040/03080] [00:13:02/00:25:35, 0.753s/it]: train_loss_raw=1.2061, running_loss=1.1591, LR=0.000100
[2025-08-27 02:45:49,177][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028768] [Batch 01048/03080] [00:13:08/00:25:29, 0.752s/it]: train_loss_raw=1.0684, running_loss=1.1558, LR=0.000100
[2025-08-27 02:45:55,057][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028776] [Batch 01056/03080] [00:13:14/00:25:22, 0.752s/it]: train_loss_raw=1.1581, running_loss=1.1554, LR=0.000100
[2025-08-27 02:46:00,842][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028784] [Batch 01064/03080] [00:13:20/00:25:16, 0.752s/it]: train_loss_raw=1.1191, running_loss=1.1515, LR=0.000100
[2025-08-27 02:46:06,736][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028792] [Batch 01072/03080] [00:13:26/00:25:10, 0.752s/it]: train_loss_raw=1.2159, running_loss=1.1497, LR=0.000100
[2025-08-27 02:46:12,594][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028800] [Batch 01080/03080] [00:13:32/00:25:03, 0.752s/it]: train_loss_raw=1.2318, running_loss=1.1511, LR=0.000100
[2025-08-27 02:46:18,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028808] [Batch 01088/03080] [00:13:37/00:24:57, 0.752s/it]: train_loss_raw=1.2020, running_loss=1.1519, LR=0.000100
[2025-08-27 02:46:24,441][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028816] [Batch 01096/03080] [00:13:43/00:24:51, 0.752s/it]: train_loss_raw=1.0557, running_loss=1.1504, LR=0.000100
[2025-08-27 02:46:30,276][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028824] [Batch 01104/03080] [00:13:49/00:24:45, 0.752s/it]: train_loss_raw=1.1000, running_loss=1.1464, LR=0.000100
[2025-08-27 02:46:36,139][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028832] [Batch 01112/03080] [00:13:55/00:24:38, 0.751s/it]: train_loss_raw=1.2185, running_loss=1.1469, LR=0.000100
[2025-08-27 02:46:42,011][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028840] [Batch 01120/03080] [00:14:01/00:24:32, 0.751s/it]: train_loss_raw=1.2080, running_loss=1.1473, LR=0.000100
[2025-08-27 02:46:47,741][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028848] [Batch 01128/03080] [00:14:07/00:24:25, 0.751s/it]: train_loss_raw=1.0314, running_loss=1.1457, LR=0.000100
[2025-08-27 02:46:53,619][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028856] [Batch 01136/03080] [00:14:13/00:24:19, 0.751s/it]: train_loss_raw=1.1268, running_loss=1.1470, LR=0.000100
[2025-08-27 02:46:59,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028864] [Batch 01144/03080] [00:14:18/00:24:13, 0.751s/it]: train_loss_raw=1.2303, running_loss=1.1495, LR=0.000100
[2025-08-27 02:47:05,398][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028872] [Batch 01152/03080] [00:14:24/00:24:07, 0.751s/it]: train_loss_raw=1.1613, running_loss=1.1481, LR=0.000100
[2025-08-27 02:47:11,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028880] [Batch 01160/03080] [00:14:30/00:24:01, 0.751s/it]: train_loss_raw=1.1002, running_loss=1.1463, LR=0.000100
[2025-08-27 02:47:17,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028888] [Batch 01168/03080] [00:14:36/00:23:55, 0.751s/it]: train_loss_raw=1.1002, running_loss=1.1464, LR=0.000100
[2025-08-27 02:47:23,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028896] [Batch 01176/03080] [00:14:42/00:23:49, 0.751s/it]: train_loss_raw=1.0731, running_loss=1.1437, LR=0.000100
[2025-08-27 02:47:29,129][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028904] [Batch 01184/03080] [00:14:48/00:23:42, 0.750s/it]: train_loss_raw=1.1049, running_loss=1.1466, LR=0.000100
[2025-08-27 02:47:35,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028912] [Batch 01192/03080] [00:14:54/00:23:36, 0.751s/it]: train_loss_raw=1.0910, running_loss=1.1476, LR=0.000100
[2025-08-27 02:47:41,294][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028920] [Batch 01200/03080] [00:15:00/00:23:31, 0.751s/it]: train_loss_raw=1.1884, running_loss=1.1500, LR=0.000100
[2025-08-27 02:47:47,345][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028928] [Batch 01208/03080] [00:15:06/00:23:25, 0.751s/it]: train_loss_raw=1.1770, running_loss=1.1504, LR=0.000100
[2025-08-27 02:47:53,342][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028936] [Batch 01216/03080] [00:15:12/00:23:19, 0.751s/it]: train_loss_raw=1.0692, running_loss=1.1482, LR=0.000100
[2025-08-27 02:47:59,378][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028944] [Batch 01224/03080] [00:15:18/00:23:13, 0.751s/it]: train_loss_raw=1.1967, running_loss=1.1505, LR=0.000100
[2025-08-27 02:48:05,367][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028952] [Batch 01232/03080] [00:15:24/00:23:07, 0.751s/it]: train_loss_raw=1.1894, running_loss=1.1507, LR=0.000100
[2025-08-27 02:48:11,239][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028960] [Batch 01240/03080] [00:15:30/00:23:00, 0.751s/it]: train_loss_raw=1.2006, running_loss=1.1508, LR=0.000100
[2025-08-27 02:48:17,196][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028968] [Batch 01248/03080] [00:15:36/00:22:54, 0.750s/it]: train_loss_raw=1.1148, running_loss=1.1512, LR=0.000100
[2025-08-27 02:48:23,160][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028976] [Batch 01256/03080] [00:15:42/00:22:48, 0.750s/it]: train_loss_raw=1.1251, running_loss=1.1477, LR=0.000100
[2025-08-27 02:48:29,185][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028984] [Batch 01264/03080] [00:15:48/00:22:42, 0.750s/it]: train_loss_raw=1.1580, running_loss=1.1476, LR=0.000100
[2025-08-27 02:48:35,316][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 028992] [Batch 01272/03080] [00:15:54/00:22:37, 0.751s/it]: train_loss_raw=1.0554, running_loss=1.1457, LR=0.000100
[2025-08-27 02:48:41,396][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029000] [Batch 01280/03080] [00:16:00/00:22:31, 0.751s/it]: train_loss_raw=1.1667, running_loss=1.1448, LR=0.000100
[2025-08-27 02:48:47,284][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029008] [Batch 01288/03080] [00:16:06/00:22:24, 0.751s/it]: train_loss_raw=1.0477, running_loss=1.1437, LR=0.000100
[2025-08-27 02:48:53,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029016] [Batch 01296/03080] [00:16:12/00:22:18, 0.750s/it]: train_loss_raw=1.0776, running_loss=1.1434, LR=0.000100
[2025-08-27 02:48:59,099][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029024] [Batch 01304/03080] [00:16:18/00:22:12, 0.750s/it]: train_loss_raw=1.1544, running_loss=1.1417, LR=0.000100
[2025-08-27 02:49:05,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029032] [Batch 01312/03080] [00:16:24/00:22:06, 0.750s/it]: train_loss_raw=1.2066, running_loss=1.1441, LR=0.000100
[2025-08-27 02:49:11,241][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029040] [Batch 01320/03080] [00:16:30/00:22:00, 0.750s/it]: train_loss_raw=1.1378, running_loss=1.1405, LR=0.000100
[2025-08-27 02:49:17,132][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029048] [Batch 01328/03080] [00:16:36/00:21:54, 0.750s/it]: train_loss_raw=1.0623, running_loss=1.1393, LR=0.000100
[2025-08-27 02:49:23,257][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029056] [Batch 01336/03080] [00:16:42/00:21:48, 0.751s/it]: train_loss_raw=1.1931, running_loss=1.1408, LR=0.000100
[2025-08-27 02:49:29,381][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029064] [Batch 01344/03080] [00:16:48/00:21:43, 0.751s/it]: train_loss_raw=1.1168, running_loss=1.1394, LR=0.000100
[2025-08-27 02:49:35,360][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029072] [Batch 01352/03080] [00:16:54/00:21:36, 0.751s/it]: train_loss_raw=1.0958, running_loss=1.1388, LR=0.000100
[2025-08-27 02:49:41,201][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029080] [Batch 01360/03080] [00:17:00/00:21:30, 0.750s/it]: train_loss_raw=1.1143, running_loss=1.1397, LR=0.000100
[2025-08-27 02:49:46,941][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029088] [Batch 01368/03080] [00:17:06/00:21:24, 0.750s/it]: train_loss_raw=1.1636, running_loss=1.1423, LR=0.000100
[2025-08-27 02:49:52,707][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029096] [Batch 01376/03080] [00:17:12/00:21:18, 0.750s/it]: train_loss_raw=1.1508, running_loss=1.1416, LR=0.000100
[2025-08-27 02:49:58,512][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029104] [Batch 01384/03080] [00:17:17/00:21:11, 0.750s/it]: train_loss_raw=1.2220, running_loss=1.1433, LR=0.000100
[2025-08-27 02:50:04,547][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029112] [Batch 01392/03080] [00:17:23/00:21:05, 0.750s/it]: train_loss_raw=1.1057, running_loss=1.1438, LR=0.000100
[2025-08-27 02:50:10,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029120] [Batch 01400/03080] [00:17:29/00:20:59, 0.750s/it]: train_loss_raw=1.1788, running_loss=1.1449, LR=0.000100
[2025-08-27 02:50:16,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029128] [Batch 01408/03080] [00:17:35/00:20:53, 0.750s/it]: train_loss_raw=1.1574, running_loss=1.1477, LR=0.000100
[2025-08-27 02:50:22,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029136] [Batch 01416/03080] [00:17:41/00:20:47, 0.750s/it]: train_loss_raw=1.1272, running_loss=1.1477, LR=0.000100
[2025-08-27 02:50:28,376][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029144] [Batch 01424/03080] [00:17:47/00:20:41, 0.750s/it]: train_loss_raw=1.0832, running_loss=1.1455, LR=0.000100
[2025-08-27 02:50:34,261][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029152] [Batch 01432/03080] [00:17:53/00:20:35, 0.750s/it]: train_loss_raw=1.1507, running_loss=1.1452, LR=0.000100
[2025-08-27 02:50:40,204][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029160] [Batch 01440/03080] [00:17:59/00:20:29, 0.750s/it]: train_loss_raw=1.1458, running_loss=1.1428, LR=0.000100
[2025-08-27 02:50:46,155][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029168] [Batch 01448/03080] [00:18:05/00:20:23, 0.750s/it]: train_loss_raw=1.2141, running_loss=1.1447, LR=0.000100
[2025-08-27 02:50:52,169][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029176] [Batch 01456/03080] [00:18:11/00:20:17, 0.750s/it]: train_loss_raw=1.2295, running_loss=1.1434, LR=0.000100
[2025-08-27 02:50:58,136][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029184] [Batch 01464/03080] [00:18:17/00:20:11, 0.750s/it]: train_loss_raw=1.1546, running_loss=1.1433, LR=0.000100
[2025-08-27 02:51:04,063][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029192] [Batch 01472/03080] [00:18:23/00:20:05, 0.750s/it]: train_loss_raw=1.1968, running_loss=1.1435, LR=0.000100
[2025-08-27 02:51:10,047][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029200] [Batch 01480/03080] [00:18:29/00:19:59, 0.750s/it]: train_loss_raw=1.1042, running_loss=1.1447, LR=0.000100
[2025-08-27 02:51:15,988][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029208] [Batch 01488/03080] [00:18:35/00:19:53, 0.750s/it]: train_loss_raw=1.0048, running_loss=1.1440, LR=0.000100
[2025-08-27 02:51:22,046][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029216] [Batch 01496/03080] [00:18:41/00:19:47, 0.750s/it]: train_loss_raw=1.1018, running_loss=1.1431, LR=0.000100
[2025-08-27 02:51:28,077][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029224] [Batch 01504/03080] [00:18:47/00:19:41, 0.750s/it]: train_loss_raw=1.0245, running_loss=1.1408, LR=0.000100
[2025-08-27 02:51:33,942][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029232] [Batch 01512/03080] [00:18:53/00:19:35, 0.750s/it]: train_loss_raw=1.0896, running_loss=1.1398, LR=0.000100
[2025-08-27 02:51:39,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029240] [Batch 01520/03080] [00:18:59/00:19:29, 0.750s/it]: train_loss_raw=1.0474, running_loss=1.1384, LR=0.000100
[2025-08-27 02:51:45,802][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029248] [Batch 01528/03080] [00:19:05/00:19:23, 0.749s/it]: train_loss_raw=1.1027, running_loss=1.1363, LR=0.000100
[2025-08-27 02:51:51,785][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029256] [Batch 01536/03080] [00:19:11/00:19:17, 0.749s/it]: train_loss_raw=1.0868, running_loss=1.1353, LR=0.000100
[2025-08-27 02:51:57,837][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029264] [Batch 01544/03080] [00:19:17/00:19:11, 0.750s/it]: train_loss_raw=1.1776, running_loss=1.1341, LR=0.000100
[2025-08-27 02:52:03,678][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029272] [Batch 01552/03080] [00:19:23/00:19:05, 0.749s/it]: train_loss_raw=1.2041, running_loss=1.1356, LR=0.000100
[2025-08-27 02:52:09,440][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029280] [Batch 01560/03080] [00:19:28/00:18:58, 0.749s/it]: train_loss_raw=1.1041, running_loss=1.1344, LR=0.000100
[2025-08-27 02:52:15,507][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029288] [Batch 01568/03080] [00:19:34/00:18:52, 0.749s/it]: train_loss_raw=1.1347, running_loss=1.1302, LR=0.000100
[2025-08-27 02:52:21,477][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029296] [Batch 01576/03080] [00:19:40/00:18:46, 0.749s/it]: train_loss_raw=1.2207, running_loss=1.1328, LR=0.000100
[2025-08-27 02:52:27,403][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029304] [Batch 01584/03080] [00:19:46/00:18:40, 0.749s/it]: train_loss_raw=0.9772, running_loss=1.1326, LR=0.000100
[2025-08-27 02:52:33,268][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029312] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=1.1895, running_loss=1.1337, LR=0.000100
[2025-08-27 02:52:39,305][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029320] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=1.2087, running_loss=1.1368, LR=0.000100
[2025-08-27 02:52:45,240][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029328] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=1.1796, running_loss=1.1405, LR=0.000100
[2025-08-27 02:52:51,206][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029336] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=1.0992, running_loss=1.1411, LR=0.000100
[2025-08-27 02:52:57,170][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029344] [Batch 01624/03080] [00:20:16/00:18:10, 0.749s/it]: train_loss_raw=1.1624, running_loss=1.1421, LR=0.000100
[2025-08-27 02:53:03,082][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029352] [Batch 01632/03080] [00:20:22/00:18:04, 0.749s/it]: train_loss_raw=1.1230, running_loss=1.1420, LR=0.000100
[2025-08-27 02:53:08,950][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029360] [Batch 01640/03080] [00:20:28/00:17:58, 0.749s/it]: train_loss_raw=1.1416, running_loss=1.1431, LR=0.000100
[2025-08-27 02:53:15,006][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029368] [Batch 01648/03080] [00:20:34/00:17:52, 0.749s/it]: train_loss_raw=1.1352, running_loss=1.1439, LR=0.000100
[2025-08-27 02:53:21,056][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029376] [Batch 01656/03080] [00:20:40/00:17:46, 0.749s/it]: train_loss_raw=1.1051, running_loss=1.1428, LR=0.000100
[2025-08-27 02:53:27,054][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029384] [Batch 01664/03080] [00:20:46/00:17:40, 0.749s/it]: train_loss_raw=1.1763, running_loss=1.1450, LR=0.000100
[2025-08-27 02:53:33,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029392] [Batch 01672/03080] [00:20:52/00:17:34, 0.749s/it]: train_loss_raw=1.2067, running_loss=1.1426, LR=0.000100
[2025-08-27 02:53:38,935][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029400] [Batch 01680/03080] [00:20:58/00:17:28, 0.749s/it]: train_loss_raw=1.1944, running_loss=1.1460, LR=0.000100
[2025-08-27 02:53:44,892][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029408] [Batch 01688/03080] [00:21:04/00:17:22, 0.749s/it]: train_loss_raw=1.2674, running_loss=1.1475, LR=0.000100
[2025-08-27 02:53:51,140][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029416] [Batch 01696/03080] [00:21:10/00:17:16, 0.749s/it]: train_loss_raw=1.1430, running_loss=1.1439, LR=0.000100
[2025-08-27 02:53:56,945][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029424] [Batch 01704/03080] [00:21:16/00:17:10, 0.749s/it]: train_loss_raw=1.1763, running_loss=1.1448, LR=0.000100
[2025-08-27 02:54:02,847][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029432] [Batch 01712/03080] [00:21:22/00:17:04, 0.749s/it]: train_loss_raw=1.1022, running_loss=1.1464, LR=0.000100
[2025-08-27 02:54:08,941][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029440] [Batch 01720/03080] [00:21:28/00:16:58, 0.749s/it]: train_loss_raw=1.1847, running_loss=1.1496, LR=0.000100
[2025-08-27 02:54:15,029][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029448] [Batch 01728/03080] [00:21:34/00:16:52, 0.749s/it]: train_loss_raw=1.1506, running_loss=1.1492, LR=0.000100
[2025-08-27 02:54:21,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029456] [Batch 01736/03080] [00:21:40/00:16:46, 0.749s/it]: train_loss_raw=1.1454, running_loss=1.1493, LR=0.000100
[2025-08-27 02:54:27,018][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029464] [Batch 01744/03080] [00:21:46/00:16:40, 0.749s/it]: train_loss_raw=1.1097, running_loss=1.1488, LR=0.000100
[2025-08-27 02:54:33,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029472] [Batch 01752/03080] [00:21:52/00:16:34, 0.749s/it]: train_loss_raw=1.1106, running_loss=1.1476, LR=0.000100
[2025-08-27 02:54:39,141][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029480] [Batch 01760/03080] [00:21:58/00:16:28, 0.749s/it]: train_loss_raw=1.1593, running_loss=1.1481, LR=0.000100
[2025-08-27 02:54:45,019][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029488] [Batch 01768/03080] [00:22:04/00:16:22, 0.749s/it]: train_loss_raw=1.0841, running_loss=1.1449, LR=0.000100
[2025-08-27 02:54:50,864][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029496] [Batch 01776/03080] [00:22:10/00:16:16, 0.749s/it]: train_loss_raw=1.3450, running_loss=1.1459, LR=0.000100
[2025-08-27 02:54:56,757][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029504] [Batch 01784/03080] [00:22:16/00:16:10, 0.749s/it]: train_loss_raw=1.1613, running_loss=1.1456, LR=0.000100
[2025-08-27 02:55:02,624][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029512] [Batch 01792/03080] [00:22:22/00:16:04, 0.749s/it]: train_loss_raw=1.1816, running_loss=1.1446, LR=0.000100
[2025-08-27 02:55:08,499][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029520] [Batch 01800/03080] [00:22:27/00:15:58, 0.749s/it]: train_loss_raw=1.1758, running_loss=1.1443, LR=0.000100
[2025-08-27 02:55:14,681][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029528] [Batch 01808/03080] [00:22:34/00:15:52, 0.749s/it]: train_loss_raw=1.1208, running_loss=1.1426, LR=0.000100
[2025-08-27 02:55:20,668][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029536] [Batch 01816/03080] [00:22:40/00:15:46, 0.749s/it]: train_loss_raw=1.2115, running_loss=1.1441, LR=0.000100
[2025-08-27 02:55:26,497][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029544] [Batch 01824/03080] [00:22:45/00:15:40, 0.749s/it]: train_loss_raw=1.2732, running_loss=1.1459, LR=0.000100
[2025-08-27 02:55:32,328][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029552] [Batch 01832/03080] [00:22:51/00:15:34, 0.749s/it]: train_loss_raw=1.1318, running_loss=1.1433, LR=0.000100
[2025-08-27 02:55:38,245][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029560] [Batch 01840/03080] [00:22:57/00:15:28, 0.749s/it]: train_loss_raw=1.0525, running_loss=1.1416, LR=0.000100
[2025-08-27 02:55:44,178][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029568] [Batch 01848/03080] [00:23:03/00:15:22, 0.749s/it]: train_loss_raw=1.1526, running_loss=1.1440, LR=0.000100
[2025-08-27 02:55:50,155][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029576] [Batch 01856/03080] [00:23:09/00:15:16, 0.749s/it]: train_loss_raw=1.1685, running_loss=1.1422, LR=0.000100
[2025-08-27 02:55:55,988][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029584] [Batch 01864/03080] [00:23:15/00:15:10, 0.749s/it]: train_loss_raw=1.1034, running_loss=1.1425, LR=0.000100
[2025-08-27 02:56:01,858][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029592] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=1.1194, running_loss=1.1408, LR=0.000100
[2025-08-27 02:56:07,761][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029600] [Batch 01880/03080] [00:23:27/00:14:58, 0.748s/it]: train_loss_raw=1.1115, running_loss=1.1404, LR=0.000100
[2025-08-27 02:56:13,671][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029608] [Batch 01888/03080] [00:23:33/00:14:52, 0.748s/it]: train_loss_raw=1.0790, running_loss=1.1421, LR=0.000100
[2025-08-27 02:56:19,621][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029616] [Batch 01896/03080] [00:23:39/00:14:46, 0.748s/it]: train_loss_raw=1.1619, running_loss=1.1404, LR=0.000100
[2025-08-27 02:56:25,525][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029624] [Batch 01904/03080] [00:23:44/00:14:40, 0.748s/it]: train_loss_raw=1.0692, running_loss=1.1389, LR=0.000100
[2025-08-27 02:56:31,581][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029632] [Batch 01912/03080] [00:23:50/00:14:34, 0.748s/it]: train_loss_raw=1.1554, running_loss=1.1379, LR=0.000100
[2025-08-27 02:56:37,474][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029640] [Batch 01920/03080] [00:23:56/00:14:28, 0.748s/it]: train_loss_raw=1.1092, running_loss=1.1363, LR=0.000100
[2025-08-27 02:56:43,385][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029648] [Batch 01928/03080] [00:24:02/00:14:22, 0.748s/it]: train_loss_raw=1.1608, running_loss=1.1392, LR=0.000100
[2025-08-27 02:56:49,381][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029656] [Batch 01936/03080] [00:24:08/00:14:16, 0.748s/it]: train_loss_raw=1.1443, running_loss=1.1382, LR=0.000100
[2025-08-27 02:56:55,378][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029664] [Batch 01944/03080] [00:24:14/00:14:10, 0.748s/it]: train_loss_raw=1.1187, running_loss=1.1372, LR=0.000100
[2025-08-27 02:57:01,132][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029672] [Batch 01952/03080] [00:24:20/00:14:04, 0.748s/it]: train_loss_raw=1.1636, running_loss=1.1386, LR=0.000100
[2025-08-27 02:57:07,193][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029680] [Batch 01960/03080] [00:24:26/00:13:58, 0.748s/it]: train_loss_raw=1.0749, running_loss=1.1381, LR=0.000100
[2025-08-27 02:57:13,386][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029688] [Batch 01968/03080] [00:24:32/00:13:52, 0.748s/it]: train_loss_raw=1.1872, running_loss=1.1370, LR=0.000100
[2025-08-27 02:57:19,408][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029696] [Batch 01976/03080] [00:24:38/00:13:46, 0.748s/it]: train_loss_raw=1.1360, running_loss=1.1375, LR=0.000100
[2025-08-27 02:57:25,442][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029704] [Batch 01984/03080] [00:24:44/00:13:40, 0.748s/it]: train_loss_raw=1.1988, running_loss=1.1352, LR=0.000100
[2025-08-27 02:57:31,330][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029712] [Batch 01992/03080] [00:24:50/00:13:34, 0.748s/it]: train_loss_raw=0.9890, running_loss=1.1345, LR=0.000100
[2025-08-27 02:57:37,315][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029720] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=1.1156, running_loss=1.1367, LR=0.000100
[2025-08-27 02:57:43,434][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029728] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=1.1198, running_loss=1.1359, LR=0.000100
[2025-08-27 02:57:49,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029736] [Batch 02016/03080] [00:25:08/00:13:16, 0.748s/it]: train_loss_raw=1.1757, running_loss=1.1336, LR=0.000100
[2025-08-27 02:57:55,193][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029744] [Batch 02024/03080] [00:25:14/00:13:10, 0.748s/it]: train_loss_raw=1.1963, running_loss=1.1340, LR=0.000100
[2025-08-27 02:58:01,095][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029752] [Batch 02032/03080] [00:25:20/00:13:04, 0.748s/it]: train_loss_raw=1.1131, running_loss=1.1342, LR=0.000100
[2025-08-27 02:58:07,026][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029760] [Batch 02040/03080] [00:25:26/00:12:58, 0.748s/it]: train_loss_raw=1.1069, running_loss=1.1333, LR=0.000100
[2025-08-27 02:58:12,886][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029768] [Batch 02048/03080] [00:25:32/00:12:52, 0.748s/it]: train_loss_raw=1.1266, running_loss=1.1330, LR=0.000100
[2025-08-27 02:58:18,804][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029776] [Batch 02056/03080] [00:25:38/00:12:46, 0.748s/it]: train_loss_raw=1.1436, running_loss=1.1344, LR=0.000100
[2025-08-27 02:58:24,705][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029784] [Batch 02064/03080] [00:25:44/00:12:40, 0.748s/it]: train_loss_raw=0.9762, running_loss=1.1291, LR=0.000100
[2025-08-27 02:58:30,699][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029792] [Batch 02072/03080] [00:25:50/00:12:34, 0.748s/it]: train_loss_raw=1.1334, running_loss=1.1281, LR=0.000100
[2025-08-27 02:58:36,631][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029800] [Batch 02080/03080] [00:25:56/00:12:28, 0.748s/it]: train_loss_raw=1.1304, running_loss=1.1282, LR=0.000100
[2025-08-27 02:58:42,626][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029808] [Batch 02088/03080] [00:26:02/00:12:22, 0.748s/it]: train_loss_raw=1.1418, running_loss=1.1315, LR=0.000100
[2025-08-27 02:58:48,500][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029816] [Batch 02096/03080] [00:26:07/00:12:16, 0.748s/it]: train_loss_raw=1.0851, running_loss=1.1324, LR=0.000100
[2025-08-27 02:58:54,574][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029824] [Batch 02104/03080] [00:26:13/00:12:10, 0.748s/it]: train_loss_raw=1.1850, running_loss=1.1335, LR=0.000100
[2025-08-27 02:59:00,664][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029832] [Batch 02112/03080] [00:26:20/00:12:04, 0.748s/it]: train_loss_raw=0.9871, running_loss=1.1350, LR=0.000100
[2025-08-27 02:59:06,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029840] [Batch 02120/03080] [00:26:26/00:11:58, 0.748s/it]: train_loss_raw=1.0911, running_loss=1.1344, LR=0.000100
[2025-08-27 02:59:12,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029848] [Batch 02128/03080] [00:26:31/00:11:52, 0.748s/it]: train_loss_raw=1.0912, running_loss=1.1341, LR=0.000100
[2025-08-27 02:59:18,515][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029856] [Batch 02136/03080] [00:26:37/00:11:46, 0.748s/it]: train_loss_raw=1.1379, running_loss=1.1314, LR=0.000100
[2025-08-27 02:59:24,547][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029864] [Batch 02144/03080] [00:26:43/00:11:40, 0.748s/it]: train_loss_raw=1.1471, running_loss=1.1353, LR=0.000100
[2025-08-27 02:59:30,337][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029872] [Batch 02152/03080] [00:26:49/00:11:34, 0.748s/it]: train_loss_raw=1.0337, running_loss=1.1361, LR=0.000100
[2025-08-27 02:59:36,284][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029880] [Batch 02160/03080] [00:26:55/00:11:28, 0.748s/it]: train_loss_raw=1.1174, running_loss=1.1344, LR=0.000100
[2025-08-27 02:59:42,210][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029888] [Batch 02168/03080] [00:27:01/00:11:22, 0.748s/it]: train_loss_raw=1.1733, running_loss=1.1344, LR=0.000100
[2025-08-27 02:59:48,128][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029896] [Batch 02176/03080] [00:27:07/00:11:16, 0.748s/it]: train_loss_raw=1.2646, running_loss=1.1320, LR=0.000100
[2025-08-27 02:59:54,012][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029904] [Batch 02184/03080] [00:27:13/00:11:10, 0.748s/it]: train_loss_raw=1.0578, running_loss=1.1310, LR=0.000100
[2025-08-27 02:59:59,850][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029912] [Batch 02192/03080] [00:27:19/00:11:04, 0.748s/it]: train_loss_raw=1.1257, running_loss=1.1314, LR=0.000100
[2025-08-27 03:00:05,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029920] [Batch 02200/03080] [00:27:25/00:10:58, 0.748s/it]: train_loss_raw=1.1014, running_loss=1.1304, LR=0.000100
[2025-08-27 03:00:11,743][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029928] [Batch 02208/03080] [00:27:31/00:10:52, 0.748s/it]: train_loss_raw=1.0567, running_loss=1.1287, LR=0.000100
[2025-08-27 03:00:17,853][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029936] [Batch 02216/03080] [00:27:37/00:10:46, 0.748s/it]: train_loss_raw=1.0760, running_loss=1.1295, LR=0.000100
[2025-08-27 03:00:23,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029944] [Batch 02224/03080] [00:27:43/00:10:40, 0.748s/it]: train_loss_raw=1.0802, running_loss=1.1274, LR=0.000100
[2025-08-27 03:00:29,573][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029952] [Batch 02232/03080] [00:27:48/00:10:34, 0.748s/it]: train_loss_raw=1.0741, running_loss=1.1286, LR=0.000100
[2025-08-27 03:00:35,574][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029960] [Batch 02240/03080] [00:27:54/00:10:28, 0.748s/it]: train_loss_raw=1.0708, running_loss=1.1250, LR=0.000100
[2025-08-27 03:00:41,535][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029968] [Batch 02248/03080] [00:28:00/00:10:22, 0.748s/it]: train_loss_raw=1.2496, running_loss=1.1298, LR=0.000100
[2025-08-27 03:00:47,611][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029976] [Batch 02256/03080] [00:28:07/00:10:16, 0.748s/it]: train_loss_raw=1.1314, running_loss=1.1302, LR=0.000100
[2025-08-27 03:00:53,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029984] [Batch 02264/03080] [00:28:12/00:10:10, 0.748s/it]: train_loss_raw=1.0496, running_loss=1.1280, LR=0.000100
[2025-08-27 03:00:59,681][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 029992] [Batch 02272/03080] [00:28:19/00:10:04, 0.748s/it]: train_loss_raw=1.0401, running_loss=1.1275, LR=0.000100
[2025-08-27 03:01:05,549][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030000] [Batch 02280/03080] [00:28:24/00:09:58, 0.748s/it]: train_loss_raw=1.0153, running_loss=1.1245, LR=0.000100
[2025-08-27 03:01:15,590][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030008] [Batch 02288/03080] [00:28:35/00:09:53, 0.750s/it]: train_loss_raw=1.1634, running_loss=1.1250, LR=0.000100
[2025-08-27 03:01:21,560][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030016] [Batch 02296/03080] [00:28:40/00:09:47, 0.750s/it]: train_loss_raw=1.1072, running_loss=1.1227, LR=0.000100
[2025-08-27 03:01:27,476][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030024] [Batch 02304/03080] [00:28:46/00:09:41, 0.750s/it]: train_loss_raw=1.0921, running_loss=1.1209, LR=0.000100
[2025-08-27 03:01:33,444][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030032] [Batch 02312/03080] [00:28:52/00:09:35, 0.750s/it]: train_loss_raw=1.2764, running_loss=1.1214, LR=0.000100
[2025-08-27 03:01:39,397][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030040] [Batch 02320/03080] [00:28:58/00:09:29, 0.749s/it]: train_loss_raw=1.1346, running_loss=1.1232, LR=0.000100
[2025-08-27 03:01:45,363][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030048] [Batch 02328/03080] [00:29:04/00:09:23, 0.749s/it]: train_loss_raw=1.1135, running_loss=1.1202, LR=0.000100
[2025-08-27 03:01:51,263][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030056] [Batch 02336/03080] [00:29:10/00:09:17, 0.749s/it]: train_loss_raw=1.0690, running_loss=1.1207, LR=0.000100
[2025-08-27 03:01:57,196][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030064] [Batch 02344/03080] [00:29:16/00:09:11, 0.749s/it]: train_loss_raw=1.1462, running_loss=1.1228, LR=0.000100
[2025-08-27 03:02:03,183][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030072] [Batch 02352/03080] [00:29:22/00:09:05, 0.749s/it]: train_loss_raw=1.2005, running_loss=1.1253, LR=0.000100
[2025-08-27 03:02:09,130][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030080] [Batch 02360/03080] [00:29:28/00:08:59, 0.749s/it]: train_loss_raw=1.1411, running_loss=1.1267, LR=0.000100
[2025-08-27 03:02:14,932][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030088] [Batch 02368/03080] [00:29:34/00:08:53, 0.749s/it]: train_loss_raw=1.2126, running_loss=1.1233, LR=0.000100
[2025-08-27 03:02:20,829][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030096] [Batch 02376/03080] [00:29:40/00:08:47, 0.749s/it]: train_loss_raw=1.1424, running_loss=1.1248, LR=0.000100
[2025-08-27 03:02:26,701][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030104] [Batch 02384/03080] [00:29:46/00:08:41, 0.749s/it]: train_loss_raw=1.1236, running_loss=1.1268, LR=0.000100
[2025-08-27 03:02:32,788][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030112] [Batch 02392/03080] [00:29:52/00:08:35, 0.749s/it]: train_loss_raw=1.0331, running_loss=1.1228, LR=0.000100
[2025-08-27 03:02:38,737][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030120] [Batch 02400/03080] [00:29:58/00:08:29, 0.749s/it]: train_loss_raw=1.1335, running_loss=1.1250, LR=0.000100
[2025-08-27 03:02:44,647][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030128] [Batch 02408/03080] [00:30:04/00:08:23, 0.749s/it]: train_loss_raw=1.2107, running_loss=1.1249, LR=0.000100
[2025-08-27 03:02:50,768][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030136] [Batch 02416/03080] [00:30:10/00:08:17, 0.749s/it]: train_loss_raw=1.0605, running_loss=1.1248, LR=0.000100
[2025-08-27 03:02:56,753][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030144] [Batch 02424/03080] [00:30:16/00:08:11, 0.749s/it]: train_loss_raw=1.1771, running_loss=1.1277, LR=0.000100
[2025-08-27 03:03:02,633][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030152] [Batch 02432/03080] [00:30:22/00:08:05, 0.749s/it]: train_loss_raw=1.1514, running_loss=1.1274, LR=0.000100
[2025-08-27 03:03:08,709][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030160] [Batch 02440/03080] [00:30:28/00:07:59, 0.749s/it]: train_loss_raw=1.1349, running_loss=1.1304, LR=0.000100
[2025-08-27 03:03:14,538][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030168] [Batch 02448/03080] [00:30:33/00:07:53, 0.749s/it]: train_loss_raw=1.0847, running_loss=1.1302, LR=0.000100
[2025-08-27 03:03:20,391][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030176] [Batch 02456/03080] [00:30:39/00:07:47, 0.749s/it]: train_loss_raw=1.1432, running_loss=1.1306, LR=0.000100
[2025-08-27 03:03:26,267][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030184] [Batch 02464/03080] [00:30:45/00:07:41, 0.749s/it]: train_loss_raw=1.0766, running_loss=1.1313, LR=0.000100
[2025-08-27 03:03:32,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030192] [Batch 02472/03080] [00:30:51/00:07:35, 0.749s/it]: train_loss_raw=1.0462, running_loss=1.1320, LR=0.000100
[2025-08-27 03:03:38,247][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030200] [Batch 02480/03080] [00:30:57/00:07:29, 0.749s/it]: train_loss_raw=1.0557, running_loss=1.1296, LR=0.000100
[2025-08-27 03:03:44,175][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030208] [Batch 02488/03080] [00:31:03/00:07:23, 0.749s/it]: train_loss_raw=1.1876, running_loss=1.1290, LR=0.000100
[2025-08-27 03:03:50,001][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030216] [Batch 02496/03080] [00:31:09/00:07:17, 0.749s/it]: train_loss_raw=1.0538, running_loss=1.1301, LR=0.000100
[2025-08-27 03:03:55,838][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030224] [Batch 02504/03080] [00:31:15/00:07:11, 0.749s/it]: train_loss_raw=1.1388, running_loss=1.1273, LR=0.000100
[2025-08-27 03:04:01,712][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030232] [Batch 02512/03080] [00:31:21/00:07:05, 0.749s/it]: train_loss_raw=1.2161, running_loss=1.1281, LR=0.000100
[2025-08-27 03:04:07,666][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030240] [Batch 02520/03080] [00:31:27/00:06:59, 0.749s/it]: train_loss_raw=1.1637, running_loss=1.1294, LR=0.000100
[2025-08-27 03:04:13,681][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030248] [Batch 02528/03080] [00:31:33/00:06:53, 0.749s/it]: train_loss_raw=1.1673, running_loss=1.1283, LR=0.000100
[2025-08-27 03:04:19,566][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030256] [Batch 02536/03080] [00:31:38/00:06:47, 0.749s/it]: train_loss_raw=1.0759, running_loss=1.1293, LR=0.000100
[2025-08-27 03:04:25,422][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030264] [Batch 02544/03080] [00:31:44/00:06:41, 0.749s/it]: train_loss_raw=1.1337, running_loss=1.1275, LR=0.000100
[2025-08-27 03:04:31,335][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030272] [Batch 02552/03080] [00:31:50/00:06:35, 0.749s/it]: train_loss_raw=1.1595, running_loss=1.1242, LR=0.000100
[2025-08-27 03:04:37,204][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030280] [Batch 02560/03080] [00:31:56/00:06:29, 0.749s/it]: train_loss_raw=1.1759, running_loss=1.1249, LR=0.000100
[2025-08-27 03:04:43,104][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030288] [Batch 02568/03080] [00:32:02/00:06:23, 0.749s/it]: train_loss_raw=1.2070, running_loss=1.1252, LR=0.000100
[2025-08-27 03:04:49,051][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030296] [Batch 02576/03080] [00:32:08/00:06:17, 0.749s/it]: train_loss_raw=1.0695, running_loss=1.1261, LR=0.000100
[2025-08-27 03:04:54,933][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030304] [Batch 02584/03080] [00:32:14/00:06:11, 0.749s/it]: train_loss_raw=1.1639, running_loss=1.1278, LR=0.000100
[2025-08-27 03:05:00,883][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030312] [Batch 02592/03080] [00:32:20/00:06:05, 0.749s/it]: train_loss_raw=1.1988, running_loss=1.1278, LR=0.000100
[2025-08-27 03:05:06,820][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030320] [Batch 02600/03080] [00:32:26/00:05:59, 0.749s/it]: train_loss_raw=0.9699, running_loss=1.1218, LR=0.000100
[2025-08-27 03:05:12,793][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030328] [Batch 02608/03080] [00:32:32/00:05:53, 0.749s/it]: train_loss_raw=1.0803, running_loss=1.1230, LR=0.000100
[2025-08-27 03:05:18,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030336] [Batch 02616/03080] [00:32:38/00:05:47, 0.749s/it]: train_loss_raw=1.1051, running_loss=1.1210, LR=0.000100
[2025-08-27 03:05:24,528][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030344] [Batch 02624/03080] [00:32:43/00:05:41, 0.748s/it]: train_loss_raw=1.1093, running_loss=1.1227, LR=0.000100
[2025-08-27 03:05:30,329][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030352] [Batch 02632/03080] [00:32:49/00:05:35, 0.748s/it]: train_loss_raw=1.1030, running_loss=1.1254, LR=0.000100
[2025-08-27 03:05:36,443][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030360] [Batch 02640/03080] [00:32:55/00:05:29, 0.748s/it]: train_loss_raw=1.1905, running_loss=1.1221, LR=0.000100
[2025-08-27 03:05:42,297][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030368] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=1.1657, running_loss=1.1222, LR=0.000100
[2025-08-27 03:05:48,143][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030376] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=1.0687, running_loss=1.1206, LR=0.000100
[2025-08-27 03:05:54,004][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030384] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=1.1115, running_loss=1.1182, LR=0.000100
[2025-08-27 03:06:00,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030392] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=1.1593, running_loss=1.1153, LR=0.000100
[2025-08-27 03:06:06,059][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030400] [Batch 02680/03080] [00:33:25/00:04:59, 0.748s/it]: train_loss_raw=1.1897, running_loss=1.1159, LR=0.000100
[2025-08-27 03:06:12,064][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030408] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=1.1569, running_loss=1.1174, LR=0.000100
[2025-08-27 03:06:18,103][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030416] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=1.0491, running_loss=1.1199, LR=0.000100
[2025-08-27 03:06:24,097][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030424] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=0.9872, running_loss=1.1198, LR=0.000100
[2025-08-27 03:06:30,097][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030432] [Batch 02712/03080] [00:33:49/00:04:35, 0.748s/it]: train_loss_raw=1.1568, running_loss=1.1219, LR=0.000100
[2025-08-27 03:06:36,091][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030440] [Batch 02720/03080] [00:33:55/00:04:29, 0.748s/it]: train_loss_raw=1.0609, running_loss=1.1207, LR=0.000100
[2025-08-27 03:06:42,065][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030448] [Batch 02728/03080] [00:34:01/00:04:23, 0.748s/it]: train_loss_raw=1.1134, running_loss=1.1198, LR=0.000100
[2025-08-27 03:06:48,001][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030456] [Batch 02736/03080] [00:34:07/00:04:17, 0.748s/it]: train_loss_raw=1.0229, running_loss=1.1188, LR=0.000100
[2025-08-27 03:06:53,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030464] [Batch 02744/03080] [00:34:13/00:04:11, 0.748s/it]: train_loss_raw=1.1511, running_loss=1.1186, LR=0.000100
[2025-08-27 03:06:59,633][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030472] [Batch 02752/03080] [00:34:19/00:04:05, 0.748s/it]: train_loss_raw=1.1747, running_loss=1.1222, LR=0.000100
[2025-08-27 03:07:05,531][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030480] [Batch 02760/03080] [00:34:24/00:03:59, 0.748s/it]: train_loss_raw=1.1177, running_loss=1.1220, LR=0.000100
[2025-08-27 03:07:11,369][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030488] [Batch 02768/03080] [00:34:30/00:03:53, 0.748s/it]: train_loss_raw=1.1053, running_loss=1.1240, LR=0.000100
[2025-08-27 03:07:17,220][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030496] [Batch 02776/03080] [00:34:36/00:03:47, 0.748s/it]: train_loss_raw=1.1691, running_loss=1.1245, LR=0.000100
[2025-08-27 03:07:23,349][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030504] [Batch 02784/03080] [00:34:42/00:03:41, 0.748s/it]: train_loss_raw=1.0859, running_loss=1.1246, LR=0.000100
[2025-08-27 03:07:29,341][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030512] [Batch 02792/03080] [00:34:48/00:03:35, 0.748s/it]: train_loss_raw=1.1077, running_loss=1.1239, LR=0.000100
[2025-08-27 03:07:35,402][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030520] [Batch 02800/03080] [00:34:54/00:03:29, 0.748s/it]: train_loss_raw=1.1253, running_loss=1.1221, LR=0.000100
[2025-08-27 03:07:41,374][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030528] [Batch 02808/03080] [00:35:00/00:03:23, 0.748s/it]: train_loss_raw=1.1543, running_loss=1.1222, LR=0.000100
[2025-08-27 03:07:47,185][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030536] [Batch 02816/03080] [00:35:06/00:03:17, 0.748s/it]: train_loss_raw=1.0991, running_loss=1.1210, LR=0.000100
[2025-08-27 03:07:52,963][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030544] [Batch 02824/03080] [00:35:12/00:03:11, 0.748s/it]: train_loss_raw=1.1846, running_loss=1.1222, LR=0.000100
[2025-08-27 03:07:58,909][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030552] [Batch 02832/03080] [00:35:18/00:03:05, 0.748s/it]: train_loss_raw=1.2069, running_loss=1.1233, LR=0.000100
[2025-08-27 03:08:04,734][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030560] [Batch 02840/03080] [00:35:24/00:02:59, 0.748s/it]: train_loss_raw=1.0502, running_loss=1.1226, LR=0.000100
[2025-08-27 03:08:10,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030568] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=1.1377, running_loss=1.1233, LR=0.000100
[2025-08-27 03:08:16,790][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030576] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=1.0994, running_loss=1.1199, LR=0.000100
[2025-08-27 03:08:22,653][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030584] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=1.0560, running_loss=1.1189, LR=0.000100
[2025-08-27 03:08:28,515][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030592] [Batch 02872/03080] [00:35:47/00:02:35, 0.748s/it]: train_loss_raw=1.0781, running_loss=1.1170, LR=0.000100
[2025-08-27 03:08:34,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030600] [Batch 02880/03080] [00:35:53/00:02:29, 0.748s/it]: train_loss_raw=1.1073, running_loss=1.1116, LR=0.000100
[2025-08-27 03:08:40,389][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030608] [Batch 02888/03080] [00:35:59/00:02:23, 0.748s/it]: train_loss_raw=1.1128, running_loss=1.1115, LR=0.000100
[2025-08-27 03:08:46,376][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030616] [Batch 02896/03080] [00:36:05/00:02:17, 0.748s/it]: train_loss_raw=1.0722, running_loss=1.1080, LR=0.000100
[2025-08-27 03:08:52,533][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030624] [Batch 02904/03080] [00:36:11/00:02:11, 0.748s/it]: train_loss_raw=1.0748, running_loss=1.1072, LR=0.000100
[2025-08-27 03:08:58,458][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030632] [Batch 02912/03080] [00:36:17/00:02:05, 0.748s/it]: train_loss_raw=1.1626, running_loss=1.1073, LR=0.000100
[2025-08-27 03:09:04,358][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030640] [Batch 02920/03080] [00:36:23/00:01:59, 0.748s/it]: train_loss_raw=1.0715, running_loss=1.1051, LR=0.000100
[2025-08-27 03:09:10,418][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030648] [Batch 02928/03080] [00:36:29/00:01:53, 0.748s/it]: train_loss_raw=1.1497, running_loss=1.1045, LR=0.000100
[2025-08-27 03:09:16,284][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030656] [Batch 02936/03080] [00:36:35/00:01:47, 0.748s/it]: train_loss_raw=0.9603, running_loss=1.1016, LR=0.000100
[2025-08-27 03:09:22,344][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030664] [Batch 02944/03080] [00:36:41/00:01:41, 0.748s/it]: train_loss_raw=1.0598, running_loss=1.0993, LR=0.000100
[2025-08-27 03:09:28,241][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030672] [Batch 02952/03080] [00:36:47/00:01:35, 0.748s/it]: train_loss_raw=1.0776, running_loss=1.1012, LR=0.000100
[2025-08-27 03:09:34,147][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030680] [Batch 02960/03080] [00:36:53/00:01:29, 0.748s/it]: train_loss_raw=1.2435, running_loss=1.1013, LR=0.000100
[2025-08-27 03:09:40,032][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030688] [Batch 02968/03080] [00:36:59/00:01:23, 0.748s/it]: train_loss_raw=1.1058, running_loss=1.1039, LR=0.000100
[2025-08-27 03:09:46,048][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030696] [Batch 02976/03080] [00:37:05/00:01:17, 0.748s/it]: train_loss_raw=1.1529, running_loss=1.1041, LR=0.000100
[2025-08-27 03:09:52,408][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030704] [Batch 02984/03080] [00:37:11/00:01:11, 0.748s/it]: train_loss_raw=1.1319, running_loss=1.1052, LR=0.000100
[2025-08-27 03:09:58,602][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030712] [Batch 02992/03080] [00:37:18/00:01:05, 0.748s/it]: train_loss_raw=1.1318, running_loss=1.1089, LR=0.000100
[2025-08-27 03:10:04,533][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030720] [Batch 03000/03080] [00:37:23/00:00:59, 0.748s/it]: train_loss_raw=1.0632, running_loss=1.1068, LR=0.000100
[2025-08-27 03:10:10,394][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030728] [Batch 03008/03080] [00:37:29/00:00:53, 0.748s/it]: train_loss_raw=1.0690, running_loss=1.1056, LR=0.000100
[2025-08-27 03:10:16,307][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030736] [Batch 03016/03080] [00:37:35/00:00:47, 0.748s/it]: train_loss_raw=0.9983, running_loss=1.1051, LR=0.000100
[2025-08-27 03:10:22,142][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030744] [Batch 03024/03080] [00:37:41/00:00:41, 0.748s/it]: train_loss_raw=1.0880, running_loss=1.1051, LR=0.000100
[2025-08-27 03:10:28,085][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030752] [Batch 03032/03080] [00:37:47/00:00:35, 0.748s/it]: train_loss_raw=0.9999, running_loss=1.1050, LR=0.000100
[2025-08-27 03:10:34,301][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030760] [Batch 03040/03080] [00:37:53/00:00:29, 0.748s/it]: train_loss_raw=1.1339, running_loss=1.1079, LR=0.000100
[2025-08-27 03:10:40,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030768] [Batch 03048/03080] [00:37:59/00:00:23, 0.748s/it]: train_loss_raw=1.0861, running_loss=1.1070, LR=0.000100
[2025-08-27 03:10:46,264][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030776] [Batch 03056/03080] [00:38:05/00:00:17, 0.748s/it]: train_loss_raw=1.1140, running_loss=1.1088, LR=0.000100
[2025-08-27 03:10:52,222][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030784] [Batch 03064/03080] [00:38:11/00:00:11, 0.748s/it]: train_loss_raw=1.1045, running_loss=1.1072, LR=0.000100
[2025-08-27 03:10:58,188][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030792] [Batch 03072/03080] [00:38:17/00:00:05, 0.748s/it]: train_loss_raw=1.0046, running_loss=1.1056, LR=0.000100
[2025-08-27 03:11:09,650][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 030800] [Batch 03080/03080] [00:38:29/00:00:00, 0.750s/it]: train_loss_raw=1.1022, running_loss=1.1042, LR=0.000100
[2025-08-27 03:11:10,132][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-27 03:11:21,451][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00007/00310] [00:00:11/00:07:07, 1.415s/it]
[2025-08-27 03:11:32,689][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00015/00310] [00:00:22/00:06:54, 1.410s/it]
[2025-08-27 03:11:44,477][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00023/00310] [00:00:34/00:06:49, 1.431s/it]
[2025-08-27 03:11:56,740][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00031/00310] [00:00:46/00:06:44, 1.456s/it]
[2025-08-27 03:12:09,553][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00039/00310] [00:00:59/00:06:41, 1.486s/it]
[2025-08-27 03:12:22,155][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00047/00310] [00:01:12/00:06:33, 1.500s/it]
[2025-08-27 03:12:34,968][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00055/00310] [00:01:24/00:06:24, 1.515s/it]
[2025-08-27 03:12:47,480][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00063/00310] [00:01:37/00:06:14, 1.521s/it]
[2025-08-27 03:13:00,542][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00071/00310] [00:01:50/00:06:04, 1.533s/it]
[2025-08-27 03:13:12,817][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00079/00310] [00:02:02/00:05:52, 1.534s/it]
[2025-08-27 03:13:25,067][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00087/00310] [00:02:14/00:05:40, 1.533s/it]
[2025-08-27 03:13:37,660][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00095/00310] [00:02:27/00:05:28, 1.537s/it]
[2025-08-27 03:13:50,650][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00103/00310] [00:02:40/00:05:17, 1.543s/it]
[2025-08-27 03:14:03,411][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00111/00310] [00:02:53/00:05:06, 1.547s/it]
[2025-08-27 03:14:16,093][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00119/00310] [00:03:05/00:04:54, 1.550s/it]
[2025-08-27 03:14:28,527][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00127/00310] [00:03:18/00:04:42, 1.550s/it]
[2025-08-27 03:14:41,191][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00135/00310] [00:03:31/00:04:30, 1.552s/it]
[2025-08-27 03:14:53,795][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00143/00310] [00:03:43/00:04:17, 1.553s/it]
[2025-08-27 03:15:05,513][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00151/00310] [00:03:55/00:04:04, 1.549s/it]
[2025-08-27 03:15:17,419][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00159/00310] [00:04:07/00:03:51, 1.546s/it]
[2025-08-27 03:15:30,250][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00167/00310] [00:04:20/00:03:39, 1.548s/it]
[2025-08-27 03:15:41,861][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00175/00310] [00:04:31/00:03:26, 1.544s/it]
[2025-08-27 03:15:54,015][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00183/00310] [00:04:43/00:03:14, 1.543s/it]
[2025-08-27 03:16:06,856][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00191/00310] [00:04:56/00:03:02, 1.545s/it]
[2025-08-27 03:16:18,577][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00199/00310] [00:05:08/00:02:49, 1.542s/it]
[2025-08-27 03:16:30,537][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00207/00310] [00:05:20/00:02:37, 1.540s/it]
[2025-08-27 03:16:42,483][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00215/00310] [00:05:32/00:02:24, 1.539s/it]
[2025-08-27 03:16:54,545][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00223/00310] [00:05:44/00:02:12, 1.538s/it]
[2025-08-27 03:17:07,386][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00231/00310] [00:05:57/00:02:00, 1.540s/it]
[2025-08-27 03:17:19,765][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00239/00310] [00:06:09/00:01:47, 1.540s/it]
[2025-08-27 03:17:31,605][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00247/00310] [00:06:21/00:01:35, 1.538s/it]
[2025-08-27 03:17:44,259][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00255/00310] [00:06:34/00:01:23, 1.540s/it]
[2025-08-27 03:17:57,132][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00263/00310] [00:06:46/00:01:10, 1.542s/it]
[2025-08-27 03:18:09,482][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00271/00310] [00:06:59/00:00:58, 1.542s/it]
[2025-08-27 03:18:21,548][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00279/00310] [00:07:11/00:00:46, 1.541s/it]
[2025-08-27 03:18:33,753][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00287/00310] [00:07:23/00:00:33, 1.540s/it]
[2025-08-27 03:18:45,278][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00295/00310] [00:07:35/00:00:21, 1.538s/it]
[2025-08-27 03:18:57,749][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 030801] [Batch 00303/00310] [00:07:47/00:00:09, 1.538s/it]
[2025-08-27 03:19:07,131][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.10416, valid_loss=1.89064
[2025-08-27 03:19:07,131][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-27 03:19:07,132][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.716
[2025-08-27 03:19:07,132][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.042
[2025-08-27 03:19:07,132][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.043
[2025-08-27 03:19:07,132][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.014
[2025-08-27 03:19:07,146][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 07:52:21, remaining time 15:44:42, 00:47:14 per epoch
[2025-08-27 03:19:12,809][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030808] [Batch 00008/03080] [00:00:05/00:34:34, 0.675s/it]: train_loss_raw=1.0752, running_loss=1.1444, LR=0.000100
[2025-08-27 03:19:18,980][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030816] [Batch 00016/03080] [00:00:11/00:36:56, 0.723s/it]: train_loss_raw=1.1254, running_loss=1.1407, LR=0.000100
[2025-08-27 03:19:24,960][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030824] [Batch 00024/03080] [00:00:17/00:37:15, 0.731s/it]: train_loss_raw=1.0483, running_loss=1.1354, LR=0.000100
[2025-08-27 03:19:30,870][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030832] [Batch 00032/03080] [00:00:23/00:37:14, 0.733s/it]: train_loss_raw=1.0646, running_loss=1.1333, LR=0.000100
[2025-08-27 03:19:36,790][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030840] [Batch 00040/03080] [00:00:29/00:37:13, 0.735s/it]: train_loss_raw=1.0306, running_loss=1.1302, LR=0.000100
[2025-08-27 03:19:42,741][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030848] [Batch 00048/03080] [00:00:35/00:37:11, 0.736s/it]: train_loss_raw=1.0203, running_loss=1.1268, LR=0.000100
[2025-08-27 03:19:48,890][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030856] [Batch 00056/03080] [00:00:41/00:37:20, 0.741s/it]: train_loss_raw=1.1773, running_loss=1.1261, LR=0.000100
[2025-08-27 03:19:54,945][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030864] [Batch 00064/03080] [00:00:47/00:37:20, 0.743s/it]: train_loss_raw=1.0333, running_loss=1.1216, LR=0.000100
[2025-08-27 03:20:00,840][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030872] [Batch 00072/03080] [00:00:53/00:37:12, 0.742s/it]: train_loss_raw=1.1309, running_loss=1.1201, LR=0.000100
[2025-08-27 03:20:06,710][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030880] [Batch 00080/03080] [00:00:59/00:37:03, 0.741s/it]: train_loss_raw=1.1475, running_loss=1.1165, LR=0.000100
[2025-08-27 03:20:12,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030888] [Batch 00088/03080] [00:01:05/00:36:51, 0.739s/it]: train_loss_raw=1.0528, running_loss=1.1137, LR=0.000100
[2025-08-27 03:20:18,243][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030896] [Batch 00096/03080] [00:01:10/00:36:41, 0.738s/it]: train_loss_raw=1.0830, running_loss=1.1098, LR=0.000100
[2025-08-27 03:20:24,021][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030904] [Batch 00104/03080] [00:01:16/00:36:32, 0.737s/it]: train_loss_raw=0.9184, running_loss=1.1042, LR=0.000100
[2025-08-27 03:20:30,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030912] [Batch 00112/03080] [00:01:22/00:36:29, 0.738s/it]: train_loss_raw=1.0679, running_loss=1.1038, LR=0.000100
[2025-08-27 03:20:35,995][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030920] [Batch 00120/03080] [00:01:28/00:36:25, 0.738s/it]: train_loss_raw=1.0557, running_loss=1.0996, LR=0.000100
[2025-08-27 03:20:41,589][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030928] [Batch 00128/03080] [00:01:34/00:36:12, 0.736s/it]: train_loss_raw=1.0495, running_loss=1.0963, LR=0.000100
[2025-08-27 03:20:47,484][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030936] [Batch 00136/03080] [00:01:40/00:36:06, 0.736s/it]: train_loss_raw=1.1681, running_loss=1.0911, LR=0.000100
[2025-08-27 03:20:53,354][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030944] [Batch 00144/03080] [00:01:45/00:36:00, 0.736s/it]: train_loss_raw=1.1063, running_loss=1.0890, LR=0.000100
[2025-08-27 03:20:59,258][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030952] [Batch 00152/03080] [00:01:51/00:35:54, 0.736s/it]: train_loss_raw=1.0332, running_loss=1.0876, LR=0.000100
[2025-08-27 03:21:05,304][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030960] [Batch 00160/03080] [00:01:57/00:35:51, 0.737s/it]: train_loss_raw=1.0301, running_loss=1.0873, LR=0.000100
[2025-08-27 03:21:11,291][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030968] [Batch 00168/03080] [00:02:03/00:35:47, 0.737s/it]: train_loss_raw=1.1299, running_loss=1.0845, LR=0.000100
[2025-08-27 03:21:17,286][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030976] [Batch 00176/03080] [00:02:09/00:35:43, 0.738s/it]: train_loss_raw=1.1470, running_loss=1.0848, LR=0.000100
[2025-08-27 03:21:23,256][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030984] [Batch 00184/03080] [00:02:15/00:35:38, 0.738s/it]: train_loss_raw=1.1559, running_loss=1.0838, LR=0.000100
[2025-08-27 03:21:29,197][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 030992] [Batch 00192/03080] [00:02:21/00:35:32, 0.738s/it]: train_loss_raw=1.0006, running_loss=1.0845, LR=0.000100
[2025-08-27 03:21:35,266][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031000] [Batch 00200/03080] [00:02:27/00:35:29, 0.739s/it]: train_loss_raw=1.0870, running_loss=1.0833, LR=0.000100
[2025-08-27 03:21:41,224][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031008] [Batch 00208/03080] [00:02:33/00:35:23, 0.740s/it]: train_loss_raw=1.0468, running_loss=1.0821, LR=0.000100
[2025-08-27 03:21:46,976][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031016] [Batch 00216/03080] [00:02:39/00:35:15, 0.739s/it]: train_loss_raw=0.9632, running_loss=1.0825, LR=0.000100
[2025-08-27 03:21:52,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031024] [Batch 00224/03080] [00:02:45/00:35:11, 0.739s/it]: train_loss_raw=1.0913, running_loss=1.0817, LR=0.000100
[2025-08-27 03:21:58,885][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031032] [Batch 00232/03080] [00:02:51/00:35:05, 0.739s/it]: train_loss_raw=0.9982, running_loss=1.0836, LR=0.000100
[2025-08-27 03:22:04,986][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031040] [Batch 00240/03080] [00:02:57/00:35:01, 0.740s/it]: train_loss_raw=1.1039, running_loss=1.0834, LR=0.000100
[2025-08-27 03:22:10,767][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031048] [Batch 00248/03080] [00:03:03/00:34:53, 0.739s/it]: train_loss_raw=0.9882, running_loss=1.0808, LR=0.000100
[2025-08-27 03:22:16,609][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031056] [Batch 00256/03080] [00:03:09/00:34:47, 0.739s/it]: train_loss_raw=1.1763, running_loss=1.0794, LR=0.000100
[2025-08-27 03:22:22,552][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031064] [Batch 00264/03080] [00:03:15/00:34:41, 0.739s/it]: train_loss_raw=1.0831, running_loss=1.0805, LR=0.000100
[2025-08-27 03:22:28,530][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031072] [Batch 00272/03080] [00:03:21/00:34:36, 0.739s/it]: train_loss_raw=1.0187, running_loss=1.0816, LR=0.000100
[2025-08-27 03:22:34,537][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031080] [Batch 00280/03080] [00:03:27/00:34:31, 0.740s/it]: train_loss_raw=0.9928, running_loss=1.0797, LR=0.000100
[2025-08-27 03:22:40,572][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031088] [Batch 00288/03080] [00:03:33/00:34:26, 0.740s/it]: train_loss_raw=1.0557, running_loss=1.0828, LR=0.000100
[2025-08-27 03:22:46,626][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031096] [Batch 00296/03080] [00:03:39/00:34:21, 0.741s/it]: train_loss_raw=0.9299, running_loss=1.0787, LR=0.000100
[2025-08-27 03:22:52,418][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031104] [Batch 00304/03080] [00:03:45/00:34:14, 0.740s/it]: train_loss_raw=1.0964, running_loss=1.0791, LR=0.000100
[2025-08-27 03:22:58,396][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031112] [Batch 00312/03080] [00:03:50/00:34:09, 0.740s/it]: train_loss_raw=1.0687, running_loss=1.0758, LR=0.000100
[2025-08-27 03:23:04,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031120] [Batch 00320/03080] [00:03:56/00:34:03, 0.740s/it]: train_loss_raw=1.0573, running_loss=1.0747, LR=0.000100
[2025-08-27 03:23:10,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031128] [Batch 00328/03080] [00:04:02/00:33:58, 0.741s/it]: train_loss_raw=1.1633, running_loss=1.0761, LR=0.000100
[2025-08-27 03:23:16,468][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031136] [Batch 00336/03080] [00:04:09/00:33:53, 0.741s/it]: train_loss_raw=1.0792, running_loss=1.0771, LR=0.000100
[2025-08-27 03:23:22,570][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031144] [Batch 00344/03080] [00:04:15/00:33:49, 0.742s/it]: train_loss_raw=1.0453, running_loss=1.0768, LR=0.000100
[2025-08-27 03:23:28,700][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031152] [Batch 00352/03080] [00:04:21/00:33:45, 0.742s/it]: train_loss_raw=1.0313, running_loss=1.0771, LR=0.000100
[2025-08-27 03:23:34,831][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031160] [Batch 00360/03080] [00:04:27/00:33:40, 0.743s/it]: train_loss_raw=1.0808, running_loss=1.0796, LR=0.000100
[2025-08-27 03:23:40,949][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031168] [Batch 00368/03080] [00:04:33/00:33:35, 0.743s/it]: train_loss_raw=0.9536, running_loss=1.0805, LR=0.000100
[2025-08-27 03:23:46,950][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031176] [Batch 00376/03080] [00:04:39/00:33:30, 0.743s/it]: train_loss_raw=0.9770, running_loss=1.0819, LR=0.000100
[2025-08-27 03:23:52,889][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031184] [Batch 00384/03080] [00:04:45/00:33:24, 0.743s/it]: train_loss_raw=1.0483, running_loss=1.0797, LR=0.000100
[2025-08-27 03:23:58,854][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031192] [Batch 00392/03080] [00:04:51/00:33:18, 0.743s/it]: train_loss_raw=1.1565, running_loss=1.0790, LR=0.000100
[2025-08-27 03:24:04,903][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031200] [Batch 00400/03080] [00:04:57/00:33:13, 0.744s/it]: train_loss_raw=1.0384, running_loss=1.0779, LR=0.000100
[2025-08-27 03:24:10,842][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031208] [Batch 00408/03080] [00:05:03/00:33:07, 0.744s/it]: train_loss_raw=1.1310, running_loss=1.0809, LR=0.000100
[2025-08-27 03:24:16,791][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031216] [Batch 00416/03080] [00:05:09/00:33:01, 0.744s/it]: train_loss_raw=1.0875, running_loss=1.0805, LR=0.000100
[2025-08-27 03:24:22,812][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031224] [Batch 00424/03080] [00:05:15/00:32:55, 0.744s/it]: train_loss_raw=1.0986, running_loss=1.0801, LR=0.000100
[2025-08-27 03:24:28,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031232] [Batch 00432/03080] [00:05:21/00:32:51, 0.744s/it]: train_loss_raw=1.1067, running_loss=1.0800, LR=0.000100
[2025-08-27 03:24:35,082][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031240] [Batch 00440/03080] [00:05:27/00:32:46, 0.745s/it]: train_loss_raw=1.0693, running_loss=1.0806, LR=0.000100
[2025-08-27 03:24:40,904][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031248] [Batch 00448/03080] [00:05:33/00:32:39, 0.744s/it]: train_loss_raw=0.9975, running_loss=1.0791, LR=0.000100
[2025-08-27 03:24:46,801][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031256] [Batch 00456/03080] [00:05:39/00:32:33, 0.744s/it]: train_loss_raw=1.1030, running_loss=1.0779, LR=0.000100
[2025-08-27 03:24:52,645][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031264] [Batch 00464/03080] [00:05:45/00:32:26, 0.744s/it]: train_loss_raw=1.0159, running_loss=1.0792, LR=0.000100
[2025-08-27 03:24:58,512][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031272] [Batch 00472/03080] [00:05:51/00:32:20, 0.744s/it]: train_loss_raw=1.0717, running_loss=1.0816, LR=0.000100
[2025-08-27 03:25:04,594][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031280] [Batch 00480/03080] [00:05:57/00:32:14, 0.744s/it]: train_loss_raw=1.1619, running_loss=1.0818, LR=0.000100
[2025-08-27 03:25:10,593][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031288] [Batch 00488/03080] [00:06:03/00:32:09, 0.744s/it]: train_loss_raw=1.1397, running_loss=1.0830, LR=0.000100
[2025-08-27 03:25:16,563][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031296] [Batch 00496/03080] [00:06:09/00:32:03, 0.744s/it]: train_loss_raw=1.0302, running_loss=1.0819, LR=0.000100
[2025-08-27 03:25:22,549][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031304] [Batch 00504/03080] [00:06:15/00:31:57, 0.744s/it]: train_loss_raw=1.1569, running_loss=1.0851, LR=0.000100
[2025-08-27 03:25:28,498][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031312] [Batch 00512/03080] [00:06:21/00:31:51, 0.744s/it]: train_loss_raw=1.1148, running_loss=1.0863, LR=0.000100
[2025-08-27 03:25:34,469][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031320] [Batch 00520/03080] [00:06:27/00:31:45, 0.744s/it]: train_loss_raw=1.0743, running_loss=1.0844, LR=0.000100
[2025-08-27 03:25:40,571][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031328] [Batch 00528/03080] [00:06:33/00:31:40, 0.745s/it]: train_loss_raw=1.1051, running_loss=1.0856, LR=0.000100
[2025-08-27 03:25:46,599][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031336] [Batch 00536/03080] [00:06:39/00:31:34, 0.745s/it]: train_loss_raw=1.0562, running_loss=1.0856, LR=0.000100
[2025-08-27 03:25:52,431][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031344] [Batch 00544/03080] [00:06:45/00:31:28, 0.745s/it]: train_loss_raw=1.0132, running_loss=1.0822, LR=0.000100
[2025-08-27 03:25:58,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031352] [Batch 00552/03080] [00:06:50/00:31:22, 0.744s/it]: train_loss_raw=1.0636, running_loss=1.0803, LR=0.000100
[2025-08-27 03:26:04,405][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031360] [Batch 00560/03080] [00:06:56/00:31:16, 0.745s/it]: train_loss_raw=1.1662, running_loss=1.0799, LR=0.000100
[2025-08-27 03:26:10,270][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031368] [Batch 00568/03080] [00:07:02/00:31:10, 0.744s/it]: train_loss_raw=1.1356, running_loss=1.0800, LR=0.000100
[2025-08-27 03:26:16,201][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031376] [Batch 00576/03080] [00:07:08/00:31:04, 0.744s/it]: train_loss_raw=1.0550, running_loss=1.0797, LR=0.000100
[2025-08-27 03:26:22,208][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031384] [Batch 00584/03080] [00:07:14/00:30:58, 0.745s/it]: train_loss_raw=1.0955, running_loss=1.0780, LR=0.000100
[2025-08-27 03:26:28,170][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031392] [Batch 00592/03080] [00:07:20/00:30:52, 0.745s/it]: train_loss_raw=1.0590, running_loss=1.0768, LR=0.000100
[2025-08-27 03:26:34,123][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031400] [Batch 00600/03080] [00:07:26/00:30:46, 0.745s/it]: train_loss_raw=1.1231, running_loss=1.0761, LR=0.000100
[2025-08-27 03:26:40,073][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031408] [Batch 00608/03080] [00:07:32/00:30:40, 0.745s/it]: train_loss_raw=1.1118, running_loss=1.0778, LR=0.000100
[2025-08-27 03:26:45,928][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031416] [Batch 00616/03080] [00:07:38/00:30:34, 0.744s/it]: train_loss_raw=1.1385, running_loss=1.0789, LR=0.000100
[2025-08-27 03:26:51,791][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031424] [Batch 00624/03080] [00:07:44/00:30:27, 0.744s/it]: train_loss_raw=1.1003, running_loss=1.0779, LR=0.000100
[2025-08-27 03:26:57,707][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031432] [Batch 00632/03080] [00:07:50/00:30:21, 0.744s/it]: train_loss_raw=1.1357, running_loss=1.0785, LR=0.000100
[2025-08-27 03:27:03,649][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031440] [Batch 00640/03080] [00:07:56/00:30:15, 0.744s/it]: train_loss_raw=1.1184, running_loss=1.0799, LR=0.000100
[2025-08-27 03:27:09,811][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031448] [Batch 00648/03080] [00:08:02/00:30:10, 0.744s/it]: train_loss_raw=0.9795, running_loss=1.0793, LR=0.000100
[2025-08-27 03:27:15,784][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031456] [Batch 00656/03080] [00:08:08/00:30:04, 0.744s/it]: train_loss_raw=1.0224, running_loss=1.0793, LR=0.000100
[2025-08-27 03:27:21,768][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031464] [Batch 00664/03080] [00:08:14/00:29:58, 0.745s/it]: train_loss_raw=1.0860, running_loss=1.0798, LR=0.000100
[2025-08-27 03:27:27,777][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031472] [Batch 00672/03080] [00:08:20/00:29:52, 0.745s/it]: train_loss_raw=0.9958, running_loss=1.0789, LR=0.000100
[2025-08-27 03:27:33,624][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031480] [Batch 00680/03080] [00:08:26/00:29:46, 0.744s/it]: train_loss_raw=1.2472, running_loss=1.0801, LR=0.000100
[2025-08-27 03:27:39,452][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031488] [Batch 00688/03080] [00:08:32/00:29:40, 0.744s/it]: train_loss_raw=0.9787, running_loss=1.0778, LR=0.000100
[2025-08-27 03:27:45,308][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031496] [Batch 00696/03080] [00:08:37/00:29:33, 0.744s/it]: train_loss_raw=1.1284, running_loss=1.0772, LR=0.000100
[2025-08-27 03:27:51,309][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031504] [Batch 00704/03080] [00:08:43/00:29:28, 0.744s/it]: train_loss_raw=1.0365, running_loss=1.0752, LR=0.000100
[2025-08-27 03:27:57,353][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031512] [Batch 00712/03080] [00:08:49/00:29:22, 0.744s/it]: train_loss_raw=1.1366, running_loss=1.0766, LR=0.000100
[2025-08-27 03:28:03,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031520] [Batch 00720/03080] [00:08:55/00:29:16, 0.744s/it]: train_loss_raw=1.0542, running_loss=1.0762, LR=0.000100
[2025-08-27 03:28:09,203][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031528] [Batch 00728/03080] [00:09:01/00:29:10, 0.744s/it]: train_loss_raw=1.1234, running_loss=1.0726, LR=0.000100
[2025-08-27 03:28:15,180][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031536] [Batch 00736/03080] [00:09:07/00:29:04, 0.744s/it]: train_loss_raw=1.0571, running_loss=1.0699, LR=0.000100
[2025-08-27 03:28:21,048][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031544] [Batch 00744/03080] [00:09:13/00:28:58, 0.744s/it]: train_loss_raw=1.0943, running_loss=1.0708, LR=0.000100
[2025-08-27 03:28:27,174][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031552] [Batch 00752/03080] [00:09:19/00:28:52, 0.744s/it]: train_loss_raw=1.1654, running_loss=1.0738, LR=0.000100
[2025-08-27 03:28:32,972][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031560] [Batch 00760/03080] [00:09:25/00:28:46, 0.744s/it]: train_loss_raw=1.0384, running_loss=1.0714, LR=0.000100
[2025-08-27 03:28:38,877][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031568] [Batch 00768/03080] [00:09:31/00:28:40, 0.744s/it]: train_loss_raw=1.0633, running_loss=1.0722, LR=0.000100
[2025-08-27 03:28:44,827][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031576] [Batch 00776/03080] [00:09:37/00:28:34, 0.744s/it]: train_loss_raw=1.1421, running_loss=1.0744, LR=0.000100
[2025-08-27 03:28:50,759][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031584] [Batch 00784/03080] [00:09:43/00:28:28, 0.744s/it]: train_loss_raw=1.0993, running_loss=1.0746, LR=0.000100
[2025-08-27 03:28:56,710][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031592] [Batch 00792/03080] [00:09:49/00:28:22, 0.744s/it]: train_loss_raw=1.1271, running_loss=1.0751, LR=0.000100
[2025-08-27 03:29:02,485][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031600] [Batch 00800/03080] [00:09:55/00:28:15, 0.744s/it]: train_loss_raw=0.9450, running_loss=1.0738, LR=0.000100
[2025-08-27 03:29:08,365][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031608] [Batch 00808/03080] [00:10:00/00:28:09, 0.744s/it]: train_loss_raw=1.0817, running_loss=1.0732, LR=0.000100
[2025-08-27 03:29:14,395][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031616] [Batch 00816/03080] [00:10:06/00:28:04, 0.744s/it]: train_loss_raw=1.0824, running_loss=1.0745, LR=0.000100
[2025-08-27 03:29:20,314][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031624] [Batch 00824/03080] [00:10:12/00:27:58, 0.744s/it]: train_loss_raw=1.0274, running_loss=1.0780, LR=0.000100
[2025-08-27 03:29:26,263][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031632] [Batch 00832/03080] [00:10:18/00:27:52, 0.744s/it]: train_loss_raw=1.0334, running_loss=1.0762, LR=0.000100
[2025-08-27 03:29:32,197][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031640] [Batch 00840/03080] [00:10:24/00:27:46, 0.744s/it]: train_loss_raw=1.1157, running_loss=1.0755, LR=0.000100
[2025-08-27 03:29:38,328][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031648] [Batch 00848/03080] [00:10:30/00:27:40, 0.744s/it]: train_loss_raw=1.0393, running_loss=1.0759, LR=0.000100
[2025-08-27 03:29:44,270][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031656] [Batch 00856/03080] [00:10:36/00:27:34, 0.744s/it]: train_loss_raw=1.0924, running_loss=1.0761, LR=0.000100
[2025-08-27 03:29:50,210][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031664] [Batch 00864/03080] [00:10:42/00:27:28, 0.744s/it]: train_loss_raw=1.1867, running_loss=1.0741, LR=0.000100
[2025-08-27 03:29:56,177][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031672] [Batch 00872/03080] [00:10:48/00:27:22, 0.744s/it]: train_loss_raw=1.1775, running_loss=1.0769, LR=0.000100
[2025-08-27 03:30:02,156][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031680] [Batch 00880/03080] [00:10:54/00:27:16, 0.744s/it]: train_loss_raw=1.1261, running_loss=1.0812, LR=0.000100
[2025-08-27 03:30:07,892][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031688] [Batch 00888/03080] [00:11:00/00:27:10, 0.744s/it]: train_loss_raw=1.1143, running_loss=1.0798, LR=0.000100
[2025-08-27 03:30:13,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031696] [Batch 00896/03080] [00:11:06/00:27:04, 0.744s/it]: train_loss_raw=0.9762, running_loss=1.0761, LR=0.000100
[2025-08-27 03:30:19,724][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031704] [Batch 00904/03080] [00:11:12/00:26:58, 0.744s/it]: train_loss_raw=1.0308, running_loss=1.0756, LR=0.000100
[2025-08-27 03:30:25,540][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031712] [Batch 00912/03080] [00:11:18/00:26:52, 0.744s/it]: train_loss_raw=1.0435, running_loss=1.0728, LR=0.000100
[2025-08-27 03:30:31,456][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031720] [Batch 00920/03080] [00:11:24/00:26:46, 0.744s/it]: train_loss_raw=1.0790, running_loss=1.0724, LR=0.000100
[2025-08-27 03:30:37,354][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031728] [Batch 00928/03080] [00:11:29/00:26:39, 0.743s/it]: train_loss_raw=1.2049, running_loss=1.0745, LR=0.000100
[2025-08-27 03:30:43,266][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031736] [Batch 00936/03080] [00:11:35/00:26:33, 0.743s/it]: train_loss_raw=1.1676, running_loss=1.0805, LR=0.000100
[2025-08-27 03:30:49,144][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031744] [Batch 00944/03080] [00:11:41/00:26:27, 0.743s/it]: train_loss_raw=1.1582, running_loss=1.0819, LR=0.000100
[2025-08-27 03:30:54,978][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031752] [Batch 00952/03080] [00:11:47/00:26:21, 0.743s/it]: train_loss_raw=1.1038, running_loss=1.0777, LR=0.000100
[2025-08-27 03:31:00,868][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031760] [Batch 00960/03080] [00:11:53/00:26:15, 0.743s/it]: train_loss_raw=1.0083, running_loss=1.0735, LR=0.000100
[2025-08-27 03:31:06,672][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031768] [Batch 00968/03080] [00:11:59/00:26:09, 0.743s/it]: train_loss_raw=1.1094, running_loss=1.0732, LR=0.000100
[2025-08-27 03:31:12,436][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031776] [Batch 00976/03080] [00:12:05/00:26:02, 0.743s/it]: train_loss_raw=0.9813, running_loss=1.0753, LR=0.000100
[2025-08-27 03:31:18,419][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031784] [Batch 00984/03080] [00:12:11/00:25:57, 0.743s/it]: train_loss_raw=1.0786, running_loss=1.0754, LR=0.000100
[2025-08-27 03:31:24,255][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031792] [Batch 00992/03080] [00:12:16/00:25:50, 0.743s/it]: train_loss_raw=1.0429, running_loss=1.0752, LR=0.000100
[2025-08-27 03:31:30,278][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031800] [Batch 01000/03080] [00:12:22/00:25:45, 0.743s/it]: train_loss_raw=1.0974, running_loss=1.0723, LR=0.000100
[2025-08-27 03:31:36,131][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031808] [Batch 01008/03080] [00:12:28/00:25:39, 0.743s/it]: train_loss_raw=1.0614, running_loss=1.0731, LR=0.000100
[2025-08-27 03:31:42,055][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031816] [Batch 01016/03080] [00:12:34/00:25:33, 0.743s/it]: train_loss_raw=0.9904, running_loss=1.0719, LR=0.000100
[2025-08-27 03:31:48,011][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031824] [Batch 01024/03080] [00:12:40/00:25:27, 0.743s/it]: train_loss_raw=1.0667, running_loss=1.0702, LR=0.000100
[2025-08-27 03:31:53,996][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031832] [Batch 01032/03080] [00:12:46/00:25:21, 0.743s/it]: train_loss_raw=1.0939, running_loss=1.0727, LR=0.000100
[2025-08-27 03:31:59,943][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031840] [Batch 01040/03080] [00:12:52/00:25:15, 0.743s/it]: train_loss_raw=1.1521, running_loss=1.0746, LR=0.000100
[2025-08-27 03:32:05,857][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031848] [Batch 01048/03080] [00:12:58/00:25:09, 0.743s/it]: train_loss_raw=1.0994, running_loss=1.0761, LR=0.000100
[2025-08-27 03:32:11,661][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031856] [Batch 01056/03080] [00:13:04/00:25:03, 0.743s/it]: train_loss_raw=1.0915, running_loss=1.0741, LR=0.000100
[2025-08-27 03:32:17,581][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031864] [Batch 01064/03080] [00:13:10/00:24:57, 0.743s/it]: train_loss_raw=1.1242, running_loss=1.0717, LR=0.000100
[2025-08-27 03:32:23,422][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031872] [Batch 01072/03080] [00:13:16/00:24:51, 0.743s/it]: train_loss_raw=1.0205, running_loss=1.0716, LR=0.000100
[2025-08-27 03:32:29,108][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031880] [Batch 01080/03080] [00:13:21/00:24:44, 0.742s/it]: train_loss_raw=0.9649, running_loss=1.0693, LR=0.000100
[2025-08-27 03:32:35,005][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031888] [Batch 01088/03080] [00:13:27/00:24:38, 0.742s/it]: train_loss_raw=1.0431, running_loss=1.0729, LR=0.000100
[2025-08-27 03:32:40,891][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031896] [Batch 01096/03080] [00:13:33/00:24:32, 0.742s/it]: train_loss_raw=0.9308, running_loss=1.0723, LR=0.000100
[2025-08-27 03:32:46,789][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031904] [Batch 01104/03080] [00:13:39/00:24:26, 0.742s/it]: train_loss_raw=0.9795, running_loss=1.0695, LR=0.000100
[2025-08-27 03:32:52,769][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031912] [Batch 01112/03080] [00:13:45/00:24:20, 0.742s/it]: train_loss_raw=1.0049, running_loss=1.0703, LR=0.000100
[2025-08-27 03:32:58,660][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031920] [Batch 01120/03080] [00:13:51/00:24:14, 0.742s/it]: train_loss_raw=1.0515, running_loss=1.0699, LR=0.000100
[2025-08-27 03:33:04,566][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031928] [Batch 01128/03080] [00:13:57/00:24:08, 0.742s/it]: train_loss_raw=1.0159, running_loss=1.0713, LR=0.000100
[2025-08-27 03:33:10,370][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031936] [Batch 01136/03080] [00:14:02/00:24:02, 0.742s/it]: train_loss_raw=1.0977, running_loss=1.0686, LR=0.000100
[2025-08-27 03:33:16,268][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031944] [Batch 01144/03080] [00:14:08/00:23:56, 0.742s/it]: train_loss_raw=1.1388, running_loss=1.0665, LR=0.000100
[2025-08-27 03:33:22,287][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031952] [Batch 01152/03080] [00:14:14/00:23:50, 0.742s/it]: train_loss_raw=1.0662, running_loss=1.0692, LR=0.000100
[2025-08-27 03:33:28,244][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031960] [Batch 01160/03080] [00:14:20/00:23:44, 0.742s/it]: train_loss_raw=1.0900, running_loss=1.0709, LR=0.000100
[2025-08-27 03:33:34,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031968] [Batch 01168/03080] [00:14:26/00:23:38, 0.742s/it]: train_loss_raw=1.0378, running_loss=1.0707, LR=0.000100
[2025-08-27 03:33:40,111][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031976] [Batch 01176/03080] [00:14:32/00:23:32, 0.742s/it]: train_loss_raw=1.0066, running_loss=1.0677, LR=0.000100
[2025-08-27 03:33:45,975][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031984] [Batch 01184/03080] [00:14:38/00:23:26, 0.742s/it]: train_loss_raw=1.0774, running_loss=1.0660, LR=0.000100
[2025-08-27 03:33:51,973][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 031992] [Batch 01192/03080] [00:14:44/00:23:21, 0.742s/it]: train_loss_raw=1.1643, running_loss=1.0675, LR=0.000100
[2025-08-27 03:33:57,977][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032000] [Batch 01200/03080] [00:14:50/00:23:15, 0.742s/it]: train_loss_raw=1.0802, running_loss=1.0713, LR=0.000100
[2025-08-27 03:34:07,859][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032008] [Batch 01208/03080] [00:15:00/00:23:15, 0.745s/it]: train_loss_raw=1.1118, running_loss=1.0719, LR=0.000100
[2025-08-27 03:34:13,622][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032016] [Batch 01216/03080] [00:15:06/00:23:09, 0.745s/it]: train_loss_raw=1.0965, running_loss=1.0717, LR=0.000100
[2025-08-27 03:34:19,563][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032024] [Batch 01224/03080] [00:15:12/00:23:03, 0.745s/it]: train_loss_raw=1.1081, running_loss=1.0721, LR=0.000100
[2025-08-27 03:34:25,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032032] [Batch 01232/03080] [00:15:18/00:22:57, 0.745s/it]: train_loss_raw=1.1889, running_loss=1.0733, LR=0.000100
[2025-08-27 03:34:31,347][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032040] [Batch 01240/03080] [00:15:23/00:22:51, 0.745s/it]: train_loss_raw=1.0881, running_loss=1.0716, LR=0.000100
[2025-08-27 03:34:37,234][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032048] [Batch 01248/03080] [00:15:29/00:22:44, 0.745s/it]: train_loss_raw=1.0414, running_loss=1.0694, LR=0.000100
[2025-08-27 03:34:43,142][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032056] [Batch 01256/03080] [00:15:35/00:22:38, 0.745s/it]: train_loss_raw=1.0907, running_loss=1.0669, LR=0.000100
[2025-08-27 03:34:49,040][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032064] [Batch 01264/03080] [00:15:41/00:22:32, 0.745s/it]: train_loss_raw=1.1740, running_loss=1.0667, LR=0.000100
[2025-08-27 03:34:54,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032072] [Batch 01272/03080] [00:15:47/00:22:26, 0.745s/it]: train_loss_raw=1.0191, running_loss=1.0676, LR=0.000100
[2025-08-27 03:35:00,770][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032080] [Batch 01280/03080] [00:15:53/00:22:20, 0.745s/it]: train_loss_raw=1.0005, running_loss=1.0663, LR=0.000100
[2025-08-27 03:35:06,653][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032088] [Batch 01288/03080] [00:15:59/00:22:14, 0.745s/it]: train_loss_raw=0.9817, running_loss=1.0639, LR=0.000100
[2025-08-27 03:35:12,520][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032096] [Batch 01296/03080] [00:16:05/00:22:08, 0.745s/it]: train_loss_raw=1.0633, running_loss=1.0648, LR=0.000100
[2025-08-27 03:35:18,348][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032104] [Batch 01304/03080] [00:16:10/00:22:02, 0.745s/it]: train_loss_raw=1.0283, running_loss=1.0646, LR=0.000100
[2025-08-27 03:35:24,284][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032112] [Batch 01312/03080] [00:16:16/00:21:56, 0.745s/it]: train_loss_raw=1.0498, running_loss=1.0623, LR=0.000100
[2025-08-27 03:35:30,287][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032120] [Batch 01320/03080] [00:16:22/00:21:50, 0.745s/it]: train_loss_raw=0.9285, running_loss=1.0645, LR=0.000100
[2025-08-27 03:35:36,233][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032128] [Batch 01328/03080] [00:16:28/00:21:44, 0.745s/it]: train_loss_raw=1.0738, running_loss=1.0668, LR=0.000100
[2025-08-27 03:35:42,153][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032136] [Batch 01336/03080] [00:16:34/00:21:38, 0.745s/it]: train_loss_raw=1.0806, running_loss=1.0667, LR=0.000100
[2025-08-27 03:35:47,918][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032144] [Batch 01344/03080] [00:16:40/00:21:32, 0.744s/it]: train_loss_raw=1.0365, running_loss=1.0655, LR=0.000100
[2025-08-27 03:35:53,684][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032152] [Batch 01352/03080] [00:16:46/00:21:26, 0.744s/it]: train_loss_raw=1.0524, running_loss=1.0662, LR=0.000100
[2025-08-27 03:35:59,468][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032160] [Batch 01360/03080] [00:16:52/00:21:19, 0.744s/it]: train_loss_raw=1.0231, running_loss=1.0678, LR=0.000100
[2025-08-27 03:36:05,254][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032168] [Batch 01368/03080] [00:16:57/00:21:13, 0.744s/it]: train_loss_raw=1.0816, running_loss=1.0675, LR=0.000100
[2025-08-27 03:36:11,039][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032176] [Batch 01376/03080] [00:17:03/00:21:07, 0.744s/it]: train_loss_raw=1.1188, running_loss=1.0700, LR=0.000100
[2025-08-27 03:36:16,864][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032184] [Batch 01384/03080] [00:17:09/00:21:01, 0.744s/it]: train_loss_raw=1.1000, running_loss=1.0698, LR=0.000100
[2025-08-27 03:36:22,868][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032192] [Batch 01392/03080] [00:17:15/00:20:55, 0.744s/it]: train_loss_raw=1.0573, running_loss=1.0696, LR=0.000100
[2025-08-27 03:36:28,769][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032200] [Batch 01400/03080] [00:17:21/00:20:49, 0.744s/it]: train_loss_raw=1.0543, running_loss=1.0684, LR=0.000100
[2025-08-27 03:36:34,626][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032208] [Batch 01408/03080] [00:17:27/00:20:43, 0.744s/it]: train_loss_raw=1.0031, running_loss=1.0669, LR=0.000100
[2025-08-27 03:36:40,477][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032216] [Batch 01416/03080] [00:17:33/00:20:37, 0.744s/it]: train_loss_raw=1.1293, running_loss=1.0680, LR=0.000100
[2025-08-27 03:36:46,315][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032224] [Batch 01424/03080] [00:17:38/00:20:31, 0.744s/it]: train_loss_raw=1.0144, running_loss=1.0676, LR=0.000100
[2025-08-27 03:36:52,143][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032232] [Batch 01432/03080] [00:17:44/00:20:25, 0.744s/it]: train_loss_raw=1.1170, running_loss=1.0654, LR=0.000100
[2025-08-27 03:36:57,900][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032240] [Batch 01440/03080] [00:17:50/00:20:19, 0.743s/it]: train_loss_raw=1.2193, running_loss=1.0692, LR=0.000100
[2025-08-27 03:37:03,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032248] [Batch 01448/03080] [00:17:56/00:20:13, 0.743s/it]: train_loss_raw=1.0259, running_loss=1.0686, LR=0.000100
[2025-08-27 03:37:09,415][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032256] [Batch 01456/03080] [00:18:02/00:20:06, 0.743s/it]: train_loss_raw=1.0784, running_loss=1.0695, LR=0.000100
[2025-08-27 03:37:15,343][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032264] [Batch 01464/03080] [00:18:07/00:20:00, 0.743s/it]: train_loss_raw=1.0849, running_loss=1.0682, LR=0.000100
[2025-08-27 03:37:21,332][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032272] [Batch 01472/03080] [00:18:13/00:19:54, 0.743s/it]: train_loss_raw=0.9649, running_loss=1.0670, LR=0.000100
[2025-08-27 03:37:27,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032280] [Batch 01480/03080] [00:18:19/00:19:48, 0.743s/it]: train_loss_raw=0.9704, running_loss=1.0668, LR=0.000100
[2025-08-27 03:37:33,028][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032288] [Batch 01488/03080] [00:18:25/00:19:42, 0.743s/it]: train_loss_raw=1.0038, running_loss=1.0643, LR=0.000100
[2025-08-27 03:37:38,928][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032296] [Batch 01496/03080] [00:18:31/00:19:36, 0.743s/it]: train_loss_raw=1.1807, running_loss=1.0662, LR=0.000100
[2025-08-27 03:37:44,760][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032304] [Batch 01504/03080] [00:18:37/00:19:30, 0.743s/it]: train_loss_raw=1.2108, running_loss=1.0665, LR=0.000100
[2025-08-27 03:37:50,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032312] [Batch 01512/03080] [00:18:43/00:19:24, 0.743s/it]: train_loss_raw=1.0561, running_loss=1.0667, LR=0.000100
[2025-08-27 03:37:56,394][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032320] [Batch 01520/03080] [00:18:48/00:19:18, 0.743s/it]: train_loss_raw=1.1024, running_loss=1.0681, LR=0.000100
[2025-08-27 03:38:02,260][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032328] [Batch 01528/03080] [00:18:54/00:19:12, 0.743s/it]: train_loss_raw=1.1020, running_loss=1.0677, LR=0.000100
[2025-08-27 03:38:08,242][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032336] [Batch 01536/03080] [00:19:00/00:19:06, 0.743s/it]: train_loss_raw=1.1561, running_loss=1.0684, LR=0.000100
[2025-08-27 03:38:14,180][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032344] [Batch 01544/03080] [00:19:06/00:19:00, 0.743s/it]: train_loss_raw=1.0197, running_loss=1.0704, LR=0.000100
[2025-08-27 03:38:20,199][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032352] [Batch 01552/03080] [00:19:12/00:18:54, 0.743s/it]: train_loss_raw=0.9342, running_loss=1.0682, LR=0.000100
[2025-08-27 03:38:26,258][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032360] [Batch 01560/03080] [00:19:18/00:18:49, 0.743s/it]: train_loss_raw=1.0615, running_loss=1.0636, LR=0.000100
[2025-08-27 03:38:32,162][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032368] [Batch 01568/03080] [00:19:24/00:18:43, 0.743s/it]: train_loss_raw=1.0272, running_loss=1.0682, LR=0.000100
[2025-08-27 03:38:38,086][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032376] [Batch 01576/03080] [00:19:30/00:18:37, 0.743s/it]: train_loss_raw=1.0427, running_loss=1.0673, LR=0.000100
[2025-08-27 03:38:43,951][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032384] [Batch 01584/03080] [00:19:36/00:18:31, 0.743s/it]: train_loss_raw=1.0836, running_loss=1.0656, LR=0.000100
[2025-08-27 03:38:49,923][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032392] [Batch 01592/03080] [00:19:42/00:18:25, 0.743s/it]: train_loss_raw=1.0334, running_loss=1.0638, LR=0.000100
[2025-08-27 03:38:55,938][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032400] [Batch 01600/03080] [00:19:48/00:18:19, 0.743s/it]: train_loss_raw=1.1195, running_loss=1.0651, LR=0.000100
[2025-08-27 03:39:01,679][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032408] [Batch 01608/03080] [00:19:54/00:18:13, 0.743s/it]: train_loss_raw=1.0451, running_loss=1.0629, LR=0.000100
[2025-08-27 03:39:07,682][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032416] [Batch 01616/03080] [00:20:00/00:18:07, 0.743s/it]: train_loss_raw=1.1550, running_loss=1.0654, LR=0.000100
[2025-08-27 03:39:13,579][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032424] [Batch 01624/03080] [00:20:06/00:18:01, 0.743s/it]: train_loss_raw=0.9967, running_loss=1.0655, LR=0.000100
[2025-08-27 03:39:19,460][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032432] [Batch 01632/03080] [00:20:12/00:17:55, 0.743s/it]: train_loss_raw=1.1171, running_loss=1.0667, LR=0.000100
[2025-08-27 03:39:25,318][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032440] [Batch 01640/03080] [00:20:17/00:17:49, 0.743s/it]: train_loss_raw=1.1672, running_loss=1.0681, LR=0.000100
[2025-08-27 03:39:31,247][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032448] [Batch 01648/03080] [00:20:23/00:17:43, 0.743s/it]: train_loss_raw=1.0954, running_loss=1.0682, LR=0.000100
[2025-08-27 03:39:37,207][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032456] [Batch 01656/03080] [00:20:29/00:17:37, 0.743s/it]: train_loss_raw=1.1554, running_loss=1.0696, LR=0.000100
[2025-08-27 03:39:43,111][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032464] [Batch 01664/03080] [00:20:35/00:17:31, 0.743s/it]: train_loss_raw=1.0159, running_loss=1.0675, LR=0.000100
[2025-08-27 03:39:49,075][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032472] [Batch 01672/03080] [00:20:41/00:17:25, 0.743s/it]: train_loss_raw=1.0440, running_loss=1.0645, LR=0.000100
[2025-08-27 03:39:55,658][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032480] [Batch 01680/03080] [00:20:48/00:17:20, 0.743s/it]: train_loss_raw=1.0652, running_loss=1.0661, LR=0.000100
[2025-08-27 03:40:01,651][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032488] [Batch 01688/03080] [00:20:54/00:17:14, 0.743s/it]: train_loss_raw=1.1152, running_loss=1.0664, LR=0.000100
[2025-08-27 03:40:07,780][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032496] [Batch 01696/03080] [00:21:00/00:17:08, 0.743s/it]: train_loss_raw=0.9550, running_loss=1.0668, LR=0.000100
[2025-08-27 03:40:13,705][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032504] [Batch 01704/03080] [00:21:06/00:17:02, 0.743s/it]: train_loss_raw=1.0926, running_loss=1.0647, LR=0.000100
[2025-08-27 03:40:19,634][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032512] [Batch 01712/03080] [00:21:12/00:16:56, 0.743s/it]: train_loss_raw=1.0611, running_loss=1.0659, LR=0.000100
[2025-08-27 03:40:25,535][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032520] [Batch 01720/03080] [00:21:18/00:16:50, 0.743s/it]: train_loss_raw=1.1368, running_loss=1.0682, LR=0.000100
[2025-08-27 03:40:31,392][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032528] [Batch 01728/03080] [00:21:23/00:16:44, 0.743s/it]: train_loss_raw=1.0203, running_loss=1.0641, LR=0.000100
[2025-08-27 03:40:37,392][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032536] [Batch 01736/03080] [00:21:29/00:16:38, 0.743s/it]: train_loss_raw=1.0363, running_loss=1.0619, LR=0.000100
[2025-08-27 03:40:43,384][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032544] [Batch 01744/03080] [00:21:35/00:16:32, 0.743s/it]: train_loss_raw=1.0778, running_loss=1.0617, LR=0.000100
[2025-08-27 03:40:49,443][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032552] [Batch 01752/03080] [00:21:42/00:16:26, 0.743s/it]: train_loss_raw=0.9673, running_loss=1.0614, LR=0.000100
[2025-08-27 03:40:55,186][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032560] [Batch 01760/03080] [00:21:47/00:16:20, 0.743s/it]: train_loss_raw=1.0783, running_loss=1.0632, LR=0.000100
[2025-08-27 03:41:01,083][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032568] [Batch 01768/03080] [00:21:53/00:16:14, 0.743s/it]: train_loss_raw=1.0724, running_loss=1.0629, LR=0.000100
[2025-08-27 03:41:06,993][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032576] [Batch 01776/03080] [00:21:59/00:16:08, 0.743s/it]: train_loss_raw=1.0482, running_loss=1.0622, LR=0.000100
[2025-08-27 03:41:12,940][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032584] [Batch 01784/03080] [00:22:05/00:16:02, 0.743s/it]: train_loss_raw=1.0890, running_loss=1.0626, LR=0.000100
[2025-08-27 03:41:18,899][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032592] [Batch 01792/03080] [00:22:11/00:15:57, 0.743s/it]: train_loss_raw=1.1224, running_loss=1.0659, LR=0.000100
[2025-08-27 03:41:24,884][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032600] [Batch 01800/03080] [00:22:17/00:15:51, 0.743s/it]: train_loss_raw=1.1601, running_loss=1.0658, LR=0.000100
[2025-08-27 03:41:30,864][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032608] [Batch 01808/03080] [00:22:23/00:15:45, 0.743s/it]: train_loss_raw=1.0529, running_loss=1.0649, LR=0.000100
[2025-08-27 03:41:36,761][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032616] [Batch 01816/03080] [00:22:29/00:15:39, 0.743s/it]: train_loss_raw=1.0579, running_loss=1.0617, LR=0.000100
[2025-08-27 03:41:42,682][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032624] [Batch 01824/03080] [00:22:35/00:15:33, 0.743s/it]: train_loss_raw=1.1617, running_loss=1.0615, LR=0.000100
[2025-08-27 03:41:48,695][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032632] [Batch 01832/03080] [00:22:41/00:15:27, 0.743s/it]: train_loss_raw=1.0574, running_loss=1.0621, LR=0.000100
[2025-08-27 03:41:54,723][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032640] [Batch 01840/03080] [00:22:47/00:15:21, 0.743s/it]: train_loss_raw=1.1280, running_loss=1.0643, LR=0.000100
[2025-08-27 03:42:00,736][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032648] [Batch 01848/03080] [00:22:53/00:15:15, 0.743s/it]: train_loss_raw=1.1032, running_loss=1.0662, LR=0.000100
[2025-08-27 03:42:06,833][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032656] [Batch 01856/03080] [00:22:59/00:15:09, 0.743s/it]: train_loss_raw=1.1263, running_loss=1.0649, LR=0.000100
[2025-08-27 03:42:12,837][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032664] [Batch 01864/03080] [00:23:05/00:15:03, 0.743s/it]: train_loss_raw=1.0226, running_loss=1.0624, LR=0.000100
[2025-08-27 03:42:18,732][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032672] [Batch 01872/03080] [00:23:11/00:14:57, 0.743s/it]: train_loss_raw=1.1164, running_loss=1.0623, LR=0.000100
[2025-08-27 03:42:24,617][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032680] [Batch 01880/03080] [00:23:17/00:14:51, 0.743s/it]: train_loss_raw=1.1141, running_loss=1.0618, LR=0.000100
[2025-08-27 03:42:30,765][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032688] [Batch 01888/03080] [00:23:23/00:14:46, 0.743s/it]: train_loss_raw=0.9865, running_loss=1.0609, LR=0.000100
[2025-08-27 03:42:36,652][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032696] [Batch 01896/03080] [00:23:29/00:14:40, 0.743s/it]: train_loss_raw=0.9913, running_loss=1.0637, LR=0.000100
[2025-08-27 03:42:42,565][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032704] [Batch 01904/03080] [00:23:35/00:14:34, 0.743s/it]: train_loss_raw=1.1954, running_loss=1.0634, LR=0.000100
[2025-08-27 03:42:48,542][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032712] [Batch 01912/03080] [00:23:41/00:14:28, 0.743s/it]: train_loss_raw=1.0098, running_loss=1.0619, LR=0.000100
[2025-08-27 03:42:54,495][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032720] [Batch 01920/03080] [00:23:47/00:14:22, 0.743s/it]: train_loss_raw=0.9253, running_loss=1.0619, LR=0.000100
[2025-08-27 03:43:00,426][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032728] [Batch 01928/03080] [00:23:53/00:14:16, 0.743s/it]: train_loss_raw=0.9961, running_loss=1.0595, LR=0.000100
[2025-08-27 03:43:06,378][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032736] [Batch 01936/03080] [00:23:58/00:14:10, 0.743s/it]: train_loss_raw=1.0450, running_loss=1.0577, LR=0.000100
[2025-08-27 03:43:12,272][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032744] [Batch 01944/03080] [00:24:04/00:14:04, 0.743s/it]: train_loss_raw=1.0897, running_loss=1.0587, LR=0.000100
[2025-08-27 03:43:18,201][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032752] [Batch 01952/03080] [00:24:10/00:13:58, 0.743s/it]: train_loss_raw=1.0365, running_loss=1.0585, LR=0.000100
[2025-08-27 03:43:24,194][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032760] [Batch 01960/03080] [00:24:16/00:13:52, 0.743s/it]: train_loss_raw=1.1363, running_loss=1.0577, LR=0.000100
[2025-08-27 03:43:30,149][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032768] [Batch 01968/03080] [00:24:22/00:13:46, 0.743s/it]: train_loss_raw=1.1038, running_loss=1.0559, LR=0.000100
[2025-08-27 03:43:36,245][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032776] [Batch 01976/03080] [00:24:28/00:13:40, 0.743s/it]: train_loss_raw=1.1079, running_loss=1.0572, LR=0.000100
[2025-08-27 03:43:42,015][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032784] [Batch 01984/03080] [00:24:34/00:13:34, 0.743s/it]: train_loss_raw=0.9790, running_loss=1.0579, LR=0.000100
[2025-08-27 03:43:47,840][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032792] [Batch 01992/03080] [00:24:40/00:13:28, 0.743s/it]: train_loss_raw=1.0703, running_loss=1.0591, LR=0.000100
[2025-08-27 03:43:53,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032800] [Batch 02000/03080] [00:24:46/00:13:22, 0.743s/it]: train_loss_raw=1.0723, running_loss=1.0593, LR=0.000100
[2025-08-27 03:43:59,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032808] [Batch 02008/03080] [00:24:52/00:13:16, 0.743s/it]: train_loss_raw=1.0391, running_loss=1.0587, LR=0.000100
[2025-08-27 03:44:05,494][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032816] [Batch 02016/03080] [00:24:58/00:13:10, 0.743s/it]: train_loss_raw=1.0204, running_loss=1.0584, LR=0.000100
[2025-08-27 03:44:11,406][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032824] [Batch 02024/03080] [00:25:03/00:13:04, 0.743s/it]: train_loss_raw=1.0632, running_loss=1.0577, LR=0.000100
[2025-08-27 03:44:17,362][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032832] [Batch 02032/03080] [00:25:09/00:12:58, 0.743s/it]: train_loss_raw=1.0588, running_loss=1.0567, LR=0.000100
[2025-08-27 03:44:23,308][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032840] [Batch 02040/03080] [00:25:15/00:12:52, 0.743s/it]: train_loss_raw=1.0040, running_loss=1.0560, LR=0.000100
[2025-08-27 03:44:29,170][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032848] [Batch 02048/03080] [00:25:21/00:12:46, 0.743s/it]: train_loss_raw=1.0327, running_loss=1.0554, LR=0.000100
[2025-08-27 03:44:35,104][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032856] [Batch 02056/03080] [00:25:27/00:12:40, 0.743s/it]: train_loss_raw=1.0075, running_loss=1.0558, LR=0.000100
[2025-08-27 03:44:41,062][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032864] [Batch 02064/03080] [00:25:33/00:12:34, 0.743s/it]: train_loss_raw=1.0025, running_loss=1.0540, LR=0.000100
[2025-08-27 03:44:46,934][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032872] [Batch 02072/03080] [00:25:39/00:12:28, 0.743s/it]: train_loss_raw=1.1990, running_loss=1.0581, LR=0.000100
[2025-08-27 03:44:52,978][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032880] [Batch 02080/03080] [00:25:45/00:12:23, 0.743s/it]: train_loss_raw=0.9580, running_loss=1.0555, LR=0.000100
[2025-08-27 03:44:58,976][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032888] [Batch 02088/03080] [00:25:51/00:12:17, 0.743s/it]: train_loss_raw=1.0347, running_loss=1.0568, LR=0.000100
[2025-08-27 03:45:04,931][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032896] [Batch 02096/03080] [00:25:57/00:12:11, 0.743s/it]: train_loss_raw=0.9946, running_loss=1.0546, LR=0.000100
[2025-08-27 03:45:10,844][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032904] [Batch 02104/03080] [00:26:03/00:12:05, 0.743s/it]: train_loss_raw=0.9989, running_loss=1.0558, LR=0.000100
[2025-08-27 03:45:16,717][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032912] [Batch 02112/03080] [00:26:09/00:11:59, 0.743s/it]: train_loss_raw=1.0809, running_loss=1.0523, LR=0.000100
[2025-08-27 03:45:22,659][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032920] [Batch 02120/03080] [00:26:15/00:11:53, 0.743s/it]: train_loss_raw=1.1174, running_loss=1.0510, LR=0.000100
[2025-08-27 03:45:28,616][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032928] [Batch 02128/03080] [00:26:21/00:11:47, 0.743s/it]: train_loss_raw=1.0402, running_loss=1.0509, LR=0.000100
[2025-08-27 03:45:34,715][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032936] [Batch 02136/03080] [00:26:27/00:11:41, 0.743s/it]: train_loss_raw=1.0487, running_loss=1.0492, LR=0.000100
[2025-08-27 03:45:40,674][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032944] [Batch 02144/03080] [00:26:33/00:11:35, 0.743s/it]: train_loss_raw=1.0729, running_loss=1.0505, LR=0.000100
[2025-08-27 03:45:46,812][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032952] [Batch 02152/03080] [00:26:39/00:11:29, 0.743s/it]: train_loss_raw=1.0863, running_loss=1.0488, LR=0.000100
[2025-08-27 03:45:52,854][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032960] [Batch 02160/03080] [00:26:45/00:11:23, 0.743s/it]: train_loss_raw=1.0008, running_loss=1.0511, LR=0.000100
[2025-08-27 03:45:58,815][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032968] [Batch 02168/03080] [00:26:51/00:11:17, 0.743s/it]: train_loss_raw=1.1213, running_loss=1.0515, LR=0.000100
[2025-08-27 03:46:04,753][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032976] [Batch 02176/03080] [00:26:57/00:11:11, 0.743s/it]: train_loss_raw=1.0371, running_loss=1.0516, LR=0.000100
[2025-08-27 03:46:10,589][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032984] [Batch 02184/03080] [00:27:03/00:11:05, 0.743s/it]: train_loss_raw=0.9977, running_loss=1.0495, LR=0.000100
[2025-08-27 03:46:16,596][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 032992] [Batch 02192/03080] [00:27:09/00:10:59, 0.743s/it]: train_loss_raw=0.8743, running_loss=1.0473, LR=0.000100
[2025-08-27 03:46:22,611][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033000] [Batch 02200/03080] [00:27:15/00:10:54, 0.743s/it]: train_loss_raw=1.0268, running_loss=1.0489, LR=0.000100
[2025-08-27 03:46:28,537][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033008] [Batch 02208/03080] [00:27:21/00:10:48, 0.743s/it]: train_loss_raw=0.9778, running_loss=1.0464, LR=0.000100
[2025-08-27 03:46:34,534][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033016] [Batch 02216/03080] [00:27:27/00:10:42, 0.743s/it]: train_loss_raw=1.1436, running_loss=1.0490, LR=0.000100
[2025-08-27 03:46:40,524][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033024] [Batch 02224/03080] [00:27:33/00:10:36, 0.743s/it]: train_loss_raw=1.0293, running_loss=1.0494, LR=0.000100
[2025-08-27 03:46:46,457][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033032] [Batch 02232/03080] [00:27:39/00:10:30, 0.743s/it]: train_loss_raw=1.1715, running_loss=1.0524, LR=0.000100
[2025-08-27 03:46:52,416][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033040] [Batch 02240/03080] [00:27:45/00:10:24, 0.743s/it]: train_loss_raw=0.9778, running_loss=1.0520, LR=0.000100
[2025-08-27 03:46:58,358][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033048] [Batch 02248/03080] [00:27:50/00:10:18, 0.743s/it]: train_loss_raw=1.1388, running_loss=1.0523, LR=0.000100
[2025-08-27 03:47:04,144][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033056] [Batch 02256/03080] [00:27:56/00:10:12, 0.743s/it]: train_loss_raw=0.9894, running_loss=1.0502, LR=0.000100
[2025-08-27 03:47:09,939][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033064] [Batch 02264/03080] [00:28:02/00:10:06, 0.743s/it]: train_loss_raw=1.0066, running_loss=1.0511, LR=0.000100
[2025-08-27 03:47:15,902][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033072] [Batch 02272/03080] [00:28:08/00:10:00, 0.743s/it]: train_loss_raw=1.1392, running_loss=1.0541, LR=0.000100
[2025-08-27 03:47:21,839][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033080] [Batch 02280/03080] [00:28:14/00:09:54, 0.743s/it]: train_loss_raw=1.1049, running_loss=1.0547, LR=0.000100
[2025-08-27 03:47:27,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033088] [Batch 02288/03080] [00:28:20/00:09:48, 0.743s/it]: train_loss_raw=1.1401, running_loss=1.0558, LR=0.000100
[2025-08-27 03:47:33,722][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033096] [Batch 02296/03080] [00:28:26/00:09:42, 0.743s/it]: train_loss_raw=1.0583, running_loss=1.0528, LR=0.000100
[2025-08-27 03:47:39,567][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033104] [Batch 02304/03080] [00:28:32/00:09:36, 0.743s/it]: train_loss_raw=1.0257, running_loss=1.0521, LR=0.000100
[2025-08-27 03:47:45,349][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033112] [Batch 02312/03080] [00:28:37/00:09:30, 0.743s/it]: train_loss_raw=1.0207, running_loss=1.0500, LR=0.000100
[2025-08-27 03:47:51,159][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033120] [Batch 02320/03080] [00:28:43/00:09:24, 0.743s/it]: train_loss_raw=0.9774, running_loss=1.0486, LR=0.000100
[2025-08-27 03:47:56,945][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033128] [Batch 02328/03080] [00:28:49/00:09:18, 0.743s/it]: train_loss_raw=1.0321, running_loss=1.0474, LR=0.000100
[2025-08-27 03:48:03,131][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033136] [Batch 02336/03080] [00:28:55/00:09:12, 0.743s/it]: train_loss_raw=1.0847, running_loss=1.0477, LR=0.000100
[2025-08-27 03:48:09,293][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033144] [Batch 02344/03080] [00:29:01/00:09:06, 0.743s/it]: train_loss_raw=0.9820, running_loss=1.0463, LR=0.000100
[2025-08-27 03:48:15,210][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033152] [Batch 02352/03080] [00:29:07/00:09:00, 0.743s/it]: train_loss_raw=0.9870, running_loss=1.0470, LR=0.000100
[2025-08-27 03:48:21,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033160] [Batch 02360/03080] [00:29:13/00:08:55, 0.743s/it]: train_loss_raw=1.0052, running_loss=1.0455, LR=0.000100
[2025-08-27 03:48:26,841][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033168] [Batch 02368/03080] [00:29:19/00:08:49, 0.743s/it]: train_loss_raw=1.0519, running_loss=1.0430, LR=0.000100
[2025-08-27 03:48:32,716][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033176] [Batch 02376/03080] [00:29:25/00:08:43, 0.743s/it]: train_loss_raw=1.0297, running_loss=1.0433, LR=0.000100
[2025-08-27 03:48:38,693][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033184] [Batch 02384/03080] [00:29:31/00:08:37, 0.743s/it]: train_loss_raw=1.0436, running_loss=1.0429, LR=0.000100
[2025-08-27 03:48:44,596][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033192] [Batch 02392/03080] [00:29:37/00:08:31, 0.743s/it]: train_loss_raw=1.0551, running_loss=1.0432, LR=0.000100
[2025-08-27 03:48:50,473][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033200] [Batch 02400/03080] [00:29:43/00:08:25, 0.743s/it]: train_loss_raw=1.1730, running_loss=1.0450, LR=0.000100
[2025-08-27 03:48:56,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033208] [Batch 02408/03080] [00:29:48/00:08:19, 0.743s/it]: train_loss_raw=1.1496, running_loss=1.0484, LR=0.000100
[2025-08-27 03:49:02,304][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033216] [Batch 02416/03080] [00:29:54/00:08:13, 0.743s/it]: train_loss_raw=1.0884, running_loss=1.0478, LR=0.000100
[2025-08-27 03:49:08,247][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033224] [Batch 02424/03080] [00:30:00/00:08:07, 0.743s/it]: train_loss_raw=1.0346, running_loss=1.0494, LR=0.000100
[2025-08-27 03:49:14,230][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033232] [Batch 02432/03080] [00:30:06/00:08:01, 0.743s/it]: train_loss_raw=1.0568, running_loss=1.0506, LR=0.000100
[2025-08-27 03:49:20,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033240] [Batch 02440/03080] [00:30:12/00:07:55, 0.743s/it]: train_loss_raw=1.0024, running_loss=1.0493, LR=0.000100
[2025-08-27 03:49:26,106][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033248] [Batch 02448/03080] [00:30:18/00:07:49, 0.743s/it]: train_loss_raw=1.0299, running_loss=1.0475, LR=0.000100
[2025-08-27 03:49:32,065][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033256] [Batch 02456/03080] [00:30:24/00:07:43, 0.743s/it]: train_loss_raw=0.9022, running_loss=1.0461, LR=0.000100
[2025-08-27 03:49:37,899][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033264] [Batch 02464/03080] [00:30:30/00:07:37, 0.743s/it]: train_loss_raw=1.0056, running_loss=1.0427, LR=0.000100
[2025-08-27 03:49:43,685][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033272] [Batch 02472/03080] [00:30:36/00:07:31, 0.743s/it]: train_loss_raw=1.1380, running_loss=1.0457, LR=0.000100
[2025-08-27 03:49:49,485][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033280] [Batch 02480/03080] [00:30:42/00:07:25, 0.743s/it]: train_loss_raw=0.9573, running_loss=1.0457, LR=0.000100
[2025-08-27 03:49:55,380][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033288] [Batch 02488/03080] [00:30:47/00:07:19, 0.743s/it]: train_loss_raw=0.9449, running_loss=1.0447, LR=0.000100
[2025-08-27 03:50:01,358][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033296] [Batch 02496/03080] [00:30:53/00:07:13, 0.743s/it]: train_loss_raw=1.0058, running_loss=1.0446, LR=0.000100
[2025-08-27 03:50:07,277][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033304] [Batch 02504/03080] [00:30:59/00:07:07, 0.743s/it]: train_loss_raw=1.0817, running_loss=1.0463, LR=0.000100
[2025-08-27 03:50:13,096][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033312] [Batch 02512/03080] [00:31:05/00:07:01, 0.743s/it]: train_loss_raw=1.0215, running_loss=1.0457, LR=0.000100
[2025-08-27 03:50:19,117][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033320] [Batch 02520/03080] [00:31:11/00:06:55, 0.743s/it]: train_loss_raw=0.9790, running_loss=1.0436, LR=0.000100
[2025-08-27 03:50:25,034][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033328] [Batch 02528/03080] [00:31:17/00:06:49, 0.743s/it]: train_loss_raw=1.0328, running_loss=1.0432, LR=0.000100
[2025-08-27 03:50:30,994][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033336] [Batch 02536/03080] [00:31:23/00:06:44, 0.743s/it]: train_loss_raw=1.0606, running_loss=1.0423, LR=0.000100
[2025-08-27 03:50:36,834][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033344] [Batch 02544/03080] [00:31:29/00:06:38, 0.743s/it]: train_loss_raw=1.0031, running_loss=1.0425, LR=0.000100
[2025-08-27 03:50:42,797][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033352] [Batch 02552/03080] [00:31:35/00:06:32, 0.743s/it]: train_loss_raw=1.0690, running_loss=1.0407, LR=0.000100
[2025-08-27 03:50:48,649][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033360] [Batch 02560/03080] [00:31:41/00:06:26, 0.743s/it]: train_loss_raw=1.1476, running_loss=1.0423, LR=0.000100
[2025-08-27 03:50:54,423][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033368] [Batch 02568/03080] [00:31:47/00:06:20, 0.743s/it]: train_loss_raw=1.0993, running_loss=1.0395, LR=0.000100
[2025-08-27 03:51:00,249][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033376] [Batch 02576/03080] [00:31:52/00:06:14, 0.743s/it]: train_loss_raw=1.0970, running_loss=1.0391, LR=0.000100
[2025-08-27 03:51:06,139][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033384] [Batch 02584/03080] [00:31:58/00:06:08, 0.743s/it]: train_loss_raw=1.0686, running_loss=1.0405, LR=0.000100
[2025-08-27 03:51:12,092][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033392] [Batch 02592/03080] [00:32:04/00:06:02, 0.743s/it]: train_loss_raw=1.0860, running_loss=1.0411, LR=0.000100
[2025-08-27 03:51:18,014][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033400] [Batch 02600/03080] [00:32:10/00:05:56, 0.743s/it]: train_loss_raw=1.0875, running_loss=1.0424, LR=0.000100
[2025-08-27 03:51:23,814][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033408] [Batch 02608/03080] [00:32:16/00:05:50, 0.742s/it]: train_loss_raw=1.0587, running_loss=1.0410, LR=0.000100
[2025-08-27 03:51:29,821][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033416] [Batch 02616/03080] [00:32:22/00:05:44, 0.743s/it]: train_loss_raw=1.1031, running_loss=1.0420, LR=0.000100
[2025-08-27 03:51:35,614][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033424] [Batch 02624/03080] [00:32:28/00:05:38, 0.742s/it]: train_loss_raw=1.0204, running_loss=1.0427, LR=0.000100
[2025-08-27 03:51:41,407][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033432] [Batch 02632/03080] [00:32:33/00:05:32, 0.742s/it]: train_loss_raw=1.1137, running_loss=1.0425, LR=0.000100
[2025-08-27 03:51:47,193][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033440] [Batch 02640/03080] [00:32:39/00:05:26, 0.742s/it]: train_loss_raw=1.1039, running_loss=1.0436, LR=0.000100
[2025-08-27 03:51:53,108][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033448] [Batch 02648/03080] [00:32:45/00:05:20, 0.742s/it]: train_loss_raw=1.0243, running_loss=1.0439, LR=0.000100
[2025-08-27 03:51:58,945][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033456] [Batch 02656/03080] [00:32:51/00:05:14, 0.742s/it]: train_loss_raw=1.0479, running_loss=1.0441, LR=0.000100
[2025-08-27 03:52:04,722][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033464] [Batch 02664/03080] [00:32:57/00:05:08, 0.742s/it]: train_loss_raw=0.9325, running_loss=1.0429, LR=0.000100
[2025-08-27 03:52:10,514][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033472] [Batch 02672/03080] [00:33:03/00:05:02, 0.742s/it]: train_loss_raw=0.9240, running_loss=1.0410, LR=0.000100
[2025-08-27 03:52:16,432][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033480] [Batch 02680/03080] [00:33:09/00:04:56, 0.742s/it]: train_loss_raw=1.0303, running_loss=1.0396, LR=0.000100
[2025-08-27 03:52:22,291][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033488] [Batch 02688/03080] [00:33:14/00:04:50, 0.742s/it]: train_loss_raw=1.0107, running_loss=1.0379, LR=0.000100
[2025-08-27 03:52:28,198][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033496] [Batch 02696/03080] [00:33:20/00:04:44, 0.742s/it]: train_loss_raw=1.1048, running_loss=1.0398, LR=0.000100
[2025-08-27 03:52:34,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033504] [Batch 02704/03080] [00:33:26/00:04:39, 0.742s/it]: train_loss_raw=0.8915, running_loss=1.0422, LR=0.000100
[2025-08-27 03:52:40,245][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033512] [Batch 02712/03080] [00:33:32/00:04:33, 0.742s/it]: train_loss_raw=0.9401, running_loss=1.0439, LR=0.000100
[2025-08-27 03:52:46,221][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033520] [Batch 02720/03080] [00:33:38/00:04:27, 0.742s/it]: train_loss_raw=1.0295, running_loss=1.0420, LR=0.000100
[2025-08-27 03:52:52,126][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033528] [Batch 02728/03080] [00:33:44/00:04:21, 0.742s/it]: train_loss_raw=0.9593, running_loss=1.0396, LR=0.000100
[2025-08-27 03:52:57,940][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033536] [Batch 02736/03080] [00:33:50/00:04:15, 0.742s/it]: train_loss_raw=1.1370, running_loss=1.0398, LR=0.000100
[2025-08-27 03:53:03,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033544] [Batch 02744/03080] [00:33:56/00:04:09, 0.742s/it]: train_loss_raw=0.9998, running_loss=1.0395, LR=0.000100
[2025-08-27 03:53:09,635][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033552] [Batch 02752/03080] [00:34:02/00:04:03, 0.742s/it]: train_loss_raw=1.0031, running_loss=1.0401, LR=0.000100
[2025-08-27 03:53:15,418][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033560] [Batch 02760/03080] [00:34:08/00:03:57, 0.742s/it]: train_loss_raw=1.0488, running_loss=1.0421, LR=0.000100
[2025-08-27 03:53:21,428][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033568] [Batch 02768/03080] [00:34:14/00:03:51, 0.742s/it]: train_loss_raw=1.0426, running_loss=1.0401, LR=0.000100
[2025-08-27 03:53:27,223][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033576] [Batch 02776/03080] [00:34:19/00:03:45, 0.742s/it]: train_loss_raw=0.9858, running_loss=1.0379, LR=0.000100
[2025-08-27 03:53:33,189][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033584] [Batch 02784/03080] [00:34:25/00:03:39, 0.742s/it]: train_loss_raw=1.1700, running_loss=1.0387, LR=0.000100
[2025-08-27 03:53:39,227][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033592] [Batch 02792/03080] [00:34:31/00:03:33, 0.742s/it]: train_loss_raw=1.1266, running_loss=1.0384, LR=0.000100
[2025-08-27 03:53:44,957][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033600] [Batch 02800/03080] [00:34:37/00:03:27, 0.742s/it]: train_loss_raw=1.1207, running_loss=1.0387, LR=0.000100
[2025-08-27 03:53:50,901][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033608] [Batch 02808/03080] [00:34:43/00:03:21, 0.742s/it]: train_loss_raw=0.9880, running_loss=1.0373, LR=0.000100
[2025-08-27 03:53:56,680][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033616] [Batch 02816/03080] [00:34:49/00:03:15, 0.742s/it]: train_loss_raw=1.0230, running_loss=1.0357, LR=0.000100
[2025-08-27 03:54:02,522][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033624] [Batch 02824/03080] [00:34:55/00:03:09, 0.742s/it]: train_loss_raw=1.0663, running_loss=1.0351, LR=0.000100
[2025-08-27 03:54:08,408][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033632] [Batch 02832/03080] [00:35:01/00:03:03, 0.742s/it]: train_loss_raw=1.0017, running_loss=1.0337, LR=0.000100
[2025-08-27 03:54:14,418][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033640] [Batch 02840/03080] [00:35:07/00:02:58, 0.742s/it]: train_loss_raw=1.0019, running_loss=1.0289, LR=0.000100
[2025-08-27 03:54:20,348][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033648] [Batch 02848/03080] [00:35:12/00:02:52, 0.742s/it]: train_loss_raw=0.9311, running_loss=1.0280, LR=0.000100
[2025-08-27 03:54:26,348][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033656] [Batch 02856/03080] [00:35:18/00:02:46, 0.742s/it]: train_loss_raw=1.0164, running_loss=1.0298, LR=0.000100
[2025-08-27 03:54:32,321][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033664] [Batch 02864/03080] [00:35:24/00:02:40, 0.742s/it]: train_loss_raw=0.9863, running_loss=1.0328, LR=0.000100
[2025-08-27 03:54:38,110][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033672] [Batch 02872/03080] [00:35:30/00:02:34, 0.742s/it]: train_loss_raw=0.9419, running_loss=1.0337, LR=0.000100
[2025-08-27 03:54:43,885][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033680] [Batch 02880/03080] [00:35:36/00:02:28, 0.742s/it]: train_loss_raw=1.1305, running_loss=1.0368, LR=0.000100
[2025-08-27 03:54:49,829][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033688] [Batch 02888/03080] [00:35:42/00:02:22, 0.742s/it]: train_loss_raw=0.9414, running_loss=1.0386, LR=0.000100
[2025-08-27 03:54:55,745][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033696] [Batch 02896/03080] [00:35:48/00:02:16, 0.742s/it]: train_loss_raw=0.9633, running_loss=1.0389, LR=0.000100
[2025-08-27 03:55:01,631][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033704] [Batch 02904/03080] [00:35:54/00:02:10, 0.742s/it]: train_loss_raw=1.1052, running_loss=1.0382, LR=0.000100
[2025-08-27 03:55:07,496][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033712] [Batch 02912/03080] [00:36:00/00:02:04, 0.742s/it]: train_loss_raw=0.9782, running_loss=1.0397, LR=0.000100
[2025-08-27 03:55:13,326][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033720] [Batch 02920/03080] [00:36:05/00:01:58, 0.742s/it]: train_loss_raw=0.9946, running_loss=1.0378, LR=0.000100
[2025-08-27 03:55:19,095][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033728] [Batch 02928/03080] [00:36:11/00:01:52, 0.742s/it]: train_loss_raw=1.0909, running_loss=1.0384, LR=0.000100
[2025-08-27 03:55:24,748][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033736] [Batch 02936/03080] [00:36:17/00:01:46, 0.742s/it]: train_loss_raw=1.1170, running_loss=1.0418, LR=0.000100
[2025-08-27 03:55:30,477][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033744] [Batch 02944/03080] [00:36:23/00:01:40, 0.742s/it]: train_loss_raw=1.0559, running_loss=1.0391, LR=0.000100
[2025-08-27 03:55:36,208][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033752] [Batch 02952/03080] [00:36:28/00:01:34, 0.741s/it]: train_loss_raw=0.9945, running_loss=1.0386, LR=0.000100
[2025-08-27 03:55:42,061][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033760] [Batch 02960/03080] [00:36:34/00:01:28, 0.741s/it]: train_loss_raw=0.9610, running_loss=1.0377, LR=0.000100
[2025-08-27 03:55:47,981][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033768] [Batch 02968/03080] [00:36:40/00:01:23, 0.741s/it]: train_loss_raw=1.0682, running_loss=1.0408, LR=0.000100
[2025-08-27 03:55:53,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033776] [Batch 02976/03080] [00:36:46/00:01:17, 0.741s/it]: train_loss_raw=0.8814, running_loss=1.0425, LR=0.000100
[2025-08-27 03:55:59,669][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033784] [Batch 02984/03080] [00:36:52/00:01:11, 0.741s/it]: train_loss_raw=0.9547, running_loss=1.0413, LR=0.000100
[2025-08-27 03:56:05,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033792] [Batch 02992/03080] [00:36:58/00:01:05, 0.741s/it]: train_loss_raw=0.9842, running_loss=1.0391, LR=0.000100
[2025-08-27 03:56:11,732][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033800] [Batch 03000/03080] [00:37:04/00:00:59, 0.741s/it]: train_loss_raw=0.8689, running_loss=1.0378, LR=0.000100
[2025-08-27 03:56:17,672][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033808] [Batch 03008/03080] [00:37:10/00:00:53, 0.741s/it]: train_loss_raw=1.0077, running_loss=1.0386, LR=0.000100
[2025-08-27 03:56:23,654][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033816] [Batch 03016/03080] [00:37:16/00:00:47, 0.741s/it]: train_loss_raw=1.0465, running_loss=1.0387, LR=0.000100
[2025-08-27 03:56:29,646][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033824] [Batch 03024/03080] [00:37:22/00:00:41, 0.741s/it]: train_loss_raw=1.0817, running_loss=1.0390, LR=0.000100
[2025-08-27 03:56:35,605][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033832] [Batch 03032/03080] [00:37:28/00:00:35, 0.741s/it]: train_loss_raw=1.0436, running_loss=1.0387, LR=0.000100
[2025-08-27 03:56:41,675][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033840] [Batch 03040/03080] [00:37:34/00:00:29, 0.742s/it]: train_loss_raw=1.0518, running_loss=1.0392, LR=0.000100
[2025-08-27 03:56:47,528][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033848] [Batch 03048/03080] [00:37:40/00:00:23, 0.742s/it]: train_loss_raw=1.0697, running_loss=1.0400, LR=0.000100
[2025-08-27 03:56:53,311][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033856] [Batch 03056/03080] [00:37:45/00:00:17, 0.741s/it]: train_loss_raw=1.1082, running_loss=1.0429, LR=0.000100
[2025-08-27 03:56:59,243][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033864] [Batch 03064/03080] [00:37:51/00:00:11, 0.741s/it]: train_loss_raw=1.0417, running_loss=1.0405, LR=0.000100
[2025-08-27 03:57:05,126][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033872] [Batch 03072/03080] [00:37:57/00:00:05, 0.741s/it]: train_loss_raw=0.9852, running_loss=1.0393, LR=0.000100
[2025-08-27 03:57:10,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 033880] [Batch 03080/03080] [00:38:03/00:00:00, 0.741s/it]: train_loss_raw=0.9729, running_loss=1.0411, LR=0.000100
[2025-08-27 03:57:11,461][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-27 03:57:22,972][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00007/00310] [00:00:11/00:07:14, 1.439s/it]
[2025-08-27 03:57:35,012][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00015/00310] [00:00:23/00:07:12, 1.472s/it]
[2025-08-27 03:57:47,470][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00023/00310] [00:00:36/00:07:09, 1.500s/it]
[2025-08-27 03:58:00,043][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00031/00310] [00:00:48/00:07:02, 1.518s/it]
[2025-08-27 03:58:13,041][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00039/00310] [00:01:01/00:06:55, 1.540s/it]
[2025-08-27 03:58:25,616][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00047/00310] [00:01:14/00:06:44, 1.545s/it]
[2025-08-27 03:58:38,597][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00055/00310] [00:01:27/00:06:35, 1.556s/it]
[2025-08-27 03:58:50,965][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00063/00310] [00:01:39/00:06:22, 1.555s/it]
[2025-08-27 03:59:03,560][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00071/00310] [00:01:52/00:06:10, 1.557s/it]
[2025-08-27 03:59:16,066][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00079/00310] [00:02:04/00:05:58, 1.558s/it]
[2025-08-27 03:59:28,866][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00087/00310] [00:02:17/00:05:46, 1.561s/it]
[2025-08-27 03:59:42,054][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00095/00310] [00:02:30/00:05:35, 1.569s/it]
[2025-08-27 03:59:54,796][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00103/00310] [00:02:43/00:05:23, 1.571s/it]
[2025-08-27 04:00:07,270][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00111/00310] [00:02:55/00:05:10, 1.570s/it]
[2025-08-27 04:00:20,239][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00119/00310] [00:03:08/00:04:58, 1.573s/it]
[2025-08-27 04:00:33,227][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00127/00310] [00:03:21/00:04:46, 1.576s/it]
[2025-08-27 04:00:45,728][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00135/00310] [00:03:34/00:04:34, 1.575s/it]
[2025-08-27 04:00:58,655][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00143/00310] [00:03:47/00:04:21, 1.578s/it]
[2025-08-27 04:01:10,287][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00151/00310] [00:03:58/00:04:08, 1.571s/it]
[2025-08-27 04:01:22,106][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00159/00310] [00:04:10/00:03:54, 1.567s/it]
[2025-08-27 04:01:34,744][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00167/00310] [00:04:23/00:03:42, 1.567s/it]
[2025-08-27 04:01:46,049][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00175/00310] [00:04:34/00:03:29, 1.560s/it]
[2025-08-27 04:01:57,421][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00183/00310] [00:04:45/00:03:15, 1.554s/it]
[2025-08-27 04:02:09,802][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00191/00310] [00:04:58/00:03:03, 1.554s/it]
[2025-08-27 04:02:22,176][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00199/00310] [00:05:10/00:02:50, 1.554s/it]
[2025-08-27 04:02:34,318][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00207/00310] [00:05:22/00:02:38, 1.552s/it]
[2025-08-27 04:02:46,574][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00215/00310] [00:05:35/00:02:25, 1.551s/it]
[2025-08-27 04:02:59,540][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00223/00310] [00:05:48/00:02:13, 1.554s/it]
[2025-08-27 04:03:12,511][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00231/00310] [00:06:01/00:02:01, 1.556s/it]
[2025-08-27 04:03:24,291][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00239/00310] [00:06:12/00:01:48, 1.553s/it]
[2025-08-27 04:03:35,953][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00247/00310] [00:06:24/00:01:36, 1.550s/it]
[2025-08-27 04:03:48,518][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00255/00310] [00:06:37/00:01:23, 1.551s/it]
[2025-08-27 04:04:01,210][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00263/00310] [00:06:49/00:01:11, 1.552s/it]
[2025-08-27 04:04:13,511][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00271/00310] [00:07:02/00:00:58, 1.552s/it]
[2025-08-27 04:04:25,787][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00279/00310] [00:07:14/00:00:46, 1.551s/it]
[2025-08-27 04:04:38,735][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00287/00310] [00:07:27/00:00:34, 1.553s/it]
[2025-08-27 04:04:50,623][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00295/00310] [00:07:39/00:00:21, 1.551s/it]
[2025-08-27 04:05:02,997][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 033881] [Batch 00303/00310] [00:07:51/00:00:09, 1.551s/it]
[2025-08-27 04:05:12,518][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.04114, valid_loss=1.86501
[2025-08-27 04:05:12,518][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-27 04:05:12,518][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.702
[2025-08-27 04:05:12,518][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.048
[2025-08-27 04:05:12,518][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.050
[2025-08-27 04:05:12,519][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.015
[2025-08-27 04:05:12,546][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 08:38:26, remaining time 14:55:29, 00:47:07 per epoch
[2025-08-27 04:05:18,118][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033888] [Batch 00008/03080] [00:00:05/00:33:59, 0.664s/it]: train_loss_raw=1.0311, running_loss=1.0661, LR=0.000100
[2025-08-27 04:05:24,088][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033896] [Batch 00016/03080] [00:00:11/00:36:00, 0.705s/it]: train_loss_raw=1.0554, running_loss=1.0649, LR=0.000100
[2025-08-27 04:05:29,996][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033904] [Batch 00024/03080] [00:00:17/00:36:28, 0.716s/it]: train_loss_raw=0.9425, running_loss=1.0606, LR=0.000100
[2025-08-27 04:05:35,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033912] [Batch 00032/03080] [00:00:23/00:36:44, 0.723s/it]: train_loss_raw=1.0004, running_loss=1.0583, LR=0.000100
[2025-08-27 04:05:41,925][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033920] [Batch 00040/03080] [00:00:29/00:36:52, 0.728s/it]: train_loss_raw=1.0035, running_loss=1.0550, LR=0.000100
[2025-08-27 04:05:47,814][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033928] [Batch 00048/03080] [00:00:35/00:36:51, 0.729s/it]: train_loss_raw=0.9438, running_loss=1.0509, LR=0.000100
[2025-08-27 04:05:53,776][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033936] [Batch 00056/03080] [00:00:40/00:36:52, 0.732s/it]: train_loss_raw=1.0019, running_loss=1.0499, LR=0.000100
[2025-08-27 04:05:59,762][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033944] [Batch 00064/03080] [00:00:46/00:36:52, 0.734s/it]: train_loss_raw=1.1093, running_loss=1.0474, LR=0.000100
[2025-08-27 04:06:05,678][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033952] [Batch 00072/03080] [00:00:52/00:36:48, 0.734s/it]: train_loss_raw=0.9626, running_loss=1.0448, LR=0.000100
[2025-08-27 04:06:11,570][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033960] [Batch 00080/03080] [00:00:58/00:36:43, 0.735s/it]: train_loss_raw=0.9986, running_loss=1.0399, LR=0.000100
[2025-08-27 04:06:17,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033968] [Batch 00088/03080] [00:01:04/00:36:37, 0.735s/it]: train_loss_raw=0.9652, running_loss=1.0395, LR=0.000100
[2025-08-27 04:06:23,395][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033976] [Batch 00096/03080] [00:01:10/00:36:34, 0.735s/it]: train_loss_raw=1.0114, running_loss=1.0363, LR=0.000100
[2025-08-27 04:06:29,476][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033984] [Batch 00104/03080] [00:01:16/00:36:33, 0.737s/it]: train_loss_raw=1.0643, running_loss=1.0363, LR=0.000100
[2025-08-27 04:06:35,387][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 033992] [Batch 00112/03080] [00:01:22/00:36:28, 0.737s/it]: train_loss_raw=0.9710, running_loss=1.0356, LR=0.000100
[2025-08-27 04:06:41,257][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034000] [Batch 00120/03080] [00:01:28/00:36:21, 0.737s/it]: train_loss_raw=1.0047, running_loss=1.0331, LR=0.000100
[2025-08-27 04:06:51,158][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034008] [Batch 00128/03080] [00:01:38/00:37:48, 0.768s/it]: train_loss_raw=1.0564, running_loss=1.0309, LR=0.000100
[2025-08-27 04:06:57,130][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034016] [Batch 00136/03080] [00:01:44/00:37:38, 0.767s/it]: train_loss_raw=1.1011, running_loss=1.0322, LR=0.000100
[2025-08-27 04:07:03,165][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034024] [Batch 00144/03080] [00:01:50/00:37:30, 0.766s/it]: train_loss_raw=1.1091, running_loss=1.0335, LR=0.000100
[2025-08-27 04:07:09,195][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034032] [Batch 00152/03080] [00:01:56/00:37:21, 0.766s/it]: train_loss_raw=0.9469, running_loss=1.0309, LR=0.000100
[2025-08-27 04:07:15,110][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034040] [Batch 00160/03080] [00:02:02/00:37:12, 0.764s/it]: train_loss_raw=1.0353, running_loss=1.0287, LR=0.000100
[2025-08-27 04:07:21,157][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034048] [Batch 00168/03080] [00:02:08/00:37:04, 0.764s/it]: train_loss_raw=1.0568, running_loss=1.0250, LR=0.000100
[2025-08-27 04:07:27,233][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034056] [Batch 00176/03080] [00:02:14/00:36:58, 0.764s/it]: train_loss_raw=0.8970, running_loss=1.0231, LR=0.000100
[2025-08-27 04:07:33,062][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034064] [Batch 00184/03080] [00:02:20/00:36:47, 0.762s/it]: train_loss_raw=1.0913, running_loss=1.0250, LR=0.000100
[2025-08-27 04:07:38,932][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034072] [Batch 00192/03080] [00:02:26/00:36:37, 0.761s/it]: train_loss_raw=1.0531, running_loss=1.0273, LR=0.000100
[2025-08-27 04:07:44,852][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034080] [Batch 00200/03080] [00:02:32/00:36:29, 0.760s/it]: train_loss_raw=1.0707, running_loss=1.0265, LR=0.000100
[2025-08-27 04:07:50,801][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034088] [Batch 00208/03080] [00:02:37/00:36:21, 0.760s/it]: train_loss_raw=0.9088, running_loss=1.0247, LR=0.000100
[2025-08-27 04:07:56,758][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034096] [Batch 00216/03080] [00:02:43/00:36:13, 0.759s/it]: train_loss_raw=1.1061, running_loss=1.0241, LR=0.000100
[2025-08-27 04:08:02,791][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034104] [Batch 00224/03080] [00:02:49/00:36:07, 0.759s/it]: train_loss_raw=1.0749, running_loss=1.0246, LR=0.000100
[2025-08-27 04:08:08,763][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034112] [Batch 00232/03080] [00:02:55/00:35:59, 0.758s/it]: train_loss_raw=0.9642, running_loss=1.0253, LR=0.000100
[2025-08-27 04:08:14,769][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034120] [Batch 00240/03080] [00:03:01/00:35:53, 0.758s/it]: train_loss_raw=1.0107, running_loss=1.0260, LR=0.000100
[2025-08-27 04:08:20,734][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034128] [Batch 00248/03080] [00:03:07/00:35:45, 0.758s/it]: train_loss_raw=0.9995, running_loss=1.0263, LR=0.000100
[2025-08-27 04:08:27,157][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034136] [Batch 00256/03080] [00:03:14/00:35:43, 0.759s/it]: train_loss_raw=0.9888, running_loss=1.0243, LR=0.000100
[2025-08-27 04:08:33,031][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034144] [Batch 00264/03080] [00:03:20/00:35:35, 0.758s/it]: train_loss_raw=1.0416, running_loss=1.0233, LR=0.000100
[2025-08-27 04:08:38,972][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034152] [Batch 00272/03080] [00:03:26/00:35:28, 0.758s/it]: train_loss_raw=1.0329, running_loss=1.0234, LR=0.000100
[2025-08-27 04:08:44,876][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034160] [Batch 00280/03080] [00:03:32/00:35:20, 0.757s/it]: train_loss_raw=1.1037, running_loss=1.0260, LR=0.000100
[2025-08-27 04:08:50,786][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034168] [Batch 00288/03080] [00:03:37/00:35:13, 0.757s/it]: train_loss_raw=0.9743, running_loss=1.0271, LR=0.000100
[2025-08-27 04:08:56,733][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034176] [Batch 00296/03080] [00:03:43/00:35:06, 0.757s/it]: train_loss_raw=0.9591, running_loss=1.0284, LR=0.000100
[2025-08-27 04:09:02,666][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034184] [Batch 00304/03080] [00:03:49/00:34:58, 0.756s/it]: train_loss_raw=1.1213, running_loss=1.0297, LR=0.000100
[2025-08-27 04:09:08,554][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034192] [Batch 00312/03080] [00:03:55/00:34:51, 0.756s/it]: train_loss_raw=1.0260, running_loss=1.0312, LR=0.000100
[2025-08-27 04:09:14,405][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034200] [Batch 00320/03080] [00:04:01/00:34:43, 0.755s/it]: train_loss_raw=0.8855, running_loss=1.0293, LR=0.000100
[2025-08-27 04:09:20,340][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034208] [Batch 00328/03080] [00:04:07/00:34:36, 0.755s/it]: train_loss_raw=1.0562, running_loss=1.0300, LR=0.000100
[2025-08-27 04:09:26,246][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034216] [Batch 00336/03080] [00:04:13/00:34:29, 0.754s/it]: train_loss_raw=1.0418, running_loss=1.0310, LR=0.000100
[2025-08-27 04:09:32,151][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034224] [Batch 00344/03080] [00:04:19/00:34:22, 0.754s/it]: train_loss_raw=0.9827, running_loss=1.0294, LR=0.000100
[2025-08-27 04:09:38,029][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034232] [Batch 00352/03080] [00:04:25/00:34:15, 0.753s/it]: train_loss_raw=1.0206, running_loss=1.0282, LR=0.000100
[2025-08-27 04:09:43,933][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034240] [Batch 00360/03080] [00:04:31/00:34:08, 0.753s/it]: train_loss_raw=0.9920, running_loss=1.0275, LR=0.000100
[2025-08-27 04:09:49,832][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034248] [Batch 00368/03080] [00:04:37/00:34:01, 0.753s/it]: train_loss_raw=0.9793, running_loss=1.0273, LR=0.000100
[2025-08-27 04:09:55,652][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034256] [Batch 00376/03080] [00:04:42/00:33:54, 0.752s/it]: train_loss_raw=0.9734, running_loss=1.0262, LR=0.000100
[2025-08-27 04:10:01,544][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034264] [Batch 00384/03080] [00:04:48/00:33:47, 0.752s/it]: train_loss_raw=0.9456, running_loss=1.0258, LR=0.000100
[2025-08-27 04:10:07,515][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034272] [Batch 00392/03080] [00:04:54/00:33:40, 0.752s/it]: train_loss_raw=0.9741, running_loss=1.0228, LR=0.000100
[2025-08-27 04:10:13,362][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034280] [Batch 00400/03080] [00:05:00/00:33:33, 0.751s/it]: train_loss_raw=1.0904, running_loss=1.0225, LR=0.000100
[2025-08-27 04:10:19,315][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034288] [Batch 00408/03080] [00:05:06/00:33:27, 0.751s/it]: train_loss_raw=1.0121, running_loss=1.0210, LR=0.000100
[2025-08-27 04:10:25,330][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034296] [Batch 00416/03080] [00:05:12/00:33:21, 0.751s/it]: train_loss_raw=1.0030, running_loss=1.0200, LR=0.000100
[2025-08-27 04:10:31,429][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034304] [Batch 00424/03080] [00:05:18/00:33:15, 0.751s/it]: train_loss_raw=0.9594, running_loss=1.0188, LR=0.000100
[2025-08-27 04:10:37,205][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034312] [Batch 00432/03080] [00:05:24/00:33:08, 0.751s/it]: train_loss_raw=1.1167, running_loss=1.0189, LR=0.000100
[2025-08-27 04:10:43,095][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034320] [Batch 00440/03080] [00:05:30/00:33:01, 0.751s/it]: train_loss_raw=1.0123, running_loss=1.0172, LR=0.000100
[2025-08-27 04:10:49,003][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034328] [Batch 00448/03080] [00:05:36/00:32:55, 0.750s/it]: train_loss_raw=1.0306, running_loss=1.0179, LR=0.000100
[2025-08-27 04:10:54,816][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034336] [Batch 00456/03080] [00:05:42/00:32:48, 0.750s/it]: train_loss_raw=1.0815, running_loss=1.0180, LR=0.000100
[2025-08-27 04:11:00,649][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034344] [Batch 00464/03080] [00:05:47/00:32:41, 0.750s/it]: train_loss_raw=0.9980, running_loss=1.0172, LR=0.000100
[2025-08-27 04:11:06,605][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034352] [Batch 00472/03080] [00:05:53/00:32:34, 0.750s/it]: train_loss_raw=0.9765, running_loss=1.0159, LR=0.000100
[2025-08-27 04:11:12,502][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034360] [Batch 00480/03080] [00:05:59/00:32:28, 0.749s/it]: train_loss_raw=1.0353, running_loss=1.0182, LR=0.000100
[2025-08-27 04:11:18,466][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034368] [Batch 00488/03080] [00:06:05/00:32:22, 0.749s/it]: train_loss_raw=1.0579, running_loss=1.0198, LR=0.000100
[2025-08-27 04:11:24,407][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034376] [Batch 00496/03080] [00:06:11/00:32:15, 0.749s/it]: train_loss_raw=0.9569, running_loss=1.0169, LR=0.000100
[2025-08-27 04:11:30,337][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034384] [Batch 00504/03080] [00:06:17/00:32:09, 0.749s/it]: train_loss_raw=0.9902, running_loss=1.0160, LR=0.000100
[2025-08-27 04:11:36,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034392] [Batch 00512/03080] [00:06:23/00:32:03, 0.749s/it]: train_loss_raw=1.0133, running_loss=1.0153, LR=0.000100
[2025-08-27 04:11:42,070][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034400] [Batch 00520/03080] [00:06:29/00:31:56, 0.749s/it]: train_loss_raw=0.9588, running_loss=1.0160, LR=0.000100
[2025-08-27 04:11:48,056][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034408] [Batch 00528/03080] [00:06:35/00:31:50, 0.749s/it]: train_loss_raw=0.9924, running_loss=1.0173, LR=0.000100
[2025-08-27 04:11:53,938][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034416] [Batch 00536/03080] [00:06:41/00:31:43, 0.748s/it]: train_loss_raw=0.9966, running_loss=1.0171, LR=0.000100
[2025-08-27 04:11:59,708][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034424] [Batch 00544/03080] [00:06:46/00:31:36, 0.748s/it]: train_loss_raw=0.9473, running_loss=1.0172, LR=0.000100
[2025-08-27 04:12:05,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034432] [Batch 00552/03080] [00:06:52/00:31:30, 0.748s/it]: train_loss_raw=0.9204, running_loss=1.0168, LR=0.000100
[2025-08-27 04:12:11,527][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034440] [Batch 00560/03080] [00:06:58/00:31:24, 0.748s/it]: train_loss_raw=1.0237, running_loss=1.0163, LR=0.000100
[2025-08-27 04:12:17,553][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034448] [Batch 00568/03080] [00:07:04/00:31:18, 0.748s/it]: train_loss_raw=0.9880, running_loss=1.0166, LR=0.000100
[2025-08-27 04:12:23,440][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034456] [Batch 00576/03080] [00:07:10/00:31:12, 0.748s/it]: train_loss_raw=1.1201, running_loss=1.0164, LR=0.000100
[2025-08-27 04:12:29,327][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034464] [Batch 00584/03080] [00:07:16/00:31:05, 0.747s/it]: train_loss_raw=1.0563, running_loss=1.0165, LR=0.000100
[2025-08-27 04:12:35,278][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034472] [Batch 00592/03080] [00:07:22/00:30:59, 0.747s/it]: train_loss_raw=1.1051, running_loss=1.0170, LR=0.000100
[2025-08-27 04:12:41,287][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034480] [Batch 00600/03080] [00:07:28/00:30:53, 0.747s/it]: train_loss_raw=0.9777, running_loss=1.0158, LR=0.000100
[2025-08-27 04:12:47,198][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034488] [Batch 00608/03080] [00:07:34/00:30:47, 0.747s/it]: train_loss_raw=1.0497, running_loss=1.0168, LR=0.000100
[2025-08-27 04:12:53,170][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034496] [Batch 00616/03080] [00:07:40/00:30:41, 0.747s/it]: train_loss_raw=1.0940, running_loss=1.0151, LR=0.000100
[2025-08-27 04:12:59,105][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034504] [Batch 00624/03080] [00:07:46/00:30:35, 0.747s/it]: train_loss_raw=1.0272, running_loss=1.0129, LR=0.000100
[2025-08-27 04:13:04,971][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034512] [Batch 00632/03080] [00:07:52/00:30:28, 0.747s/it]: train_loss_raw=0.9444, running_loss=1.0144, LR=0.000100
[2025-08-27 04:13:10,931][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034520] [Batch 00640/03080] [00:07:58/00:30:22, 0.747s/it]: train_loss_raw=0.9231, running_loss=1.0129, LR=0.000100
[2025-08-27 04:13:16,861][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034528] [Batch 00648/03080] [00:08:04/00:30:16, 0.747s/it]: train_loss_raw=0.9690, running_loss=1.0144, LR=0.000100
[2025-08-27 04:13:22,732][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034536] [Batch 00656/03080] [00:08:09/00:30:10, 0.747s/it]: train_loss_raw=0.9512, running_loss=1.0097, LR=0.000100
[2025-08-27 04:13:28,643][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034544] [Batch 00664/03080] [00:08:15/00:30:04, 0.747s/it]: train_loss_raw=0.9653, running_loss=1.0128, LR=0.000100
[2025-08-27 04:13:34,525][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034552] [Batch 00672/03080] [00:08:21/00:29:57, 0.747s/it]: train_loss_raw=1.1011, running_loss=1.0124, LR=0.000100
[2025-08-27 04:13:40,392][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034560] [Batch 00680/03080] [00:08:27/00:29:51, 0.746s/it]: train_loss_raw=1.0272, running_loss=1.0122, LR=0.000100
[2025-08-27 04:13:46,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034568] [Batch 00688/03080] [00:08:33/00:29:44, 0.746s/it]: train_loss_raw=1.0519, running_loss=1.0140, LR=0.000100
[2025-08-27 04:13:52,059][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034576] [Batch 00696/03080] [00:08:39/00:29:38, 0.746s/it]: train_loss_raw=1.0529, running_loss=1.0135, LR=0.000100
[2025-08-27 04:13:58,000][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034584] [Batch 00704/03080] [00:08:45/00:29:32, 0.746s/it]: train_loss_raw=1.0289, running_loss=1.0133, LR=0.000100
[2025-08-27 04:14:03,837][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034592] [Batch 00712/03080] [00:08:51/00:29:26, 0.746s/it]: train_loss_raw=0.9937, running_loss=1.0124, LR=0.000100
[2025-08-27 04:14:09,930][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034600] [Batch 00720/03080] [00:08:57/00:29:20, 0.746s/it]: train_loss_raw=0.9627, running_loss=1.0130, LR=0.000100
[2025-08-27 04:14:16,021][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034608] [Batch 00728/03080] [00:09:03/00:29:14, 0.746s/it]: train_loss_raw=0.9592, running_loss=1.0113, LR=0.000100
[2025-08-27 04:14:21,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034616] [Batch 00736/03080] [00:09:09/00:29:08, 0.746s/it]: train_loss_raw=0.9799, running_loss=1.0139, LR=0.000100
[2025-08-27 04:14:27,819][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034624] [Batch 00744/03080] [00:09:15/00:29:02, 0.746s/it]: train_loss_raw=1.0379, running_loss=1.0127, LR=0.000100
[2025-08-27 04:14:33,729][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034632] [Batch 00752/03080] [00:09:20/00:28:56, 0.746s/it]: train_loss_raw=1.0017, running_loss=1.0137, LR=0.000100
[2025-08-27 04:14:39,609][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034640] [Batch 00760/03080] [00:09:26/00:28:50, 0.746s/it]: train_loss_raw=0.9239, running_loss=1.0140, LR=0.000100
[2025-08-27 04:14:45,631][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034648] [Batch 00768/03080] [00:09:32/00:28:44, 0.746s/it]: train_loss_raw=1.1021, running_loss=1.0153, LR=0.000100
[2025-08-27 04:14:51,808][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034656] [Batch 00776/03080] [00:09:38/00:28:39, 0.746s/it]: train_loss_raw=0.9193, running_loss=1.0165, LR=0.000100
[2025-08-27 04:14:57,690][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034664] [Batch 00784/03080] [00:09:44/00:28:32, 0.746s/it]: train_loss_raw=0.9563, running_loss=1.0157, LR=0.000100
[2025-08-27 04:15:03,607][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034672] [Batch 00792/03080] [00:09:50/00:28:26, 0.746s/it]: train_loss_raw=1.0267, running_loss=1.0156, LR=0.000100
[2025-08-27 04:15:09,491][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034680] [Batch 00800/03080] [00:09:56/00:28:20, 0.746s/it]: train_loss_raw=1.0205, running_loss=1.0134, LR=0.000100
[2025-08-27 04:15:15,283][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034688] [Batch 00808/03080] [00:10:02/00:28:14, 0.746s/it]: train_loss_raw=0.9817, running_loss=1.0107, LR=0.000100
[2025-08-27 04:15:21,090][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034696] [Batch 00816/03080] [00:10:08/00:28:07, 0.745s/it]: train_loss_raw=0.9584, running_loss=1.0088, LR=0.000100
[2025-08-27 04:15:27,043][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034704] [Batch 00824/03080] [00:10:14/00:28:01, 0.745s/it]: train_loss_raw=0.9943, running_loss=1.0093, LR=0.000100
[2025-08-27 04:15:33,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034712] [Batch 00832/03080] [00:10:20/00:27:56, 0.746s/it]: train_loss_raw=1.1395, running_loss=1.0082, LR=0.000100
[2025-08-27 04:15:39,226][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034720] [Batch 00840/03080] [00:10:26/00:27:50, 0.746s/it]: train_loss_raw=0.9118, running_loss=1.0086, LR=0.000100
[2025-08-27 04:15:45,242][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034728] [Batch 00848/03080] [00:10:32/00:27:44, 0.746s/it]: train_loss_raw=0.9806, running_loss=1.0085, LR=0.000100
[2025-08-27 04:15:51,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034736] [Batch 00856/03080] [00:10:38/00:27:39, 0.746s/it]: train_loss_raw=1.1598, running_loss=1.0083, LR=0.000100
[2025-08-27 04:15:57,637][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034744] [Batch 00864/03080] [00:10:44/00:27:33, 0.746s/it]: train_loss_raw=1.0917, running_loss=1.0102, LR=0.000100
[2025-08-27 04:16:03,828][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034752] [Batch 00872/03080] [00:10:51/00:27:28, 0.747s/it]: train_loss_raw=0.9987, running_loss=1.0093, LR=0.000100
[2025-08-27 04:16:09,675][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034760] [Batch 00880/03080] [00:10:56/00:27:22, 0.746s/it]: train_loss_raw=1.0124, running_loss=1.0083, LR=0.000100
[2025-08-27 04:16:15,635][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034768] [Batch 00888/03080] [00:11:02/00:27:16, 0.746s/it]: train_loss_raw=0.9950, running_loss=1.0084, LR=0.000100
[2025-08-27 04:16:21,610][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034776] [Batch 00896/03080] [00:11:08/00:27:10, 0.746s/it]: train_loss_raw=0.9360, running_loss=1.0042, LR=0.000100
[2025-08-27 04:16:27,519][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034784] [Batch 00904/03080] [00:11:14/00:27:04, 0.746s/it]: train_loss_raw=1.0892, running_loss=1.0060, LR=0.000100
[2025-08-27 04:16:33,381][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034792] [Batch 00912/03080] [00:11:20/00:26:57, 0.746s/it]: train_loss_raw=1.0035, running_loss=1.0070, LR=0.000100
[2025-08-27 04:16:39,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034800] [Batch 00920/03080] [00:11:26/00:26:51, 0.746s/it]: train_loss_raw=0.9983, running_loss=1.0054, LR=0.000100
[2025-08-27 04:16:45,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034808] [Batch 00928/03080] [00:11:32/00:26:45, 0.746s/it]: train_loss_raw=0.9675, running_loss=1.0038, LR=0.000100
[2025-08-27 04:16:51,200][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034816] [Batch 00936/03080] [00:11:38/00:26:39, 0.746s/it]: train_loss_raw=0.9381, running_loss=1.0019, LR=0.000100
[2025-08-27 04:16:57,212][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034824] [Batch 00944/03080] [00:11:44/00:26:33, 0.746s/it]: train_loss_raw=1.0304, running_loss=1.0028, LR=0.000100
[2025-08-27 04:17:03,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034832] [Batch 00952/03080] [00:11:50/00:26:27, 0.746s/it]: train_loss_raw=1.0147, running_loss=1.0020, LR=0.000100
[2025-08-27 04:17:09,304][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034840] [Batch 00960/03080] [00:11:56/00:26:22, 0.746s/it]: train_loss_raw=1.0063, running_loss=1.0024, LR=0.000100
[2025-08-27 04:17:15,235][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034848] [Batch 00968/03080] [00:12:02/00:26:16, 0.746s/it]: train_loss_raw=1.0736, running_loss=1.0012, LR=0.000100
[2025-08-27 04:17:21,165][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034856] [Batch 00976/03080] [00:12:08/00:26:10, 0.746s/it]: train_loss_raw=0.9682, running_loss=1.0022, LR=0.000100
[2025-08-27 04:17:27,106][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034864] [Batch 00984/03080] [00:12:14/00:26:04, 0.746s/it]: train_loss_raw=0.8934, running_loss=1.0038, LR=0.000100
[2025-08-27 04:17:32,919][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034872] [Batch 00992/03080] [00:12:20/00:25:57, 0.746s/it]: train_loss_raw=0.9998, running_loss=1.0032, LR=0.000100
[2025-08-27 04:17:38,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034880] [Batch 01000/03080] [00:12:26/00:25:51, 0.746s/it]: train_loss_raw=0.9944, running_loss=1.0042, LR=0.000100
[2025-08-27 04:17:44,802][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034888] [Batch 01008/03080] [00:12:31/00:25:45, 0.746s/it]: train_loss_raw=1.0048, running_loss=1.0056, LR=0.000100
[2025-08-27 04:17:50,673][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034896] [Batch 01016/03080] [00:12:37/00:25:39, 0.746s/it]: train_loss_raw=1.0465, running_loss=1.0053, LR=0.000100
[2025-08-27 04:17:56,567][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034904] [Batch 01024/03080] [00:12:43/00:25:33, 0.746s/it]: train_loss_raw=1.1275, running_loss=1.0055, LR=0.000100
[2025-08-27 04:18:02,437][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034912] [Batch 01032/03080] [00:12:49/00:25:27, 0.746s/it]: train_loss_raw=1.0602, running_loss=1.0055, LR=0.000100
[2025-08-27 04:18:08,243][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034920] [Batch 01040/03080] [00:12:55/00:25:21, 0.746s/it]: train_loss_raw=0.9642, running_loss=1.0035, LR=0.000100
[2025-08-27 04:18:14,074][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034928] [Batch 01048/03080] [00:13:01/00:25:14, 0.745s/it]: train_loss_raw=0.9523, running_loss=1.0020, LR=0.000100
[2025-08-27 04:18:19,917][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034936] [Batch 01056/03080] [00:13:07/00:25:08, 0.745s/it]: train_loss_raw=1.0620, running_loss=1.0029, LR=0.000100
[2025-08-27 04:18:25,775][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034944] [Batch 01064/03080] [00:13:12/00:25:02, 0.745s/it]: train_loss_raw=0.9332, running_loss=1.0042, LR=0.000100
[2025-08-27 04:18:31,569][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034952] [Batch 01072/03080] [00:13:18/00:24:56, 0.745s/it]: train_loss_raw=0.9099, running_loss=1.0010, LR=0.000100
[2025-08-27 04:18:37,453][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034960] [Batch 01080/03080] [00:13:24/00:24:50, 0.745s/it]: train_loss_raw=1.0841, running_loss=1.0024, LR=0.000100
[2025-08-27 04:18:43,296][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034968] [Batch 01088/03080] [00:13:30/00:24:43, 0.745s/it]: train_loss_raw=0.9579, running_loss=1.0017, LR=0.000100
[2025-08-27 04:18:49,170][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034976] [Batch 01096/03080] [00:13:36/00:24:37, 0.745s/it]: train_loss_raw=1.0008, running_loss=1.0004, LR=0.000100
[2025-08-27 04:18:55,019][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034984] [Batch 01104/03080] [00:13:42/00:24:31, 0.745s/it]: train_loss_raw=0.9504, running_loss=0.9998, LR=0.000100
[2025-08-27 04:19:00,895][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 034992] [Batch 01112/03080] [00:13:48/00:24:25, 0.745s/it]: train_loss_raw=0.9893, running_loss=1.0033, LR=0.000100
[2025-08-27 04:19:06,883][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035000] [Batch 01120/03080] [00:13:54/00:24:19, 0.745s/it]: train_loss_raw=1.1147, running_loss=1.0052, LR=0.000100
[2025-08-27 04:19:12,750][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035008] [Batch 01128/03080] [00:13:59/00:24:13, 0.745s/it]: train_loss_raw=1.0886, running_loss=1.0055, LR=0.000100
[2025-08-27 04:19:18,679][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035016] [Batch 01136/03080] [00:14:05/00:24:07, 0.745s/it]: train_loss_raw=0.9859, running_loss=1.0031, LR=0.000100
[2025-08-27 04:19:24,546][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035024] [Batch 01144/03080] [00:14:11/00:24:01, 0.745s/it]: train_loss_raw=1.0708, running_loss=1.0002, LR=0.000100
[2025-08-27 04:19:30,486][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035032] [Batch 01152/03080] [00:14:17/00:23:55, 0.745s/it]: train_loss_raw=0.9384, running_loss=0.9985, LR=0.000100
[2025-08-27 04:19:36,508][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035040] [Batch 01160/03080] [00:14:23/00:23:49, 0.745s/it]: train_loss_raw=1.0793, running_loss=1.0003, LR=0.000100
[2025-08-27 04:19:42,443][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035048] [Batch 01168/03080] [00:14:29/00:23:43, 0.745s/it]: train_loss_raw=0.9069, running_loss=1.0013, LR=0.000100
[2025-08-27 04:19:48,358][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035056] [Batch 01176/03080] [00:14:35/00:23:37, 0.745s/it]: train_loss_raw=1.0682, running_loss=1.0041, LR=0.000100
[2025-08-27 04:19:54,215][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035064] [Batch 01184/03080] [00:14:41/00:23:31, 0.744s/it]: train_loss_raw=0.9161, running_loss=1.0039, LR=0.000100
[2025-08-27 04:20:00,097][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035072] [Batch 01192/03080] [00:14:47/00:23:25, 0.744s/it]: train_loss_raw=0.9473, running_loss=1.0018, LR=0.000100
[2025-08-27 04:20:05,988][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035080] [Batch 01200/03080] [00:14:53/00:23:19, 0.744s/it]: train_loss_raw=0.9907, running_loss=1.0000, LR=0.000100
[2025-08-27 04:20:12,012][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035088] [Batch 01208/03080] [00:14:59/00:23:13, 0.744s/it]: train_loss_raw=1.0447, running_loss=0.9982, LR=0.000100
[2025-08-27 04:20:18,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035096] [Batch 01216/03080] [00:15:05/00:23:07, 0.745s/it]: train_loss_raw=1.0980, running_loss=0.9975, LR=0.000100
[2025-08-27 04:20:24,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035104] [Batch 01224/03080] [00:15:11/00:23:02, 0.745s/it]: train_loss_raw=0.9367, running_loss=0.9994, LR=0.000100
[2025-08-27 04:20:30,025][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035112] [Batch 01232/03080] [00:15:17/00:22:55, 0.744s/it]: train_loss_raw=0.9916, running_loss=0.9981, LR=0.000100
[2025-08-27 04:20:35,964][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035120] [Batch 01240/03080] [00:15:23/00:22:49, 0.744s/it]: train_loss_raw=1.0726, running_loss=0.9992, LR=0.000100
[2025-08-27 04:20:41,911][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035128] [Batch 01248/03080] [00:15:29/00:22:43, 0.744s/it]: train_loss_raw=0.8525, running_loss=0.9963, LR=0.000100
[2025-08-27 04:20:47,807][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035136] [Batch 01256/03080] [00:15:34/00:22:37, 0.744s/it]: train_loss_raw=0.8882, running_loss=0.9966, LR=0.000100
[2025-08-27 04:20:53,743][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035144] [Batch 01264/03080] [00:15:40/00:22:31, 0.744s/it]: train_loss_raw=1.0209, running_loss=0.9964, LR=0.000100
[2025-08-27 04:20:59,567][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035152] [Batch 01272/03080] [00:15:46/00:22:25, 0.744s/it]: train_loss_raw=0.9362, running_loss=0.9955, LR=0.000100
[2025-08-27 04:21:05,440][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035160] [Batch 01280/03080] [00:15:52/00:22:19, 0.744s/it]: train_loss_raw=1.0656, running_loss=0.9956, LR=0.000100
[2025-08-27 04:21:11,308][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035168] [Batch 01288/03080] [00:15:58/00:22:13, 0.744s/it]: train_loss_raw=0.8968, running_loss=0.9959, LR=0.000100
[2025-08-27 04:21:17,346][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035176] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=1.0071, running_loss=0.9989, LR=0.000100
[2025-08-27 04:21:23,385][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035184] [Batch 01304/03080] [00:16:10/00:22:01, 0.744s/it]: train_loss_raw=1.0383, running_loss=0.9984, LR=0.000100
[2025-08-27 04:21:29,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035192] [Batch 01312/03080] [00:16:16/00:21:55, 0.744s/it]: train_loss_raw=0.9361, running_loss=0.9980, LR=0.000100
[2025-08-27 04:21:35,269][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035200] [Batch 01320/03080] [00:16:22/00:21:49, 0.744s/it]: train_loss_raw=1.0349, running_loss=0.9969, LR=0.000100
[2025-08-27 04:21:41,136][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035208] [Batch 01328/03080] [00:16:28/00:21:43, 0.744s/it]: train_loss_raw=0.9362, running_loss=0.9967, LR=0.000100
[2025-08-27 04:21:47,085][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035216] [Batch 01336/03080] [00:16:34/00:21:37, 0.744s/it]: train_loss_raw=0.9376, running_loss=0.9934, LR=0.000100
[2025-08-27 04:21:53,070][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035224] [Batch 01344/03080] [00:16:40/00:21:32, 0.744s/it]: train_loss_raw=1.0108, running_loss=0.9936, LR=0.000100
[2025-08-27 04:21:58,948][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035232] [Batch 01352/03080] [00:16:46/00:21:25, 0.744s/it]: train_loss_raw=1.0178, running_loss=0.9939, LR=0.000100
[2025-08-27 04:22:04,865][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035240] [Batch 01360/03080] [00:16:52/00:21:19, 0.744s/it]: train_loss_raw=0.9934, running_loss=0.9943, LR=0.000100
[2025-08-27 04:22:10,791][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035248] [Batch 01368/03080] [00:16:57/00:21:13, 0.744s/it]: train_loss_raw=1.1060, running_loss=0.9979, LR=0.000100
[2025-08-27 04:22:16,719][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035256] [Batch 01376/03080] [00:17:03/00:21:07, 0.744s/it]: train_loss_raw=0.9648, running_loss=0.9963, LR=0.000100
[2025-08-27 04:22:22,623][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035264] [Batch 01384/03080] [00:17:09/00:21:01, 0.744s/it]: train_loss_raw=1.0385, running_loss=0.9959, LR=0.000100
[2025-08-27 04:22:28,615][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035272] [Batch 01392/03080] [00:17:15/00:20:56, 0.744s/it]: train_loss_raw=0.9446, running_loss=0.9952, LR=0.000100
[2025-08-27 04:22:34,680][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035280] [Batch 01400/03080] [00:17:21/00:20:50, 0.744s/it]: train_loss_raw=1.0071, running_loss=0.9984, LR=0.000100
[2025-08-27 04:22:40,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035288] [Batch 01408/03080] [00:17:27/00:20:44, 0.744s/it]: train_loss_raw=0.9650, running_loss=0.9980, LR=0.000100
[2025-08-27 04:22:46,481][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035296] [Batch 01416/03080] [00:17:33/00:20:38, 0.744s/it]: train_loss_raw=0.9637, running_loss=0.9957, LR=0.000100
[2025-08-27 04:22:52,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035304] [Batch 01424/03080] [00:17:39/00:20:32, 0.744s/it]: train_loss_raw=0.9163, running_loss=0.9942, LR=0.000100
[2025-08-27 04:22:58,418][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035312] [Batch 01432/03080] [00:17:45/00:20:26, 0.744s/it]: train_loss_raw=1.0555, running_loss=0.9936, LR=0.000100
[2025-08-27 04:23:04,344][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035320] [Batch 01440/03080] [00:17:51/00:20:20, 0.744s/it]: train_loss_raw=0.8835, running_loss=0.9910, LR=0.000100
[2025-08-27 04:23:10,256][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035328] [Batch 01448/03080] [00:17:57/00:20:14, 0.744s/it]: train_loss_raw=0.9218, running_loss=0.9905, LR=0.000100
[2025-08-27 04:23:16,106][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035336] [Batch 01456/03080] [00:18:03/00:20:08, 0.744s/it]: train_loss_raw=0.9697, running_loss=0.9905, LR=0.000100
[2025-08-27 04:23:22,255][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035344] [Batch 01464/03080] [00:18:09/00:20:02, 0.744s/it]: train_loss_raw=0.9028, running_loss=0.9874, LR=0.000100
[2025-08-27 04:23:28,206][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035352] [Batch 01472/03080] [00:18:15/00:19:56, 0.744s/it]: train_loss_raw=0.9815, running_loss=0.9881, LR=0.000100
[2025-08-27 04:23:34,260][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035360] [Batch 01480/03080] [00:18:21/00:19:50, 0.744s/it]: train_loss_raw=0.8927, running_loss=0.9866, LR=0.000100
[2025-08-27 04:23:40,241][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035368] [Batch 01488/03080] [00:18:27/00:19:44, 0.744s/it]: train_loss_raw=1.0541, running_loss=0.9886, LR=0.000100
[2025-08-27 04:23:46,039][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035376] [Batch 01496/03080] [00:18:33/00:19:38, 0.744s/it]: train_loss_raw=1.0269, running_loss=0.9895, LR=0.000100
[2025-08-27 04:23:51,962][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035384] [Batch 01504/03080] [00:18:39/00:19:32, 0.744s/it]: train_loss_raw=1.0456, running_loss=0.9924, LR=0.000100
[2025-08-27 04:23:57,843][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035392] [Batch 01512/03080] [00:18:45/00:19:26, 0.744s/it]: train_loss_raw=0.8606, running_loss=0.9904, LR=0.000100
[2025-08-27 04:24:03,704][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035400] [Batch 01520/03080] [00:18:50/00:19:20, 0.744s/it]: train_loss_raw=1.0508, running_loss=0.9879, LR=0.000100
[2025-08-27 04:24:09,629][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035408] [Batch 01528/03080] [00:18:56/00:19:14, 0.744s/it]: train_loss_raw=0.9342, running_loss=0.9871, LR=0.000100
[2025-08-27 04:24:15,567][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035416] [Batch 01536/03080] [00:19:02/00:19:08, 0.744s/it]: train_loss_raw=1.0046, running_loss=0.9896, LR=0.000100
[2025-08-27 04:24:21,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035424] [Batch 01544/03080] [00:19:08/00:19:02, 0.744s/it]: train_loss_raw=0.9222, running_loss=0.9907, LR=0.000100
[2025-08-27 04:24:27,678][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035432] [Batch 01552/03080] [00:19:14/00:18:57, 0.744s/it]: train_loss_raw=0.9804, running_loss=0.9930, LR=0.000100
[2025-08-27 04:24:33,494][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035440] [Batch 01560/03080] [00:19:20/00:18:50, 0.744s/it]: train_loss_raw=1.0350, running_loss=0.9927, LR=0.000100
[2025-08-27 04:24:39,520][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035448] [Batch 01568/03080] [00:19:26/00:18:45, 0.744s/it]: train_loss_raw=1.0252, running_loss=0.9907, LR=0.000100
[2025-08-27 04:24:45,487][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035456] [Batch 01576/03080] [00:19:32/00:18:39, 0.744s/it]: train_loss_raw=0.9417, running_loss=0.9922, LR=0.000100
[2025-08-27 04:24:51,541][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035464] [Batch 01584/03080] [00:19:38/00:18:33, 0.744s/it]: train_loss_raw=1.0163, running_loss=0.9935, LR=0.000100
[2025-08-27 04:24:57,549][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035472] [Batch 01592/03080] [00:19:44/00:18:27, 0.744s/it]: train_loss_raw=0.9423, running_loss=0.9926, LR=0.000100
[2025-08-27 04:25:03,471][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035480] [Batch 01600/03080] [00:19:50/00:18:21, 0.744s/it]: train_loss_raw=0.9747, running_loss=0.9928, LR=0.000100
[2025-08-27 04:25:09,394][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035488] [Batch 01608/03080] [00:19:56/00:18:15, 0.744s/it]: train_loss_raw=1.0386, running_loss=0.9958, LR=0.000100
[2025-08-27 04:25:15,409][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035496] [Batch 01616/03080] [00:20:02/00:18:09, 0.744s/it]: train_loss_raw=0.9521, running_loss=0.9961, LR=0.000100
[2025-08-27 04:25:21,301][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035504] [Batch 01624/03080] [00:20:08/00:18:03, 0.744s/it]: train_loss_raw=1.0201, running_loss=0.9944, LR=0.000100
[2025-08-27 04:25:27,194][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035512] [Batch 01632/03080] [00:20:14/00:17:57, 0.744s/it]: train_loss_raw=0.8724, running_loss=0.9909, LR=0.000100
[2025-08-27 04:25:33,267][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035520] [Batch 01640/03080] [00:20:20/00:17:51, 0.744s/it]: train_loss_raw=0.9059, running_loss=0.9887, LR=0.000100
[2025-08-27 04:25:39,257][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035528] [Batch 01648/03080] [00:20:26/00:17:45, 0.744s/it]: train_loss_raw=1.0885, running_loss=0.9870, LR=0.000100
[2025-08-27 04:25:45,271][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035536] [Batch 01656/03080] [00:20:32/00:17:39, 0.744s/it]: train_loss_raw=1.0123, running_loss=0.9880, LR=0.000100
[2025-08-27 04:25:51,314][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035544] [Batch 01664/03080] [00:20:38/00:17:33, 0.744s/it]: train_loss_raw=0.9530, running_loss=0.9881, LR=0.000100
[2025-08-27 04:25:57,193][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035552] [Batch 01672/03080] [00:20:44/00:17:27, 0.744s/it]: train_loss_raw=0.9072, running_loss=0.9823, LR=0.000100
[2025-08-27 04:26:03,154][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035560] [Batch 01680/03080] [00:20:50/00:17:21, 0.744s/it]: train_loss_raw=0.9054, running_loss=0.9819, LR=0.000100
[2025-08-27 04:26:09,064][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035568] [Batch 01688/03080] [00:20:56/00:17:15, 0.744s/it]: train_loss_raw=0.9822, running_loss=0.9791, LR=0.000100
[2025-08-27 04:26:15,075][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035576] [Batch 01696/03080] [00:21:02/00:17:10, 0.744s/it]: train_loss_raw=1.0084, running_loss=0.9816, LR=0.000100
[2025-08-27 04:26:21,107][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035584] [Batch 01704/03080] [00:21:08/00:17:04, 0.744s/it]: train_loss_raw=1.0727, running_loss=0.9809, LR=0.000100
[2025-08-27 04:26:27,014][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035592] [Batch 01712/03080] [00:21:14/00:16:58, 0.744s/it]: train_loss_raw=1.0209, running_loss=0.9832, LR=0.000100
[2025-08-27 04:26:32,985][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035600] [Batch 01720/03080] [00:21:20/00:16:52, 0.744s/it]: train_loss_raw=0.8956, running_loss=0.9799, LR=0.000100
[2025-08-27 04:26:38,886][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035608] [Batch 01728/03080] [00:21:26/00:16:46, 0.744s/it]: train_loss_raw=0.9529, running_loss=0.9807, LR=0.000100
[2025-08-27 04:26:45,153][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035616] [Batch 01736/03080] [00:21:32/00:16:40, 0.744s/it]: train_loss_raw=1.0265, running_loss=0.9794, LR=0.000100
[2025-08-27 04:26:51,087][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035624] [Batch 01744/03080] [00:21:38/00:16:34, 0.744s/it]: train_loss_raw=0.9608, running_loss=0.9810, LR=0.000100
[2025-08-27 04:26:57,051][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035632] [Batch 01752/03080] [00:21:44/00:16:28, 0.744s/it]: train_loss_raw=0.9828, running_loss=0.9793, LR=0.000100
[2025-08-27 04:27:02,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035640] [Batch 01760/03080] [00:21:50/00:16:22, 0.744s/it]: train_loss_raw=0.8231, running_loss=0.9770, LR=0.000100
[2025-08-27 04:27:08,793][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035648] [Batch 01768/03080] [00:21:55/00:16:16, 0.744s/it]: train_loss_raw=1.0252, running_loss=0.9772, LR=0.000100
[2025-08-27 04:27:14,679][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035656] [Batch 01776/03080] [00:22:01/00:16:10, 0.744s/it]: train_loss_raw=1.0453, running_loss=0.9762, LR=0.000100
[2025-08-27 04:27:20,602][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035664] [Batch 01784/03080] [00:22:07/00:16:04, 0.744s/it]: train_loss_raw=1.0105, running_loss=0.9799, LR=0.000100
[2025-08-27 04:27:26,483][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035672] [Batch 01792/03080] [00:22:13/00:15:58, 0.744s/it]: train_loss_raw=0.9553, running_loss=0.9798, LR=0.000100
[2025-08-27 04:27:32,415][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035680] [Batch 01800/03080] [00:22:19/00:15:52, 0.744s/it]: train_loss_raw=0.9602, running_loss=0.9825, LR=0.000100
[2025-08-27 04:27:38,428][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035688] [Batch 01808/03080] [00:22:25/00:15:46, 0.744s/it]: train_loss_raw=1.0351, running_loss=0.9804, LR=0.000100
[2025-08-27 04:27:44,361][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035696] [Batch 01816/03080] [00:22:31/00:15:40, 0.744s/it]: train_loss_raw=0.9068, running_loss=0.9800, LR=0.000100
[2025-08-27 04:27:50,283][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035704] [Batch 01824/03080] [00:22:37/00:15:34, 0.744s/it]: train_loss_raw=1.0615, running_loss=0.9826, LR=0.000100
[2025-08-27 04:27:56,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035712] [Batch 01832/03080] [00:22:43/00:15:28, 0.744s/it]: train_loss_raw=0.9845, running_loss=0.9812, LR=0.000100
[2025-08-27 04:28:02,229][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035720] [Batch 01840/03080] [00:22:49/00:15:22, 0.744s/it]: train_loss_raw=1.0928, running_loss=0.9798, LR=0.000100
[2025-08-27 04:28:08,130][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035728] [Batch 01848/03080] [00:22:55/00:15:16, 0.744s/it]: train_loss_raw=1.0692, running_loss=0.9818, LR=0.000100
[2025-08-27 04:28:14,089][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035736] [Batch 01856/03080] [00:23:01/00:15:10, 0.744s/it]: train_loss_raw=0.9773, running_loss=0.9813, LR=0.000100
[2025-08-27 04:28:20,070][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035744] [Batch 01864/03080] [00:23:07/00:15:04, 0.744s/it]: train_loss_raw=0.9085, running_loss=0.9807, LR=0.000100
[2025-08-27 04:28:26,046][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035752] [Batch 01872/03080] [00:23:13/00:14:59, 0.744s/it]: train_loss_raw=0.9450, running_loss=0.9808, LR=0.000100
[2025-08-27 04:28:32,003][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035760] [Batch 01880/03080] [00:23:19/00:14:53, 0.744s/it]: train_loss_raw=1.1097, running_loss=0.9837, LR=0.000100
[2025-08-27 04:28:37,979][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035768] [Batch 01888/03080] [00:23:25/00:14:47, 0.744s/it]: train_loss_raw=1.0166, running_loss=0.9847, LR=0.000100
[2025-08-27 04:28:44,069][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035776] [Batch 01896/03080] [00:23:31/00:14:41, 0.744s/it]: train_loss_raw=1.0552, running_loss=0.9853, LR=0.000100
[2025-08-27 04:28:50,126][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035784] [Batch 01904/03080] [00:23:37/00:14:35, 0.744s/it]: train_loss_raw=0.9846, running_loss=0.9818, LR=0.000100
[2025-08-27 04:28:56,064][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035792] [Batch 01912/03080] [00:23:43/00:14:29, 0.744s/it]: train_loss_raw=1.0294, running_loss=0.9818, LR=0.000100
[2025-08-27 04:29:02,146][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035800] [Batch 01920/03080] [00:23:49/00:14:23, 0.744s/it]: train_loss_raw=1.0009, running_loss=0.9812, LR=0.000100
[2025-08-27 04:29:08,187][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035808] [Batch 01928/03080] [00:23:55/00:14:17, 0.744s/it]: train_loss_raw=0.9913, running_loss=0.9811, LR=0.000100
[2025-08-27 04:29:14,244][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035816] [Batch 01936/03080] [00:24:01/00:14:11, 0.745s/it]: train_loss_raw=0.9211, running_loss=0.9799, LR=0.000100
[2025-08-27 04:29:20,267][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035824] [Batch 01944/03080] [00:24:07/00:14:05, 0.745s/it]: train_loss_raw=1.0058, running_loss=0.9763, LR=0.000100
[2025-08-27 04:29:26,228][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035832] [Batch 01952/03080] [00:24:13/00:13:59, 0.745s/it]: train_loss_raw=0.9769, running_loss=0.9783, LR=0.000100
[2025-08-27 04:29:32,232][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035840] [Batch 01960/03080] [00:24:19/00:13:53, 0.745s/it]: train_loss_raw=1.0367, running_loss=0.9771, LR=0.000100
[2025-08-27 04:29:38,183][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035848] [Batch 01968/03080] [00:24:25/00:13:47, 0.745s/it]: train_loss_raw=0.9684, running_loss=0.9765, LR=0.000100
[2025-08-27 04:29:44,145][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035856] [Batch 01976/03080] [00:24:31/00:13:42, 0.745s/it]: train_loss_raw=0.8878, running_loss=0.9733, LR=0.000100
[2025-08-27 04:29:50,109][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035864] [Batch 01984/03080] [00:24:37/00:13:36, 0.745s/it]: train_loss_raw=1.1139, running_loss=0.9748, LR=0.000100
[2025-08-27 04:29:56,283][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035872] [Batch 01992/03080] [00:24:43/00:13:30, 0.745s/it]: train_loss_raw=0.9753, running_loss=0.9751, LR=0.000100
[2025-08-27 04:30:02,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035880] [Batch 02000/03080] [00:24:49/00:13:24, 0.745s/it]: train_loss_raw=0.9726, running_loss=0.9748, LR=0.000100
[2025-08-27 04:30:08,150][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035888] [Batch 02008/03080] [00:24:55/00:13:18, 0.745s/it]: train_loss_raw=1.0022, running_loss=0.9744, LR=0.000100
[2025-08-27 04:30:14,393][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035896] [Batch 02016/03080] [00:25:01/00:13:12, 0.745s/it]: train_loss_raw=0.9229, running_loss=0.9755, LR=0.000100
[2025-08-27 04:30:20,402][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035904] [Batch 02024/03080] [00:25:07/00:13:06, 0.745s/it]: train_loss_raw=0.9594, running_loss=0.9759, LR=0.000100
[2025-08-27 04:30:26,383][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035912] [Batch 02032/03080] [00:25:13/00:13:00, 0.745s/it]: train_loss_raw=0.8497, running_loss=0.9748, LR=0.000100
[2025-08-27 04:30:32,176][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035920] [Batch 02040/03080] [00:25:19/00:12:54, 0.745s/it]: train_loss_raw=0.9858, running_loss=0.9756, LR=0.000100
[2025-08-27 04:30:38,057][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035928] [Batch 02048/03080] [00:25:25/00:12:48, 0.745s/it]: train_loss_raw=0.9803, running_loss=0.9756, LR=0.000100
[2025-08-27 04:30:44,086][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035936] [Batch 02056/03080] [00:25:31/00:12:42, 0.745s/it]: train_loss_raw=0.9244, running_loss=0.9760, LR=0.000100
[2025-08-27 04:30:49,904][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035944] [Batch 02064/03080] [00:25:37/00:12:36, 0.745s/it]: train_loss_raw=1.0479, running_loss=0.9771, LR=0.000100
[2025-08-27 04:30:55,772][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035952] [Batch 02072/03080] [00:25:42/00:12:30, 0.745s/it]: train_loss_raw=0.8502, running_loss=0.9744, LR=0.000100
[2025-08-27 04:31:01,706][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035960] [Batch 02080/03080] [00:25:48/00:12:24, 0.745s/it]: train_loss_raw=1.0476, running_loss=0.9758, LR=0.000100
[2025-08-27 04:31:07,482][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035968] [Batch 02088/03080] [00:25:54/00:12:18, 0.745s/it]: train_loss_raw=1.0657, running_loss=0.9764, LR=0.000100
[2025-08-27 04:31:13,552][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035976] [Batch 02096/03080] [00:26:00/00:12:12, 0.745s/it]: train_loss_raw=0.9614, running_loss=0.9787, LR=0.000100
[2025-08-27 04:31:19,431][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035984] [Batch 02104/03080] [00:26:06/00:12:06, 0.745s/it]: train_loss_raw=0.8167, running_loss=0.9757, LR=0.000100
[2025-08-27 04:31:25,329][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 035992] [Batch 02112/03080] [00:26:12/00:12:00, 0.745s/it]: train_loss_raw=0.9380, running_loss=0.9773, LR=0.000100
[2025-08-27 04:31:31,113][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036000] [Batch 02120/03080] [00:26:18/00:11:54, 0.744s/it]: train_loss_raw=1.0365, running_loss=0.9786, LR=0.000100
[2025-08-27 04:31:41,177][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036008] [Batch 02128/03080] [00:26:28/00:11:50, 0.746s/it]: train_loss_raw=0.9166, running_loss=0.9775, LR=0.000100
[2025-08-27 04:31:47,052][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036016] [Batch 02136/03080] [00:26:34/00:11:44, 0.746s/it]: train_loss_raw=0.9642, running_loss=0.9765, LR=0.000100
[2025-08-27 04:31:52,886][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036024] [Batch 02144/03080] [00:26:40/00:11:38, 0.746s/it]: train_loss_raw=1.0192, running_loss=0.9749, LR=0.000100
[2025-08-27 04:31:58,815][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036032] [Batch 02152/03080] [00:26:46/00:11:32, 0.746s/it]: train_loss_raw=0.9753, running_loss=0.9734, LR=0.000100
[2025-08-27 04:32:04,387][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036040] [Batch 02160/03080] [00:26:51/00:11:26, 0.746s/it]: train_loss_raw=1.0207, running_loss=0.9767, LR=0.000100
[2025-08-27 04:32:10,271][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036048] [Batch 02168/03080] [00:26:57/00:11:20, 0.746s/it]: train_loss_raw=1.0023, running_loss=0.9768, LR=0.000100
[2025-08-27 04:32:16,169][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036056] [Batch 02176/03080] [00:27:03/00:11:14, 0.746s/it]: train_loss_raw=0.8249, running_loss=0.9751, LR=0.000100
[2025-08-27 04:32:22,049][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036064] [Batch 02184/03080] [00:27:09/00:11:08, 0.746s/it]: train_loss_raw=0.9595, running_loss=0.9753, LR=0.000100
[2025-08-27 04:32:27,936][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036072] [Batch 02192/03080] [00:27:15/00:11:02, 0.746s/it]: train_loss_raw=0.9550, running_loss=0.9779, LR=0.000100
[2025-08-27 04:32:33,790][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036080] [Batch 02200/03080] [00:27:20/00:10:56, 0.746s/it]: train_loss_raw=0.9033, running_loss=0.9776, LR=0.000100
[2025-08-27 04:32:39,710][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036088] [Batch 02208/03080] [00:27:26/00:10:50, 0.746s/it]: train_loss_raw=0.9021, running_loss=0.9736, LR=0.000100
[2025-08-27 04:32:45,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036096] [Batch 02216/03080] [00:27:32/00:10:44, 0.746s/it]: train_loss_raw=0.8926, running_loss=0.9720, LR=0.000100
[2025-08-27 04:32:51,317][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036104] [Batch 02224/03080] [00:27:38/00:10:38, 0.746s/it]: train_loss_raw=0.9716, running_loss=0.9713, LR=0.000100
[2025-08-27 04:32:57,195][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036112] [Batch 02232/03080] [00:27:44/00:10:32, 0.746s/it]: train_loss_raw=1.0815, running_loss=0.9719, LR=0.000100
[2025-08-27 04:33:02,977][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036120] [Batch 02240/03080] [00:27:50/00:10:26, 0.746s/it]: train_loss_raw=0.9968, running_loss=0.9706, LR=0.000100
[2025-08-27 04:33:08,921][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036128] [Batch 02248/03080] [00:27:56/00:10:20, 0.746s/it]: train_loss_raw=1.0174, running_loss=0.9730, LR=0.000100
[2025-08-27 04:33:14,844][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036136] [Batch 02256/03080] [00:28:02/00:10:14, 0.746s/it]: train_loss_raw=0.9763, running_loss=0.9718, LR=0.000100
[2025-08-27 04:33:20,775][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036144] [Batch 02264/03080] [00:28:07/00:10:08, 0.746s/it]: train_loss_raw=1.0066, running_loss=0.9704, LR=0.000100
[2025-08-27 04:33:26,622][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036152] [Batch 02272/03080] [00:28:13/00:10:02, 0.746s/it]: train_loss_raw=0.9771, running_loss=0.9684, LR=0.000100
[2025-08-27 04:33:32,546][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036160] [Batch 02280/03080] [00:28:19/00:09:56, 0.745s/it]: train_loss_raw=0.9686, running_loss=0.9706, LR=0.000100
[2025-08-27 04:33:38,448][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036168] [Batch 02288/03080] [00:28:25/00:09:50, 0.745s/it]: train_loss_raw=1.0332, running_loss=0.9716, LR=0.000100
[2025-08-27 04:33:44,535][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036176] [Batch 02296/03080] [00:28:31/00:09:44, 0.746s/it]: train_loss_raw=0.9294, running_loss=0.9732, LR=0.000100
[2025-08-27 04:33:50,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036184] [Batch 02304/03080] [00:28:37/00:09:38, 0.745s/it]: train_loss_raw=0.9449, running_loss=0.9717, LR=0.000100
[2025-08-27 04:33:56,244][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036192] [Batch 02312/03080] [00:28:43/00:09:32, 0.745s/it]: train_loss_raw=0.8805, running_loss=0.9701, LR=0.000100
[2025-08-27 04:34:02,110][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036200] [Batch 02320/03080] [00:28:49/00:09:26, 0.745s/it]: train_loss_raw=0.9373, running_loss=0.9705, LR=0.000100
[2025-08-27 04:34:08,017][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036208] [Batch 02328/03080] [00:28:55/00:09:20, 0.745s/it]: train_loss_raw=0.8839, running_loss=0.9716, LR=0.000100
[2025-08-27 04:34:13,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036216] [Batch 02336/03080] [00:29:01/00:09:14, 0.745s/it]: train_loss_raw=0.8956, running_loss=0.9690, LR=0.000100
[2025-08-27 04:34:19,697][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036224] [Batch 02344/03080] [00:29:06/00:09:08, 0.745s/it]: train_loss_raw=0.9089, running_loss=0.9673, LR=0.000100
[2025-08-27 04:34:25,735][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036232] [Batch 02352/03080] [00:29:12/00:09:02, 0.745s/it]: train_loss_raw=1.0746, running_loss=0.9694, LR=0.000100
[2025-08-27 04:34:31,699][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036240] [Batch 02360/03080] [00:29:18/00:08:56, 0.745s/it]: train_loss_raw=0.8446, running_loss=0.9713, LR=0.000100
[2025-08-27 04:34:37,632][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036248] [Batch 02368/03080] [00:29:24/00:08:50, 0.745s/it]: train_loss_raw=0.9302, running_loss=0.9739, LR=0.000100
[2025-08-27 04:34:43,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036256] [Batch 02376/03080] [00:29:30/00:08:44, 0.745s/it]: train_loss_raw=0.8959, running_loss=0.9708, LR=0.000100
[2025-08-27 04:34:49,455][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036264] [Batch 02384/03080] [00:29:36/00:08:38, 0.745s/it]: train_loss_raw=1.0230, running_loss=0.9711, LR=0.000100
[2025-08-27 04:34:55,289][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036272] [Batch 02392/03080] [00:29:42/00:08:32, 0.745s/it]: train_loss_raw=0.9856, running_loss=0.9714, LR=0.000100
[2025-08-27 04:35:01,213][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036280] [Batch 02400/03080] [00:29:48/00:08:26, 0.745s/it]: train_loss_raw=0.8815, running_loss=0.9702, LR=0.000100
[2025-08-27 04:35:07,205][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036288] [Batch 02408/03080] [00:29:54/00:08:20, 0.745s/it]: train_loss_raw=0.9843, running_loss=0.9719, LR=0.000100
[2025-08-27 04:35:12,988][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036296] [Batch 02416/03080] [00:30:00/00:08:14, 0.745s/it]: train_loss_raw=0.9065, running_loss=0.9727, LR=0.000100
[2025-08-27 04:35:18,804][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036304] [Batch 02424/03080] [00:30:05/00:08:08, 0.745s/it]: train_loss_raw=0.9366, running_loss=0.9715, LR=0.000100
[2025-08-27 04:35:24,660][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036312] [Batch 02432/03080] [00:30:11/00:08:02, 0.745s/it]: train_loss_raw=1.0917, running_loss=0.9736, LR=0.000100
[2025-08-27 04:35:30,544][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036320] [Batch 02440/03080] [00:30:17/00:07:56, 0.745s/it]: train_loss_raw=0.8982, running_loss=0.9720, LR=0.000100
[2025-08-27 04:35:36,449][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036328] [Batch 02448/03080] [00:30:23/00:07:50, 0.745s/it]: train_loss_raw=0.8118, running_loss=0.9731, LR=0.000100
[2025-08-27 04:35:42,357][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036336] [Batch 02456/03080] [00:30:29/00:07:44, 0.745s/it]: train_loss_raw=0.8977, running_loss=0.9711, LR=0.000100
[2025-08-27 04:35:48,468][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036344] [Batch 02464/03080] [00:30:35/00:07:38, 0.745s/it]: train_loss_raw=0.9640, running_loss=0.9697, LR=0.000100
[2025-08-27 04:35:54,500][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036352] [Batch 02472/03080] [00:30:41/00:07:32, 0.745s/it]: train_loss_raw=0.9674, running_loss=0.9671, LR=0.000100
[2025-08-27 04:36:00,407][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036360] [Batch 02480/03080] [00:30:47/00:07:26, 0.745s/it]: train_loss_raw=0.9702, running_loss=0.9667, LR=0.000100
[2025-08-27 04:36:06,279][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036368] [Batch 02488/03080] [00:30:53/00:07:21, 0.745s/it]: train_loss_raw=0.8867, running_loss=0.9665, LR=0.000100
[2025-08-27 04:36:12,192][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036376] [Batch 02496/03080] [00:30:59/00:07:15, 0.745s/it]: train_loss_raw=0.9215, running_loss=0.9675, LR=0.000100
[2025-08-27 04:36:18,092][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036384] [Batch 02504/03080] [00:31:05/00:07:09, 0.745s/it]: train_loss_raw=1.0202, running_loss=0.9716, LR=0.000100
[2025-08-27 04:36:24,037][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036392] [Batch 02512/03080] [00:31:11/00:07:03, 0.745s/it]: train_loss_raw=0.9494, running_loss=0.9698, LR=0.000100
[2025-08-27 04:36:29,727][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036400] [Batch 02520/03080] [00:31:16/00:06:57, 0.745s/it]: train_loss_raw=1.0100, running_loss=0.9714, LR=0.000100
[2025-08-27 04:36:35,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036408] [Batch 02528/03080] [00:31:22/00:06:51, 0.745s/it]: train_loss_raw=1.0075, running_loss=0.9700, LR=0.000100
[2025-08-27 04:36:41,160][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036416] [Batch 02536/03080] [00:31:28/00:06:45, 0.745s/it]: train_loss_raw=0.8469, running_loss=0.9666, LR=0.000100
[2025-08-27 04:36:47,131][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036424] [Batch 02544/03080] [00:31:34/00:06:39, 0.745s/it]: train_loss_raw=0.9429, running_loss=0.9635, LR=0.000100
[2025-08-27 04:36:53,160][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036432] [Batch 02552/03080] [00:31:40/00:06:33, 0.745s/it]: train_loss_raw=0.9935, running_loss=0.9632, LR=0.000100
[2025-08-27 04:36:58,971][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036440] [Batch 02560/03080] [00:31:46/00:06:27, 0.745s/it]: train_loss_raw=0.9253, running_loss=0.9644, LR=0.000100
[2025-08-27 04:37:04,780][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036448] [Batch 02568/03080] [00:31:51/00:06:21, 0.745s/it]: train_loss_raw=1.0476, running_loss=0.9680, LR=0.000100
[2025-08-27 04:37:10,596][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036456] [Batch 02576/03080] [00:31:57/00:06:15, 0.744s/it]: train_loss_raw=1.0256, running_loss=0.9690, LR=0.000100
[2025-08-27 04:37:16,500][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036464] [Batch 02584/03080] [00:32:03/00:06:09, 0.744s/it]: train_loss_raw=0.8882, running_loss=0.9682, LR=0.000100
[2025-08-27 04:37:22,007][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036472] [Batch 02592/03080] [00:32:09/00:06:03, 0.744s/it]: train_loss_raw=1.0213, running_loss=0.9697, LR=0.000100
[2025-08-27 04:37:27,827][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036480] [Batch 02600/03080] [00:32:15/00:05:57, 0.744s/it]: train_loss_raw=0.8980, running_loss=0.9682, LR=0.000100
[2025-08-27 04:37:33,691][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036488] [Batch 02608/03080] [00:32:20/00:05:51, 0.744s/it]: train_loss_raw=0.9750, running_loss=0.9681, LR=0.000100
[2025-08-27 04:37:39,496][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036496] [Batch 02616/03080] [00:32:26/00:05:45, 0.744s/it]: train_loss_raw=1.0970, running_loss=0.9687, LR=0.000100
[2025-08-27 04:37:45,375][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036504] [Batch 02624/03080] [00:32:32/00:05:39, 0.744s/it]: train_loss_raw=1.0474, running_loss=0.9713, LR=0.000100
[2025-08-27 04:37:51,241][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036512] [Batch 02632/03080] [00:32:38/00:05:33, 0.744s/it]: train_loss_raw=1.0727, running_loss=0.9689, LR=0.000100
[2025-08-27 04:37:57,105][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036520] [Batch 02640/03080] [00:32:44/00:05:27, 0.744s/it]: train_loss_raw=0.9382, running_loss=0.9681, LR=0.000100
[2025-08-27 04:38:02,928][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036528] [Batch 02648/03080] [00:32:50/00:05:21, 0.744s/it]: train_loss_raw=1.0854, running_loss=0.9683, LR=0.000100
[2025-08-27 04:38:08,875][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036536] [Batch 02656/03080] [00:32:56/00:05:15, 0.744s/it]: train_loss_raw=0.9394, running_loss=0.9693, LR=0.000100
[2025-08-27 04:38:14,708][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036544] [Batch 02664/03080] [00:33:01/00:05:09, 0.744s/it]: train_loss_raw=0.9526, running_loss=0.9682, LR=0.000100
[2025-08-27 04:38:20,594][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036552] [Batch 02672/03080] [00:33:07/00:05:03, 0.744s/it]: train_loss_raw=0.9674, running_loss=0.9674, LR=0.000100
[2025-08-27 04:38:26,530][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036560] [Batch 02680/03080] [00:33:13/00:04:57, 0.744s/it]: train_loss_raw=0.9628, running_loss=0.9678, LR=0.000100
[2025-08-27 04:38:32,498][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036568] [Batch 02688/03080] [00:33:19/00:04:51, 0.744s/it]: train_loss_raw=0.9235, running_loss=0.9685, LR=0.000100
[2025-08-27 04:38:38,402][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036576] [Batch 02696/03080] [00:33:25/00:04:45, 0.744s/it]: train_loss_raw=0.9760, running_loss=0.9658, LR=0.000100
[2025-08-27 04:38:44,250][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036584] [Batch 02704/03080] [00:33:31/00:04:39, 0.744s/it]: train_loss_raw=1.0087, running_loss=0.9669, LR=0.000100
[2025-08-27 04:38:50,044][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036592] [Batch 02712/03080] [00:33:37/00:04:33, 0.744s/it]: train_loss_raw=0.9952, running_loss=0.9663, LR=0.000100
[2025-08-27 04:38:55,807][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036600] [Batch 02720/03080] [00:33:42/00:04:27, 0.744s/it]: train_loss_raw=1.0559, running_loss=0.9663, LR=0.000100
[2025-08-27 04:39:01,731][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036608] [Batch 02728/03080] [00:33:48/00:04:21, 0.744s/it]: train_loss_raw=0.9264, running_loss=0.9653, LR=0.000100
[2025-08-27 04:39:07,635][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036616] [Batch 02736/03080] [00:33:54/00:04:15, 0.744s/it]: train_loss_raw=1.0509, running_loss=0.9667, LR=0.000100
[2025-08-27 04:39:13,452][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036624] [Batch 02744/03080] [00:34:00/00:04:09, 0.744s/it]: train_loss_raw=0.9127, running_loss=0.9682, LR=0.000100
[2025-08-27 04:39:19,277][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036632] [Batch 02752/03080] [00:34:06/00:04:03, 0.744s/it]: train_loss_raw=0.9120, running_loss=0.9665, LR=0.000100
[2025-08-27 04:39:25,131][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036640] [Batch 02760/03080] [00:34:12/00:03:57, 0.744s/it]: train_loss_raw=0.8239, running_loss=0.9661, LR=0.000100
[2025-08-27 04:39:31,188][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036648] [Batch 02768/03080] [00:34:18/00:03:52, 0.744s/it]: train_loss_raw=0.9776, running_loss=0.9650, LR=0.000100
[2025-08-27 04:39:37,085][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036656] [Batch 02776/03080] [00:34:24/00:03:46, 0.744s/it]: train_loss_raw=0.9262, running_loss=0.9636, LR=0.000100
[2025-08-27 04:39:42,983][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036664] [Batch 02784/03080] [00:34:30/00:03:40, 0.744s/it]: train_loss_raw=0.9913, running_loss=0.9640, LR=0.000100
[2025-08-27 04:39:48,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036672] [Batch 02792/03080] [00:34:36/00:03:34, 0.744s/it]: train_loss_raw=0.8850, running_loss=0.9619, LR=0.000100
[2025-08-27 04:39:54,762][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036680] [Batch 02800/03080] [00:34:41/00:03:28, 0.744s/it]: train_loss_raw=0.8996, running_loss=0.9602, LR=0.000100
[2025-08-27 04:40:00,840][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036688] [Batch 02808/03080] [00:34:48/00:03:22, 0.744s/it]: train_loss_raw=0.8335, running_loss=0.9578, LR=0.000100
[2025-08-27 04:40:06,795][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036696] [Batch 02816/03080] [00:34:53/00:03:16, 0.744s/it]: train_loss_raw=0.9611, running_loss=0.9577, LR=0.000100
[2025-08-27 04:40:12,652][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036704] [Batch 02824/03080] [00:34:59/00:03:10, 0.744s/it]: train_loss_raw=0.9058, running_loss=0.9571, LR=0.000100
[2025-08-27 04:40:18,601][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036712] [Batch 02832/03080] [00:35:05/00:03:04, 0.744s/it]: train_loss_raw=0.9847, running_loss=0.9592, LR=0.000100
[2025-08-27 04:40:24,396][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036720] [Batch 02840/03080] [00:35:11/00:02:58, 0.744s/it]: train_loss_raw=1.0545, running_loss=0.9601, LR=0.000100
[2025-08-27 04:40:30,264][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036728] [Batch 02848/03080] [00:35:17/00:02:52, 0.743s/it]: train_loss_raw=0.9872, running_loss=0.9589, LR=0.000100
[2025-08-27 04:40:36,285][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036736] [Batch 02856/03080] [00:35:23/00:02:46, 0.744s/it]: train_loss_raw=0.8430, running_loss=0.9581, LR=0.000100
[2025-08-27 04:40:42,171][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036744] [Batch 02864/03080] [00:35:29/00:02:40, 0.743s/it]: train_loss_raw=0.9879, running_loss=0.9580, LR=0.000100
[2025-08-27 04:40:48,071][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036752] [Batch 02872/03080] [00:35:35/00:02:34, 0.743s/it]: train_loss_raw=1.0230, running_loss=0.9588, LR=0.000100
[2025-08-27 04:40:54,022][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036760] [Batch 02880/03080] [00:35:41/00:02:28, 0.743s/it]: train_loss_raw=0.8565, running_loss=0.9578, LR=0.000100
[2025-08-27 04:40:59,860][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036768] [Batch 02888/03080] [00:35:47/00:02:22, 0.743s/it]: train_loss_raw=0.9232, running_loss=0.9580, LR=0.000100
[2025-08-27 04:41:05,787][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036776] [Batch 02896/03080] [00:35:52/00:02:16, 0.743s/it]: train_loss_raw=0.8481, running_loss=0.9536, LR=0.000100
[2025-08-27 04:41:11,800][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036784] [Batch 02904/03080] [00:35:58/00:02:10, 0.743s/it]: train_loss_raw=0.9901, running_loss=0.9561, LR=0.000100
[2025-08-27 04:41:17,704][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036792] [Batch 02912/03080] [00:36:04/00:02:04, 0.743s/it]: train_loss_raw=0.9953, running_loss=0.9556, LR=0.000100
[2025-08-27 04:41:23,586][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036800] [Batch 02920/03080] [00:36:10/00:01:58, 0.743s/it]: train_loss_raw=0.8444, running_loss=0.9528, LR=0.000100
[2025-08-27 04:41:29,864][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036808] [Batch 02928/03080] [00:36:17/00:01:53, 0.744s/it]: train_loss_raw=1.0521, running_loss=0.9527, LR=0.000100
[2025-08-27 04:41:35,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036816] [Batch 02936/03080] [00:36:23/00:01:47, 0.744s/it]: train_loss_raw=0.9533, running_loss=0.9529, LR=0.000100
[2025-08-27 04:41:41,717][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036824] [Batch 02944/03080] [00:36:28/00:01:41, 0.744s/it]: train_loss_raw=0.8761, running_loss=0.9524, LR=0.000100
[2025-08-27 04:41:47,542][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036832] [Batch 02952/03080] [00:36:34/00:01:35, 0.743s/it]: train_loss_raw=0.9016, running_loss=0.9498, LR=0.000100
[2025-08-27 04:41:53,342][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036840] [Batch 02960/03080] [00:36:40/00:01:29, 0.743s/it]: train_loss_raw=0.9754, running_loss=0.9492, LR=0.000100
[2025-08-27 04:41:59,118][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036848] [Batch 02968/03080] [00:36:46/00:01:23, 0.743s/it]: train_loss_raw=0.9531, running_loss=0.9514, LR=0.000100
[2025-08-27 04:42:04,838][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036856] [Batch 02976/03080] [00:36:52/00:01:17, 0.743s/it]: train_loss_raw=0.8747, running_loss=0.9510, LR=0.000100
[2025-08-27 04:42:10,622][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036864] [Batch 02984/03080] [00:36:57/00:01:11, 0.743s/it]: train_loss_raw=0.9111, running_loss=0.9527, LR=0.000100
[2025-08-27 04:42:16,525][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036872] [Batch 02992/03080] [00:37:03/00:01:05, 0.743s/it]: train_loss_raw=0.8964, running_loss=0.9490, LR=0.000100
[2025-08-27 04:42:22,529][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036880] [Batch 03000/03080] [00:37:09/00:00:59, 0.743s/it]: train_loss_raw=0.9115, running_loss=0.9470, LR=0.000100
[2025-08-27 04:42:28,417][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036888] [Batch 03008/03080] [00:37:15/00:00:53, 0.743s/it]: train_loss_raw=0.9746, running_loss=0.9452, LR=0.000100
[2025-08-27 04:42:34,340][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036896] [Batch 03016/03080] [00:37:21/00:00:47, 0.743s/it]: train_loss_raw=0.9072, running_loss=0.9481, LR=0.000100
[2025-08-27 04:42:40,262][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036904] [Batch 03024/03080] [00:37:27/00:00:41, 0.743s/it]: train_loss_raw=0.9567, running_loss=0.9478, LR=0.000100
[2025-08-27 04:42:46,255][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036912] [Batch 03032/03080] [00:37:33/00:00:35, 0.743s/it]: train_loss_raw=0.9610, running_loss=0.9462, LR=0.000100
[2025-08-27 04:42:52,303][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036920] [Batch 03040/03080] [00:37:39/00:00:29, 0.743s/it]: train_loss_raw=0.8643, running_loss=0.9425, LR=0.000100
[2025-08-27 04:42:58,238][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036928] [Batch 03048/03080] [00:37:45/00:00:23, 0.743s/it]: train_loss_raw=0.9298, running_loss=0.9417, LR=0.000100
[2025-08-27 04:43:04,147][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036936] [Batch 03056/03080] [00:37:51/00:00:17, 0.743s/it]: train_loss_raw=1.0299, running_loss=0.9425, LR=0.000100
[2025-08-27 04:43:09,962][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036944] [Batch 03064/03080] [00:37:57/00:00:11, 0.743s/it]: train_loss_raw=0.9843, running_loss=0.9413, LR=0.000100
[2025-08-27 04:43:15,819][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036952] [Batch 03072/03080] [00:38:03/00:00:05, 0.743s/it]: train_loss_raw=0.9149, running_loss=0.9395, LR=0.000100
[2025-08-27 04:43:26,800][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 036960] [Batch 03080/03080] [00:38:13/00:00:00, 0.745s/it]: train_loss_raw=1.0082, running_loss=0.9376, LR=0.000100
[2025-08-27 04:43:27,299][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-27 04:43:39,236][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00007/00310] [00:00:11/00:07:30, 1.492s/it]
[2025-08-27 04:43:51,514][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00015/00310] [00:00:24/00:07:24, 1.513s/it]
[2025-08-27 04:44:04,198][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00023/00310] [00:00:36/00:07:19, 1.537s/it]
[2025-08-27 04:44:16,762][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00031/00310] [00:00:49/00:07:09, 1.546s/it]
[2025-08-27 04:44:30,071][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00039/00310] [00:01:02/00:07:03, 1.569s/it]
[2025-08-27 04:44:42,249][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00047/00310] [00:01:14/00:06:49, 1.561s/it]
[2025-08-27 04:44:54,771][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00055/00310] [00:01:27/00:06:36, 1.562s/it]
[2025-08-27 04:45:07,716][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00063/00310] [00:01:40/00:06:25, 1.569s/it]
[2025-08-27 04:45:20,896][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00071/00310] [00:01:53/00:06:15, 1.578s/it]
[2025-08-27 04:45:33,455][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00079/00310] [00:02:06/00:06:02, 1.577s/it]
[2025-08-27 04:45:46,059][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00087/00310] [00:02:18/00:05:50, 1.577s/it]
[2025-08-27 04:45:58,556][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00095/00310] [00:02:31/00:05:37, 1.576s/it]
[2025-08-27 04:46:11,143][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00103/00310] [00:02:43/00:05:24, 1.575s/it]
[2025-08-27 04:46:23,738][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00111/00310] [00:02:56/00:05:11, 1.575s/it]
[2025-08-27 04:46:36,142][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00119/00310] [00:03:08/00:04:59, 1.574s/it]
[2025-08-27 04:46:48,643][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00127/00310] [00:03:21/00:04:46, 1.573s/it]
[2025-08-27 04:47:01,710][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00135/00310] [00:03:34/00:04:34, 1.577s/it]
[2025-08-27 04:47:14,588][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00143/00310] [00:03:47/00:04:22, 1.578s/it]
[2025-08-27 04:47:25,786][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00151/00310] [00:03:58/00:04:07, 1.569s/it]
[2025-08-27 04:47:37,394][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00159/00310] [00:04:10/00:03:54, 1.563s/it]
[2025-08-27 04:47:49,745][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00167/00310] [00:04:22/00:03:41, 1.562s/it]
[2025-08-27 04:48:00,909][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00175/00310] [00:04:33/00:03:28, 1.555s/it]
[2025-08-27 04:48:12,862][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00183/00310] [00:04:45/00:03:15, 1.552s/it]
[2025-08-27 04:48:25,170][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00191/00310] [00:04:57/00:03:03, 1.551s/it]
[2025-08-27 04:48:37,403][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00199/00310] [00:05:10/00:02:50, 1.551s/it]
[2025-08-27 04:48:49,464][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00207/00310] [00:05:22/00:02:37, 1.549s/it]
[2025-08-27 04:49:01,975][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00215/00310] [00:05:34/00:02:25, 1.549s/it]
[2025-08-27 04:49:14,015][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00223/00310] [00:05:46/00:02:13, 1.548s/it]
[2025-08-27 04:49:26,236][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00231/00310] [00:05:58/00:02:00, 1.547s/it]
[2025-08-27 04:49:38,474][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00239/00310] [00:06:11/00:01:48, 1.547s/it]
[2025-08-27 04:49:50,424][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00247/00310] [00:06:23/00:01:35, 1.545s/it]
[2025-08-27 04:50:02,908][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00255/00310] [00:06:35/00:01:23, 1.545s/it]
[2025-08-27 04:50:15,169][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00263/00310] [00:06:47/00:01:11, 1.545s/it]
[2025-08-27 04:50:27,185][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00271/00310] [00:06:59/00:00:58, 1.544s/it]
[2025-08-27 04:50:39,822][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00279/00310] [00:07:12/00:00:46, 1.545s/it]
[2025-08-27 04:50:52,679][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00287/00310] [00:07:25/00:00:34, 1.546s/it]
[2025-08-27 04:51:04,362][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00295/00310] [00:07:37/00:00:21, 1.544s/it]
[2025-08-27 04:51:17,172][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 036961] [Batch 00303/00310] [00:07:49/00:00:09, 1.546s/it]
[2025-08-27 04:51:26,860][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=0.93758, valid_loss=1.82291
[2025-08-27 04:51:26,861][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-27 04:51:26,861][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.690
[2025-08-27 04:51:26,861][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.052
[2025-08-27 04:51:26,861][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.054
[2025-08-27 04:51:26,861][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.018
[2025-08-27 04:51:26,874][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 09:24:40, remaining time 14:07:01, 00:47:03 per epoch
[2025-08-27 04:51:32,792][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036968] [Batch 00008/03080] [00:00:05/00:35:28, 0.693s/it]: train_loss_raw=0.9382, running_loss=0.9865, LR=0.000100
[2025-08-27 04:51:38,662][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036976] [Batch 00016/03080] [00:00:11/00:36:25, 0.713s/it]: train_loss_raw=0.9146, running_loss=0.9817, LR=0.000100
[2025-08-27 04:51:44,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036984] [Batch 00024/03080] [00:00:17/00:36:46, 0.722s/it]: train_loss_raw=0.9444, running_loss=0.9772, LR=0.000100
[2025-08-27 04:51:50,584][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 036992] [Batch 00032/03080] [00:00:23/00:37:02, 0.729s/it]: train_loss_raw=0.8453, running_loss=0.9737, LR=0.000100
[2025-08-27 04:51:56,616][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037000] [Batch 00040/03080] [00:00:29/00:37:11, 0.734s/it]: train_loss_raw=0.9115, running_loss=0.9663, LR=0.000100
[2025-08-27 04:52:02,587][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037008] [Batch 00048/03080] [00:00:35/00:37:12, 0.736s/it]: train_loss_raw=0.8436, running_loss=0.9624, LR=0.000100
[2025-08-27 04:52:08,648][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037016] [Batch 00056/03080] [00:00:41/00:37:15, 0.739s/it]: train_loss_raw=0.9620, running_loss=0.9587, LR=0.000100
[2025-08-27 04:52:14,647][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037024] [Batch 00064/03080] [00:00:47/00:37:13, 0.741s/it]: train_loss_raw=0.8829, running_loss=0.9535, LR=0.000100
[2025-08-27 04:52:20,523][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037032] [Batch 00072/03080] [00:00:53/00:37:05, 0.740s/it]: train_loss_raw=0.9246, running_loss=0.9528, LR=0.000100
[2025-08-27 04:52:26,622][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037040] [Batch 00080/03080] [00:00:59/00:37:06, 0.742s/it]: train_loss_raw=0.9606, running_loss=0.9525, LR=0.000100
[2025-08-27 04:52:32,607][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037048] [Batch 00088/03080] [00:01:05/00:37:02, 0.743s/it]: train_loss_raw=0.9298, running_loss=0.9473, LR=0.000100
[2025-08-27 04:52:38,448][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037056] [Batch 00096/03080] [00:01:11/00:36:53, 0.742s/it]: train_loss_raw=0.9199, running_loss=0.9449, LR=0.000100
[2025-08-27 04:52:44,388][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037064] [Batch 00104/03080] [00:01:17/00:36:47, 0.742s/it]: train_loss_raw=1.0628, running_loss=0.9443, LR=0.000100
[2025-08-27 04:52:50,316][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037072] [Batch 00112/03080] [00:01:23/00:36:41, 0.742s/it]: train_loss_raw=0.8618, running_loss=0.9410, LR=0.000100
[2025-08-27 04:52:56,274][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037080] [Batch 00120/03080] [00:01:29/00:36:35, 0.742s/it]: train_loss_raw=0.8945, running_loss=0.9407, LR=0.000100
[2025-08-27 04:53:02,126][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037088] [Batch 00128/03080] [00:01:34/00:36:28, 0.741s/it]: train_loss_raw=0.8333, running_loss=0.9380, LR=0.000100
[2025-08-27 04:53:08,084][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037096] [Batch 00136/03080] [00:01:40/00:36:22, 0.741s/it]: train_loss_raw=0.9127, running_loss=0.9358, LR=0.000100
[2025-08-27 04:53:13,985][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037104] [Batch 00144/03080] [00:01:46/00:36:16, 0.741s/it]: train_loss_raw=0.9860, running_loss=0.9324, LR=0.000100
[2025-08-27 04:53:19,887][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037112] [Batch 00152/03080] [00:01:52/00:36:09, 0.741s/it]: train_loss_raw=0.9909, running_loss=0.9314, LR=0.000100
[2025-08-27 04:53:25,660][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037120] [Batch 00160/03080] [00:01:58/00:36:00, 0.740s/it]: train_loss_raw=1.0001, running_loss=0.9308, LR=0.000100
[2025-08-27 04:53:31,573][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037128] [Batch 00168/03080] [00:02:04/00:35:54, 0.740s/it]: train_loss_raw=0.9663, running_loss=0.9322, LR=0.000100
[2025-08-27 04:53:37,437][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037136] [Batch 00176/03080] [00:02:10/00:35:48, 0.740s/it]: train_loss_raw=0.8670, running_loss=0.9286, LR=0.000100
[2025-08-27 04:53:43,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037144] [Batch 00184/03080] [00:02:16/00:35:42, 0.740s/it]: train_loss_raw=0.8873, running_loss=0.9272, LR=0.000100
[2025-08-27 04:53:49,167][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037152] [Batch 00192/03080] [00:02:21/00:35:34, 0.739s/it]: train_loss_raw=0.9157, running_loss=0.9262, LR=0.000100
[2025-08-27 04:53:54,977][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037160] [Batch 00200/03080] [00:02:27/00:35:27, 0.739s/it]: train_loss_raw=0.9013, running_loss=0.9247, LR=0.000100
[2025-08-27 04:54:00,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037168] [Batch 00208/03080] [00:02:33/00:35:21, 0.739s/it]: train_loss_raw=0.9473, running_loss=0.9242, LR=0.000100
[2025-08-27 04:54:06,903][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037176] [Batch 00216/03080] [00:02:39/00:35:16, 0.739s/it]: train_loss_raw=1.0234, running_loss=0.9223, LR=0.000100
[2025-08-27 04:54:12,788][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037184] [Batch 00224/03080] [00:02:45/00:35:10, 0.739s/it]: train_loss_raw=0.9561, running_loss=0.9206, LR=0.000100
[2025-08-27 04:54:18,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037192] [Batch 00232/03080] [00:02:51/00:35:05, 0.739s/it]: train_loss_raw=0.8329, running_loss=0.9195, LR=0.000100
[2025-08-27 04:54:24,744][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037200] [Batch 00240/03080] [00:02:57/00:35:00, 0.740s/it]: train_loss_raw=0.8584, running_loss=0.9227, LR=0.000100
[2025-08-27 04:54:30,627][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037208] [Batch 00248/03080] [00:03:03/00:34:54, 0.739s/it]: train_loss_raw=0.8667, running_loss=0.9217, LR=0.000100
[2025-08-27 04:54:36,608][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037216] [Batch 00256/03080] [00:03:09/00:34:48, 0.740s/it]: train_loss_raw=0.8571, running_loss=0.9215, LR=0.000100
[2025-08-27 04:54:42,450][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037224] [Batch 00264/03080] [00:03:15/00:34:42, 0.739s/it]: train_loss_raw=0.8622, running_loss=0.9240, LR=0.000100
[2025-08-27 04:54:48,210][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037232] [Batch 00272/03080] [00:03:20/00:34:34, 0.739s/it]: train_loss_raw=1.0731, running_loss=0.9257, LR=0.000100
[2025-08-27 04:54:54,122][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037240] [Batch 00280/03080] [00:03:26/00:34:28, 0.739s/it]: train_loss_raw=0.9473, running_loss=0.9251, LR=0.000100
[2025-08-27 04:55:00,166][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037248] [Batch 00288/03080] [00:03:32/00:34:24, 0.739s/it]: train_loss_raw=0.9420, running_loss=0.9227, LR=0.000100
[2025-08-27 04:55:06,116][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037256] [Batch 00296/03080] [00:03:38/00:34:18, 0.739s/it]: train_loss_raw=1.0320, running_loss=0.9226, LR=0.000100
[2025-08-27 04:55:12,059][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037264] [Batch 00304/03080] [00:03:44/00:34:12, 0.740s/it]: train_loss_raw=0.8375, running_loss=0.9212, LR=0.000100
[2025-08-27 04:55:17,950][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037272] [Batch 00312/03080] [00:03:50/00:34:06, 0.739s/it]: train_loss_raw=0.9151, running_loss=0.9178, LR=0.000100
[2025-08-27 04:55:23,893][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037280] [Batch 00320/03080] [00:03:56/00:34:01, 0.740s/it]: train_loss_raw=0.9558, running_loss=0.9161, LR=0.000100
[2025-08-27 04:55:29,790][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037288] [Batch 00328/03080] [00:04:02/00:33:54, 0.739s/it]: train_loss_raw=0.9551, running_loss=0.9202, LR=0.000100
[2025-08-27 04:55:35,679][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037296] [Batch 00336/03080] [00:04:08/00:33:48, 0.739s/it]: train_loss_raw=0.8500, running_loss=0.9202, LR=0.000100
[2025-08-27 04:55:41,576][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037304] [Batch 00344/03080] [00:04:14/00:33:42, 0.739s/it]: train_loss_raw=0.8604, running_loss=0.9219, LR=0.000100
[2025-08-27 04:55:47,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037312] [Batch 00352/03080] [00:04:20/00:33:36, 0.739s/it]: train_loss_raw=0.9010, running_loss=0.9204, LR=0.000100
[2025-08-27 04:55:53,328][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037320] [Batch 00360/03080] [00:04:26/00:33:30, 0.739s/it]: train_loss_raw=0.8442, running_loss=0.9187, LR=0.000100
[2025-08-27 04:55:59,147][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037328] [Batch 00368/03080] [00:04:31/00:33:23, 0.739s/it]: train_loss_raw=1.0110, running_loss=0.9177, LR=0.000100
[2025-08-27 04:56:05,050][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037336] [Batch 00376/03080] [00:04:37/00:33:17, 0.739s/it]: train_loss_raw=1.0518, running_loss=0.9177, LR=0.000100
[2025-08-27 04:56:10,917][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037344] [Batch 00384/03080] [00:04:43/00:33:11, 0.739s/it]: train_loss_raw=0.9936, running_loss=0.9188, LR=0.000100
[2025-08-27 04:56:16,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037352] [Batch 00392/03080] [00:04:49/00:33:06, 0.739s/it]: train_loss_raw=1.0054, running_loss=0.9195, LR=0.000100
[2025-08-27 04:56:22,894][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037360] [Batch 00400/03080] [00:04:55/00:33:00, 0.739s/it]: train_loss_raw=0.9433, running_loss=0.9192, LR=0.000100
[2025-08-27 04:56:29,012][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037368] [Batch 00408/03080] [00:05:01/00:32:56, 0.740s/it]: train_loss_raw=0.8423, running_loss=0.9187, LR=0.000100
[2025-08-27 04:56:35,133][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037376] [Batch 00416/03080] [00:05:07/00:32:51, 0.740s/it]: train_loss_raw=0.9875, running_loss=0.9218, LR=0.000100
[2025-08-27 04:56:41,121][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037384] [Batch 00424/03080] [00:05:13/00:32:46, 0.740s/it]: train_loss_raw=1.0036, running_loss=0.9222, LR=0.000100
[2025-08-27 04:56:47,051][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037392] [Batch 00432/03080] [00:05:19/00:32:40, 0.740s/it]: train_loss_raw=0.9655, running_loss=0.9242, LR=0.000100
[2025-08-27 04:56:53,020][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037400] [Batch 00440/03080] [00:05:25/00:32:34, 0.740s/it]: train_loss_raw=0.9644, running_loss=0.9254, LR=0.000100
[2025-08-27 04:56:58,878][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037408] [Batch 00448/03080] [00:05:31/00:32:28, 0.740s/it]: train_loss_raw=0.9048, running_loss=0.9236, LR=0.000100
[2025-08-27 04:57:04,817][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037416] [Batch 00456/03080] [00:05:37/00:32:22, 0.740s/it]: train_loss_raw=0.9371, running_loss=0.9232, LR=0.000100
[2025-08-27 04:57:10,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037424] [Batch 00464/03080] [00:05:43/00:32:16, 0.740s/it]: train_loss_raw=1.0107, running_loss=0.9252, LR=0.000100
[2025-08-27 04:57:16,747][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037432] [Batch 00472/03080] [00:05:49/00:32:11, 0.740s/it]: train_loss_raw=0.9299, running_loss=0.9243, LR=0.000100
[2025-08-27 04:57:22,638][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037440] [Batch 00480/03080] [00:05:55/00:32:05, 0.740s/it]: train_loss_raw=0.8379, running_loss=0.9239, LR=0.000100
[2025-08-27 04:57:28,567][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037448] [Batch 00488/03080] [00:06:01/00:31:59, 0.740s/it]: train_loss_raw=0.8634, running_loss=0.9218, LR=0.000100
[2025-08-27 04:57:34,625][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037456] [Batch 00496/03080] [00:06:07/00:31:53, 0.741s/it]: train_loss_raw=0.7869, running_loss=0.9221, LR=0.000100
[2025-08-27 04:57:40,641][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037464] [Batch 00504/03080] [00:06:13/00:31:48, 0.741s/it]: train_loss_raw=0.8964, running_loss=0.9227, LR=0.000100
[2025-08-27 04:57:46,627][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037472] [Batch 00512/03080] [00:06:19/00:31:42, 0.741s/it]: train_loss_raw=0.9631, running_loss=0.9238, LR=0.000100
[2025-08-27 04:57:52,584][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037480] [Batch 00520/03080] [00:06:25/00:31:37, 0.741s/it]: train_loss_raw=1.0158, running_loss=0.9245, LR=0.000100
[2025-08-27 04:57:58,514][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037488] [Batch 00528/03080] [00:06:31/00:31:31, 0.741s/it]: train_loss_raw=0.9631, running_loss=0.9252, LR=0.000100
[2025-08-27 04:58:04,424][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037496] [Batch 00536/03080] [00:06:37/00:31:25, 0.741s/it]: train_loss_raw=1.1045, running_loss=0.9257, LR=0.000100
[2025-08-27 04:58:10,633][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037504] [Batch 00544/03080] [00:06:43/00:31:20, 0.742s/it]: train_loss_raw=0.9852, running_loss=0.9253, LR=0.000100
[2025-08-27 04:58:16,858][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037512] [Batch 00552/03080] [00:06:49/00:31:15, 0.742s/it]: train_loss_raw=0.9063, running_loss=0.9247, LR=0.000100
[2025-08-27 04:58:22,644][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037520] [Batch 00560/03080] [00:06:55/00:31:09, 0.742s/it]: train_loss_raw=0.9142, running_loss=0.9267, LR=0.000100
[2025-08-27 04:58:28,539][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037528] [Batch 00568/03080] [00:07:01/00:31:03, 0.742s/it]: train_loss_raw=0.7880, running_loss=0.9220, LR=0.000100
[2025-08-27 04:58:34,528][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037536] [Batch 00576/03080] [00:07:07/00:30:57, 0.742s/it]: train_loss_raw=1.0209, running_loss=0.9221, LR=0.000100
[2025-08-27 04:58:40,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037544] [Batch 00584/03080] [00:07:13/00:30:51, 0.742s/it]: train_loss_raw=0.9593, running_loss=0.9237, LR=0.000100
[2025-08-27 04:58:46,195][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037552] [Batch 00592/03080] [00:07:18/00:30:44, 0.741s/it]: train_loss_raw=0.8965, running_loss=0.9269, LR=0.000100
[2025-08-27 04:58:52,177][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037560] [Batch 00600/03080] [00:07:24/00:30:39, 0.742s/it]: train_loss_raw=0.8703, running_loss=0.9233, LR=0.000100
[2025-08-27 04:58:58,451][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037568] [Batch 00608/03080] [00:07:31/00:30:34, 0.742s/it]: train_loss_raw=0.9228, running_loss=0.9245, LR=0.000100
[2025-08-27 04:59:04,432][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037576] [Batch 00616/03080] [00:07:37/00:30:28, 0.742s/it]: train_loss_raw=0.9826, running_loss=0.9251, LR=0.000100
[2025-08-27 04:59:10,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037584] [Batch 00624/03080] [00:07:43/00:30:22, 0.742s/it]: train_loss_raw=0.9124, running_loss=0.9242, LR=0.000100
[2025-08-27 04:59:16,349][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037592] [Batch 00632/03080] [00:07:49/00:30:17, 0.742s/it]: train_loss_raw=0.8549, running_loss=0.9214, LR=0.000100
[2025-08-27 04:59:22,295][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037600] [Batch 00640/03080] [00:07:55/00:30:11, 0.742s/it]: train_loss_raw=0.8483, running_loss=0.9201, LR=0.000100
[2025-08-27 04:59:28,285][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037608] [Batch 00648/03080] [00:08:01/00:30:05, 0.742s/it]: train_loss_raw=0.7904, running_loss=0.9167, LR=0.000100
[2025-08-27 04:59:34,167][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037616] [Batch 00656/03080] [00:08:06/00:29:59, 0.742s/it]: train_loss_raw=0.9726, running_loss=0.9185, LR=0.000100
[2025-08-27 04:59:40,149][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037624] [Batch 00664/03080] [00:08:12/00:29:53, 0.742s/it]: train_loss_raw=0.8673, running_loss=0.9209, LR=0.000100
[2025-08-27 04:59:46,093][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037632] [Batch 00672/03080] [00:08:18/00:29:47, 0.742s/it]: train_loss_raw=0.8543, running_loss=0.9192, LR=0.000100
[2025-08-27 04:59:51,955][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037640] [Batch 00680/03080] [00:08:24/00:29:41, 0.742s/it]: train_loss_raw=0.8972, running_loss=0.9200, LR=0.000100
[2025-08-27 04:59:57,881][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037648] [Batch 00688/03080] [00:08:30/00:29:35, 0.742s/it]: train_loss_raw=0.9055, running_loss=0.9186, LR=0.000100
[2025-08-27 05:00:04,067][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037656] [Batch 00696/03080] [00:08:36/00:29:30, 0.743s/it]: train_loss_raw=1.0265, running_loss=0.9163, LR=0.000100
[2025-08-27 05:00:09,991][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037664] [Batch 00704/03080] [00:08:42/00:29:24, 0.743s/it]: train_loss_raw=0.9081, running_loss=0.9154, LR=0.000100
[2025-08-27 05:00:15,901][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037672] [Batch 00712/03080] [00:08:48/00:29:18, 0.742s/it]: train_loss_raw=0.9946, running_loss=0.9154, LR=0.000100
[2025-08-27 05:00:21,917][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037680] [Batch 00720/03080] [00:08:54/00:29:12, 0.743s/it]: train_loss_raw=0.8878, running_loss=0.9134, LR=0.000100
[2025-08-27 05:00:27,939][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037688] [Batch 00728/03080] [00:09:00/00:29:06, 0.743s/it]: train_loss_raw=0.9136, running_loss=0.9153, LR=0.000100
[2025-08-27 05:00:33,861][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037696] [Batch 00736/03080] [00:09:06/00:29:00, 0.743s/it]: train_loss_raw=0.8754, running_loss=0.9148, LR=0.000100
[2025-08-27 05:00:39,756][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037704] [Batch 00744/03080] [00:09:12/00:28:54, 0.743s/it]: train_loss_raw=0.9072, running_loss=0.9151, LR=0.000100
[2025-08-27 05:00:45,645][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037712] [Batch 00752/03080] [00:09:18/00:28:48, 0.743s/it]: train_loss_raw=0.8484, running_loss=0.9161, LR=0.000100
[2025-08-27 05:00:51,556][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037720] [Batch 00760/03080] [00:09:24/00:28:42, 0.743s/it]: train_loss_raw=0.9644, running_loss=0.9129, LR=0.000100
[2025-08-27 05:00:57,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037728] [Batch 00768/03080] [00:09:30/00:28:36, 0.743s/it]: train_loss_raw=0.8727, running_loss=0.9106, LR=0.000100
[2025-08-27 05:01:03,447][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037736] [Batch 00776/03080] [00:09:36/00:28:30, 0.743s/it]: train_loss_raw=0.7676, running_loss=0.9101, LR=0.000100
[2025-08-27 05:01:09,338][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037744] [Batch 00784/03080] [00:09:42/00:28:24, 0.742s/it]: train_loss_raw=1.0393, running_loss=0.9118, LR=0.000100
[2025-08-27 05:01:15,294][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037752] [Batch 00792/03080] [00:09:48/00:28:18, 0.742s/it]: train_loss_raw=0.9123, running_loss=0.9125, LR=0.000100
[2025-08-27 05:01:21,359][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037760] [Batch 00800/03080] [00:09:54/00:28:13, 0.743s/it]: train_loss_raw=0.9516, running_loss=0.9100, LR=0.000100
[2025-08-27 05:01:27,103][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037768] [Batch 00808/03080] [00:09:59/00:28:06, 0.742s/it]: train_loss_raw=0.9471, running_loss=0.9097, LR=0.000100
[2025-08-27 05:01:33,072][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037776] [Batch 00816/03080] [00:10:05/00:28:00, 0.742s/it]: train_loss_raw=0.9239, running_loss=0.9088, LR=0.000100
[2025-08-27 05:01:38,955][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037784] [Batch 00824/03080] [00:10:11/00:27:54, 0.742s/it]: train_loss_raw=0.9641, running_loss=0.9099, LR=0.000100
[2025-08-27 05:01:44,951][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037792] [Batch 00832/03080] [00:10:17/00:27:48, 0.742s/it]: train_loss_raw=0.8359, running_loss=0.9107, LR=0.000100
[2025-08-27 05:01:50,905][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037800] [Batch 00840/03080] [00:10:23/00:27:43, 0.742s/it]: train_loss_raw=0.9514, running_loss=0.9093, LR=0.000100
[2025-08-27 05:01:56,831][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037808] [Batch 00848/03080] [00:10:29/00:27:37, 0.742s/it]: train_loss_raw=0.8883, running_loss=0.9089, LR=0.000100
[2025-08-27 05:02:02,806][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037816] [Batch 00856/03080] [00:10:35/00:27:31, 0.742s/it]: train_loss_raw=0.9783, running_loss=0.9101, LR=0.000100
[2025-08-27 05:02:08,787][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037824] [Batch 00864/03080] [00:10:41/00:27:25, 0.743s/it]: train_loss_raw=0.9894, running_loss=0.9084, LR=0.000100
[2025-08-27 05:02:14,646][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037832] [Batch 00872/03080] [00:10:47/00:27:19, 0.742s/it]: train_loss_raw=0.8629, running_loss=0.9103, LR=0.000100
[2025-08-27 05:02:20,521][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037840] [Batch 00880/03080] [00:10:53/00:27:13, 0.742s/it]: train_loss_raw=0.9078, running_loss=0.9084, LR=0.000100
[2025-08-27 05:02:26,412][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037848] [Batch 00888/03080] [00:10:59/00:27:07, 0.742s/it]: train_loss_raw=0.9731, running_loss=0.9108, LR=0.000100
[2025-08-27 05:02:32,353][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037856] [Batch 00896/03080] [00:11:05/00:27:01, 0.742s/it]: train_loss_raw=0.9213, running_loss=0.9093, LR=0.000100
[2025-08-27 05:02:38,301][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037864] [Batch 00904/03080] [00:11:11/00:26:55, 0.742s/it]: train_loss_raw=0.9633, running_loss=0.9127, LR=0.000100
[2025-08-27 05:02:44,269][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037872] [Batch 00912/03080] [00:11:17/00:26:49, 0.742s/it]: train_loss_raw=0.8916, running_loss=0.9156, LR=0.000100
[2025-08-27 05:02:50,169][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037880] [Batch 00920/03080] [00:11:22/00:26:43, 0.742s/it]: train_loss_raw=0.8969, running_loss=0.9149, LR=0.000100
[2025-08-27 05:02:56,049][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037888] [Batch 00928/03080] [00:11:28/00:26:37, 0.742s/it]: train_loss_raw=0.8948, running_loss=0.9127, LR=0.000100
[2025-08-27 05:03:02,019][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037896] [Batch 00936/03080] [00:11:34/00:26:31, 0.742s/it]: train_loss_raw=0.9375, running_loss=0.9117, LR=0.000100
[2025-08-27 05:03:07,974][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037904] [Batch 00944/03080] [00:11:40/00:26:25, 0.742s/it]: train_loss_raw=0.9066, running_loss=0.9097, LR=0.000100
[2025-08-27 05:03:13,913][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037912] [Batch 00952/03080] [00:11:46/00:26:19, 0.742s/it]: train_loss_raw=0.8794, running_loss=0.9087, LR=0.000100
[2025-08-27 05:03:19,859][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037920] [Batch 00960/03080] [00:11:52/00:26:13, 0.742s/it]: train_loss_raw=0.8653, running_loss=0.9075, LR=0.000100
[2025-08-27 05:03:25,737][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037928] [Batch 00968/03080] [00:11:58/00:26:07, 0.742s/it]: train_loss_raw=0.8390, running_loss=0.9057, LR=0.000100
[2025-08-27 05:03:31,687][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037936] [Batch 00976/03080] [00:12:04/00:26:01, 0.742s/it]: train_loss_raw=0.9513, running_loss=0.9044, LR=0.000100
[2025-08-27 05:03:37,571][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037944] [Batch 00984/03080] [00:12:10/00:25:55, 0.742s/it]: train_loss_raw=0.9148, running_loss=0.9019, LR=0.000100
[2025-08-27 05:03:43,557][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037952] [Batch 00992/03080] [00:12:16/00:25:49, 0.742s/it]: train_loss_raw=0.9674, running_loss=0.9012, LR=0.000100
[2025-08-27 05:03:49,779][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037960] [Batch 01000/03080] [00:12:22/00:25:44, 0.743s/it]: train_loss_raw=0.9734, running_loss=0.9057, LR=0.000100
[2025-08-27 05:03:55,630][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037968] [Batch 01008/03080] [00:12:28/00:25:38, 0.742s/it]: train_loss_raw=0.8616, running_loss=0.9088, LR=0.000100
[2025-08-27 05:04:01,538][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037976] [Batch 01016/03080] [00:12:34/00:25:32, 0.742s/it]: train_loss_raw=0.8806, running_loss=0.9070, LR=0.000100
[2025-08-27 05:04:07,517][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037984] [Batch 01024/03080] [00:12:40/00:25:26, 0.742s/it]: train_loss_raw=0.8815, running_loss=0.9084, LR=0.000100
[2025-08-27 05:04:13,465][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 037992] [Batch 01032/03080] [00:12:46/00:25:20, 0.742s/it]: train_loss_raw=0.8310, running_loss=0.9075, LR=0.000100
[2025-08-27 05:04:19,321][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038000] [Batch 01040/03080] [00:12:52/00:25:14, 0.742s/it]: train_loss_raw=0.8748, running_loss=0.9069, LR=0.000100
[2025-08-27 05:04:29,269][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038008] [Batch 01048/03080] [00:13:02/00:25:16, 0.746s/it]: train_loss_raw=0.9296, running_loss=0.9038, LR=0.000100
[2025-08-27 05:04:35,129][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038016] [Batch 01056/03080] [00:13:07/00:25:10, 0.746s/it]: train_loss_raw=0.8273, running_loss=0.9023, LR=0.000100
[2025-08-27 05:04:41,013][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038024] [Batch 01064/03080] [00:13:13/00:25:03, 0.746s/it]: train_loss_raw=0.8834, running_loss=0.8998, LR=0.000100
[2025-08-27 05:04:46,956][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038032] [Batch 01072/03080] [00:13:19/00:24:57, 0.746s/it]: train_loss_raw=0.9591, running_loss=0.9013, LR=0.000100
[2025-08-27 05:04:52,901][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038040] [Batch 01080/03080] [00:13:25/00:24:51, 0.746s/it]: train_loss_raw=0.9234, running_loss=0.8999, LR=0.000100
[2025-08-27 05:04:58,880][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038048] [Batch 01088/03080] [00:13:31/00:24:45, 0.746s/it]: train_loss_raw=1.0561, running_loss=0.9011, LR=0.000100
[2025-08-27 05:05:04,914][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038056] [Batch 01096/03080] [00:13:37/00:24:40, 0.746s/it]: train_loss_raw=0.8237, running_loss=0.9035, LR=0.000100
[2025-08-27 05:05:10,780][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038064] [Batch 01104/03080] [00:13:43/00:24:33, 0.746s/it]: train_loss_raw=0.9078, running_loss=0.9039, LR=0.000100
[2025-08-27 05:05:16,885][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038072] [Batch 01112/03080] [00:13:49/00:24:28, 0.746s/it]: train_loss_raw=0.9552, running_loss=0.9031, LR=0.000100
[2025-08-27 05:05:22,885][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038080] [Batch 01120/03080] [00:13:55/00:24:22, 0.746s/it]: train_loss_raw=1.0015, running_loss=0.9042, LR=0.000100
[2025-08-27 05:05:28,735][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038088] [Batch 01128/03080] [00:14:01/00:24:16, 0.746s/it]: train_loss_raw=0.8789, running_loss=0.9052, LR=0.000100
[2025-08-27 05:05:34,983][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038096] [Batch 01136/03080] [00:14:07/00:24:10, 0.746s/it]: train_loss_raw=1.0523, running_loss=0.9063, LR=0.000100
[2025-08-27 05:05:40,991][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038104] [Batch 01144/03080] [00:14:13/00:24:04, 0.746s/it]: train_loss_raw=0.8854, running_loss=0.9055, LR=0.000100
[2025-08-27 05:05:46,906][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038112] [Batch 01152/03080] [00:14:19/00:23:58, 0.746s/it]: train_loss_raw=0.9234, running_loss=0.9072, LR=0.000100
[2025-08-27 05:05:52,789][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038120] [Batch 01160/03080] [00:14:25/00:23:52, 0.746s/it]: train_loss_raw=0.9153, running_loss=0.9083, LR=0.000100
[2025-08-27 05:05:58,634][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038128] [Batch 01168/03080] [00:14:31/00:23:46, 0.746s/it]: train_loss_raw=0.8807, running_loss=0.9076, LR=0.000100
[2025-08-27 05:06:04,460][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038136] [Batch 01176/03080] [00:14:37/00:23:40, 0.746s/it]: train_loss_raw=0.8817, running_loss=0.9062, LR=0.000100
[2025-08-27 05:06:10,370][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038144] [Batch 01184/03080] [00:14:43/00:23:34, 0.746s/it]: train_loss_raw=0.8935, running_loss=0.9075, LR=0.000100
[2025-08-27 05:06:16,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038152] [Batch 01192/03080] [00:14:49/00:23:28, 0.746s/it]: train_loss_raw=0.9768, running_loss=0.9073, LR=0.000100
[2025-08-27 05:06:22,378][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038160] [Batch 01200/03080] [00:14:55/00:23:22, 0.746s/it]: train_loss_raw=0.9364, running_loss=0.9055, LR=0.000100
[2025-08-27 05:06:28,398][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038168] [Batch 01208/03080] [00:15:01/00:23:16, 0.746s/it]: train_loss_raw=0.8846, running_loss=0.9033, LR=0.000100
[2025-08-27 05:06:34,271][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038176] [Batch 01216/03080] [00:15:07/00:23:10, 0.746s/it]: train_loss_raw=0.9397, running_loss=0.9050, LR=0.000100
[2025-08-27 05:06:40,254][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038184] [Batch 01224/03080] [00:15:13/00:23:04, 0.746s/it]: train_loss_raw=0.9653, running_loss=0.9054, LR=0.000100
[2025-08-27 05:06:46,135][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038192] [Batch 01232/03080] [00:15:18/00:22:58, 0.746s/it]: train_loss_raw=0.8727, running_loss=0.9048, LR=0.000100
[2025-08-27 05:06:52,102][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038200] [Batch 01240/03080] [00:15:24/00:22:52, 0.746s/it]: train_loss_raw=0.8364, running_loss=0.9034, LR=0.000100
[2025-08-27 05:06:57,997][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038208] [Batch 01248/03080] [00:15:30/00:22:46, 0.746s/it]: train_loss_raw=0.9282, running_loss=0.9055, LR=0.000100
[2025-08-27 05:07:03,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038216] [Batch 01256/03080] [00:15:36/00:22:40, 0.746s/it]: train_loss_raw=0.7856, running_loss=0.9032, LR=0.000100
[2025-08-27 05:07:09,776][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038224] [Batch 01264/03080] [00:15:42/00:22:34, 0.746s/it]: train_loss_raw=0.9927, running_loss=0.9040, LR=0.000100
[2025-08-27 05:07:15,698][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038232] [Batch 01272/03080] [00:15:48/00:22:28, 0.746s/it]: train_loss_raw=0.9160, running_loss=0.9059, LR=0.000100
[2025-08-27 05:07:21,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038240] [Batch 01280/03080] [00:15:54/00:22:22, 0.746s/it]: train_loss_raw=0.8914, running_loss=0.9059, LR=0.000100
[2025-08-27 05:07:27,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038248] [Batch 01288/03080] [00:16:00/00:22:16, 0.746s/it]: train_loss_raw=0.9651, running_loss=0.9054, LR=0.000100
[2025-08-27 05:07:33,762][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038256] [Batch 01296/03080] [00:16:06/00:22:10, 0.746s/it]: train_loss_raw=0.8286, running_loss=0.9013, LR=0.000100
[2025-08-27 05:07:39,738][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038264] [Batch 01304/03080] [00:16:12/00:22:04, 0.746s/it]: train_loss_raw=0.9096, running_loss=0.8969, LR=0.000100
[2025-08-27 05:07:45,672][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038272] [Batch 01312/03080] [00:16:18/00:21:58, 0.746s/it]: train_loss_raw=0.8263, running_loss=0.8954, LR=0.000100
[2025-08-27 05:07:51,615][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038280] [Batch 01320/03080] [00:16:24/00:21:52, 0.746s/it]: train_loss_raw=0.8891, running_loss=0.8939, LR=0.000100
[2025-08-27 05:07:57,474][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038288] [Batch 01328/03080] [00:16:30/00:21:46, 0.746s/it]: train_loss_raw=0.9742, running_loss=0.8960, LR=0.000100
[2025-08-27 05:08:03,362][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038296] [Batch 01336/03080] [00:16:36/00:21:40, 0.746s/it]: train_loss_raw=0.9181, running_loss=0.8954, LR=0.000100
[2025-08-27 05:08:09,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038304] [Batch 01344/03080] [00:16:41/00:21:34, 0.746s/it]: train_loss_raw=0.9340, running_loss=0.8941, LR=0.000100
[2025-08-27 05:08:14,934][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038312] [Batch 01352/03080] [00:16:47/00:21:27, 0.745s/it]: train_loss_raw=0.8640, running_loss=0.8962, LR=0.000100
[2025-08-27 05:08:20,819][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038320] [Batch 01360/03080] [00:16:53/00:21:21, 0.745s/it]: train_loss_raw=0.7992, running_loss=0.8978, LR=0.000100
[2025-08-27 05:08:26,712][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038328] [Batch 01368/03080] [00:16:59/00:21:15, 0.745s/it]: train_loss_raw=0.8444, running_loss=0.8980, LR=0.000100
[2025-08-27 05:08:32,675][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038336] [Batch 01376/03080] [00:17:05/00:21:09, 0.745s/it]: train_loss_raw=0.8282, running_loss=0.8977, LR=0.000100
[2025-08-27 05:08:38,618][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038344] [Batch 01384/03080] [00:17:11/00:21:03, 0.745s/it]: train_loss_raw=0.9411, running_loss=0.8975, LR=0.000100
[2025-08-27 05:08:44,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038352] [Batch 01392/03080] [00:17:17/00:20:57, 0.745s/it]: train_loss_raw=0.8796, running_loss=0.8977, LR=0.000100
[2025-08-27 05:08:50,556][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038360] [Batch 01400/03080] [00:17:23/00:20:51, 0.745s/it]: train_loss_raw=0.9018, running_loss=0.8991, LR=0.000100
[2025-08-27 05:08:56,448][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038368] [Batch 01408/03080] [00:17:29/00:20:45, 0.745s/it]: train_loss_raw=0.8455, running_loss=0.8990, LR=0.000100
[2025-08-27 05:09:02,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038376] [Batch 01416/03080] [00:17:35/00:20:40, 0.745s/it]: train_loss_raw=0.9809, running_loss=0.8981, LR=0.000100
[2025-08-27 05:09:08,351][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038384] [Batch 01424/03080] [00:17:41/00:20:33, 0.745s/it]: train_loss_raw=0.8794, running_loss=0.8998, LR=0.000100
[2025-08-27 05:09:14,237][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038392] [Batch 01432/03080] [00:17:46/00:20:27, 0.745s/it]: train_loss_raw=0.8580, running_loss=0.8968, LR=0.000100
[2025-08-27 05:09:20,098][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038400] [Batch 01440/03080] [00:17:52/00:20:21, 0.745s/it]: train_loss_raw=0.8092, running_loss=0.8949, LR=0.000100
[2025-08-27 05:09:26,037][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038408] [Batch 01448/03080] [00:17:58/00:20:15, 0.745s/it]: train_loss_raw=0.9263, running_loss=0.8938, LR=0.000100
[2025-08-27 05:09:32,053][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038416] [Batch 01456/03080] [00:18:04/00:20:09, 0.745s/it]: train_loss_raw=0.9654, running_loss=0.8941, LR=0.000100
[2025-08-27 05:09:37,975][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038424] [Batch 01464/03080] [00:18:10/00:20:03, 0.745s/it]: train_loss_raw=0.9288, running_loss=0.8960, LR=0.000100
[2025-08-27 05:09:43,862][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038432] [Batch 01472/03080] [00:18:16/00:19:57, 0.745s/it]: train_loss_raw=0.8645, running_loss=0.8953, LR=0.000100
[2025-08-27 05:09:49,818][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038440] [Batch 01480/03080] [00:18:22/00:19:51, 0.745s/it]: train_loss_raw=0.9235, running_loss=0.8949, LR=0.000100
[2025-08-27 05:09:55,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038448] [Batch 01488/03080] [00:18:28/00:19:45, 0.745s/it]: train_loss_raw=0.8533, running_loss=0.8950, LR=0.000100
[2025-08-27 05:10:01,642][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038456] [Batch 01496/03080] [00:18:34/00:19:39, 0.745s/it]: train_loss_raw=0.8901, running_loss=0.8974, LR=0.000100
[2025-08-27 05:10:07,570][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038464] [Batch 01504/03080] [00:18:40/00:19:33, 0.745s/it]: train_loss_raw=1.0095, running_loss=0.9011, LR=0.000100
[2025-08-27 05:10:13,877][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038472] [Batch 01512/03080] [00:18:46/00:19:28, 0.745s/it]: train_loss_raw=0.8966, running_loss=0.9004, LR=0.000100
[2025-08-27 05:10:19,756][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038480] [Batch 01520/03080] [00:18:52/00:19:22, 0.745s/it]: train_loss_raw=0.8276, running_loss=0.8959, LR=0.000100
[2025-08-27 05:10:25,722][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038488] [Batch 01528/03080] [00:18:58/00:19:16, 0.745s/it]: train_loss_raw=0.8434, running_loss=0.8948, LR=0.000100
[2025-08-27 05:10:31,623][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038496] [Batch 01536/03080] [00:19:04/00:19:10, 0.745s/it]: train_loss_raw=0.8950, running_loss=0.8914, LR=0.000100
[2025-08-27 05:10:37,559][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038504] [Batch 01544/03080] [00:19:10/00:19:04, 0.745s/it]: train_loss_raw=0.9694, running_loss=0.8898, LR=0.000100
[2025-08-27 05:10:43,707][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038512] [Batch 01552/03080] [00:19:16/00:18:58, 0.745s/it]: train_loss_raw=0.8928, running_loss=0.8911, LR=0.000100
[2025-08-27 05:10:49,760][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038520] [Batch 01560/03080] [00:19:22/00:18:52, 0.745s/it]: train_loss_raw=0.8974, running_loss=0.8910, LR=0.000100
[2025-08-27 05:10:55,667][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038528] [Batch 01568/03080] [00:19:28/00:18:46, 0.745s/it]: train_loss_raw=0.9545, running_loss=0.8929, LR=0.000100
[2025-08-27 05:11:01,484][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038536] [Batch 01576/03080] [00:19:34/00:18:40, 0.745s/it]: train_loss_raw=0.8802, running_loss=0.8928, LR=0.000100
[2025-08-27 05:11:07,412][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038544] [Batch 01584/03080] [00:19:40/00:18:34, 0.745s/it]: train_loss_raw=0.8605, running_loss=0.8930, LR=0.000100
[2025-08-27 05:11:13,332][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038552] [Batch 01592/03080] [00:19:46/00:18:28, 0.745s/it]: train_loss_raw=0.9910, running_loss=0.8940, LR=0.000100
[2025-08-27 05:11:19,216][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038560] [Batch 01600/03080] [00:19:51/00:18:22, 0.745s/it]: train_loss_raw=0.8579, running_loss=0.8924, LR=0.000100
[2025-08-27 05:11:25,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038568] [Batch 01608/03080] [00:19:57/00:18:16, 0.745s/it]: train_loss_raw=0.8716, running_loss=0.8928, LR=0.000100
[2025-08-27 05:11:31,064][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038576] [Batch 01616/03080] [00:20:03/00:18:10, 0.745s/it]: train_loss_raw=0.8739, running_loss=0.8904, LR=0.000100
[2025-08-27 05:11:36,901][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038584] [Batch 01624/03080] [00:20:09/00:18:04, 0.745s/it]: train_loss_raw=0.8900, running_loss=0.8916, LR=0.000100
[2025-08-27 05:11:42,845][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038592] [Batch 01632/03080] [00:20:15/00:17:58, 0.745s/it]: train_loss_raw=0.7203, running_loss=0.8911, LR=0.000100
[2025-08-27 05:11:48,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038600] [Batch 01640/03080] [00:20:21/00:17:52, 0.745s/it]: train_loss_raw=0.9968, running_loss=0.8921, LR=0.000100
[2025-08-27 05:11:54,709][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038608] [Batch 01648/03080] [00:20:27/00:17:46, 0.745s/it]: train_loss_raw=0.8434, running_loss=0.8929, LR=0.000100
[2025-08-27 05:12:00,551][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038616] [Batch 01656/03080] [00:20:33/00:17:40, 0.745s/it]: train_loss_raw=0.8581, running_loss=0.8935, LR=0.000100
[2025-08-27 05:12:06,392][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038624] [Batch 01664/03080] [00:20:39/00:17:34, 0.745s/it]: train_loss_raw=0.9342, running_loss=0.8950, LR=0.000100
[2025-08-27 05:12:12,257][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038632] [Batch 01672/03080] [00:20:45/00:17:28, 0.745s/it]: train_loss_raw=0.8920, running_loss=0.8926, LR=0.000100
[2025-08-27 05:12:18,175][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038640] [Batch 01680/03080] [00:20:50/00:17:22, 0.745s/it]: train_loss_raw=0.7721, running_loss=0.8902, LR=0.000100
[2025-08-27 05:12:24,168][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038648] [Batch 01688/03080] [00:20:56/00:17:16, 0.745s/it]: train_loss_raw=0.9678, running_loss=0.8938, LR=0.000100
[2025-08-27 05:12:30,069][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038656] [Batch 01696/03080] [00:21:02/00:17:10, 0.745s/it]: train_loss_raw=0.9044, running_loss=0.8941, LR=0.000100
[2025-08-27 05:12:35,953][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038664] [Batch 01704/03080] [00:21:08/00:17:04, 0.745s/it]: train_loss_raw=0.9692, running_loss=0.8947, LR=0.000100
[2025-08-27 05:12:41,870][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038672] [Batch 01712/03080] [00:21:14/00:16:58, 0.745s/it]: train_loss_raw=0.8700, running_loss=0.8936, LR=0.000100
[2025-08-27 05:12:47,715][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038680] [Batch 01720/03080] [00:21:20/00:16:52, 0.744s/it]: train_loss_raw=0.8131, running_loss=0.8942, LR=0.000100
[2025-08-27 05:12:53,645][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038688] [Batch 01728/03080] [00:21:26/00:16:46, 0.744s/it]: train_loss_raw=0.9785, running_loss=0.8959, LR=0.000100
[2025-08-27 05:12:59,479][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038696] [Batch 01736/03080] [00:21:32/00:16:40, 0.744s/it]: train_loss_raw=0.8329, running_loss=0.8963, LR=0.000100
[2025-08-27 05:13:05,327][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038704] [Batch 01744/03080] [00:21:38/00:16:34, 0.744s/it]: train_loss_raw=0.8595, running_loss=0.8949, LR=0.000100
[2025-08-27 05:13:11,187][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038712] [Batch 01752/03080] [00:21:43/00:16:28, 0.744s/it]: train_loss_raw=0.8812, running_loss=0.8965, LR=0.000100
[2025-08-27 05:13:16,968][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038720] [Batch 01760/03080] [00:21:49/00:16:22, 0.744s/it]: train_loss_raw=0.9770, running_loss=0.8943, LR=0.000100
[2025-08-27 05:13:22,757][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038728] [Batch 01768/03080] [00:21:55/00:16:16, 0.744s/it]: train_loss_raw=0.9106, running_loss=0.8962, LR=0.000100
[2025-08-27 05:13:28,596][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038736] [Batch 01776/03080] [00:22:01/00:16:10, 0.744s/it]: train_loss_raw=0.9065, running_loss=0.8983, LR=0.000100
[2025-08-27 05:13:34,688][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038744] [Batch 01784/03080] [00:22:07/00:16:04, 0.744s/it]: train_loss_raw=1.0136, running_loss=0.9019, LR=0.000100
[2025-08-27 05:13:40,824][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038752] [Batch 01792/03080] [00:22:13/00:15:58, 0.744s/it]: train_loss_raw=0.9161, running_loss=0.9021, LR=0.000100
[2025-08-27 05:13:46,781][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038760] [Batch 01800/03080] [00:22:19/00:15:52, 0.744s/it]: train_loss_raw=0.9384, running_loss=0.9018, LR=0.000100
[2025-08-27 05:13:52,764][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038768] [Batch 01808/03080] [00:22:25/00:15:46, 0.744s/it]: train_loss_raw=0.9535, running_loss=0.9011, LR=0.000100
[2025-08-27 05:13:58,689][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038776] [Batch 01816/03080] [00:22:31/00:15:40, 0.744s/it]: train_loss_raw=0.8544, running_loss=0.9007, LR=0.000100
[2025-08-27 05:14:04,650][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038784] [Batch 01824/03080] [00:22:37/00:15:34, 0.744s/it]: train_loss_raw=0.8573, running_loss=0.9015, LR=0.000100
[2025-08-27 05:14:10,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038792] [Batch 01832/03080] [00:22:43/00:15:28, 0.744s/it]: train_loss_raw=0.8766, running_loss=0.9007, LR=0.000100
[2025-08-27 05:14:16,415][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038800] [Batch 01840/03080] [00:22:49/00:15:22, 0.744s/it]: train_loss_raw=0.8497, running_loss=0.8982, LR=0.000100
[2025-08-27 05:14:22,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038808] [Batch 01848/03080] [00:22:55/00:15:16, 0.744s/it]: train_loss_raw=0.8040, running_loss=0.8963, LR=0.000100
[2025-08-27 05:14:28,436][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038816] [Batch 01856/03080] [00:23:01/00:15:10, 0.744s/it]: train_loss_raw=0.8549, running_loss=0.8955, LR=0.000100
[2025-08-27 05:14:34,350][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038824] [Batch 01864/03080] [00:23:07/00:15:04, 0.744s/it]: train_loss_raw=0.8277, running_loss=0.8947, LR=0.000100
[2025-08-27 05:14:40,378][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038832] [Batch 01872/03080] [00:23:13/00:14:58, 0.744s/it]: train_loss_raw=0.9096, running_loss=0.8951, LR=0.000100
[2025-08-27 05:14:46,364][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038840] [Batch 01880/03080] [00:23:19/00:14:53, 0.744s/it]: train_loss_raw=0.8838, running_loss=0.8913, LR=0.000100
[2025-08-27 05:14:52,335][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038848] [Batch 01888/03080] [00:23:25/00:14:47, 0.744s/it]: train_loss_raw=0.7942, running_loss=0.8909, LR=0.000100
[2025-08-27 05:14:58,334][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038856] [Batch 01896/03080] [00:23:31/00:14:41, 0.744s/it]: train_loss_raw=1.0309, running_loss=0.8913, LR=0.000100
[2025-08-27 05:15:04,169][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038864] [Batch 01904/03080] [00:23:36/00:14:35, 0.744s/it]: train_loss_raw=0.8669, running_loss=0.8878, LR=0.000100
[2025-08-27 05:15:10,133][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038872] [Batch 01912/03080] [00:23:42/00:14:29, 0.744s/it]: train_loss_raw=0.8841, running_loss=0.8868, LR=0.000100
[2025-08-27 05:15:16,092][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038880] [Batch 01920/03080] [00:23:48/00:14:23, 0.744s/it]: train_loss_raw=0.9140, running_loss=0.8871, LR=0.000100
[2025-08-27 05:15:22,217][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038888] [Batch 01928/03080] [00:23:54/00:14:17, 0.744s/it]: train_loss_raw=0.9792, running_loss=0.8887, LR=0.000100
[2025-08-27 05:15:28,222][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038896] [Batch 01936/03080] [00:24:00/00:14:11, 0.744s/it]: train_loss_raw=0.8669, running_loss=0.8894, LR=0.000100
[2025-08-27 05:15:34,222][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038904] [Batch 01944/03080] [00:24:06/00:14:05, 0.744s/it]: train_loss_raw=0.9114, running_loss=0.8885, LR=0.000100
[2025-08-27 05:15:40,289][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038912] [Batch 01952/03080] [00:24:13/00:13:59, 0.744s/it]: train_loss_raw=0.9261, running_loss=0.8890, LR=0.000100
[2025-08-27 05:15:46,228][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038920] [Batch 01960/03080] [00:24:18/00:13:53, 0.744s/it]: train_loss_raw=0.9866, running_loss=0.8907, LR=0.000100
[2025-08-27 05:15:52,198][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038928] [Batch 01968/03080] [00:24:24/00:13:47, 0.744s/it]: train_loss_raw=0.8765, running_loss=0.8882, LR=0.000100
[2025-08-27 05:15:58,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038936] [Batch 01976/03080] [00:24:30/00:13:41, 0.744s/it]: train_loss_raw=1.0069, running_loss=0.8923, LR=0.000100
[2025-08-27 05:16:04,138][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038944] [Batch 01984/03080] [00:24:36/00:13:35, 0.744s/it]: train_loss_raw=0.9415, running_loss=0.8897, LR=0.000100
[2025-08-27 05:16:10,081][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038952] [Batch 01992/03080] [00:24:42/00:13:29, 0.744s/it]: train_loss_raw=0.9671, running_loss=0.8885, LR=0.000100
[2025-08-27 05:16:16,087][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038960] [Batch 02000/03080] [00:24:48/00:13:23, 0.744s/it]: train_loss_raw=0.8821, running_loss=0.8875, LR=0.000100
[2025-08-27 05:16:22,059][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038968] [Batch 02008/03080] [00:24:54/00:13:18, 0.744s/it]: train_loss_raw=0.9548, running_loss=0.8875, LR=0.000100
[2025-08-27 05:16:27,987][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038976] [Batch 02016/03080] [00:25:00/00:13:12, 0.744s/it]: train_loss_raw=0.9301, running_loss=0.8860, LR=0.000100
[2025-08-27 05:16:33,831][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038984] [Batch 02024/03080] [00:25:06/00:13:06, 0.744s/it]: train_loss_raw=0.8969, running_loss=0.8871, LR=0.000100
[2025-08-27 05:16:39,699][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 038992] [Batch 02032/03080] [00:25:12/00:13:00, 0.744s/it]: train_loss_raw=0.9116, running_loss=0.8878, LR=0.000100
[2025-08-27 05:16:45,490][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039000] [Batch 02040/03080] [00:25:18/00:12:54, 0.744s/it]: train_loss_raw=0.8237, running_loss=0.8874, LR=0.000100
[2025-08-27 05:16:51,503][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039008] [Batch 02048/03080] [00:25:24/00:12:48, 0.744s/it]: train_loss_raw=0.9195, running_loss=0.8860, LR=0.000100
[2025-08-27 05:16:57,376][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039016] [Batch 02056/03080] [00:25:30/00:12:42, 0.744s/it]: train_loss_raw=0.7924, running_loss=0.8826, LR=0.000100
[2025-08-27 05:17:03,238][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039024] [Batch 02064/03080] [00:25:35/00:12:36, 0.744s/it]: train_loss_raw=0.8808, running_loss=0.8827, LR=0.000100
[2025-08-27 05:17:09,118][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039032] [Batch 02072/03080] [00:25:41/00:12:30, 0.744s/it]: train_loss_raw=0.9667, running_loss=0.8835, LR=0.000100
[2025-08-27 05:17:14,978][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039040] [Batch 02080/03080] [00:25:47/00:12:24, 0.744s/it]: train_loss_raw=0.8837, running_loss=0.8811, LR=0.000100
[2025-08-27 05:17:21,019][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039048] [Batch 02088/03080] [00:25:53/00:12:18, 0.744s/it]: train_loss_raw=0.8718, running_loss=0.8826, LR=0.000100
[2025-08-27 05:17:26,934][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039056] [Batch 02096/03080] [00:25:59/00:12:12, 0.744s/it]: train_loss_raw=0.8329, running_loss=0.8826, LR=0.000100
[2025-08-27 05:17:32,773][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039064] [Batch 02104/03080] [00:26:05/00:12:06, 0.744s/it]: train_loss_raw=1.0049, running_loss=0.8844, LR=0.000100
[2025-08-27 05:17:38,532][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039072] [Batch 02112/03080] [00:26:11/00:12:00, 0.744s/it]: train_loss_raw=0.9639, running_loss=0.8889, LR=0.000100
[2025-08-27 05:17:44,334][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039080] [Batch 02120/03080] [00:26:17/00:11:54, 0.744s/it]: train_loss_raw=0.8611, running_loss=0.8891, LR=0.000100
[2025-08-27 05:17:50,215][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039088] [Batch 02128/03080] [00:26:22/00:11:48, 0.744s/it]: train_loss_raw=0.7236, running_loss=0.8858, LR=0.000100
[2025-08-27 05:17:55,951][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039096] [Batch 02136/03080] [00:26:28/00:11:42, 0.744s/it]: train_loss_raw=0.7894, running_loss=0.8839, LR=0.000100
[2025-08-27 05:18:01,783][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039104] [Batch 02144/03080] [00:26:34/00:11:36, 0.744s/it]: train_loss_raw=0.7940, running_loss=0.8837, LR=0.000100
[2025-08-27 05:18:07,628][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039112] [Batch 02152/03080] [00:26:40/00:11:30, 0.744s/it]: train_loss_raw=0.8063, running_loss=0.8831, LR=0.000100
[2025-08-27 05:18:13,520][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039120] [Batch 02160/03080] [00:26:46/00:11:24, 0.744s/it]: train_loss_raw=0.7833, running_loss=0.8820, LR=0.000100
[2025-08-27 05:18:19,494][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039128] [Batch 02168/03080] [00:26:52/00:11:18, 0.744s/it]: train_loss_raw=0.8254, running_loss=0.8803, LR=0.000100
[2025-08-27 05:18:25,449][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039136] [Batch 02176/03080] [00:26:58/00:11:12, 0.744s/it]: train_loss_raw=0.8285, running_loss=0.8809, LR=0.000100
[2025-08-27 05:18:31,337][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039144] [Batch 02184/03080] [00:27:04/00:11:06, 0.744s/it]: train_loss_raw=0.8633, running_loss=0.8800, LR=0.000100
[2025-08-27 05:18:37,054][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039152] [Batch 02192/03080] [00:27:09/00:11:00, 0.744s/it]: train_loss_raw=0.7960, running_loss=0.8790, LR=0.000100
[2025-08-27 05:18:42,912][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039160] [Batch 02200/03080] [00:27:15/00:10:54, 0.743s/it]: train_loss_raw=0.9324, running_loss=0.8788, LR=0.000100
[2025-08-27 05:18:48,962][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039168] [Batch 02208/03080] [00:27:21/00:10:48, 0.744s/it]: train_loss_raw=0.7558, running_loss=0.8778, LR=0.000100
[2025-08-27 05:18:54,961][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039176] [Batch 02216/03080] [00:27:27/00:10:42, 0.744s/it]: train_loss_raw=0.8571, running_loss=0.8791, LR=0.000100
[2025-08-27 05:19:00,866][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039184] [Batch 02224/03080] [00:27:33/00:10:36, 0.744s/it]: train_loss_raw=0.9163, running_loss=0.8778, LR=0.000100
[2025-08-27 05:19:06,809][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039192] [Batch 02232/03080] [00:27:39/00:10:30, 0.744s/it]: train_loss_raw=0.8337, running_loss=0.8764, LR=0.000100
[2025-08-27 05:19:12,700][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039200] [Batch 02240/03080] [00:27:45/00:10:24, 0.744s/it]: train_loss_raw=0.8977, running_loss=0.8773, LR=0.000100
[2025-08-27 05:19:18,270][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039208] [Batch 02248/03080] [00:27:51/00:10:18, 0.743s/it]: train_loss_raw=0.8796, running_loss=0.8779, LR=0.000100
[2025-08-27 05:19:23,911][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039216] [Batch 02256/03080] [00:27:56/00:10:12, 0.743s/it]: train_loss_raw=0.9539, running_loss=0.8796, LR=0.000100
[2025-08-27 05:19:29,851][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039224] [Batch 02264/03080] [00:28:02/00:10:06, 0.743s/it]: train_loss_raw=0.9211, running_loss=0.8807, LR=0.000100
[2025-08-27 05:19:35,805][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039232] [Batch 02272/03080] [00:28:08/00:10:00, 0.743s/it]: train_loss_raw=0.9121, running_loss=0.8837, LR=0.000100
[2025-08-27 05:19:41,788][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039240] [Batch 02280/03080] [00:28:14/00:09:54, 0.743s/it]: train_loss_raw=0.9274, running_loss=0.8865, LR=0.000100
[2025-08-27 05:19:47,595][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039248] [Batch 02288/03080] [00:28:20/00:09:48, 0.743s/it]: train_loss_raw=0.9356, running_loss=0.8838, LR=0.000100
[2025-08-27 05:19:53,479][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039256] [Batch 02296/03080] [00:28:26/00:09:42, 0.743s/it]: train_loss_raw=0.9052, running_loss=0.8859, LR=0.000100
[2025-08-27 05:19:59,265][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039264] [Batch 02304/03080] [00:28:32/00:09:36, 0.743s/it]: train_loss_raw=0.8543, running_loss=0.8833, LR=0.000100
[2025-08-27 05:20:05,012][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039272] [Batch 02312/03080] [00:28:37/00:09:30, 0.743s/it]: train_loss_raw=0.7677, running_loss=0.8794, LR=0.000100
[2025-08-27 05:20:10,923][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039280] [Batch 02320/03080] [00:28:43/00:09:24, 0.743s/it]: train_loss_raw=0.9197, running_loss=0.8798, LR=0.000100
[2025-08-27 05:20:16,737][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039288] [Batch 02328/03080] [00:28:49/00:09:18, 0.743s/it]: train_loss_raw=0.9904, running_loss=0.8824, LR=0.000100
[2025-08-27 05:20:22,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039296] [Batch 02336/03080] [00:28:55/00:09:12, 0.743s/it]: train_loss_raw=0.8818, running_loss=0.8838, LR=0.000100
[2025-08-27 05:20:28,385][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039304] [Batch 02344/03080] [00:29:01/00:09:06, 0.743s/it]: train_loss_raw=0.7791, running_loss=0.8832, LR=0.000100
[2025-08-27 05:20:34,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039312] [Batch 02352/03080] [00:29:07/00:09:00, 0.743s/it]: train_loss_raw=0.8944, running_loss=0.8834, LR=0.000100
[2025-08-27 05:20:40,215][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039320] [Batch 02360/03080] [00:29:12/00:08:54, 0.743s/it]: train_loss_raw=0.8289, running_loss=0.8836, LR=0.000100
[2025-08-27 05:20:46,047][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039328] [Batch 02368/03080] [00:29:18/00:08:48, 0.743s/it]: train_loss_raw=0.9453, running_loss=0.8863, LR=0.000100
[2025-08-27 05:20:51,845][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039336] [Batch 02376/03080] [00:29:24/00:08:42, 0.743s/it]: train_loss_raw=0.8296, running_loss=0.8817, LR=0.000100
[2025-08-27 05:20:57,890][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039344] [Batch 02384/03080] [00:29:30/00:08:36, 0.743s/it]: train_loss_raw=0.8800, running_loss=0.8792, LR=0.000100
[2025-08-27 05:21:03,774][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039352] [Batch 02392/03080] [00:29:36/00:08:30, 0.743s/it]: train_loss_raw=0.8140, running_loss=0.8829, LR=0.000100
[2025-08-27 05:21:09,632][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039360] [Batch 02400/03080] [00:29:42/00:08:25, 0.743s/it]: train_loss_raw=0.8698, running_loss=0.8817, LR=0.000100
[2025-08-27 05:21:15,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039368] [Batch 02408/03080] [00:29:48/00:08:19, 0.743s/it]: train_loss_raw=0.8913, running_loss=0.8817, LR=0.000100
[2025-08-27 05:21:21,537][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039376] [Batch 02416/03080] [00:29:54/00:08:13, 0.743s/it]: train_loss_raw=0.8311, running_loss=0.8814, LR=0.000100
[2025-08-27 05:21:27,347][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039384] [Batch 02424/03080] [00:30:00/00:08:07, 0.743s/it]: train_loss_raw=0.9805, running_loss=0.8805, LR=0.000100
[2025-08-27 05:21:33,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039392] [Batch 02432/03080] [00:30:05/00:08:01, 0.743s/it]: train_loss_raw=0.9554, running_loss=0.8801, LR=0.000100
[2025-08-27 05:21:39,136][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039400] [Batch 02440/03080] [00:30:11/00:07:55, 0.743s/it]: train_loss_raw=0.8875, running_loss=0.8788, LR=0.000100
[2025-08-27 05:21:44,970][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039408] [Batch 02448/03080] [00:30:17/00:07:49, 0.743s/it]: train_loss_raw=0.9294, running_loss=0.8783, LR=0.000100
[2025-08-27 05:21:50,924][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039416] [Batch 02456/03080] [00:30:23/00:07:43, 0.743s/it]: train_loss_raw=0.9559, running_loss=0.8787, LR=0.000100
[2025-08-27 05:21:56,873][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039424] [Batch 02464/03080] [00:30:29/00:07:37, 0.743s/it]: train_loss_raw=0.8642, running_loss=0.8772, LR=0.000100
[2025-08-27 05:22:02,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039432] [Batch 02472/03080] [00:30:35/00:07:31, 0.743s/it]: train_loss_raw=0.8255, running_loss=0.8770, LR=0.000100
[2025-08-27 05:22:08,588][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039440] [Batch 02480/03080] [00:30:41/00:07:25, 0.742s/it]: train_loss_raw=0.8479, running_loss=0.8774, LR=0.000100
[2025-08-27 05:22:14,491][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039448] [Batch 02488/03080] [00:30:47/00:07:19, 0.742s/it]: train_loss_raw=0.9085, running_loss=0.8760, LR=0.000100
[2025-08-27 05:22:20,270][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039456] [Batch 02496/03080] [00:30:53/00:07:13, 0.742s/it]: train_loss_raw=0.9506, running_loss=0.8744, LR=0.000100
[2025-08-27 05:22:26,060][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039464] [Batch 02504/03080] [00:30:58/00:07:07, 0.742s/it]: train_loss_raw=0.9109, running_loss=0.8755, LR=0.000100
[2025-08-27 05:22:31,921][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039472] [Batch 02512/03080] [00:31:04/00:07:01, 0.742s/it]: train_loss_raw=0.8955, running_loss=0.8760, LR=0.000100
[2025-08-27 05:22:37,686][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039480] [Batch 02520/03080] [00:31:10/00:06:55, 0.742s/it]: train_loss_raw=0.8354, running_loss=0.8761, LR=0.000100
[2025-08-27 05:22:43,546][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039488] [Batch 02528/03080] [00:31:16/00:06:49, 0.742s/it]: train_loss_raw=0.8383, running_loss=0.8772, LR=0.000100
[2025-08-27 05:22:49,328][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039496] [Batch 02536/03080] [00:31:22/00:06:43, 0.742s/it]: train_loss_raw=0.7639, running_loss=0.8742, LR=0.000100
[2025-08-27 05:22:54,975][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039504] [Batch 02544/03080] [00:31:27/00:06:37, 0.742s/it]: train_loss_raw=0.9039, running_loss=0.8734, LR=0.000100
[2025-08-27 05:23:00,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039512] [Batch 02552/03080] [00:31:33/00:06:31, 0.742s/it]: train_loss_raw=0.8697, running_loss=0.8714, LR=0.000100
[2025-08-27 05:23:06,930][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039520] [Batch 02560/03080] [00:31:39/00:06:25, 0.742s/it]: train_loss_raw=0.9260, running_loss=0.8727, LR=0.000100
[2025-08-27 05:23:12,918][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039528] [Batch 02568/03080] [00:31:45/00:06:19, 0.742s/it]: train_loss_raw=0.8160, running_loss=0.8707, LR=0.000100
[2025-08-27 05:23:18,720][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039536] [Batch 02576/03080] [00:31:51/00:06:13, 0.742s/it]: train_loss_raw=0.8757, running_loss=0.8699, LR=0.000100
[2025-08-27 05:23:24,636][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039544] [Batch 02584/03080] [00:31:57/00:06:08, 0.742s/it]: train_loss_raw=0.9644, running_loss=0.8706, LR=0.000100
[2025-08-27 05:23:30,555][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039552] [Batch 02592/03080] [00:32:03/00:06:02, 0.742s/it]: train_loss_raw=0.9136, running_loss=0.8739, LR=0.000100
[2025-08-27 05:23:36,466][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039560] [Batch 02600/03080] [00:32:09/00:05:56, 0.742s/it]: train_loss_raw=0.8530, running_loss=0.8745, LR=0.000100
[2025-08-27 05:23:42,384][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039568] [Batch 02608/03080] [00:32:15/00:05:50, 0.742s/it]: train_loss_raw=0.8017, running_loss=0.8752, LR=0.000100
[2025-08-27 05:23:48,282][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039576] [Batch 02616/03080] [00:32:21/00:05:44, 0.742s/it]: train_loss_raw=0.8693, running_loss=0.8785, LR=0.000100
[2025-08-27 05:23:54,241][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039584] [Batch 02624/03080] [00:32:26/00:05:38, 0.742s/it]: train_loss_raw=0.7865, running_loss=0.8750, LR=0.000100
[2025-08-27 05:24:00,173][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039592] [Batch 02632/03080] [00:32:32/00:05:32, 0.742s/it]: train_loss_raw=0.7778, running_loss=0.8728, LR=0.000100
[2025-08-27 05:24:05,871][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039600] [Batch 02640/03080] [00:32:38/00:05:26, 0.742s/it]: train_loss_raw=0.9664, running_loss=0.8707, LR=0.000100
[2025-08-27 05:24:11,648][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039608] [Batch 02648/03080] [00:32:44/00:05:20, 0.742s/it]: train_loss_raw=0.8583, running_loss=0.8690, LR=0.000100
[2025-08-27 05:24:17,554][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039616] [Batch 02656/03080] [00:32:50/00:05:14, 0.742s/it]: train_loss_raw=0.8497, running_loss=0.8680, LR=0.000100
[2025-08-27 05:24:23,436][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039624] [Batch 02664/03080] [00:32:56/00:05:08, 0.742s/it]: train_loss_raw=0.8833, running_loss=0.8728, LR=0.000100
[2025-08-27 05:24:29,309][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039632] [Batch 02672/03080] [00:33:02/00:05:02, 0.742s/it]: train_loss_raw=0.8865, running_loss=0.8744, LR=0.000100
[2025-08-27 05:24:35,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039640] [Batch 02680/03080] [00:33:07/00:04:56, 0.742s/it]: train_loss_raw=0.8431, running_loss=0.8727, LR=0.000100
[2025-08-27 05:24:41,346][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039648] [Batch 02688/03080] [00:33:14/00:04:50, 0.742s/it]: train_loss_raw=0.8787, running_loss=0.8729, LR=0.000100
[2025-08-27 05:24:47,267][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039656] [Batch 02696/03080] [00:33:20/00:04:44, 0.742s/it]: train_loss_raw=0.8278, running_loss=0.8702, LR=0.000100
[2025-08-27 05:24:53,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039664] [Batch 02704/03080] [00:33:25/00:04:38, 0.742s/it]: train_loss_raw=0.9786, running_loss=0.8716, LR=0.000100
[2025-08-27 05:24:58,940][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039672] [Batch 02712/03080] [00:33:31/00:04:32, 0.742s/it]: train_loss_raw=0.8245, running_loss=0.8733, LR=0.000100
[2025-08-27 05:25:04,722][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039680] [Batch 02720/03080] [00:33:37/00:04:27, 0.742s/it]: train_loss_raw=0.8358, running_loss=0.8715, LR=0.000100
[2025-08-27 05:25:10,621][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039688] [Batch 02728/03080] [00:33:43/00:04:21, 0.742s/it]: train_loss_raw=0.9420, running_loss=0.8702, LR=0.000100
[2025-08-27 05:25:16,583][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039696] [Batch 02736/03080] [00:33:49/00:04:15, 0.742s/it]: train_loss_raw=0.8570, running_loss=0.8670, LR=0.000100
[2025-08-27 05:25:22,319][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039704] [Batch 02744/03080] [00:33:55/00:04:09, 0.742s/it]: train_loss_raw=0.8349, running_loss=0.8635, LR=0.000100
[2025-08-27 05:25:28,199][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039712] [Batch 02752/03080] [00:34:00/00:04:03, 0.742s/it]: train_loss_raw=0.7654, running_loss=0.8606, LR=0.000100
[2025-08-27 05:25:34,057][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039720] [Batch 02760/03080] [00:34:06/00:03:57, 0.742s/it]: train_loss_raw=0.8334, running_loss=0.8595, LR=0.000100
[2025-08-27 05:25:39,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039728] [Batch 02768/03080] [00:34:12/00:03:51, 0.742s/it]: train_loss_raw=0.8537, running_loss=0.8597, LR=0.000100
[2025-08-27 05:25:45,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039736] [Batch 02776/03080] [00:34:18/00:03:45, 0.741s/it]: train_loss_raw=0.8871, running_loss=0.8612, LR=0.000100
[2025-08-27 05:25:51,339][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039744] [Batch 02784/03080] [00:34:24/00:03:39, 0.741s/it]: train_loss_raw=0.8600, running_loss=0.8589, LR=0.000100
[2025-08-27 05:25:57,287][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039752] [Batch 02792/03080] [00:34:30/00:03:33, 0.741s/it]: train_loss_raw=0.7998, running_loss=0.8590, LR=0.000100
[2025-08-27 05:26:03,191][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039760] [Batch 02800/03080] [00:34:35/00:03:27, 0.741s/it]: train_loss_raw=0.8396, running_loss=0.8581, LR=0.000100
[2025-08-27 05:26:09,146][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039768] [Batch 02808/03080] [00:34:41/00:03:21, 0.741s/it]: train_loss_raw=0.8295, running_loss=0.8548, LR=0.000100
[2025-08-27 05:26:15,112][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039776] [Batch 02816/03080] [00:34:47/00:03:15, 0.741s/it]: train_loss_raw=0.9447, running_loss=0.8559, LR=0.000100
[2025-08-27 05:26:21,163][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039784] [Batch 02824/03080] [00:34:53/00:03:09, 0.741s/it]: train_loss_raw=0.9150, running_loss=0.8560, LR=0.000100
[2025-08-27 05:26:27,277][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039792] [Batch 02832/03080] [00:35:00/00:03:03, 0.742s/it]: train_loss_raw=0.7999, running_loss=0.8561, LR=0.000100
[2025-08-27 05:26:33,188][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039800] [Batch 02840/03080] [00:35:05/00:02:57, 0.742s/it]: train_loss_raw=0.8475, running_loss=0.8573, LR=0.000100
[2025-08-27 05:26:39,030][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039808] [Batch 02848/03080] [00:35:11/00:02:52, 0.741s/it]: train_loss_raw=0.8778, running_loss=0.8585, LR=0.000100
[2025-08-27 05:26:44,896][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039816] [Batch 02856/03080] [00:35:17/00:02:46, 0.741s/it]: train_loss_raw=0.8953, running_loss=0.8578, LR=0.000100
[2025-08-27 05:26:50,753][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039824] [Batch 02864/03080] [00:35:23/00:02:40, 0.741s/it]: train_loss_raw=0.8804, running_loss=0.8595, LR=0.000100
[2025-08-27 05:26:56,594][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039832] [Batch 02872/03080] [00:35:29/00:02:34, 0.741s/it]: train_loss_raw=0.8634, running_loss=0.8597, LR=0.000100
[2025-08-27 05:27:02,406][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039840] [Batch 02880/03080] [00:35:35/00:02:28, 0.741s/it]: train_loss_raw=0.9751, running_loss=0.8644, LR=0.000100
[2025-08-27 05:27:08,214][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039848] [Batch 02888/03080] [00:35:40/00:02:22, 0.741s/it]: train_loss_raw=0.8278, running_loss=0.8645, LR=0.000100
[2025-08-27 05:27:14,089][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039856] [Batch 02896/03080] [00:35:46/00:02:16, 0.741s/it]: train_loss_raw=0.9643, running_loss=0.8671, LR=0.000100
[2025-08-27 05:27:19,873][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039864] [Batch 02904/03080] [00:35:52/00:02:10, 0.741s/it]: train_loss_raw=0.8323, running_loss=0.8640, LR=0.000100
[2025-08-27 05:27:25,862][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039872] [Batch 02912/03080] [00:35:58/00:02:04, 0.741s/it]: train_loss_raw=0.9283, running_loss=0.8604, LR=0.000100
[2025-08-27 05:27:31,843][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039880] [Batch 02920/03080] [00:36:04/00:01:58, 0.741s/it]: train_loss_raw=0.8169, running_loss=0.8601, LR=0.000100
[2025-08-27 05:27:37,727][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039888] [Batch 02928/03080] [00:36:10/00:01:52, 0.741s/it]: train_loss_raw=0.8748, running_loss=0.8611, LR=0.000100
[2025-08-27 05:27:43,608][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039896] [Batch 02936/03080] [00:36:16/00:01:46, 0.741s/it]: train_loss_raw=0.8467, running_loss=0.8602, LR=0.000100
[2025-08-27 05:27:49,431][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039904] [Batch 02944/03080] [00:36:22/00:01:40, 0.741s/it]: train_loss_raw=0.8300, running_loss=0.8602, LR=0.000100
[2025-08-27 05:27:55,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039912] [Batch 02952/03080] [00:36:28/00:01:34, 0.741s/it]: train_loss_raw=0.8667, running_loss=0.8598, LR=0.000100
[2025-08-27 05:28:01,218][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039920] [Batch 02960/03080] [00:36:33/00:01:28, 0.741s/it]: train_loss_raw=1.0020, running_loss=0.8591, LR=0.000100
[2025-08-27 05:28:07,082][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039928] [Batch 02968/03080] [00:36:39/00:01:23, 0.741s/it]: train_loss_raw=0.8973, running_loss=0.8626, LR=0.000100
[2025-08-27 05:28:12,966][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039936] [Batch 02976/03080] [00:36:45/00:01:17, 0.741s/it]: train_loss_raw=0.8284, running_loss=0.8598, LR=0.000100
[2025-08-27 05:28:18,877][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039944] [Batch 02984/03080] [00:36:51/00:01:11, 0.741s/it]: train_loss_raw=0.7136, running_loss=0.8572, LR=0.000100
[2025-08-27 05:28:24,823][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039952] [Batch 02992/03080] [00:36:57/00:01:05, 0.741s/it]: train_loss_raw=0.9329, running_loss=0.8573, LR=0.000100
[2025-08-27 05:28:30,815][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039960] [Batch 03000/03080] [00:37:03/00:00:59, 0.741s/it]: train_loss_raw=0.9005, running_loss=0.8604, LR=0.000100
[2025-08-27 05:28:36,627][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039968] [Batch 03008/03080] [00:37:09/00:00:53, 0.741s/it]: train_loss_raw=0.9089, running_loss=0.8604, LR=0.000100
[2025-08-27 05:28:42,494][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039976] [Batch 03016/03080] [00:37:15/00:00:47, 0.741s/it]: train_loss_raw=0.7909, running_loss=0.8612, LR=0.000100
[2025-08-27 05:28:48,329][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039984] [Batch 03024/03080] [00:37:21/00:00:41, 0.741s/it]: train_loss_raw=0.7815, running_loss=0.8609, LR=0.000100
[2025-08-27 05:28:54,286][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 039992] [Batch 03032/03080] [00:37:27/00:00:35, 0.741s/it]: train_loss_raw=0.8297, running_loss=0.8592, LR=0.000100
[2025-08-27 05:29:00,064][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040000] [Batch 03040/03080] [00:37:32/00:00:29, 0.741s/it]: train_loss_raw=0.8938, running_loss=0.8600, LR=0.000100
[2025-08-27 05:29:09,724][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040008] [Batch 03048/03080] [00:37:42/00:00:23, 0.742s/it]: train_loss_raw=0.9697, running_loss=0.8596, LR=0.000100
[2025-08-27 05:29:15,509][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040016] [Batch 03056/03080] [00:37:48/00:00:17, 0.742s/it]: train_loss_raw=0.9139, running_loss=0.8580, LR=0.000100
[2025-08-27 05:29:21,262][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040024] [Batch 03064/03080] [00:37:54/00:00:11, 0.742s/it]: train_loss_raw=0.8684, running_loss=0.8583, LR=0.000100
[2025-08-27 05:29:27,008][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040032] [Batch 03072/03080] [00:37:59/00:00:05, 0.742s/it]: train_loss_raw=0.8687, running_loss=0.8570, LR=0.000100
[2025-08-27 05:29:32,794][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 040040] [Batch 03080/03080] [00:38:05/00:00:00, 0.742s/it]: train_loss_raw=0.8105, running_loss=0.8571, LR=0.000100
[2025-08-27 05:29:33,304][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-27 05:29:44,512][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00007/00310] [00:00:11/00:07:03, 1.401s/it]
[2025-08-27 05:29:56,129][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00015/00310] [00:00:22/00:06:59, 1.427s/it]
[2025-08-27 05:30:08,426][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00023/00310] [00:00:35/00:06:58, 1.463s/it]
[2025-08-27 05:30:21,314][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00031/00310] [00:00:48/00:06:57, 1.500s/it]
[2025-08-27 05:30:34,332][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00039/00310] [00:01:01/00:06:51, 1.526s/it]
[2025-08-27 05:30:46,645][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00047/00310] [00:01:13/00:06:40, 1.528s/it]
[2025-08-27 05:30:59,557][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00055/00310] [00:01:26/00:06:31, 1.540s/it]
[2025-08-27 05:31:12,053][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00063/00310] [00:01:38/00:06:19, 1.543s/it]
[2025-08-27 05:31:25,352][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00071/00310] [00:01:52/00:06:10, 1.556s/it]
[2025-08-27 05:31:38,490][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00079/00310] [00:02:05/00:05:59, 1.565s/it]
[2025-08-27 05:31:51,090][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00087/00310] [00:02:17/00:05:47, 1.566s/it]
[2025-08-27 05:32:02,921][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00095/00310] [00:02:29/00:05:33, 1.559s/it]
[2025-08-27 05:32:15,460][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00103/00310] [00:02:42/00:05:21, 1.559s/it]
[2025-08-27 05:32:28,103][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00111/00310] [00:02:54/00:05:09, 1.561s/it]
[2025-08-27 05:32:41,190][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00119/00310] [00:03:07/00:04:57, 1.566s/it]
[2025-08-27 05:32:54,490][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00127/00310] [00:03:21/00:04:46, 1.572s/it]
[2025-08-27 05:33:07,160][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00135/00310] [00:03:33/00:04:33, 1.572s/it]
[2025-08-27 05:33:20,285][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00143/00310] [00:03:46/00:04:21, 1.576s/it]
[2025-08-27 05:33:31,211][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00151/00310] [00:03:57/00:04:07, 1.565s/it]
[2025-08-27 05:33:43,107][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00159/00310] [00:04:09/00:03:54, 1.561s/it]
[2025-08-27 05:33:55,744][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00167/00310] [00:04:22/00:03:41, 1.562s/it]
[2025-08-27 05:34:07,113][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00175/00310] [00:04:33/00:03:28, 1.556s/it]
[2025-08-27 05:34:18,413][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00183/00310] [00:04:45/00:03:15, 1.550s/it]
[2025-08-27 05:34:31,253][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00191/00310] [00:04:57/00:03:03, 1.552s/it]
[2025-08-27 05:34:43,532][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00199/00310] [00:05:10/00:02:50, 1.551s/it]
[2025-08-27 05:34:54,936][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00207/00310] [00:05:21/00:02:37, 1.546s/it]
[2025-08-27 05:35:06,712][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00215/00310] [00:05:33/00:02:25, 1.544s/it]
[2025-08-27 05:35:18,964][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00223/00310] [00:05:45/00:02:12, 1.543s/it]
[2025-08-27 05:35:31,284][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00231/00310] [00:05:57/00:02:00, 1.543s/it]
[2025-08-27 05:35:43,590][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00239/00310] [00:06:10/00:01:47, 1.543s/it]
[2025-08-27 05:35:55,853][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00247/00310] [00:06:22/00:01:35, 1.543s/it]
[2025-08-27 05:36:08,404][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00255/00310] [00:06:35/00:01:23, 1.543s/it]
[2025-08-27 05:36:21,107][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00263/00310] [00:06:47/00:01:11, 1.545s/it]
[2025-08-27 05:36:33,376][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00271/00310] [00:07:00/00:00:58, 1.544s/it]
[2025-08-27 05:36:45,720][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00279/00310] [00:07:12/00:00:46, 1.544s/it]
[2025-08-27 05:36:58,147][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00287/00310] [00:07:24/00:00:33, 1.545s/it]
[2025-08-27 05:37:10,154][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00295/00310] [00:07:36/00:00:21, 1.543s/it]
[2025-08-27 05:37:22,758][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 040041] [Batch 00303/00310] [00:07:49/00:00:09, 1.544s/it]
[2025-08-27 05:37:32,481][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=0.85711, valid_loss=1.81278
[2025-08-27 05:37:32,482][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-27 05:37:32,482][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.664
[2025-08-27 05:37:32,482][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.058
[2025-08-27 05:37:32,482][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.060
[2025-08-27 05:37:32,482][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.022
[2025-08-27 05:37:32,497][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 10:10:46, remaining time 13:18:42, 00:46:58 per epoch
[2025-08-27 05:37:40,615][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040048] [Batch 00008/03080] [00:00:05/00:34:16, 0.669s/it]: train_loss_raw=0.8401, running_loss=0.8335, LR=0.000100
[2025-08-27 05:37:46,560][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040056] [Batch 00016/03080] [00:00:11/00:36:03, 0.706s/it]: train_loss_raw=0.9192, running_loss=0.8366, LR=0.000100
[2025-08-27 05:37:52,532][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040064] [Batch 00024/03080] [00:00:17/00:36:39, 0.720s/it]: train_loss_raw=0.8630, running_loss=0.8377, LR=0.000100
[2025-08-27 05:37:58,431][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040072] [Batch 00032/03080] [00:00:23/00:36:47, 0.724s/it]: train_loss_raw=0.8788, running_loss=0.8402, LR=0.000100
[2025-08-27 05:38:04,287][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040080] [Batch 00040/03080] [00:00:29/00:36:46, 0.726s/it]: train_loss_raw=0.7599, running_loss=0.8411, LR=0.000100
[2025-08-27 05:38:10,154][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040088] [Batch 00048/03080] [00:00:34/00:36:44, 0.727s/it]: train_loss_raw=0.8777, running_loss=0.8442, LR=0.000100
[2025-08-27 05:38:16,186][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040096] [Batch 00056/03080] [00:00:40/00:36:49, 0.731s/it]: train_loss_raw=0.7626, running_loss=0.8444, LR=0.000100
[2025-08-27 05:38:22,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040104] [Batch 00064/03080] [00:00:46/00:36:53, 0.734s/it]: train_loss_raw=0.9075, running_loss=0.8463, LR=0.000100
[2025-08-27 05:38:28,141][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040112] [Batch 00072/03080] [00:00:52/00:36:49, 0.734s/it]: train_loss_raw=0.8770, running_loss=0.8494, LR=0.000100
[2025-08-27 05:38:34,064][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040120] [Batch 00080/03080] [00:00:58/00:36:45, 0.735s/it]: train_loss_raw=0.9571, running_loss=0.8503, LR=0.000100
[2025-08-27 05:38:39,989][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040128] [Batch 00088/03080] [00:01:04/00:36:40, 0.736s/it]: train_loss_raw=0.7775, running_loss=0.8516, LR=0.000100
[2025-08-27 05:38:45,935][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040136] [Batch 00096/03080] [00:01:10/00:36:36, 0.736s/it]: train_loss_raw=0.8763, running_loss=0.8507, LR=0.000100
[2025-08-27 05:38:51,904][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040144] [Batch 00104/03080] [00:01:16/00:36:33, 0.737s/it]: train_loss_raw=0.7561, running_loss=0.8505, LR=0.000100
[2025-08-27 05:38:57,855][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040152] [Batch 00112/03080] [00:01:22/00:36:28, 0.737s/it]: train_loss_raw=0.9078, running_loss=0.8532, LR=0.000100
[2025-08-27 05:39:03,952][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040160] [Batch 00120/03080] [00:01:28/00:36:27, 0.739s/it]: train_loss_raw=0.7647, running_loss=0.8532, LR=0.000100
[2025-08-27 05:39:09,907][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040168] [Batch 00128/03080] [00:01:34/00:36:22, 0.739s/it]: train_loss_raw=0.7686, running_loss=0.8537, LR=0.000100
[2025-08-27 05:39:15,803][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040176] [Batch 00136/03080] [00:01:40/00:36:16, 0.739s/it]: train_loss_raw=0.8114, running_loss=0.8529, LR=0.000100
[2025-08-27 05:39:21,994][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040184] [Batch 00144/03080] [00:01:46/00:36:16, 0.741s/it]: train_loss_raw=0.9068, running_loss=0.8557, LR=0.000100
[2025-08-27 05:39:27,874][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040192] [Batch 00152/03080] [00:01:52/00:36:09, 0.741s/it]: train_loss_raw=0.8511, running_loss=0.8587, LR=0.000100
[2025-08-27 05:39:34,025][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040200] [Batch 00160/03080] [00:01:58/00:36:07, 0.742s/it]: train_loss_raw=0.8903, running_loss=0.8562, LR=0.000100
[2025-08-27 05:39:39,867][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040208] [Batch 00168/03080] [00:02:04/00:35:59, 0.742s/it]: train_loss_raw=0.8371, running_loss=0.8557, LR=0.000100
[2025-08-27 05:39:46,054][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040216] [Batch 00176/03080] [00:02:10/00:35:58, 0.743s/it]: train_loss_raw=0.9258, running_loss=0.8562, LR=0.000100
[2025-08-27 05:39:51,970][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040224] [Batch 00184/03080] [00:02:16/00:35:51, 0.743s/it]: train_loss_raw=0.8470, running_loss=0.8552, LR=0.000100
[2025-08-27 05:39:58,063][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040232] [Batch 00192/03080] [00:02:22/00:35:47, 0.744s/it]: train_loss_raw=0.8877, running_loss=0.8539, LR=0.000100
[2025-08-27 05:40:04,141][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040240] [Batch 00200/03080] [00:02:28/00:35:43, 0.744s/it]: train_loss_raw=0.8707, running_loss=0.8535, LR=0.000100
[2025-08-27 05:40:09,883][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040248] [Batch 00208/03080] [00:02:34/00:35:34, 0.743s/it]: train_loss_raw=0.8056, running_loss=0.8516, LR=0.000100
[2025-08-27 05:40:15,717][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040256] [Batch 00216/03080] [00:02:40/00:35:27, 0.743s/it]: train_loss_raw=0.7816, running_loss=0.8493, LR=0.000100
[2025-08-27 05:40:21,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040264] [Batch 00224/03080] [00:02:46/00:35:22, 0.743s/it]: train_loss_raw=0.8510, running_loss=0.8523, LR=0.000100
[2025-08-27 05:40:27,853][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040272] [Batch 00232/03080] [00:02:52/00:35:18, 0.744s/it]: train_loss_raw=0.7262, running_loss=0.8517, LR=0.000100
[2025-08-27 05:40:33,751][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040280] [Batch 00240/03080] [00:02:58/00:35:12, 0.744s/it]: train_loss_raw=0.9054, running_loss=0.8536, LR=0.000100
[2025-08-27 05:40:39,588][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040288] [Batch 00248/03080] [00:03:04/00:35:04, 0.743s/it]: train_loss_raw=0.9274, running_loss=0.8547, LR=0.000100
[2025-08-27 05:40:45,567][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040296] [Batch 00256/03080] [00:03:10/00:34:59, 0.743s/it]: train_loss_raw=0.8669, running_loss=0.8540, LR=0.000100
[2025-08-27 05:40:51,694][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040304] [Batch 00264/03080] [00:03:16/00:34:55, 0.744s/it]: train_loss_raw=0.8826, running_loss=0.8548, LR=0.000100
[2025-08-27 05:40:57,935][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040312] [Batch 00272/03080] [00:03:22/00:34:52, 0.745s/it]: train_loss_raw=0.9201, running_loss=0.8560, LR=0.000100
[2025-08-27 05:41:04,109][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040320] [Batch 00280/03080] [00:03:28/00:34:48, 0.746s/it]: train_loss_raw=0.9984, running_loss=0.8577, LR=0.000100
[2025-08-27 05:41:10,255][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040328] [Batch 00288/03080] [00:03:34/00:34:44, 0.747s/it]: train_loss_raw=0.8361, running_loss=0.8585, LR=0.000100
[2025-08-27 05:41:16,586][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040336] [Batch 00296/03080] [00:03:41/00:34:41, 0.748s/it]: train_loss_raw=0.9405, running_loss=0.8583, LR=0.000100
[2025-08-27 05:41:22,530][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040344] [Batch 00304/03080] [00:03:47/00:34:35, 0.748s/it]: train_loss_raw=0.8233, running_loss=0.8593, LR=0.000100
[2025-08-27 05:41:28,485][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040352] [Batch 00312/03080] [00:03:53/00:34:29, 0.748s/it]: train_loss_raw=0.9456, running_loss=0.8593, LR=0.000100
[2025-08-27 05:41:34,531][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040360] [Batch 00320/03080] [00:03:59/00:34:23, 0.748s/it]: train_loss_raw=0.8379, running_loss=0.8605, LR=0.000100
[2025-08-27 05:41:40,502][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040368] [Batch 00328/03080] [00:04:05/00:34:17, 0.748s/it]: train_loss_raw=0.7629, running_loss=0.8595, LR=0.000100
[2025-08-27 05:41:46,422][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040376] [Batch 00336/03080] [00:04:11/00:34:11, 0.748s/it]: train_loss_raw=0.8429, running_loss=0.8590, LR=0.000100
[2025-08-27 05:41:52,325][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040384] [Batch 00344/03080] [00:04:17/00:34:04, 0.747s/it]: train_loss_raw=0.7969, running_loss=0.8599, LR=0.000100
[2025-08-27 05:41:58,209][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040392] [Batch 00352/03080] [00:04:22/00:33:57, 0.747s/it]: train_loss_raw=0.9035, running_loss=0.8583, LR=0.000100
[2025-08-27 05:42:04,382][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040400] [Batch 00360/03080] [00:04:29/00:33:53, 0.748s/it]: train_loss_raw=0.8023, running_loss=0.8567, LR=0.000100
[2025-08-27 05:42:10,553][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040408] [Batch 00368/03080] [00:04:35/00:33:48, 0.748s/it]: train_loss_raw=0.8851, running_loss=0.8553, LR=0.000100
[2025-08-27 05:42:16,521][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040416] [Batch 00376/03080] [00:04:41/00:33:42, 0.748s/it]: train_loss_raw=0.9107, running_loss=0.8554, LR=0.000100
[2025-08-27 05:42:22,574][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040424] [Batch 00384/03080] [00:04:47/00:33:37, 0.748s/it]: train_loss_raw=0.8489, running_loss=0.8554, LR=0.000100
[2025-08-27 05:42:28,465][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040432] [Batch 00392/03080] [00:04:53/00:33:30, 0.748s/it]: train_loss_raw=0.8600, running_loss=0.8567, LR=0.000100
[2025-08-27 05:42:34,381][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040440] [Batch 00400/03080] [00:04:59/00:33:24, 0.748s/it]: train_loss_raw=0.8208, running_loss=0.8556, LR=0.000100
[2025-08-27 05:42:40,360][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040448] [Batch 00408/03080] [00:05:05/00:33:18, 0.748s/it]: train_loss_raw=0.8464, running_loss=0.8561, LR=0.000100
[2025-08-27 05:42:46,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040456] [Batch 00416/03080] [00:05:10/00:33:11, 0.748s/it]: train_loss_raw=0.8647, running_loss=0.8559, LR=0.000100
[2025-08-27 05:42:52,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040464] [Batch 00424/03080] [00:05:16/00:33:05, 0.748s/it]: train_loss_raw=0.9254, running_loss=0.8529, LR=0.000100
[2025-08-27 05:42:58,054][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040472] [Batch 00432/03080] [00:05:22/00:32:58, 0.747s/it]: train_loss_raw=0.7600, running_loss=0.8517, LR=0.000100
[2025-08-27 05:43:03,850][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040480] [Batch 00440/03080] [00:05:28/00:32:51, 0.747s/it]: train_loss_raw=0.8298, running_loss=0.8508, LR=0.000100
[2025-08-27 05:43:09,766][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040488] [Batch 00448/03080] [00:05:34/00:32:45, 0.747s/it]: train_loss_raw=0.9151, running_loss=0.8515, LR=0.000100
[2025-08-27 05:43:15,713][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040496] [Batch 00456/03080] [00:05:40/00:32:39, 0.747s/it]: train_loss_raw=0.8544, running_loss=0.8527, LR=0.000100
[2025-08-27 05:43:21,623][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040504] [Batch 00464/03080] [00:05:46/00:32:32, 0.746s/it]: train_loss_raw=0.8208, running_loss=0.8521, LR=0.000100
[2025-08-27 05:43:27,586][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040512] [Batch 00472/03080] [00:05:52/00:32:26, 0.746s/it]: train_loss_raw=0.8186, running_loss=0.8504, LR=0.000100
[2025-08-27 05:43:33,430][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040520] [Batch 00480/03080] [00:05:58/00:32:20, 0.746s/it]: train_loss_raw=0.7604, running_loss=0.8501, LR=0.000100
[2025-08-27 05:43:39,266][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040528] [Batch 00488/03080] [00:06:04/00:32:13, 0.746s/it]: train_loss_raw=0.9642, running_loss=0.8508, LR=0.000100
[2025-08-27 05:43:45,136][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040536] [Batch 00496/03080] [00:06:09/00:32:06, 0.746s/it]: train_loss_raw=0.8531, running_loss=0.8497, LR=0.000100
[2025-08-27 05:43:51,084][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040544] [Batch 00504/03080] [00:06:15/00:32:00, 0.746s/it]: train_loss_raw=0.8942, running_loss=0.8497, LR=0.000100
[2025-08-27 05:43:57,027][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040552] [Batch 00512/03080] [00:06:21/00:31:54, 0.746s/it]: train_loss_raw=0.9037, running_loss=0.8493, LR=0.000100
[2025-08-27 05:44:03,017][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040560] [Batch 00520/03080] [00:06:27/00:31:48, 0.746s/it]: train_loss_raw=0.9381, running_loss=0.8474, LR=0.000100
[2025-08-27 05:44:09,002][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040568] [Batch 00528/03080] [00:06:33/00:31:43, 0.746s/it]: train_loss_raw=0.7942, running_loss=0.8499, LR=0.000100
[2025-08-27 05:44:14,916][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040576] [Batch 00536/03080] [00:06:39/00:31:36, 0.746s/it]: train_loss_raw=0.7599, running_loss=0.8479, LR=0.000100
[2025-08-27 05:44:20,866][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040584] [Batch 00544/03080] [00:06:45/00:31:30, 0.746s/it]: train_loss_raw=0.9347, running_loss=0.8470, LR=0.000100
[2025-08-27 05:44:26,806][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040592] [Batch 00552/03080] [00:06:51/00:31:24, 0.746s/it]: train_loss_raw=0.8711, running_loss=0.8489, LR=0.000100
[2025-08-27 05:44:32,697][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040600] [Batch 00560/03080] [00:06:57/00:31:18, 0.745s/it]: train_loss_raw=0.7763, running_loss=0.8492, LR=0.000100
[2025-08-27 05:44:38,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040608] [Batch 00568/03080] [00:07:03/00:31:12, 0.745s/it]: train_loss_raw=0.9128, running_loss=0.8489, LR=0.000100
[2025-08-27 05:44:44,590][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040616] [Batch 00576/03080] [00:07:09/00:31:06, 0.745s/it]: train_loss_raw=0.8397, running_loss=0.8478, LR=0.000100
[2025-08-27 05:44:50,489][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040624] [Batch 00584/03080] [00:07:15/00:31:00, 0.745s/it]: train_loss_raw=0.7259, running_loss=0.8462, LR=0.000100
[2025-08-27 05:44:56,484][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040632] [Batch 00592/03080] [00:07:21/00:30:54, 0.745s/it]: train_loss_raw=0.8490, running_loss=0.8446, LR=0.000100
[2025-08-27 05:45:02,457][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040640] [Batch 00600/03080] [00:07:27/00:30:48, 0.745s/it]: train_loss_raw=0.8655, running_loss=0.8462, LR=0.000100
[2025-08-27 05:45:08,459][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040648] [Batch 00608/03080] [00:07:33/00:30:42, 0.745s/it]: train_loss_raw=0.8811, running_loss=0.8452, LR=0.000100
[2025-08-27 05:45:14,309][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040656] [Batch 00616/03080] [00:07:39/00:30:36, 0.745s/it]: train_loss_raw=0.9242, running_loss=0.8463, LR=0.000100
[2025-08-27 05:45:20,285][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040664] [Batch 00624/03080] [00:07:45/00:30:30, 0.745s/it]: train_loss_raw=0.9705, running_loss=0.8491, LR=0.000100
[2025-08-27 05:45:26,135][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040672] [Batch 00632/03080] [00:07:50/00:30:23, 0.745s/it]: train_loss_raw=0.7742, running_loss=0.8465, LR=0.000100
[2025-08-27 05:45:32,124][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040680] [Batch 00640/03080] [00:07:56/00:30:18, 0.745s/it]: train_loss_raw=0.9039, running_loss=0.8454, LR=0.000100
[2025-08-27 05:45:38,151][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040688] [Batch 00648/03080] [00:08:02/00:30:12, 0.745s/it]: train_loss_raw=0.8420, running_loss=0.8453, LR=0.000100
[2025-08-27 05:45:44,168][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040696] [Batch 00656/03080] [00:08:08/00:30:06, 0.745s/it]: train_loss_raw=0.7775, running_loss=0.8456, LR=0.000100
[2025-08-27 05:45:50,068][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040704] [Batch 00664/03080] [00:08:14/00:30:00, 0.745s/it]: train_loss_raw=0.7540, running_loss=0.8468, LR=0.000100
[2025-08-27 05:45:55,916][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040712] [Batch 00672/03080] [00:08:20/00:29:54, 0.745s/it]: train_loss_raw=0.8390, running_loss=0.8450, LR=0.000100
[2025-08-27 05:46:01,867][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040720] [Batch 00680/03080] [00:08:26/00:29:48, 0.745s/it]: train_loss_raw=0.8428, running_loss=0.8454, LR=0.000100
[2025-08-27 05:46:07,849][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040728] [Batch 00688/03080] [00:08:32/00:29:42, 0.745s/it]: train_loss_raw=0.8386, running_loss=0.8444, LR=0.000100
[2025-08-27 05:46:13,713][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040736] [Batch 00696/03080] [00:08:38/00:29:35, 0.745s/it]: train_loss_raw=0.7802, running_loss=0.8433, LR=0.000100
[2025-08-27 05:46:19,663][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040744] [Batch 00704/03080] [00:08:44/00:29:29, 0.745s/it]: train_loss_raw=0.9186, running_loss=0.8434, LR=0.000100
[2025-08-27 05:46:25,545][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040752] [Batch 00712/03080] [00:08:50/00:29:23, 0.745s/it]: train_loss_raw=0.8146, running_loss=0.8429, LR=0.000100
[2025-08-27 05:46:31,491][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040760] [Batch 00720/03080] [00:08:56/00:29:17, 0.745s/it]: train_loss_raw=0.7681, running_loss=0.8418, LR=0.000100
[2025-08-27 05:46:37,452][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040768] [Batch 00728/03080] [00:09:02/00:29:11, 0.745s/it]: train_loss_raw=0.8535, running_loss=0.8420, LR=0.000100
[2025-08-27 05:46:43,304][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040776] [Batch 00736/03080] [00:09:08/00:29:05, 0.745s/it]: train_loss_raw=0.8296, running_loss=0.8400, LR=0.000100
[2025-08-27 05:46:49,254][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040784] [Batch 00744/03080] [00:09:13/00:28:59, 0.745s/it]: train_loss_raw=0.8559, running_loss=0.8411, LR=0.000100
[2025-08-27 05:46:55,092][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040792] [Batch 00752/03080] [00:09:19/00:28:53, 0.744s/it]: train_loss_raw=0.9176, running_loss=0.8425, LR=0.000100
[2025-08-27 05:47:00,917][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040800] [Batch 00760/03080] [00:09:25/00:28:46, 0.744s/it]: train_loss_raw=0.9347, running_loss=0.8429, LR=0.000100
[2025-08-27 05:47:06,700][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040808] [Batch 00768/03080] [00:09:31/00:28:40, 0.744s/it]: train_loss_raw=0.9263, running_loss=0.8444, LR=0.000100
[2025-08-27 05:47:12,549][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040816] [Batch 00776/03080] [00:09:37/00:28:34, 0.744s/it]: train_loss_raw=0.8915, running_loss=0.8440, LR=0.000100
[2025-08-27 05:47:18,504][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040824] [Batch 00784/03080] [00:09:43/00:28:28, 0.744s/it]: train_loss_raw=0.8485, running_loss=0.8417, LR=0.000100
[2025-08-27 05:47:24,530][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040832] [Batch 00792/03080] [00:09:49/00:28:22, 0.744s/it]: train_loss_raw=0.7200, running_loss=0.8411, LR=0.000100
[2025-08-27 05:47:30,427][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040840] [Batch 00800/03080] [00:09:55/00:28:16, 0.744s/it]: train_loss_raw=0.9126, running_loss=0.8427, LR=0.000100
[2025-08-27 05:47:36,530][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040848] [Batch 00808/03080] [00:10:01/00:28:10, 0.744s/it]: train_loss_raw=0.7477, running_loss=0.8412, LR=0.000100
[2025-08-27 05:47:42,517][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040856] [Batch 00816/03080] [00:10:07/00:28:04, 0.744s/it]: train_loss_raw=0.8286, running_loss=0.8410, LR=0.000100
[2025-08-27 05:47:48,534][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040864] [Batch 00824/03080] [00:10:13/00:27:59, 0.744s/it]: train_loss_raw=0.7758, running_loss=0.8407, LR=0.000100
[2025-08-27 05:47:54,595][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040872] [Batch 00832/03080] [00:10:19/00:27:53, 0.744s/it]: train_loss_raw=0.8965, running_loss=0.8403, LR=0.000100
[2025-08-27 05:48:00,601][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040880] [Batch 00840/03080] [00:10:25/00:27:47, 0.744s/it]: train_loss_raw=0.9242, running_loss=0.8415, LR=0.000100
[2025-08-27 05:48:06,398][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040888] [Batch 00848/03080] [00:10:31/00:27:41, 0.744s/it]: train_loss_raw=0.9094, running_loss=0.8432, LR=0.000100
[2025-08-27 05:48:12,281][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040896] [Batch 00856/03080] [00:10:37/00:27:35, 0.744s/it]: train_loss_raw=0.7608, running_loss=0.8427, LR=0.000100
[2025-08-27 05:48:18,211][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040904] [Batch 00864/03080] [00:10:42/00:27:29, 0.744s/it]: train_loss_raw=0.8105, running_loss=0.8416, LR=0.000100
[2025-08-27 05:48:24,146][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040912] [Batch 00872/03080] [00:10:48/00:27:23, 0.744s/it]: train_loss_raw=0.8886, running_loss=0.8404, LR=0.000100
[2025-08-27 05:48:30,228][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040920] [Batch 00880/03080] [00:10:54/00:27:17, 0.744s/it]: train_loss_raw=0.8635, running_loss=0.8411, LR=0.000100
[2025-08-27 05:48:36,215][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040928] [Batch 00888/03080] [00:11:00/00:27:11, 0.744s/it]: train_loss_raw=0.7715, running_loss=0.8381, LR=0.000100
[2025-08-27 05:48:42,169][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040936] [Batch 00896/03080] [00:11:06/00:27:05, 0.744s/it]: train_loss_raw=0.8156, running_loss=0.8350, LR=0.000100
[2025-08-27 05:48:48,005][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040944] [Batch 00904/03080] [00:11:12/00:26:59, 0.744s/it]: train_loss_raw=0.7872, running_loss=0.8321, LR=0.000100
[2025-08-27 05:48:53,916][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040952] [Batch 00912/03080] [00:11:18/00:26:53, 0.744s/it]: train_loss_raw=0.8921, running_loss=0.8311, LR=0.000100
[2025-08-27 05:48:59,800][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040960] [Batch 00920/03080] [00:11:24/00:26:47, 0.744s/it]: train_loss_raw=0.7716, running_loss=0.8320, LR=0.000100
[2025-08-27 05:49:05,733][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040968] [Batch 00928/03080] [00:11:30/00:26:41, 0.744s/it]: train_loss_raw=0.8701, running_loss=0.8322, LR=0.000100
[2025-08-27 05:49:11,620][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040976] [Batch 00936/03080] [00:11:36/00:26:35, 0.744s/it]: train_loss_raw=0.9183, running_loss=0.8340, LR=0.000100
[2025-08-27 05:49:17,565][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040984] [Batch 00944/03080] [00:11:42/00:26:29, 0.744s/it]: train_loss_raw=0.8775, running_loss=0.8328, LR=0.000100
[2025-08-27 05:49:23,472][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 040992] [Batch 00952/03080] [00:11:48/00:26:23, 0.744s/it]: train_loss_raw=0.8657, running_loss=0.8350, LR=0.000100
[2025-08-27 05:49:29,188][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041000] [Batch 00960/03080] [00:11:53/00:26:16, 0.744s/it]: train_loss_raw=0.7427, running_loss=0.8345, LR=0.000100
[2025-08-27 05:49:35,597][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041008] [Batch 00968/03080] [00:12:00/00:26:11, 0.744s/it]: train_loss_raw=0.9434, running_loss=0.8345, LR=0.000100
[2025-08-27 05:49:41,602][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041016] [Batch 00976/03080] [00:12:06/00:26:05, 0.744s/it]: train_loss_raw=0.8789, running_loss=0.8342, LR=0.000100
[2025-08-27 05:49:47,568][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041024] [Batch 00984/03080] [00:12:12/00:25:59, 0.744s/it]: train_loss_raw=0.8482, running_loss=0.8338, LR=0.000100
[2025-08-27 05:49:53,556][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041032] [Batch 00992/03080] [00:12:18/00:25:53, 0.744s/it]: train_loss_raw=0.8838, running_loss=0.8346, LR=0.000100
[2025-08-27 05:49:59,535][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041040] [Batch 01000/03080] [00:12:24/00:25:48, 0.744s/it]: train_loss_raw=0.7865, running_loss=0.8353, LR=0.000100
[2025-08-27 05:50:05,423][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041048] [Batch 01008/03080] [00:12:30/00:25:42, 0.744s/it]: train_loss_raw=0.8824, running_loss=0.8345, LR=0.000100
[2025-08-27 05:50:11,397][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041056] [Batch 01016/03080] [00:12:36/00:25:36, 0.744s/it]: train_loss_raw=0.8169, running_loss=0.8350, LR=0.000100
[2025-08-27 05:50:17,463][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041064] [Batch 01024/03080] [00:12:42/00:25:30, 0.744s/it]: train_loss_raw=0.7267, running_loss=0.8314, LR=0.000100
[2025-08-27 05:50:23,370][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041072] [Batch 01032/03080] [00:12:48/00:25:24, 0.744s/it]: train_loss_raw=0.8627, running_loss=0.8336, LR=0.000100
[2025-08-27 05:50:29,191][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041080] [Batch 01040/03080] [00:12:53/00:25:18, 0.744s/it]: train_loss_raw=0.8250, running_loss=0.8344, LR=0.000100
[2025-08-27 05:50:35,049][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041088] [Batch 01048/03080] [00:12:59/00:25:11, 0.744s/it]: train_loss_raw=0.7386, running_loss=0.8334, LR=0.000100
[2025-08-27 05:50:40,997][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041096] [Batch 01056/03080] [00:13:05/00:25:05, 0.744s/it]: train_loss_raw=0.7722, running_loss=0.8339, LR=0.000100
[2025-08-27 05:50:46,864][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041104] [Batch 01064/03080] [00:13:11/00:24:59, 0.744s/it]: train_loss_raw=0.9214, running_loss=0.8343, LR=0.000100
[2025-08-27 05:50:52,888][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041112] [Batch 01072/03080] [00:13:17/00:24:54, 0.744s/it]: train_loss_raw=0.8664, running_loss=0.8342, LR=0.000100
[2025-08-27 05:50:58,798][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041120] [Batch 01080/03080] [00:13:23/00:24:48, 0.744s/it]: train_loss_raw=0.7645, running_loss=0.8336, LR=0.000100
[2025-08-27 05:51:04,771][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041128] [Batch 01088/03080] [00:13:29/00:24:42, 0.744s/it]: train_loss_raw=0.7843, running_loss=0.8310, LR=0.000100
[2025-08-27 05:51:10,819][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041136] [Batch 01096/03080] [00:13:35/00:24:36, 0.744s/it]: train_loss_raw=0.8259, running_loss=0.8295, LR=0.000100
[2025-08-27 05:51:16,884][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041144] [Batch 01104/03080] [00:13:41/00:24:30, 0.744s/it]: train_loss_raw=0.8219, running_loss=0.8302, LR=0.000100
[2025-08-27 05:51:22,957][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041152] [Batch 01112/03080] [00:13:47/00:24:24, 0.744s/it]: train_loss_raw=0.8576, running_loss=0.8293, LR=0.000100
[2025-08-27 05:51:28,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041160] [Batch 01120/03080] [00:13:53/00:24:18, 0.744s/it]: train_loss_raw=0.7797, running_loss=0.8278, LR=0.000100
[2025-08-27 05:51:34,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041168] [Batch 01128/03080] [00:13:59/00:24:12, 0.744s/it]: train_loss_raw=0.8344, running_loss=0.8259, LR=0.000100
[2025-08-27 05:51:40,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041176] [Batch 01136/03080] [00:14:05/00:24:07, 0.744s/it]: train_loss_raw=0.8676, running_loss=0.8281, LR=0.000100
[2025-08-27 05:51:47,009][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041184] [Batch 01144/03080] [00:14:11/00:24:01, 0.745s/it]: train_loss_raw=0.7857, running_loss=0.8250, LR=0.000100
[2025-08-27 05:51:53,079][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041192] [Batch 01152/03080] [00:14:17/00:23:55, 0.745s/it]: train_loss_raw=0.8254, running_loss=0.8240, LR=0.000100
[2025-08-27 05:51:58,856][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041200] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=0.7695, running_loss=0.8236, LR=0.000100
[2025-08-27 05:52:04,783][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041208] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=0.7889, running_loss=0.8204, LR=0.000100
[2025-08-27 05:52:10,868][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041216] [Batch 01176/03080] [00:14:35/00:23:37, 0.745s/it]: train_loss_raw=0.8720, running_loss=0.8189, LR=0.000100
[2025-08-27 05:52:17,131][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041224] [Batch 01184/03080] [00:14:41/00:23:32, 0.745s/it]: train_loss_raw=0.8347, running_loss=0.8247, LR=0.000100
[2025-08-27 05:52:23,300][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041232] [Batch 01192/03080] [00:14:48/00:23:26, 0.745s/it]: train_loss_raw=0.8149, running_loss=0.8265, LR=0.000100
[2025-08-27 05:52:29,100][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041240] [Batch 01200/03080] [00:14:53/00:23:20, 0.745s/it]: train_loss_raw=0.8129, running_loss=0.8227, LR=0.000100
[2025-08-27 05:52:34,986][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041248] [Batch 01208/03080] [00:14:59/00:23:14, 0.745s/it]: train_loss_raw=0.8691, running_loss=0.8220, LR=0.000100
[2025-08-27 05:52:41,067][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041256] [Batch 01216/03080] [00:15:05/00:23:08, 0.745s/it]: train_loss_raw=0.8504, running_loss=0.8216, LR=0.000100
[2025-08-27 05:52:47,145][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041264] [Batch 01224/03080] [00:15:11/00:23:02, 0.745s/it]: train_loss_raw=0.8027, running_loss=0.8214, LR=0.000100
[2025-08-27 05:52:53,241][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041272] [Batch 01232/03080] [00:15:17/00:22:56, 0.745s/it]: train_loss_raw=0.7157, running_loss=0.8226, LR=0.000100
[2025-08-27 05:52:59,571][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041280] [Batch 01240/03080] [00:15:24/00:22:51, 0.745s/it]: train_loss_raw=0.8246, running_loss=0.8227, LR=0.000100
[2025-08-27 05:53:05,673][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041288] [Batch 01248/03080] [00:15:30/00:22:45, 0.746s/it]: train_loss_raw=0.9351, running_loss=0.8237, LR=0.000100
[2025-08-27 05:53:11,589][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041296] [Batch 01256/03080] [00:15:36/00:22:39, 0.745s/it]: train_loss_raw=0.8006, running_loss=0.8258, LR=0.000100
[2025-08-27 05:53:17,645][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041304] [Batch 01264/03080] [00:15:42/00:22:33, 0.746s/it]: train_loss_raw=0.9430, running_loss=0.8285, LR=0.000100
[2025-08-27 05:53:23,750][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041312] [Batch 01272/03080] [00:15:48/00:22:28, 0.746s/it]: train_loss_raw=0.8413, running_loss=0.8272, LR=0.000100
[2025-08-27 05:53:29,756][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041320] [Batch 01280/03080] [00:15:54/00:22:22, 0.746s/it]: train_loss_raw=0.9100, running_loss=0.8258, LR=0.000100
[2025-08-27 05:53:35,738][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041328] [Batch 01288/03080] [00:16:00/00:22:16, 0.746s/it]: train_loss_raw=0.8601, running_loss=0.8268, LR=0.000100
[2025-08-27 05:53:41,622][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041336] [Batch 01296/03080] [00:16:06/00:22:10, 0.746s/it]: train_loss_raw=0.7188, running_loss=0.8266, LR=0.000100
[2025-08-27 05:53:47,541][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041344] [Batch 01304/03080] [00:16:12/00:22:04, 0.746s/it]: train_loss_raw=0.8765, running_loss=0.8263, LR=0.000100
[2025-08-27 05:53:53,537][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041352] [Batch 01312/03080] [00:16:18/00:21:58, 0.746s/it]: train_loss_raw=0.7765, running_loss=0.8258, LR=0.000100
[2025-08-27 05:53:59,552][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041360] [Batch 01320/03080] [00:16:24/00:21:52, 0.746s/it]: train_loss_raw=0.7301, running_loss=0.8244, LR=0.000100
[2025-08-27 05:54:05,526][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041368] [Batch 01328/03080] [00:16:30/00:21:46, 0.746s/it]: train_loss_raw=0.8457, running_loss=0.8224, LR=0.000100
[2025-08-27 05:54:11,439][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041376] [Batch 01336/03080] [00:16:36/00:21:40, 0.746s/it]: train_loss_raw=0.8738, running_loss=0.8258, LR=0.000100
[2025-08-27 05:54:17,422][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041384] [Batch 01344/03080] [00:16:42/00:21:34, 0.746s/it]: train_loss_raw=0.7730, running_loss=0.8243, LR=0.000100
[2025-08-27 05:54:23,426][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041392] [Batch 01352/03080] [00:16:48/00:21:28, 0.746s/it]: train_loss_raw=0.7548, running_loss=0.8233, LR=0.000100
[2025-08-27 05:54:29,562][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041400] [Batch 01360/03080] [00:16:54/00:21:22, 0.746s/it]: train_loss_raw=0.8088, running_loss=0.8229, LR=0.000100
[2025-08-27 05:54:35,740][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041408] [Batch 01368/03080] [00:17:00/00:21:17, 0.746s/it]: train_loss_raw=0.8590, running_loss=0.8214, LR=0.000100
[2025-08-27 05:54:41,998][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041416] [Batch 01376/03080] [00:17:06/00:21:11, 0.746s/it]: train_loss_raw=0.8388, running_loss=0.8202, LR=0.000100
[2025-08-27 05:54:48,152][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041424] [Batch 01384/03080] [00:17:12/00:21:05, 0.746s/it]: train_loss_raw=0.8091, running_loss=0.8205, LR=0.000100
[2025-08-27 05:54:54,247][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041432] [Batch 01392/03080] [00:17:18/00:20:59, 0.746s/it]: train_loss_raw=0.8983, running_loss=0.8213, LR=0.000100
[2025-08-27 05:55:00,160][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041440] [Batch 01400/03080] [00:17:24/00:20:53, 0.746s/it]: train_loss_raw=0.8145, running_loss=0.8220, LR=0.000100
[2025-08-27 05:55:06,030][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041448] [Batch 01408/03080] [00:17:30/00:20:47, 0.746s/it]: train_loss_raw=0.8613, running_loss=0.8242, LR=0.000100
[2025-08-27 05:55:12,129][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041456] [Batch 01416/03080] [00:17:36/00:20:41, 0.746s/it]: train_loss_raw=0.8653, running_loss=0.8228, LR=0.000100
[2025-08-27 05:55:18,127][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041464] [Batch 01424/03080] [00:17:42/00:20:36, 0.746s/it]: train_loss_raw=0.7883, running_loss=0.8211, LR=0.000100
[2025-08-27 05:55:24,107][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041472] [Batch 01432/03080] [00:17:48/00:20:30, 0.746s/it]: train_loss_raw=0.8809, running_loss=0.8227, LR=0.000100
[2025-08-27 05:55:30,242][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041480] [Batch 01440/03080] [00:17:54/00:20:24, 0.747s/it]: train_loss_raw=0.7700, running_loss=0.8249, LR=0.000100
[2025-08-27 05:55:36,214][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041488] [Batch 01448/03080] [00:18:00/00:20:18, 0.747s/it]: train_loss_raw=0.7531, running_loss=0.8212, LR=0.000100
[2025-08-27 05:55:42,124][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041496] [Batch 01456/03080] [00:18:06/00:20:12, 0.746s/it]: train_loss_raw=0.8533, running_loss=0.8204, LR=0.000100
[2025-08-27 05:55:48,039][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041504] [Batch 01464/03080] [00:18:12/00:20:06, 0.746s/it]: train_loss_raw=0.7196, running_loss=0.8203, LR=0.000100
[2025-08-27 05:55:54,182][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041512] [Batch 01472/03080] [00:18:18/00:20:00, 0.747s/it]: train_loss_raw=0.8968, running_loss=0.8199, LR=0.000100
[2025-08-27 05:56:00,091][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041520] [Batch 01480/03080] [00:18:24/00:19:54, 0.747s/it]: train_loss_raw=0.8697, running_loss=0.8210, LR=0.000100
[2025-08-27 05:56:05,995][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041528] [Batch 01488/03080] [00:18:30/00:19:48, 0.746s/it]: train_loss_raw=0.8507, running_loss=0.8207, LR=0.000100
[2025-08-27 05:56:11,872][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041536] [Batch 01496/03080] [00:18:36/00:19:42, 0.746s/it]: train_loss_raw=0.8501, running_loss=0.8186, LR=0.000100
[2025-08-27 05:56:17,816][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041544] [Batch 01504/03080] [00:18:42/00:19:36, 0.746s/it]: train_loss_raw=0.8888, running_loss=0.8203, LR=0.000100
[2025-08-27 05:56:23,786][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041552] [Batch 01512/03080] [00:18:48/00:19:30, 0.746s/it]: train_loss_raw=0.8840, running_loss=0.8207, LR=0.000100
[2025-08-27 05:56:29,743][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041560] [Batch 01520/03080] [00:18:54/00:19:24, 0.746s/it]: train_loss_raw=0.8556, running_loss=0.8224, LR=0.000100
[2025-08-27 05:56:35,671][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041568] [Batch 01528/03080] [00:19:00/00:19:18, 0.746s/it]: train_loss_raw=0.8121, running_loss=0.8224, LR=0.000100
[2025-08-27 05:56:41,518][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041576] [Batch 01536/03080] [00:19:06/00:19:12, 0.746s/it]: train_loss_raw=0.8267, running_loss=0.8218, LR=0.000100
[2025-08-27 05:56:47,846][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041584] [Batch 01544/03080] [00:19:12/00:19:06, 0.746s/it]: train_loss_raw=0.7137, running_loss=0.8221, LR=0.000100
[2025-08-27 05:56:53,905][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041592] [Batch 01552/03080] [00:19:18/00:19:00, 0.747s/it]: train_loss_raw=0.7980, running_loss=0.8177, LR=0.000100
[2025-08-27 05:56:59,745][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041600] [Batch 01560/03080] [00:19:24/00:18:54, 0.746s/it]: train_loss_raw=0.8216, running_loss=0.8178, LR=0.000100
[2025-08-27 05:57:05,884][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041608] [Batch 01568/03080] [00:19:30/00:18:48, 0.747s/it]: train_loss_raw=0.7641, running_loss=0.8158, LR=0.000100
[2025-08-27 05:57:11,938][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041616] [Batch 01576/03080] [00:19:36/00:18:42, 0.747s/it]: train_loss_raw=0.7653, running_loss=0.8130, LR=0.000100
[2025-08-27 05:57:18,055][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041624] [Batch 01584/03080] [00:19:42/00:18:37, 0.747s/it]: train_loss_raw=0.8449, running_loss=0.8148, LR=0.000100
[2025-08-27 05:57:24,141][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041632] [Batch 01592/03080] [00:19:48/00:18:31, 0.747s/it]: train_loss_raw=0.8592, running_loss=0.8166, LR=0.000100
[2025-08-27 05:57:30,232][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041640] [Batch 01600/03080] [00:19:54/00:18:25, 0.747s/it]: train_loss_raw=0.7783, running_loss=0.8167, LR=0.000100
[2025-08-27 05:57:36,239][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041648] [Batch 01608/03080] [00:20:00/00:18:19, 0.747s/it]: train_loss_raw=0.8054, running_loss=0.8150, LR=0.000100
[2025-08-27 05:57:42,286][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041656] [Batch 01616/03080] [00:20:07/00:18:13, 0.747s/it]: train_loss_raw=0.8231, running_loss=0.8138, LR=0.000100
[2025-08-27 05:57:48,444][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041664] [Batch 01624/03080] [00:20:13/00:18:07, 0.747s/it]: train_loss_raw=0.7805, running_loss=0.8128, LR=0.000100
[2025-08-27 05:57:54,509][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041672] [Batch 01632/03080] [00:20:19/00:18:01, 0.747s/it]: train_loss_raw=0.8962, running_loss=0.8158, LR=0.000100
[2025-08-27 05:58:00,590][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041680] [Batch 01640/03080] [00:20:25/00:17:55, 0.747s/it]: train_loss_raw=0.8012, running_loss=0.8181, LR=0.000100
[2025-08-27 05:58:06,366][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041688] [Batch 01648/03080] [00:20:31/00:17:49, 0.747s/it]: train_loss_raw=0.8579, running_loss=0.8212, LR=0.000100
[2025-08-27 05:58:12,178][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041696] [Batch 01656/03080] [00:20:36/00:17:43, 0.747s/it]: train_loss_raw=0.8742, running_loss=0.8224, LR=0.000100
[2025-08-27 05:58:17,917][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041704] [Batch 01664/03080] [00:20:42/00:17:37, 0.747s/it]: train_loss_raw=0.7858, running_loss=0.8180, LR=0.000100
[2025-08-27 05:58:23,796][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041712] [Batch 01672/03080] [00:20:48/00:17:31, 0.747s/it]: train_loss_raw=0.7658, running_loss=0.8177, LR=0.000100
[2025-08-27 05:58:29,732][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041720] [Batch 01680/03080] [00:20:54/00:17:25, 0.747s/it]: train_loss_raw=0.8155, running_loss=0.8202, LR=0.000100
[2025-08-27 05:58:35,764][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041728] [Batch 01688/03080] [00:21:00/00:17:19, 0.747s/it]: train_loss_raw=0.8017, running_loss=0.8183, LR=0.000100
[2025-08-27 05:58:41,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041736] [Batch 01696/03080] [00:21:06/00:17:13, 0.747s/it]: train_loss_raw=0.8728, running_loss=0.8199, LR=0.000100
[2025-08-27 05:58:47,535][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041744] [Batch 01704/03080] [00:21:12/00:17:07, 0.747s/it]: train_loss_raw=0.8486, running_loss=0.8194, LR=0.000100
[2025-08-27 05:58:53,571][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041752] [Batch 01712/03080] [00:21:18/00:17:01, 0.747s/it]: train_loss_raw=0.9079, running_loss=0.8212, LR=0.000100
[2025-08-27 05:58:59,537][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041760] [Batch 01720/03080] [00:21:24/00:16:55, 0.747s/it]: train_loss_raw=0.8166, running_loss=0.8249, LR=0.000100
[2025-08-27 05:59:05,560][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041768] [Batch 01728/03080] [00:21:30/00:16:49, 0.747s/it]: train_loss_raw=0.8559, running_loss=0.8231, LR=0.000100
[2025-08-27 05:59:11,539][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041776] [Batch 01736/03080] [00:21:36/00:16:43, 0.747s/it]: train_loss_raw=0.7517, running_loss=0.8230, LR=0.000100
[2025-08-27 05:59:17,626][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041784] [Batch 01744/03080] [00:21:42/00:16:37, 0.747s/it]: train_loss_raw=0.9484, running_loss=0.8272, LR=0.000100
[2025-08-27 05:59:23,557][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041792] [Batch 01752/03080] [00:21:48/00:16:31, 0.747s/it]: train_loss_raw=0.8208, running_loss=0.8291, LR=0.000100
[2025-08-27 05:59:29,399][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041800] [Batch 01760/03080] [00:21:54/00:16:25, 0.747s/it]: train_loss_raw=0.7849, running_loss=0.8273, LR=0.000100
[2025-08-27 05:59:35,539][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041808] [Batch 01768/03080] [00:22:00/00:16:19, 0.747s/it]: train_loss_raw=0.8431, running_loss=0.8254, LR=0.000100
[2025-08-27 05:59:41,722][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041816] [Batch 01776/03080] [00:22:06/00:16:13, 0.747s/it]: train_loss_raw=0.8071, running_loss=0.8228, LR=0.000100
[2025-08-27 05:59:47,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041824] [Batch 01784/03080] [00:22:12/00:16:07, 0.747s/it]: train_loss_raw=0.7205, running_loss=0.8209, LR=0.000100
[2025-08-27 05:59:53,420][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041832] [Batch 01792/03080] [00:22:18/00:16:01, 0.747s/it]: train_loss_raw=0.9033, running_loss=0.8224, LR=0.000100
[2025-08-27 05:59:59,362][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041840] [Batch 01800/03080] [00:22:24/00:15:55, 0.747s/it]: train_loss_raw=0.8927, running_loss=0.8207, LR=0.000100
[2025-08-27 06:00:05,573][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041848] [Batch 01808/03080] [00:22:30/00:15:49, 0.747s/it]: train_loss_raw=0.7406, running_loss=0.8180, LR=0.000100
[2025-08-27 06:00:11,395][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041856] [Batch 01816/03080] [00:22:36/00:15:43, 0.747s/it]: train_loss_raw=0.9395, running_loss=0.8181, LR=0.000100
[2025-08-27 06:00:17,193][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041864] [Batch 01824/03080] [00:22:41/00:15:37, 0.747s/it]: train_loss_raw=0.8901, running_loss=0.8146, LR=0.000100
[2025-08-27 06:00:23,205][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041872] [Batch 01832/03080] [00:22:47/00:15:31, 0.747s/it]: train_loss_raw=0.7717, running_loss=0.8108, LR=0.000100
[2025-08-27 06:00:29,107][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041880] [Batch 01840/03080] [00:22:53/00:15:25, 0.747s/it]: train_loss_raw=0.7942, running_loss=0.8110, LR=0.000100
[2025-08-27 06:00:34,917][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041888] [Batch 01848/03080] [00:22:59/00:15:19, 0.747s/it]: train_loss_raw=0.8254, running_loss=0.8096, LR=0.000100
[2025-08-27 06:00:40,794][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041896] [Batch 01856/03080] [00:23:05/00:15:13, 0.747s/it]: train_loss_raw=0.8697, running_loss=0.8107, LR=0.000100
[2025-08-27 06:00:46,891][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041904] [Batch 01864/03080] [00:23:11/00:15:07, 0.747s/it]: train_loss_raw=0.7494, running_loss=0.8106, LR=0.000100
[2025-08-27 06:00:53,016][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041912] [Batch 01872/03080] [00:23:17/00:15:01, 0.747s/it]: train_loss_raw=0.8875, running_loss=0.8097, LR=0.000100
[2025-08-27 06:00:59,018][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041920] [Batch 01880/03080] [00:23:23/00:14:56, 0.747s/it]: train_loss_raw=0.7687, running_loss=0.8093, LR=0.000100
[2025-08-27 06:01:05,001][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041928] [Batch 01888/03080] [00:23:29/00:14:50, 0.747s/it]: train_loss_raw=0.8035, running_loss=0.8090, LR=0.000100
[2025-08-27 06:01:10,898][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041936] [Batch 01896/03080] [00:23:35/00:14:44, 0.747s/it]: train_loss_raw=0.7721, running_loss=0.8081, LR=0.000100
[2025-08-27 06:01:16,877][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041944] [Batch 01904/03080] [00:23:41/00:14:38, 0.747s/it]: train_loss_raw=0.8027, running_loss=0.8084, LR=0.000100
[2025-08-27 06:01:22,834][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041952] [Batch 01912/03080] [00:23:47/00:14:32, 0.747s/it]: train_loss_raw=0.7811, running_loss=0.8085, LR=0.000100
[2025-08-27 06:01:28,710][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041960] [Batch 01920/03080] [00:23:53/00:14:26, 0.747s/it]: train_loss_raw=0.7413, running_loss=0.8085, LR=0.000100
[2025-08-27 06:01:34,803][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041968] [Batch 01928/03080] [00:23:59/00:14:20, 0.747s/it]: train_loss_raw=0.7967, running_loss=0.8086, LR=0.000100
[2025-08-27 06:01:40,730][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041976] [Batch 01936/03080] [00:24:05/00:14:14, 0.747s/it]: train_loss_raw=0.7317, running_loss=0.8070, LR=0.000100
[2025-08-27 06:01:46,556][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041984] [Batch 01944/03080] [00:24:11/00:14:08, 0.747s/it]: train_loss_raw=0.8894, running_loss=0.8090, LR=0.000100
[2025-08-27 06:01:52,602][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 041992] [Batch 01952/03080] [00:24:17/00:14:02, 0.747s/it]: train_loss_raw=0.8210, running_loss=0.8103, LR=0.000100
[2025-08-27 06:01:58,554][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042000] [Batch 01960/03080] [00:24:23/00:13:56, 0.747s/it]: train_loss_raw=0.7954, running_loss=0.8106, LR=0.000100
[2025-08-27 06:02:08,544][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042008] [Batch 01968/03080] [00:24:33/00:13:52, 0.749s/it]: train_loss_raw=0.8612, running_loss=0.8099, LR=0.000100
[2025-08-27 06:02:14,453][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042016] [Batch 01976/03080] [00:24:39/00:13:46, 0.749s/it]: train_loss_raw=0.7498, running_loss=0.8116, LR=0.000100
[2025-08-27 06:02:20,317][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042024] [Batch 01984/03080] [00:24:45/00:13:40, 0.749s/it]: train_loss_raw=0.7743, running_loss=0.8129, LR=0.000100
[2025-08-27 06:02:26,275][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042032] [Batch 01992/03080] [00:24:51/00:13:34, 0.749s/it]: train_loss_raw=0.8190, running_loss=0.8123, LR=0.000100
[2025-08-27 06:02:32,185][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042040] [Batch 02000/03080] [00:24:56/00:13:28, 0.748s/it]: train_loss_raw=0.8421, running_loss=0.8108, LR=0.000100
[2025-08-27 06:02:38,054][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042048] [Batch 02008/03080] [00:25:02/00:13:22, 0.748s/it]: train_loss_raw=0.7816, running_loss=0.8104, LR=0.000100
[2025-08-27 06:02:43,816][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042056] [Batch 02016/03080] [00:25:08/00:13:16, 0.748s/it]: train_loss_raw=0.7320, running_loss=0.8101, LR=0.000100
[2025-08-27 06:02:49,803][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042064] [Batch 02024/03080] [00:25:14/00:13:10, 0.748s/it]: train_loss_raw=0.6572, running_loss=0.8079, LR=0.000100
[2025-08-27 06:02:55,813][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042072] [Batch 02032/03080] [00:25:20/00:13:04, 0.748s/it]: train_loss_raw=0.8337, running_loss=0.8084, LR=0.000100
[2025-08-27 06:03:01,747][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042080] [Batch 02040/03080] [00:25:26/00:12:58, 0.748s/it]: train_loss_raw=0.7373, running_loss=0.8057, LR=0.000100
[2025-08-27 06:03:07,835][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042088] [Batch 02048/03080] [00:25:32/00:12:52, 0.748s/it]: train_loss_raw=0.8325, running_loss=0.8066, LR=0.000100
[2025-08-27 06:03:13,718][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042096] [Batch 02056/03080] [00:25:38/00:12:46, 0.748s/it]: train_loss_raw=0.8535, running_loss=0.8060, LR=0.000100
[2025-08-27 06:03:19,624][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042104] [Batch 02064/03080] [00:25:44/00:12:40, 0.748s/it]: train_loss_raw=0.7799, running_loss=0.8064, LR=0.000100
[2025-08-27 06:03:25,702][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042112] [Batch 02072/03080] [00:25:50/00:12:34, 0.748s/it]: train_loss_raw=0.7199, running_loss=0.8074, LR=0.000100
[2025-08-27 06:03:31,703][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042120] [Batch 02080/03080] [00:25:56/00:12:28, 0.748s/it]: train_loss_raw=0.8372, running_loss=0.8089, LR=0.000100
[2025-08-27 06:03:37,564][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042128] [Batch 02088/03080] [00:26:02/00:12:22, 0.748s/it]: train_loss_raw=0.8573, running_loss=0.8109, LR=0.000100
[2025-08-27 06:03:43,322][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042136] [Batch 02096/03080] [00:26:08/00:12:16, 0.748s/it]: train_loss_raw=0.7731, running_loss=0.8094, LR=0.000100
[2025-08-27 06:03:49,185][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042144] [Batch 02104/03080] [00:26:13/00:12:10, 0.748s/it]: train_loss_raw=0.8300, running_loss=0.8073, LR=0.000100
[2025-08-27 06:03:55,059][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042152] [Batch 02112/03080] [00:26:19/00:12:04, 0.748s/it]: train_loss_raw=0.8056, running_loss=0.8065, LR=0.000100
[2025-08-27 06:04:01,117][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042160] [Batch 02120/03080] [00:26:25/00:11:58, 0.748s/it]: train_loss_raw=0.8027, running_loss=0.8064, LR=0.000100
[2025-08-27 06:04:07,225][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042168] [Batch 02128/03080] [00:26:31/00:11:52, 0.748s/it]: train_loss_raw=0.7511, running_loss=0.8085, LR=0.000100
[2025-08-27 06:04:13,411][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042176] [Batch 02136/03080] [00:26:38/00:11:46, 0.748s/it]: train_loss_raw=0.7840, running_loss=0.8087, LR=0.000100
[2025-08-27 06:04:19,393][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042184] [Batch 02144/03080] [00:26:44/00:11:40, 0.748s/it]: train_loss_raw=0.7536, running_loss=0.8066, LR=0.000100
[2025-08-27 06:04:25,270][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042192] [Batch 02152/03080] [00:26:50/00:11:34, 0.748s/it]: train_loss_raw=0.7797, running_loss=0.8074, LR=0.000100
[2025-08-27 06:04:31,160][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042200] [Batch 02160/03080] [00:26:55/00:11:28, 0.748s/it]: train_loss_raw=0.8087, running_loss=0.8057, LR=0.000100
[2025-08-27 06:04:36,907][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042208] [Batch 02168/03080] [00:27:01/00:11:22, 0.748s/it]: train_loss_raw=0.8144, running_loss=0.8066, LR=0.000100
[2025-08-27 06:04:42,759][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042216] [Batch 02176/03080] [00:27:07/00:11:16, 0.748s/it]: train_loss_raw=0.8271, running_loss=0.8053, LR=0.000100
[2025-08-27 06:04:48,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042224] [Batch 02184/03080] [00:27:13/00:11:10, 0.748s/it]: train_loss_raw=0.7459, running_loss=0.8049, LR=0.000100
[2025-08-27 06:04:54,432][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042232] [Batch 02192/03080] [00:27:19/00:11:04, 0.748s/it]: train_loss_raw=0.8132, running_loss=0.8064, LR=0.000100
[2025-08-27 06:05:00,373][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042240] [Batch 02200/03080] [00:27:25/00:10:58, 0.748s/it]: train_loss_raw=0.8431, running_loss=0.8062, LR=0.000100
[2025-08-27 06:05:06,420][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042248] [Batch 02208/03080] [00:27:31/00:10:52, 0.748s/it]: train_loss_raw=0.7645, running_loss=0.8062, LR=0.000100
[2025-08-27 06:05:12,467][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042256] [Batch 02216/03080] [00:27:37/00:10:46, 0.748s/it]: train_loss_raw=0.8424, running_loss=0.8073, LR=0.000100
[2025-08-27 06:05:18,630][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042264] [Batch 02224/03080] [00:27:43/00:10:40, 0.748s/it]: train_loss_raw=0.7853, running_loss=0.8097, LR=0.000100
[2025-08-27 06:05:24,596][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042272] [Batch 02232/03080] [00:27:49/00:10:34, 0.748s/it]: train_loss_raw=0.8294, running_loss=0.8102, LR=0.000100
[2025-08-27 06:05:30,418][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042280] [Batch 02240/03080] [00:27:55/00:10:28, 0.748s/it]: train_loss_raw=0.8347, running_loss=0.8127, LR=0.000100
[2025-08-27 06:05:36,323][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042288] [Batch 02248/03080] [00:28:01/00:10:22, 0.748s/it]: train_loss_raw=0.7689, running_loss=0.8153, LR=0.000100
[2025-08-27 06:05:42,176][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042296] [Batch 02256/03080] [00:28:06/00:10:16, 0.748s/it]: train_loss_raw=0.8402, running_loss=0.8142, LR=0.000100
[2025-08-27 06:05:48,105][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042304] [Batch 02264/03080] [00:28:12/00:10:10, 0.748s/it]: train_loss_raw=0.8433, running_loss=0.8111, LR=0.000100
[2025-08-27 06:05:53,974][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042312] [Batch 02272/03080] [00:28:18/00:10:04, 0.748s/it]: train_loss_raw=0.8121, running_loss=0.8102, LR=0.000100
[2025-08-27 06:06:00,041][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042320] [Batch 02280/03080] [00:28:24/00:09:58, 0.748s/it]: train_loss_raw=0.8373, running_loss=0.8121, LR=0.000100
[2025-08-27 06:06:05,845][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042328] [Batch 02288/03080] [00:28:30/00:09:52, 0.748s/it]: train_loss_raw=0.7546, running_loss=0.8076, LR=0.000100
[2025-08-27 06:06:11,608][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042336] [Batch 02296/03080] [00:28:36/00:09:46, 0.748s/it]: train_loss_raw=0.7990, running_loss=0.8088, LR=0.000100
[2025-08-27 06:06:17,404][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042344] [Batch 02304/03080] [00:28:42/00:09:40, 0.747s/it]: train_loss_raw=0.8157, running_loss=0.8072, LR=0.000100
[2025-08-27 06:06:23,409][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042352] [Batch 02312/03080] [00:28:48/00:09:34, 0.747s/it]: train_loss_raw=0.7673, running_loss=0.8050, LR=0.000100
[2025-08-27 06:06:29,182][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042360] [Batch 02320/03080] [00:28:53/00:09:28, 0.747s/it]: train_loss_raw=0.7757, running_loss=0.8082, LR=0.000100
[2025-08-27 06:06:35,175][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042368] [Batch 02328/03080] [00:28:59/00:09:22, 0.747s/it]: train_loss_raw=0.8081, running_loss=0.8091, LR=0.000100
[2025-08-27 06:06:41,048][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042376] [Batch 02336/03080] [00:29:05/00:09:16, 0.747s/it]: train_loss_raw=0.7557, running_loss=0.8077, LR=0.000100
[2025-08-27 06:06:46,761][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042384] [Batch 02344/03080] [00:29:11/00:09:09, 0.747s/it]: train_loss_raw=0.8323, running_loss=0.8085, LR=0.000100
[2025-08-27 06:06:52,605][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042392] [Batch 02352/03080] [00:29:17/00:09:03, 0.747s/it]: train_loss_raw=0.8015, running_loss=0.8065, LR=0.000100
[2025-08-27 06:06:58,790][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042400] [Batch 02360/03080] [00:29:23/00:08:58, 0.747s/it]: train_loss_raw=0.8373, running_loss=0.8068, LR=0.000100
[2025-08-27 06:07:04,589][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042408] [Batch 02368/03080] [00:29:29/00:08:51, 0.747s/it]: train_loss_raw=0.8047, running_loss=0.8052, LR=0.000100
[2025-08-27 06:07:10,331][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042416] [Batch 02376/03080] [00:29:35/00:08:45, 0.747s/it]: train_loss_raw=0.7710, running_loss=0.8047, LR=0.000100
[2025-08-27 06:07:16,212][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042424] [Batch 02384/03080] [00:29:40/00:08:39, 0.747s/it]: train_loss_raw=0.8339, running_loss=0.8038, LR=0.000100
[2025-08-27 06:07:22,422][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042432] [Batch 02392/03080] [00:29:47/00:08:34, 0.747s/it]: train_loss_raw=0.7470, running_loss=0.8045, LR=0.000100
[2025-08-27 06:07:28,365][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042440] [Batch 02400/03080] [00:29:53/00:08:28, 0.747s/it]: train_loss_raw=0.6636, running_loss=0.8027, LR=0.000100
[2025-08-27 06:07:34,232][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042448] [Batch 02408/03080] [00:29:58/00:08:22, 0.747s/it]: train_loss_raw=0.7038, running_loss=0.8012, LR=0.000100
[2025-08-27 06:07:40,320][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042456] [Batch 02416/03080] [00:30:05/00:08:16, 0.747s/it]: train_loss_raw=0.7307, running_loss=0.8014, LR=0.000100
[2025-08-27 06:07:46,261][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042464] [Batch 02424/03080] [00:30:11/00:08:10, 0.747s/it]: train_loss_raw=0.7415, running_loss=0.7981, LR=0.000100
[2025-08-27 06:07:52,067][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042472] [Batch 02432/03080] [00:30:16/00:08:04, 0.747s/it]: train_loss_raw=0.7958, running_loss=0.8017, LR=0.000100
[2025-08-27 06:07:57,959][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042480] [Batch 02440/03080] [00:30:22/00:07:58, 0.747s/it]: train_loss_raw=0.8851, running_loss=0.8026, LR=0.000100
[2025-08-27 06:08:03,904][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042488] [Batch 02448/03080] [00:30:28/00:07:52, 0.747s/it]: train_loss_raw=0.8662, running_loss=0.8011, LR=0.000100
[2025-08-27 06:08:09,715][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042496] [Batch 02456/03080] [00:30:34/00:07:46, 0.747s/it]: train_loss_raw=0.8445, running_loss=0.8015, LR=0.000100
[2025-08-27 06:08:15,439][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042504] [Batch 02464/03080] [00:30:40/00:07:40, 0.747s/it]: train_loss_raw=0.6795, running_loss=0.7977, LR=0.000100
[2025-08-27 06:08:21,622][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042512] [Batch 02472/03080] [00:30:46/00:07:34, 0.747s/it]: train_loss_raw=0.8121, running_loss=0.7990, LR=0.000100
[2025-08-27 06:08:27,622][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042520] [Batch 02480/03080] [00:30:52/00:07:28, 0.747s/it]: train_loss_raw=0.8206, running_loss=0.8010, LR=0.000100
[2025-08-27 06:08:33,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042528] [Batch 02488/03080] [00:30:58/00:07:22, 0.747s/it]: train_loss_raw=0.7870, running_loss=0.7966, LR=0.000100
[2025-08-27 06:08:39,743][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042536] [Batch 02496/03080] [00:31:04/00:07:16, 0.747s/it]: train_loss_raw=0.8415, running_loss=0.7942, LR=0.000100
[2025-08-27 06:08:45,670][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042544] [Batch 02504/03080] [00:31:10/00:07:10, 0.747s/it]: train_loss_raw=0.9416, running_loss=0.7963, LR=0.000100
[2025-08-27 06:08:51,617][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042552] [Batch 02512/03080] [00:31:16/00:07:04, 0.747s/it]: train_loss_raw=0.8810, running_loss=0.8013, LR=0.000100
[2025-08-27 06:08:57,558][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042560] [Batch 02520/03080] [00:31:22/00:06:58, 0.747s/it]: train_loss_raw=0.7862, running_loss=0.7997, LR=0.000100
[2025-08-27 06:09:03,713][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042568] [Batch 02528/03080] [00:31:28/00:06:52, 0.747s/it]: train_loss_raw=0.7472, running_loss=0.7995, LR=0.000100
[2025-08-27 06:09:09,796][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042576] [Batch 02536/03080] [00:31:34/00:06:46, 0.747s/it]: train_loss_raw=0.8124, running_loss=0.7996, LR=0.000100
[2025-08-27 06:09:15,825][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042584] [Batch 02544/03080] [00:31:40/00:06:40, 0.747s/it]: train_loss_raw=0.8586, running_loss=0.8000, LR=0.000100
[2025-08-27 06:09:21,693][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042592] [Batch 02552/03080] [00:31:46/00:06:34, 0.747s/it]: train_loss_raw=0.7481, running_loss=0.7981, LR=0.000100
[2025-08-27 06:09:27,654][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042600] [Batch 02560/03080] [00:31:52/00:06:28, 0.747s/it]: train_loss_raw=0.8079, running_loss=0.7974, LR=0.000100
[2025-08-27 06:09:33,669][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042608] [Batch 02568/03080] [00:31:58/00:06:22, 0.747s/it]: train_loss_raw=0.7690, running_loss=0.7972, LR=0.000100
[2025-08-27 06:09:39,742][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042616] [Batch 02576/03080] [00:32:04/00:06:16, 0.747s/it]: train_loss_raw=0.7517, running_loss=0.7968, LR=0.000100
[2025-08-27 06:09:45,909][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042624] [Batch 02584/03080] [00:32:10/00:06:10, 0.747s/it]: train_loss_raw=0.7429, running_loss=0.7925, LR=0.000100
[2025-08-27 06:09:51,852][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042632] [Batch 02592/03080] [00:32:16/00:06:04, 0.747s/it]: train_loss_raw=0.8241, running_loss=0.7948, LR=0.000100
[2025-08-27 06:09:57,679][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042640] [Batch 02600/03080] [00:32:22/00:05:58, 0.747s/it]: train_loss_raw=0.6879, running_loss=0.7939, LR=0.000100
[2025-08-27 06:10:03,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042648] [Batch 02608/03080] [00:32:28/00:05:52, 0.747s/it]: train_loss_raw=0.7242, running_loss=0.7954, LR=0.000100
[2025-08-27 06:10:09,913][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042656] [Batch 02616/03080] [00:32:34/00:05:46, 0.747s/it]: train_loss_raw=0.8125, running_loss=0.7961, LR=0.000100
[2025-08-27 06:10:16,109][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042664] [Batch 02624/03080] [00:32:40/00:05:40, 0.747s/it]: train_loss_raw=0.8469, running_loss=0.7946, LR=0.000100
[2025-08-27 06:10:21,995][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042672] [Batch 02632/03080] [00:32:46/00:05:34, 0.747s/it]: train_loss_raw=0.9546, running_loss=0.7957, LR=0.000100
[2025-08-27 06:10:28,048][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042680] [Batch 02640/03080] [00:32:52/00:05:28, 0.747s/it]: train_loss_raw=0.7058, running_loss=0.7940, LR=0.000100
[2025-08-27 06:10:33,989][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042688] [Batch 02648/03080] [00:32:58/00:05:22, 0.747s/it]: train_loss_raw=0.8017, running_loss=0.7932, LR=0.000100
[2025-08-27 06:10:40,084][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042696] [Batch 02656/03080] [00:33:04/00:05:16, 0.747s/it]: train_loss_raw=0.8812, running_loss=0.7967, LR=0.000100
[2025-08-27 06:10:45,982][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042704] [Batch 02664/03080] [00:33:10/00:05:10, 0.747s/it]: train_loss_raw=0.8515, running_loss=0.7988, LR=0.000100
[2025-08-27 06:10:51,942][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042712] [Batch 02672/03080] [00:33:16/00:05:04, 0.747s/it]: train_loss_raw=0.8041, running_loss=0.7976, LR=0.000100
[2025-08-27 06:10:57,575][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042720] [Batch 02680/03080] [00:33:22/00:04:58, 0.747s/it]: train_loss_raw=0.8634, running_loss=0.7957, LR=0.000100
[2025-08-27 06:11:03,643][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042728] [Batch 02688/03080] [00:33:28/00:04:52, 0.747s/it]: train_loss_raw=0.8218, running_loss=0.7956, LR=0.000100
[2025-08-27 06:11:09,896][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042736] [Batch 02696/03080] [00:33:34/00:04:46, 0.747s/it]: train_loss_raw=0.8521, running_loss=0.7959, LR=0.000100
[2025-08-27 06:11:15,851][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042744] [Batch 02704/03080] [00:33:40/00:04:40, 0.747s/it]: train_loss_raw=0.8201, running_loss=0.7941, LR=0.000100
[2025-08-27 06:11:21,823][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042752] [Batch 02712/03080] [00:33:46/00:04:34, 0.747s/it]: train_loss_raw=0.8425, running_loss=0.7931, LR=0.000100
[2025-08-27 06:11:28,011][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042760] [Batch 02720/03080] [00:33:52/00:04:29, 0.747s/it]: train_loss_raw=0.7851, running_loss=0.7933, LR=0.000100
[2025-08-27 06:11:33,963][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042768] [Batch 02728/03080] [00:33:58/00:04:23, 0.747s/it]: train_loss_raw=0.8902, running_loss=0.7948, LR=0.000100
[2025-08-27 06:11:39,873][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042776] [Batch 02736/03080] [00:34:04/00:04:17, 0.747s/it]: train_loss_raw=0.8360, running_loss=0.7940, LR=0.000100
[2025-08-27 06:11:46,009][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042784] [Batch 02744/03080] [00:34:10/00:04:11, 0.747s/it]: train_loss_raw=0.7154, running_loss=0.7948, LR=0.000100
[2025-08-27 06:11:52,202][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042792] [Batch 02752/03080] [00:34:16/00:04:05, 0.747s/it]: train_loss_raw=0.6898, running_loss=0.7920, LR=0.000100
[2025-08-27 06:11:58,125][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042800] [Batch 02760/03080] [00:34:22/00:03:59, 0.747s/it]: train_loss_raw=0.7753, running_loss=0.7904, LR=0.000100
[2025-08-27 06:12:04,106][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042808] [Batch 02768/03080] [00:34:28/00:03:53, 0.747s/it]: train_loss_raw=0.7744, running_loss=0.7891, LR=0.000100
[2025-08-27 06:12:10,150][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042816] [Batch 02776/03080] [00:34:34/00:03:47, 0.747s/it]: train_loss_raw=0.7468, running_loss=0.7894, LR=0.000100
[2025-08-27 06:12:16,157][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042824] [Batch 02784/03080] [00:34:40/00:03:41, 0.747s/it]: train_loss_raw=0.6258, running_loss=0.7870, LR=0.000100
[2025-08-27 06:12:22,306][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042832] [Batch 02792/03080] [00:34:47/00:03:35, 0.748s/it]: train_loss_raw=0.8278, running_loss=0.7887, LR=0.000100
[2025-08-27 06:12:28,518][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042840] [Batch 02800/03080] [00:34:53/00:03:29, 0.748s/it]: train_loss_raw=0.8953, running_loss=0.7887, LR=0.000100
[2025-08-27 06:12:34,628][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042848] [Batch 02808/03080] [00:34:59/00:03:23, 0.748s/it]: train_loss_raw=0.7179, running_loss=0.7864, LR=0.000100
[2025-08-27 06:12:40,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042856] [Batch 02816/03080] [00:35:05/00:03:17, 0.748s/it]: train_loss_raw=0.7527, running_loss=0.7852, LR=0.000100
[2025-08-27 06:12:46,793][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042864] [Batch 02824/03080] [00:35:11/00:03:11, 0.748s/it]: train_loss_raw=0.8343, running_loss=0.7894, LR=0.000100
[2025-08-27 06:12:53,017][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042872] [Batch 02832/03080] [00:35:17/00:03:05, 0.748s/it]: train_loss_raw=0.7745, running_loss=0.7881, LR=0.000100
[2025-08-27 06:12:59,222][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042880] [Batch 02840/03080] [00:35:23/00:02:59, 0.748s/it]: train_loss_raw=0.6847, running_loss=0.7863, LR=0.000100
[2025-08-27 06:13:05,417][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042888] [Batch 02848/03080] [00:35:30/00:02:53, 0.748s/it]: train_loss_raw=0.8335, running_loss=0.7860, LR=0.000100
[2025-08-27 06:13:11,647][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042896] [Batch 02856/03080] [00:35:36/00:02:47, 0.748s/it]: train_loss_raw=0.6980, running_loss=0.7853, LR=0.000100
[2025-08-27 06:13:17,775][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042904] [Batch 02864/03080] [00:35:42/00:02:41, 0.748s/it]: train_loss_raw=0.8427, running_loss=0.7871, LR=0.000100
[2025-08-27 06:13:23,865][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042912] [Batch 02872/03080] [00:35:48/00:02:35, 0.748s/it]: train_loss_raw=0.8678, running_loss=0.7878, LR=0.000100
[2025-08-27 06:13:29,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042920] [Batch 02880/03080] [00:35:54/00:02:29, 0.748s/it]: train_loss_raw=0.8292, running_loss=0.7899, LR=0.000100
[2025-08-27 06:13:35,816][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042928] [Batch 02888/03080] [00:36:00/00:02:23, 0.748s/it]: train_loss_raw=0.8023, running_loss=0.7893, LR=0.000100
[2025-08-27 06:13:41,734][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042936] [Batch 02896/03080] [00:36:06/00:02:17, 0.748s/it]: train_loss_raw=0.7884, running_loss=0.7910, LR=0.000100
[2025-08-27 06:13:47,650][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042944] [Batch 02904/03080] [00:36:12/00:02:11, 0.748s/it]: train_loss_raw=0.7647, running_loss=0.7929, LR=0.000100
[2025-08-27 06:13:53,765][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042952] [Batch 02912/03080] [00:36:18/00:02:05, 0.748s/it]: train_loss_raw=0.8204, running_loss=0.7941, LR=0.000100
[2025-08-27 06:13:59,718][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042960] [Batch 02920/03080] [00:36:24/00:01:59, 0.748s/it]: train_loss_raw=0.9210, running_loss=0.7936, LR=0.000100
[2025-08-27 06:14:05,751][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042968] [Batch 02928/03080] [00:36:30/00:01:53, 0.748s/it]: train_loss_raw=0.7767, running_loss=0.7923, LR=0.000100
[2025-08-27 06:14:11,772][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042976] [Batch 02936/03080] [00:36:36/00:01:47, 0.748s/it]: train_loss_raw=0.8039, running_loss=0.7918, LR=0.000100
[2025-08-27 06:14:17,846][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042984] [Batch 02944/03080] [00:36:42/00:01:41, 0.748s/it]: train_loss_raw=0.8106, running_loss=0.7932, LR=0.000100
[2025-08-27 06:14:23,820][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 042992] [Batch 02952/03080] [00:36:48/00:01:35, 0.748s/it]: train_loss_raw=0.8639, running_loss=0.7937, LR=0.000100
[2025-08-27 06:14:30,091][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043000] [Batch 02960/03080] [00:36:54/00:01:29, 0.748s/it]: train_loss_raw=0.7358, running_loss=0.7928, LR=0.000100
[2025-08-27 06:14:36,126][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043008] [Batch 02968/03080] [00:37:00/00:01:23, 0.748s/it]: train_loss_raw=0.7405, running_loss=0.7903, LR=0.000100
[2025-08-27 06:14:42,466][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043016] [Batch 02976/03080] [00:37:07/00:01:17, 0.748s/it]: train_loss_raw=0.7380, running_loss=0.7945, LR=0.000100
[2025-08-27 06:14:48,305][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043024] [Batch 02984/03080] [00:37:13/00:01:11, 0.748s/it]: train_loss_raw=0.8524, running_loss=0.7954, LR=0.000100
[2025-08-27 06:14:54,194][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043032] [Batch 02992/03080] [00:37:18/00:01:05, 0.748s/it]: train_loss_raw=0.8261, running_loss=0.7942, LR=0.000100
[2025-08-27 06:15:00,379][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043040] [Batch 03000/03080] [00:37:25/00:00:59, 0.748s/it]: train_loss_raw=0.7967, running_loss=0.7925, LR=0.000100
[2025-08-27 06:15:06,370][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043048] [Batch 03008/03080] [00:37:31/00:00:53, 0.748s/it]: train_loss_raw=0.7326, running_loss=0.7910, LR=0.000100
[2025-08-27 06:15:12,318][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043056] [Batch 03016/03080] [00:37:37/00:00:47, 0.748s/it]: train_loss_raw=0.7699, running_loss=0.7903, LR=0.000100
[2025-08-27 06:15:18,216][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043064] [Batch 03024/03080] [00:37:42/00:00:41, 0.748s/it]: train_loss_raw=0.6633, running_loss=0.7905, LR=0.000100
[2025-08-27 06:15:23,992][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043072] [Batch 03032/03080] [00:37:48/00:00:35, 0.748s/it]: train_loss_raw=0.7490, running_loss=0.7898, LR=0.000100
[2025-08-27 06:15:29,888][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043080] [Batch 03040/03080] [00:37:54/00:00:29, 0.748s/it]: train_loss_raw=0.7524, running_loss=0.7901, LR=0.000100
[2025-08-27 06:15:35,781][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043088] [Batch 03048/03080] [00:38:00/00:00:23, 0.748s/it]: train_loss_raw=0.7560, running_loss=0.7904, LR=0.000100
[2025-08-27 06:15:41,676][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043096] [Batch 03056/03080] [00:38:06/00:00:17, 0.748s/it]: train_loss_raw=0.7035, running_loss=0.7863, LR=0.000100
[2025-08-27 06:15:47,810][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043104] [Batch 03064/03080] [00:38:12/00:00:11, 0.748s/it]: train_loss_raw=0.7127, running_loss=0.7877, LR=0.000100
[2025-08-27 06:15:53,827][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043112] [Batch 03072/03080] [00:38:18/00:00:05, 0.748s/it]: train_loss_raw=0.8237, running_loss=0.7864, LR=0.000100
[2025-08-27 06:16:03,995][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 043120] [Batch 03080/03080] [00:38:28/00:00:00, 0.750s/it]: train_loss_raw=0.8152, running_loss=0.7843, LR=0.000100
[2025-08-27 06:16:04,521][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-27 06:16:16,063][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00007/00310] [00:00:11/00:07:15, 1.443s/it]
[2025-08-27 06:16:28,095][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00015/00310] [00:00:23/00:07:13, 1.473s/it]
[2025-08-27 06:16:40,710][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00023/00310] [00:00:36/00:07:11, 1.508s/it]
[2025-08-27 06:16:53,010][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00031/00310] [00:00:48/00:07:01, 1.515s/it]
[2025-08-27 06:17:06,185][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00039/00310] [00:01:01/00:06:56, 1.542s/it]
[2025-08-27 06:17:19,277][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00047/00310] [00:01:14/00:06:48, 1.557s/it]
[2025-08-27 06:17:32,513][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00055/00310] [00:01:27/00:06:39, 1.571s/it]
[2025-08-27 06:17:44,950][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00063/00310] [00:01:40/00:06:26, 1.569s/it]
[2025-08-27 06:17:57,266][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00071/00310] [00:01:52/00:06:12, 1.566s/it]
[2025-08-27 06:18:10,131][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00079/00310] [00:02:05/00:06:01, 1.570s/it]
[2025-08-27 06:18:23,264][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00087/00310] [00:02:18/00:05:50, 1.577s/it]
[2025-08-27 06:18:35,745][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00095/00310] [00:02:31/00:05:37, 1.575s/it]
[2025-08-27 06:18:48,743][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00103/00310] [00:02:44/00:05:25, 1.579s/it]
[2025-08-27 06:19:01,335][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00111/00310] [00:02:56/00:05:12, 1.579s/it]
[2025-08-27 06:19:13,953][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00119/00310] [00:03:09/00:04:59, 1.579s/it]
[2025-08-27 06:19:26,847][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00127/00310] [00:03:22/00:04:47, 1.581s/it]
[2025-08-27 06:19:39,515][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00135/00310] [00:03:34/00:04:35, 1.581s/it]
[2025-08-27 06:19:51,985][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00143/00310] [00:03:47/00:04:22, 1.580s/it]
[2025-08-27 06:20:03,933][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00151/00310] [00:03:59/00:04:08, 1.575s/it]
[2025-08-27 06:20:15,490][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00159/00310] [00:04:10/00:03:55, 1.569s/it]
[2025-08-27 06:20:27,972][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00167/00310] [00:04:23/00:03:42, 1.568s/it]
[2025-08-27 06:20:39,543][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00175/00310] [00:04:35/00:03:29, 1.563s/it]
[2025-08-27 06:20:51,479][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00183/00310] [00:04:46/00:03:16, 1.560s/it]
[2025-08-27 06:21:04,054][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00191/00310] [00:04:59/00:03:04, 1.560s/it]
[2025-08-27 06:21:15,769][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00199/00310] [00:05:11/00:02:51, 1.556s/it]
[2025-08-27 06:21:27,391][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00207/00310] [00:05:22/00:02:38, 1.552s/it]
[2025-08-27 06:21:39,423][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00215/00310] [00:05:34/00:02:25, 1.550s/it]
[2025-08-27 06:21:51,685][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00223/00310] [00:05:47/00:02:13, 1.550s/it]
[2025-08-27 06:22:04,603][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00231/00310] [00:06:00/00:02:01, 1.552s/it]
[2025-08-27 06:22:17,221][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00239/00310] [00:06:12/00:01:48, 1.553s/it]
[2025-08-27 06:22:29,051][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00247/00310] [00:06:24/00:01:36, 1.551s/it]
[2025-08-27 06:22:41,146][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00255/00310] [00:06:36/00:01:23, 1.549s/it]
[2025-08-27 06:22:53,289][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00263/00310] [00:06:48/00:01:11, 1.548s/it]
[2025-08-27 06:23:05,778][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00271/00310] [00:07:01/00:00:58, 1.549s/it]
[2025-08-27 06:23:18,253][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00279/00310] [00:07:13/00:00:46, 1.549s/it]
[2025-08-27 06:23:30,606][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00287/00310] [00:07:26/00:00:34, 1.549s/it]
[2025-08-27 06:23:42,897][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00295/00310] [00:07:38/00:00:21, 1.549s/it]
[2025-08-27 06:23:55,602][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 043121] [Batch 00303/00310] [00:07:51/00:00:09, 1.550s/it]
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=0.78427, valid_loss=1.74725
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.652
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.063
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.065
[2025-08-27 06:24:05,230][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.025
[2025-08-27 06:24:05,248][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 10:57:19, remaining time 12:31:13, 00:46:57 per epoch
[2025-08-27 06:24:11,188][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043128] [Batch 00008/03080] [00:00:05/00:35:39, 0.696s/it]: train_loss_raw=0.8025, running_loss=0.7777, LR=0.000100
[2025-08-27 06:24:17,431][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043136] [Batch 00016/03080] [00:00:11/00:37:42, 0.738s/it]: train_loss_raw=0.6932, running_loss=0.7737, LR=0.000100
[2025-08-27 06:24:23,623][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043144] [Batch 00024/03080] [00:00:18/00:38:12, 0.750s/it]: train_loss_raw=0.7214, running_loss=0.7725, LR=0.000100
[2025-08-27 06:24:29,540][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043152] [Batch 00032/03080] [00:00:23/00:37:58, 0.748s/it]: train_loss_raw=0.7152, running_loss=0.7695, LR=0.000100
[2025-08-27 06:24:35,659][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043160] [Batch 00040/03080] [00:00:30/00:38:03, 0.751s/it]: train_loss_raw=0.7512, running_loss=0.7703, LR=0.000100
[2025-08-27 06:24:41,834][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043168] [Batch 00048/03080] [00:00:36/00:38:07, 0.755s/it]: train_loss_raw=0.7508, running_loss=0.7693, LR=0.000100
[2025-08-27 06:24:47,959][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043176] [Batch 00056/03080] [00:00:42/00:38:06, 0.756s/it]: train_loss_raw=0.7896, running_loss=0.7682, LR=0.000100
[2025-08-27 06:24:54,063][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043184] [Batch 00064/03080] [00:00:48/00:38:03, 0.757s/it]: train_loss_raw=0.6890, running_loss=0.7660, LR=0.000100
[2025-08-27 06:25:00,154][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043192] [Batch 00072/03080] [00:00:54/00:37:58, 0.757s/it]: train_loss_raw=0.7303, running_loss=0.7639, LR=0.000100
[2025-08-27 06:25:06,202][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043200] [Batch 00080/03080] [00:01:00/00:37:51, 0.757s/it]: train_loss_raw=0.7705, running_loss=0.7638, LR=0.000100
[2025-08-27 06:25:12,050][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043208] [Batch 00088/03080] [00:01:06/00:37:38, 0.755s/it]: train_loss_raw=0.7853, running_loss=0.7657, LR=0.000100
[2025-08-27 06:25:17,812][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043216] [Batch 00096/03080] [00:01:12/00:37:24, 0.752s/it]: train_loss_raw=0.7038, running_loss=0.7617, LR=0.000100
[2025-08-27 06:25:23,743][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043224] [Batch 00104/03080] [00:01:18/00:37:15, 0.751s/it]: train_loss_raw=0.7087, running_loss=0.7625, LR=0.000100
[2025-08-27 06:25:29,842][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043232] [Batch 00112/03080] [00:01:24/00:37:11, 0.752s/it]: train_loss_raw=0.7820, running_loss=0.7633, LR=0.000100
[2025-08-27 06:25:35,779][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043240] [Batch 00120/03080] [00:01:30/00:37:04, 0.751s/it]: train_loss_raw=0.7694, running_loss=0.7651, LR=0.000100
[2025-08-27 06:25:42,048][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043248] [Batch 00128/03080] [00:01:36/00:37:03, 0.753s/it]: train_loss_raw=0.7258, running_loss=0.7639, LR=0.000100
[2025-08-27 06:25:48,310][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043256] [Batch 00136/03080] [00:01:42/00:37:03, 0.755s/it]: train_loss_raw=0.6643, running_loss=0.7606, LR=0.000100
[2025-08-27 06:25:54,048][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043264] [Batch 00144/03080] [00:01:48/00:36:50, 0.753s/it]: train_loss_raw=0.7174, running_loss=0.7597, LR=0.000100
[2025-08-27 06:26:00,187][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043272] [Batch 00152/03080] [00:01:54/00:36:46, 0.754s/it]: train_loss_raw=0.7304, running_loss=0.7576, LR=0.000100
[2025-08-27 06:26:05,945][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043280] [Batch 00160/03080] [00:02:00/00:36:36, 0.752s/it]: train_loss_raw=0.6917, running_loss=0.7569, LR=0.000100
[2025-08-27 06:26:11,701][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043288] [Batch 00168/03080] [00:02:06/00:36:25, 0.751s/it]: train_loss_raw=0.6469, running_loss=0.7567, LR=0.000100
[2025-08-27 06:26:17,654][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043296] [Batch 00176/03080] [00:02:12/00:36:18, 0.750s/it]: train_loss_raw=0.7622, running_loss=0.7576, LR=0.000100
[2025-08-27 06:26:23,702][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043304] [Batch 00184/03080] [00:02:18/00:36:13, 0.750s/it]: train_loss_raw=0.8356, running_loss=0.7563, LR=0.000100
[2025-08-27 06:26:29,818][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043312] [Batch 00192/03080] [00:02:24/00:36:09, 0.751s/it]: train_loss_raw=0.6715, running_loss=0.7547, LR=0.000100
[2025-08-27 06:26:35,981][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043320] [Batch 00200/03080] [00:02:30/00:36:05, 0.752s/it]: train_loss_raw=0.7799, running_loss=0.7528, LR=0.000100
[2025-08-27 06:26:41,917][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043328] [Batch 00208/03080] [00:02:36/00:35:58, 0.751s/it]: train_loss_raw=0.5892, running_loss=0.7532, LR=0.000100
[2025-08-27 06:26:47,967][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043336] [Batch 00216/03080] [00:02:42/00:35:52, 0.752s/it]: train_loss_raw=0.7464, running_loss=0.7588, LR=0.000100
[2025-08-27 06:26:54,025][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043344] [Batch 00224/03080] [00:02:48/00:35:47, 0.752s/it]: train_loss_raw=0.7758, running_loss=0.7557, LR=0.000100
[2025-08-27 06:26:59,930][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043352] [Batch 00232/03080] [00:02:54/00:35:39, 0.751s/it]: train_loss_raw=0.6754, running_loss=0.7538, LR=0.000100
[2025-08-27 06:27:05,842][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043360] [Batch 00240/03080] [00:03:00/00:35:32, 0.751s/it]: train_loss_raw=0.7810, running_loss=0.7532, LR=0.000100
[2025-08-27 06:27:12,036][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043368] [Batch 00248/03080] [00:03:06/00:35:28, 0.752s/it]: train_loss_raw=0.7172, running_loss=0.7533, LR=0.000100
[2025-08-27 06:27:18,004][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043376] [Batch 00256/03080] [00:03:12/00:35:22, 0.752s/it]: train_loss_raw=0.8383, running_loss=0.7539, LR=0.000100
[2025-08-27 06:27:24,019][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043384] [Batch 00264/03080] [00:03:18/00:35:16, 0.752s/it]: train_loss_raw=0.7354, running_loss=0.7512, LR=0.000100
[2025-08-27 06:27:30,230][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043392] [Batch 00272/03080] [00:03:24/00:35:12, 0.752s/it]: train_loss_raw=0.8110, running_loss=0.7528, LR=0.000100
[2025-08-27 06:27:36,289][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043400] [Batch 00280/03080] [00:03:30/00:35:06, 0.752s/it]: train_loss_raw=0.8314, running_loss=0.7541, LR=0.000100
[2025-08-27 06:27:42,377][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043408] [Batch 00288/03080] [00:03:36/00:35:01, 0.753s/it]: train_loss_raw=0.8050, running_loss=0.7548, LR=0.000100
[2025-08-27 06:27:48,516][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043416] [Batch 00296/03080] [00:03:42/00:34:56, 0.753s/it]: train_loss_raw=0.7364, running_loss=0.7550, LR=0.000100
[2025-08-27 06:27:54,471][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043424] [Batch 00304/03080] [00:03:48/00:34:49, 0.753s/it]: train_loss_raw=0.7550, running_loss=0.7555, LR=0.000100
[2025-08-27 06:28:00,573][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043432] [Batch 00312/03080] [00:03:54/00:34:44, 0.753s/it]: train_loss_raw=0.6961, running_loss=0.7570, LR=0.000100
[2025-08-27 06:28:06,593][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043440] [Batch 00320/03080] [00:04:00/00:34:38, 0.753s/it]: train_loss_raw=0.7516, running_loss=0.7560, LR=0.000100
[2025-08-27 06:28:12,361][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043448] [Batch 00328/03080] [00:04:06/00:34:30, 0.752s/it]: train_loss_raw=0.7686, running_loss=0.7545, LR=0.000100
[2025-08-27 06:28:18,109][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043456] [Batch 00336/03080] [00:04:12/00:34:22, 0.751s/it]: train_loss_raw=0.8687, running_loss=0.7556, LR=0.000100
[2025-08-27 06:28:23,915][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043464] [Batch 00344/03080] [00:04:18/00:34:14, 0.751s/it]: train_loss_raw=0.7508, running_loss=0.7554, LR=0.000100
[2025-08-27 06:28:29,752][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043472] [Batch 00352/03080] [00:04:24/00:34:07, 0.750s/it]: train_loss_raw=0.7625, running_loss=0.7560, LR=0.000100
[2025-08-27 06:28:35,670][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043480] [Batch 00360/03080] [00:04:30/00:34:00, 0.750s/it]: train_loss_raw=0.8622, running_loss=0.7552, LR=0.000100
[2025-08-27 06:28:41,761][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043488] [Batch 00368/03080] [00:04:36/00:33:55, 0.750s/it]: train_loss_raw=0.7217, running_loss=0.7529, LR=0.000100
[2025-08-27 06:28:47,639][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043496] [Batch 00376/03080] [00:04:42/00:33:48, 0.750s/it]: train_loss_raw=0.8007, running_loss=0.7556, LR=0.000100
[2025-08-27 06:28:53,899][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043504] [Batch 00384/03080] [00:04:48/00:33:43, 0.751s/it]: train_loss_raw=0.6136, running_loss=0.7540, LR=0.000100
[2025-08-27 06:28:59,862][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043512] [Batch 00392/03080] [00:04:54/00:33:37, 0.751s/it]: train_loss_raw=0.8109, running_loss=0.7548, LR=0.000100
[2025-08-27 06:29:05,671][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043520] [Batch 00400/03080] [00:05:00/00:33:30, 0.750s/it]: train_loss_raw=0.7404, running_loss=0.7542, LR=0.000100
[2025-08-27 06:29:11,605][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043528] [Batch 00408/03080] [00:05:05/00:33:23, 0.750s/it]: train_loss_raw=0.7222, running_loss=0.7546, LR=0.000100
[2025-08-27 06:29:17,735][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043536] [Batch 00416/03080] [00:05:12/00:33:18, 0.750s/it]: train_loss_raw=0.7130, running_loss=0.7581, LR=0.000100
[2025-08-27 06:29:23,887][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043544] [Batch 00424/03080] [00:05:18/00:33:13, 0.751s/it]: train_loss_raw=0.7551, running_loss=0.7557, LR=0.000100
[2025-08-27 06:29:29,998][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043552] [Batch 00432/03080] [00:05:24/00:33:08, 0.751s/it]: train_loss_raw=0.7980, running_loss=0.7568, LR=0.000100
[2025-08-27 06:29:36,168][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043560] [Batch 00440/03080] [00:05:30/00:33:03, 0.751s/it]: train_loss_raw=0.7850, running_loss=0.7587, LR=0.000100
[2025-08-27 06:29:42,513][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043568] [Batch 00448/03080] [00:05:36/00:32:59, 0.752s/it]: train_loss_raw=0.7996, running_loss=0.7605, LR=0.000100
[2025-08-27 06:29:48,544][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043576] [Batch 00456/03080] [00:05:42/00:32:53, 0.752s/it]: train_loss_raw=0.6563, running_loss=0.7599, LR=0.000100
[2025-08-27 06:29:54,528][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043584] [Batch 00464/03080] [00:05:48/00:32:47, 0.752s/it]: train_loss_raw=0.7460, running_loss=0.7596, LR=0.000100
[2025-08-27 06:30:00,446][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043592] [Batch 00472/03080] [00:05:54/00:32:40, 0.752s/it]: train_loss_raw=0.7988, running_loss=0.7594, LR=0.000100
[2025-08-27 06:30:06,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043600] [Batch 00480/03080] [00:06:00/00:32:33, 0.751s/it]: train_loss_raw=0.8198, running_loss=0.7593, LR=0.000100
[2025-08-27 06:30:12,296][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043608] [Batch 00488/03080] [00:06:06/00:32:27, 0.751s/it]: train_loss_raw=0.7696, running_loss=0.7587, LR=0.000100
[2025-08-27 06:30:18,203][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043616] [Batch 00496/03080] [00:06:12/00:32:21, 0.751s/it]: train_loss_raw=0.7411, running_loss=0.7587, LR=0.000100
[2025-08-27 06:30:24,208][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043624] [Batch 00504/03080] [00:06:18/00:32:15, 0.751s/it]: train_loss_raw=0.6880, running_loss=0.7577, LR=0.000100
[2025-08-27 06:30:30,188][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043632] [Batch 00512/03080] [00:06:24/00:32:08, 0.751s/it]: train_loss_raw=0.7569, running_loss=0.7566, LR=0.000100
[2025-08-27 06:30:36,244][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043640] [Batch 00520/03080] [00:06:30/00:32:03, 0.751s/it]: train_loss_raw=0.7503, running_loss=0.7576, LR=0.000100
[2025-08-27 06:30:42,125][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043648] [Batch 00528/03080] [00:06:36/00:31:56, 0.751s/it]: train_loss_raw=0.7179, running_loss=0.7560, LR=0.000100
[2025-08-27 06:30:48,233][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043656] [Batch 00536/03080] [00:06:42/00:31:50, 0.751s/it]: train_loss_raw=0.8164, running_loss=0.7546, LR=0.000100
[2025-08-27 06:30:54,210][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043664] [Batch 00544/03080] [00:06:48/00:31:44, 0.751s/it]: train_loss_raw=0.7505, running_loss=0.7508, LR=0.000100
[2025-08-27 06:31:00,005][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043672] [Batch 00552/03080] [00:06:54/00:31:37, 0.751s/it]: train_loss_raw=0.7427, running_loss=0.7533, LR=0.000100
[2025-08-27 06:31:05,770][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043680] [Batch 00560/03080] [00:07:00/00:31:30, 0.750s/it]: train_loss_raw=0.7605, running_loss=0.7547, LR=0.000100
[2025-08-27 06:31:11,613][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043688] [Batch 00568/03080] [00:07:05/00:31:23, 0.750s/it]: train_loss_raw=0.7665, running_loss=0.7537, LR=0.000100
[2025-08-27 06:31:17,612][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043696] [Batch 00576/03080] [00:07:11/00:31:17, 0.750s/it]: train_loss_raw=0.6620, running_loss=0.7527, LR=0.000100
[2025-08-27 06:31:23,452][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043704] [Batch 00584/03080] [00:07:17/00:31:11, 0.750s/it]: train_loss_raw=0.8253, running_loss=0.7550, LR=0.000100
[2025-08-27 06:31:29,337][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043712] [Batch 00592/03080] [00:07:23/00:31:04, 0.750s/it]: train_loss_raw=0.7542, running_loss=0.7552, LR=0.000100
[2025-08-27 06:31:35,140][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043720] [Batch 00600/03080] [00:07:29/00:30:58, 0.749s/it]: train_loss_raw=0.7346, running_loss=0.7543, LR=0.000100
[2025-08-27 06:31:40,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043728] [Batch 00608/03080] [00:07:35/00:30:51, 0.749s/it]: train_loss_raw=0.8201, running_loss=0.7548, LR=0.000100
[2025-08-27 06:31:46,862][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043736] [Batch 00616/03080] [00:07:41/00:30:44, 0.749s/it]: train_loss_raw=0.7138, running_loss=0.7543, LR=0.000100
[2025-08-27 06:31:52,865][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043744] [Batch 00624/03080] [00:07:47/00:30:39, 0.749s/it]: train_loss_raw=0.8262, running_loss=0.7551, LR=0.000100
[2025-08-27 06:31:58,752][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043752] [Batch 00632/03080] [00:07:53/00:30:32, 0.749s/it]: train_loss_raw=0.8010, running_loss=0.7549, LR=0.000100
[2025-08-27 06:32:04,657][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043760] [Batch 00640/03080] [00:07:59/00:30:26, 0.749s/it]: train_loss_raw=0.7118, running_loss=0.7535, LR=0.000100
[2025-08-27 06:32:10,533][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043768] [Batch 00648/03080] [00:08:04/00:30:19, 0.748s/it]: train_loss_raw=0.6812, running_loss=0.7527, LR=0.000100
[2025-08-27 06:32:16,359][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043776] [Batch 00656/03080] [00:08:10/00:30:13, 0.748s/it]: train_loss_raw=0.7640, running_loss=0.7535, LR=0.000100
[2025-08-27 06:32:22,250][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043784] [Batch 00664/03080] [00:08:16/00:30:07, 0.748s/it]: train_loss_raw=0.7698, running_loss=0.7518, LR=0.000100
[2025-08-27 06:32:28,127][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043792] [Batch 00672/03080] [00:08:22/00:30:00, 0.748s/it]: train_loss_raw=0.7595, running_loss=0.7519, LR=0.000100
[2025-08-27 06:32:34,021][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043800] [Batch 00680/03080] [00:08:28/00:29:54, 0.748s/it]: train_loss_raw=0.8139, running_loss=0.7522, LR=0.000100
[2025-08-27 06:32:39,855][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043808] [Batch 00688/03080] [00:08:34/00:29:47, 0.747s/it]: train_loss_raw=0.7400, running_loss=0.7533, LR=0.000100
[2025-08-27 06:32:45,650][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043816] [Batch 00696/03080] [00:08:40/00:29:41, 0.747s/it]: train_loss_raw=0.7544, running_loss=0.7540, LR=0.000100
[2025-08-27 06:32:51,538][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043824] [Batch 00704/03080] [00:08:45/00:29:34, 0.747s/it]: train_loss_raw=0.7491, running_loss=0.7535, LR=0.000100
[2025-08-27 06:32:57,371][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043832] [Batch 00712/03080] [00:08:51/00:29:28, 0.747s/it]: train_loss_raw=0.8029, running_loss=0.7533, LR=0.000100
[2025-08-27 06:33:03,211][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043840] [Batch 00720/03080] [00:08:57/00:29:22, 0.747s/it]: train_loss_raw=0.7374, running_loss=0.7546, LR=0.000100
[2025-08-27 06:33:08,999][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043848] [Batch 00728/03080] [00:09:03/00:29:15, 0.746s/it]: train_loss_raw=0.7342, running_loss=0.7545, LR=0.000100
[2025-08-27 06:33:14,866][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043856] [Batch 00736/03080] [00:09:09/00:29:09, 0.746s/it]: train_loss_raw=0.7961, running_loss=0.7548, LR=0.000100
[2025-08-27 06:33:20,865][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043864] [Batch 00744/03080] [00:09:15/00:29:03, 0.746s/it]: train_loss_raw=0.6156, running_loss=0.7523, LR=0.000100
[2025-08-27 06:33:26,917][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043872] [Batch 00752/03080] [00:09:21/00:28:57, 0.746s/it]: train_loss_raw=0.8496, running_loss=0.7521, LR=0.000100
[2025-08-27 06:33:32,592][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043880] [Batch 00760/03080] [00:09:26/00:28:50, 0.746s/it]: train_loss_raw=0.7966, running_loss=0.7532, LR=0.000100
[2025-08-27 06:33:38,233][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043888] [Batch 00768/03080] [00:09:32/00:28:43, 0.746s/it]: train_loss_raw=0.7736, running_loss=0.7513, LR=0.000100
[2025-08-27 06:33:44,026][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043896] [Batch 00776/03080] [00:09:38/00:28:37, 0.745s/it]: train_loss_raw=0.7138, running_loss=0.7508, LR=0.000100
[2025-08-27 06:33:49,904][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043904] [Batch 00784/03080] [00:09:44/00:28:31, 0.745s/it]: train_loss_raw=0.7411, running_loss=0.7525, LR=0.000100
[2025-08-27 06:33:55,721][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043912] [Batch 00792/03080] [00:09:50/00:28:24, 0.745s/it]: train_loss_raw=0.7177, running_loss=0.7516, LR=0.000100
[2025-08-27 06:34:01,576][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043920] [Batch 00800/03080] [00:09:55/00:28:18, 0.745s/it]: train_loss_raw=0.7516, running_loss=0.7527, LR=0.000100
[2025-08-27 06:34:07,485][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043928] [Batch 00808/03080] [00:10:01/00:28:12, 0.745s/it]: train_loss_raw=0.6942, running_loss=0.7523, LR=0.000100
[2025-08-27 06:34:13,491][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043936] [Batch 00816/03080] [00:10:07/00:28:06, 0.745s/it]: train_loss_raw=0.6610, running_loss=0.7523, LR=0.000100
[2025-08-27 06:34:19,333][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043944] [Batch 00824/03080] [00:10:13/00:28:00, 0.745s/it]: train_loss_raw=0.7219, running_loss=0.7525, LR=0.000100
[2025-08-27 06:34:25,249][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043952] [Batch 00832/03080] [00:10:19/00:27:54, 0.745s/it]: train_loss_raw=0.7176, running_loss=0.7481, LR=0.000100
[2025-08-27 06:34:31,075][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043960] [Batch 00840/03080] [00:10:25/00:27:47, 0.745s/it]: train_loss_raw=0.7441, running_loss=0.7487, LR=0.000100
[2025-08-27 06:34:36,912][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043968] [Batch 00848/03080] [00:10:31/00:27:41, 0.744s/it]: train_loss_raw=0.7158, running_loss=0.7479, LR=0.000100
[2025-08-27 06:34:42,825][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043976] [Batch 00856/03080] [00:10:37/00:27:35, 0.744s/it]: train_loss_raw=0.7961, running_loss=0.7479, LR=0.000100
[2025-08-27 06:34:48,707][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043984] [Batch 00864/03080] [00:10:43/00:27:29, 0.744s/it]: train_loss_raw=0.6936, running_loss=0.7459, LR=0.000100
[2025-08-27 06:34:54,532][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 043992] [Batch 00872/03080] [00:10:48/00:27:23, 0.744s/it]: train_loss_raw=0.8076, running_loss=0.7454, LR=0.000100
[2025-08-27 06:35:00,392][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044000] [Batch 00880/03080] [00:10:54/00:27:16, 0.744s/it]: train_loss_raw=0.6413, running_loss=0.7464, LR=0.000100
[2025-08-27 06:35:10,327][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044008] [Batch 00888/03080] [00:11:04/00:27:20, 0.749s/it]: train_loss_raw=0.8367, running_loss=0.7462, LR=0.000100
[2025-08-27 06:35:16,116][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044016] [Batch 00896/03080] [00:11:10/00:27:14, 0.748s/it]: train_loss_raw=0.8161, running_loss=0.7455, LR=0.000100
[2025-08-27 06:35:21,928][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044024] [Batch 00904/03080] [00:11:16/00:27:07, 0.748s/it]: train_loss_raw=0.7643, running_loss=0.7474, LR=0.000100
[2025-08-27 06:35:27,644][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044032] [Batch 00912/03080] [00:11:22/00:27:01, 0.748s/it]: train_loss_raw=0.8301, running_loss=0.7483, LR=0.000100
[2025-08-27 06:35:33,520][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044040] [Batch 00920/03080] [00:11:27/00:26:55, 0.748s/it]: train_loss_raw=0.7299, running_loss=0.7487, LR=0.000100
[2025-08-27 06:35:39,389][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044048] [Batch 00928/03080] [00:11:33/00:26:48, 0.748s/it]: train_loss_raw=0.7274, running_loss=0.7460, LR=0.000100
[2025-08-27 06:35:45,232][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044056] [Batch 00936/03080] [00:11:39/00:26:42, 0.747s/it]: train_loss_raw=0.7242, running_loss=0.7463, LR=0.000100
[2025-08-27 06:35:50,920][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044064] [Batch 00944/03080] [00:11:45/00:26:35, 0.747s/it]: train_loss_raw=0.6504, running_loss=0.7440, LR=0.000100
[2025-08-27 06:35:56,616][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044072] [Batch 00952/03080] [00:11:51/00:26:29, 0.747s/it]: train_loss_raw=0.7790, running_loss=0.7456, LR=0.000100
[2025-08-27 06:36:02,541][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044080] [Batch 00960/03080] [00:11:56/00:26:23, 0.747s/it]: train_loss_raw=0.7329, running_loss=0.7441, LR=0.000100
[2025-08-27 06:36:08,495][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044088] [Batch 00968/03080] [00:12:02/00:26:17, 0.747s/it]: train_loss_raw=0.7984, running_loss=0.7447, LR=0.000100
[2025-08-27 06:36:14,308][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044096] [Batch 00976/03080] [00:12:08/00:26:10, 0.747s/it]: train_loss_raw=0.7870, running_loss=0.7459, LR=0.000100
[2025-08-27 06:36:20,143][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044104] [Batch 00984/03080] [00:12:14/00:26:04, 0.746s/it]: train_loss_raw=0.7336, running_loss=0.7447, LR=0.000100
[2025-08-27 06:36:25,636][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044112] [Batch 00992/03080] [00:12:20/00:25:57, 0.746s/it]: train_loss_raw=0.7117, running_loss=0.7440, LR=0.000100
[2025-08-27 06:36:31,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044120] [Batch 01000/03080] [00:12:25/00:25:51, 0.746s/it]: train_loss_raw=0.7089, running_loss=0.7426, LR=0.000100
[2025-08-27 06:36:36,990][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044128] [Batch 01008/03080] [00:12:31/00:25:44, 0.745s/it]: train_loss_raw=0.7445, running_loss=0.7416, LR=0.000100
[2025-08-27 06:36:42,825][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044136] [Batch 01016/03080] [00:12:37/00:25:38, 0.745s/it]: train_loss_raw=0.7134, running_loss=0.7397, LR=0.000100
[2025-08-27 06:36:48,758][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044144] [Batch 01024/03080] [00:12:43/00:25:32, 0.745s/it]: train_loss_raw=0.7905, running_loss=0.7394, LR=0.000100
[2025-08-27 06:36:54,585][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044152] [Batch 01032/03080] [00:12:48/00:25:26, 0.745s/it]: train_loss_raw=0.8067, running_loss=0.7381, LR=0.000100
[2025-08-27 06:37:00,474][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044160] [Batch 01040/03080] [00:12:54/00:25:19, 0.745s/it]: train_loss_raw=0.6862, running_loss=0.7373, LR=0.000100
[2025-08-27 06:37:06,382][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044168] [Batch 01048/03080] [00:13:00/00:25:13, 0.745s/it]: train_loss_raw=0.8720, running_loss=0.7384, LR=0.000100
[2025-08-27 06:37:12,242][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044176] [Batch 01056/03080] [00:13:06/00:25:07, 0.745s/it]: train_loss_raw=0.7281, running_loss=0.7385, LR=0.000100
[2025-08-27 06:37:18,099][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044184] [Batch 01064/03080] [00:13:12/00:25:01, 0.745s/it]: train_loss_raw=0.7729, running_loss=0.7392, LR=0.000100
[2025-08-27 06:37:23,946][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044192] [Batch 01072/03080] [00:13:18/00:24:55, 0.745s/it]: train_loss_raw=0.7423, running_loss=0.7392, LR=0.000100
[2025-08-27 06:37:29,778][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044200] [Batch 01080/03080] [00:13:24/00:24:49, 0.745s/it]: train_loss_raw=0.7464, running_loss=0.7381, LR=0.000100
[2025-08-27 06:37:35,696][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044208] [Batch 01088/03080] [00:13:30/00:24:43, 0.745s/it]: train_loss_raw=0.8533, running_loss=0.7400, LR=0.000100
[2025-08-27 06:37:41,482][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044216] [Batch 01096/03080] [00:13:35/00:24:36, 0.744s/it]: train_loss_raw=0.8216, running_loss=0.7394, LR=0.000100
[2025-08-27 06:37:47,328][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044224] [Batch 01104/03080] [00:13:41/00:24:30, 0.744s/it]: train_loss_raw=0.7603, running_loss=0.7403, LR=0.000100
[2025-08-27 06:37:53,220][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044232] [Batch 01112/03080] [00:13:47/00:24:24, 0.744s/it]: train_loss_raw=0.7247, running_loss=0.7414, LR=0.000100
[2025-08-27 06:37:59,327][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044240] [Batch 01120/03080] [00:13:53/00:24:18, 0.744s/it]: train_loss_raw=0.8481, running_loss=0.7444, LR=0.000100
[2025-08-27 06:38:05,253][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044248] [Batch 01128/03080] [00:13:59/00:24:12, 0.744s/it]: train_loss_raw=0.7062, running_loss=0.7425, LR=0.000100
[2025-08-27 06:38:11,149][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044256] [Batch 01136/03080] [00:14:05/00:24:06, 0.744s/it]: train_loss_raw=0.7524, running_loss=0.7422, LR=0.000100
[2025-08-27 06:38:16,949][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044264] [Batch 01144/03080] [00:14:11/00:24:00, 0.744s/it]: train_loss_raw=0.6644, running_loss=0.7422, LR=0.000100
[2025-08-27 06:38:22,923][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044272] [Batch 01152/03080] [00:14:17/00:23:54, 0.744s/it]: train_loss_raw=0.7067, running_loss=0.7428, LR=0.000100
[2025-08-27 06:38:28,786][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044280] [Batch 01160/03080] [00:14:23/00:23:48, 0.744s/it]: train_loss_raw=0.7729, running_loss=0.7453, LR=0.000100
[2025-08-27 06:38:34,625][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044288] [Batch 01168/03080] [00:14:29/00:23:42, 0.744s/it]: train_loss_raw=0.7549, running_loss=0.7438, LR=0.000100
[2025-08-27 06:38:40,536][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044296] [Batch 01176/03080] [00:14:34/00:23:36, 0.744s/it]: train_loss_raw=0.7127, running_loss=0.7433, LR=0.000100
[2025-08-27 06:38:46,372][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044304] [Batch 01184/03080] [00:14:40/00:23:30, 0.744s/it]: train_loss_raw=0.6327, running_loss=0.7411, LR=0.000100
[2025-08-27 06:38:52,410][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044312] [Batch 01192/03080] [00:14:46/00:23:24, 0.744s/it]: train_loss_raw=0.7204, running_loss=0.7401, LR=0.000100
[2025-08-27 06:38:58,369][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044320] [Batch 01200/03080] [00:14:52/00:23:18, 0.744s/it]: train_loss_raw=0.7406, running_loss=0.7379, LR=0.000100
[2025-08-27 06:39:04,252][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044328] [Batch 01208/03080] [00:14:58/00:23:12, 0.744s/it]: train_loss_raw=0.6968, running_loss=0.7371, LR=0.000100
[2025-08-27 06:39:10,159][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044336] [Batch 01216/03080] [00:15:04/00:23:06, 0.744s/it]: train_loss_raw=0.7198, running_loss=0.7343, LR=0.000100
[2025-08-27 06:39:16,071][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044344] [Batch 01224/03080] [00:15:10/00:23:00, 0.744s/it]: train_loss_raw=0.7441, running_loss=0.7346, LR=0.000100
[2025-08-27 06:39:22,001][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044352] [Batch 01232/03080] [00:15:16/00:22:54, 0.744s/it]: train_loss_raw=0.7197, running_loss=0.7352, LR=0.000100
[2025-08-27 06:39:27,874][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044360] [Batch 01240/03080] [00:15:22/00:22:48, 0.744s/it]: train_loss_raw=0.8325, running_loss=0.7345, LR=0.000100
[2025-08-27 06:39:33,653][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044368] [Batch 01248/03080] [00:15:28/00:22:42, 0.744s/it]: train_loss_raw=0.7991, running_loss=0.7333, LR=0.000100
[2025-08-27 06:39:39,584][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044376] [Batch 01256/03080] [00:15:33/00:22:36, 0.744s/it]: train_loss_raw=0.8125, running_loss=0.7361, LR=0.000100
[2025-08-27 06:39:45,400][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044384] [Batch 01264/03080] [00:15:39/00:22:30, 0.743s/it]: train_loss_raw=0.6752, running_loss=0.7350, LR=0.000100
[2025-08-27 06:39:51,253][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044392] [Batch 01272/03080] [00:15:45/00:22:24, 0.743s/it]: train_loss_raw=0.8380, running_loss=0.7350, LR=0.000100
[2025-08-27 06:39:57,081][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044400] [Batch 01280/03080] [00:15:51/00:22:17, 0.743s/it]: train_loss_raw=0.6333, running_loss=0.7363, LR=0.000100
[2025-08-27 06:40:03,006][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044408] [Batch 01288/03080] [00:15:57/00:22:12, 0.743s/it]: train_loss_raw=0.7121, running_loss=0.7362, LR=0.000100
[2025-08-27 06:40:08,889][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044416] [Batch 01296/03080] [00:16:03/00:22:05, 0.743s/it]: train_loss_raw=0.7612, running_loss=0.7358, LR=0.000100
[2025-08-27 06:40:14,711][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044424] [Batch 01304/03080] [00:16:09/00:21:59, 0.743s/it]: train_loss_raw=0.7147, running_loss=0.7369, LR=0.000100
[2025-08-27 06:40:20,531][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044432] [Batch 01312/03080] [00:16:14/00:21:53, 0.743s/it]: train_loss_raw=0.7349, running_loss=0.7384, LR=0.000100
[2025-08-27 06:40:26,487][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044440] [Batch 01320/03080] [00:16:20/00:21:47, 0.743s/it]: train_loss_raw=0.6787, running_loss=0.7382, LR=0.000100
[2025-08-27 06:40:32,354][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044448] [Batch 01328/03080] [00:16:26/00:21:41, 0.743s/it]: train_loss_raw=0.7214, running_loss=0.7385, LR=0.000100
[2025-08-27 06:40:38,132][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044456] [Batch 01336/03080] [00:16:32/00:21:35, 0.743s/it]: train_loss_raw=0.7686, running_loss=0.7406, LR=0.000100
[2025-08-27 06:40:44,065][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044464] [Batch 01344/03080] [00:16:38/00:21:29, 0.743s/it]: train_loss_raw=0.7280, running_loss=0.7373, LR=0.000100
[2025-08-27 06:40:50,124][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044472] [Batch 01352/03080] [00:16:44/00:21:23, 0.743s/it]: train_loss_raw=0.7758, running_loss=0.7351, LR=0.000100
[2025-08-27 06:40:56,081][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044480] [Batch 01360/03080] [00:16:50/00:21:17, 0.743s/it]: train_loss_raw=0.7029, running_loss=0.7368, LR=0.000100
[2025-08-27 06:41:01,961][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044488] [Batch 01368/03080] [00:16:56/00:21:11, 0.743s/it]: train_loss_raw=0.7752, running_loss=0.7395, LR=0.000100
[2025-08-27 06:41:07,998][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044496] [Batch 01376/03080] [00:17:02/00:21:06, 0.743s/it]: train_loss_raw=0.7788, running_loss=0.7389, LR=0.000100
[2025-08-27 06:41:14,005][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044504] [Batch 01384/03080] [00:17:08/00:21:00, 0.743s/it]: train_loss_raw=0.7236, running_loss=0.7375, LR=0.000100
[2025-08-27 06:41:19,831][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044512] [Batch 01392/03080] [00:17:14/00:20:54, 0.743s/it]: train_loss_raw=0.7979, running_loss=0.7378, LR=0.000100
[2025-08-27 06:41:25,928][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044520] [Batch 01400/03080] [00:17:20/00:20:48, 0.743s/it]: train_loss_raw=0.8195, running_loss=0.7370, LR=0.000100
[2025-08-27 06:41:32,082][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044528] [Batch 01408/03080] [00:17:26/00:20:42, 0.743s/it]: train_loss_raw=0.7511, running_loss=0.7401, LR=0.000100
[2025-08-27 06:41:38,017][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044536] [Batch 01416/03080] [00:17:32/00:20:36, 0.743s/it]: train_loss_raw=0.7277, running_loss=0.7404, LR=0.000100
[2025-08-27 06:41:44,009][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044544] [Batch 01424/03080] [00:17:38/00:20:30, 0.743s/it]: train_loss_raw=0.8048, running_loss=0.7407, LR=0.000100
[2025-08-27 06:41:50,127][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044552] [Batch 01432/03080] [00:17:44/00:20:25, 0.743s/it]: train_loss_raw=0.7033, running_loss=0.7391, LR=0.000100
[2025-08-27 06:41:55,898][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044560] [Batch 01440/03080] [00:17:50/00:20:18, 0.743s/it]: train_loss_raw=0.7533, running_loss=0.7377, LR=0.000100
[2025-08-27 06:42:01,788][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044568] [Batch 01448/03080] [00:17:56/00:20:12, 0.743s/it]: train_loss_raw=0.7676, running_loss=0.7387, LR=0.000100
[2025-08-27 06:42:07,627][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044576] [Batch 01456/03080] [00:18:02/00:20:06, 0.743s/it]: train_loss_raw=0.6759, running_loss=0.7354, LR=0.000100
[2025-08-27 06:42:13,485][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044584] [Batch 01464/03080] [00:18:07/00:20:00, 0.743s/it]: train_loss_raw=0.6066, running_loss=0.7344, LR=0.000100
[2025-08-27 06:42:19,443][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044592] [Batch 01472/03080] [00:18:13/00:19:54, 0.743s/it]: train_loss_raw=0.6631, running_loss=0.7352, LR=0.000100
[2025-08-27 06:42:25,258][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044600] [Batch 01480/03080] [00:18:19/00:19:48, 0.743s/it]: train_loss_raw=0.7822, running_loss=0.7365, LR=0.000100
[2025-08-27 06:42:31,015][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044608] [Batch 01488/03080] [00:18:25/00:19:42, 0.743s/it]: train_loss_raw=0.8266, running_loss=0.7387, LR=0.000100
[2025-08-27 06:42:36,891][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044616] [Batch 01496/03080] [00:18:31/00:19:36, 0.743s/it]: train_loss_raw=0.7639, running_loss=0.7383, LR=0.000100
[2025-08-27 06:42:42,700][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044624] [Batch 01504/03080] [00:18:37/00:19:30, 0.743s/it]: train_loss_raw=0.7999, running_loss=0.7394, LR=0.000100
[2025-08-27 06:42:48,595][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044632] [Batch 01512/03080] [00:18:42/00:19:24, 0.743s/it]: train_loss_raw=0.7350, running_loss=0.7382, LR=0.000100
[2025-08-27 06:42:54,520][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044640] [Batch 01520/03080] [00:18:48/00:19:18, 0.743s/it]: train_loss_raw=0.7089, running_loss=0.7374, LR=0.000100
[2025-08-27 06:43:00,575][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044648] [Batch 01528/03080] [00:18:54/00:19:12, 0.743s/it]: train_loss_raw=0.7372, running_loss=0.7387, LR=0.000100
[2025-08-27 06:43:06,589][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044656] [Batch 01536/03080] [00:19:00/00:19:06, 0.743s/it]: train_loss_raw=0.6767, running_loss=0.7388, LR=0.000100
[2025-08-27 06:43:12,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044664] [Batch 01544/03080] [00:19:06/00:19:00, 0.743s/it]: train_loss_raw=0.6855, running_loss=0.7367, LR=0.000100
[2025-08-27 06:43:18,428][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044672] [Batch 01552/03080] [00:19:12/00:18:54, 0.743s/it]: train_loss_raw=0.7273, running_loss=0.7366, LR=0.000100
[2025-08-27 06:43:24,513][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044680] [Batch 01560/03080] [00:19:18/00:18:49, 0.743s/it]: train_loss_raw=0.7531, running_loss=0.7341, LR=0.000100
[2025-08-27 06:43:30,373][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044688] [Batch 01568/03080] [00:19:24/00:18:43, 0.743s/it]: train_loss_raw=0.8077, running_loss=0.7339, LR=0.000100
[2025-08-27 06:43:36,334][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044696] [Batch 01576/03080] [00:19:30/00:18:37, 0.743s/it]: train_loss_raw=0.7523, running_loss=0.7357, LR=0.000100
[2025-08-27 06:43:42,005][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044704] [Batch 01584/03080] [00:19:36/00:18:31, 0.743s/it]: train_loss_raw=0.7167, running_loss=0.7372, LR=0.000100
[2025-08-27 06:43:47,828][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044712] [Batch 01592/03080] [00:19:42/00:18:24, 0.743s/it]: train_loss_raw=0.6827, running_loss=0.7359, LR=0.000100
[2025-08-27 06:43:53,613][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044720] [Batch 01600/03080] [00:19:47/00:18:18, 0.742s/it]: train_loss_raw=0.8631, running_loss=0.7358, LR=0.000100
[2025-08-27 06:43:59,512][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044728] [Batch 01608/03080] [00:19:53/00:18:12, 0.742s/it]: train_loss_raw=0.7268, running_loss=0.7356, LR=0.000100
[2025-08-27 06:44:05,381][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044736] [Batch 01616/03080] [00:19:59/00:18:06, 0.742s/it]: train_loss_raw=0.7406, running_loss=0.7322, LR=0.000100
[2025-08-27 06:44:11,210][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044744] [Batch 01624/03080] [00:20:05/00:18:00, 0.742s/it]: train_loss_raw=0.6722, running_loss=0.7302, LR=0.000100
[2025-08-27 06:44:17,088][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044752] [Batch 01632/03080] [00:20:11/00:17:54, 0.742s/it]: train_loss_raw=0.7755, running_loss=0.7307, LR=0.000100
[2025-08-27 06:44:22,887][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044760] [Batch 01640/03080] [00:20:17/00:17:48, 0.742s/it]: train_loss_raw=0.8786, running_loss=0.7336, LR=0.000100
[2025-08-27 06:44:28,775][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044768] [Batch 01648/03080] [00:20:23/00:17:42, 0.742s/it]: train_loss_raw=0.6272, running_loss=0.7303, LR=0.000100
[2025-08-27 06:44:34,607][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044776] [Batch 01656/03080] [00:20:28/00:17:36, 0.742s/it]: train_loss_raw=0.7396, running_loss=0.7301, LR=0.000100
[2025-08-27 06:44:40,391][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044784] [Batch 01664/03080] [00:20:34/00:17:30, 0.742s/it]: train_loss_raw=0.8012, running_loss=0.7308, LR=0.000100
[2025-08-27 06:44:46,354][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044792] [Batch 01672/03080] [00:20:40/00:17:24, 0.742s/it]: train_loss_raw=0.7507, running_loss=0.7325, LR=0.000100
[2025-08-27 06:44:52,187][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044800] [Batch 01680/03080] [00:20:46/00:17:18, 0.742s/it]: train_loss_raw=0.6885, running_loss=0.7309, LR=0.000100
[2025-08-27 06:44:57,808][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044808] [Batch 01688/03080] [00:20:52/00:17:12, 0.742s/it]: train_loss_raw=0.7749, running_loss=0.7309, LR=0.000100
[2025-08-27 06:45:03,463][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044816] [Batch 01696/03080] [00:20:57/00:17:06, 0.742s/it]: train_loss_raw=0.6553, running_loss=0.7312, LR=0.000100
[2025-08-27 06:45:09,351][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044824] [Batch 01704/03080] [00:21:03/00:17:00, 0.742s/it]: train_loss_raw=0.6854, running_loss=0.7310, LR=0.000100
[2025-08-27 06:45:15,208][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044832] [Batch 01712/03080] [00:21:09/00:16:54, 0.742s/it]: train_loss_raw=0.6908, running_loss=0.7298, LR=0.000100
[2025-08-27 06:45:21,053][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044840] [Batch 01720/03080] [00:21:15/00:16:48, 0.742s/it]: train_loss_raw=0.7389, running_loss=0.7287, LR=0.000100
[2025-08-27 06:45:26,923][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044848] [Batch 01728/03080] [00:21:21/00:16:42, 0.741s/it]: train_loss_raw=0.5837, running_loss=0.7279, LR=0.000100
[2025-08-27 06:45:32,737][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044856] [Batch 01736/03080] [00:21:27/00:16:36, 0.741s/it]: train_loss_raw=0.7442, running_loss=0.7303, LR=0.000100
[2025-08-27 06:45:38,606][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044864] [Batch 01744/03080] [00:21:32/00:16:30, 0.741s/it]: train_loss_raw=0.7093, running_loss=0.7302, LR=0.000100
[2025-08-27 06:45:44,512][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044872] [Batch 01752/03080] [00:21:38/00:16:24, 0.741s/it]: train_loss_raw=0.7025, running_loss=0.7298, LR=0.000100
[2025-08-27 06:45:50,403][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044880] [Batch 01760/03080] [00:21:44/00:16:18, 0.741s/it]: train_loss_raw=0.8255, running_loss=0.7303, LR=0.000100
[2025-08-27 06:45:56,548][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044888] [Batch 01768/03080] [00:21:50/00:16:12, 0.741s/it]: train_loss_raw=0.7780, running_loss=0.7306, LR=0.000100
[2025-08-27 06:46:02,522][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044896] [Batch 01776/03080] [00:21:56/00:16:06, 0.742s/it]: train_loss_raw=0.8229, running_loss=0.7332, LR=0.000100
[2025-08-27 06:46:08,385][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044904] [Batch 01784/03080] [00:22:02/00:16:00, 0.741s/it]: train_loss_raw=0.7164, running_loss=0.7312, LR=0.000100
[2025-08-27 06:46:14,406][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044912] [Batch 01792/03080] [00:22:08/00:15:55, 0.742s/it]: train_loss_raw=0.7106, running_loss=0.7301, LR=0.000100
[2025-08-27 06:46:20,287][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044920] [Batch 01800/03080] [00:22:14/00:15:49, 0.741s/it]: train_loss_raw=0.6996, running_loss=0.7288, LR=0.000100
[2025-08-27 06:46:26,180][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044928] [Batch 01808/03080] [00:22:20/00:15:43, 0.741s/it]: train_loss_raw=0.7841, running_loss=0.7329, LR=0.000100
[2025-08-27 06:46:32,129][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044936] [Batch 01816/03080] [00:22:26/00:15:37, 0.741s/it]: train_loss_raw=0.6919, running_loss=0.7295, LR=0.000100
[2025-08-27 06:46:38,062][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044944] [Batch 01824/03080] [00:22:32/00:15:31, 0.741s/it]: train_loss_raw=0.7576, running_loss=0.7312, LR=0.000100
[2025-08-27 06:46:44,188][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044952] [Batch 01832/03080] [00:22:38/00:15:25, 0.742s/it]: train_loss_raw=0.7207, running_loss=0.7317, LR=0.000100
[2025-08-27 06:46:50,132][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044960] [Batch 01840/03080] [00:22:44/00:15:19, 0.742s/it]: train_loss_raw=0.7988, running_loss=0.7333, LR=0.000100
[2025-08-27 06:46:56,100][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044968] [Batch 01848/03080] [00:22:50/00:15:13, 0.742s/it]: train_loss_raw=0.7278, running_loss=0.7342, LR=0.000100
[2025-08-27 06:47:01,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044976] [Batch 01856/03080] [00:22:56/00:15:07, 0.742s/it]: train_loss_raw=0.6693, running_loss=0.7307, LR=0.000100
[2025-08-27 06:47:07,801][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044984] [Batch 01864/03080] [00:23:02/00:15:01, 0.742s/it]: train_loss_raw=0.7375, running_loss=0.7305, LR=0.000100
[2025-08-27 06:47:13,683][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 044992] [Batch 01872/03080] [00:23:08/00:14:55, 0.741s/it]: train_loss_raw=0.6239, running_loss=0.7297, LR=0.000100
[2025-08-27 06:47:19,587][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045000] [Batch 01880/03080] [00:23:13/00:14:49, 0.741s/it]: train_loss_raw=0.6731, running_loss=0.7290, LR=0.000100
[2025-08-27 06:47:25,325][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045008] [Batch 01888/03080] [00:23:19/00:14:43, 0.741s/it]: train_loss_raw=0.6845, running_loss=0.7257, LR=0.000100
[2025-08-27 06:47:31,196][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045016] [Batch 01896/03080] [00:23:25/00:14:37, 0.741s/it]: train_loss_raw=0.7571, running_loss=0.7245, LR=0.000100
[2025-08-27 06:47:37,260][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045024] [Batch 01904/03080] [00:23:31/00:14:31, 0.741s/it]: train_loss_raw=0.6295, running_loss=0.7243, LR=0.000100
[2025-08-27 06:47:43,424][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045032] [Batch 01912/03080] [00:23:37/00:14:26, 0.742s/it]: train_loss_raw=0.7925, running_loss=0.7247, LR=0.000100
[2025-08-27 06:47:49,597][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045040] [Batch 01920/03080] [00:23:43/00:14:20, 0.742s/it]: train_loss_raw=0.6365, running_loss=0.7242, LR=0.000100
[2025-08-27 06:47:55,543][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045048] [Batch 01928/03080] [00:23:49/00:14:14, 0.742s/it]: train_loss_raw=0.7098, running_loss=0.7233, LR=0.000100
[2025-08-27 06:48:01,603][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045056] [Batch 01936/03080] [00:23:55/00:14:08, 0.742s/it]: train_loss_raw=0.7196, running_loss=0.7238, LR=0.000100
[2025-08-27 06:48:07,636][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045064] [Batch 01944/03080] [00:24:02/00:14:02, 0.742s/it]: train_loss_raw=0.8484, running_loss=0.7251, LR=0.000100
[2025-08-27 06:48:13,429][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045072] [Batch 01952/03080] [00:24:07/00:13:56, 0.742s/it]: train_loss_raw=0.6407, running_loss=0.7238, LR=0.000100
[2025-08-27 06:48:19,266][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045080] [Batch 01960/03080] [00:24:13/00:13:50, 0.742s/it]: train_loss_raw=0.7570, running_loss=0.7222, LR=0.000100
[2025-08-27 06:48:25,144][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045088] [Batch 01968/03080] [00:24:19/00:13:44, 0.742s/it]: train_loss_raw=0.7065, running_loss=0.7216, LR=0.000100
[2025-08-27 06:48:31,427][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045096] [Batch 01976/03080] [00:24:25/00:13:38, 0.742s/it]: train_loss_raw=0.7527, running_loss=0.7218, LR=0.000100
[2025-08-27 06:48:37,439][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045104] [Batch 01984/03080] [00:24:31/00:13:33, 0.742s/it]: train_loss_raw=0.6812, running_loss=0.7184, LR=0.000100
[2025-08-27 06:48:43,256][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045112] [Batch 01992/03080] [00:24:37/00:13:27, 0.742s/it]: train_loss_raw=0.6606, running_loss=0.7200, LR=0.000100
[2025-08-27 06:48:49,036][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045120] [Batch 02000/03080] [00:24:43/00:13:21, 0.742s/it]: train_loss_raw=0.6773, running_loss=0.7201, LR=0.000100
[2025-08-27 06:48:54,895][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045128] [Batch 02008/03080] [00:24:49/00:13:15, 0.742s/it]: train_loss_raw=0.6831, running_loss=0.7189, LR=0.000100
[2025-08-27 06:49:00,941][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045136] [Batch 02016/03080] [00:24:55/00:13:09, 0.742s/it]: train_loss_raw=0.7454, running_loss=0.7179, LR=0.000100
[2025-08-27 06:49:06,841][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045144] [Batch 02024/03080] [00:25:01/00:13:03, 0.742s/it]: train_loss_raw=0.7225, running_loss=0.7185, LR=0.000100
[2025-08-27 06:49:12,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045152] [Batch 02032/03080] [00:25:07/00:12:57, 0.742s/it]: train_loss_raw=0.7161, running_loss=0.7180, LR=0.000100
[2025-08-27 06:49:18,743][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045160] [Batch 02040/03080] [00:25:13/00:12:51, 0.742s/it]: train_loss_raw=0.7063, running_loss=0.7180, LR=0.000100
[2025-08-27 06:49:24,765][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045168] [Batch 02048/03080] [00:25:19/00:12:45, 0.742s/it]: train_loss_raw=0.8615, running_loss=0.7235, LR=0.000100
[2025-08-27 06:49:30,329][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045176] [Batch 02056/03080] [00:25:24/00:12:39, 0.742s/it]: train_loss_raw=0.7356, running_loss=0.7226, LR=0.000100
[2025-08-27 06:49:36,187][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045184] [Batch 02064/03080] [00:25:30/00:12:33, 0.742s/it]: train_loss_raw=0.7432, running_loss=0.7221, LR=0.000100
[2025-08-27 06:49:42,093][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045192] [Batch 02072/03080] [00:25:36/00:12:27, 0.742s/it]: train_loss_raw=0.7097, running_loss=0.7223, LR=0.000100
[2025-08-27 06:49:48,106][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045200] [Batch 02080/03080] [00:25:42/00:12:21, 0.742s/it]: train_loss_raw=0.6996, running_loss=0.7231, LR=0.000100
[2025-08-27 06:49:54,111][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045208] [Batch 02088/03080] [00:25:48/00:12:15, 0.742s/it]: train_loss_raw=0.7556, running_loss=0.7244, LR=0.000100
[2025-08-27 06:50:00,254][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045216] [Batch 02096/03080] [00:25:54/00:12:09, 0.742s/it]: train_loss_raw=0.7832, running_loss=0.7225, LR=0.000100
[2025-08-27 06:50:06,300][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045224] [Batch 02104/03080] [00:26:00/00:12:03, 0.742s/it]: train_loss_raw=0.7146, running_loss=0.7231, LR=0.000100
[2025-08-27 06:50:12,374][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045232] [Batch 02112/03080] [00:26:06/00:11:58, 0.742s/it]: train_loss_raw=0.6541, running_loss=0.7205, LR=0.000100
[2025-08-27 06:50:18,550][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045240] [Batch 02120/03080] [00:26:12/00:11:52, 0.742s/it]: train_loss_raw=0.6892, running_loss=0.7192, LR=0.000100
[2025-08-27 06:50:24,482][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045248] [Batch 02128/03080] [00:26:18/00:11:46, 0.742s/it]: train_loss_raw=0.6690, running_loss=0.7194, LR=0.000100
[2025-08-27 06:50:30,566][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045256] [Batch 02136/03080] [00:26:24/00:11:40, 0.742s/it]: train_loss_raw=0.6936, running_loss=0.7202, LR=0.000100
[2025-08-27 06:50:36,449][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045264] [Batch 02144/03080] [00:26:30/00:11:34, 0.742s/it]: train_loss_raw=0.7102, running_loss=0.7205, LR=0.000100
[2025-08-27 06:50:42,430][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045272] [Batch 02152/03080] [00:26:36/00:11:28, 0.742s/it]: train_loss_raw=0.8752, running_loss=0.7229, LR=0.000100
[2025-08-27 06:50:48,576][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045280] [Batch 02160/03080] [00:26:42/00:11:22, 0.742s/it]: train_loss_raw=0.6910, running_loss=0.7224, LR=0.000100
[2025-08-27 06:50:54,535][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045288] [Batch 02168/03080] [00:26:48/00:11:16, 0.742s/it]: train_loss_raw=0.6637, running_loss=0.7197, LR=0.000100
[2025-08-27 06:51:00,422][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045296] [Batch 02176/03080] [00:26:54/00:11:10, 0.742s/it]: train_loss_raw=0.7878, running_loss=0.7204, LR=0.000100
[2025-08-27 06:51:06,220][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045304] [Batch 02184/03080] [00:27:00/00:11:04, 0.742s/it]: train_loss_raw=0.6611, running_loss=0.7159, LR=0.000100
[2025-08-27 06:51:11,940][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045312] [Batch 02192/03080] [00:27:06/00:10:58, 0.742s/it]: train_loss_raw=0.6545, running_loss=0.7169, LR=0.000100
[2025-08-27 06:51:17,670][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045320] [Batch 02200/03080] [00:27:12/00:10:52, 0.742s/it]: train_loss_raw=0.7429, running_loss=0.7166, LR=0.000100
[2025-08-27 06:51:23,800][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045328] [Batch 02208/03080] [00:27:18/00:10:46, 0.742s/it]: train_loss_raw=0.7030, running_loss=0.7157, LR=0.000100
[2025-08-27 06:51:29,911][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045336] [Batch 02216/03080] [00:27:24/00:10:41, 0.742s/it]: train_loss_raw=0.6970, running_loss=0.7155, LR=0.000100
[2025-08-27 06:51:35,998][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045344] [Batch 02224/03080] [00:27:30/00:10:35, 0.742s/it]: train_loss_raw=0.6618, running_loss=0.7136, LR=0.000100
[2025-08-27 06:51:42,067][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045352] [Batch 02232/03080] [00:27:36/00:10:29, 0.742s/it]: train_loss_raw=0.6610, running_loss=0.7131, LR=0.000100
[2025-08-27 06:51:48,185][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045360] [Batch 02240/03080] [00:27:42/00:10:23, 0.742s/it]: train_loss_raw=0.6601, running_loss=0.7137, LR=0.000100
[2025-08-27 06:51:54,265][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045368] [Batch 02248/03080] [00:27:48/00:10:17, 0.742s/it]: train_loss_raw=0.6503, running_loss=0.7144, LR=0.000100
[2025-08-27 06:52:00,340][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045376] [Batch 02256/03080] [00:27:54/00:10:11, 0.742s/it]: train_loss_raw=0.7269, running_loss=0.7123, LR=0.000100
[2025-08-27 06:52:06,403][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045384] [Batch 02264/03080] [00:28:00/00:10:05, 0.742s/it]: train_loss_raw=0.8061, running_loss=0.7130, LR=0.000100
[2025-08-27 06:52:12,509][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045392] [Batch 02272/03080] [00:28:06/00:09:59, 0.742s/it]: train_loss_raw=0.7364, running_loss=0.7152, LR=0.000100
[2025-08-27 06:52:18,637][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045400] [Batch 02280/03080] [00:28:13/00:09:54, 0.743s/it]: train_loss_raw=0.5657, running_loss=0.7128, LR=0.000100
[2025-08-27 06:52:24,499][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045408] [Batch 02288/03080] [00:28:18/00:09:48, 0.743s/it]: train_loss_raw=0.7451, running_loss=0.7103, LR=0.000100
[2025-08-27 06:52:30,454][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045416] [Batch 02296/03080] [00:28:24/00:09:42, 0.743s/it]: train_loss_raw=0.8216, running_loss=0.7115, LR=0.000100
[2025-08-27 06:52:36,562][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045424] [Batch 02304/03080] [00:28:30/00:09:36, 0.743s/it]: train_loss_raw=0.7838, running_loss=0.7151, LR=0.000100
[2025-08-27 06:52:42,618][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045432] [Batch 02312/03080] [00:28:37/00:09:30, 0.743s/it]: train_loss_raw=0.7337, running_loss=0.7140, LR=0.000100
[2025-08-27 06:52:48,690][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045440] [Batch 02320/03080] [00:28:43/00:09:24, 0.743s/it]: train_loss_raw=0.6904, running_loss=0.7164, LR=0.000100
[2025-08-27 06:52:54,773][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045448] [Batch 02328/03080] [00:28:49/00:09:18, 0.743s/it]: train_loss_raw=0.7644, running_loss=0.7184, LR=0.000100
[2025-08-27 06:53:00,746][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045456] [Batch 02336/03080] [00:28:55/00:09:12, 0.743s/it]: train_loss_raw=0.7834, running_loss=0.7221, LR=0.000100
[2025-08-27 06:53:06,706][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045464] [Batch 02344/03080] [00:29:01/00:09:06, 0.743s/it]: train_loss_raw=0.6733, running_loss=0.7231, LR=0.000100
[2025-08-27 06:53:12,685][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045472] [Batch 02352/03080] [00:29:07/00:09:00, 0.743s/it]: train_loss_raw=0.5893, running_loss=0.7203, LR=0.000100
[2025-08-27 06:53:18,803][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045480] [Batch 02360/03080] [00:29:13/00:08:54, 0.743s/it]: train_loss_raw=0.6710, running_loss=0.7176, LR=0.000100
[2025-08-27 06:53:24,917][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045488] [Batch 02368/03080] [00:29:19/00:08:48, 0.743s/it]: train_loss_raw=0.7292, running_loss=0.7168, LR=0.000100
[2025-08-27 06:53:30,771][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045496] [Batch 02376/03080] [00:29:25/00:08:43, 0.743s/it]: train_loss_raw=0.6610, running_loss=0.7183, LR=0.000100
[2025-08-27 06:53:36,590][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045504] [Batch 02384/03080] [00:29:30/00:08:37, 0.743s/it]: train_loss_raw=0.8271, running_loss=0.7194, LR=0.000100
[2025-08-27 06:53:42,593][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045512] [Batch 02392/03080] [00:29:36/00:08:31, 0.743s/it]: train_loss_raw=0.7656, running_loss=0.7186, LR=0.000100
[2025-08-27 06:53:48,703][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045520] [Batch 02400/03080] [00:29:43/00:08:25, 0.743s/it]: train_loss_raw=0.7749, running_loss=0.7142, LR=0.000100
[2025-08-27 06:53:54,778][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045528] [Batch 02408/03080] [00:29:49/00:08:19, 0.743s/it]: train_loss_raw=0.6160, running_loss=0.7137, LR=0.000100
[2025-08-27 06:54:00,839][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045536] [Batch 02416/03080] [00:29:55/00:08:13, 0.743s/it]: train_loss_raw=0.7011, running_loss=0.7132, LR=0.000100
[2025-08-27 06:54:06,871][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045544] [Batch 02424/03080] [00:30:01/00:08:07, 0.743s/it]: train_loss_raw=0.7678, running_loss=0.7146, LR=0.000100
[2025-08-27 06:54:12,934][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045552] [Batch 02432/03080] [00:30:07/00:08:01, 0.743s/it]: train_loss_raw=0.6602, running_loss=0.7112, LR=0.000100
[2025-08-27 06:54:19,022][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045560] [Batch 02440/03080] [00:30:13/00:07:55, 0.743s/it]: train_loss_raw=0.7234, running_loss=0.7107, LR=0.000100
[2025-08-27 06:54:25,099][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045568] [Batch 02448/03080] [00:30:19/00:07:49, 0.743s/it]: train_loss_raw=0.7582, running_loss=0.7086, LR=0.000100
[2025-08-27 06:54:31,222][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045576] [Batch 02456/03080] [00:30:25/00:07:43, 0.743s/it]: train_loss_raw=0.6783, running_loss=0.7076, LR=0.000100
[2025-08-27 06:54:37,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045584] [Batch 02464/03080] [00:30:31/00:07:37, 0.743s/it]: train_loss_raw=0.7254, running_loss=0.7051, LR=0.000100
[2025-08-27 06:54:43,422][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045592] [Batch 02472/03080] [00:30:37/00:07:32, 0.743s/it]: train_loss_raw=0.7541, running_loss=0.7055, LR=0.000100
[2025-08-27 06:54:49,537][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045600] [Batch 02480/03080] [00:30:43/00:07:26, 0.744s/it]: train_loss_raw=0.7533, running_loss=0.7069, LR=0.000100
[2025-08-27 06:54:55,674][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045608] [Batch 02488/03080] [00:30:50/00:07:20, 0.744s/it]: train_loss_raw=0.7638, running_loss=0.7088, LR=0.000100
[2025-08-27 06:55:01,775][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045616] [Batch 02496/03080] [00:30:56/00:07:14, 0.744s/it]: train_loss_raw=0.7107, running_loss=0.7085, LR=0.000100
[2025-08-27 06:55:07,836][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045624] [Batch 02504/03080] [00:31:02/00:07:08, 0.744s/it]: train_loss_raw=0.6133, running_loss=0.7099, LR=0.000100
[2025-08-27 06:55:13,945][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045632] [Batch 02512/03080] [00:31:08/00:07:02, 0.744s/it]: train_loss_raw=0.6541, running_loss=0.7089, LR=0.000100
[2025-08-27 06:55:19,999][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045640] [Batch 02520/03080] [00:31:14/00:06:56, 0.744s/it]: train_loss_raw=0.5927, running_loss=0.7081, LR=0.000100
[2025-08-27 06:55:26,056][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045648] [Batch 02528/03080] [00:31:20/00:06:50, 0.744s/it]: train_loss_raw=0.6811, running_loss=0.7070, LR=0.000100
[2025-08-27 06:55:32,081][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045656] [Batch 02536/03080] [00:31:26/00:06:44, 0.744s/it]: train_loss_raw=0.6436, running_loss=0.7039, LR=0.000100
[2025-08-27 06:55:38,137][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045664] [Batch 02544/03080] [00:31:32/00:06:38, 0.744s/it]: train_loss_raw=0.6963, running_loss=0.7038, LR=0.000100
[2025-08-27 06:55:44,688][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045672] [Batch 02552/03080] [00:31:39/00:06:32, 0.744s/it]: train_loss_raw=0.7882, running_loss=0.7025, LR=0.000100
[2025-08-27 06:55:50,769][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045680] [Batch 02560/03080] [00:31:45/00:06:26, 0.744s/it]: train_loss_raw=0.7387, running_loss=0.7029, LR=0.000100
[2025-08-27 06:55:56,848][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045688] [Batch 02568/03080] [00:31:51/00:06:21, 0.744s/it]: train_loss_raw=0.7350, running_loss=0.7048, LR=0.000100
[2025-08-27 06:56:02,959][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045696] [Batch 02576/03080] [00:31:57/00:06:15, 0.744s/it]: train_loss_raw=0.6356, running_loss=0.7052, LR=0.000100
[2025-08-27 06:56:09,025][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045704] [Batch 02584/03080] [00:32:03/00:06:09, 0.744s/it]: train_loss_raw=0.6914, running_loss=0.7058, LR=0.000100
[2025-08-27 06:56:15,144][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045712] [Batch 02592/03080] [00:32:09/00:06:03, 0.744s/it]: train_loss_raw=0.6986, running_loss=0.7041, LR=0.000100
[2025-08-27 06:56:21,182][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045720] [Batch 02600/03080] [00:32:15/00:05:57, 0.744s/it]: train_loss_raw=0.6302, running_loss=0.7017, LR=0.000100
[2025-08-27 06:56:27,219][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045728] [Batch 02608/03080] [00:32:21/00:05:51, 0.744s/it]: train_loss_raw=0.7879, running_loss=0.7042, LR=0.000100
[2025-08-27 06:56:33,269][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045736] [Batch 02616/03080] [00:32:27/00:05:45, 0.745s/it]: train_loss_raw=0.7641, running_loss=0.7037, LR=0.000100
[2025-08-27 06:56:39,320][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045744] [Batch 02624/03080] [00:32:33/00:05:39, 0.745s/it]: train_loss_raw=0.6796, running_loss=0.7053, LR=0.000100
[2025-08-27 06:56:45,428][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045752] [Batch 02632/03080] [00:32:39/00:05:33, 0.745s/it]: train_loss_raw=0.7663, running_loss=0.7069, LR=0.000100
[2025-08-27 06:56:51,528][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045760] [Batch 02640/03080] [00:32:45/00:05:27, 0.745s/it]: train_loss_raw=0.7332, running_loss=0.7044, LR=0.000100
[2025-08-27 06:56:57,619][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045768] [Batch 02648/03080] [00:32:52/00:05:21, 0.745s/it]: train_loss_raw=0.8099, running_loss=0.7093, LR=0.000100
[2025-08-27 06:57:03,683][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045776] [Batch 02656/03080] [00:32:58/00:05:15, 0.745s/it]: train_loss_raw=0.7682, running_loss=0.7110, LR=0.000100
[2025-08-27 06:57:09,765][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045784] [Batch 02664/03080] [00:33:04/00:05:09, 0.745s/it]: train_loss_raw=0.7114, running_loss=0.7104, LR=0.000100
[2025-08-27 06:57:15,850][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045792] [Batch 02672/03080] [00:33:10/00:05:03, 0.745s/it]: train_loss_raw=0.6966, running_loss=0.7090, LR=0.000100
[2025-08-27 06:57:21,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045800] [Batch 02680/03080] [00:33:16/00:04:57, 0.745s/it]: train_loss_raw=0.7147, running_loss=0.7063, LR=0.000100
[2025-08-27 06:57:28,040][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045808] [Batch 02688/03080] [00:33:22/00:04:52, 0.745s/it]: train_loss_raw=0.6089, running_loss=0.7015, LR=0.000100
[2025-08-27 06:57:34,164][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045816] [Batch 02696/03080] [00:33:28/00:04:46, 0.745s/it]: train_loss_raw=0.6952, running_loss=0.7009, LR=0.000100
[2025-08-27 06:57:40,231][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045824] [Batch 02704/03080] [00:33:34/00:04:40, 0.745s/it]: train_loss_raw=0.6158, running_loss=0.7014, LR=0.000100
[2025-08-27 06:57:46,348][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045832] [Batch 02712/03080] [00:33:40/00:04:34, 0.745s/it]: train_loss_raw=0.7254, running_loss=0.7010, LR=0.000100
[2025-08-27 06:57:52,490][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045840] [Batch 02720/03080] [00:33:46/00:04:28, 0.745s/it]: train_loss_raw=0.7101, running_loss=0.7005, LR=0.000100
[2025-08-27 06:57:58,575][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045848] [Batch 02728/03080] [00:33:52/00:04:22, 0.745s/it]: train_loss_raw=0.7970, running_loss=0.7036, LR=0.000100
[2025-08-27 06:58:04,627][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045856] [Batch 02736/03080] [00:33:59/00:04:16, 0.745s/it]: train_loss_raw=0.6725, running_loss=0.7021, LR=0.000100
[2025-08-27 06:58:10,693][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045864] [Batch 02744/03080] [00:34:05/00:04:10, 0.745s/it]: train_loss_raw=0.7501, running_loss=0.7047, LR=0.000100
[2025-08-27 06:58:16,746][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045872] [Batch 02752/03080] [00:34:11/00:04:04, 0.745s/it]: train_loss_raw=0.7966, running_loss=0.7063, LR=0.000100
[2025-08-27 06:58:22,744][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045880] [Batch 02760/03080] [00:34:17/00:03:58, 0.745s/it]: train_loss_raw=0.7053, running_loss=0.7050, LR=0.000100
[2025-08-27 06:58:28,894][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045888] [Batch 02768/03080] [00:34:23/00:03:52, 0.745s/it]: train_loss_raw=0.6762, running_loss=0.7074, LR=0.000100
[2025-08-27 06:58:35,057][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045896] [Batch 02776/03080] [00:34:29/00:03:46, 0.745s/it]: train_loss_raw=0.6372, running_loss=0.7057, LR=0.000100
[2025-08-27 06:58:41,222][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045904] [Batch 02784/03080] [00:34:35/00:03:40, 0.746s/it]: train_loss_raw=0.7478, running_loss=0.7057, LR=0.000100
[2025-08-27 06:58:47,353][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045912] [Batch 02792/03080] [00:34:41/00:03:34, 0.746s/it]: train_loss_raw=0.6071, running_loss=0.7044, LR=0.000100
[2025-08-27 06:58:53,504][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045920] [Batch 02800/03080] [00:34:47/00:03:28, 0.746s/it]: train_loss_raw=0.7014, running_loss=0.7040, LR=0.000100
[2025-08-27 06:58:59,641][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045928] [Batch 02808/03080] [00:34:54/00:03:22, 0.746s/it]: train_loss_raw=0.6470, running_loss=0.7033, LR=0.000100
[2025-08-27 06:59:05,747][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045936] [Batch 02816/03080] [00:35:00/00:03:16, 0.746s/it]: train_loss_raw=0.7392, running_loss=0.7044, LR=0.000100
[2025-08-27 06:59:11,815][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045944] [Batch 02824/03080] [00:35:06/00:03:10, 0.746s/it]: train_loss_raw=0.6897, running_loss=0.7033, LR=0.000100
[2025-08-27 06:59:17,887][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045952] [Batch 02832/03080] [00:35:12/00:03:04, 0.746s/it]: train_loss_raw=0.6453, running_loss=0.7025, LR=0.000100
[2025-08-27 06:59:23,931][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045960] [Batch 02840/03080] [00:35:18/00:02:59, 0.746s/it]: train_loss_raw=0.7014, running_loss=0.7021, LR=0.000100
[2025-08-27 06:59:29,948][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045968] [Batch 02848/03080] [00:35:24/00:02:53, 0.746s/it]: train_loss_raw=0.6240, running_loss=0.7007, LR=0.000100
[2025-08-27 06:59:36,040][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045976] [Batch 02856/03080] [00:35:30/00:02:47, 0.746s/it]: train_loss_raw=0.6428, running_loss=0.7005, LR=0.000100
[2025-08-27 06:59:42,080][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045984] [Batch 02864/03080] [00:35:36/00:02:41, 0.746s/it]: train_loss_raw=0.7584, running_loss=0.7013, LR=0.000100
[2025-08-27 06:59:48,159][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 045992] [Batch 02872/03080] [00:35:42/00:02:35, 0.746s/it]: train_loss_raw=0.7707, running_loss=0.7002, LR=0.000100
[2025-08-27 06:59:54,274][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046000] [Batch 02880/03080] [00:35:48/00:02:29, 0.746s/it]: train_loss_raw=0.7180, running_loss=0.6996, LR=0.000100
[2025-08-27 07:00:03,651][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046008] [Batch 02888/03080] [00:35:58/00:02:23, 0.747s/it]: train_loss_raw=0.7496, running_loss=0.6997, LR=0.000100
[2025-08-27 07:00:09,374][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046016] [Batch 02896/03080] [00:36:03/00:02:17, 0.747s/it]: train_loss_raw=0.6825, running_loss=0.6989, LR=0.000100
[2025-08-27 07:00:15,203][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046024] [Batch 02904/03080] [00:36:09/00:02:11, 0.747s/it]: train_loss_raw=0.6907, running_loss=0.7019, LR=0.000100
[2025-08-27 07:00:21,074][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046032] [Batch 02912/03080] [00:36:15/00:02:05, 0.747s/it]: train_loss_raw=0.6441, running_loss=0.7026, LR=0.000100
[2025-08-27 07:00:26,988][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046040] [Batch 02920/03080] [00:36:21/00:01:59, 0.747s/it]: train_loss_raw=0.7777, running_loss=0.7025, LR=0.000100
[2025-08-27 07:00:32,873][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046048] [Batch 02928/03080] [00:36:27/00:01:53, 0.747s/it]: train_loss_raw=0.7072, running_loss=0.7021, LR=0.000100
[2025-08-27 07:00:38,868][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046056] [Batch 02936/03080] [00:36:33/00:01:47, 0.747s/it]: train_loss_raw=0.6599, running_loss=0.7009, LR=0.000100
[2025-08-27 07:00:44,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046064] [Batch 02944/03080] [00:36:39/00:01:41, 0.747s/it]: train_loss_raw=0.7004, running_loss=0.7029, LR=0.000100
[2025-08-27 07:00:50,845][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046072] [Batch 02952/03080] [00:36:45/00:01:35, 0.747s/it]: train_loss_raw=0.6021, running_loss=0.7018, LR=0.000100
[2025-08-27 07:00:57,014][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046080] [Batch 02960/03080] [00:36:51/00:01:29, 0.747s/it]: train_loss_raw=0.7637, running_loss=0.7037, LR=0.000100
[2025-08-27 07:01:03,140][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046088] [Batch 02968/03080] [00:36:57/00:01:23, 0.747s/it]: train_loss_raw=0.6471, running_loss=0.7025, LR=0.000100
[2025-08-27 07:01:09,282][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046096] [Batch 02976/03080] [00:37:03/00:01:17, 0.747s/it]: train_loss_raw=0.7925, running_loss=0.7033, LR=0.000100
[2025-08-27 07:01:15,325][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046104] [Batch 02984/03080] [00:37:09/00:01:11, 0.747s/it]: train_loss_raw=0.7525, running_loss=0.7037, LR=0.000100
[2025-08-27 07:01:21,389][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046112] [Batch 02992/03080] [00:37:15/00:01:05, 0.747s/it]: train_loss_raw=0.6049, running_loss=0.7053, LR=0.000100
[2025-08-27 07:01:27,436][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046120] [Batch 03000/03080] [00:37:21/00:00:59, 0.747s/it]: train_loss_raw=0.6921, running_loss=0.7048, LR=0.000100
[2025-08-27 07:01:33,533][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046128] [Batch 03008/03080] [00:37:27/00:00:53, 0.747s/it]: train_loss_raw=0.6292, running_loss=0.7040, LR=0.000100
[2025-08-27 07:01:39,674][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046136] [Batch 03016/03080] [00:37:34/00:00:47, 0.747s/it]: train_loss_raw=0.5863, running_loss=0.7015, LR=0.000100
[2025-08-27 07:01:45,760][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046144] [Batch 03024/03080] [00:37:40/00:00:41, 0.747s/it]: train_loss_raw=0.7410, running_loss=0.7002, LR=0.000100
[2025-08-27 07:01:51,844][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046152] [Batch 03032/03080] [00:37:46/00:00:35, 0.747s/it]: train_loss_raw=0.8065, running_loss=0.7001, LR=0.000100
[2025-08-27 07:01:57,905][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046160] [Batch 03040/03080] [00:37:52/00:00:29, 0.747s/it]: train_loss_raw=0.7005, running_loss=0.6994, LR=0.000100
[2025-08-27 07:02:04,008][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046168] [Batch 03048/03080] [00:37:58/00:00:23, 0.748s/it]: train_loss_raw=0.7399, running_loss=0.6987, LR=0.000100
[2025-08-27 07:02:10,081][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046176] [Batch 03056/03080] [00:38:04/00:00:17, 0.748s/it]: train_loss_raw=0.5484, running_loss=0.6963, LR=0.000100
[2025-08-27 07:02:16,120][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046184] [Batch 03064/03080] [00:38:10/00:00:11, 0.748s/it]: train_loss_raw=0.6957, running_loss=0.6961, LR=0.000100
[2025-08-27 07:02:22,219][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046192] [Batch 03072/03080] [00:38:16/00:00:05, 0.748s/it]: train_loss_raw=0.7229, running_loss=0.6953, LR=0.000100
[2025-08-27 07:02:28,251][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 046200] [Batch 03080/03080] [00:38:22/00:00:00, 0.748s/it]: train_loss_raw=0.7170, running_loss=0.6980, LR=0.000100
[2025-08-27 07:02:28,781][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-27 07:02:40,601][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00007/00310] [00:00:11/00:07:26, 1.477s/it]
[2025-08-27 07:02:52,669][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00015/00310] [00:00:23/00:07:18, 1.493s/it]
[2025-08-27 07:03:05,140][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00023/00310] [00:00:36/00:07:13, 1.515s/it]
[2025-08-27 07:03:17,612][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00031/00310] [00:00:48/00:07:04, 1.526s/it]
[2025-08-27 07:03:30,351][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00039/00310] [00:01:01/00:06:55, 1.539s/it]
[2025-08-27 07:03:42,726][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00047/00310] [00:01:13/00:06:43, 1.541s/it]
[2025-08-27 07:03:55,179][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00055/00310] [00:01:26/00:06:31, 1.543s/it]
[2025-08-27 07:04:07,284][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00063/00310] [00:01:38/00:06:18, 1.539s/it]
[2025-08-27 07:04:19,716][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00071/00310] [00:01:50/00:06:06, 1.541s/it]
[2025-08-27 07:04:31,958][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00079/00310] [00:02:03/00:05:54, 1.540s/it]
[2025-08-27 07:04:44,268][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00087/00310] [00:02:15/00:05:41, 1.540s/it]
[2025-08-27 07:04:56,769][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00095/00310] [00:02:27/00:05:29, 1.542s/it]
[2025-08-27 07:05:09,154][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00103/00310] [00:02:40/00:05:17, 1.542s/it]
[2025-08-27 07:05:21,553][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00111/00310] [00:02:52/00:05:05, 1.543s/it]
[2025-08-27 07:05:33,642][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00119/00310] [00:03:04/00:04:52, 1.541s/it]
[2025-08-27 07:05:45,863][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00127/00310] [00:03:17/00:04:40, 1.540s/it]
[2025-08-27 07:05:57,766][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00135/00310] [00:03:28/00:04:27, 1.537s/it]
[2025-08-27 07:06:09,936][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00143/00310] [00:03:41/00:04:14, 1.536s/it]
[2025-08-27 07:06:21,102][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00151/00310] [00:03:52/00:04:01, 1.528s/it]
[2025-08-27 07:06:31,917][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00159/00310] [00:04:03/00:03:47, 1.520s/it]
[2025-08-27 07:06:44,971][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00167/00310] [00:04:16/00:03:36, 1.525s/it]
[2025-08-27 07:06:55,492][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00175/00310] [00:04:26/00:03:23, 1.515s/it]
[2025-08-27 07:07:07,065][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00183/00310] [00:04:38/00:03:10, 1.512s/it]
[2025-08-27 07:07:18,939][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00191/00310] [00:04:50/00:02:58, 1.511s/it]
[2025-08-27 07:07:30,873][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00199/00310] [00:05:02/00:02:46, 1.510s/it]
[2025-08-27 07:07:42,609][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00207/00310] [00:05:13/00:02:33, 1.509s/it]
[2025-08-27 07:07:54,359][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00215/00310] [00:05:25/00:02:21, 1.507s/it]
[2025-08-27 07:08:06,255][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00223/00310] [00:05:37/00:02:09, 1.507s/it]
[2025-08-27 07:08:18,466][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00231/00310] [00:05:49/00:01:57, 1.507s/it]
[2025-08-27 07:08:30,245][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00239/00310] [00:06:01/00:01:45, 1.506s/it]
[2025-08-27 07:08:41,894][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00247/00310] [00:06:13/00:01:33, 1.504s/it]
[2025-08-27 07:08:53,941][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00255/00310] [00:06:25/00:01:21, 1.505s/it]
[2025-08-27 07:09:06,586][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00263/00310] [00:06:37/00:01:09, 1.507s/it]
[2025-08-27 07:09:18,470][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00271/00310] [00:06:49/00:00:57, 1.506s/it]
[2025-08-27 07:09:30,409][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00279/00310] [00:07:01/00:00:45, 1.506s/it]
[2025-08-27 07:09:42,925][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00287/00310] [00:07:14/00:00:33, 1.507s/it]
[2025-08-27 07:09:54,594][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00295/00310] [00:07:25/00:00:21, 1.506s/it]
[2025-08-27 07:10:06,914][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 046201] [Batch 00303/00310] [00:07:38/00:00:09, 1.507s/it]
[2025-08-27 07:10:15,766][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=0.69795, valid_loss=1.68118
[2025-08-27 07:10:15,767][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-27 07:10:15,767][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.611
[2025-08-27 07:10:15,767][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.075
[2025-08-27 07:10:15,767][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.077
[2025-08-27 07:10:15,767][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.032
[2025-08-27 07:10:15,777][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 11:43:29, remaining time 11:43:29, 00:46:53 per epoch
[2025-08-27 07:10:21,401][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046208] [Batch 00008/03080] [00:00:05/00:34:17, 0.670s/it]: train_loss_raw=0.7470, running_loss=0.7201, LR=0.000100
[2025-08-27 07:10:27,495][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046216] [Batch 00016/03080] [00:00:11/00:36:33, 0.716s/it]: train_loss_raw=0.6782, running_loss=0.7183, LR=0.000100
[2025-08-27 07:10:33,469][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046224] [Batch 00024/03080] [00:00:17/00:36:58, 0.726s/it]: train_loss_raw=0.6783, running_loss=0.7154, LR=0.000100
[2025-08-27 07:10:39,455][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046232] [Batch 00032/03080] [00:00:23/00:37:10, 0.732s/it]: train_loss_raw=0.6270, running_loss=0.7134, LR=0.000100
[2025-08-27 07:10:45,373][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046240] [Batch 00040/03080] [00:00:29/00:37:09, 0.733s/it]: train_loss_raw=0.5818, running_loss=0.7102, LR=0.000100
[2025-08-27 07:10:51,295][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046248] [Batch 00048/03080] [00:00:35/00:37:06, 0.734s/it]: train_loss_raw=0.6479, running_loss=0.7082, LR=0.000100
[2025-08-27 07:10:57,254][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046256] [Batch 00056/03080] [00:00:41/00:37:05, 0.736s/it]: train_loss_raw=0.6702, running_loss=0.7081, LR=0.000100
[2025-08-27 07:11:03,399][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046264] [Batch 00064/03080] [00:00:47/00:37:11, 0.740s/it]: train_loss_raw=0.6629, running_loss=0.7052, LR=0.000100
[2025-08-27 07:11:09,502][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046272] [Batch 00072/03080] [00:00:53/00:37:13, 0.742s/it]: train_loss_raw=0.6962, running_loss=0.7044, LR=0.000100
[2025-08-27 07:11:15,730][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046280] [Batch 00080/03080] [00:00:59/00:37:18, 0.746s/it]: train_loss_raw=0.6964, running_loss=0.7026, LR=0.000100
[2025-08-27 07:11:21,831][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046288] [Batch 00088/03080] [00:01:05/00:37:16, 0.748s/it]: train_loss_raw=0.6490, running_loss=0.7028, LR=0.000100
[2025-08-27 07:11:27,965][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046296] [Batch 00096/03080] [00:01:11/00:37:15, 0.749s/it]: train_loss_raw=0.6453, running_loss=0.7020, LR=0.000100
[2025-08-27 07:11:34,087][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046304] [Batch 00104/03080] [00:01:18/00:37:13, 0.750s/it]: train_loss_raw=0.7032, running_loss=0.7019, LR=0.000100
[2025-08-27 07:11:40,135][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046312] [Batch 00112/03080] [00:01:24/00:37:08, 0.751s/it]: train_loss_raw=0.6741, running_loss=0.7003, LR=0.000100
[2025-08-27 07:11:45,979][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046320] [Batch 00120/03080] [00:01:29/00:36:58, 0.749s/it]: train_loss_raw=0.6157, running_loss=0.7012, LR=0.000100
[2025-08-27 07:11:51,691][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046328] [Batch 00128/03080] [00:01:35/00:36:45, 0.747s/it]: train_loss_raw=0.7152, running_loss=0.7000, LR=0.000100
[2025-08-27 07:11:57,560][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046336] [Batch 00136/03080] [00:01:41/00:36:37, 0.746s/it]: train_loss_raw=0.7038, running_loss=0.6999, LR=0.000100
[2025-08-27 07:12:03,410][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046344] [Batch 00144/03080] [00:01:47/00:36:29, 0.746s/it]: train_loss_raw=0.6252, running_loss=0.6973, LR=0.000100
[2025-08-27 07:12:09,294][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046352] [Batch 00152/03080] [00:01:53/00:36:21, 0.745s/it]: train_loss_raw=0.7069, running_loss=0.6974, LR=0.000100
[2025-08-27 07:12:14,861][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046360] [Batch 00160/03080] [00:01:58/00:36:08, 0.743s/it]: train_loss_raw=0.6363, running_loss=0.6952, LR=0.000100
[2025-08-27 07:12:20,666][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046368] [Batch 00168/03080] [00:02:04/00:36:00, 0.742s/it]: train_loss_raw=0.6438, running_loss=0.6937, LR=0.000100
[2025-08-27 07:12:26,611][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046376] [Batch 00176/03080] [00:02:10/00:35:54, 0.742s/it]: train_loss_raw=0.6557, running_loss=0.6915, LR=0.000100
[2025-08-27 07:12:32,554][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046384] [Batch 00184/03080] [00:02:16/00:35:48, 0.742s/it]: train_loss_raw=0.7718, running_loss=0.6930, LR=0.000100
[2025-08-27 07:12:38,653][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046392] [Batch 00192/03080] [00:02:22/00:35:45, 0.743s/it]: train_loss_raw=0.7428, running_loss=0.6947, LR=0.000100
[2025-08-27 07:12:44,769][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046400] [Batch 00200/03080] [00:02:28/00:35:41, 0.744s/it]: train_loss_raw=0.6918, running_loss=0.6959, LR=0.000100
[2025-08-27 07:12:50,848][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046408] [Batch 00208/03080] [00:02:34/00:35:37, 0.744s/it]: train_loss_raw=0.7453, running_loss=0.6965, LR=0.000100
[2025-08-27 07:12:56,884][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046416] [Batch 00216/03080] [00:02:40/00:35:32, 0.745s/it]: train_loss_raw=0.6370, running_loss=0.6942, LR=0.000100
[2025-08-27 07:13:02,967][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046424] [Batch 00224/03080] [00:02:46/00:35:28, 0.745s/it]: train_loss_raw=0.6528, running_loss=0.6944, LR=0.000100
[2025-08-27 07:13:08,999][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046432] [Batch 00232/03080] [00:02:52/00:35:23, 0.746s/it]: train_loss_raw=0.6637, running_loss=0.6935, LR=0.000100
[2025-08-27 07:13:15,083][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046440] [Batch 00240/03080] [00:02:59/00:35:18, 0.746s/it]: train_loss_raw=0.6188, running_loss=0.6930, LR=0.000100
[2025-08-27 07:13:21,183][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046448] [Batch 00248/03080] [00:03:05/00:35:14, 0.747s/it]: train_loss_raw=0.7548, running_loss=0.6909, LR=0.000100
[2025-08-27 07:13:27,343][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046456] [Batch 00256/03080] [00:03:11/00:35:10, 0.747s/it]: train_loss_raw=0.5993, running_loss=0.6917, LR=0.000100
[2025-08-27 07:13:33,535][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046464] [Batch 00264/03080] [00:03:17/00:35:06, 0.748s/it]: train_loss_raw=0.6820, running_loss=0.6909, LR=0.000100
[2025-08-27 07:13:39,707][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046472] [Batch 00272/03080] [00:03:23/00:35:02, 0.749s/it]: train_loss_raw=0.6720, running_loss=0.6887, LR=0.000100
[2025-08-27 07:13:45,901][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046480] [Batch 00280/03080] [00:03:29/00:34:58, 0.749s/it]: train_loss_raw=0.7038, running_loss=0.6884, LR=0.000100
[2025-08-27 07:13:52,054][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046488] [Batch 00288/03080] [00:03:36/00:34:54, 0.750s/it]: train_loss_raw=0.6916, running_loss=0.6859, LR=0.000100
[2025-08-27 07:13:58,190][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046496] [Batch 00296/03080] [00:03:42/00:34:49, 0.750s/it]: train_loss_raw=0.6227, running_loss=0.6869, LR=0.000100
[2025-08-27 07:14:04,290][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046504] [Batch 00304/03080] [00:03:48/00:34:44, 0.751s/it]: train_loss_raw=0.7741, running_loss=0.6869, LR=0.000100
[2025-08-27 07:14:10,388][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046512] [Batch 00312/03080] [00:03:54/00:34:39, 0.751s/it]: train_loss_raw=0.6950, running_loss=0.6874, LR=0.000100
[2025-08-27 07:14:16,552][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046520] [Batch 00320/03080] [00:04:00/00:34:34, 0.752s/it]: train_loss_raw=0.8027, running_loss=0.6872, LR=0.000100
[2025-08-27 07:14:22,639][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046528] [Batch 00328/03080] [00:04:06/00:34:29, 0.752s/it]: train_loss_raw=0.6770, running_loss=0.6870, LR=0.000100
[2025-08-27 07:14:28,718][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046536] [Batch 00336/03080] [00:04:12/00:34:23, 0.752s/it]: train_loss_raw=0.6430, running_loss=0.6866, LR=0.000100
[2025-08-27 07:14:34,859][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046544] [Batch 00344/03080] [00:04:18/00:34:18, 0.752s/it]: train_loss_raw=0.6638, running_loss=0.6864, LR=0.000100
[2025-08-27 07:14:40,974][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046552] [Batch 00352/03080] [00:04:24/00:34:13, 0.753s/it]: train_loss_raw=0.6798, running_loss=0.6847, LR=0.000100
[2025-08-27 07:14:47,161][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046560] [Batch 00360/03080] [00:04:31/00:34:08, 0.753s/it]: train_loss_raw=0.6261, running_loss=0.6858, LR=0.000100
[2025-08-27 07:14:53,270][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046568] [Batch 00368/03080] [00:04:37/00:34:03, 0.753s/it]: train_loss_raw=0.7091, running_loss=0.6863, LR=0.000100
[2025-08-27 07:14:59,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046576] [Batch 00376/03080] [00:04:43/00:33:57, 0.753s/it]: train_loss_raw=0.6896, running_loss=0.6860, LR=0.000100
[2025-08-27 07:15:05,499][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046584] [Batch 00384/03080] [00:04:49/00:33:52, 0.754s/it]: train_loss_raw=0.6623, running_loss=0.6836, LR=0.000100
[2025-08-27 07:15:11,538][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046592] [Batch 00392/03080] [00:04:55/00:33:46, 0.754s/it]: train_loss_raw=0.5657, running_loss=0.6821, LR=0.000100
[2025-08-27 07:15:17,602][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046600] [Batch 00400/03080] [00:05:01/00:33:40, 0.754s/it]: train_loss_raw=0.7139, running_loss=0.6827, LR=0.000100
[2025-08-27 07:15:23,674][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046608] [Batch 00408/03080] [00:05:07/00:33:34, 0.754s/it]: train_loss_raw=0.7686, running_loss=0.6847, LR=0.000100
[2025-08-27 07:15:29,791][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046616] [Batch 00416/03080] [00:05:13/00:33:29, 0.754s/it]: train_loss_raw=0.6602, running_loss=0.6811, LR=0.000100
[2025-08-27 07:15:35,834][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046624] [Batch 00424/03080] [00:05:19/00:33:23, 0.754s/it]: train_loss_raw=0.6271, running_loss=0.6820, LR=0.000100
[2025-08-27 07:15:42,007][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046632] [Batch 00432/03080] [00:05:25/00:33:18, 0.755s/it]: train_loss_raw=0.6952, running_loss=0.6814, LR=0.000100
[2025-08-27 07:15:48,059][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046640] [Batch 00440/03080] [00:05:32/00:33:12, 0.755s/it]: train_loss_raw=0.7218, running_loss=0.6801, LR=0.000100
[2025-08-27 07:15:54,130][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046648] [Batch 00448/03080] [00:05:38/00:33:06, 0.755s/it]: train_loss_raw=0.8900, running_loss=0.6809, LR=0.000100
[2025-08-27 07:16:00,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046656] [Batch 00456/03080] [00:05:44/00:33:00, 0.755s/it]: train_loss_raw=0.6114, running_loss=0.6804, LR=0.000100
[2025-08-27 07:16:06,270][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046664] [Batch 00464/03080] [00:05:50/00:32:54, 0.755s/it]: train_loss_raw=0.6448, running_loss=0.6811, LR=0.000100
[2025-08-27 07:16:12,342][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046672] [Batch 00472/03080] [00:05:56/00:32:48, 0.755s/it]: train_loss_raw=0.6788, running_loss=0.6806, LR=0.000100
[2025-08-27 07:16:18,405][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046680] [Batch 00480/03080] [00:06:02/00:32:42, 0.755s/it]: train_loss_raw=0.6588, running_loss=0.6822, LR=0.000100
[2025-08-27 07:16:24,369][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046688] [Batch 00488/03080] [00:06:08/00:32:36, 0.755s/it]: train_loss_raw=0.7091, running_loss=0.6836, LR=0.000100
[2025-08-27 07:16:30,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046696] [Batch 00496/03080] [00:06:14/00:32:29, 0.755s/it]: train_loss_raw=0.7082, running_loss=0.6832, LR=0.000100
[2025-08-27 07:16:36,423][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046704] [Batch 00504/03080] [00:06:20/00:32:24, 0.755s/it]: train_loss_raw=0.7176, running_loss=0.6822, LR=0.000100
[2025-08-27 07:16:42,387][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046712] [Batch 00512/03080] [00:06:26/00:32:17, 0.755s/it]: train_loss_raw=0.7078, running_loss=0.6830, LR=0.000100
[2025-08-27 07:16:48,380][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046720] [Batch 00520/03080] [00:06:32/00:32:11, 0.754s/it]: train_loss_raw=0.7325, running_loss=0.6814, LR=0.000100
[2025-08-27 07:16:54,450][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046728] [Batch 00528/03080] [00:06:38/00:32:05, 0.755s/it]: train_loss_raw=0.7641, running_loss=0.6816, LR=0.000100
[2025-08-27 07:17:00,519][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046736] [Batch 00536/03080] [00:06:44/00:31:59, 0.755s/it]: train_loss_raw=0.6554, running_loss=0.6822, LR=0.000100
[2025-08-27 07:17:06,560][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046744] [Batch 00544/03080] [00:06:50/00:31:53, 0.755s/it]: train_loss_raw=0.5990, running_loss=0.6796, LR=0.000100
[2025-08-27 07:17:12,614][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046752] [Batch 00552/03080] [00:06:56/00:31:47, 0.755s/it]: train_loss_raw=0.7589, running_loss=0.6796, LR=0.000100
[2025-08-27 07:17:18,676][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046760] [Batch 00560/03080] [00:07:02/00:31:41, 0.755s/it]: train_loss_raw=0.7063, running_loss=0.6778, LR=0.000100
[2025-08-27 07:17:24,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046768] [Batch 00568/03080] [00:07:08/00:31:36, 0.755s/it]: train_loss_raw=0.6347, running_loss=0.6765, LR=0.000100
[2025-08-27 07:17:30,909][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046776] [Batch 00576/03080] [00:07:14/00:31:30, 0.755s/it]: train_loss_raw=0.6166, running_loss=0.6730, LR=0.000100
[2025-08-27 07:17:37,014][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046784] [Batch 00584/03080] [00:07:20/00:31:24, 0.755s/it]: train_loss_raw=0.6942, running_loss=0.6735, LR=0.000100
[2025-08-27 07:17:43,055][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046792] [Batch 00592/03080] [00:07:27/00:31:18, 0.755s/it]: train_loss_raw=0.7911, running_loss=0.6760, LR=0.000100
[2025-08-27 07:17:49,227][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046800] [Batch 00600/03080] [00:07:33/00:31:13, 0.755s/it]: train_loss_raw=0.6627, running_loss=0.6764, LR=0.000100
[2025-08-27 07:17:55,328][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046808] [Batch 00608/03080] [00:07:39/00:31:07, 0.755s/it]: train_loss_raw=0.7557, running_loss=0.6734, LR=0.000100
[2025-08-27 07:18:01,381][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046816] [Batch 00616/03080] [00:07:45/00:31:01, 0.755s/it]: train_loss_raw=0.6922, running_loss=0.6751, LR=0.000100
[2025-08-27 07:18:07,426][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046824] [Batch 00624/03080] [00:07:51/00:30:55, 0.755s/it]: train_loss_raw=0.6283, running_loss=0.6752, LR=0.000100
[2025-08-27 07:18:13,532][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046832] [Batch 00632/03080] [00:07:57/00:30:49, 0.756s/it]: train_loss_raw=0.5884, running_loss=0.6722, LR=0.000100
[2025-08-27 07:18:19,648][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046840] [Batch 00640/03080] [00:08:03/00:30:43, 0.756s/it]: train_loss_raw=0.6368, running_loss=0.6702, LR=0.000100
[2025-08-27 07:18:25,784][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046848] [Batch 00648/03080] [00:08:09/00:30:38, 0.756s/it]: train_loss_raw=0.5670, running_loss=0.6689, LR=0.000100
[2025-08-27 07:18:31,890][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046856] [Batch 00656/03080] [00:08:15/00:30:32, 0.756s/it]: train_loss_raw=0.6395, running_loss=0.6669, LR=0.000100
[2025-08-27 07:18:38,008][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046864] [Batch 00664/03080] [00:08:21/00:30:26, 0.756s/it]: train_loss_raw=0.6692, running_loss=0.6659, LR=0.000100
[2025-08-27 07:18:44,148][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046872] [Batch 00672/03080] [00:08:28/00:30:20, 0.756s/it]: train_loss_raw=0.6269, running_loss=0.6667, LR=0.000100
[2025-08-27 07:18:50,237][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046880] [Batch 00680/03080] [00:08:34/00:30:14, 0.756s/it]: train_loss_raw=0.6610, running_loss=0.6686, LR=0.000100
[2025-08-27 07:18:56,306][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046888] [Batch 00688/03080] [00:08:40/00:30:08, 0.756s/it]: train_loss_raw=0.6177, running_loss=0.6659, LR=0.000100
[2025-08-27 07:19:02,428][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046896] [Batch 00696/03080] [00:08:46/00:30:03, 0.756s/it]: train_loss_raw=0.5941, running_loss=0.6650, LR=0.000100
[2025-08-27 07:19:08,482][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046904] [Batch 00704/03080] [00:08:52/00:29:56, 0.756s/it]: train_loss_raw=0.6830, running_loss=0.6636, LR=0.000100
[2025-08-27 07:19:14,527][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046912] [Batch 00712/03080] [00:08:58/00:29:50, 0.756s/it]: train_loss_raw=0.6946, running_loss=0.6640, LR=0.000100
[2025-08-27 07:19:20,585][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046920] [Batch 00720/03080] [00:09:04/00:29:44, 0.756s/it]: train_loss_raw=0.6694, running_loss=0.6662, LR=0.000100
[2025-08-27 07:19:26,664][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046928] [Batch 00728/03080] [00:09:10/00:29:38, 0.756s/it]: train_loss_raw=0.7396, running_loss=0.6670, LR=0.000100
[2025-08-27 07:19:32,798][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046936] [Batch 00736/03080] [00:09:16/00:29:33, 0.756s/it]: train_loss_raw=0.6196, running_loss=0.6660, LR=0.000100
[2025-08-27 07:19:38,917][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046944] [Batch 00744/03080] [00:09:22/00:29:27, 0.757s/it]: train_loss_raw=0.6326, running_loss=0.6664, LR=0.000100
[2025-08-27 07:19:45,189][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046952] [Batch 00752/03080] [00:09:29/00:29:21, 0.757s/it]: train_loss_raw=0.6360, running_loss=0.6651, LR=0.000100
[2025-08-27 07:19:51,228][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046960] [Batch 00760/03080] [00:09:35/00:29:15, 0.757s/it]: train_loss_raw=0.7130, running_loss=0.6657, LR=0.000100
[2025-08-27 07:19:57,329][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046968] [Batch 00768/03080] [00:09:41/00:29:09, 0.757s/it]: train_loss_raw=0.7071, running_loss=0.6666, LR=0.000100
[2025-08-27 07:20:03,495][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046976] [Batch 00776/03080] [00:09:47/00:29:04, 0.757s/it]: train_loss_raw=0.5746, running_loss=0.6666, LR=0.000100
[2025-08-27 07:20:09,557][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046984] [Batch 00784/03080] [00:09:53/00:28:58, 0.757s/it]: train_loss_raw=0.6612, running_loss=0.6682, LR=0.000100
[2025-08-27 07:20:15,685][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 046992] [Batch 00792/03080] [00:09:59/00:28:52, 0.757s/it]: train_loss_raw=0.7865, running_loss=0.6694, LR=0.000100
[2025-08-27 07:20:21,817][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047000] [Batch 00800/03080] [00:10:05/00:28:46, 0.757s/it]: train_loss_raw=0.7291, running_loss=0.6717, LR=0.000100
[2025-08-27 07:20:27,925][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047008] [Batch 00808/03080] [00:10:11/00:28:40, 0.757s/it]: train_loss_raw=0.6740, running_loss=0.6729, LR=0.000100
[2025-08-27 07:20:34,061][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047016] [Batch 00816/03080] [00:10:18/00:28:34, 0.757s/it]: train_loss_raw=0.6724, running_loss=0.6753, LR=0.000100
[2025-08-27 07:20:40,200][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047024] [Batch 00824/03080] [00:10:24/00:28:28, 0.757s/it]: train_loss_raw=0.7213, running_loss=0.6761, LR=0.000100
[2025-08-27 07:20:46,339][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047032] [Batch 00832/03080] [00:10:30/00:28:23, 0.758s/it]: train_loss_raw=0.7647, running_loss=0.6762, LR=0.000100
[2025-08-27 07:20:52,449][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047040] [Batch 00840/03080] [00:10:36/00:28:17, 0.758s/it]: train_loss_raw=0.6380, running_loss=0.6757, LR=0.000100
[2025-08-27 07:20:58,504][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047048] [Batch 00848/03080] [00:10:42/00:28:11, 0.758s/it]: train_loss_raw=0.7396, running_loss=0.6754, LR=0.000100
[2025-08-27 07:21:04,579][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047056] [Batch 00856/03080] [00:10:48/00:28:04, 0.758s/it]: train_loss_raw=0.5836, running_loss=0.6727, LR=0.000100
[2025-08-27 07:21:10,780][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047064] [Batch 00864/03080] [00:10:54/00:27:59, 0.758s/it]: train_loss_raw=0.7879, running_loss=0.6741, LR=0.000100
[2025-08-27 07:21:16,905][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047072] [Batch 00872/03080] [00:11:00/00:27:53, 0.758s/it]: train_loss_raw=0.7052, running_loss=0.6749, LR=0.000100
[2025-08-27 07:21:23,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047080] [Batch 00880/03080] [00:11:06/00:27:47, 0.758s/it]: train_loss_raw=0.7005, running_loss=0.6745, LR=0.000100
[2025-08-27 07:21:29,127][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047088] [Batch 00888/03080] [00:11:13/00:27:41, 0.758s/it]: train_loss_raw=0.6547, running_loss=0.6714, LR=0.000100
[2025-08-27 07:21:35,253][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047096] [Batch 00896/03080] [00:11:19/00:27:35, 0.758s/it]: train_loss_raw=0.6719, running_loss=0.6724, LR=0.000100
[2025-08-27 07:21:41,299][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047104] [Batch 00904/03080] [00:11:25/00:27:29, 0.758s/it]: train_loss_raw=0.7050, running_loss=0.6686, LR=0.000100
[2025-08-27 07:21:47,395][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047112] [Batch 00912/03080] [00:11:31/00:27:23, 0.758s/it]: train_loss_raw=0.7178, running_loss=0.6677, LR=0.000100
[2025-08-27 07:21:53,594][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047120] [Batch 00920/03080] [00:11:37/00:27:17, 0.758s/it]: train_loss_raw=0.5709, running_loss=0.6657, LR=0.000100
[2025-08-27 07:21:59,686][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047128] [Batch 00928/03080] [00:11:43/00:27:11, 0.758s/it]: train_loss_raw=0.6491, running_loss=0.6647, LR=0.000100
[2025-08-27 07:22:05,779][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047136] [Batch 00936/03080] [00:11:49/00:27:05, 0.758s/it]: train_loss_raw=0.7283, running_loss=0.6643, LR=0.000100
[2025-08-27 07:22:11,894][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047144] [Batch 00944/03080] [00:11:55/00:26:59, 0.758s/it]: train_loss_raw=0.6730, running_loss=0.6645, LR=0.000100
[2025-08-27 07:22:17,935][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047152] [Batch 00952/03080] [00:12:01/00:26:53, 0.758s/it]: train_loss_raw=0.5575, running_loss=0.6636, LR=0.000100
[2025-08-27 07:22:24,010][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047160] [Batch 00960/03080] [00:12:07/00:26:47, 0.758s/it]: train_loss_raw=0.6865, running_loss=0.6680, LR=0.000100
[2025-08-27 07:22:30,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047168] [Batch 00968/03080] [00:12:14/00:26:41, 0.758s/it]: train_loss_raw=0.6289, running_loss=0.6688, LR=0.000100
[2025-08-27 07:22:36,156][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047176] [Batch 00976/03080] [00:12:20/00:26:35, 0.758s/it]: train_loss_raw=0.6831, running_loss=0.6688, LR=0.000100
[2025-08-27 07:22:42,206][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047184] [Batch 00984/03080] [00:12:26/00:26:29, 0.758s/it]: train_loss_raw=0.6580, running_loss=0.6675, LR=0.000100
[2025-08-27 07:22:48,270][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047192] [Batch 00992/03080] [00:12:32/00:26:23, 0.758s/it]: train_loss_raw=0.5959, running_loss=0.6692, LR=0.000100
[2025-08-27 07:22:54,349][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047200] [Batch 01000/03080] [00:12:38/00:26:17, 0.758s/it]: train_loss_raw=0.6834, running_loss=0.6672, LR=0.000100
[2025-08-27 07:23:00,491][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047208] [Batch 01008/03080] [00:12:44/00:26:11, 0.758s/it]: train_loss_raw=0.6975, running_loss=0.6667, LR=0.000100
[2025-08-27 07:23:06,639][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047216] [Batch 01016/03080] [00:12:50/00:26:05, 0.758s/it]: train_loss_raw=0.7299, running_loss=0.6677, LR=0.000100
[2025-08-27 07:23:12,719][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047224] [Batch 01024/03080] [00:12:56/00:25:59, 0.758s/it]: train_loss_raw=0.6623, running_loss=0.6687, LR=0.000100
[2025-08-27 07:23:18,789][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047232] [Batch 01032/03080] [00:13:02/00:25:53, 0.758s/it]: train_loss_raw=0.7300, running_loss=0.6660, LR=0.000100
[2025-08-27 07:23:24,897][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047240] [Batch 01040/03080] [00:13:08/00:25:47, 0.759s/it]: train_loss_raw=0.6864, running_loss=0.6682, LR=0.000100
[2025-08-27 07:23:31,036][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047248] [Batch 01048/03080] [00:13:14/00:25:41, 0.759s/it]: train_loss_raw=0.6344, running_loss=0.6670, LR=0.000100
[2025-08-27 07:23:37,178][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047256] [Batch 01056/03080] [00:13:21/00:25:35, 0.759s/it]: train_loss_raw=0.6184, running_loss=0.6677, LR=0.000100
[2025-08-27 07:23:43,336][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047264] [Batch 01064/03080] [00:13:27/00:25:29, 0.759s/it]: train_loss_raw=0.6494, running_loss=0.6680, LR=0.000100
[2025-08-27 07:23:49,468][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047272] [Batch 01072/03080] [00:13:33/00:25:23, 0.759s/it]: train_loss_raw=0.7379, running_loss=0.6691, LR=0.000100
[2025-08-27 07:23:55,581][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047280] [Batch 01080/03080] [00:13:39/00:25:17, 0.759s/it]: train_loss_raw=0.6764, running_loss=0.6698, LR=0.000100
[2025-08-27 07:24:01,660][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047288] [Batch 01088/03080] [00:13:45/00:25:11, 0.759s/it]: train_loss_raw=0.6813, running_loss=0.6693, LR=0.000100
[2025-08-27 07:24:07,731][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047296] [Batch 01096/03080] [00:13:51/00:25:05, 0.759s/it]: train_loss_raw=0.5859, running_loss=0.6684, LR=0.000100
[2025-08-27 07:24:13,813][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047304] [Batch 01104/03080] [00:13:57/00:24:59, 0.759s/it]: train_loss_raw=0.6707, running_loss=0.6681, LR=0.000100
[2025-08-27 07:24:19,776][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047312] [Batch 01112/03080] [00:14:03/00:24:53, 0.759s/it]: train_loss_raw=0.7476, running_loss=0.6683, LR=0.000100
[2025-08-27 07:24:25,819][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047320] [Batch 01120/03080] [00:14:09/00:24:47, 0.759s/it]: train_loss_raw=0.6438, running_loss=0.6676, LR=0.000100
[2025-08-27 07:24:31,920][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047328] [Batch 01128/03080] [00:14:15/00:24:41, 0.759s/it]: train_loss_raw=0.6620, running_loss=0.6664, LR=0.000100
[2025-08-27 07:24:38,009][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047336] [Batch 01136/03080] [00:14:21/00:24:35, 0.759s/it]: train_loss_raw=0.7430, running_loss=0.6662, LR=0.000100
[2025-08-27 07:24:44,134][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047344] [Batch 01144/03080] [00:14:28/00:24:29, 0.759s/it]: train_loss_raw=0.5719, running_loss=0.6670, LR=0.000100
[2025-08-27 07:24:50,228][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047352] [Batch 01152/03080] [00:14:34/00:24:23, 0.759s/it]: train_loss_raw=0.7143, running_loss=0.6662, LR=0.000100
[2025-08-27 07:24:56,351][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047360] [Batch 01160/03080] [00:14:40/00:24:17, 0.759s/it]: train_loss_raw=0.6943, running_loss=0.6673, LR=0.000100
[2025-08-27 07:25:02,405][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047368] [Batch 01168/03080] [00:14:46/00:24:10, 0.759s/it]: train_loss_raw=0.7228, running_loss=0.6674, LR=0.000100
[2025-08-27 07:25:08,229][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047376] [Batch 01176/03080] [00:14:52/00:24:04, 0.759s/it]: train_loss_raw=0.6215, running_loss=0.6675, LR=0.000100
[2025-08-27 07:25:14,094][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047384] [Batch 01184/03080] [00:14:58/00:23:58, 0.758s/it]: train_loss_raw=0.6963, running_loss=0.6646, LR=0.000100
[2025-08-27 07:25:19,964][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047392] [Batch 01192/03080] [00:15:03/00:23:51, 0.758s/it]: train_loss_raw=0.7616, running_loss=0.6651, LR=0.000100
[2025-08-27 07:25:26,019][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047400] [Batch 01200/03080] [00:15:09/00:23:45, 0.758s/it]: train_loss_raw=0.7635, running_loss=0.6679, LR=0.000100
[2025-08-27 07:25:32,075][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047408] [Batch 01208/03080] [00:15:16/00:23:39, 0.758s/it]: train_loss_raw=0.6027, running_loss=0.6646, LR=0.000100
[2025-08-27 07:25:38,072][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047416] [Batch 01216/03080] [00:15:22/00:23:33, 0.758s/it]: train_loss_raw=0.5796, running_loss=0.6641, LR=0.000100
[2025-08-27 07:25:44,201][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047424] [Batch 01224/03080] [00:15:28/00:23:27, 0.758s/it]: train_loss_raw=0.6097, running_loss=0.6620, LR=0.000100
[2025-08-27 07:25:50,328][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047432] [Batch 01232/03080] [00:15:34/00:23:21, 0.758s/it]: train_loss_raw=0.6552, running_loss=0.6616, LR=0.000100
[2025-08-27 07:25:56,540][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047440] [Batch 01240/03080] [00:15:40/00:23:15, 0.758s/it]: train_loss_raw=0.7096, running_loss=0.6607, LR=0.000100
[2025-08-27 07:26:02,668][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047448] [Batch 01248/03080] [00:15:46/00:23:09, 0.759s/it]: train_loss_raw=0.6493, running_loss=0.6606, LR=0.000100
[2025-08-27 07:26:08,725][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047456] [Batch 01256/03080] [00:15:52/00:23:03, 0.759s/it]: train_loss_raw=0.6541, running_loss=0.6612, LR=0.000100
[2025-08-27 07:26:14,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047464] [Batch 01264/03080] [00:15:58/00:22:57, 0.759s/it]: train_loss_raw=0.6300, running_loss=0.6637, LR=0.000100
[2025-08-27 07:26:20,984][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047472] [Batch 01272/03080] [00:16:04/00:22:51, 0.759s/it]: train_loss_raw=0.6289, running_loss=0.6653, LR=0.000100
[2025-08-27 07:26:27,112][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047480] [Batch 01280/03080] [00:16:11/00:22:45, 0.759s/it]: train_loss_raw=0.6536, running_loss=0.6630, LR=0.000100
[2025-08-27 07:26:33,274][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047488] [Batch 01288/03080] [00:16:17/00:22:39, 0.759s/it]: train_loss_raw=0.5972, running_loss=0.6633, LR=0.000100
[2025-08-27 07:26:39,408][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047496] [Batch 01296/03080] [00:16:23/00:22:33, 0.759s/it]: train_loss_raw=0.6510, running_loss=0.6619, LR=0.000100
[2025-08-27 07:26:45,520][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047504] [Batch 01304/03080] [00:16:29/00:22:27, 0.759s/it]: train_loss_raw=0.7714, running_loss=0.6631, LR=0.000100
[2025-08-27 07:26:51,627][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047512] [Batch 01312/03080] [00:16:35/00:22:21, 0.759s/it]: train_loss_raw=0.6388, running_loss=0.6635, LR=0.000100
[2025-08-27 07:26:58,306][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047520] [Batch 01320/03080] [00:16:42/00:22:16, 0.759s/it]: train_loss_raw=0.6793, running_loss=0.6644, LR=0.000100
[2025-08-27 07:27:04,445][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047528] [Batch 01328/03080] [00:16:48/00:22:10, 0.759s/it]: train_loss_raw=0.5971, running_loss=0.6634, LR=0.000100
[2025-08-27 07:27:10,529][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047536] [Batch 01336/03080] [00:16:54/00:22:04, 0.759s/it]: train_loss_raw=0.6684, running_loss=0.6646, LR=0.000100
[2025-08-27 07:27:16,588][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047544] [Batch 01344/03080] [00:17:00/00:21:58, 0.759s/it]: train_loss_raw=0.6635, running_loss=0.6645, LR=0.000100
[2025-08-27 07:27:22,781][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047552] [Batch 01352/03080] [00:17:06/00:21:52, 0.759s/it]: train_loss_raw=0.6642, running_loss=0.6661, LR=0.000100
[2025-08-27 07:27:28,885][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047560] [Batch 01360/03080] [00:17:12/00:21:46, 0.759s/it]: train_loss_raw=0.6045, running_loss=0.6618, LR=0.000100
[2025-08-27 07:27:34,997][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047568] [Batch 01368/03080] [00:17:18/00:21:40, 0.759s/it]: train_loss_raw=0.7828, running_loss=0.6647, LR=0.000100
[2025-08-27 07:27:41,095][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047576] [Batch 01376/03080] [00:17:25/00:21:34, 0.759s/it]: train_loss_raw=0.5873, running_loss=0.6657, LR=0.000100
[2025-08-27 07:27:47,244][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047584] [Batch 01384/03080] [00:17:31/00:21:28, 0.760s/it]: train_loss_raw=0.5626, running_loss=0.6644, LR=0.000100
[2025-08-27 07:27:53,398][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047592] [Batch 01392/03080] [00:17:37/00:21:22, 0.760s/it]: train_loss_raw=0.6963, running_loss=0.6649, LR=0.000100
[2025-08-27 07:27:59,571][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047600] [Batch 01400/03080] [00:17:43/00:21:16, 0.760s/it]: train_loss_raw=0.8214, running_loss=0.6649, LR=0.000100
[2025-08-27 07:28:05,522][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047608] [Batch 01408/03080] [00:17:49/00:21:10, 0.760s/it]: train_loss_raw=0.6859, running_loss=0.6651, LR=0.000100
[2025-08-27 07:28:11,552][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047616] [Batch 01416/03080] [00:17:55/00:21:03, 0.760s/it]: train_loss_raw=0.6747, running_loss=0.6617, LR=0.000100
[2025-08-27 07:28:17,755][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047624] [Batch 01424/03080] [00:18:01/00:20:57, 0.760s/it]: train_loss_raw=0.5823, running_loss=0.6626, LR=0.000100
[2025-08-27 07:28:23,855][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047632] [Batch 01432/03080] [00:18:07/00:20:51, 0.760s/it]: train_loss_raw=0.6464, running_loss=0.6622, LR=0.000100
[2025-08-27 07:28:29,979][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047640] [Batch 01440/03080] [00:18:13/00:20:45, 0.760s/it]: train_loss_raw=0.6770, running_loss=0.6644, LR=0.000100
[2025-08-27 07:28:35,893][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047648] [Batch 01448/03080] [00:18:19/00:20:39, 0.760s/it]: train_loss_raw=0.7098, running_loss=0.6639, LR=0.000100
[2025-08-27 07:28:41,762][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047656] [Batch 01456/03080] [00:18:25/00:20:33, 0.759s/it]: train_loss_raw=0.6978, running_loss=0.6644, LR=0.000100
[2025-08-27 07:28:47,665][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047664] [Batch 01464/03080] [00:18:31/00:20:27, 0.759s/it]: train_loss_raw=0.6793, running_loss=0.6674, LR=0.000100
[2025-08-27 07:28:53,760][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047672] [Batch 01472/03080] [00:18:37/00:20:20, 0.759s/it]: train_loss_raw=0.6924, running_loss=0.6659, LR=0.000100
[2025-08-27 07:28:59,902][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047680] [Batch 01480/03080] [00:18:43/00:20:14, 0.759s/it]: train_loss_raw=0.6594, running_loss=0.6643, LR=0.000100
[2025-08-27 07:29:06,128][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047688] [Batch 01488/03080] [00:18:50/00:20:09, 0.759s/it]: train_loss_raw=0.7041, running_loss=0.6641, LR=0.000100
[2025-08-27 07:29:12,222][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047696] [Batch 01496/03080] [00:18:56/00:20:03, 0.759s/it]: train_loss_raw=0.7090, running_loss=0.6608, LR=0.000100
[2025-08-27 07:29:18,394][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047704] [Batch 01504/03080] [00:19:02/00:19:57, 0.760s/it]: train_loss_raw=0.6895, running_loss=0.6613, LR=0.000100
[2025-08-27 07:29:24,529][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047712] [Batch 01512/03080] [00:19:08/00:19:51, 0.760s/it]: train_loss_raw=0.5478, running_loss=0.6598, LR=0.000100
[2025-08-27 07:29:30,564][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047720] [Batch 01520/03080] [00:19:14/00:19:44, 0.760s/it]: train_loss_raw=0.6947, running_loss=0.6599, LR=0.000100
[2025-08-27 07:29:36,583][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047728] [Batch 01528/03080] [00:19:20/00:19:38, 0.760s/it]: train_loss_raw=0.6394, running_loss=0.6582, LR=0.000100
[2025-08-27 07:29:42,692][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047736] [Batch 01536/03080] [00:19:26/00:19:32, 0.760s/it]: train_loss_raw=0.6837, running_loss=0.6574, LR=0.000100
[2025-08-27 07:29:48,826][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047744] [Batch 01544/03080] [00:19:32/00:19:26, 0.760s/it]: train_loss_raw=0.6082, running_loss=0.6563, LR=0.000100
[2025-08-27 07:29:54,976][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047752] [Batch 01552/03080] [00:19:38/00:19:20, 0.760s/it]: train_loss_raw=0.6509, running_loss=0.6571, LR=0.000100
[2025-08-27 07:30:01,093][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047760] [Batch 01560/03080] [00:19:45/00:19:14, 0.760s/it]: train_loss_raw=0.6114, running_loss=0.6553, LR=0.000100
[2025-08-27 07:30:07,150][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047768] [Batch 01568/03080] [00:19:51/00:19:08, 0.760s/it]: train_loss_raw=0.6274, running_loss=0.6544, LR=0.000100
[2025-08-27 07:30:13,241][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047776] [Batch 01576/03080] [00:19:57/00:19:02, 0.760s/it]: train_loss_raw=0.6637, running_loss=0.6553, LR=0.000100
[2025-08-27 07:30:19,337][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047784] [Batch 01584/03080] [00:20:03/00:18:56, 0.760s/it]: train_loss_raw=0.6512, running_loss=0.6549, LR=0.000100
[2025-08-27 07:30:25,415][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047792] [Batch 01592/03080] [00:20:09/00:18:50, 0.760s/it]: train_loss_raw=0.7765, running_loss=0.6552, LR=0.000100
[2025-08-27 07:30:31,431][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047800] [Batch 01600/03080] [00:20:15/00:18:44, 0.760s/it]: train_loss_raw=0.6976, running_loss=0.6557, LR=0.000100
[2025-08-27 07:30:37,597][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047808] [Batch 01608/03080] [00:20:21/00:18:38, 0.760s/it]: train_loss_raw=0.5798, running_loss=0.6545, LR=0.000100
[2025-08-27 07:30:43,718][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047816] [Batch 01616/03080] [00:20:27/00:18:32, 0.760s/it]: train_loss_raw=0.6614, running_loss=0.6481, LR=0.000100
[2025-08-27 07:30:49,829][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047824] [Batch 01624/03080] [00:20:33/00:18:26, 0.760s/it]: train_loss_raw=0.6733, running_loss=0.6511, LR=0.000100
[2025-08-27 07:30:55,906][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047832] [Batch 01632/03080] [00:20:39/00:18:20, 0.760s/it]: train_loss_raw=0.6121, running_loss=0.6519, LR=0.000100
[2025-08-27 07:31:01,941][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047840] [Batch 01640/03080] [00:20:45/00:18:13, 0.760s/it]: train_loss_raw=0.7048, running_loss=0.6510, LR=0.000100
[2025-08-27 07:31:08,125][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047848] [Batch 01648/03080] [00:20:52/00:18:07, 0.760s/it]: train_loss_raw=0.8330, running_loss=0.6547, LR=0.000100
[2025-08-27 07:31:14,364][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047856] [Batch 01656/03080] [00:20:58/00:18:02, 0.760s/it]: train_loss_raw=0.6963, running_loss=0.6563, LR=0.000100
[2025-08-27 07:31:20,507][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047864] [Batch 01664/03080] [00:21:04/00:17:56, 0.760s/it]: train_loss_raw=0.6408, running_loss=0.6560, LR=0.000100
[2025-08-27 07:31:26,560][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047872] [Batch 01672/03080] [00:21:10/00:17:49, 0.760s/it]: train_loss_raw=0.6615, running_loss=0.6537, LR=0.000100
[2025-08-27 07:31:32,618][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047880] [Batch 01680/03080] [00:21:16/00:17:43, 0.760s/it]: train_loss_raw=0.6450, running_loss=0.6505, LR=0.000100
[2025-08-27 07:31:38,714][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047888] [Batch 01688/03080] [00:21:22/00:17:37, 0.760s/it]: train_loss_raw=0.5979, running_loss=0.6504, LR=0.000100
[2025-08-27 07:31:44,917][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047896] [Batch 01696/03080] [00:21:28/00:17:31, 0.760s/it]: train_loss_raw=0.6531, running_loss=0.6489, LR=0.000100
[2025-08-27 07:31:50,947][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047904] [Batch 01704/03080] [00:21:34/00:17:25, 0.760s/it]: train_loss_raw=0.7439, running_loss=0.6496, LR=0.000100
[2025-08-27 07:31:57,088][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047912] [Batch 01712/03080] [00:21:41/00:17:19, 0.760s/it]: train_loss_raw=0.7735, running_loss=0.6526, LR=0.000100
[2025-08-27 07:32:03,050][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047920] [Batch 01720/03080] [00:21:47/00:17:13, 0.760s/it]: train_loss_raw=0.6171, running_loss=0.6512, LR=0.000100
[2025-08-27 07:32:08,851][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047928] [Batch 01728/03080] [00:21:52/00:17:07, 0.760s/it]: train_loss_raw=0.7141, running_loss=0.6542, LR=0.000100
[2025-08-27 07:32:14,654][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047936] [Batch 01736/03080] [00:21:58/00:17:00, 0.760s/it]: train_loss_raw=0.5021, running_loss=0.6526, LR=0.000100
[2025-08-27 07:32:20,601][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047944] [Batch 01744/03080] [00:22:04/00:16:54, 0.759s/it]: train_loss_raw=0.7179, running_loss=0.6548, LR=0.000100
[2025-08-27 07:32:26,254][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047952] [Batch 01752/03080] [00:22:10/00:16:48, 0.759s/it]: train_loss_raw=0.5974, running_loss=0.6532, LR=0.000100
[2025-08-27 07:32:31,726][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047960] [Batch 01760/03080] [00:22:15/00:16:41, 0.759s/it]: train_loss_raw=0.6759, running_loss=0.6526, LR=0.000100
[2025-08-27 07:32:37,558][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047968] [Batch 01768/03080] [00:22:21/00:16:35, 0.759s/it]: train_loss_raw=0.5920, running_loss=0.6521, LR=0.000100
[2025-08-27 07:32:43,721][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047976] [Batch 01776/03080] [00:22:27/00:16:29, 0.759s/it]: train_loss_raw=0.6223, running_loss=0.6535, LR=0.000100
[2025-08-27 07:32:49,909][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047984] [Batch 01784/03080] [00:22:33/00:16:23, 0.759s/it]: train_loss_raw=0.6247, running_loss=0.6517, LR=0.000100
[2025-08-27 07:32:56,068][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 047992] [Batch 01792/03080] [00:22:40/00:16:17, 0.759s/it]: train_loss_raw=0.6470, running_loss=0.6512, LR=0.000100
[2025-08-27 07:33:02,125][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048000] [Batch 01800/03080] [00:22:46/00:16:11, 0.759s/it]: train_loss_raw=0.6796, running_loss=0.6494, LR=0.000100
[2025-08-27 07:33:12,435][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048008] [Batch 01808/03080] [00:22:56/00:16:08, 0.761s/it]: train_loss_raw=0.6975, running_loss=0.6533, LR=0.000100
[2025-08-27 07:33:18,391][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048016] [Batch 01816/03080] [00:23:02/00:16:02, 0.761s/it]: train_loss_raw=0.6792, running_loss=0.6524, LR=0.000100
[2025-08-27 07:33:24,411][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048024] [Batch 01824/03080] [00:23:08/00:15:56, 0.761s/it]: train_loss_raw=0.4961, running_loss=0.6521, LR=0.000100
[2025-08-27 07:33:30,534][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048032] [Batch 01832/03080] [00:23:14/00:15:49, 0.761s/it]: train_loss_raw=0.6820, running_loss=0.6506, LR=0.000100
[2025-08-27 07:33:36,731][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048040] [Batch 01840/03080] [00:23:20/00:15:43, 0.761s/it]: train_loss_raw=0.6922, running_loss=0.6509, LR=0.000100
[2025-08-27 07:33:42,802][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048048] [Batch 01848/03080] [00:23:26/00:15:37, 0.761s/it]: train_loss_raw=0.6771, running_loss=0.6504, LR=0.000100
[2025-08-27 07:33:48,884][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048056] [Batch 01856/03080] [00:23:32/00:15:31, 0.761s/it]: train_loss_raw=0.6802, running_loss=0.6509, LR=0.000100
[2025-08-27 07:33:55,009][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048064] [Batch 01864/03080] [00:23:38/00:15:25, 0.761s/it]: train_loss_raw=0.5915, running_loss=0.6511, LR=0.000100
[2025-08-27 07:34:01,174][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048072] [Batch 01872/03080] [00:23:45/00:15:19, 0.761s/it]: train_loss_raw=0.7503, running_loss=0.6524, LR=0.000100
[2025-08-27 07:34:07,342][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048080] [Batch 01880/03080] [00:23:51/00:15:13, 0.761s/it]: train_loss_raw=0.5637, running_loss=0.6500, LR=0.000100
[2025-08-27 07:34:13,443][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048088] [Batch 01888/03080] [00:23:57/00:15:07, 0.761s/it]: train_loss_raw=0.7087, running_loss=0.6499, LR=0.000100
[2025-08-27 07:34:19,367][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048096] [Batch 01896/03080] [00:24:03/00:15:01, 0.761s/it]: train_loss_raw=0.6570, running_loss=0.6481, LR=0.000100
[2025-08-27 07:34:25,258][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048104] [Batch 01904/03080] [00:24:09/00:14:55, 0.761s/it]: train_loss_raw=0.6324, running_loss=0.6465, LR=0.000100
[2025-08-27 07:34:31,110][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048112] [Batch 01912/03080] [00:24:15/00:14:48, 0.761s/it]: train_loss_raw=0.6619, running_loss=0.6446, LR=0.000100
[2025-08-27 07:34:37,002][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048120] [Batch 01920/03080] [00:24:20/00:14:42, 0.761s/it]: train_loss_raw=0.5247, running_loss=0.6426, LR=0.000100
[2025-08-27 07:34:42,891][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048128] [Batch 01928/03080] [00:24:26/00:14:36, 0.761s/it]: train_loss_raw=0.6845, running_loss=0.6423, LR=0.000100
[2025-08-27 07:34:49,045][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048136] [Batch 01936/03080] [00:24:33/00:14:30, 0.761s/it]: train_loss_raw=0.6587, running_loss=0.6404, LR=0.000100
[2025-08-27 07:34:55,112][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048144] [Batch 01944/03080] [00:24:39/00:14:24, 0.761s/it]: train_loss_raw=0.6400, running_loss=0.6435, LR=0.000100
[2025-08-27 07:35:01,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048152] [Batch 01952/03080] [00:24:45/00:14:18, 0.761s/it]: train_loss_raw=0.7335, running_loss=0.6466, LR=0.000100
[2025-08-27 07:35:07,140][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048160] [Batch 01960/03080] [00:24:51/00:14:12, 0.761s/it]: train_loss_raw=0.6348, running_loss=0.6465, LR=0.000100
[2025-08-27 07:35:13,069][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048168] [Batch 01968/03080] [00:24:57/00:14:05, 0.761s/it]: train_loss_raw=0.6505, running_loss=0.6471, LR=0.000100
[2025-08-27 07:35:19,249][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048176] [Batch 01976/03080] [00:25:03/00:13:59, 0.761s/it]: train_loss_raw=0.6038, running_loss=0.6446, LR=0.000100
[2025-08-27 07:35:25,130][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048184] [Batch 01984/03080] [00:25:09/00:13:53, 0.761s/it]: train_loss_raw=0.6069, running_loss=0.6441, LR=0.000100
[2025-08-27 07:35:30,930][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048192] [Batch 01992/03080] [00:25:14/00:13:47, 0.760s/it]: train_loss_raw=0.6019, running_loss=0.6419, LR=0.000100
[2025-08-27 07:35:37,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048200] [Batch 02000/03080] [00:25:21/00:13:41, 0.761s/it]: train_loss_raw=0.6220, running_loss=0.6405, LR=0.000100
[2025-08-27 07:35:43,212][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048208] [Batch 02008/03080] [00:25:27/00:13:35, 0.761s/it]: train_loss_raw=0.6625, running_loss=0.6397, LR=0.000100
[2025-08-27 07:35:49,401][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048216] [Batch 02016/03080] [00:25:33/00:13:29, 0.761s/it]: train_loss_raw=0.7008, running_loss=0.6416, LR=0.000100
[2025-08-27 07:35:55,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048224] [Batch 02024/03080] [00:25:39/00:13:23, 0.760s/it]: train_loss_raw=0.5826, running_loss=0.6414, LR=0.000100
[2025-08-27 07:36:01,120][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048232] [Batch 02032/03080] [00:25:45/00:13:16, 0.760s/it]: train_loss_raw=0.6925, running_loss=0.6415, LR=0.000100
[2025-08-27 07:36:07,019][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048240] [Batch 02040/03080] [00:25:50/00:13:10, 0.760s/it]: train_loss_raw=0.5835, running_loss=0.6398, LR=0.000100
[2025-08-27 07:36:13,171][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048248] [Batch 02048/03080] [00:25:57/00:13:04, 0.760s/it]: train_loss_raw=0.5386, running_loss=0.6388, LR=0.000100
[2025-08-27 07:36:19,081][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048256] [Batch 02056/03080] [00:26:03/00:12:58, 0.760s/it]: train_loss_raw=0.7296, running_loss=0.6390, LR=0.000100
[2025-08-27 07:36:25,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048264] [Batch 02064/03080] [00:26:09/00:12:52, 0.760s/it]: train_loss_raw=0.6787, running_loss=0.6395, LR=0.000100
[2025-08-27 07:36:31,352][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048272] [Batch 02072/03080] [00:26:15/00:12:46, 0.760s/it]: train_loss_raw=0.6336, running_loss=0.6415, LR=0.000100
[2025-08-27 07:36:37,553][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048280] [Batch 02080/03080] [00:26:21/00:12:40, 0.760s/it]: train_loss_raw=0.5970, running_loss=0.6415, LR=0.000100
[2025-08-27 07:36:43,781][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048288] [Batch 02088/03080] [00:26:27/00:12:34, 0.760s/it]: train_loss_raw=0.6255, running_loss=0.6426, LR=0.000100
[2025-08-27 07:36:49,897][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048296] [Batch 02096/03080] [00:26:33/00:12:28, 0.760s/it]: train_loss_raw=0.6432, running_loss=0.6463, LR=0.000100
[2025-08-27 07:36:55,837][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048304] [Batch 02104/03080] [00:26:39/00:12:22, 0.760s/it]: train_loss_raw=0.6397, running_loss=0.6453, LR=0.000100
[2025-08-27 07:37:01,725][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048312] [Batch 02112/03080] [00:26:45/00:12:15, 0.760s/it]: train_loss_raw=0.6718, running_loss=0.6477, LR=0.000100
[2025-08-27 07:37:07,500][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048320] [Batch 02120/03080] [00:26:51/00:12:09, 0.760s/it]: train_loss_raw=0.5926, running_loss=0.6474, LR=0.000100
[2025-08-27 07:37:13,285][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048328] [Batch 02128/03080] [00:26:57/00:12:03, 0.760s/it]: train_loss_raw=0.6268, running_loss=0.6447, LR=0.000100
[2025-08-27 07:37:19,361][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048336] [Batch 02136/03080] [00:27:03/00:11:57, 0.760s/it]: train_loss_raw=0.5322, running_loss=0.6436, LR=0.000100
[2025-08-27 07:37:25,219][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048344] [Batch 02144/03080] [00:27:09/00:11:51, 0.760s/it]: train_loss_raw=0.7438, running_loss=0.6458, LR=0.000100
[2025-08-27 07:37:31,389][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048352] [Batch 02152/03080] [00:27:15/00:11:45, 0.760s/it]: train_loss_raw=0.6122, running_loss=0.6442, LR=0.000100
[2025-08-27 07:37:37,517][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048360] [Batch 02160/03080] [00:27:21/00:11:39, 0.760s/it]: train_loss_raw=0.6668, running_loss=0.6436, LR=0.000100
[2025-08-27 07:37:43,557][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048368] [Batch 02168/03080] [00:27:27/00:11:33, 0.760s/it]: train_loss_raw=0.6006, running_loss=0.6393, LR=0.000100
[2025-08-27 07:37:49,674][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048376] [Batch 02176/03080] [00:27:33/00:11:26, 0.760s/it]: train_loss_raw=0.6059, running_loss=0.6422, LR=0.000100
[2025-08-27 07:37:55,773][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048384] [Batch 02184/03080] [00:27:39/00:11:20, 0.760s/it]: train_loss_raw=0.6248, running_loss=0.6403, LR=0.000100
[2025-08-27 07:38:01,820][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048392] [Batch 02192/03080] [00:27:45/00:11:14, 0.760s/it]: train_loss_raw=0.6524, running_loss=0.6401, LR=0.000100
[2025-08-27 07:38:07,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048400] [Batch 02200/03080] [00:27:51/00:11:08, 0.760s/it]: train_loss_raw=0.5763, running_loss=0.6393, LR=0.000100
[2025-08-27 07:38:13,922][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048408] [Batch 02208/03080] [00:27:57/00:11:02, 0.760s/it]: train_loss_raw=0.6880, running_loss=0.6386, LR=0.000100
[2025-08-27 07:38:19,943][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048416] [Batch 02216/03080] [00:28:03/00:10:56, 0.760s/it]: train_loss_raw=0.6046, running_loss=0.6366, LR=0.000100
[2025-08-27 07:38:26,003][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048424] [Batch 02224/03080] [00:28:09/00:10:50, 0.760s/it]: train_loss_raw=0.5924, running_loss=0.6363, LR=0.000100
[2025-08-27 07:38:31,961][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048432] [Batch 02232/03080] [00:28:15/00:10:44, 0.760s/it]: train_loss_raw=0.5324, running_loss=0.6326, LR=0.000100
[2025-08-27 07:38:37,875][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048440] [Batch 02240/03080] [00:28:21/00:10:38, 0.760s/it]: train_loss_raw=0.6741, running_loss=0.6291, LR=0.000100
[2025-08-27 07:38:44,099][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048448] [Batch 02248/03080] [00:28:28/00:10:32, 0.760s/it]: train_loss_raw=0.5991, running_loss=0.6293, LR=0.000100
[2025-08-27 07:38:50,094][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048456] [Batch 02256/03080] [00:28:34/00:10:26, 0.760s/it]: train_loss_raw=0.7161, running_loss=0.6290, LR=0.000100
[2025-08-27 07:38:56,043][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048464] [Batch 02264/03080] [00:28:40/00:10:19, 0.760s/it]: train_loss_raw=0.6197, running_loss=0.6292, LR=0.000100
[2025-08-27 07:39:02,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048472] [Batch 02272/03080] [00:28:46/00:10:13, 0.760s/it]: train_loss_raw=0.6996, running_loss=0.6298, LR=0.000100
[2025-08-27 07:39:08,441][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048480] [Batch 02280/03080] [00:28:52/00:10:07, 0.760s/it]: train_loss_raw=0.5391, running_loss=0.6299, LR=0.000100
[2025-08-27 07:39:14,752][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048488] [Batch 02288/03080] [00:28:58/00:10:01, 0.760s/it]: train_loss_raw=0.5977, running_loss=0.6311, LR=0.000100
[2025-08-27 07:39:20,980][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048496] [Batch 02296/03080] [00:29:04/00:09:55, 0.760s/it]: train_loss_raw=0.5481, running_loss=0.6293, LR=0.000100
[2025-08-27 07:39:27,063][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048504] [Batch 02304/03080] [00:29:11/00:09:49, 0.760s/it]: train_loss_raw=0.6706, running_loss=0.6305, LR=0.000100
[2025-08-27 07:39:33,323][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048512] [Batch 02312/03080] [00:29:17/00:09:43, 0.760s/it]: train_loss_raw=0.5927, running_loss=0.6318, LR=0.000100
[2025-08-27 07:39:39,533][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048520] [Batch 02320/03080] [00:29:23/00:09:37, 0.760s/it]: train_loss_raw=0.5940, running_loss=0.6327, LR=0.000100
[2025-08-27 07:39:45,639][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048528] [Batch 02328/03080] [00:29:29/00:09:31, 0.760s/it]: train_loss_raw=0.5664, running_loss=0.6328, LR=0.000100
[2025-08-27 07:39:51,684][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048536] [Batch 02336/03080] [00:29:35/00:09:25, 0.760s/it]: train_loss_raw=0.6327, running_loss=0.6320, LR=0.000100
[2025-08-27 07:39:57,744][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048544] [Batch 02344/03080] [00:29:41/00:09:19, 0.760s/it]: train_loss_raw=0.7349, running_loss=0.6320, LR=0.000100
[2025-08-27 07:40:03,847][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048552] [Batch 02352/03080] [00:29:47/00:09:13, 0.760s/it]: train_loss_raw=0.5956, running_loss=0.6306, LR=0.000100
[2025-08-27 07:40:10,032][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048560] [Batch 02360/03080] [00:29:53/00:09:07, 0.760s/it]: train_loss_raw=0.7299, running_loss=0.6334, LR=0.000100
[2025-08-27 07:40:16,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048568] [Batch 02368/03080] [00:30:00/00:09:01, 0.760s/it]: train_loss_raw=0.6870, running_loss=0.6362, LR=0.000100
[2025-08-27 07:40:22,354][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048576] [Batch 02376/03080] [00:30:06/00:08:55, 0.760s/it]: train_loss_raw=0.7849, running_loss=0.6370, LR=0.000100
[2025-08-27 07:40:28,555][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048584] [Batch 02384/03080] [00:30:12/00:08:49, 0.760s/it]: train_loss_raw=0.6356, running_loss=0.6370, LR=0.000100
[2025-08-27 07:40:34,610][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048592] [Batch 02392/03080] [00:30:18/00:08:43, 0.760s/it]: train_loss_raw=0.5448, running_loss=0.6362, LR=0.000100
[2025-08-27 07:40:40,804][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048600] [Batch 02400/03080] [00:30:24/00:08:37, 0.760s/it]: train_loss_raw=0.6515, running_loss=0.6370, LR=0.000100
[2025-08-27 07:40:46,911][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048608] [Batch 02408/03080] [00:30:30/00:08:30, 0.760s/it]: train_loss_raw=0.7291, running_loss=0.6395, LR=0.000100
[2025-08-27 07:40:53,113][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048616] [Batch 02416/03080] [00:30:37/00:08:24, 0.760s/it]: train_loss_raw=0.7728, running_loss=0.6407, LR=0.000100
[2025-08-27 07:40:59,297][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048624] [Batch 02424/03080] [00:30:43/00:08:18, 0.760s/it]: train_loss_raw=0.6175, running_loss=0.6373, LR=0.000100
[2025-08-27 07:41:05,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048632] [Batch 02432/03080] [00:30:49/00:08:12, 0.760s/it]: train_loss_raw=0.6214, running_loss=0.6368, LR=0.000100
[2025-08-27 07:41:11,277][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048640] [Batch 02440/03080] [00:30:55/00:08:06, 0.760s/it]: train_loss_raw=0.7191, running_loss=0.6362, LR=0.000100
[2025-08-27 07:41:16,822][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048648] [Batch 02448/03080] [00:31:00/00:08:00, 0.760s/it]: train_loss_raw=0.5600, running_loss=0.6360, LR=0.000100
[2025-08-27 07:41:22,514][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048656] [Batch 02456/03080] [00:31:06/00:07:54, 0.760s/it]: train_loss_raw=0.6447, running_loss=0.6377, LR=0.000100
[2025-08-27 07:41:28,553][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048664] [Batch 02464/03080] [00:31:12/00:07:48, 0.760s/it]: train_loss_raw=0.6961, running_loss=0.6404, LR=0.000100
[2025-08-27 07:41:34,604][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048672] [Batch 02472/03080] [00:31:18/00:07:42, 0.760s/it]: train_loss_raw=0.6988, running_loss=0.6422, LR=0.000100
[2025-08-27 07:41:40,519][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048680] [Batch 02480/03080] [00:31:24/00:07:35, 0.760s/it]: train_loss_raw=0.5775, running_loss=0.6386, LR=0.000100
[2025-08-27 07:41:46,637][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048688] [Batch 02488/03080] [00:31:30/00:07:29, 0.760s/it]: train_loss_raw=0.6916, running_loss=0.6380, LR=0.000100
[2025-08-27 07:41:52,723][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048696] [Batch 02496/03080] [00:31:36/00:07:23, 0.760s/it]: train_loss_raw=0.6196, running_loss=0.6391, LR=0.000100
[2025-08-27 07:41:58,850][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048704] [Batch 02504/03080] [00:31:42/00:07:17, 0.760s/it]: train_loss_raw=0.5961, running_loss=0.6375, LR=0.000100
[2025-08-27 07:42:04,973][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048712] [Batch 02512/03080] [00:31:48/00:07:11, 0.760s/it]: train_loss_raw=0.7616, running_loss=0.6358, LR=0.000100
[2025-08-27 07:42:11,197][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048720] [Batch 02520/03080] [00:31:55/00:07:05, 0.760s/it]: train_loss_raw=0.6149, running_loss=0.6361, LR=0.000100
[2025-08-27 07:42:17,321][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048728] [Batch 02528/03080] [00:32:01/00:06:59, 0.760s/it]: train_loss_raw=0.6505, running_loss=0.6349, LR=0.000100
[2025-08-27 07:42:23,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048736] [Batch 02536/03080] [00:32:07/00:06:53, 0.760s/it]: train_loss_raw=0.7461, running_loss=0.6362, LR=0.000100
[2025-08-27 07:42:29,504][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048744] [Batch 02544/03080] [00:32:13/00:06:47, 0.760s/it]: train_loss_raw=0.6353, running_loss=0.6374, LR=0.000100
[2025-08-27 07:42:35,602][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048752] [Batch 02552/03080] [00:32:19/00:06:41, 0.760s/it]: train_loss_raw=0.7125, running_loss=0.6365, LR=0.000100
[2025-08-27 07:42:41,761][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048760] [Batch 02560/03080] [00:32:25/00:06:35, 0.760s/it]: train_loss_raw=0.7614, running_loss=0.6389, LR=0.000100
[2025-08-27 07:42:47,850][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048768] [Batch 02568/03080] [00:32:31/00:06:29, 0.760s/it]: train_loss_raw=0.5323, running_loss=0.6385, LR=0.000100
[2025-08-27 07:42:53,950][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048776] [Batch 02576/03080] [00:32:37/00:06:23, 0.760s/it]: train_loss_raw=0.5758, running_loss=0.6392, LR=0.000100
[2025-08-27 07:43:00,057][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048784] [Batch 02584/03080] [00:32:44/00:06:16, 0.760s/it]: train_loss_raw=0.5671, running_loss=0.6352, LR=0.000100
[2025-08-27 07:43:06,186][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048792] [Batch 02592/03080] [00:32:50/00:06:10, 0.760s/it]: train_loss_raw=0.6388, running_loss=0.6348, LR=0.000100
[2025-08-27 07:43:12,245][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048800] [Batch 02600/03080] [00:32:56/00:06:04, 0.760s/it]: train_loss_raw=0.6994, running_loss=0.6338, LR=0.000100
[2025-08-27 07:43:18,275][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048808] [Batch 02608/03080] [00:33:02/00:05:58, 0.760s/it]: train_loss_raw=0.7155, running_loss=0.6327, LR=0.000100
[2025-08-27 07:43:24,424][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048816] [Batch 02616/03080] [00:33:08/00:05:52, 0.760s/it]: train_loss_raw=0.6052, running_loss=0.6344, LR=0.000100
[2025-08-27 07:43:30,306][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048824] [Batch 02624/03080] [00:33:14/00:05:46, 0.760s/it]: train_loss_raw=0.6455, running_loss=0.6343, LR=0.000100
[2025-08-27 07:43:36,299][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048832] [Batch 02632/03080] [00:33:20/00:05:40, 0.760s/it]: train_loss_raw=0.5586, running_loss=0.6335, LR=0.000100
[2025-08-27 07:43:42,293][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048840] [Batch 02640/03080] [00:33:26/00:05:34, 0.760s/it]: train_loss_raw=0.6649, running_loss=0.6352, LR=0.000100
[2025-08-27 07:43:48,420][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048848] [Batch 02648/03080] [00:33:32/00:05:28, 0.760s/it]: train_loss_raw=0.5884, running_loss=0.6356, LR=0.000100
[2025-08-27 07:43:54,535][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048856] [Batch 02656/03080] [00:33:38/00:05:22, 0.760s/it]: train_loss_raw=0.6323, running_loss=0.6382, LR=0.000100
[2025-08-27 07:44:00,653][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048864] [Batch 02664/03080] [00:33:44/00:05:16, 0.760s/it]: train_loss_raw=0.6486, running_loss=0.6364, LR=0.000100
[2025-08-27 07:44:06,796][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048872] [Batch 02672/03080] [00:33:50/00:05:10, 0.760s/it]: train_loss_raw=0.6564, running_loss=0.6361, LR=0.000100
[2025-08-27 07:44:12,916][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048880] [Batch 02680/03080] [00:33:56/00:05:04, 0.760s/it]: train_loss_raw=0.6348, running_loss=0.6341, LR=0.000100
[2025-08-27 07:44:19,014][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048888] [Batch 02688/03080] [00:34:02/00:04:57, 0.760s/it]: train_loss_raw=0.7051, running_loss=0.6316, LR=0.000100
[2025-08-27 07:44:25,047][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048896] [Batch 02696/03080] [00:34:09/00:04:51, 0.760s/it]: train_loss_raw=0.7118, running_loss=0.6325, LR=0.000100
[2025-08-27 07:44:31,119][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048904] [Batch 02704/03080] [00:34:15/00:04:45, 0.760s/it]: train_loss_raw=0.7694, running_loss=0.6354, LR=0.000100
[2025-08-27 07:44:37,248][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048912] [Batch 02712/03080] [00:34:21/00:04:39, 0.760s/it]: train_loss_raw=0.6632, running_loss=0.6338, LR=0.000100
[2025-08-27 07:44:43,350][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048920] [Batch 02720/03080] [00:34:27/00:04:33, 0.760s/it]: train_loss_raw=0.5558, running_loss=0.6324, LR=0.000100
[2025-08-27 07:44:49,471][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048928] [Batch 02728/03080] [00:34:33/00:04:27, 0.760s/it]: train_loss_raw=0.5801, running_loss=0.6304, LR=0.000100
[2025-08-27 07:44:55,545][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048936] [Batch 02736/03080] [00:34:39/00:04:21, 0.760s/it]: train_loss_raw=0.6106, running_loss=0.6296, LR=0.000100
[2025-08-27 07:45:01,634][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048944] [Batch 02744/03080] [00:34:45/00:04:15, 0.760s/it]: train_loss_raw=0.6941, running_loss=0.6309, LR=0.000100
[2025-08-27 07:45:07,729][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048952] [Batch 02752/03080] [00:34:51/00:04:09, 0.760s/it]: train_loss_raw=0.6465, running_loss=0.6312, LR=0.000100
[2025-08-27 07:45:13,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048960] [Batch 02760/03080] [00:34:57/00:04:03, 0.760s/it]: train_loss_raw=0.6675, running_loss=0.6333, LR=0.000100
[2025-08-27 07:45:19,891][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048968] [Batch 02768/03080] [00:35:03/00:03:57, 0.760s/it]: train_loss_raw=0.6244, running_loss=0.6346, LR=0.000100
[2025-08-27 07:45:25,947][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048976] [Batch 02776/03080] [00:35:09/00:03:51, 0.760s/it]: train_loss_raw=0.6359, running_loss=0.6353, LR=0.000100
[2025-08-27 07:45:31,968][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048984] [Batch 02784/03080] [00:35:15/00:03:44, 0.760s/it]: train_loss_raw=0.5290, running_loss=0.6359, LR=0.000100
[2025-08-27 07:45:38,036][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 048992] [Batch 02792/03080] [00:35:21/00:03:38, 0.760s/it]: train_loss_raw=0.6236, running_loss=0.6387, LR=0.000100
[2025-08-27 07:45:44,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049000] [Batch 02800/03080] [00:35:28/00:03:32, 0.760s/it]: train_loss_raw=0.6129, running_loss=0.6388, LR=0.000100
[2025-08-27 07:45:50,422][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049008] [Batch 02808/03080] [00:35:34/00:03:26, 0.760s/it]: train_loss_raw=0.5884, running_loss=0.6367, LR=0.000100
[2025-08-27 07:45:56,578][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049016] [Batch 02816/03080] [00:35:40/00:03:20, 0.760s/it]: train_loss_raw=0.6180, running_loss=0.6349, LR=0.000100
[2025-08-27 07:46:02,633][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049024] [Batch 02824/03080] [00:35:46/00:03:14, 0.760s/it]: train_loss_raw=0.6062, running_loss=0.6331, LR=0.000100
[2025-08-27 07:46:08,666][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049032] [Batch 02832/03080] [00:35:52/00:03:08, 0.760s/it]: train_loss_raw=0.6085, running_loss=0.6321, LR=0.000100
[2025-08-27 07:46:14,794][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049040] [Batch 02840/03080] [00:35:58/00:03:02, 0.760s/it]: train_loss_raw=0.5851, running_loss=0.6295, LR=0.000100
[2025-08-27 07:46:20,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049048] [Batch 02848/03080] [00:36:04/00:02:56, 0.760s/it]: train_loss_raw=0.6012, running_loss=0.6283, LR=0.000100
[2025-08-27 07:46:26,939][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049056] [Batch 02856/03080] [00:36:10/00:02:50, 0.760s/it]: train_loss_raw=0.5855, running_loss=0.6301, LR=0.000100
[2025-08-27 07:46:32,860][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049064] [Batch 02864/03080] [00:36:16/00:02:44, 0.760s/it]: train_loss_raw=0.6500, running_loss=0.6311, LR=0.000100
[2025-08-27 07:46:38,743][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049072] [Batch 02872/03080] [00:36:22/00:02:38, 0.760s/it]: train_loss_raw=0.6015, running_loss=0.6295, LR=0.000100
[2025-08-27 07:46:44,813][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049080] [Batch 02880/03080] [00:36:28/00:02:31, 0.760s/it]: train_loss_raw=0.7442, running_loss=0.6303, LR=0.000100
[2025-08-27 07:46:50,975][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049088] [Batch 02888/03080] [00:36:34/00:02:25, 0.760s/it]: train_loss_raw=0.5712, running_loss=0.6291, LR=0.000100
[2025-08-27 07:46:57,059][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049096] [Batch 02896/03080] [00:36:41/00:02:19, 0.760s/it]: train_loss_raw=0.6464, running_loss=0.6271, LR=0.000100
[2025-08-27 07:47:03,295][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049104] [Batch 02904/03080] [00:36:47/00:02:13, 0.760s/it]: train_loss_raw=0.6601, running_loss=0.6267, LR=0.000100
[2025-08-27 07:47:09,565][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049112] [Batch 02912/03080] [00:36:53/00:02:07, 0.760s/it]: train_loss_raw=0.6320, running_loss=0.6269, LR=0.000100
[2025-08-27 07:47:15,741][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049120] [Batch 02920/03080] [00:36:59/00:02:01, 0.760s/it]: train_loss_raw=0.7115, running_loss=0.6271, LR=0.000100
[2025-08-27 07:47:21,827][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049128] [Batch 02928/03080] [00:37:05/00:01:55, 0.760s/it]: train_loss_raw=0.6872, running_loss=0.6278, LR=0.000100
[2025-08-27 07:47:27,921][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049136] [Batch 02936/03080] [00:37:11/00:01:49, 0.760s/it]: train_loss_raw=0.6076, running_loss=0.6274, LR=0.000100
[2025-08-27 07:47:34,029][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049144] [Batch 02944/03080] [00:37:17/00:01:43, 0.760s/it]: train_loss_raw=0.6220, running_loss=0.6266, LR=0.000100
[2025-08-27 07:47:40,068][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049152] [Batch 02952/03080] [00:37:24/00:01:37, 0.760s/it]: train_loss_raw=0.6896, running_loss=0.6305, LR=0.000100
[2025-08-27 07:47:46,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049160] [Batch 02960/03080] [00:37:30/00:01:31, 0.760s/it]: train_loss_raw=0.6871, running_loss=0.6294, LR=0.000100
[2025-08-27 07:47:52,317][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049168] [Batch 02968/03080] [00:37:36/00:01:25, 0.760s/it]: train_loss_raw=0.6668, running_loss=0.6289, LR=0.000100
[2025-08-27 07:47:58,092][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049176] [Batch 02976/03080] [00:37:42/00:01:19, 0.760s/it]: train_loss_raw=0.5982, running_loss=0.6284, LR=0.000100
[2025-08-27 07:48:04,109][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049184] [Batch 02984/03080] [00:37:48/00:01:12, 0.760s/it]: train_loss_raw=0.5841, running_loss=0.6285, LR=0.000100
[2025-08-27 07:48:10,258][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049192] [Batch 02992/03080] [00:37:54/00:01:06, 0.760s/it]: train_loss_raw=0.6580, running_loss=0.6268, LR=0.000100
[2025-08-27 07:48:16,344][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049200] [Batch 03000/03080] [00:38:00/00:01:00, 0.760s/it]: train_loss_raw=0.7390, running_loss=0.6294, LR=0.000100
[2025-08-27 07:48:22,558][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049208] [Batch 03008/03080] [00:38:06/00:00:54, 0.760s/it]: train_loss_raw=0.7619, running_loss=0.6284, LR=0.000100
[2025-08-27 07:48:28,672][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049216] [Batch 03016/03080] [00:38:12/00:00:48, 0.760s/it]: train_loss_raw=0.5979, running_loss=0.6277, LR=0.000100
[2025-08-27 07:48:34,906][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049224] [Batch 03024/03080] [00:38:18/00:00:42, 0.760s/it]: train_loss_raw=0.7368, running_loss=0.6286, LR=0.000100
[2025-08-27 07:48:41,000][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049232] [Batch 03032/03080] [00:38:24/00:00:36, 0.760s/it]: train_loss_raw=0.6704, running_loss=0.6291, LR=0.000100
[2025-08-27 07:48:47,082][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049240] [Batch 03040/03080] [00:38:31/00:00:30, 0.760s/it]: train_loss_raw=0.6407, running_loss=0.6301, LR=0.000100
[2025-08-27 07:48:53,135][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049248] [Batch 03048/03080] [00:38:37/00:00:24, 0.760s/it]: train_loss_raw=0.6162, running_loss=0.6292, LR=0.000100
[2025-08-27 07:48:59,214][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049256] [Batch 03056/03080] [00:38:43/00:00:18, 0.760s/it]: train_loss_raw=0.6038, running_loss=0.6287, LR=0.000100
[2025-08-27 07:49:05,279][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049264] [Batch 03064/03080] [00:38:49/00:00:12, 0.760s/it]: train_loss_raw=0.7263, running_loss=0.6284, LR=0.000100
[2025-08-27 07:49:11,395][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049272] [Batch 03072/03080] [00:38:55/00:00:06, 0.760s/it]: train_loss_raw=0.6258, running_loss=0.6297, LR=0.000100
[2025-08-27 07:49:23,275][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 049280] [Batch 03080/03080] [00:39:07/00:00:00, 0.762s/it]: train_loss_raw=0.6364, running_loss=0.6314, LR=0.000100
[2025-08-27 07:49:23,814][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-27 07:49:35,254][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00007/00310] [00:00:11/00:07:11, 1.430s/it]
[2025-08-27 07:49:47,010][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00015/00310] [00:00:23/00:07:06, 1.450s/it]
[2025-08-27 07:49:59,470][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00023/00310] [00:00:35/00:07:04, 1.486s/it]
[2025-08-27 07:50:11,956][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00031/00310] [00:00:48/00:06:58, 1.504s/it]
[2025-08-27 07:50:23,449][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00039/00310] [00:00:59/00:06:42, 1.491s/it]
[2025-08-27 07:50:35,042][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00047/00310] [00:01:11/00:06:28, 1.484s/it]
[2025-08-27 07:50:47,004][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00055/00310] [00:01:23/00:06:17, 1.486s/it]
[2025-08-27 07:50:59,005][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00063/00310] [00:01:35/00:06:05, 1.487s/it]
[2025-08-27 07:51:11,136][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00071/00310] [00:01:47/00:05:54, 1.491s/it]
[2025-08-27 07:51:24,076][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00079/00310] [00:02:00/00:05:45, 1.503s/it]
[2025-08-27 07:51:36,476][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00087/00310] [00:02:12/00:05:34, 1.508s/it]
[2025-08-27 07:51:49,406][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00095/00310] [00:02:25/00:05:24, 1.517s/it]
[2025-08-27 07:52:01,973][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00103/00310] [00:02:38/00:05:13, 1.521s/it]
[2025-08-27 07:52:14,182][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00111/00310] [00:02:50/00:05:01, 1.521s/it]
[2025-08-27 07:52:26,963][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00119/00310] [00:03:03/00:04:49, 1.526s/it]
[2025-08-27 07:52:39,581][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00127/00310] [00:03:15/00:04:38, 1.529s/it]
[2025-08-27 07:52:52,425][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00135/00310] [00:03:28/00:04:26, 1.534s/it]
[2025-08-27 07:53:05,146][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00143/00310] [00:03:41/00:04:15, 1.537s/it]
[2025-08-27 07:53:17,017][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00151/00310] [00:03:53/00:04:02, 1.534s/it]
[2025-08-27 07:53:28,574][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00159/00310] [00:04:04/00:03:49, 1.530s/it]
[2025-08-27 07:53:41,378][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00167/00310] [00:04:17/00:03:37, 1.533s/it]
[2025-08-27 07:53:52,429][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00175/00310] [00:04:28/00:03:24, 1.526s/it]
[2025-08-27 07:54:04,141][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00183/00310] [00:04:40/00:03:11, 1.524s/it]
[2025-08-27 07:54:16,105][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00191/00310] [00:04:52/00:02:59, 1.522s/it]
[2025-08-27 07:54:28,335][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00199/00310] [00:05:04/00:02:47, 1.523s/it]
[2025-08-27 07:54:40,221][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00207/00310] [00:05:16/00:02:35, 1.521s/it]
[2025-08-27 07:54:52,054][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00215/00310] [00:05:28/00:02:22, 1.520s/it]
[2025-08-27 07:55:04,494][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00223/00310] [00:05:40/00:02:10, 1.521s/it]
[2025-08-27 07:55:16,653][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00231/00310] [00:05:52/00:01:58, 1.521s/it]
[2025-08-27 07:55:28,934][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00239/00310] [00:06:05/00:01:46, 1.521s/it]
[2025-08-27 07:55:40,700][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00247/00310] [00:06:16/00:01:34, 1.520s/it]
[2025-08-27 07:55:52,809][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00255/00310] [00:06:28/00:01:22, 1.520s/it]
[2025-08-27 07:56:05,498][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00263/00310] [00:06:41/00:01:09, 1.522s/it]
[2025-08-27 07:56:17,855][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00271/00310] [00:06:54/00:00:57, 1.522s/it]
[2025-08-27 07:56:29,741][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00279/00310] [00:07:05/00:00:45, 1.521s/it]
[2025-08-27 07:56:42,318][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00287/00310] [00:07:18/00:00:33, 1.523s/it]
[2025-08-27 07:56:54,530][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00295/00310] [00:07:30/00:00:21, 1.523s/it]
[2025-08-27 07:57:07,335][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 049281] [Batch 00303/00310] [00:07:43/00:00:09, 1.525s/it]
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=0.63139, valid_loss=1.59468
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.591
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.086
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.089
[2025-08-27 07:57:16,643][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.039
[2025-08-27 07:57:16,652][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 12:30:30, remaining time 10:56:41, 00:46:54 per epoch
[2025-08-27 07:57:22,421][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049288] [Batch 00008/03080] [00:00:05/00:35:05, 0.685s/it]: train_loss_raw=0.5690, running_loss=0.5974, LR=0.000100
[2025-08-27 07:57:28,493][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049296] [Batch 00016/03080] [00:00:11/00:36:52, 0.722s/it]: train_loss_raw=0.6621, running_loss=0.5991, LR=0.000100
[2025-08-27 07:57:34,615][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049304] [Batch 00024/03080] [00:00:17/00:37:30, 0.737s/it]: train_loss_raw=0.6112, running_loss=0.6008, LR=0.000100
[2025-08-27 07:57:40,654][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049312] [Batch 00032/03080] [00:00:23/00:37:38, 0.741s/it]: train_loss_raw=0.5787, running_loss=0.5998, LR=0.000100
[2025-08-27 07:57:46,777][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049320] [Batch 00040/03080] [00:00:29/00:37:47, 0.746s/it]: train_loss_raw=0.7161, running_loss=0.5988, LR=0.000100
[2025-08-27 07:57:52,876][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049328] [Batch 00048/03080] [00:00:35/00:37:50, 0.749s/it]: train_loss_raw=0.6509, running_loss=0.5983, LR=0.000100
[2025-08-27 07:57:58,973][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049336] [Batch 00056/03080] [00:00:42/00:37:49, 0.751s/it]: train_loss_raw=0.6829, running_loss=0.5986, LR=0.000100
[2025-08-27 07:58:04,982][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049344] [Batch 00064/03080] [00:00:48/00:37:44, 0.751s/it]: train_loss_raw=0.5718, running_loss=0.5978, LR=0.000100
[2025-08-27 07:58:11,039][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049352] [Batch 00072/03080] [00:00:54/00:37:40, 0.751s/it]: train_loss_raw=0.6524, running_loss=0.5958, LR=0.000100
[2025-08-27 07:58:17,054][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049360] [Batch 00080/03080] [00:01:00/00:37:34, 0.751s/it]: train_loss_raw=0.6484, running_loss=0.5957, LR=0.000100
[2025-08-27 07:58:23,110][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049368] [Batch 00088/03080] [00:01:06/00:37:29, 0.752s/it]: train_loss_raw=0.6334, running_loss=0.5984, LR=0.000100
[2025-08-27 07:58:29,173][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049376] [Batch 00096/03080] [00:01:12/00:37:25, 0.752s/it]: train_loss_raw=0.6660, running_loss=0.6004, LR=0.000100
[2025-08-27 07:58:35,229][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049384] [Batch 00104/03080] [00:01:18/00:37:20, 0.753s/it]: train_loss_raw=0.5077, running_loss=0.5991, LR=0.000100
[2025-08-27 07:58:41,331][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049392] [Batch 00112/03080] [00:01:24/00:37:16, 0.754s/it]: train_loss_raw=0.6802, running_loss=0.5998, LR=0.000100
[2025-08-27 07:58:47,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049400] [Batch 00120/03080] [00:01:30/00:37:13, 0.755s/it]: train_loss_raw=0.5654, running_loss=0.5988, LR=0.000100
[2025-08-27 07:58:53,560][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049408] [Batch 00128/03080] [00:01:36/00:37:08, 0.755s/it]: train_loss_raw=0.5720, running_loss=0.5982, LR=0.000100
[2025-08-27 07:58:59,592][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049416] [Batch 00136/03080] [00:01:42/00:37:02, 0.755s/it]: train_loss_raw=0.5680, running_loss=0.5991, LR=0.000100
[2025-08-27 07:59:06,025][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049424] [Batch 00144/03080] [00:01:49/00:37:04, 0.758s/it]: train_loss_raw=0.6577, running_loss=0.5995, LR=0.000100
[2025-08-27 07:59:12,090][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049432] [Batch 00152/03080] [00:01:55/00:36:58, 0.758s/it]: train_loss_raw=0.5871, running_loss=0.6004, LR=0.000100
[2025-08-27 07:59:18,155][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049440] [Batch 00160/03080] [00:02:01/00:36:52, 0.758s/it]: train_loss_raw=0.6778, running_loss=0.6024, LR=0.000100
[2025-08-27 07:59:24,218][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049448] [Batch 00168/03080] [00:02:07/00:36:46, 0.758s/it]: train_loss_raw=0.4823, running_loss=0.6009, LR=0.000100
[2025-08-27 07:59:30,276][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049456] [Batch 00176/03080] [00:02:13/00:36:40, 0.758s/it]: train_loss_raw=0.5874, running_loss=0.6015, LR=0.000100
[2025-08-27 07:59:36,463][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049464] [Batch 00184/03080] [00:02:19/00:36:36, 0.758s/it]: train_loss_raw=0.7297, running_loss=0.6029, LR=0.000100
[2025-08-27 07:59:42,525][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049472] [Batch 00192/03080] [00:02:25/00:36:29, 0.758s/it]: train_loss_raw=0.5484, running_loss=0.6011, LR=0.000100
[2025-08-27 07:59:48,641][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049480] [Batch 00200/03080] [00:02:31/00:36:24, 0.759s/it]: train_loss_raw=0.7227, running_loss=0.6038, LR=0.000100
[2025-08-27 07:59:54,788][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049488] [Batch 00208/03080] [00:02:37/00:36:19, 0.759s/it]: train_loss_raw=0.6713, running_loss=0.6051, LR=0.000100
[2025-08-27 08:00:00,922][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049496] [Batch 00216/03080] [00:02:43/00:36:14, 0.759s/it]: train_loss_raw=0.5195, running_loss=0.6045, LR=0.000100
[2025-08-27 08:00:07,008][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049504] [Batch 00224/03080] [00:02:50/00:36:08, 0.759s/it]: train_loss_raw=0.6132, running_loss=0.6040, LR=0.000100
[2025-08-27 08:00:13,119][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049512] [Batch 00232/03080] [00:02:56/00:36:02, 0.759s/it]: train_loss_raw=0.5121, running_loss=0.6020, LR=0.000100
[2025-08-27 08:00:19,315][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049520] [Batch 00240/03080] [00:03:02/00:35:58, 0.760s/it]: train_loss_raw=0.5802, running_loss=0.6030, LR=0.000100
[2025-08-27 08:00:25,560][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049528] [Batch 00248/03080] [00:03:08/00:35:53, 0.761s/it]: train_loss_raw=0.5482, running_loss=0.6033, LR=0.000100
[2025-08-27 08:00:31,623][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049536] [Batch 00256/03080] [00:03:14/00:35:47, 0.760s/it]: train_loss_raw=0.5696, running_loss=0.6024, LR=0.000100
[2025-08-27 08:00:37,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049544] [Batch 00264/03080] [00:03:20/00:35:40, 0.760s/it]: train_loss_raw=0.5684, running_loss=0.6017, LR=0.000100
[2025-08-27 08:00:43,155][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049552] [Batch 00272/03080] [00:03:26/00:35:28, 0.758s/it]: train_loss_raw=0.5920, running_loss=0.6029, LR=0.000100
[2025-08-27 08:00:49,249][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049560] [Batch 00280/03080] [00:03:32/00:35:23, 0.758s/it]: train_loss_raw=0.5919, running_loss=0.6051, LR=0.000100
[2025-08-27 08:00:55,388][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049568] [Batch 00288/03080] [00:03:38/00:35:17, 0.759s/it]: train_loss_raw=0.5177, running_loss=0.6039, LR=0.000100
[2025-08-27 08:01:01,435][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049576] [Batch 00296/03080] [00:03:44/00:35:11, 0.758s/it]: train_loss_raw=0.5164, running_loss=0.6025, LR=0.000100
[2025-08-27 08:01:07,461][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049584] [Batch 00304/03080] [00:03:50/00:35:05, 0.758s/it]: train_loss_raw=0.6482, running_loss=0.6007, LR=0.000100
[2025-08-27 08:01:13,545][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049592] [Batch 00312/03080] [00:03:56/00:34:59, 0.758s/it]: train_loss_raw=0.5844, running_loss=0.6017, LR=0.000100
[2025-08-27 08:01:19,656][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049600] [Batch 00320/03080] [00:04:02/00:34:53, 0.758s/it]: train_loss_raw=0.5846, running_loss=0.6027, LR=0.000100
[2025-08-27 08:01:25,786][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049608] [Batch 00328/03080] [00:04:08/00:34:47, 0.759s/it]: train_loss_raw=0.5871, running_loss=0.6035, LR=0.000100
[2025-08-27 08:01:31,942][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049616] [Batch 00336/03080] [00:04:15/00:34:42, 0.759s/it]: train_loss_raw=0.5917, running_loss=0.6039, LR=0.000100
[2025-08-27 08:01:38,026][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049624] [Batch 00344/03080] [00:04:21/00:34:36, 0.759s/it]: train_loss_raw=0.6407, running_loss=0.6027, LR=0.000100
[2025-08-27 08:01:44,137][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049632] [Batch 00352/03080] [00:04:27/00:34:30, 0.759s/it]: train_loss_raw=0.5947, running_loss=0.6018, LR=0.000100
[2025-08-27 08:01:50,276][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049640] [Batch 00360/03080] [00:04:33/00:34:25, 0.759s/it]: train_loss_raw=0.6703, running_loss=0.6009, LR=0.000100
[2025-08-27 08:01:56,368][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049648] [Batch 00368/03080] [00:04:39/00:34:19, 0.759s/it]: train_loss_raw=0.6552, running_loss=0.6012, LR=0.000100
[2025-08-27 08:02:02,453][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049656] [Batch 00376/03080] [00:04:45/00:34:13, 0.759s/it]: train_loss_raw=0.6450, running_loss=0.6008, LR=0.000100
[2025-08-27 08:02:08,582][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049664] [Batch 00384/03080] [00:04:51/00:34:07, 0.759s/it]: train_loss_raw=0.6109, running_loss=0.6008, LR=0.000100
[2025-08-27 08:02:14,709][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049672] [Batch 00392/03080] [00:04:57/00:34:01, 0.760s/it]: train_loss_raw=0.6117, running_loss=0.6001, LR=0.000100
[2025-08-27 08:02:20,825][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049680] [Batch 00400/03080] [00:05:03/00:33:56, 0.760s/it]: train_loss_raw=0.4951, running_loss=0.5984, LR=0.000100
[2025-08-27 08:02:27,013][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049688] [Batch 00408/03080] [00:05:10/00:33:50, 0.760s/it]: train_loss_raw=0.5657, running_loss=0.5982, LR=0.000100
[2025-08-27 08:02:33,067][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049696] [Batch 00416/03080] [00:05:16/00:33:44, 0.760s/it]: train_loss_raw=0.5337, running_loss=0.5984, LR=0.000100
[2025-08-27 08:02:39,226][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049704] [Batch 00424/03080] [00:05:22/00:33:38, 0.760s/it]: train_loss_raw=0.4729, running_loss=0.5985, LR=0.000100
[2025-08-27 08:02:45,372][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049712] [Batch 00432/03080] [00:05:28/00:33:33, 0.760s/it]: train_loss_raw=0.6580, running_loss=0.6001, LR=0.000100
[2025-08-27 08:02:51,453][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049720] [Batch 00440/03080] [00:05:34/00:33:27, 0.760s/it]: train_loss_raw=0.6515, running_loss=0.5996, LR=0.000100
[2025-08-27 08:02:57,588][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049728] [Batch 00448/03080] [00:05:40/00:33:21, 0.760s/it]: train_loss_raw=0.5663, running_loss=0.5983, LR=0.000100
[2025-08-27 08:03:03,882][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049736] [Batch 00456/03080] [00:05:46/00:33:16, 0.761s/it]: train_loss_raw=0.5604, running_loss=0.5978, LR=0.000100
[2025-08-27 08:03:10,116][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049744] [Batch 00464/03080] [00:05:53/00:33:11, 0.761s/it]: train_loss_raw=0.5602, running_loss=0.5975, LR=0.000100
[2025-08-27 08:03:16,307][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049752] [Batch 00472/03080] [00:05:59/00:33:05, 0.761s/it]: train_loss_raw=0.5221, running_loss=0.5981, LR=0.000100
[2025-08-27 08:03:22,483][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049760] [Batch 00480/03080] [00:06:05/00:33:00, 0.762s/it]: train_loss_raw=0.6382, running_loss=0.5964, LR=0.000100
[2025-08-27 08:03:28,598][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049768] [Batch 00488/03080] [00:06:11/00:32:54, 0.762s/it]: train_loss_raw=0.6738, running_loss=0.5972, LR=0.000100
[2025-08-27 08:03:34,670][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049776] [Batch 00496/03080] [00:06:17/00:32:47, 0.762s/it]: train_loss_raw=0.5302, running_loss=0.5968, LR=0.000100
[2025-08-27 08:03:40,748][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049784] [Batch 00504/03080] [00:06:23/00:32:41, 0.762s/it]: train_loss_raw=0.6255, running_loss=0.5990, LR=0.000100
[2025-08-27 08:03:46,733][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049792] [Batch 00512/03080] [00:06:29/00:32:35, 0.761s/it]: train_loss_raw=0.6122, running_loss=0.5982, LR=0.000100
[2025-08-27 08:03:52,309][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049800] [Batch 00520/03080] [00:06:35/00:32:26, 0.760s/it]: train_loss_raw=0.5729, running_loss=0.5982, LR=0.000100
[2025-08-27 08:03:58,288][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049808] [Batch 00528/03080] [00:06:41/00:32:19, 0.760s/it]: train_loss_raw=0.5791, running_loss=0.5979, LR=0.000100
[2025-08-27 08:04:04,395][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049816] [Batch 00536/03080] [00:06:47/00:32:13, 0.760s/it]: train_loss_raw=0.6290, running_loss=0.5992, LR=0.000100
[2025-08-27 08:04:10,534][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049824] [Batch 00544/03080] [00:06:53/00:32:08, 0.760s/it]: train_loss_raw=0.5839, running_loss=0.5987, LR=0.000100
[2025-08-27 08:04:16,687][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049832] [Batch 00552/03080] [00:06:59/00:32:02, 0.760s/it]: train_loss_raw=0.6035, running_loss=0.5964, LR=0.000100
[2025-08-27 08:04:22,815][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049840] [Batch 00560/03080] [00:07:05/00:31:56, 0.760s/it]: train_loss_raw=0.5065, running_loss=0.5951, LR=0.000100
[2025-08-27 08:04:29,024][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049848] [Batch 00568/03080] [00:07:12/00:31:50, 0.761s/it]: train_loss_raw=0.4814, running_loss=0.5943, LR=0.000100
[2025-08-27 08:04:35,050][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049856] [Batch 00576/03080] [00:07:18/00:31:44, 0.761s/it]: train_loss_raw=0.5614, running_loss=0.5918, LR=0.000100
[2025-08-27 08:04:41,014][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049864] [Batch 00584/03080] [00:07:24/00:31:37, 0.760s/it]: train_loss_raw=0.5865, running_loss=0.5931, LR=0.000100
[2025-08-27 08:04:47,041][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049872] [Batch 00592/03080] [00:07:30/00:31:31, 0.760s/it]: train_loss_raw=0.6134, running_loss=0.5905, LR=0.000100
[2025-08-27 08:04:53,258][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049880] [Batch 00600/03080] [00:07:36/00:31:26, 0.761s/it]: train_loss_raw=0.5247, running_loss=0.5891, LR=0.000100
[2025-08-27 08:04:59,415][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049888] [Batch 00608/03080] [00:07:42/00:31:20, 0.761s/it]: train_loss_raw=0.5878, running_loss=0.5909, LR=0.000100
[2025-08-27 08:05:05,473][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049896] [Batch 00616/03080] [00:07:48/00:31:14, 0.761s/it]: train_loss_raw=0.5796, running_loss=0.5900, LR=0.000100
[2025-08-27 08:05:11,643][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049904] [Batch 00624/03080] [00:07:54/00:31:08, 0.761s/it]: train_loss_raw=0.5376, running_loss=0.5902, LR=0.000100
[2025-08-27 08:05:17,737][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049912] [Batch 00632/03080] [00:08:00/00:31:02, 0.761s/it]: train_loss_raw=0.6467, running_loss=0.5910, LR=0.000100
[2025-08-27 08:05:23,942][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049920] [Batch 00640/03080] [00:08:07/00:30:56, 0.761s/it]: train_loss_raw=0.5336, running_loss=0.5894, LR=0.000100
[2025-08-27 08:05:30,204][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049928] [Batch 00648/03080] [00:08:13/00:30:51, 0.761s/it]: train_loss_raw=0.6085, running_loss=0.5921, LR=0.000100
[2025-08-27 08:05:36,343][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049936] [Batch 00656/03080] [00:08:19/00:30:45, 0.761s/it]: train_loss_raw=0.5892, running_loss=0.5934, LR=0.000100
[2025-08-27 08:05:42,495][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049944] [Batch 00664/03080] [00:08:25/00:30:39, 0.761s/it]: train_loss_raw=0.5161, running_loss=0.5931, LR=0.000100
[2025-08-27 08:05:48,579][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049952] [Batch 00672/03080] [00:08:31/00:30:33, 0.761s/it]: train_loss_raw=0.6624, running_loss=0.5937, LR=0.000100
[2025-08-27 08:05:54,613][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049960] [Batch 00680/03080] [00:08:37/00:30:27, 0.761s/it]: train_loss_raw=0.5326, running_loss=0.5917, LR=0.000100
[2025-08-27 08:06:00,683][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049968] [Batch 00688/03080] [00:08:43/00:30:20, 0.761s/it]: train_loss_raw=0.6192, running_loss=0.5924, LR=0.000100
[2025-08-27 08:06:06,734][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049976] [Batch 00696/03080] [00:08:49/00:30:14, 0.761s/it]: train_loss_raw=0.5822, running_loss=0.5928, LR=0.000100
[2025-08-27 08:06:12,789][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049984] [Batch 00704/03080] [00:08:55/00:30:08, 0.761s/it]: train_loss_raw=0.5219, running_loss=0.5902, LR=0.000100
[2025-08-27 08:06:18,960][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 049992] [Batch 00712/03080] [00:09:02/00:30:02, 0.761s/it]: train_loss_raw=0.5959, running_loss=0.5905, LR=0.000100
[2025-08-27 08:06:25,101][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050000] [Batch 00720/03080] [00:09:08/00:29:56, 0.761s/it]: train_loss_raw=0.6123, running_loss=0.5921, LR=0.000100
[2025-08-27 08:06:34,522][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050008] [Batch 00728/03080] [00:09:17/00:30:01, 0.766s/it]: train_loss_raw=0.5972, running_loss=0.5910, LR=0.000100
[2025-08-27 08:06:40,168][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050016] [Batch 00736/03080] [00:09:23/00:29:53, 0.765s/it]: train_loss_raw=0.4900, running_loss=0.5882, LR=0.000100
[2025-08-27 08:06:46,223][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050024] [Batch 00744/03080] [00:09:29/00:29:47, 0.765s/it]: train_loss_raw=0.5010, running_loss=0.5886, LR=0.000100
[2025-08-27 08:06:52,340][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050032] [Batch 00752/03080] [00:09:35/00:29:41, 0.765s/it]: train_loss_raw=0.6035, running_loss=0.5902, LR=0.000100
[2025-08-27 08:06:58,365][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050040] [Batch 00760/03080] [00:09:41/00:29:34, 0.765s/it]: train_loss_raw=0.6080, running_loss=0.5897, LR=0.000100
[2025-08-27 08:07:04,547][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050048] [Batch 00768/03080] [00:09:47/00:29:28, 0.765s/it]: train_loss_raw=0.5462, running_loss=0.5882, LR=0.000100
[2025-08-27 08:07:10,677][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050056] [Batch 00776/03080] [00:09:53/00:29:22, 0.765s/it]: train_loss_raw=0.4849, running_loss=0.5885, LR=0.000100
[2025-08-27 08:07:16,818][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050064] [Batch 00784/03080] [00:09:59/00:29:16, 0.765s/it]: train_loss_raw=0.5939, running_loss=0.5896, LR=0.000100
[2025-08-27 08:07:22,953][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050072] [Batch 00792/03080] [00:10:06/00:29:10, 0.765s/it]: train_loss_raw=0.4824, running_loss=0.5893, LR=0.000100
[2025-08-27 08:07:29,288][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050080] [Batch 00800/03080] [00:10:12/00:29:05, 0.765s/it]: train_loss_raw=0.5565, running_loss=0.5909, LR=0.000100
[2025-08-27 08:07:35,540][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050088] [Batch 00808/03080] [00:10:18/00:28:59, 0.766s/it]: train_loss_raw=0.4596, running_loss=0.5906, LR=0.000100
[2025-08-27 08:07:41,721][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050096] [Batch 00816/03080] [00:10:24/00:28:53, 0.766s/it]: train_loss_raw=0.6244, running_loss=0.5896, LR=0.000100
[2025-08-27 08:07:47,890][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050104] [Batch 00824/03080] [00:10:30/00:28:47, 0.766s/it]: train_loss_raw=0.5798, running_loss=0.5877, LR=0.000100
[2025-08-27 08:07:54,066][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050112] [Batch 00832/03080] [00:10:37/00:28:41, 0.766s/it]: train_loss_raw=0.6355, running_loss=0.5885, LR=0.000100
[2025-08-27 08:08:00,237][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050120] [Batch 00840/03080] [00:10:43/00:28:35, 0.766s/it]: train_loss_raw=0.5530, running_loss=0.5910, LR=0.000100
[2025-08-27 08:08:06,376][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050128] [Batch 00848/03080] [00:10:49/00:28:29, 0.766s/it]: train_loss_raw=0.5130, running_loss=0.5915, LR=0.000100
[2025-08-27 08:08:12,591][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050136] [Batch 00856/03080] [00:10:55/00:28:23, 0.766s/it]: train_loss_raw=0.5154, running_loss=0.5905, LR=0.000100
[2025-08-27 08:08:18,788][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050144] [Batch 00864/03080] [00:11:01/00:28:17, 0.766s/it]: train_loss_raw=0.6168, running_loss=0.5913, LR=0.000100
[2025-08-27 08:08:24,973][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050152] [Batch 00872/03080] [00:11:08/00:28:11, 0.766s/it]: train_loss_raw=0.5857, running_loss=0.5901, LR=0.000100
[2025-08-27 08:08:31,115][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050160] [Batch 00880/03080] [00:11:14/00:28:05, 0.766s/it]: train_loss_raw=0.5027, running_loss=0.5909, LR=0.000100
[2025-08-27 08:08:37,289][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050168] [Batch 00888/03080] [00:11:20/00:27:59, 0.766s/it]: train_loss_raw=0.5756, running_loss=0.5885, LR=0.000100
[2025-08-27 08:08:43,445][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050176] [Batch 00896/03080] [00:11:26/00:27:53, 0.766s/it]: train_loss_raw=0.5530, running_loss=0.5864, LR=0.000100
[2025-08-27 08:08:49,571][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050184] [Batch 00904/03080] [00:11:32/00:27:47, 0.766s/it]: train_loss_raw=0.6194, running_loss=0.5858, LR=0.000100
[2025-08-27 08:08:55,627][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050192] [Batch 00912/03080] [00:11:38/00:27:40, 0.766s/it]: train_loss_raw=0.5406, running_loss=0.5862, LR=0.000100
[2025-08-27 08:09:01,738][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050200] [Batch 00920/03080] [00:11:44/00:27:34, 0.766s/it]: train_loss_raw=0.4888, running_loss=0.5873, LR=0.000100
[2025-08-27 08:09:07,914][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050208] [Batch 00928/03080] [00:11:50/00:27:28, 0.766s/it]: train_loss_raw=0.5782, running_loss=0.5869, LR=0.000100
[2025-08-27 08:09:14,002][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050216] [Batch 00936/03080] [00:11:57/00:27:22, 0.766s/it]: train_loss_raw=0.5517, running_loss=0.5870, LR=0.000100
[2025-08-27 08:09:20,185][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050224] [Batch 00944/03080] [00:12:03/00:27:16, 0.766s/it]: train_loss_raw=0.4934, running_loss=0.5856, LR=0.000100
[2025-08-27 08:09:26,438][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050232] [Batch 00952/03080] [00:12:09/00:27:10, 0.766s/it]: train_loss_raw=0.6877, running_loss=0.5853, LR=0.000100
[2025-08-27 08:09:32,526][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050240] [Batch 00960/03080] [00:12:15/00:27:04, 0.766s/it]: train_loss_raw=0.5516, running_loss=0.5866, LR=0.000100
[2025-08-27 08:09:38,631][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050248] [Batch 00968/03080] [00:12:21/00:26:58, 0.766s/it]: train_loss_raw=0.6128, running_loss=0.5884, LR=0.000100
[2025-08-27 08:09:44,844][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050256] [Batch 00976/03080] [00:12:27/00:26:52, 0.766s/it]: train_loss_raw=0.5939, running_loss=0.5874, LR=0.000100
[2025-08-27 08:09:50,971][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050264] [Batch 00984/03080] [00:12:34/00:26:46, 0.766s/it]: train_loss_raw=0.6403, running_loss=0.5881, LR=0.000100
[2025-08-27 08:09:57,072][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050272] [Batch 00992/03080] [00:12:40/00:26:39, 0.766s/it]: train_loss_raw=0.5292, running_loss=0.5891, LR=0.000100
[2025-08-27 08:10:03,085][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050280] [Batch 01000/03080] [00:12:46/00:26:33, 0.766s/it]: train_loss_raw=0.5215, running_loss=0.5884, LR=0.000100
[2025-08-27 08:10:09,129][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050288] [Batch 01008/03080] [00:12:52/00:26:27, 0.766s/it]: train_loss_raw=0.5599, running_loss=0.5878, LR=0.000100
[2025-08-27 08:10:15,280][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050296] [Batch 01016/03080] [00:12:58/00:26:21, 0.766s/it]: train_loss_raw=0.5707, running_loss=0.5877, LR=0.000100
[2025-08-27 08:10:21,440][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050304] [Batch 01024/03080] [00:13:04/00:26:15, 0.766s/it]: train_loss_raw=0.6043, running_loss=0.5844, LR=0.000100
[2025-08-27 08:10:27,630][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050312] [Batch 01032/03080] [00:13:10/00:26:09, 0.766s/it]: train_loss_raw=0.6133, running_loss=0.5857, LR=0.000100
[2025-08-27 08:10:33,693][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050320] [Batch 01040/03080] [00:13:16/00:26:02, 0.766s/it]: train_loss_raw=0.4900, running_loss=0.5850, LR=0.000100
[2025-08-27 08:10:39,827][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050328] [Batch 01048/03080] [00:13:22/00:25:56, 0.766s/it]: train_loss_raw=0.5403, running_loss=0.5845, LR=0.000100
[2025-08-27 08:10:46,060][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050336] [Batch 01056/03080] [00:13:29/00:25:50, 0.766s/it]: train_loss_raw=0.6218, running_loss=0.5842, LR=0.000100
[2025-08-27 08:10:52,225][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050344] [Batch 01064/03080] [00:13:35/00:25:44, 0.766s/it]: train_loss_raw=0.6428, running_loss=0.5869, LR=0.000100
[2025-08-27 08:10:58,416][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050352] [Batch 01072/03080] [00:13:41/00:25:38, 0.766s/it]: train_loss_raw=0.5554, running_loss=0.5842, LR=0.000100
[2025-08-27 08:11:04,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050360] [Batch 01080/03080] [00:13:47/00:25:32, 0.766s/it]: train_loss_raw=0.6342, running_loss=0.5848, LR=0.000100
[2025-08-27 08:11:10,648][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050368] [Batch 01088/03080] [00:13:53/00:25:26, 0.766s/it]: train_loss_raw=0.5539, running_loss=0.5862, LR=0.000100
[2025-08-27 08:11:16,754][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050376] [Batch 01096/03080] [00:13:59/00:25:20, 0.766s/it]: train_loss_raw=0.5584, running_loss=0.5863, LR=0.000100
[2025-08-27 08:11:22,793][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050384] [Batch 01104/03080] [00:14:05/00:25:13, 0.766s/it]: train_loss_raw=0.5804, running_loss=0.5852, LR=0.000100
[2025-08-27 08:11:28,933][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050392] [Batch 01112/03080] [00:14:11/00:25:07, 0.766s/it]: train_loss_raw=0.5145, running_loss=0.5852, LR=0.000100
[2025-08-27 08:11:35,111][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050400] [Batch 01120/03080] [00:14:18/00:25:01, 0.766s/it]: train_loss_raw=0.6552, running_loss=0.5889, LR=0.000100
[2025-08-27 08:11:41,246][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050408] [Batch 01128/03080] [00:14:24/00:24:55, 0.766s/it]: train_loss_raw=0.5750, running_loss=0.5882, LR=0.000100
[2025-08-27 08:11:47,352][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050416] [Batch 01136/03080] [00:14:30/00:24:49, 0.766s/it]: train_loss_raw=0.5817, running_loss=0.5909, LR=0.000100
[2025-08-27 08:11:53,377][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050424] [Batch 01144/03080] [00:14:36/00:24:43, 0.766s/it]: train_loss_raw=0.6004, running_loss=0.5886, LR=0.000100
[2025-08-27 08:11:59,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050432] [Batch 01152/03080] [00:14:42/00:24:37, 0.766s/it]: train_loss_raw=0.5741, running_loss=0.5896, LR=0.000100
[2025-08-27 08:12:05,576][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050440] [Batch 01160/03080] [00:14:48/00:24:30, 0.766s/it]: train_loss_raw=0.5096, running_loss=0.5904, LR=0.000100
[2025-08-27 08:12:11,708][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050448] [Batch 01168/03080] [00:14:54/00:24:24, 0.766s/it]: train_loss_raw=0.6197, running_loss=0.5894, LR=0.000100
[2025-08-27 08:12:17,786][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050456] [Batch 01176/03080] [00:15:00/00:24:18, 0.766s/it]: train_loss_raw=0.6378, running_loss=0.5879, LR=0.000100
[2025-08-27 08:12:23,936][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050464] [Batch 01184/03080] [00:15:06/00:24:12, 0.766s/it]: train_loss_raw=0.6462, running_loss=0.5886, LR=0.000100
[2025-08-27 08:12:30,053][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050472] [Batch 01192/03080] [00:15:13/00:24:06, 0.766s/it]: train_loss_raw=0.6502, running_loss=0.5874, LR=0.000100
[2025-08-27 08:12:35,985][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050480] [Batch 01200/03080] [00:15:19/00:23:59, 0.766s/it]: train_loss_raw=0.5156, running_loss=0.5861, LR=0.000100
[2025-08-27 08:12:41,626][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050488] [Batch 01208/03080] [00:15:24/00:23:52, 0.765s/it]: train_loss_raw=0.5167, running_loss=0.5868, LR=0.000100
[2025-08-27 08:12:47,803][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050496] [Batch 01216/03080] [00:15:30/00:23:46, 0.766s/it]: train_loss_raw=0.6377, running_loss=0.5879, LR=0.000100
[2025-08-27 08:12:53,958][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050504] [Batch 01224/03080] [00:15:37/00:23:40, 0.766s/it]: train_loss_raw=0.6406, running_loss=0.5887, LR=0.000100
[2025-08-27 08:12:59,901][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050512] [Batch 01232/03080] [00:15:42/00:23:34, 0.765s/it]: train_loss_raw=0.4958, running_loss=0.5848, LR=0.000100
[2025-08-27 08:13:06,132][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050520] [Batch 01240/03080] [00:15:49/00:23:28, 0.765s/it]: train_loss_raw=0.5586, running_loss=0.5848, LR=0.000100
[2025-08-27 08:13:12,253][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050528] [Batch 01248/03080] [00:15:55/00:23:22, 0.765s/it]: train_loss_raw=0.6757, running_loss=0.5848, LR=0.000100
[2025-08-27 08:13:18,365][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050536] [Batch 01256/03080] [00:16:01/00:23:16, 0.765s/it]: train_loss_raw=0.6254, running_loss=0.5873, LR=0.000100
[2025-08-27 08:13:24,486][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050544] [Batch 01264/03080] [00:16:07/00:23:10, 0.765s/it]: train_loss_raw=0.6833, running_loss=0.5879, LR=0.000100
[2025-08-27 08:13:30,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050552] [Batch 01272/03080] [00:16:13/00:23:03, 0.765s/it]: train_loss_raw=0.5579, running_loss=0.5871, LR=0.000100
[2025-08-27 08:13:36,702][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050560] [Batch 01280/03080] [00:16:19/00:22:57, 0.765s/it]: train_loss_raw=0.6190, running_loss=0.5902, LR=0.000100
[2025-08-27 08:13:42,952][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050568] [Batch 01288/03080] [00:16:26/00:22:51, 0.766s/it]: train_loss_raw=0.5945, running_loss=0.5879, LR=0.000100
[2025-08-27 08:13:49,244][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050576] [Batch 01296/03080] [00:16:32/00:22:45, 0.766s/it]: train_loss_raw=0.5455, running_loss=0.5882, LR=0.000100
[2025-08-27 08:13:55,443][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050584] [Batch 01304/03080] [00:16:38/00:22:39, 0.766s/it]: train_loss_raw=0.4873, running_loss=0.5887, LR=0.000100
[2025-08-27 08:14:01,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050592] [Batch 01312/03080] [00:16:44/00:22:33, 0.766s/it]: train_loss_raw=0.5560, running_loss=0.5892, LR=0.000100
[2025-08-27 08:14:07,799][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050600] [Batch 01320/03080] [00:16:50/00:22:27, 0.766s/it]: train_loss_raw=0.6142, running_loss=0.5884, LR=0.000100
[2025-08-27 08:14:13,898][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050608] [Batch 01328/03080] [00:16:56/00:22:21, 0.766s/it]: train_loss_raw=0.6095, running_loss=0.5876, LR=0.000100
[2025-08-27 08:14:19,963][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050616] [Batch 01336/03080] [00:17:03/00:22:15, 0.766s/it]: train_loss_raw=0.5009, running_loss=0.5869, LR=0.000100
[2025-08-27 08:14:26,105][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050624] [Batch 01344/03080] [00:17:09/00:22:09, 0.766s/it]: train_loss_raw=0.5987, running_loss=0.5868, LR=0.000100
[2025-08-27 08:14:32,236][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050632] [Batch 01352/03080] [00:17:15/00:22:03, 0.766s/it]: train_loss_raw=0.5644, running_loss=0.5876, LR=0.000100
[2025-08-27 08:14:38,336][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050640] [Batch 01360/03080] [00:17:21/00:21:57, 0.766s/it]: train_loss_raw=0.6017, running_loss=0.5889, LR=0.000100
[2025-08-27 08:14:44,503][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050648] [Batch 01368/03080] [00:17:27/00:21:50, 0.766s/it]: train_loss_raw=0.6313, running_loss=0.5897, LR=0.000100
[2025-08-27 08:14:50,638][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050656] [Batch 01376/03080] [00:17:33/00:21:44, 0.766s/it]: train_loss_raw=0.5570, running_loss=0.5887, LR=0.000100
[2025-08-27 08:14:56,756][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050664] [Batch 01384/03080] [00:17:39/00:21:38, 0.766s/it]: train_loss_raw=0.5471, running_loss=0.5912, LR=0.000100
[2025-08-27 08:15:02,848][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050672] [Batch 01392/03080] [00:17:45/00:21:32, 0.766s/it]: train_loss_raw=0.5509, running_loss=0.5875, LR=0.000100
[2025-08-27 08:15:08,661][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050680] [Batch 01400/03080] [00:17:51/00:21:26, 0.766s/it]: train_loss_raw=0.4959, running_loss=0.5843, LR=0.000100
[2025-08-27 08:15:14,843][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050688] [Batch 01408/03080] [00:17:57/00:21:20, 0.766s/it]: train_loss_raw=0.5395, running_loss=0.5816, LR=0.000100
[2025-08-27 08:15:20,902][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050696] [Batch 01416/03080] [00:18:03/00:21:13, 0.766s/it]: train_loss_raw=0.5983, running_loss=0.5833, LR=0.000100
[2025-08-27 08:15:27,001][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050704] [Batch 01424/03080] [00:18:10/00:21:07, 0.765s/it]: train_loss_raw=0.6275, running_loss=0.5828, LR=0.000100
[2025-08-27 08:15:33,107][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050712] [Batch 01432/03080] [00:18:16/00:21:01, 0.765s/it]: train_loss_raw=0.7299, running_loss=0.5856, LR=0.000100
[2025-08-27 08:15:39,215][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050720] [Batch 01440/03080] [00:18:22/00:20:55, 0.765s/it]: train_loss_raw=0.5130, running_loss=0.5830, LR=0.000100
[2025-08-27 08:15:45,352][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050728] [Batch 01448/03080] [00:18:28/00:20:49, 0.765s/it]: train_loss_raw=0.5458, running_loss=0.5833, LR=0.000100
[2025-08-27 08:15:51,522][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050736] [Batch 01456/03080] [00:18:34/00:20:43, 0.766s/it]: train_loss_raw=0.6249, running_loss=0.5841, LR=0.000100
[2025-08-27 08:15:57,754][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050744] [Batch 01464/03080] [00:18:40/00:20:37, 0.766s/it]: train_loss_raw=0.5031, running_loss=0.5847, LR=0.000100
[2025-08-27 08:16:03,979][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050752] [Batch 01472/03080] [00:18:47/00:20:31, 0.766s/it]: train_loss_raw=0.5191, running_loss=0.5832, LR=0.000100
[2025-08-27 08:16:10,130][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050760] [Batch 01480/03080] [00:18:53/00:20:25, 0.766s/it]: train_loss_raw=0.5225, running_loss=0.5839, LR=0.000100
[2025-08-27 08:16:16,281][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050768] [Batch 01488/03080] [00:18:59/00:20:18, 0.766s/it]: train_loss_raw=0.6443, running_loss=0.5837, LR=0.000100
[2025-08-27 08:16:22,400][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050776] [Batch 01496/03080] [00:19:05/00:20:12, 0.766s/it]: train_loss_raw=0.5802, running_loss=0.5839, LR=0.000100
[2025-08-27 08:16:28,507][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050784] [Batch 01504/03080] [00:19:11/00:20:06, 0.766s/it]: train_loss_raw=0.6365, running_loss=0.5845, LR=0.000100
[2025-08-27 08:16:34,669][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050792] [Batch 01512/03080] [00:19:17/00:20:00, 0.766s/it]: train_loss_raw=0.6430, running_loss=0.5839, LR=0.000100
[2025-08-27 08:16:40,808][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050800] [Batch 01520/03080] [00:19:23/00:19:54, 0.766s/it]: train_loss_raw=0.6699, running_loss=0.5847, LR=0.000100
[2025-08-27 08:16:46,920][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050808] [Batch 01528/03080] [00:19:29/00:19:48, 0.766s/it]: train_loss_raw=0.6226, running_loss=0.5873, LR=0.000100
[2025-08-27 08:16:52,999][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050816] [Batch 01536/03080] [00:19:36/00:19:42, 0.766s/it]: train_loss_raw=0.6152, running_loss=0.5875, LR=0.000100
[2025-08-27 08:16:59,096][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050824] [Batch 01544/03080] [00:19:42/00:19:36, 0.766s/it]: train_loss_raw=0.5889, running_loss=0.5857, LR=0.000100
[2025-08-27 08:17:05,232][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050832] [Batch 01552/03080] [00:19:48/00:19:29, 0.766s/it]: train_loss_raw=0.5347, running_loss=0.5840, LR=0.000100
[2025-08-27 08:17:11,374][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050840] [Batch 01560/03080] [00:19:54/00:19:23, 0.766s/it]: train_loss_raw=0.5937, running_loss=0.5852, LR=0.000100
[2025-08-27 08:17:17,461][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050848] [Batch 01568/03080] [00:20:00/00:19:17, 0.766s/it]: train_loss_raw=0.5139, running_loss=0.5865, LR=0.000100
[2025-08-27 08:17:23,617][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050856] [Batch 01576/03080] [00:20:06/00:19:11, 0.766s/it]: train_loss_raw=0.6318, running_loss=0.5860, LR=0.000100
[2025-08-27 08:17:29,654][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050864] [Batch 01584/03080] [00:20:12/00:19:05, 0.766s/it]: train_loss_raw=0.5740, running_loss=0.5857, LR=0.000100
[2025-08-27 08:17:35,860][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050872] [Batch 01592/03080] [00:20:18/00:18:59, 0.766s/it]: train_loss_raw=0.6426, running_loss=0.5869, LR=0.000100
[2025-08-27 08:17:42,017][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050880] [Batch 01600/03080] [00:20:25/00:18:53, 0.766s/it]: train_loss_raw=0.5791, running_loss=0.5860, LR=0.000100
[2025-08-27 08:17:48,150][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050888] [Batch 01608/03080] [00:20:31/00:18:47, 0.766s/it]: train_loss_raw=0.6536, running_loss=0.5866, LR=0.000100
[2025-08-27 08:17:54,286][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050896] [Batch 01616/03080] [00:20:37/00:18:40, 0.766s/it]: train_loss_raw=0.6514, running_loss=0.5882, LR=0.000100
[2025-08-27 08:18:00,398][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050904] [Batch 01624/03080] [00:20:43/00:18:34, 0.766s/it]: train_loss_raw=0.5303, running_loss=0.5896, LR=0.000100
[2025-08-27 08:18:06,498][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050912] [Batch 01632/03080] [00:20:49/00:18:28, 0.766s/it]: train_loss_raw=0.5830, running_loss=0.5855, LR=0.000100
[2025-08-27 08:18:12,598][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050920] [Batch 01640/03080] [00:20:55/00:18:22, 0.766s/it]: train_loss_raw=0.5894, running_loss=0.5843, LR=0.000100
[2025-08-27 08:18:18,651][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050928] [Batch 01648/03080] [00:21:01/00:18:16, 0.766s/it]: train_loss_raw=0.4868, running_loss=0.5818, LR=0.000100
[2025-08-27 08:18:24,778][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050936] [Batch 01656/03080] [00:21:07/00:18:10, 0.766s/it]: train_loss_raw=0.6077, running_loss=0.5823, LR=0.000100
[2025-08-27 08:18:30,865][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050944] [Batch 01664/03080] [00:21:13/00:18:04, 0.766s/it]: train_loss_raw=0.5028, running_loss=0.5808, LR=0.000100
[2025-08-27 08:18:36,978][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050952] [Batch 01672/03080] [00:21:20/00:17:57, 0.766s/it]: train_loss_raw=0.6009, running_loss=0.5806, LR=0.000100
[2025-08-27 08:18:43,069][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050960] [Batch 01680/03080] [00:21:26/00:17:51, 0.766s/it]: train_loss_raw=0.4894, running_loss=0.5800, LR=0.000100
[2025-08-27 08:18:49,196][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050968] [Batch 01688/03080] [00:21:32/00:17:45, 0.766s/it]: train_loss_raw=0.6684, running_loss=0.5805, LR=0.000100
[2025-08-27 08:18:55,305][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050976] [Batch 01696/03080] [00:21:38/00:17:39, 0.766s/it]: train_loss_raw=0.6471, running_loss=0.5832, LR=0.000100
[2025-08-27 08:19:01,543][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050984] [Batch 01704/03080] [00:21:44/00:17:33, 0.766s/it]: train_loss_raw=0.6074, running_loss=0.5856, LR=0.000100
[2025-08-27 08:19:07,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 050992] [Batch 01712/03080] [00:21:50/00:17:27, 0.766s/it]: train_loss_raw=0.6093, running_loss=0.5838, LR=0.000100
[2025-08-27 08:19:13,819][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051000] [Batch 01720/03080] [00:21:56/00:17:21, 0.766s/it]: train_loss_raw=0.6591, running_loss=0.5827, LR=0.000100
[2025-08-27 08:19:19,977][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051008] [Batch 01728/03080] [00:22:03/00:17:15, 0.766s/it]: train_loss_raw=0.5971, running_loss=0.5832, LR=0.000100
[2025-08-27 08:19:26,185][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051016] [Batch 01736/03080] [00:22:09/00:17:09, 0.766s/it]: train_loss_raw=0.4881, running_loss=0.5810, LR=0.000100
[2025-08-27 08:19:32,269][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051024] [Batch 01744/03080] [00:22:15/00:17:02, 0.766s/it]: train_loss_raw=0.6236, running_loss=0.5808, LR=0.000100
[2025-08-27 08:19:38,356][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051032] [Batch 01752/03080] [00:22:21/00:16:56, 0.766s/it]: train_loss_raw=0.5323, running_loss=0.5799, LR=0.000100
[2025-08-27 08:19:44,457][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051040] [Batch 01760/03080] [00:22:27/00:16:50, 0.766s/it]: train_loss_raw=0.4880, running_loss=0.5818, LR=0.000100
[2025-08-27 08:19:50,540][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051048] [Batch 01768/03080] [00:22:33/00:16:44, 0.766s/it]: train_loss_raw=0.5655, running_loss=0.5797, LR=0.000100
[2025-08-27 08:19:56,660][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051056] [Batch 01776/03080] [00:22:39/00:16:38, 0.766s/it]: train_loss_raw=0.6415, running_loss=0.5786, LR=0.000100
[2025-08-27 08:20:02,820][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051064] [Batch 01784/03080] [00:22:45/00:16:32, 0.766s/it]: train_loss_raw=0.5124, running_loss=0.5776, LR=0.000100
[2025-08-27 08:20:08,955][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051072] [Batch 01792/03080] [00:22:52/00:16:26, 0.766s/it]: train_loss_raw=0.6110, running_loss=0.5799, LR=0.000100
[2025-08-27 08:20:15,105][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051080] [Batch 01800/03080] [00:22:58/00:16:20, 0.766s/it]: train_loss_raw=0.5915, running_loss=0.5798, LR=0.000100
[2025-08-27 08:20:21,174][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051088] [Batch 01808/03080] [00:23:04/00:16:13, 0.766s/it]: train_loss_raw=0.6174, running_loss=0.5778, LR=0.000100
[2025-08-27 08:20:27,363][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051096] [Batch 01816/03080] [00:23:10/00:16:07, 0.766s/it]: train_loss_raw=0.5655, running_loss=0.5777, LR=0.000100
[2025-08-27 08:20:33,411][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051104] [Batch 01824/03080] [00:23:16/00:16:01, 0.766s/it]: train_loss_raw=0.5854, running_loss=0.5753, LR=0.000100
[2025-08-27 08:20:39,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051112] [Batch 01832/03080] [00:23:22/00:15:55, 0.766s/it]: train_loss_raw=0.5582, running_loss=0.5783, LR=0.000100
[2025-08-27 08:20:45,498][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051120] [Batch 01840/03080] [00:23:28/00:15:49, 0.766s/it]: train_loss_raw=0.5973, running_loss=0.5791, LR=0.000100
[2025-08-27 08:20:51,327][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051128] [Batch 01848/03080] [00:23:34/00:15:42, 0.765s/it]: train_loss_raw=0.5342, running_loss=0.5793, LR=0.000100
[2025-08-27 08:20:57,458][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051136] [Batch 01856/03080] [00:23:40/00:15:36, 0.765s/it]: train_loss_raw=0.5455, running_loss=0.5798, LR=0.000100
[2025-08-27 08:21:03,480][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051144] [Batch 01864/03080] [00:23:46/00:15:30, 0.765s/it]: train_loss_raw=0.5801, running_loss=0.5780, LR=0.000100
[2025-08-27 08:21:09,435][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051152] [Batch 01872/03080] [00:23:52/00:15:24, 0.765s/it]: train_loss_raw=0.6778, running_loss=0.5770, LR=0.000100
[2025-08-27 08:21:15,509][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051160] [Batch 01880/03080] [00:23:58/00:15:18, 0.765s/it]: train_loss_raw=0.5581, running_loss=0.5772, LR=0.000100
[2025-08-27 08:21:21,796][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051168] [Batch 01888/03080] [00:24:04/00:15:12, 0.765s/it]: train_loss_raw=0.4847, running_loss=0.5742, LR=0.000100
[2025-08-27 08:21:27,868][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051176] [Batch 01896/03080] [00:24:10/00:15:06, 0.765s/it]: train_loss_raw=0.5655, running_loss=0.5752, LR=0.000100
[2025-08-27 08:21:33,956][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051184] [Batch 01904/03080] [00:24:17/00:14:59, 0.765s/it]: train_loss_raw=0.6649, running_loss=0.5739, LR=0.000100
[2025-08-27 08:21:39,805][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051192] [Batch 01912/03080] [00:24:22/00:14:53, 0.765s/it]: train_loss_raw=0.6256, running_loss=0.5743, LR=0.000100
[2025-08-27 08:21:45,809][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051200] [Batch 01920/03080] [00:24:28/00:14:47, 0.765s/it]: train_loss_raw=0.5061, running_loss=0.5727, LR=0.000100
[2025-08-27 08:21:51,902][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051208] [Batch 01928/03080] [00:24:34/00:14:41, 0.765s/it]: train_loss_raw=0.5563, running_loss=0.5742, LR=0.000100
[2025-08-27 08:21:58,001][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051216] [Batch 01936/03080] [00:24:41/00:14:35, 0.765s/it]: train_loss_raw=0.4780, running_loss=0.5731, LR=0.000100
[2025-08-27 08:22:03,902][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051224] [Batch 01944/03080] [00:24:46/00:14:28, 0.765s/it]: train_loss_raw=0.6028, running_loss=0.5744, LR=0.000100
[2025-08-27 08:22:09,736][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051232] [Batch 01952/03080] [00:24:52/00:14:22, 0.765s/it]: train_loss_raw=0.5048, running_loss=0.5747, LR=0.000100
[2025-08-27 08:22:15,561][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051240] [Batch 01960/03080] [00:24:58/00:14:16, 0.765s/it]: train_loss_raw=0.4850, running_loss=0.5755, LR=0.000100
[2025-08-27 08:22:21,384][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051248] [Batch 01968/03080] [00:25:04/00:14:10, 0.764s/it]: train_loss_raw=0.6495, running_loss=0.5759, LR=0.000100
[2025-08-27 08:22:27,295][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051256] [Batch 01976/03080] [00:25:10/00:14:03, 0.764s/it]: train_loss_raw=0.6383, running_loss=0.5775, LR=0.000100
[2025-08-27 08:22:33,299][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051264] [Batch 01984/03080] [00:25:16/00:13:57, 0.764s/it]: train_loss_raw=0.4978, running_loss=0.5803, LR=0.000100
[2025-08-27 08:22:39,355][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051272] [Batch 01992/03080] [00:25:22/00:13:51, 0.764s/it]: train_loss_raw=0.4888, running_loss=0.5790, LR=0.000100
[2025-08-27 08:22:45,539][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051280] [Batch 02000/03080] [00:25:28/00:13:45, 0.764s/it]: train_loss_raw=0.5975, running_loss=0.5779, LR=0.000100
[2025-08-27 08:22:51,413][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051288] [Batch 02008/03080] [00:25:34/00:13:39, 0.764s/it]: train_loss_raw=0.5177, running_loss=0.5755, LR=0.000100
[2025-08-27 08:22:57,512][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051296] [Batch 02016/03080] [00:25:40/00:13:33, 0.764s/it]: train_loss_raw=0.6096, running_loss=0.5778, LR=0.000100
[2025-08-27 08:23:03,329][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051304] [Batch 02024/03080] [00:25:46/00:13:26, 0.764s/it]: train_loss_raw=0.6093, running_loss=0.5755, LR=0.000100
[2025-08-27 08:23:09,185][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051312] [Batch 02032/03080] [00:25:52/00:13:20, 0.764s/it]: train_loss_raw=0.5192, running_loss=0.5758, LR=0.000100
[2025-08-27 08:23:15,070][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051320] [Batch 02040/03080] [00:25:58/00:13:14, 0.764s/it]: train_loss_raw=0.5887, running_loss=0.5770, LR=0.000100
[2025-08-27 08:23:20,914][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051328] [Batch 02048/03080] [00:26:03/00:13:08, 0.764s/it]: train_loss_raw=0.5651, running_loss=0.5755, LR=0.000100
[2025-08-27 08:23:26,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051336] [Batch 02056/03080] [00:26:09/00:13:01, 0.764s/it]: train_loss_raw=0.4972, running_loss=0.5744, LR=0.000100
[2025-08-27 08:23:32,891][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051344] [Batch 02064/03080] [00:26:15/00:12:55, 0.764s/it]: train_loss_raw=0.5475, running_loss=0.5752, LR=0.000100
[2025-08-27 08:23:39,022][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051352] [Batch 02072/03080] [00:26:22/00:12:49, 0.764s/it]: train_loss_raw=0.6051, running_loss=0.5745, LR=0.000100
[2025-08-27 08:23:45,194][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051360] [Batch 02080/03080] [00:26:28/00:12:43, 0.764s/it]: train_loss_raw=0.6079, running_loss=0.5759, LR=0.000100
[2025-08-27 08:23:51,288][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051368] [Batch 02088/03080] [00:26:34/00:12:37, 0.764s/it]: train_loss_raw=0.5626, running_loss=0.5782, LR=0.000100
[2025-08-27 08:23:57,421][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051376] [Batch 02096/03080] [00:26:40/00:12:31, 0.764s/it]: train_loss_raw=0.5895, running_loss=0.5779, LR=0.000100
[2025-08-27 08:24:03,540][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051384] [Batch 02104/03080] [00:26:46/00:12:25, 0.764s/it]: train_loss_raw=0.5383, running_loss=0.5769, LR=0.000100
[2025-08-27 08:24:09,684][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051392] [Batch 02112/03080] [00:26:52/00:12:19, 0.764s/it]: train_loss_raw=0.6448, running_loss=0.5771, LR=0.000100
[2025-08-27 08:24:15,888][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051400] [Batch 02120/03080] [00:26:58/00:12:13, 0.764s/it]: train_loss_raw=0.5854, running_loss=0.5771, LR=0.000100
[2025-08-27 08:24:21,992][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051408] [Batch 02128/03080] [00:27:05/00:12:06, 0.764s/it]: train_loss_raw=0.5043, running_loss=0.5770, LR=0.000100
[2025-08-27 08:24:28,128][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051416] [Batch 02136/03080] [00:27:11/00:12:00, 0.764s/it]: train_loss_raw=0.5344, running_loss=0.5778, LR=0.000100
[2025-08-27 08:24:34,249][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051424] [Batch 02144/03080] [00:27:17/00:11:54, 0.764s/it]: train_loss_raw=0.5235, running_loss=0.5767, LR=0.000100
[2025-08-27 08:24:40,416][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051432] [Batch 02152/03080] [00:27:23/00:11:48, 0.764s/it]: train_loss_raw=0.5127, running_loss=0.5752, LR=0.000100
[2025-08-27 08:24:46,611][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051440] [Batch 02160/03080] [00:27:29/00:11:42, 0.764s/it]: train_loss_raw=0.5389, running_loss=0.5750, LR=0.000100
[2025-08-27 08:24:52,752][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051448] [Batch 02168/03080] [00:27:35/00:11:36, 0.764s/it]: train_loss_raw=0.6571, running_loss=0.5768, LR=0.000100
[2025-08-27 08:24:58,905][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051456] [Batch 02176/03080] [00:27:41/00:11:30, 0.764s/it]: train_loss_raw=0.5895, running_loss=0.5753, LR=0.000100
[2025-08-27 08:25:05,021][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051464] [Batch 02184/03080] [00:27:48/00:11:24, 0.764s/it]: train_loss_raw=0.5516, running_loss=0.5737, LR=0.000100
[2025-08-27 08:25:11,056][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051472] [Batch 02192/03080] [00:27:54/00:11:18, 0.764s/it]: train_loss_raw=0.5519, running_loss=0.5721, LR=0.000100
[2025-08-27 08:25:17,216][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051480] [Batch 02200/03080] [00:28:00/00:11:12, 0.764s/it]: train_loss_raw=0.4576, running_loss=0.5723, LR=0.000100
[2025-08-27 08:25:23,389][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051488] [Batch 02208/03080] [00:28:06/00:11:06, 0.764s/it]: train_loss_raw=0.5536, running_loss=0.5736, LR=0.000100
[2025-08-27 08:25:29,479][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051496] [Batch 02216/03080] [00:28:12/00:10:59, 0.764s/it]: train_loss_raw=0.7108, running_loss=0.5727, LR=0.000100
[2025-08-27 08:25:35,643][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051504] [Batch 02224/03080] [00:28:18/00:10:53, 0.764s/it]: train_loss_raw=0.5198, running_loss=0.5685, LR=0.000100
[2025-08-27 08:25:41,792][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051512] [Batch 02232/03080] [00:28:24/00:10:47, 0.764s/it]: train_loss_raw=0.5933, running_loss=0.5686, LR=0.000100
[2025-08-27 08:25:47,844][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051520] [Batch 02240/03080] [00:28:30/00:10:41, 0.764s/it]: train_loss_raw=0.5272, running_loss=0.5694, LR=0.000100
[2025-08-27 08:25:53,935][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051528] [Batch 02248/03080] [00:28:36/00:10:35, 0.764s/it]: train_loss_raw=0.5338, running_loss=0.5693, LR=0.000100
[2025-08-27 08:26:00,040][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051536] [Batch 02256/03080] [00:28:43/00:10:29, 0.764s/it]: train_loss_raw=0.6007, running_loss=0.5674, LR=0.000100
[2025-08-27 08:26:06,151][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051544] [Batch 02264/03080] [00:28:49/00:10:23, 0.764s/it]: train_loss_raw=0.5673, running_loss=0.5674, LR=0.000100
[2025-08-27 08:26:12,333][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051552] [Batch 02272/03080] [00:28:55/00:10:17, 0.764s/it]: train_loss_raw=0.5461, running_loss=0.5664, LR=0.000100
[2025-08-27 08:26:18,490][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051560] [Batch 02280/03080] [00:29:01/00:10:11, 0.764s/it]: train_loss_raw=0.5274, running_loss=0.5699, LR=0.000100
[2025-08-27 08:26:24,568][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051568] [Batch 02288/03080] [00:29:07/00:10:04, 0.764s/it]: train_loss_raw=0.5501, running_loss=0.5700, LR=0.000100
[2025-08-27 08:26:30,673][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051576] [Batch 02296/03080] [00:29:13/00:09:58, 0.764s/it]: train_loss_raw=0.5836, running_loss=0.5724, LR=0.000100
[2025-08-27 08:26:36,567][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051584] [Batch 02304/03080] [00:29:19/00:09:52, 0.764s/it]: train_loss_raw=0.6679, running_loss=0.5746, LR=0.000100
[2025-08-27 08:26:42,630][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051592] [Batch 02312/03080] [00:29:25/00:09:46, 0.764s/it]: train_loss_raw=0.6556, running_loss=0.5763, LR=0.000100
[2025-08-27 08:26:48,719][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051600] [Batch 02320/03080] [00:29:31/00:09:40, 0.764s/it]: train_loss_raw=0.5694, running_loss=0.5781, LR=0.000100
[2025-08-27 08:26:54,834][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051608] [Batch 02328/03080] [00:29:37/00:09:34, 0.764s/it]: train_loss_raw=0.5847, running_loss=0.5789, LR=0.000100
[2025-08-27 08:27:00,943][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051616] [Batch 02336/03080] [00:29:44/00:09:28, 0.764s/it]: train_loss_raw=0.5696, running_loss=0.5774, LR=0.000100
[2025-08-27 08:27:07,162][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051624] [Batch 02344/03080] [00:29:50/00:09:22, 0.764s/it]: train_loss_raw=0.5656, running_loss=0.5773, LR=0.000100
[2025-08-27 08:27:13,252][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051632] [Batch 02352/03080] [00:29:56/00:09:16, 0.764s/it]: train_loss_raw=0.6689, running_loss=0.5800, LR=0.000100
[2025-08-27 08:27:19,494][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051640] [Batch 02360/03080] [00:30:02/00:09:09, 0.764s/it]: train_loss_raw=0.6058, running_loss=0.5806, LR=0.000100
[2025-08-27 08:27:25,727][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051648] [Batch 02368/03080] [00:30:08/00:09:03, 0.764s/it]: train_loss_raw=0.4985, running_loss=0.5796, LR=0.000100
[2025-08-27 08:27:31,826][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051656] [Batch 02376/03080] [00:30:14/00:08:57, 0.764s/it]: train_loss_raw=0.5319, running_loss=0.5777, LR=0.000100
[2025-08-27 08:27:37,942][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051664] [Batch 02384/03080] [00:30:21/00:08:51, 0.764s/it]: train_loss_raw=0.5546, running_loss=0.5785, LR=0.000100
[2025-08-27 08:27:44,084][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051672] [Batch 02392/03080] [00:30:27/00:08:45, 0.764s/it]: train_loss_raw=0.5707, running_loss=0.5827, LR=0.000100
[2025-08-27 08:27:50,125][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051680] [Batch 02400/03080] [00:30:33/00:08:39, 0.764s/it]: train_loss_raw=0.6217, running_loss=0.5796, LR=0.000100
[2025-08-27 08:27:56,242][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051688] [Batch 02408/03080] [00:30:39/00:08:33, 0.764s/it]: train_loss_raw=0.5147, running_loss=0.5778, LR=0.000100
[2025-08-27 08:28:02,368][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051696] [Batch 02416/03080] [00:30:45/00:08:27, 0.764s/it]: train_loss_raw=0.5207, running_loss=0.5773, LR=0.000100
[2025-08-27 08:28:08,438][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051704] [Batch 02424/03080] [00:30:51/00:08:21, 0.764s/it]: train_loss_raw=0.6052, running_loss=0.5786, LR=0.000100
[2025-08-27 08:28:13,946][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051712] [Batch 02432/03080] [00:30:57/00:08:14, 0.764s/it]: train_loss_raw=0.4705, running_loss=0.5762, LR=0.000100
[2025-08-27 08:28:19,930][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051720] [Batch 02440/03080] [00:31:02/00:08:08, 0.764s/it]: train_loss_raw=0.6497, running_loss=0.5765, LR=0.000100
[2025-08-27 08:28:26,127][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051728] [Batch 02448/03080] [00:31:09/00:08:02, 0.764s/it]: train_loss_raw=0.5567, running_loss=0.5758, LR=0.000100
[2025-08-27 08:28:32,347][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051736] [Batch 02456/03080] [00:31:15/00:07:56, 0.764s/it]: train_loss_raw=0.6210, running_loss=0.5746, LR=0.000100
[2025-08-27 08:28:38,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051744] [Batch 02464/03080] [00:31:21/00:07:50, 0.764s/it]: train_loss_raw=0.5842, running_loss=0.5745, LR=0.000100
[2025-08-27 08:28:44,904][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051752] [Batch 02472/03080] [00:31:27/00:07:44, 0.764s/it]: train_loss_raw=0.5301, running_loss=0.5737, LR=0.000100
[2025-08-27 08:28:51,034][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051760] [Batch 02480/03080] [00:31:34/00:07:38, 0.764s/it]: train_loss_raw=0.5873, running_loss=0.5752, LR=0.000100
[2025-08-27 08:28:57,102][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051768] [Batch 02488/03080] [00:31:40/00:07:32, 0.764s/it]: train_loss_raw=0.6828, running_loss=0.5734, LR=0.000100
[2025-08-27 08:29:03,151][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051776] [Batch 02496/03080] [00:31:46/00:07:26, 0.764s/it]: train_loss_raw=0.5560, running_loss=0.5729, LR=0.000100
[2025-08-27 08:29:09,207][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051784] [Batch 02504/03080] [00:31:52/00:07:19, 0.764s/it]: train_loss_raw=0.6294, running_loss=0.5727, LR=0.000100
[2025-08-27 08:29:15,301][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051792] [Batch 02512/03080] [00:31:58/00:07:13, 0.764s/it]: train_loss_raw=0.5507, running_loss=0.5736, LR=0.000100
[2025-08-27 08:29:21,408][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051800] [Batch 02520/03080] [00:32:04/00:07:07, 0.764s/it]: train_loss_raw=0.6763, running_loss=0.5755, LR=0.000100
[2025-08-27 08:29:27,537][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051808] [Batch 02528/03080] [00:32:10/00:07:01, 0.764s/it]: train_loss_raw=0.5013, running_loss=0.5740, LR=0.000100
[2025-08-27 08:29:33,593][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051816] [Batch 02536/03080] [00:32:16/00:06:55, 0.764s/it]: train_loss_raw=0.6245, running_loss=0.5723, LR=0.000100
[2025-08-27 08:29:39,667][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051824] [Batch 02544/03080] [00:32:22/00:06:49, 0.764s/it]: train_loss_raw=0.6056, running_loss=0.5717, LR=0.000100
[2025-08-27 08:29:45,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051832] [Batch 02552/03080] [00:32:28/00:06:43, 0.764s/it]: train_loss_raw=0.5259, running_loss=0.5698, LR=0.000100
[2025-08-27 08:29:51,603][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051840] [Batch 02560/03080] [00:32:34/00:06:37, 0.764s/it]: train_loss_raw=0.5528, running_loss=0.5704, LR=0.000100
[2025-08-27 08:29:57,448][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051848] [Batch 02568/03080] [00:32:40/00:06:30, 0.763s/it]: train_loss_raw=0.5828, running_loss=0.5727, LR=0.000100
[2025-08-27 08:30:03,510][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051856] [Batch 02576/03080] [00:32:46/00:06:24, 0.763s/it]: train_loss_raw=0.6007, running_loss=0.5742, LR=0.000100
[2025-08-27 08:30:09,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051864] [Batch 02584/03080] [00:32:52/00:06:18, 0.763s/it]: train_loss_raw=0.6037, running_loss=0.5737, LR=0.000100
[2025-08-27 08:30:15,247][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051872] [Batch 02592/03080] [00:32:58/00:06:12, 0.763s/it]: train_loss_raw=0.5837, running_loss=0.5727, LR=0.000100
[2025-08-27 08:30:21,235][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051880] [Batch 02600/03080] [00:33:04/00:06:06, 0.763s/it]: train_loss_raw=0.5499, running_loss=0.5743, LR=0.000100
[2025-08-27 08:30:27,349][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051888] [Batch 02608/03080] [00:33:10/00:06:00, 0.763s/it]: train_loss_raw=0.5522, running_loss=0.5703, LR=0.000100
[2025-08-27 08:30:33,464][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051896] [Batch 02616/03080] [00:33:16/00:05:54, 0.763s/it]: train_loss_raw=0.5831, running_loss=0.5703, LR=0.000100
[2025-08-27 08:30:39,486][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051904] [Batch 02624/03080] [00:33:22/00:05:48, 0.763s/it]: train_loss_raw=0.6273, running_loss=0.5692, LR=0.000100
[2025-08-27 08:30:45,641][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051912] [Batch 02632/03080] [00:33:28/00:05:41, 0.763s/it]: train_loss_raw=0.5871, running_loss=0.5685, LR=0.000100
[2025-08-27 08:30:51,827][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051920] [Batch 02640/03080] [00:33:34/00:05:35, 0.763s/it]: train_loss_raw=0.5359, running_loss=0.5689, LR=0.000100
[2025-08-27 08:30:58,037][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051928] [Batch 02648/03080] [00:33:41/00:05:29, 0.763s/it]: train_loss_raw=0.5858, running_loss=0.5693, LR=0.000100
[2025-08-27 08:31:04,167][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051936] [Batch 02656/03080] [00:33:47/00:05:23, 0.763s/it]: train_loss_raw=0.5399, running_loss=0.5684, LR=0.000100
[2025-08-27 08:31:10,295][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051944] [Batch 02664/03080] [00:33:53/00:05:17, 0.763s/it]: train_loss_raw=0.5889, running_loss=0.5688, LR=0.000100
[2025-08-27 08:31:16,476][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051952] [Batch 02672/03080] [00:33:59/00:05:11, 0.763s/it]: train_loss_raw=0.5301, running_loss=0.5678, LR=0.000100
[2025-08-27 08:31:22,711][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051960] [Batch 02680/03080] [00:34:05/00:05:05, 0.763s/it]: train_loss_raw=0.5236, running_loss=0.5659, LR=0.000100
[2025-08-27 08:31:28,757][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051968] [Batch 02688/03080] [00:34:11/00:04:59, 0.763s/it]: train_loss_raw=0.5319, running_loss=0.5658, LR=0.000100
[2025-08-27 08:31:34,480][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051976] [Batch 02696/03080] [00:34:17/00:04:53, 0.763s/it]: train_loss_raw=0.5378, running_loss=0.5645, LR=0.000100
[2025-08-27 08:31:40,009][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051984] [Batch 02704/03080] [00:34:23/00:04:46, 0.763s/it]: train_loss_raw=0.6308, running_loss=0.5650, LR=0.000100
[2025-08-27 08:31:45,654][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 051992] [Batch 02712/03080] [00:34:28/00:04:40, 0.763s/it]: train_loss_raw=0.5613, running_loss=0.5657, LR=0.000100
[2025-08-27 08:31:51,712][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052000] [Batch 02720/03080] [00:34:34/00:04:34, 0.763s/it]: train_loss_raw=0.5800, running_loss=0.5643, LR=0.000100
[2025-08-27 08:32:01,866][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052008] [Batch 02728/03080] [00:34:44/00:04:29, 0.764s/it]: train_loss_raw=0.5483, running_loss=0.5636, LR=0.000100
[2025-08-27 08:32:08,036][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052016] [Batch 02736/03080] [00:34:51/00:04:22, 0.764s/it]: train_loss_raw=0.5911, running_loss=0.5671, LR=0.000100
[2025-08-27 08:32:14,148][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052024] [Batch 02744/03080] [00:34:57/00:04:16, 0.764s/it]: train_loss_raw=0.4650, running_loss=0.5655, LR=0.000100
[2025-08-27 08:32:20,202][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052032] [Batch 02752/03080] [00:35:03/00:04:10, 0.764s/it]: train_loss_raw=0.5396, running_loss=0.5656, LR=0.000100
[2025-08-27 08:32:26,240][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052040] [Batch 02760/03080] [00:35:09/00:04:04, 0.764s/it]: train_loss_raw=0.6011, running_loss=0.5633, LR=0.000100
[2025-08-27 08:32:32,378][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052048] [Batch 02768/03080] [00:35:15/00:03:58, 0.764s/it]: train_loss_raw=0.5844, running_loss=0.5645, LR=0.000100
[2025-08-27 08:32:38,483][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052056] [Batch 02776/03080] [00:35:21/00:03:52, 0.764s/it]: train_loss_raw=0.4977, running_loss=0.5637, LR=0.000100
[2025-08-27 08:32:44,697][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052064] [Batch 02784/03080] [00:35:27/00:03:46, 0.764s/it]: train_loss_raw=0.5580, running_loss=0.5638, LR=0.000100
[2025-08-27 08:32:50,622][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052072] [Batch 02792/03080] [00:35:33/00:03:40, 0.764s/it]: train_loss_raw=0.5266, running_loss=0.5616, LR=0.000100
[2025-08-27 08:32:56,714][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052080] [Batch 02800/03080] [00:35:39/00:03:33, 0.764s/it]: train_loss_raw=0.4712, running_loss=0.5597, LR=0.000100
[2025-08-27 08:33:02,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052088] [Batch 02808/03080] [00:35:45/00:03:27, 0.764s/it]: train_loss_raw=0.5772, running_loss=0.5617, LR=0.000100
[2025-08-27 08:33:08,765][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052096] [Batch 02816/03080] [00:35:51/00:03:21, 0.764s/it]: train_loss_raw=0.5398, running_loss=0.5622, LR=0.000100
[2025-08-27 08:33:15,012][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052104] [Batch 02824/03080] [00:35:58/00:03:15, 0.764s/it]: train_loss_raw=0.5324, running_loss=0.5592, LR=0.000100
[2025-08-27 08:33:20,892][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052112] [Batch 02832/03080] [00:36:03/00:03:09, 0.764s/it]: train_loss_raw=0.6052, running_loss=0.5601, LR=0.000100
[2025-08-27 08:33:27,246][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052120] [Batch 02840/03080] [00:36:10/00:03:03, 0.764s/it]: train_loss_raw=0.6126, running_loss=0.5606, LR=0.000100
[2025-08-27 08:33:33,347][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052128] [Batch 02848/03080] [00:36:16/00:02:57, 0.764s/it]: train_loss_raw=0.5931, running_loss=0.5610, LR=0.000100
[2025-08-27 08:33:39,435][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052136] [Batch 02856/03080] [00:36:22/00:02:51, 0.764s/it]: train_loss_raw=0.5922, running_loss=0.5639, LR=0.000100
[2025-08-27 08:33:45,639][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052144] [Batch 02864/03080] [00:36:28/00:02:45, 0.764s/it]: train_loss_raw=0.5342, running_loss=0.5641, LR=0.000100
[2025-08-27 08:33:51,949][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052152] [Batch 02872/03080] [00:36:35/00:02:38, 0.764s/it]: train_loss_raw=0.6024, running_loss=0.5655, LR=0.000100
[2025-08-27 08:33:58,135][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052160] [Batch 02880/03080] [00:36:41/00:02:32, 0.764s/it]: train_loss_raw=0.4458, running_loss=0.5661, LR=0.000100
[2025-08-27 08:34:04,152][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052168] [Batch 02888/03080] [00:36:47/00:02:26, 0.764s/it]: train_loss_raw=0.4701, running_loss=0.5631, LR=0.000100
[2025-08-27 08:34:10,295][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052176] [Batch 02896/03080] [00:36:53/00:02:20, 0.764s/it]: train_loss_raw=0.6295, running_loss=0.5646, LR=0.000100
[2025-08-27 08:34:16,109][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052184] [Batch 02904/03080] [00:36:59/00:02:14, 0.764s/it]: train_loss_raw=0.5409, running_loss=0.5659, LR=0.000100
[2025-08-27 08:34:21,974][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052192] [Batch 02912/03080] [00:37:05/00:02:08, 0.764s/it]: train_loss_raw=0.6143, running_loss=0.5662, LR=0.000100
[2025-08-27 08:34:27,731][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052200] [Batch 02920/03080] [00:37:10/00:02:02, 0.764s/it]: train_loss_raw=0.5660, running_loss=0.5658, LR=0.000100
[2025-08-27 08:34:33,559][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052208] [Batch 02928/03080] [00:37:16/00:01:56, 0.764s/it]: train_loss_raw=0.5768, running_loss=0.5664, LR=0.000100
[2025-08-27 08:34:39,392][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052216] [Batch 02936/03080] [00:37:22/00:01:49, 0.764s/it]: train_loss_raw=0.6316, running_loss=0.5652, LR=0.000100
[2025-08-27 08:34:45,460][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052224] [Batch 02944/03080] [00:37:28/00:01:43, 0.764s/it]: train_loss_raw=0.6686, running_loss=0.5652, LR=0.000100
[2025-08-27 08:34:51,591][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052232] [Batch 02952/03080] [00:37:34/00:01:37, 0.764s/it]: train_loss_raw=0.6160, running_loss=0.5665, LR=0.000100
[2025-08-27 08:34:57,715][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052240] [Batch 02960/03080] [00:37:40/00:01:31, 0.764s/it]: train_loss_raw=0.6223, running_loss=0.5673, LR=0.000100
[2025-08-27 08:35:03,693][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052248] [Batch 02968/03080] [00:37:46/00:01:25, 0.764s/it]: train_loss_raw=0.5615, running_loss=0.5672, LR=0.000100
[2025-08-27 08:35:09,823][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052256] [Batch 02976/03080] [00:37:52/00:01:19, 0.764s/it]: train_loss_raw=0.6031, running_loss=0.5675, LR=0.000100
[2025-08-27 08:35:15,652][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052264] [Batch 02984/03080] [00:37:58/00:01:13, 0.764s/it]: train_loss_raw=0.4584, running_loss=0.5665, LR=0.000100
[2025-08-27 08:35:21,757][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052272] [Batch 02992/03080] [00:38:04/00:01:07, 0.764s/it]: train_loss_raw=0.6182, running_loss=0.5697, LR=0.000100
[2025-08-27 08:35:27,841][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052280] [Batch 03000/03080] [00:38:10/00:01:01, 0.764s/it]: train_loss_raw=0.5485, running_loss=0.5661, LR=0.000100
[2025-08-27 08:35:33,985][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052288] [Batch 03008/03080] [00:38:17/00:00:54, 0.764s/it]: train_loss_raw=0.5744, running_loss=0.5674, LR=0.000100
[2025-08-27 08:35:39,885][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052296] [Batch 03016/03080] [00:38:22/00:00:48, 0.764s/it]: train_loss_raw=0.5388, running_loss=0.5674, LR=0.000100
[2025-08-27 08:35:45,846][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052304] [Batch 03024/03080] [00:38:28/00:00:42, 0.764s/it]: train_loss_raw=0.5540, running_loss=0.5659, LR=0.000100
[2025-08-27 08:35:51,878][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052312] [Batch 03032/03080] [00:38:34/00:00:36, 0.764s/it]: train_loss_raw=0.6428, running_loss=0.5687, LR=0.000100
[2025-08-27 08:35:57,949][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052320] [Batch 03040/03080] [00:38:41/00:00:30, 0.763s/it]: train_loss_raw=0.5423, running_loss=0.5657, LR=0.000100
[2025-08-27 08:36:03,836][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052328] [Batch 03048/03080] [00:38:46/00:00:24, 0.763s/it]: train_loss_raw=0.5210, running_loss=0.5672, LR=0.000100
[2025-08-27 08:36:09,925][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052336] [Batch 03056/03080] [00:38:52/00:00:18, 0.763s/it]: train_loss_raw=0.5387, running_loss=0.5667, LR=0.000100
[2025-08-27 08:36:15,900][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052344] [Batch 03064/03080] [00:38:58/00:00:12, 0.763s/it]: train_loss_raw=0.5693, running_loss=0.5657, LR=0.000100
[2025-08-27 08:36:21,669][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052352] [Batch 03072/03080] [00:39:04/00:00:06, 0.763s/it]: train_loss_raw=0.4663, running_loss=0.5645, LR=0.000100
[2025-08-27 08:36:27,715][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 052360] [Batch 03080/03080] [00:39:10/00:00:00, 0.763s/it]: train_loss_raw=0.5469, running_loss=0.5647, LR=0.000100
[2025-08-27 08:36:28,241][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-27 08:36:39,897][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00007/00310] [00:00:11/00:07:19, 1.457s/it]
[2025-08-27 08:36:51,554][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00015/00310] [00:00:23/00:07:08, 1.457s/it]
[2025-08-27 08:37:03,737][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00023/00310] [00:00:35/00:07:02, 1.479s/it]
[2025-08-27 08:37:15,930][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00031/00310] [00:00:47/00:06:54, 1.490s/it]
[2025-08-27 08:37:27,924][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00039/00310] [00:00:59/00:06:42, 1.492s/it]
[2025-08-27 08:37:39,496][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00047/00310] [00:01:11/00:06:28, 1.484s/it]
[2025-08-27 08:37:51,903][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00055/00310] [00:01:23/00:06:19, 1.494s/it]
[2025-08-27 08:38:03,690][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00063/00310] [00:01:35/00:06:06, 1.491s/it]
[2025-08-27 08:38:15,472][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00071/00310] [00:01:47/00:05:54, 1.489s/it]
[2025-08-27 08:38:27,857][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00079/00310] [00:01:59/00:05:43, 1.495s/it]
[2025-08-27 08:38:40,424][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00087/00310] [00:02:12/00:05:33, 1.502s/it]
[2025-08-27 08:38:51,976][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00095/00310] [00:02:23/00:05:20, 1.497s/it]
[2025-08-27 08:39:04,641][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00103/00310] [00:02:36/00:05:09, 1.504s/it]
[2025-08-27 08:39:17,469][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00111/00310] [00:02:49/00:04:59, 1.511s/it]
[2025-08-27 08:39:29,799][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00119/00310] [00:03:01/00:04:47, 1.513s/it]
[2025-08-27 08:39:40,954][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00127/00310] [00:03:12/00:04:34, 1.506s/it]
[2025-08-27 08:39:51,978][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00135/00310] [00:03:23/00:04:20, 1.498s/it]
[2025-08-27 08:40:03,004][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00143/00310] [00:03:34/00:04:07, 1.491s/it]
[2025-08-27 08:40:13,383][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00151/00310] [00:03:45/00:03:54, 1.481s/it]
[2025-08-27 08:40:23,441][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00159/00310] [00:03:55/00:03:40, 1.470s/it]
[2025-08-27 08:40:35,706][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00167/00310] [00:04:07/00:03:29, 1.473s/it]
[2025-08-27 08:40:46,466][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00175/00310] [00:04:18/00:03:16, 1.467s/it]
[2025-08-27 08:40:57,731][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00183/00310] [00:04:29/00:03:04, 1.465s/it]
[2025-08-27 08:41:09,433][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00191/00310] [00:04:41/00:02:52, 1.465s/it]
[2025-08-27 08:41:21,298][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00199/00310] [00:04:53/00:02:41, 1.465s/it]
[2025-08-27 08:41:32,290][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00207/00310] [00:05:04/00:02:29, 1.462s/it]
[2025-08-27 08:41:43,731][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00215/00310] [00:05:15/00:02:17, 1.461s/it]
[2025-08-27 08:41:56,668][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00223/00310] [00:05:28/00:02:06, 1.466s/it]
[2025-08-27 08:42:08,893][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00231/00310] [00:05:40/00:01:54, 1.468s/it]
[2025-08-27 08:42:20,530][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00239/00310] [00:05:52/00:01:42, 1.468s/it]
[2025-08-27 08:42:31,603][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00247/00310] [00:06:03/00:01:30, 1.465s/it]
[2025-08-27 08:42:44,046][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00255/00310] [00:06:15/00:01:19, 1.468s/it]
[2025-08-27 08:42:56,244][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00263/00310] [00:06:28/00:01:07, 1.470s/it]
[2025-08-27 08:43:08,318][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00271/00310] [00:06:40/00:00:55, 1.471s/it]
[2025-08-27 08:43:20,520][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00279/00310] [00:06:52/00:00:44, 1.472s/it]
[2025-08-27 08:43:32,589][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00287/00310] [00:07:04/00:00:32, 1.473s/it]
[2025-08-27 08:43:43,692][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00295/00310] [00:07:15/00:00:20, 1.471s/it]
[2025-08-27 08:43:55,434][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 052361] [Batch 00303/00310] [00:07:27/00:00:08, 1.471s/it]
[2025-08-27 08:44:04,500][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=0.56472, valid_loss=1.54151
[2025-08-27 08:44:04,501][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-27 08:44:04,501][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.557
[2025-08-27 08:44:04,501][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.098
[2025-08-27 08:44:04,501][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.100
[2025-08-27 08:44:04,501][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.047
[2025-08-27 08:44:04,519][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 13:17:18, remaining time 10:09:42, 00:46:54 per epoch
[2025-08-27 08:44:13,076][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052368] [Batch 00008/03080] [00:00:05/00:34:45, 0.679s/it]: train_loss_raw=0.5808, running_loss=0.5403, LR=0.000100
[2025-08-27 08:44:19,413][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052376] [Batch 00016/03080] [00:00:11/00:37:33, 0.736s/it]: train_loss_raw=0.5288, running_loss=0.5392, LR=0.000100
[2025-08-27 08:44:25,409][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052384] [Batch 00024/03080] [00:00:17/00:37:42, 0.740s/it]: train_loss_raw=0.6185, running_loss=0.5421, LR=0.000100
[2025-08-27 08:44:31,386][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052392] [Batch 00032/03080] [00:00:23/00:37:41, 0.742s/it]: train_loss_raw=0.5677, running_loss=0.5463, LR=0.000100
[2025-08-27 08:44:37,491][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052400] [Batch 00040/03080] [00:00:29/00:37:48, 0.746s/it]: train_loss_raw=0.5523, running_loss=0.5482, LR=0.000100
[2025-08-27 08:44:43,494][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052408] [Batch 00048/03080] [00:00:35/00:37:44, 0.747s/it]: train_loss_raw=0.5755, running_loss=0.5488, LR=0.000100
[2025-08-27 08:44:49,513][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052416] [Batch 00056/03080] [00:00:41/00:37:40, 0.748s/it]: train_loss_raw=0.5425, running_loss=0.5505, LR=0.000100
[2025-08-27 08:44:55,530][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052424] [Batch 00064/03080] [00:00:47/00:37:36, 0.748s/it]: train_loss_raw=0.5733, running_loss=0.5532, LR=0.000100
[2025-08-27 08:45:01,533][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052432] [Batch 00072/03080] [00:00:53/00:37:31, 0.748s/it]: train_loss_raw=0.5552, running_loss=0.5555, LR=0.000100
[2025-08-27 08:45:07,499][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052440] [Batch 00080/03080] [00:00:59/00:37:24, 0.748s/it]: train_loss_raw=0.5513, running_loss=0.5545, LR=0.000100
[2025-08-27 08:45:13,281][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052448] [Batch 00088/03080] [00:01:05/00:37:11, 0.746s/it]: train_loss_raw=0.6960, running_loss=0.5582, LR=0.000100
[2025-08-27 08:45:19,439][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052456] [Batch 00096/03080] [00:01:11/00:37:11, 0.748s/it]: train_loss_raw=0.6621, running_loss=0.5605, LR=0.000100
[2025-08-27 08:45:25,630][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052464] [Batch 00104/03080] [00:01:17/00:37:11, 0.750s/it]: train_loss_raw=0.5702, running_loss=0.5587, LR=0.000100
[2025-08-27 08:45:31,754][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052472] [Batch 00112/03080] [00:01:24/00:37:08, 0.751s/it]: train_loss_raw=0.5950, running_loss=0.5604, LR=0.000100
[2025-08-27 08:45:37,739][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052480] [Batch 00120/03080] [00:01:30/00:37:02, 0.751s/it]: train_loss_raw=0.4992, running_loss=0.5576, LR=0.000100
[2025-08-27 08:45:43,650][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052488] [Batch 00128/03080] [00:01:36/00:36:54, 0.750s/it]: train_loss_raw=0.5685, running_loss=0.5569, LR=0.000100
[2025-08-27 08:45:49,689][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052496] [Batch 00136/03080] [00:01:42/00:36:48, 0.750s/it]: train_loss_raw=0.5644, running_loss=0.5571, LR=0.000100
[2025-08-27 08:45:55,792][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052504] [Batch 00144/03080] [00:01:48/00:36:45, 0.751s/it]: train_loss_raw=0.4851, running_loss=0.5553, LR=0.000100
[2025-08-27 08:46:01,962][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052512] [Batch 00152/03080] [00:01:54/00:36:42, 0.752s/it]: train_loss_raw=0.5664, running_loss=0.5554, LR=0.000100
[2025-08-27 08:46:07,988][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052520] [Batch 00160/03080] [00:02:00/00:36:36, 0.752s/it]: train_loss_raw=0.5441, running_loss=0.5550, LR=0.000100
[2025-08-27 08:46:13,903][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052528] [Batch 00168/03080] [00:02:06/00:36:28, 0.752s/it]: train_loss_raw=0.5260, running_loss=0.5537, LR=0.000100
[2025-08-27 08:46:19,850][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052536] [Batch 00176/03080] [00:02:12/00:36:21, 0.751s/it]: train_loss_raw=0.5345, running_loss=0.5538, LR=0.000100
[2025-08-27 08:46:25,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052544] [Batch 00184/03080] [00:02:18/00:36:16, 0.751s/it]: train_loss_raw=0.4645, running_loss=0.5524, LR=0.000100
[2025-08-27 08:46:31,673][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052552] [Batch 00192/03080] [00:02:24/00:36:06, 0.750s/it]: train_loss_raw=0.5965, running_loss=0.5549, LR=0.000100
[2025-08-27 08:46:37,377][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052560] [Batch 00200/03080] [00:02:29/00:35:56, 0.749s/it]: train_loss_raw=0.6345, running_loss=0.5563, LR=0.000100
[2025-08-27 08:46:43,252][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052568] [Batch 00208/03080] [00:02:35/00:35:48, 0.748s/it]: train_loss_raw=0.5119, running_loss=0.5576, LR=0.000100
[2025-08-27 08:46:49,181][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052576] [Batch 00216/03080] [00:02:41/00:35:41, 0.748s/it]: train_loss_raw=0.5154, running_loss=0.5571, LR=0.000100
[2025-08-27 08:46:55,265][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052584] [Batch 00224/03080] [00:02:47/00:35:37, 0.748s/it]: train_loss_raw=0.5562, running_loss=0.5578, LR=0.000100
[2025-08-27 08:47:01,459][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052592] [Batch 00232/03080] [00:02:53/00:35:33, 0.749s/it]: train_loss_raw=0.5272, running_loss=0.5579, LR=0.000100
[2025-08-27 08:47:07,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052600] [Batch 00240/03080] [00:02:59/00:35:28, 0.750s/it]: train_loss_raw=0.5997, running_loss=0.5588, LR=0.000100
[2025-08-27 08:47:13,749][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052608] [Batch 00248/03080] [00:03:06/00:35:25, 0.750s/it]: train_loss_raw=0.4568, running_loss=0.5560, LR=0.000100
[2025-08-27 08:47:19,760][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052616] [Batch 00256/03080] [00:03:12/00:35:19, 0.750s/it]: train_loss_raw=0.5558, running_loss=0.5571, LR=0.000100
[2025-08-27 08:47:25,751][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052624] [Batch 00264/03080] [00:03:18/00:35:13, 0.750s/it]: train_loss_raw=0.5204, running_loss=0.5582, LR=0.000100
[2025-08-27 08:47:31,778][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052632] [Batch 00272/03080] [00:03:24/00:35:07, 0.750s/it]: train_loss_raw=0.5301, running_loss=0.5598, LR=0.000100
[2025-08-27 08:47:37,795][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052640] [Batch 00280/03080] [00:03:30/00:35:01, 0.751s/it]: train_loss_raw=0.4423, running_loss=0.5550, LR=0.000100
[2025-08-27 08:47:43,784][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052648] [Batch 00288/03080] [00:03:36/00:34:55, 0.750s/it]: train_loss_raw=0.4925, running_loss=0.5512, LR=0.000100
[2025-08-27 08:47:49,967][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052656] [Batch 00296/03080] [00:03:42/00:34:51, 0.751s/it]: train_loss_raw=0.4480, running_loss=0.5508, LR=0.000100
[2025-08-27 08:47:56,016][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052664] [Batch 00304/03080] [00:03:48/00:34:45, 0.751s/it]: train_loss_raw=0.5714, running_loss=0.5501, LR=0.000100
[2025-08-27 08:48:01,810][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052672] [Batch 00312/03080] [00:03:54/00:34:37, 0.751s/it]: train_loss_raw=0.5291, running_loss=0.5497, LR=0.000100
[2025-08-27 08:48:07,652][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052680] [Batch 00320/03080] [00:04:00/00:34:30, 0.750s/it]: train_loss_raw=0.5054, running_loss=0.5511, LR=0.000100
[2025-08-27 08:48:13,546][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052688] [Batch 00328/03080] [00:04:05/00:34:23, 0.750s/it]: train_loss_raw=0.5545, running_loss=0.5496, LR=0.000100
[2025-08-27 08:48:19,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052696] [Batch 00336/03080] [00:04:11/00:34:17, 0.750s/it]: train_loss_raw=0.6012, running_loss=0.5479, LR=0.000100
[2025-08-27 08:48:25,504][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052704] [Batch 00344/03080] [00:04:17/00:34:10, 0.750s/it]: train_loss_raw=0.6167, running_loss=0.5487, LR=0.000100
[2025-08-27 08:48:31,516][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052712] [Batch 00352/03080] [00:04:23/00:34:05, 0.750s/it]: train_loss_raw=0.5907, running_loss=0.5496, LR=0.000100
[2025-08-27 08:48:37,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052720] [Batch 00360/03080] [00:04:29/00:33:59, 0.750s/it]: train_loss_raw=0.6036, running_loss=0.5487, LR=0.000100
[2025-08-27 08:48:43,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052728] [Batch 00368/03080] [00:04:35/00:33:49, 0.749s/it]: train_loss_raw=0.5753, running_loss=0.5496, LR=0.000100
[2025-08-27 08:48:48,761][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052736] [Batch 00376/03080] [00:04:41/00:33:41, 0.748s/it]: train_loss_raw=0.5266, running_loss=0.5489, LR=0.000100
[2025-08-27 08:48:54,173][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052744] [Batch 00384/03080] [00:04:46/00:33:31, 0.746s/it]: train_loss_raw=0.4793, running_loss=0.5497, LR=0.000100
[2025-08-27 08:49:00,064][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052752] [Batch 00392/03080] [00:04:52/00:33:25, 0.746s/it]: train_loss_raw=0.5128, running_loss=0.5488, LR=0.000100
[2025-08-27 08:49:06,098][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052760] [Batch 00400/03080] [00:04:58/00:33:19, 0.746s/it]: train_loss_raw=0.5963, running_loss=0.5471, LR=0.000100
[2025-08-27 08:49:12,124][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052768] [Batch 00408/03080] [00:05:04/00:33:14, 0.746s/it]: train_loss_raw=0.5189, running_loss=0.5478, LR=0.000100
[2025-08-27 08:49:18,238][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052776] [Batch 00416/03080] [00:05:10/00:33:08, 0.747s/it]: train_loss_raw=0.5819, running_loss=0.5475, LR=0.000100
[2025-08-27 08:49:24,411][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052784] [Batch 00424/03080] [00:05:16/00:33:04, 0.747s/it]: train_loss_raw=0.5115, running_loss=0.5476, LR=0.000100
[2025-08-27 08:49:30,428][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052792] [Batch 00432/03080] [00:05:22/00:32:58, 0.747s/it]: train_loss_raw=0.5402, running_loss=0.5504, LR=0.000100
[2025-08-27 08:49:36,527][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052800] [Batch 00440/03080] [00:05:28/00:32:53, 0.747s/it]: train_loss_raw=0.4514, running_loss=0.5496, LR=0.000100
[2025-08-27 08:49:42,544][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052808] [Batch 00448/03080] [00:05:34/00:32:47, 0.748s/it]: train_loss_raw=0.5656, running_loss=0.5528, LR=0.000100
[2025-08-27 08:49:48,516][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052816] [Batch 00456/03080] [00:05:40/00:32:41, 0.748s/it]: train_loss_raw=0.6190, running_loss=0.5525, LR=0.000100
[2025-08-27 08:49:54,472][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052824] [Batch 00464/03080] [00:05:46/00:32:35, 0.747s/it]: train_loss_raw=0.5736, running_loss=0.5548, LR=0.000100
[2025-08-27 08:50:00,176][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052832] [Batch 00472/03080] [00:05:52/00:32:27, 0.747s/it]: train_loss_raw=0.6244, running_loss=0.5544, LR=0.000100
[2025-08-27 08:50:05,765][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052840] [Batch 00480/03080] [00:05:58/00:32:19, 0.746s/it]: train_loss_raw=0.4917, running_loss=0.5547, LR=0.000100
[2025-08-27 08:50:11,956][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052848] [Batch 00488/03080] [00:06:04/00:32:15, 0.747s/it]: train_loss_raw=0.5978, running_loss=0.5559, LR=0.000100
[2025-08-27 08:50:17,999][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052856] [Batch 00496/03080] [00:06:10/00:32:09, 0.747s/it]: train_loss_raw=0.5192, running_loss=0.5555, LR=0.000100
[2025-08-27 08:50:23,635][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052864] [Batch 00504/03080] [00:06:15/00:32:01, 0.746s/it]: train_loss_raw=0.5677, running_loss=0.5562, LR=0.000100
[2025-08-27 08:50:29,035][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052872] [Batch 00512/03080] [00:06:21/00:31:52, 0.745s/it]: train_loss_raw=0.5325, running_loss=0.5598, LR=0.000100
[2025-08-27 08:50:34,729][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052880] [Batch 00520/03080] [00:06:27/00:31:45, 0.744s/it]: train_loss_raw=0.5330, running_loss=0.5598, LR=0.000100
[2025-08-27 08:50:40,430][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052888] [Batch 00528/03080] [00:06:32/00:31:38, 0.744s/it]: train_loss_raw=0.5381, running_loss=0.5587, LR=0.000100
[2025-08-27 08:50:45,871][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052896] [Batch 00536/03080] [00:06:38/00:31:30, 0.743s/it]: train_loss_raw=0.5499, running_loss=0.5588, LR=0.000100
[2025-08-27 08:50:51,512][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052904] [Batch 00544/03080] [00:06:43/00:31:22, 0.742s/it]: train_loss_raw=0.5761, running_loss=0.5592, LR=0.000100
[2025-08-27 08:50:57,039][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052912] [Batch 00552/03080] [00:06:49/00:31:14, 0.742s/it]: train_loss_raw=0.5083, running_loss=0.5577, LR=0.000100
[2025-08-27 08:51:02,742][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052920] [Batch 00560/03080] [00:06:55/00:31:07, 0.741s/it]: train_loss_raw=0.6140, running_loss=0.5562, LR=0.000100
[2025-08-27 08:51:08,715][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052928] [Batch 00568/03080] [00:07:01/00:31:02, 0.741s/it]: train_loss_raw=0.5189, running_loss=0.5558, LR=0.000100
[2025-08-27 08:51:14,787][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052936] [Batch 00576/03080] [00:07:07/00:30:56, 0.742s/it]: train_loss_raw=0.5197, running_loss=0.5571, LR=0.000100
[2025-08-27 08:51:20,802][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052944] [Batch 00584/03080] [00:07:13/00:30:51, 0.742s/it]: train_loss_raw=0.5341, running_loss=0.5577, LR=0.000100
[2025-08-27 08:51:26,742][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052952] [Batch 00592/03080] [00:07:19/00:30:45, 0.742s/it]: train_loss_raw=0.5921, running_loss=0.5547, LR=0.000100
[2025-08-27 08:51:32,737][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052960] [Batch 00600/03080] [00:07:25/00:30:39, 0.742s/it]: train_loss_raw=0.5681, running_loss=0.5572, LR=0.000100
[2025-08-27 08:51:38,752][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052968] [Batch 00608/03080] [00:07:31/00:30:34, 0.742s/it]: train_loss_raw=0.4813, running_loss=0.5552, LR=0.000100
[2025-08-27 08:51:44,813][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052976] [Batch 00616/03080] [00:07:37/00:30:28, 0.742s/it]: train_loss_raw=0.5814, running_loss=0.5562, LR=0.000100
[2025-08-27 08:51:50,700][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052984] [Batch 00624/03080] [00:07:43/00:30:22, 0.742s/it]: train_loss_raw=0.5477, running_loss=0.5549, LR=0.000100
[2025-08-27 08:51:56,801][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 052992] [Batch 00632/03080] [00:07:49/00:30:17, 0.742s/it]: train_loss_raw=0.5474, running_loss=0.5571, LR=0.000100
[2025-08-27 08:52:02,851][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053000] [Batch 00640/03080] [00:07:55/00:30:11, 0.743s/it]: train_loss_raw=0.5501, running_loss=0.5571, LR=0.000100
[2025-08-27 08:52:08,813][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053008] [Batch 00648/03080] [00:08:01/00:30:05, 0.743s/it]: train_loss_raw=0.5405, running_loss=0.5577, LR=0.000100
[2025-08-27 08:52:14,855][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053016] [Batch 00656/03080] [00:08:07/00:30:00, 0.743s/it]: train_loss_raw=0.5067, running_loss=0.5577, LR=0.000100
[2025-08-27 08:52:20,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053024] [Batch 00664/03080] [00:08:13/00:29:54, 0.743s/it]: train_loss_raw=0.4085, running_loss=0.5568, LR=0.000100
[2025-08-27 08:52:26,568][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053032] [Batch 00672/03080] [00:08:18/00:29:47, 0.742s/it]: train_loss_raw=0.5172, running_loss=0.5557, LR=0.000100
[2025-08-27 08:52:31,969][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053040] [Batch 00680/03080] [00:08:24/00:29:39, 0.742s/it]: train_loss_raw=0.5030, running_loss=0.5529, LR=0.000100
[2025-08-27 08:52:37,360][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053048] [Batch 00688/03080] [00:08:29/00:29:32, 0.741s/it]: train_loss_raw=0.5824, running_loss=0.5514, LR=0.000100
[2025-08-27 08:52:43,448][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053056] [Batch 00696/03080] [00:08:35/00:29:26, 0.741s/it]: train_loss_raw=0.4824, running_loss=0.5508, LR=0.000100
[2025-08-27 08:52:49,303][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053064] [Batch 00704/03080] [00:08:41/00:29:20, 0.741s/it]: train_loss_raw=0.6108, running_loss=0.5508, LR=0.000100
[2025-08-27 08:52:55,319][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053072] [Batch 00712/03080] [00:08:47/00:29:14, 0.741s/it]: train_loss_raw=0.5144, running_loss=0.5481, LR=0.000100
[2025-08-27 08:53:01,373][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053080] [Batch 00720/03080] [00:08:53/00:29:09, 0.741s/it]: train_loss_raw=0.4745, running_loss=0.5473, LR=0.000100
[2025-08-27 08:53:07,332][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053088] [Batch 00728/03080] [00:08:59/00:29:03, 0.741s/it]: train_loss_raw=0.4820, running_loss=0.5471, LR=0.000100
[2025-08-27 08:53:13,147][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053096] [Batch 00736/03080] [00:09:05/00:28:57, 0.741s/it]: train_loss_raw=0.5321, running_loss=0.5477, LR=0.000100
[2025-08-27 08:53:19,231][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053104] [Batch 00744/03080] [00:09:11/00:28:51, 0.741s/it]: train_loss_raw=0.5990, running_loss=0.5499, LR=0.000100
[2025-08-27 08:53:25,016][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053112] [Batch 00752/03080] [00:09:17/00:28:45, 0.741s/it]: train_loss_raw=0.5861, running_loss=0.5512, LR=0.000100
[2025-08-27 08:53:30,987][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053120] [Batch 00760/03080] [00:09:23/00:28:39, 0.741s/it]: train_loss_raw=0.5807, running_loss=0.5530, LR=0.000100
[2025-08-27 08:53:36,908][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053128] [Batch 00768/03080] [00:09:29/00:28:33, 0.741s/it]: train_loss_raw=0.5745, running_loss=0.5542, LR=0.000100
[2025-08-27 08:53:42,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053136] [Batch 00776/03080] [00:09:35/00:28:27, 0.741s/it]: train_loss_raw=0.5203, running_loss=0.5554, LR=0.000100
[2025-08-27 08:53:48,917][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053144] [Batch 00784/03080] [00:09:41/00:28:22, 0.741s/it]: train_loss_raw=0.6189, running_loss=0.5550, LR=0.000100
[2025-08-27 08:53:54,904][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053152] [Batch 00792/03080] [00:09:47/00:28:16, 0.741s/it]: train_loss_raw=0.5154, running_loss=0.5580, LR=0.000100
[2025-08-27 08:54:00,969][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053160] [Batch 00800/03080] [00:09:53/00:28:10, 0.742s/it]: train_loss_raw=0.4644, running_loss=0.5564, LR=0.000100
[2025-08-27 08:54:07,047][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053168] [Batch 00808/03080] [00:09:59/00:28:05, 0.742s/it]: train_loss_raw=0.5523, running_loss=0.5553, LR=0.000100
[2025-08-27 08:54:13,013][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053176] [Batch 00816/03080] [00:10:05/00:27:59, 0.742s/it]: train_loss_raw=0.5909, running_loss=0.5558, LR=0.000100
[2025-08-27 08:54:18,989][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053184] [Batch 00824/03080] [00:10:11/00:27:53, 0.742s/it]: train_loss_raw=0.6449, running_loss=0.5564, LR=0.000100
[2025-08-27 08:54:24,961][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053192] [Batch 00832/03080] [00:10:17/00:27:47, 0.742s/it]: train_loss_raw=0.5016, running_loss=0.5563, LR=0.000100
[2025-08-27 08:54:30,977][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053200] [Batch 00840/03080] [00:10:23/00:27:42, 0.742s/it]: train_loss_raw=0.5641, running_loss=0.5550, LR=0.000100
[2025-08-27 08:54:37,001][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053208] [Batch 00848/03080] [00:10:29/00:27:36, 0.742s/it]: train_loss_raw=0.6125, running_loss=0.5527, LR=0.000100
[2025-08-27 08:54:43,000][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053216] [Batch 00856/03080] [00:10:35/00:27:30, 0.742s/it]: train_loss_raw=0.5845, running_loss=0.5546, LR=0.000100
[2025-08-27 08:54:48,502][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053224] [Batch 00864/03080] [00:10:40/00:27:23, 0.742s/it]: train_loss_raw=0.4918, running_loss=0.5530, LR=0.000100
[2025-08-27 08:54:54,205][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053232] [Batch 00872/03080] [00:10:46/00:27:17, 0.741s/it]: train_loss_raw=0.5314, running_loss=0.5528, LR=0.000100
[2025-08-27 08:55:00,192][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053240] [Batch 00880/03080] [00:10:52/00:27:11, 0.742s/it]: train_loss_raw=0.5486, running_loss=0.5516, LR=0.000100
[2025-08-27 08:55:06,316][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053248] [Batch 00888/03080] [00:10:58/00:27:05, 0.742s/it]: train_loss_raw=0.5269, running_loss=0.5519, LR=0.000100
[2025-08-27 08:55:12,327][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053256] [Batch 00896/03080] [00:11:04/00:27:00, 0.742s/it]: train_loss_raw=0.5119, running_loss=0.5475, LR=0.000100
[2025-08-27 08:55:18,482][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053264] [Batch 00904/03080] [00:11:10/00:26:54, 0.742s/it]: train_loss_raw=0.4905, running_loss=0.5462, LR=0.000100
[2025-08-27 08:55:24,540][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053272] [Batch 00912/03080] [00:11:16/00:26:49, 0.742s/it]: train_loss_raw=0.5824, running_loss=0.5475, LR=0.000100
[2025-08-27 08:55:30,584][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053280] [Batch 00920/03080] [00:11:22/00:26:43, 0.742s/it]: train_loss_raw=0.5841, running_loss=0.5461, LR=0.000100
[2025-08-27 08:55:36,630][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053288] [Batch 00928/03080] [00:11:28/00:26:37, 0.742s/it]: train_loss_raw=0.6710, running_loss=0.5463, LR=0.000100
[2025-08-27 08:55:42,723][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053296] [Batch 00936/03080] [00:11:35/00:26:32, 0.743s/it]: train_loss_raw=0.5334, running_loss=0.5465, LR=0.000100
[2025-08-27 08:55:48,645][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053304] [Batch 00944/03080] [00:11:41/00:26:26, 0.743s/it]: train_loss_raw=0.5538, running_loss=0.5481, LR=0.000100
[2025-08-27 08:55:54,441][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053312] [Batch 00952/03080] [00:11:46/00:26:19, 0.742s/it]: train_loss_raw=0.5169, running_loss=0.5475, LR=0.000100
[2025-08-27 08:56:00,485][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053320] [Batch 00960/03080] [00:11:52/00:26:14, 0.743s/it]: train_loss_raw=0.4964, running_loss=0.5480, LR=0.000100
[2025-08-27 08:56:06,563][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053328] [Batch 00968/03080] [00:11:58/00:26:08, 0.743s/it]: train_loss_raw=0.6545, running_loss=0.5491, LR=0.000100
[2025-08-27 08:56:12,614][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053336] [Batch 00976/03080] [00:12:04/00:26:02, 0.743s/it]: train_loss_raw=0.5201, running_loss=0.5510, LR=0.000100
[2025-08-27 08:56:18,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053344] [Batch 00984/03080] [00:12:11/00:25:57, 0.743s/it]: train_loss_raw=0.4609, running_loss=0.5507, LR=0.000100
[2025-08-27 08:56:24,626][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053352] [Batch 00992/03080] [00:12:16/00:25:51, 0.743s/it]: train_loss_raw=0.6565, running_loss=0.5515, LR=0.000100
[2025-08-27 08:56:30,355][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053360] [Batch 01000/03080] [00:12:22/00:25:44, 0.743s/it]: train_loss_raw=0.5070, running_loss=0.5502, LR=0.000100
[2025-08-27 08:56:36,203][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053368] [Batch 01008/03080] [00:12:28/00:25:38, 0.743s/it]: train_loss_raw=0.6629, running_loss=0.5529, LR=0.000100
[2025-08-27 08:56:42,043][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053376] [Batch 01016/03080] [00:12:34/00:25:32, 0.743s/it]: train_loss_raw=0.5417, running_loss=0.5552, LR=0.000100
[2025-08-27 08:56:47,858][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053384] [Batch 01024/03080] [00:12:40/00:25:26, 0.742s/it]: train_loss_raw=0.4750, running_loss=0.5532, LR=0.000100
[2025-08-27 08:56:53,765][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053392] [Batch 01032/03080] [00:12:46/00:25:20, 0.742s/it]: train_loss_raw=0.5120, running_loss=0.5522, LR=0.000100
[2025-08-27 08:56:59,781][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053400] [Batch 01040/03080] [00:12:52/00:25:14, 0.742s/it]: train_loss_raw=0.6015, running_loss=0.5502, LR=0.000100
[2025-08-27 08:57:05,931][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053408] [Batch 01048/03080] [00:12:58/00:25:09, 0.743s/it]: train_loss_raw=0.5064, running_loss=0.5505, LR=0.000100
[2025-08-27 08:57:12,069][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053416] [Batch 01056/03080] [00:13:04/00:25:03, 0.743s/it]: train_loss_raw=0.5598, running_loss=0.5492, LR=0.000100
[2025-08-27 08:57:18,141][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053424] [Batch 01064/03080] [00:13:10/00:24:57, 0.743s/it]: train_loss_raw=0.5444, running_loss=0.5469, LR=0.000100
[2025-08-27 08:57:24,369][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053432] [Batch 01072/03080] [00:13:16/00:24:52, 0.743s/it]: train_loss_raw=0.5482, running_loss=0.5482, LR=0.000100
[2025-08-27 08:57:30,596][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053440] [Batch 01080/03080] [00:13:22/00:24:46, 0.743s/it]: train_loss_raw=0.5136, running_loss=0.5490, LR=0.000100
[2025-08-27 08:57:36,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053448] [Batch 01088/03080] [00:13:29/00:24:41, 0.744s/it]: train_loss_raw=0.5410, running_loss=0.5481, LR=0.000100
[2025-08-27 08:57:42,878][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053456] [Batch 01096/03080] [00:13:35/00:24:35, 0.744s/it]: train_loss_raw=0.5185, running_loss=0.5472, LR=0.000100
[2025-08-27 08:57:48,904][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053464] [Batch 01104/03080] [00:13:41/00:24:29, 0.744s/it]: train_loss_raw=0.5002, running_loss=0.5466, LR=0.000100
[2025-08-27 08:57:54,901][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053472] [Batch 01112/03080] [00:13:47/00:24:24, 0.744s/it]: train_loss_raw=0.4957, running_loss=0.5457, LR=0.000100
[2025-08-27 08:58:00,874][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053480] [Batch 01120/03080] [00:13:53/00:24:18, 0.744s/it]: train_loss_raw=0.6298, running_loss=0.5470, LR=0.000100
[2025-08-27 08:58:06,953][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053488] [Batch 01128/03080] [00:13:59/00:24:12, 0.744s/it]: train_loss_raw=0.5783, running_loss=0.5478, LR=0.000100
[2025-08-27 08:58:12,963][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053496] [Batch 01136/03080] [00:14:05/00:24:06, 0.744s/it]: train_loss_raw=0.5991, running_loss=0.5488, LR=0.000100
[2025-08-27 08:58:18,975][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053504] [Batch 01144/03080] [00:14:11/00:24:00, 0.744s/it]: train_loss_raw=0.7064, running_loss=0.5516, LR=0.000100
[2025-08-27 08:58:24,995][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053512] [Batch 01152/03080] [00:14:17/00:23:54, 0.744s/it]: train_loss_raw=0.5204, running_loss=0.5504, LR=0.000100
[2025-08-27 08:58:31,022][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053520] [Batch 01160/03080] [00:14:23/00:23:49, 0.744s/it]: train_loss_raw=0.6387, running_loss=0.5516, LR=0.000100
[2025-08-27 08:58:37,036][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053528] [Batch 01168/03080] [00:14:29/00:23:43, 0.744s/it]: train_loss_raw=0.4905, running_loss=0.5513, LR=0.000100
[2025-08-27 08:58:43,144][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053536] [Batch 01176/03080] [00:14:35/00:23:37, 0.744s/it]: train_loss_raw=0.5890, running_loss=0.5490, LR=0.000100
[2025-08-27 08:58:49,218][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053544] [Batch 01184/03080] [00:14:41/00:23:31, 0.745s/it]: train_loss_raw=0.5744, running_loss=0.5486, LR=0.000100
[2025-08-27 08:58:55,232][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053552] [Batch 01192/03080] [00:14:47/00:23:25, 0.745s/it]: train_loss_raw=0.5840, running_loss=0.5473, LR=0.000100
[2025-08-27 08:59:01,361][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053560] [Batch 01200/03080] [00:14:53/00:23:20, 0.745s/it]: train_loss_raw=0.5599, running_loss=0.5475, LR=0.000100
[2025-08-27 08:59:07,402][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053568] [Batch 01208/03080] [00:14:59/00:23:14, 0.745s/it]: train_loss_raw=0.5665, running_loss=0.5465, LR=0.000100
[2025-08-27 08:59:13,560][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053576] [Batch 01216/03080] [00:15:05/00:23:08, 0.745s/it]: train_loss_raw=0.5651, running_loss=0.5483, LR=0.000100
[2025-08-27 08:59:19,590][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053584] [Batch 01224/03080] [00:15:11/00:23:02, 0.745s/it]: train_loss_raw=0.4945, running_loss=0.5475, LR=0.000100
[2025-08-27 08:59:25,583][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053592] [Batch 01232/03080] [00:15:17/00:22:56, 0.745s/it]: train_loss_raw=0.6036, running_loss=0.5499, LR=0.000100
[2025-08-27 08:59:31,551][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053600] [Batch 01240/03080] [00:15:23/00:22:50, 0.745s/it]: train_loss_raw=0.5208, running_loss=0.5481, LR=0.000100
[2025-08-27 08:59:37,421][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053608] [Batch 01248/03080] [00:15:29/00:22:44, 0.745s/it]: train_loss_raw=0.5278, running_loss=0.5470, LR=0.000100
[2025-08-27 08:59:43,221][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053616] [Batch 01256/03080] [00:15:35/00:22:38, 0.745s/it]: train_loss_raw=0.4514, running_loss=0.5488, LR=0.000100
[2025-08-27 08:59:49,040][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053624] [Batch 01264/03080] [00:15:41/00:22:32, 0.745s/it]: train_loss_raw=0.5536, running_loss=0.5496, LR=0.000100
[2025-08-27 08:59:54,846][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053632] [Batch 01272/03080] [00:15:47/00:22:26, 0.745s/it]: train_loss_raw=0.4722, running_loss=0.5493, LR=0.000100
[2025-08-27 09:00:00,701][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053640] [Batch 01280/03080] [00:15:53/00:22:20, 0.745s/it]: train_loss_raw=0.5555, running_loss=0.5490, LR=0.000100
[2025-08-27 09:00:06,437][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053648] [Batch 01288/03080] [00:15:58/00:22:13, 0.744s/it]: train_loss_raw=0.5341, running_loss=0.5477, LR=0.000100
[2025-08-27 09:00:12,154][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053656] [Batch 01296/03080] [00:16:04/00:22:07, 0.744s/it]: train_loss_raw=0.6136, running_loss=0.5469, LR=0.000100
[2025-08-27 09:00:18,345][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053664] [Batch 01304/03080] [00:16:10/00:22:02, 0.744s/it]: train_loss_raw=0.5612, running_loss=0.5439, LR=0.000100
[2025-08-27 09:00:24,450][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053672] [Batch 01312/03080] [00:16:16/00:21:56, 0.745s/it]: train_loss_raw=0.4899, running_loss=0.5417, LR=0.000100
[2025-08-27 09:00:30,693][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053680] [Batch 01320/03080] [00:16:23/00:21:50, 0.745s/it]: train_loss_raw=0.5109, running_loss=0.5424, LR=0.000100
[2025-08-27 09:00:36,710][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053688] [Batch 01328/03080] [00:16:29/00:21:44, 0.745s/it]: train_loss_raw=0.4295, running_loss=0.5424, LR=0.000100
[2025-08-27 09:00:42,747][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053696] [Batch 01336/03080] [00:16:35/00:21:38, 0.745s/it]: train_loss_raw=0.5634, running_loss=0.5429, LR=0.000100
[2025-08-27 09:00:49,012][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053704] [Batch 01344/03080] [00:16:41/00:21:33, 0.745s/it]: train_loss_raw=0.6245, running_loss=0.5444, LR=0.000100
[2025-08-27 09:00:55,240][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053712] [Batch 01352/03080] [00:16:47/00:21:27, 0.745s/it]: train_loss_raw=0.5082, running_loss=0.5466, LR=0.000100
[2025-08-27 09:01:01,297][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053720] [Batch 01360/03080] [00:16:53/00:21:21, 0.745s/it]: train_loss_raw=0.6393, running_loss=0.5477, LR=0.000100
[2025-08-27 09:01:07,326][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053728] [Batch 01368/03080] [00:16:59/00:21:16, 0.745s/it]: train_loss_raw=0.5200, running_loss=0.5484, LR=0.000100
[2025-08-27 09:01:13,384][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053736] [Batch 01376/03080] [00:17:05/00:21:10, 0.745s/it]: train_loss_raw=0.6153, running_loss=0.5478, LR=0.000100
[2025-08-27 09:01:19,581][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053744] [Batch 01384/03080] [00:17:11/00:21:04, 0.746s/it]: train_loss_raw=0.5220, running_loss=0.5471, LR=0.000100
[2025-08-27 09:01:25,598][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053752] [Batch 01392/03080] [00:17:17/00:20:58, 0.746s/it]: train_loss_raw=0.6487, running_loss=0.5502, LR=0.000100
[2025-08-27 09:01:31,633][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053760] [Batch 01400/03080] [00:17:23/00:20:52, 0.746s/it]: train_loss_raw=0.4250, running_loss=0.5501, LR=0.000100
[2025-08-27 09:01:37,681][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053768] [Batch 01408/03080] [00:17:30/00:20:46, 0.746s/it]: train_loss_raw=0.5612, running_loss=0.5508, LR=0.000100
[2025-08-27 09:01:43,883][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053776] [Batch 01416/03080] [00:17:36/00:20:41, 0.746s/it]: train_loss_raw=0.5051, running_loss=0.5492, LR=0.000100
[2025-08-27 09:01:50,140][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053784] [Batch 01424/03080] [00:17:42/00:20:35, 0.746s/it]: train_loss_raw=0.5610, running_loss=0.5475, LR=0.000100
[2025-08-27 09:01:56,317][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053792] [Batch 01432/03080] [00:17:48/00:20:29, 0.746s/it]: train_loss_raw=0.5629, running_loss=0.5489, LR=0.000100
[2025-08-27 09:02:02,306][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053800] [Batch 01440/03080] [00:17:54/00:20:23, 0.746s/it]: train_loss_raw=0.5298, running_loss=0.5466, LR=0.000100
[2025-08-27 09:02:08,318][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053808] [Batch 01448/03080] [00:18:00/00:20:17, 0.746s/it]: train_loss_raw=0.5582, running_loss=0.5462, LR=0.000100
[2025-08-27 09:02:14,315][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053816] [Batch 01456/03080] [00:18:06/00:20:12, 0.746s/it]: train_loss_raw=0.5583, running_loss=0.5513, LR=0.000100
[2025-08-27 09:02:20,284][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053824] [Batch 01464/03080] [00:18:12/00:20:06, 0.746s/it]: train_loss_raw=0.4501, running_loss=0.5498, LR=0.000100
[2025-08-27 09:02:26,149][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053832] [Batch 01472/03080] [00:18:18/00:19:59, 0.746s/it]: train_loss_raw=0.5136, running_loss=0.5479, LR=0.000100
[2025-08-27 09:02:32,316][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053840] [Batch 01480/03080] [00:18:24/00:19:54, 0.746s/it]: train_loss_raw=0.5714, running_loss=0.5467, LR=0.000100
[2025-08-27 09:02:38,376][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053848] [Batch 01488/03080] [00:18:30/00:19:48, 0.746s/it]: train_loss_raw=0.5617, running_loss=0.5467, LR=0.000100
[2025-08-27 09:02:44,483][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053856] [Batch 01496/03080] [00:18:36/00:19:42, 0.747s/it]: train_loss_raw=0.5211, running_loss=0.5469, LR=0.000100
[2025-08-27 09:02:50,511][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053864] [Batch 01504/03080] [00:18:42/00:19:36, 0.747s/it]: train_loss_raw=0.5364, running_loss=0.5462, LR=0.000100
[2025-08-27 09:02:56,544][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053872] [Batch 01512/03080] [00:18:48/00:19:30, 0.747s/it]: train_loss_raw=0.5478, running_loss=0.5462, LR=0.000100
[2025-08-27 09:03:02,596][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053880] [Batch 01520/03080] [00:18:54/00:19:24, 0.747s/it]: train_loss_raw=0.5244, running_loss=0.5444, LR=0.000100
[2025-08-27 09:03:08,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053888] [Batch 01528/03080] [00:19:01/00:19:19, 0.747s/it]: train_loss_raw=0.5479, running_loss=0.5422, LR=0.000100
[2025-08-27 09:03:14,853][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053896] [Batch 01536/03080] [00:19:07/00:19:13, 0.747s/it]: train_loss_raw=0.5716, running_loss=0.5404, LR=0.000100
[2025-08-27 09:03:20,888][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053904] [Batch 01544/03080] [00:19:13/00:19:07, 0.747s/it]: train_loss_raw=0.4969, running_loss=0.5407, LR=0.000100
[2025-08-27 09:03:26,958][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053912] [Batch 01552/03080] [00:19:19/00:19:01, 0.747s/it]: train_loss_raw=0.6329, running_loss=0.5406, LR=0.000100
[2025-08-27 09:03:33,015][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053920] [Batch 01560/03080] [00:19:25/00:18:55, 0.747s/it]: train_loss_raw=0.5885, running_loss=0.5410, LR=0.000100
[2025-08-27 09:03:39,216][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053928] [Batch 01568/03080] [00:19:31/00:18:49, 0.747s/it]: train_loss_raw=0.5158, running_loss=0.5427, LR=0.000100
[2025-08-27 09:03:45,334][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053936] [Batch 01576/03080] [00:19:37/00:18:43, 0.747s/it]: train_loss_raw=0.5290, running_loss=0.5418, LR=0.000100
[2025-08-27 09:03:51,381][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053944] [Batch 01584/03080] [00:19:43/00:18:37, 0.747s/it]: train_loss_raw=0.5637, running_loss=0.5417, LR=0.000100
[2025-08-27 09:03:57,438][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053952] [Batch 01592/03080] [00:19:49/00:18:32, 0.747s/it]: train_loss_raw=0.5190, running_loss=0.5419, LR=0.000100
[2025-08-27 09:04:03,520][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053960] [Batch 01600/03080] [00:19:55/00:18:26, 0.747s/it]: train_loss_raw=0.6509, running_loss=0.5409, LR=0.000100
[2025-08-27 09:04:09,612][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053968] [Batch 01608/03080] [00:20:01/00:18:20, 0.747s/it]: train_loss_raw=0.6537, running_loss=0.5388, LR=0.000100
[2025-08-27 09:04:15,618][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053976] [Batch 01616/03080] [00:20:07/00:18:14, 0.748s/it]: train_loss_raw=0.5517, running_loss=0.5395, LR=0.000100
[2025-08-27 09:04:21,665][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053984] [Batch 01624/03080] [00:20:14/00:18:08, 0.748s/it]: train_loss_raw=0.6305, running_loss=0.5411, LR=0.000100
[2025-08-27 09:04:27,701][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 053992] [Batch 01632/03080] [00:20:20/00:18:02, 0.748s/it]: train_loss_raw=0.4963, running_loss=0.5428, LR=0.000100
[2025-08-27 09:04:33,866][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054000] [Batch 01640/03080] [00:20:26/00:17:56, 0.748s/it]: train_loss_raw=0.5442, running_loss=0.5434, LR=0.000100
[2025-08-27 09:04:43,598][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054008] [Batch 01648/03080] [00:20:35/00:17:53, 0.750s/it]: train_loss_raw=0.4518, running_loss=0.5421, LR=0.000100
[2025-08-27 09:04:49,764][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054016] [Batch 01656/03080] [00:20:42/00:17:48, 0.750s/it]: train_loss_raw=0.4459, running_loss=0.5400, LR=0.000100
[2025-08-27 09:04:55,885][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054024] [Batch 01664/03080] [00:20:48/00:17:42, 0.750s/it]: train_loss_raw=0.5772, running_loss=0.5399, LR=0.000100
[2025-08-27 09:05:01,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054032] [Batch 01672/03080] [00:20:54/00:17:36, 0.750s/it]: train_loss_raw=0.4443, running_loss=0.5360, LR=0.000100
[2025-08-27 09:05:07,956][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054040] [Batch 01680/03080] [00:21:00/00:17:30, 0.750s/it]: train_loss_raw=0.6250, running_loss=0.5363, LR=0.000100
[2025-08-27 09:05:14,086][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054048] [Batch 01688/03080] [00:21:06/00:17:24, 0.750s/it]: train_loss_raw=0.5510, running_loss=0.5357, LR=0.000100
[2025-08-27 09:05:20,156][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054056] [Batch 01696/03080] [00:21:12/00:17:18, 0.750s/it]: train_loss_raw=0.4799, running_loss=0.5378, LR=0.000100
[2025-08-27 09:05:26,217][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054064] [Batch 01704/03080] [00:21:18/00:17:12, 0.750s/it]: train_loss_raw=0.5769, running_loss=0.5372, LR=0.000100
[2025-08-27 09:05:32,265][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054072] [Batch 01712/03080] [00:21:24/00:17:06, 0.750s/it]: train_loss_raw=0.5987, running_loss=0.5356, LR=0.000100
[2025-08-27 09:05:38,256][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054080] [Batch 01720/03080] [00:21:30/00:17:00, 0.750s/it]: train_loss_raw=0.6317, running_loss=0.5353, LR=0.000100
[2025-08-27 09:05:44,341][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054088] [Batch 01728/03080] [00:21:36/00:16:54, 0.750s/it]: train_loss_raw=0.5716, running_loss=0.5352, LR=0.000100
[2025-08-27 09:05:50,450][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054096] [Batch 01736/03080] [00:21:42/00:16:48, 0.750s/it]: train_loss_raw=0.4869, running_loss=0.5349, LR=0.000100
[2025-08-27 09:05:56,468][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054104] [Batch 01744/03080] [00:21:48/00:16:42, 0.750s/it]: train_loss_raw=0.5528, running_loss=0.5342, LR=0.000100
[2025-08-27 09:06:02,518][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054112] [Batch 01752/03080] [00:21:54/00:16:36, 0.750s/it]: train_loss_raw=0.4865, running_loss=0.5322, LR=0.000100
[2025-08-27 09:06:08,527][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054120] [Batch 01760/03080] [00:22:00/00:16:30, 0.751s/it]: train_loss_raw=0.6139, running_loss=0.5349, LR=0.000100
[2025-08-27 09:06:14,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054128] [Batch 01768/03080] [00:22:06/00:16:24, 0.751s/it]: train_loss_raw=0.5787, running_loss=0.5355, LR=0.000100
[2025-08-27 09:06:20,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054136] [Batch 01776/03080] [00:22:12/00:16:18, 0.750s/it]: train_loss_raw=0.4986, running_loss=0.5381, LR=0.000100
[2025-08-27 09:06:26,516][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054144] [Batch 01784/03080] [00:22:18/00:16:12, 0.750s/it]: train_loss_raw=0.6202, running_loss=0.5390, LR=0.000100
[2025-08-27 09:06:32,420][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054152] [Batch 01792/03080] [00:22:24/00:16:06, 0.750s/it]: train_loss_raw=0.5612, running_loss=0.5410, LR=0.000100
[2025-08-27 09:06:38,169][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054160] [Batch 01800/03080] [00:22:30/00:16:00, 0.750s/it]: train_loss_raw=0.6110, running_loss=0.5431, LR=0.000100
[2025-08-27 09:06:44,222][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054168] [Batch 01808/03080] [00:22:36/00:15:54, 0.750s/it]: train_loss_raw=0.5059, running_loss=0.5453, LR=0.000100
[2025-08-27 09:06:50,270][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054176] [Batch 01816/03080] [00:22:42/00:15:48, 0.750s/it]: train_loss_raw=0.6230, running_loss=0.5443, LR=0.000100
[2025-08-27 09:06:56,316][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054184] [Batch 01824/03080] [00:22:48/00:15:42, 0.750s/it]: train_loss_raw=0.5729, running_loss=0.5446, LR=0.000100
[2025-08-27 09:07:02,328][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054192] [Batch 01832/03080] [00:22:54/00:15:36, 0.750s/it]: train_loss_raw=0.5142, running_loss=0.5440, LR=0.000100
[2025-08-27 09:07:08,344][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054200] [Batch 01840/03080] [00:23:00/00:15:30, 0.750s/it]: train_loss_raw=0.6238, running_loss=0.5455, LR=0.000100
[2025-08-27 09:07:14,389][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054208] [Batch 01848/03080] [00:23:06/00:15:24, 0.750s/it]: train_loss_raw=0.6411, running_loss=0.5451, LR=0.000100
[2025-08-27 09:07:20,435][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054216] [Batch 01856/03080] [00:23:12/00:15:18, 0.750s/it]: train_loss_raw=0.4874, running_loss=0.5430, LR=0.000100
[2025-08-27 09:07:26,415][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054224] [Batch 01864/03080] [00:23:18/00:15:12, 0.750s/it]: train_loss_raw=0.5612, running_loss=0.5431, LR=0.000100
[2025-08-27 09:07:32,387][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054232] [Batch 01872/03080] [00:23:24/00:15:06, 0.750s/it]: train_loss_raw=0.4931, running_loss=0.5423, LR=0.000100
[2025-08-27 09:07:38,378][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054240] [Batch 01880/03080] [00:23:30/00:15:00, 0.750s/it]: train_loss_raw=0.4705, running_loss=0.5421, LR=0.000100
[2025-08-27 09:07:44,424][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054248] [Batch 01888/03080] [00:23:36/00:14:54, 0.750s/it]: train_loss_raw=0.5893, running_loss=0.5413, LR=0.000100
[2025-08-27 09:07:50,548][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054256] [Batch 01896/03080] [00:23:42/00:14:48, 0.750s/it]: train_loss_raw=0.5404, running_loss=0.5446, LR=0.000100
[2025-08-27 09:07:56,974][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054264] [Batch 01904/03080] [00:23:49/00:14:42, 0.751s/it]: train_loss_raw=0.5669, running_loss=0.5438, LR=0.000100
[2025-08-27 09:08:03,050][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054272] [Batch 01912/03080] [00:23:55/00:14:36, 0.751s/it]: train_loss_raw=0.6034, running_loss=0.5449, LR=0.000100
[2025-08-27 09:08:09,261][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054280] [Batch 01920/03080] [00:24:01/00:14:30, 0.751s/it]: train_loss_raw=0.5342, running_loss=0.5432, LR=0.000100
[2025-08-27 09:08:15,346][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054288] [Batch 01928/03080] [00:24:07/00:14:25, 0.751s/it]: train_loss_raw=0.6099, running_loss=0.5424, LR=0.000100
[2025-08-27 09:08:21,415][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054296] [Batch 01936/03080] [00:24:13/00:14:19, 0.751s/it]: train_loss_raw=0.6018, running_loss=0.5436, LR=0.000100
[2025-08-27 09:08:27,624][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054304] [Batch 01944/03080] [00:24:19/00:14:13, 0.751s/it]: train_loss_raw=0.6145, running_loss=0.5440, LR=0.000100
[2025-08-27 09:08:33,684][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054312] [Batch 01952/03080] [00:24:26/00:14:07, 0.751s/it]: train_loss_raw=0.4997, running_loss=0.5442, LR=0.000100
[2025-08-27 09:08:39,723][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054320] [Batch 01960/03080] [00:24:32/00:14:01, 0.751s/it]: train_loss_raw=0.4336, running_loss=0.5444, LR=0.000100
[2025-08-27 09:08:45,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054328] [Batch 01968/03080] [00:24:38/00:13:55, 0.751s/it]: train_loss_raw=0.5818, running_loss=0.5465, LR=0.000100
[2025-08-27 09:08:52,005][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054336] [Batch 01976/03080] [00:24:44/00:13:49, 0.751s/it]: train_loss_raw=0.5788, running_loss=0.5473, LR=0.000100
[2025-08-27 09:08:58,088][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054344] [Batch 01984/03080] [00:24:50/00:13:43, 0.751s/it]: train_loss_raw=0.4687, running_loss=0.5453, LR=0.000100
[2025-08-27 09:09:04,228][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054352] [Batch 01992/03080] [00:24:56/00:13:37, 0.751s/it]: train_loss_raw=0.4145, running_loss=0.5420, LR=0.000100
[2025-08-27 09:09:10,359][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054360] [Batch 02000/03080] [00:25:02/00:13:31, 0.751s/it]: train_loss_raw=0.5809, running_loss=0.5421, LR=0.000100
[2025-08-27 09:09:16,392][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054368] [Batch 02008/03080] [00:25:08/00:13:25, 0.751s/it]: train_loss_raw=0.5865, running_loss=0.5409, LR=0.000100
[2025-08-27 09:09:22,425][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054376] [Batch 02016/03080] [00:25:14/00:13:19, 0.751s/it]: train_loss_raw=0.5574, running_loss=0.5399, LR=0.000100
[2025-08-27 09:09:28,640][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054384] [Batch 02024/03080] [00:25:20/00:13:13, 0.751s/it]: train_loss_raw=0.4693, running_loss=0.5402, LR=0.000100
[2025-08-27 09:09:34,688][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054392] [Batch 02032/03080] [00:25:27/00:13:07, 0.751s/it]: train_loss_raw=0.5256, running_loss=0.5401, LR=0.000100
[2025-08-27 09:09:40,745][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054400] [Batch 02040/03080] [00:25:33/00:13:01, 0.752s/it]: train_loss_raw=0.4752, running_loss=0.5419, LR=0.000100
[2025-08-27 09:09:46,880][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054408] [Batch 02048/03080] [00:25:39/00:12:55, 0.752s/it]: train_loss_raw=0.5559, running_loss=0.5414, LR=0.000100
[2025-08-27 09:09:52,981][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054416] [Batch 02056/03080] [00:25:45/00:12:49, 0.752s/it]: train_loss_raw=0.5363, running_loss=0.5407, LR=0.000100
[2025-08-27 09:09:59,099][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054424] [Batch 02064/03080] [00:25:51/00:12:43, 0.752s/it]: train_loss_raw=0.5875, running_loss=0.5398, LR=0.000100
[2025-08-27 09:10:05,360][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054432] [Batch 02072/03080] [00:25:57/00:12:37, 0.752s/it]: train_loss_raw=0.4448, running_loss=0.5371, LR=0.000100
[2025-08-27 09:10:11,469][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054440] [Batch 02080/03080] [00:26:03/00:12:31, 0.752s/it]: train_loss_raw=0.5183, running_loss=0.5350, LR=0.000100
[2025-08-27 09:10:17,483][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054448] [Batch 02088/03080] [00:26:09/00:12:25, 0.752s/it]: train_loss_raw=0.6292, running_loss=0.5347, LR=0.000100
[2025-08-27 09:10:23,404][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054456] [Batch 02096/03080] [00:26:15/00:12:19, 0.752s/it]: train_loss_raw=0.4722, running_loss=0.5335, LR=0.000100
[2025-08-27 09:10:29,504][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054464] [Batch 02104/03080] [00:26:21/00:12:13, 0.752s/it]: train_loss_raw=0.4937, running_loss=0.5334, LR=0.000100
[2025-08-27 09:10:35,604][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054472] [Batch 02112/03080] [00:26:27/00:12:07, 0.752s/it]: train_loss_raw=0.5092, running_loss=0.5329, LR=0.000100
[2025-08-27 09:10:41,736][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054480] [Batch 02120/03080] [00:26:34/00:12:01, 0.752s/it]: train_loss_raw=0.6177, running_loss=0.5341, LR=0.000100
[2025-08-27 09:10:47,742][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054488] [Batch 02128/03080] [00:26:40/00:11:55, 0.752s/it]: train_loss_raw=0.5375, running_loss=0.5363, LR=0.000100
[2025-08-27 09:10:53,846][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054496] [Batch 02136/03080] [00:26:46/00:11:49, 0.752s/it]: train_loss_raw=0.5298, running_loss=0.5394, LR=0.000100
[2025-08-27 09:10:59,886][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054504] [Batch 02144/03080] [00:26:52/00:11:43, 0.752s/it]: train_loss_raw=0.4846, running_loss=0.5402, LR=0.000100
[2025-08-27 09:11:05,954][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054512] [Batch 02152/03080] [00:26:58/00:11:37, 0.752s/it]: train_loss_raw=0.5655, running_loss=0.5409, LR=0.000100
[2025-08-27 09:11:12,059][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054520] [Batch 02160/03080] [00:27:04/00:11:31, 0.752s/it]: train_loss_raw=0.5291, running_loss=0.5427, LR=0.000100
[2025-08-27 09:11:18,067][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054528] [Batch 02168/03080] [00:27:10/00:11:25, 0.752s/it]: train_loss_raw=0.5753, running_loss=0.5431, LR=0.000100
[2025-08-27 09:11:24,144][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054536] [Batch 02176/03080] [00:27:16/00:11:19, 0.752s/it]: train_loss_raw=0.5084, running_loss=0.5408, LR=0.000100
[2025-08-27 09:11:30,244][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054544] [Batch 02184/03080] [00:27:22/00:11:13, 0.752s/it]: train_loss_raw=0.5818, running_loss=0.5407, LR=0.000100
[2025-08-27 09:11:36,401][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054552] [Batch 02192/03080] [00:27:28/00:11:07, 0.752s/it]: train_loss_raw=0.5780, running_loss=0.5419, LR=0.000100
[2025-08-27 09:11:42,456][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054560] [Batch 02200/03080] [00:27:34/00:11:01, 0.752s/it]: train_loss_raw=0.5814, running_loss=0.5440, LR=0.000100
[2025-08-27 09:11:48,523][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054568] [Batch 02208/03080] [00:27:40/00:10:55, 0.752s/it]: train_loss_raw=0.5214, running_loss=0.5443, LR=0.000100
[2025-08-27 09:11:54,630][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054576] [Batch 02216/03080] [00:27:46/00:10:49, 0.752s/it]: train_loss_raw=0.5463, running_loss=0.5450, LR=0.000100
[2025-08-27 09:12:00,669][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054584] [Batch 02224/03080] [00:27:53/00:10:43, 0.752s/it]: train_loss_raw=0.6042, running_loss=0.5473, LR=0.000100
[2025-08-27 09:12:06,895][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054592] [Batch 02232/03080] [00:27:59/00:10:37, 0.752s/it]: train_loss_raw=0.4446, running_loss=0.5461, LR=0.000100
[2025-08-27 09:12:12,994][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054600] [Batch 02240/03080] [00:28:05/00:10:32, 0.752s/it]: train_loss_raw=0.4947, running_loss=0.5465, LR=0.000100
[2025-08-27 09:12:19,119][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054608] [Batch 02248/03080] [00:28:11/00:10:26, 0.752s/it]: train_loss_raw=0.6426, running_loss=0.5467, LR=0.000100
[2025-08-27 09:12:25,187][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054616] [Batch 02256/03080] [00:28:17/00:10:20, 0.752s/it]: train_loss_raw=0.5212, running_loss=0.5441, LR=0.000100
[2025-08-27 09:12:31,267][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054624] [Batch 02264/03080] [00:28:23/00:10:14, 0.752s/it]: train_loss_raw=0.5757, running_loss=0.5462, LR=0.000100
[2025-08-27 09:12:37,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054632] [Batch 02272/03080] [00:28:29/00:10:08, 0.753s/it]: train_loss_raw=0.5289, running_loss=0.5467, LR=0.000100
[2025-08-27 09:12:43,491][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054640] [Batch 02280/03080] [00:28:35/00:10:02, 0.753s/it]: train_loss_raw=0.6349, running_loss=0.5465, LR=0.000100
[2025-08-27 09:12:49,557][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054648] [Batch 02288/03080] [00:28:41/00:09:56, 0.753s/it]: train_loss_raw=0.3892, running_loss=0.5448, LR=0.000100
[2025-08-27 09:12:55,396][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054656] [Batch 02296/03080] [00:28:47/00:09:49, 0.753s/it]: train_loss_raw=0.5561, running_loss=0.5432, LR=0.000100
[2025-08-27 09:13:00,958][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054664] [Batch 02304/03080] [00:28:53/00:09:43, 0.752s/it]: train_loss_raw=0.5349, running_loss=0.5419, LR=0.000100
[2025-08-27 09:13:06,948][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054672] [Batch 02312/03080] [00:28:59/00:09:37, 0.752s/it]: train_loss_raw=0.5416, running_loss=0.5418, LR=0.000100
[2025-08-27 09:13:13,047][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054680] [Batch 02320/03080] [00:29:05/00:09:31, 0.752s/it]: train_loss_raw=0.4887, running_loss=0.5375, LR=0.000100
[2025-08-27 09:13:19,187][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054688] [Batch 02328/03080] [00:29:11/00:09:25, 0.752s/it]: train_loss_raw=0.5566, running_loss=0.5343, LR=0.000100
[2025-08-27 09:13:25,290][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054696] [Batch 02336/03080] [00:29:17/00:09:19, 0.752s/it]: train_loss_raw=0.4669, running_loss=0.5335, LR=0.000100
[2025-08-27 09:13:31,369][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054704] [Batch 02344/03080] [00:29:23/00:09:13, 0.752s/it]: train_loss_raw=0.5607, running_loss=0.5342, LR=0.000100
[2025-08-27 09:13:37,489][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054712] [Batch 02352/03080] [00:29:29/00:09:07, 0.752s/it]: train_loss_raw=0.5161, running_loss=0.5355, LR=0.000100
[2025-08-27 09:13:43,345][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054720] [Batch 02360/03080] [00:29:35/00:09:01, 0.752s/it]: train_loss_raw=0.4701, running_loss=0.5356, LR=0.000100
[2025-08-27 09:13:49,391][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054728] [Batch 02368/03080] [00:29:41/00:08:55, 0.752s/it]: train_loss_raw=0.4666, running_loss=0.5362, LR=0.000100
[2025-08-27 09:13:55,350][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054736] [Batch 02376/03080] [00:29:47/00:08:49, 0.752s/it]: train_loss_raw=0.4953, running_loss=0.5343, LR=0.000100
[2025-08-27 09:14:01,471][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054744] [Batch 02384/03080] [00:29:53/00:08:43, 0.752s/it]: train_loss_raw=0.4964, running_loss=0.5327, LR=0.000100
[2025-08-27 09:14:07,473][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054752] [Batch 02392/03080] [00:29:59/00:08:37, 0.752s/it]: train_loss_raw=0.5463, running_loss=0.5312, LR=0.000100
[2025-08-27 09:14:13,501][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054760] [Batch 02400/03080] [00:30:05/00:08:31, 0.752s/it]: train_loss_raw=0.5199, running_loss=0.5296, LR=0.000100
[2025-08-27 09:14:19,575][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054768] [Batch 02408/03080] [00:30:11/00:08:25, 0.752s/it]: train_loss_raw=0.4876, running_loss=0.5290, LR=0.000100
[2025-08-27 09:14:25,670][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054776] [Batch 02416/03080] [00:30:18/00:08:19, 0.752s/it]: train_loss_raw=0.5231, running_loss=0.5289, LR=0.000100
[2025-08-27 09:14:31,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054784] [Batch 02424/03080] [00:30:24/00:08:13, 0.753s/it]: train_loss_raw=0.5066, running_loss=0.5287, LR=0.000100
[2025-08-27 09:14:37,957][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054792] [Batch 02432/03080] [00:30:30/00:08:07, 0.753s/it]: train_loss_raw=0.5098, running_loss=0.5306, LR=0.000100
[2025-08-27 09:14:43,938][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054800] [Batch 02440/03080] [00:30:36/00:08:01, 0.753s/it]: train_loss_raw=0.5180, running_loss=0.5314, LR=0.000100
[2025-08-27 09:14:49,965][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054808] [Batch 02448/03080] [00:30:42/00:07:55, 0.753s/it]: train_loss_raw=0.5751, running_loss=0.5325, LR=0.000100
[2025-08-27 09:14:56,026][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054816] [Batch 02456/03080] [00:30:48/00:07:49, 0.753s/it]: train_loss_raw=0.5335, running_loss=0.5336, LR=0.000100
[2025-08-27 09:15:02,037][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054824] [Batch 02464/03080] [00:30:54/00:07:43, 0.753s/it]: train_loss_raw=0.5468, running_loss=0.5348, LR=0.000100
[2025-08-27 09:15:08,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054832] [Batch 02472/03080] [00:31:00/00:07:37, 0.753s/it]: train_loss_raw=0.6037, running_loss=0.5336, LR=0.000100
[2025-08-27 09:15:14,114][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054840] [Batch 02480/03080] [00:31:06/00:07:31, 0.753s/it]: train_loss_raw=0.5310, running_loss=0.5335, LR=0.000100
[2025-08-27 09:15:20,125][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054848] [Batch 02488/03080] [00:31:12/00:07:25, 0.753s/it]: train_loss_raw=0.5207, running_loss=0.5353, LR=0.000100
[2025-08-27 09:15:26,131][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054856] [Batch 02496/03080] [00:31:18/00:07:19, 0.753s/it]: train_loss_raw=0.4316, running_loss=0.5320, LR=0.000100
[2025-08-27 09:15:32,175][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054864] [Batch 02504/03080] [00:31:24/00:07:13, 0.753s/it]: train_loss_raw=0.5332, running_loss=0.5302, LR=0.000100
[2025-08-27 09:15:38,293][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054872] [Batch 02512/03080] [00:31:30/00:07:07, 0.753s/it]: train_loss_raw=0.6352, running_loss=0.5313, LR=0.000100
[2025-08-27 09:15:44,387][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054880] [Batch 02520/03080] [00:31:36/00:07:01, 0.753s/it]: train_loss_raw=0.5631, running_loss=0.5295, LR=0.000100
[2025-08-27 09:15:50,385][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054888] [Batch 02528/03080] [00:31:42/00:06:55, 0.753s/it]: train_loss_raw=0.5601, running_loss=0.5283, LR=0.000100
[2025-08-27 09:15:56,341][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054896] [Batch 02536/03080] [00:31:48/00:06:49, 0.753s/it]: train_loss_raw=0.5189, running_loss=0.5297, LR=0.000100
[2025-08-27 09:16:02,367][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054904] [Batch 02544/03080] [00:31:54/00:06:43, 0.753s/it]: train_loss_raw=0.5680, running_loss=0.5330, LR=0.000100
[2025-08-27 09:16:08,417][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054912] [Batch 02552/03080] [00:32:00/00:06:37, 0.753s/it]: train_loss_raw=0.5387, running_loss=0.5340, LR=0.000100
[2025-08-27 09:16:14,453][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054920] [Batch 02560/03080] [00:32:06/00:06:31, 0.753s/it]: train_loss_raw=0.5078, running_loss=0.5321, LR=0.000100
[2025-08-27 09:16:20,511][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054928] [Batch 02568/03080] [00:32:12/00:06:25, 0.753s/it]: train_loss_raw=0.4892, running_loss=0.5336, LR=0.000100
[2025-08-27 09:16:26,632][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054936] [Batch 02576/03080] [00:32:18/00:06:19, 0.753s/it]: train_loss_raw=0.5484, running_loss=0.5338, LR=0.000100
[2025-08-27 09:16:32,748][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054944] [Batch 02584/03080] [00:32:25/00:06:13, 0.753s/it]: train_loss_raw=0.6058, running_loss=0.5326, LR=0.000100
[2025-08-27 09:16:38,787][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054952] [Batch 02592/03080] [00:32:31/00:06:07, 0.753s/it]: train_loss_raw=0.5590, running_loss=0.5334, LR=0.000100
[2025-08-27 09:16:44,838][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054960] [Batch 02600/03080] [00:32:37/00:06:01, 0.753s/it]: train_loss_raw=0.4787, running_loss=0.5323, LR=0.000100
[2025-08-27 09:16:50,893][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054968] [Batch 02608/03080] [00:32:43/00:05:55, 0.753s/it]: train_loss_raw=0.5743, running_loss=0.5322, LR=0.000100
[2025-08-27 09:16:57,030][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054976] [Batch 02616/03080] [00:32:49/00:05:49, 0.753s/it]: train_loss_raw=0.6262, running_loss=0.5331, LR=0.000100
[2025-08-27 09:17:03,013][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054984] [Batch 02624/03080] [00:32:55/00:05:43, 0.753s/it]: train_loss_raw=0.5333, running_loss=0.5326, LR=0.000100
[2025-08-27 09:17:09,052][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 054992] [Batch 02632/03080] [00:33:01/00:05:37, 0.753s/it]: train_loss_raw=0.5122, running_loss=0.5318, LR=0.000100
[2025-08-27 09:17:15,217][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055000] [Batch 02640/03080] [00:33:07/00:05:31, 0.753s/it]: train_loss_raw=0.4872, running_loss=0.5285, LR=0.000100
[2025-08-27 09:17:21,303][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055008] [Batch 02648/03080] [00:33:13/00:05:25, 0.753s/it]: train_loss_raw=0.5523, running_loss=0.5308, LR=0.000100
[2025-08-27 09:17:27,468][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055016] [Batch 02656/03080] [00:33:19/00:05:19, 0.753s/it]: train_loss_raw=0.5185, running_loss=0.5303, LR=0.000100
[2025-08-27 09:17:33,557][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055024] [Batch 02664/03080] [00:33:25/00:05:13, 0.753s/it]: train_loss_raw=0.4929, running_loss=0.5288, LR=0.000100
[2025-08-27 09:17:39,656][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055032] [Batch 02672/03080] [00:33:32/00:05:07, 0.753s/it]: train_loss_raw=0.5177, running_loss=0.5287, LR=0.000100
[2025-08-27 09:17:45,698][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055040] [Batch 02680/03080] [00:33:38/00:05:01, 0.753s/it]: train_loss_raw=0.4853, running_loss=0.5297, LR=0.000100
[2025-08-27 09:17:51,746][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055048] [Batch 02688/03080] [00:33:44/00:04:55, 0.753s/it]: train_loss_raw=0.5283, running_loss=0.5288, LR=0.000100
[2025-08-27 09:17:57,796][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055056] [Batch 02696/03080] [00:33:50/00:04:49, 0.753s/it]: train_loss_raw=0.5823, running_loss=0.5319, LR=0.000100
[2025-08-27 09:18:03,843][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055064] [Batch 02704/03080] [00:33:56/00:04:43, 0.753s/it]: train_loss_raw=0.4854, running_loss=0.5314, LR=0.000100
[2025-08-27 09:18:09,870][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055072] [Batch 02712/03080] [00:34:02/00:04:37, 0.753s/it]: train_loss_raw=0.5947, running_loss=0.5294, LR=0.000100
[2025-08-27 09:18:15,901][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055080] [Batch 02720/03080] [00:34:08/00:04:31, 0.753s/it]: train_loss_raw=0.5253, running_loss=0.5325, LR=0.000100
[2025-08-27 09:18:21,952][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055088] [Batch 02728/03080] [00:34:14/00:04:25, 0.753s/it]: train_loss_raw=0.5139, running_loss=0.5325, LR=0.000100
[2025-08-27 09:18:27,946][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055096] [Batch 02736/03080] [00:34:20/00:04:19, 0.753s/it]: train_loss_raw=0.5395, running_loss=0.5293, LR=0.000100
[2025-08-27 09:18:33,920][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055104] [Batch 02744/03080] [00:34:26/00:04:13, 0.753s/it]: train_loss_raw=0.5666, running_loss=0.5287, LR=0.000100
[2025-08-27 09:18:40,078][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055112] [Batch 02752/03080] [00:34:32/00:04:07, 0.753s/it]: train_loss_raw=0.5659, running_loss=0.5285, LR=0.000100
[2025-08-27 09:18:46,082][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055120] [Batch 02760/03080] [00:34:38/00:04:00, 0.753s/it]: train_loss_raw=0.5955, running_loss=0.5304, LR=0.000100
[2025-08-27 09:18:52,107][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055128] [Batch 02768/03080] [00:34:44/00:03:54, 0.753s/it]: train_loss_raw=0.5735, running_loss=0.5296, LR=0.000100
[2025-08-27 09:18:58,095][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055136] [Batch 02776/03080] [00:34:50/00:03:48, 0.753s/it]: train_loss_raw=0.4403, running_loss=0.5291, LR=0.000100
[2025-08-27 09:19:04,065][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055144] [Batch 02784/03080] [00:34:56/00:03:42, 0.753s/it]: train_loss_raw=0.5680, running_loss=0.5301, LR=0.000100
[2025-08-27 09:19:10,121][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055152] [Batch 02792/03080] [00:35:02/00:03:36, 0.753s/it]: train_loss_raw=0.6003, running_loss=0.5310, LR=0.000100
[2025-08-27 09:19:16,158][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055160] [Batch 02800/03080] [00:35:08/00:03:30, 0.753s/it]: train_loss_raw=0.5605, running_loss=0.5322, LR=0.000100
[2025-08-27 09:19:22,181][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055168] [Batch 02808/03080] [00:35:14/00:03:24, 0.753s/it]: train_loss_raw=0.6051, running_loss=0.5341, LR=0.000100
[2025-08-27 09:19:28,194][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055176] [Batch 02816/03080] [00:35:20/00:03:18, 0.753s/it]: train_loss_raw=0.4952, running_loss=0.5333, LR=0.000100
[2025-08-27 09:19:34,207][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055184] [Batch 02824/03080] [00:35:26/00:03:12, 0.753s/it]: train_loss_raw=0.5613, running_loss=0.5337, LR=0.000100
[2025-08-27 09:19:40,184][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055192] [Batch 02832/03080] [00:35:32/00:03:06, 0.753s/it]: train_loss_raw=0.4583, running_loss=0.5326, LR=0.000100
[2025-08-27 09:19:46,225][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055200] [Batch 02840/03080] [00:35:38/00:03:00, 0.753s/it]: train_loss_raw=0.5731, running_loss=0.5327, LR=0.000100
[2025-08-27 09:19:52,232][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055208] [Batch 02848/03080] [00:35:44/00:02:54, 0.753s/it]: train_loss_raw=0.4336, running_loss=0.5319, LR=0.000100
[2025-08-27 09:19:58,243][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055216] [Batch 02856/03080] [00:35:50/00:02:48, 0.753s/it]: train_loss_raw=0.5143, running_loss=0.5310, LR=0.000100
[2025-08-27 09:20:04,089][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055224] [Batch 02864/03080] [00:35:56/00:02:42, 0.753s/it]: train_loss_raw=0.4121, running_loss=0.5292, LR=0.000100
[2025-08-27 09:20:09,974][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055232] [Batch 02872/03080] [00:36:02/00:02:36, 0.753s/it]: train_loss_raw=0.4769, running_loss=0.5294, LR=0.000100
[2025-08-27 09:20:15,941][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055240] [Batch 02880/03080] [00:36:08/00:02:30, 0.753s/it]: train_loss_raw=0.4378, running_loss=0.5288, LR=0.000100
[2025-08-27 09:20:21,950][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055248] [Batch 02888/03080] [00:36:14/00:02:24, 0.753s/it]: train_loss_raw=0.5936, running_loss=0.5296, LR=0.000100
[2025-08-27 09:20:28,020][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055256] [Batch 02896/03080] [00:36:20/00:02:18, 0.753s/it]: train_loss_raw=0.5459, running_loss=0.5304, LR=0.000100
[2025-08-27 09:20:34,026][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055264] [Batch 02904/03080] [00:36:26/00:02:12, 0.753s/it]: train_loss_raw=0.4956, running_loss=0.5322, LR=0.000100
[2025-08-27 09:20:40,045][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055272] [Batch 02912/03080] [00:36:32/00:02:06, 0.753s/it]: train_loss_raw=0.4865, running_loss=0.5310, LR=0.000100
[2025-08-27 09:20:46,039][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055280] [Batch 02920/03080] [00:36:38/00:02:00, 0.753s/it]: train_loss_raw=0.4537, running_loss=0.5308, LR=0.000100
[2025-08-27 09:20:52,077][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055288] [Batch 02928/03080] [00:36:44/00:01:54, 0.753s/it]: train_loss_raw=0.5835, running_loss=0.5352, LR=0.000100
[2025-08-27 09:20:58,133][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055296] [Batch 02936/03080] [00:36:50/00:01:48, 0.753s/it]: train_loss_raw=0.4931, running_loss=0.5327, LR=0.000100
[2025-08-27 09:21:04,125][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055304] [Batch 02944/03080] [00:36:56/00:01:42, 0.753s/it]: train_loss_raw=0.5760, running_loss=0.5340, LR=0.000100
[2025-08-27 09:21:10,145][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055312] [Batch 02952/03080] [00:37:02/00:01:36, 0.753s/it]: train_loss_raw=0.5027, running_loss=0.5330, LR=0.000100
[2025-08-27 09:21:16,245][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055320] [Batch 02960/03080] [00:37:08/00:01:30, 0.753s/it]: train_loss_raw=0.5534, running_loss=0.5329, LR=0.000100
[2025-08-27 09:21:22,345][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055328] [Batch 02968/03080] [00:37:14/00:01:24, 0.753s/it]: train_loss_raw=0.6021, running_loss=0.5323, LR=0.000100
[2025-08-27 09:21:28,392][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055336] [Batch 02976/03080] [00:37:20/00:01:18, 0.753s/it]: train_loss_raw=0.5832, running_loss=0.5333, LR=0.000100
[2025-08-27 09:21:34,405][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055344] [Batch 02984/03080] [00:37:26/00:01:12, 0.753s/it]: train_loss_raw=0.3952, running_loss=0.5319, LR=0.000100
[2025-08-27 09:21:40,384][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055352] [Batch 02992/03080] [00:37:32/00:01:06, 0.753s/it]: train_loss_raw=0.4988, running_loss=0.5334, LR=0.000100
[2025-08-27 09:21:46,361][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055360] [Batch 03000/03080] [00:37:38/00:01:00, 0.753s/it]: train_loss_raw=0.4539, running_loss=0.5327, LR=0.000100
[2025-08-27 09:21:52,010][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055368] [Batch 03008/03080] [00:37:44/00:00:54, 0.753s/it]: train_loss_raw=0.5588, running_loss=0.5329, LR=0.000100
[2025-08-27 09:21:57,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055376] [Batch 03016/03080] [00:37:50/00:00:48, 0.753s/it]: train_loss_raw=0.5837, running_loss=0.5346, LR=0.000100
[2025-08-27 09:22:03,825][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055384] [Batch 03024/03080] [00:37:56/00:00:42, 0.753s/it]: train_loss_raw=0.4485, running_loss=0.5335, LR=0.000100
[2025-08-27 09:22:09,877][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055392] [Batch 03032/03080] [00:38:02/00:00:36, 0.753s/it]: train_loss_raw=0.4471, running_loss=0.5318, LR=0.000100
[2025-08-27 09:22:15,903][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055400] [Batch 03040/03080] [00:38:08/00:00:30, 0.753s/it]: train_loss_raw=0.4637, running_loss=0.5320, LR=0.000100
[2025-08-27 09:22:21,922][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055408] [Batch 03048/03080] [00:38:14/00:00:24, 0.753s/it]: train_loss_raw=0.5487, running_loss=0.5295, LR=0.000100
[2025-08-27 09:22:27,947][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055416] [Batch 03056/03080] [00:38:20/00:00:18, 0.753s/it]: train_loss_raw=0.5124, running_loss=0.5285, LR=0.000100
[2025-08-27 09:22:33,974][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055424] [Batch 03064/03080] [00:38:26/00:00:12, 0.753s/it]: train_loss_raw=0.6228, running_loss=0.5308, LR=0.000100
[2025-08-27 09:22:40,105][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055432] [Batch 03072/03080] [00:38:32/00:00:06, 0.753s/it]: train_loss_raw=0.5896, running_loss=0.5295, LR=0.000100
[2025-08-27 09:22:51,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 055440] [Batch 03080/03080] [00:38:43/00:00:00, 0.754s/it]: train_loss_raw=0.4339, running_loss=0.5274, LR=0.000100
[2025-08-27 09:22:51,612][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-27 09:23:02,415][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00007/00310] [00:00:10/00:06:47, 1.350s/it]
[2025-08-27 09:23:14,873][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00015/00310] [00:00:23/00:07:07, 1.454s/it]
[2025-08-27 09:23:26,734][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00023/00310] [00:00:35/00:06:58, 1.463s/it]
[2025-08-27 09:23:39,063][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00031/00310] [00:00:47/00:06:52, 1.483s/it]
[2025-08-27 09:23:51,378][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00039/00310] [00:00:59/00:06:43, 1.494s/it]
[2025-08-27 09:24:03,833][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00047/00310] [00:01:12/00:06:34, 1.505s/it]
[2025-08-27 09:24:14,870][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00055/00310] [00:01:23/00:06:17, 1.487s/it]
[2025-08-27 09:24:26,602][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00063/00310] [00:01:34/00:06:05, 1.484s/it]
[2025-08-27 09:24:38,834][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00071/00310] [00:01:47/00:05:54, 1.489s/it]
[2025-08-27 09:24:50,930][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00079/00310] [00:01:59/00:05:43, 1.491s/it]
[2025-08-27 09:25:02,298][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00087/00310] [00:02:10/00:05:29, 1.485s/it]
[2025-08-27 09:25:13,205][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00095/00310] [00:02:21/00:05:15, 1.475s/it]
[2025-08-27 09:25:25,363][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00103/00310] [00:02:33/00:05:04, 1.478s/it]
[2025-08-27 09:25:37,216][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00111/00310] [00:02:45/00:04:52, 1.479s/it]
[2025-08-27 09:25:49,266][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00119/00310] [00:02:57/00:04:41, 1.480s/it]
[2025-08-27 09:26:02,021][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00127/00310] [00:03:10/00:04:30, 1.488s/it]
[2025-08-27 09:26:14,599][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00135/00310] [00:03:22/00:04:19, 1.493s/it]
[2025-08-27 09:26:27,216][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00143/00310] [00:03:35/00:04:08, 1.497s/it]
[2025-08-27 09:26:37,470][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00151/00310] [00:03:45/00:03:54, 1.486s/it]
[2025-08-27 09:26:47,982][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00159/00310] [00:03:56/00:03:41, 1.477s/it]
[2025-08-27 09:26:59,820][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00167/00310] [00:04:08/00:03:29, 1.477s/it]
[2025-08-27 09:27:10,300][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00175/00310] [00:04:18/00:03:16, 1.470s/it]
[2025-08-27 09:27:21,600][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00183/00310] [00:04:29/00:03:04, 1.467s/it]
[2025-08-27 09:27:33,257][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00191/00310] [00:04:41/00:02:53, 1.467s/it]
[2025-08-27 09:27:44,900][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00199/00310] [00:04:53/00:02:41, 1.466s/it]
[2025-08-27 09:27:55,839][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00207/00310] [00:05:04/00:02:29, 1.463s/it]
[2025-08-27 09:28:06,449][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00215/00310] [00:05:14/00:02:17, 1.458s/it]
[2025-08-27 09:28:18,239][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00223/00310] [00:05:26/00:02:05, 1.458s/it]
[2025-08-27 09:28:30,099][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00231/00310] [00:05:38/00:01:53, 1.459s/it]
[2025-08-27 09:28:41,647][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00239/00310] [00:05:50/00:01:42, 1.458s/it]
[2025-08-27 09:28:52,821][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00247/00310] [00:06:01/00:01:30, 1.456s/it]
[2025-08-27 09:29:04,870][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00255/00310] [00:06:13/00:01:18, 1.458s/it]
[2025-08-27 09:29:17,014][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00263/00310] [00:06:25/00:01:07, 1.460s/it]
[2025-08-27 09:29:28,837][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00271/00310] [00:06:37/00:00:55, 1.460s/it]
[2025-08-27 09:29:40,709][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00279/00310] [00:06:49/00:00:43, 1.461s/it]
[2025-08-27 09:29:53,138][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00287/00310] [00:07:01/00:00:32, 1.464s/it]
[2025-08-27 09:30:04,831][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00295/00310] [00:07:13/00:00:20, 1.464s/it]
[2025-08-27 09:30:17,297][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 055441] [Batch 00303/00310] [00:07:25/00:00:08, 1.466s/it]
[2025-08-27 09:30:26,109][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=0.52739, valid_loss=1.50861
[2025-08-27 09:30:26,109][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-27 09:30:26,109][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.546
[2025-08-27 09:30:26,109][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.107
[2025-08-27 09:30:26,110][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.110
[2025-08-27 09:30:26,110][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.053
[2025-08-27 09:30:26,116][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 14:03:40, remaining time 09:22:26, 00:46:52 per epoch
[2025-08-27 09:30:31,599][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055448] [Batch 00008/03080] [00:00:05/00:33:54, 0.662s/it]: train_loss_raw=0.5032, running_loss=0.4882, LR=0.000100
[2025-08-27 09:30:37,615][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055456] [Batch 00016/03080] [00:00:11/00:36:06, 0.707s/it]: train_loss_raw=0.5664, running_loss=0.4906, LR=0.000100
[2025-08-27 09:30:43,611][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055464] [Batch 00024/03080] [00:00:17/00:36:44, 0.721s/it]: train_loss_raw=0.5118, running_loss=0.4921, LR=0.000100
[2025-08-27 09:30:49,617][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055472] [Batch 00032/03080] [00:00:23/00:37:00, 0.729s/it]: train_loss_raw=0.5493, running_loss=0.4905, LR=0.000100
[2025-08-27 09:30:55,643][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055480] [Batch 00040/03080] [00:00:29/00:37:10, 0.734s/it]: train_loss_raw=0.5061, running_loss=0.4916, LR=0.000100
[2025-08-27 09:31:01,612][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055488] [Batch 00048/03080] [00:00:35/00:37:10, 0.736s/it]: train_loss_raw=0.5392, running_loss=0.4910, LR=0.000100
[2025-08-27 09:31:07,572][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055496] [Batch 00056/03080] [00:00:41/00:37:08, 0.737s/it]: train_loss_raw=0.6174, running_loss=0.4936, LR=0.000100
[2025-08-27 09:31:13,603][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055504] [Batch 00064/03080] [00:00:47/00:37:09, 0.739s/it]: train_loss_raw=0.5047, running_loss=0.4937, LR=0.000100
[2025-08-27 09:31:19,602][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055512] [Batch 00072/03080] [00:00:53/00:37:06, 0.740s/it]: train_loss_raw=0.4497, running_loss=0.4951, LR=0.000100
[2025-08-27 09:31:25,625][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055520] [Batch 00080/03080] [00:00:59/00:37:04, 0.742s/it]: train_loss_raw=0.5090, running_loss=0.4955, LR=0.000100
[2025-08-27 09:31:31,672][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055528] [Batch 00088/03080] [00:01:05/00:37:02, 0.743s/it]: train_loss_raw=0.5809, running_loss=0.4961, LR=0.000100
[2025-08-27 09:31:37,762][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055536] [Batch 00096/03080] [00:01:11/00:37:01, 0.744s/it]: train_loss_raw=0.4605, running_loss=0.4977, LR=0.000100
[2025-08-27 09:31:43,783][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055544] [Batch 00104/03080] [00:01:17/00:36:57, 0.745s/it]: train_loss_raw=0.5960, running_loss=0.4994, LR=0.000100
[2025-08-27 09:31:49,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055552] [Batch 00112/03080] [00:01:23/00:36:55, 0.746s/it]: train_loss_raw=0.4554, running_loss=0.4991, LR=0.000100
[2025-08-27 09:31:55,877][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055560] [Batch 00120/03080] [00:01:29/00:36:49, 0.746s/it]: train_loss_raw=0.5561, running_loss=0.5010, LR=0.000100
[2025-08-27 09:32:01,576][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055568] [Batch 00128/03080] [00:01:35/00:36:37, 0.744s/it]: train_loss_raw=0.5145, running_loss=0.5017, LR=0.000100
[2025-08-27 09:32:07,194][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055576] [Batch 00136/03080] [00:01:40/00:36:24, 0.742s/it]: train_loss_raw=0.4877, running_loss=0.5012, LR=0.000100
[2025-08-27 09:32:13,336][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055584] [Batch 00144/03080] [00:01:47/00:36:22, 0.743s/it]: train_loss_raw=0.4634, running_loss=0.4981, LR=0.000100
[2025-08-27 09:32:19,514][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055592] [Batch 00152/03080] [00:01:53/00:36:20, 0.745s/it]: train_loss_raw=0.4172, running_loss=0.4974, LR=0.000100
[2025-08-27 09:32:25,508][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055600] [Batch 00160/03080] [00:01:59/00:36:15, 0.745s/it]: train_loss_raw=0.5275, running_loss=0.4993, LR=0.000100
[2025-08-27 09:32:31,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055608] [Batch 00168/03080] [00:02:05/00:36:10, 0.745s/it]: train_loss_raw=0.5796, running_loss=0.5015, LR=0.000100
[2025-08-27 09:32:37,509][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055616] [Batch 00176/03080] [00:02:11/00:36:04, 0.746s/it]: train_loss_raw=0.4809, running_loss=0.5010, LR=0.000100
[2025-08-27 09:32:43,579][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055624] [Batch 00184/03080] [00:02:17/00:36:00, 0.746s/it]: train_loss_raw=0.5362, running_loss=0.4997, LR=0.000100
[2025-08-27 09:32:49,611][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055632] [Batch 00192/03080] [00:02:23/00:35:55, 0.746s/it]: train_loss_raw=0.5445, running_loss=0.5007, LR=0.000100
[2025-08-27 09:32:55,721][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055640] [Batch 00200/03080] [00:02:29/00:35:51, 0.747s/it]: train_loss_raw=0.5593, running_loss=0.5015, LR=0.000100
[2025-08-27 09:33:01,771][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055648] [Batch 00208/03080] [00:02:35/00:35:46, 0.747s/it]: train_loss_raw=0.4151, running_loss=0.4993, LR=0.000100
[2025-08-27 09:33:07,808][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055656] [Batch 00216/03080] [00:02:41/00:35:41, 0.748s/it]: train_loss_raw=0.6198, running_loss=0.5009, LR=0.000100
[2025-08-27 09:33:13,825][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055664] [Batch 00224/03080] [00:02:47/00:35:35, 0.748s/it]: train_loss_raw=0.4788, running_loss=0.5021, LR=0.000100
[2025-08-27 09:33:19,944][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055672] [Batch 00232/03080] [00:02:53/00:35:31, 0.748s/it]: train_loss_raw=0.4687, running_loss=0.4990, LR=0.000100
[2025-08-27 09:33:25,966][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055680] [Batch 00240/03080] [00:02:59/00:35:26, 0.749s/it]: train_loss_raw=0.5205, running_loss=0.5015, LR=0.000100
[2025-08-27 09:33:32,081][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055688] [Batch 00248/03080] [00:03:05/00:35:21, 0.749s/it]: train_loss_raw=0.5798, running_loss=0.5012, LR=0.000100
[2025-08-27 09:33:38,164][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055696] [Batch 00256/03080] [00:03:11/00:35:16, 0.749s/it]: train_loss_raw=0.4608, running_loss=0.5010, LR=0.000100
[2025-08-27 09:33:44,147][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055704] [Batch 00264/03080] [00:03:17/00:35:10, 0.749s/it]: train_loss_raw=0.4841, running_loss=0.5006, LR=0.000100
[2025-08-27 09:33:50,150][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055712] [Batch 00272/03080] [00:03:23/00:35:04, 0.749s/it]: train_loss_raw=0.4164, running_loss=0.5028, LR=0.000100
[2025-08-27 09:33:56,201][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055720] [Batch 00280/03080] [00:03:29/00:34:59, 0.750s/it]: train_loss_raw=0.4572, running_loss=0.5029, LR=0.000100
[2025-08-27 09:34:02,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055728] [Batch 00288/03080] [00:03:36/00:34:54, 0.750s/it]: train_loss_raw=0.4775, running_loss=0.5016, LR=0.000100
[2025-08-27 09:34:08,433][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055736] [Batch 00296/03080] [00:03:42/00:34:49, 0.750s/it]: train_loss_raw=0.5125, running_loss=0.5036, LR=0.000100
[2025-08-27 09:34:14,458][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055744] [Batch 00304/03080] [00:03:48/00:34:43, 0.751s/it]: train_loss_raw=0.4555, running_loss=0.5035, LR=0.000100
[2025-08-27 09:34:20,467][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055752] [Batch 00312/03080] [00:03:54/00:34:37, 0.751s/it]: train_loss_raw=0.5592, running_loss=0.5024, LR=0.000100
[2025-08-27 09:34:26,437][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055760] [Batch 00320/03080] [00:04:00/00:34:31, 0.750s/it]: train_loss_raw=0.4554, running_loss=0.5028, LR=0.000100
[2025-08-27 09:34:32,431][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055768] [Batch 00328/03080] [00:04:06/00:34:25, 0.750s/it]: train_loss_raw=0.4939, running_loss=0.5042, LR=0.000100
[2025-08-27 09:34:38,577][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055776] [Batch 00336/03080] [00:04:12/00:34:20, 0.751s/it]: train_loss_raw=0.5022, running_loss=0.5041, LR=0.000100
[2025-08-27 09:34:44,584][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055784] [Batch 00344/03080] [00:04:18/00:34:14, 0.751s/it]: train_loss_raw=0.3794, running_loss=0.5027, LR=0.000100
[2025-08-27 09:34:50,662][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055792] [Batch 00352/03080] [00:04:24/00:34:08, 0.751s/it]: train_loss_raw=0.5335, running_loss=0.5018, LR=0.000100
[2025-08-27 09:34:56,652][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055800] [Batch 00360/03080] [00:04:30/00:34:02, 0.751s/it]: train_loss_raw=0.3839, running_loss=0.4991, LR=0.000100
[2025-08-27 09:35:02,646][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055808] [Batch 00368/03080] [00:04:36/00:33:56, 0.751s/it]: train_loss_raw=0.5467, running_loss=0.5022, LR=0.000100
[2025-08-27 09:35:08,444][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055816] [Batch 00376/03080] [00:04:42/00:33:49, 0.750s/it]: train_loss_raw=0.5816, running_loss=0.5003, LR=0.000100
[2025-08-27 09:35:14,438][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055824] [Batch 00384/03080] [00:04:48/00:33:42, 0.750s/it]: train_loss_raw=0.4862, running_loss=0.4997, LR=0.000100
[2025-08-27 09:35:20,401][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055832] [Batch 00392/03080] [00:04:54/00:33:36, 0.750s/it]: train_loss_raw=0.5297, running_loss=0.5001, LR=0.000100
[2025-08-27 09:35:26,276][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055840] [Batch 00400/03080] [00:04:59/00:33:29, 0.750s/it]: train_loss_raw=0.4859, running_loss=0.5001, LR=0.000100
[2025-08-27 09:35:32,385][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055848] [Batch 00408/03080] [00:05:06/00:33:24, 0.750s/it]: train_loss_raw=0.4493, running_loss=0.4993, LR=0.000100
[2025-08-27 09:35:38,357][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055856] [Batch 00416/03080] [00:05:12/00:33:18, 0.750s/it]: train_loss_raw=0.5399, running_loss=0.5001, LR=0.000100
[2025-08-27 09:35:44,395][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055864] [Batch 00424/03080] [00:05:18/00:33:12, 0.750s/it]: train_loss_raw=0.5043, running_loss=0.5023, LR=0.000100
[2025-08-27 09:35:50,346][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055872] [Batch 00432/03080] [00:05:24/00:33:06, 0.750s/it]: train_loss_raw=0.5023, running_loss=0.5026, LR=0.000100
[2025-08-27 09:35:56,294][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055880] [Batch 00440/03080] [00:05:29/00:32:59, 0.750s/it]: train_loss_raw=0.4911, running_loss=0.5043, LR=0.000100
[2025-08-27 09:36:02,286][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055888] [Batch 00448/03080] [00:05:35/00:32:53, 0.750s/it]: train_loss_raw=0.4395, running_loss=0.5029, LR=0.000100
[2025-08-27 09:36:08,275][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055896] [Batch 00456/03080] [00:05:41/00:32:47, 0.750s/it]: train_loss_raw=0.4956, running_loss=0.5052, LR=0.000100
[2025-08-27 09:36:14,265][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055904] [Batch 00464/03080] [00:05:47/00:32:41, 0.750s/it]: train_loss_raw=0.5131, running_loss=0.5024, LR=0.000100
[2025-08-27 09:36:20,284][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055912] [Batch 00472/03080] [00:05:53/00:32:35, 0.750s/it]: train_loss_raw=0.5132, running_loss=0.5032, LR=0.000100
[2025-08-27 09:36:26,323][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055920] [Batch 00480/03080] [00:06:00/00:32:30, 0.750s/it]: train_loss_raw=0.5064, running_loss=0.5024, LR=0.000100
[2025-08-27 09:36:32,370][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055928] [Batch 00488/03080] [00:06:06/00:32:24, 0.750s/it]: train_loss_raw=0.5715, running_loss=0.5002, LR=0.000100
[2025-08-27 09:36:38,320][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055936] [Batch 00496/03080] [00:06:12/00:32:18, 0.750s/it]: train_loss_raw=0.5370, running_loss=0.5005, LR=0.000100
[2025-08-27 09:36:44,437][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055944] [Batch 00504/03080] [00:06:18/00:32:12, 0.750s/it]: train_loss_raw=0.5269, running_loss=0.5019, LR=0.000100
[2025-08-27 09:36:50,578][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055952] [Batch 00512/03080] [00:06:24/00:32:07, 0.751s/it]: train_loss_raw=0.5091, running_loss=0.5017, LR=0.000100
[2025-08-27 09:36:56,579][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055960] [Batch 00520/03080] [00:06:30/00:32:01, 0.751s/it]: train_loss_raw=0.5045, running_loss=0.5025, LR=0.000100
[2025-08-27 09:37:02,831][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055968] [Batch 00528/03080] [00:06:36/00:31:56, 0.751s/it]: train_loss_raw=0.5056, running_loss=0.5039, LR=0.000100
[2025-08-27 09:37:08,830][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055976] [Batch 00536/03080] [00:06:42/00:31:50, 0.751s/it]: train_loss_raw=0.5509, running_loss=0.5033, LR=0.000100
[2025-08-27 09:37:14,917][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055984] [Batch 00544/03080] [00:06:48/00:31:44, 0.751s/it]: train_loss_raw=0.5439, running_loss=0.5044, LR=0.000100
[2025-08-27 09:37:20,996][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 055992] [Batch 00552/03080] [00:06:54/00:31:39, 0.751s/it]: train_loss_raw=0.4554, running_loss=0.5050, LR=0.000100
[2025-08-27 09:37:27,002][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056000] [Batch 00560/03080] [00:07:00/00:31:33, 0.751s/it]: train_loss_raw=0.5988, running_loss=0.5086, LR=0.000100
[2025-08-27 09:37:36,239][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056008] [Batch 00568/03080] [00:07:09/00:31:41, 0.757s/it]: train_loss_raw=0.5828, running_loss=0.5095, LR=0.000100
[2025-08-27 09:37:41,717][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056016] [Batch 00576/03080] [00:07:15/00:31:32, 0.756s/it]: train_loss_raw=0.5710, running_loss=0.5088, LR=0.000100
[2025-08-27 09:37:47,757][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056024] [Batch 00584/03080] [00:07:21/00:31:26, 0.756s/it]: train_loss_raw=0.5350, running_loss=0.5093, LR=0.000100
[2025-08-27 09:37:53,739][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056032] [Batch 00592/03080] [00:07:27/00:31:20, 0.756s/it]: train_loss_raw=0.4417, running_loss=0.5079, LR=0.000100
[2025-08-27 09:37:59,883][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056040] [Batch 00600/03080] [00:07:33/00:31:14, 0.756s/it]: train_loss_raw=0.6129, running_loss=0.5070, LR=0.000100
[2025-08-27 09:38:06,020][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056048] [Batch 00608/03080] [00:07:39/00:31:09, 0.756s/it]: train_loss_raw=0.4723, running_loss=0.5061, LR=0.000100
[2025-08-27 09:38:12,194][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056056] [Batch 00616/03080] [00:07:45/00:31:03, 0.756s/it]: train_loss_raw=0.5436, running_loss=0.5065, LR=0.000100
[2025-08-27 09:38:18,374][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056064] [Batch 00624/03080] [00:07:52/00:30:58, 0.757s/it]: train_loss_raw=0.4807, running_loss=0.5061, LR=0.000100
[2025-08-27 09:38:24,383][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056072] [Batch 00632/03080] [00:07:58/00:30:51, 0.756s/it]: train_loss_raw=0.5808, running_loss=0.5080, LR=0.000100
[2025-08-27 09:38:30,371][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056080] [Batch 00640/03080] [00:08:04/00:30:45, 0.756s/it]: train_loss_raw=0.4838, running_loss=0.5076, LR=0.000100
[2025-08-27 09:38:36,447][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056088] [Batch 00648/03080] [00:08:10/00:30:39, 0.756s/it]: train_loss_raw=0.4227, running_loss=0.5044, LR=0.000100
[2025-08-27 09:38:42,466][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056096] [Batch 00656/03080] [00:08:16/00:30:33, 0.756s/it]: train_loss_raw=0.4918, running_loss=0.5038, LR=0.000100
[2025-08-27 09:38:48,467][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056104] [Batch 00664/03080] [00:08:22/00:30:27, 0.756s/it]: train_loss_raw=0.4621, running_loss=0.5044, LR=0.000100
[2025-08-27 09:38:54,562][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056112] [Batch 00672/03080] [00:08:28/00:30:21, 0.756s/it]: train_loss_raw=0.5519, running_loss=0.5053, LR=0.000100
[2025-08-27 09:39:00,530][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056120] [Batch 00680/03080] [00:08:34/00:30:14, 0.756s/it]: train_loss_raw=0.5417, running_loss=0.5056, LR=0.000100
[2025-08-27 09:39:06,205][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056128] [Batch 00688/03080] [00:08:39/00:30:07, 0.756s/it]: train_loss_raw=0.5478, running_loss=0.5058, LR=0.000100
[2025-08-27 09:39:11,870][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056136] [Batch 00696/03080] [00:08:45/00:30:00, 0.755s/it]: train_loss_raw=0.4394, running_loss=0.5041, LR=0.000100
[2025-08-27 09:39:17,826][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056144] [Batch 00704/03080] [00:08:51/00:29:53, 0.755s/it]: train_loss_raw=0.5360, running_loss=0.5038, LR=0.000100
[2025-08-27 09:39:23,734][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056152] [Batch 00712/03080] [00:08:57/00:29:47, 0.755s/it]: train_loss_raw=0.4765, running_loss=0.5026, LR=0.000100
[2025-08-27 09:39:29,619][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056160] [Batch 00720/03080] [00:09:03/00:29:40, 0.755s/it]: train_loss_raw=0.5623, running_loss=0.5022, LR=0.000100
[2025-08-27 09:39:35,183][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056168] [Batch 00728/03080] [00:09:08/00:29:33, 0.754s/it]: train_loss_raw=0.4471, running_loss=0.4989, LR=0.000100
[2025-08-27 09:39:40,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056176] [Batch 00736/03080] [00:09:14/00:29:26, 0.754s/it]: train_loss_raw=0.5191, running_loss=0.4971, LR=0.000100
[2025-08-27 09:39:46,680][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056184] [Batch 00744/03080] [00:09:20/00:29:19, 0.753s/it]: train_loss_raw=0.4567, running_loss=0.4961, LR=0.000100
[2025-08-27 09:39:52,680][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056192] [Batch 00752/03080] [00:09:26/00:29:13, 0.753s/it]: train_loss_raw=0.4469, running_loss=0.4980, LR=0.000100
[2025-08-27 09:39:58,782][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056200] [Batch 00760/03080] [00:09:32/00:29:07, 0.753s/it]: train_loss_raw=0.5177, running_loss=0.5003, LR=0.000100
[2025-08-27 09:40:04,890][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056208] [Batch 00768/03080] [00:09:38/00:29:01, 0.753s/it]: train_loss_raw=0.4327, running_loss=0.5021, LR=0.000100
[2025-08-27 09:40:10,982][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056216] [Batch 00776/03080] [00:09:44/00:28:55, 0.753s/it]: train_loss_raw=0.5081, running_loss=0.5027, LR=0.000100
[2025-08-27 09:40:17,070][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056224] [Batch 00784/03080] [00:09:50/00:28:50, 0.754s/it]: train_loss_raw=0.4496, running_loss=0.5028, LR=0.000100
[2025-08-27 09:40:22,539][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056232] [Batch 00792/03080] [00:09:56/00:28:42, 0.753s/it]: train_loss_raw=0.4125, running_loss=0.5019, LR=0.000100
[2025-08-27 09:40:28,607][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056240] [Batch 00800/03080] [00:10:02/00:28:36, 0.753s/it]: train_loss_raw=0.4165, running_loss=0.5014, LR=0.000100
[2025-08-27 09:40:34,682][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056248] [Batch 00808/03080] [00:10:08/00:28:30, 0.753s/it]: train_loss_raw=0.5370, running_loss=0.5015, LR=0.000100
[2025-08-27 09:40:40,800][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056256] [Batch 00816/03080] [00:10:14/00:28:24, 0.753s/it]: train_loss_raw=0.6307, running_loss=0.5016, LR=0.000100
[2025-08-27 09:40:46,790][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056264] [Batch 00824/03080] [00:10:20/00:28:18, 0.753s/it]: train_loss_raw=0.5427, running_loss=0.5025, LR=0.000100
[2025-08-27 09:40:52,828][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056272] [Batch 00832/03080] [00:10:26/00:28:12, 0.753s/it]: train_loss_raw=0.4614, running_loss=0.5025, LR=0.000100
[2025-08-27 09:40:58,917][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056280] [Batch 00840/03080] [00:10:32/00:28:06, 0.753s/it]: train_loss_raw=0.4868, running_loss=0.5033, LR=0.000100
[2025-08-27 09:41:05,004][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056288] [Batch 00848/03080] [00:10:38/00:28:01, 0.753s/it]: train_loss_raw=0.5257, running_loss=0.5025, LR=0.000100
[2025-08-27 09:41:11,045][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056296] [Batch 00856/03080] [00:10:44/00:27:55, 0.753s/it]: train_loss_raw=0.4987, running_loss=0.5034, LR=0.000100
[2025-08-27 09:41:17,097][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056304] [Batch 00864/03080] [00:10:50/00:27:49, 0.753s/it]: train_loss_raw=0.4687, running_loss=0.5036, LR=0.000100
[2025-08-27 09:41:23,112][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056312] [Batch 00872/03080] [00:10:56/00:27:43, 0.753s/it]: train_loss_raw=0.4481, running_loss=0.5022, LR=0.000100
[2025-08-27 09:41:29,208][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056320] [Batch 00880/03080] [00:11:02/00:27:37, 0.753s/it]: train_loss_raw=0.5217, running_loss=0.5035, LR=0.000100
[2025-08-27 09:41:35,269][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056328] [Batch 00888/03080] [00:11:08/00:27:31, 0.753s/it]: train_loss_raw=0.4538, running_loss=0.5044, LR=0.000100
[2025-08-27 09:41:41,286][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056336] [Batch 00896/03080] [00:11:14/00:27:25, 0.753s/it]: train_loss_raw=0.4159, running_loss=0.5027, LR=0.000100
[2025-08-27 09:41:47,233][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056344] [Batch 00904/03080] [00:11:20/00:27:19, 0.753s/it]: train_loss_raw=0.6134, running_loss=0.5026, LR=0.000100
[2025-08-27 09:41:53,220][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056352] [Batch 00912/03080] [00:11:26/00:27:12, 0.753s/it]: train_loss_raw=0.4484, running_loss=0.5041, LR=0.000100
[2025-08-27 09:41:59,267][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056360] [Batch 00920/03080] [00:11:32/00:27:06, 0.753s/it]: train_loss_raw=0.5191, running_loss=0.5024, LR=0.000100
[2025-08-27 09:42:05,296][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056368] [Batch 00928/03080] [00:11:38/00:27:00, 0.753s/it]: train_loss_raw=0.4801, running_loss=0.5027, LR=0.000100
[2025-08-27 09:42:11,530][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056376] [Batch 00936/03080] [00:11:45/00:26:55, 0.753s/it]: train_loss_raw=0.5442, running_loss=0.5020, LR=0.000100
[2025-08-27 09:42:17,575][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056384] [Batch 00944/03080] [00:11:51/00:26:49, 0.753s/it]: train_loss_raw=0.4289, running_loss=0.5043, LR=0.000100
[2025-08-27 09:42:23,644][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056392] [Batch 00952/03080] [00:11:57/00:26:43, 0.754s/it]: train_loss_raw=0.5443, running_loss=0.5026, LR=0.000100
[2025-08-27 09:42:29,764][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056400] [Batch 00960/03080] [00:12:03/00:26:37, 0.754s/it]: train_loss_raw=0.5061, running_loss=0.5027, LR=0.000100
[2025-08-27 09:42:35,897][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056408] [Batch 00968/03080] [00:12:09/00:26:31, 0.754s/it]: train_loss_raw=0.5051, running_loss=0.5010, LR=0.000100
[2025-08-27 09:42:42,266][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056416] [Batch 00976/03080] [00:12:15/00:26:26, 0.754s/it]: train_loss_raw=0.5357, running_loss=0.5016, LR=0.000100
[2025-08-27 09:42:48,247][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056424] [Batch 00984/03080] [00:12:21/00:26:20, 0.754s/it]: train_loss_raw=0.4926, running_loss=0.5038, LR=0.000100
[2025-08-27 09:42:54,149][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056432] [Batch 00992/03080] [00:12:27/00:26:14, 0.754s/it]: train_loss_raw=0.5763, running_loss=0.5066, LR=0.000100
[2025-08-27 09:43:00,172][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056440] [Batch 01000/03080] [00:12:33/00:26:08, 0.754s/it]: train_loss_raw=0.4606, running_loss=0.5063, LR=0.000100
[2025-08-27 09:43:06,327][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056448] [Batch 01008/03080] [00:12:40/00:26:02, 0.754s/it]: train_loss_raw=0.5394, running_loss=0.5057, LR=0.000100
[2025-08-27 09:43:12,182][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056456] [Batch 01016/03080] [00:12:45/00:25:55, 0.754s/it]: train_loss_raw=0.4825, running_loss=0.5055, LR=0.000100
[2025-08-27 09:43:18,313][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056464] [Batch 01024/03080] [00:12:52/00:25:50, 0.754s/it]: train_loss_raw=0.5254, running_loss=0.5072, LR=0.000100
[2025-08-27 09:43:24,417][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056472] [Batch 01032/03080] [00:12:58/00:25:44, 0.754s/it]: train_loss_raw=0.5097, running_loss=0.5075, LR=0.000100
[2025-08-27 09:43:30,440][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056480] [Batch 01040/03080] [00:13:04/00:25:38, 0.754s/it]: train_loss_raw=0.5490, running_loss=0.5083, LR=0.000100
[2025-08-27 09:43:36,432][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056488] [Batch 01048/03080] [00:13:10/00:25:32, 0.754s/it]: train_loss_raw=0.5300, running_loss=0.5073, LR=0.000100
[2025-08-27 09:43:42,450][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056496] [Batch 01056/03080] [00:13:16/00:25:25, 0.754s/it]: train_loss_raw=0.5418, running_loss=0.5038, LR=0.000100
[2025-08-27 09:43:48,544][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056504] [Batch 01064/03080] [00:13:22/00:25:20, 0.754s/it]: train_loss_raw=0.4376, running_loss=0.5056, LR=0.000100
[2025-08-27 09:43:54,674][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056512] [Batch 01072/03080] [00:13:28/00:25:14, 0.754s/it]: train_loss_raw=0.5378, running_loss=0.5053, LR=0.000100
[2025-08-27 09:44:00,655][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056520] [Batch 01080/03080] [00:13:34/00:25:08, 0.754s/it]: train_loss_raw=0.4798, running_loss=0.5050, LR=0.000100
[2025-08-27 09:44:06,766][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056528] [Batch 01088/03080] [00:13:40/00:25:02, 0.754s/it]: train_loss_raw=0.5113, running_loss=0.5060, LR=0.000100
[2025-08-27 09:44:12,845][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056536] [Batch 01096/03080] [00:13:46/00:24:56, 0.754s/it]: train_loss_raw=0.4412, running_loss=0.5042, LR=0.000100
[2025-08-27 09:44:18,851][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056544] [Batch 01104/03080] [00:13:52/00:24:50, 0.754s/it]: train_loss_raw=0.5774, running_loss=0.5056, LR=0.000100
[2025-08-27 09:44:24,882][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056552] [Batch 01112/03080] [00:13:58/00:24:44, 0.754s/it]: train_loss_raw=0.5738, running_loss=0.5048, LR=0.000100
[2025-08-27 09:44:30,949][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056560] [Batch 01120/03080] [00:14:04/00:24:38, 0.754s/it]: train_loss_raw=0.4382, running_loss=0.5035, LR=0.000100
[2025-08-27 09:44:37,045][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056568] [Batch 01128/03080] [00:14:10/00:24:32, 0.754s/it]: train_loss_raw=0.5863, running_loss=0.5049, LR=0.000100
[2025-08-27 09:44:43,046][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056576] [Batch 01136/03080] [00:14:16/00:24:26, 0.754s/it]: train_loss_raw=0.5552, running_loss=0.5045, LR=0.000100
[2025-08-27 09:44:49,074][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056584] [Batch 01144/03080] [00:14:22/00:24:20, 0.754s/it]: train_loss_raw=0.5152, running_loss=0.5035, LR=0.000100
[2025-08-27 09:44:55,144][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056592] [Batch 01152/03080] [00:14:28/00:24:14, 0.754s/it]: train_loss_raw=0.4781, running_loss=0.5040, LR=0.000100
[2025-08-27 09:45:01,151][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056600] [Batch 01160/03080] [00:14:34/00:24:08, 0.754s/it]: train_loss_raw=0.5848, running_loss=0.5034, LR=0.000100
[2025-08-27 09:45:07,213][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056608] [Batch 01168/03080] [00:14:40/00:24:02, 0.754s/it]: train_loss_raw=0.4813, running_loss=0.5019, LR=0.000100
[2025-08-27 09:45:13,263][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056616] [Batch 01176/03080] [00:14:46/00:23:56, 0.754s/it]: train_loss_raw=0.4898, running_loss=0.5009, LR=0.000100
[2025-08-27 09:45:19,322][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056624] [Batch 01184/03080] [00:14:53/00:23:50, 0.754s/it]: train_loss_raw=0.5567, running_loss=0.5025, LR=0.000100
[2025-08-27 09:45:25,354][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056632] [Batch 01192/03080] [00:14:59/00:23:44, 0.754s/it]: train_loss_raw=0.6041, running_loss=0.5028, LR=0.000100
[2025-08-27 09:45:31,408][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056640] [Batch 01200/03080] [00:15:05/00:23:38, 0.754s/it]: train_loss_raw=0.4673, running_loss=0.5036, LR=0.000100
[2025-08-27 09:45:37,455][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056648] [Batch 01208/03080] [00:15:11/00:23:31, 0.754s/it]: train_loss_raw=0.5267, running_loss=0.5060, LR=0.000100
[2025-08-27 09:45:43,459][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056656] [Batch 01216/03080] [00:15:17/00:23:25, 0.754s/it]: train_loss_raw=0.5904, running_loss=0.5073, LR=0.000100
[2025-08-27 09:45:49,541][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056664] [Batch 01224/03080] [00:15:23/00:23:19, 0.754s/it]: train_loss_raw=0.4663, running_loss=0.5062, LR=0.000100
[2025-08-27 09:45:55,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056672] [Batch 01232/03080] [00:15:29/00:23:13, 0.754s/it]: train_loss_raw=0.3906, running_loss=0.5056, LR=0.000100
[2025-08-27 09:46:01,605][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056680] [Batch 01240/03080] [00:15:35/00:23:07, 0.754s/it]: train_loss_raw=0.4408, running_loss=0.5024, LR=0.000100
[2025-08-27 09:46:07,554][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056688] [Batch 01248/03080] [00:15:41/00:23:01, 0.754s/it]: train_loss_raw=0.5421, running_loss=0.5047, LR=0.000100
[2025-08-27 09:46:13,540][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056696] [Batch 01256/03080] [00:15:47/00:22:55, 0.754s/it]: train_loss_raw=0.5476, running_loss=0.5050, LR=0.000100
[2025-08-27 09:46:19,585][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056704] [Batch 01264/03080] [00:15:53/00:22:49, 0.754s/it]: train_loss_raw=0.4669, running_loss=0.5062, LR=0.000100
[2025-08-27 09:46:25,840][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056712] [Batch 01272/03080] [00:15:59/00:22:43, 0.754s/it]: train_loss_raw=0.4778, running_loss=0.5055, LR=0.000100
[2025-08-27 09:46:32,094][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056720] [Batch 01280/03080] [00:16:05/00:22:38, 0.755s/it]: train_loss_raw=0.5588, running_loss=0.5047, LR=0.000100
[2025-08-27 09:46:38,235][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056728] [Batch 01288/03080] [00:16:11/00:22:32, 0.755s/it]: train_loss_raw=0.4603, running_loss=0.5047, LR=0.000100
[2025-08-27 09:46:44,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056736] [Batch 01296/03080] [00:16:18/00:22:26, 0.755s/it]: train_loss_raw=0.4698, running_loss=0.5053, LR=0.000100
[2025-08-27 09:46:50,398][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056744] [Batch 01304/03080] [00:16:24/00:22:20, 0.755s/it]: train_loss_raw=0.5181, running_loss=0.5040, LR=0.000100
[2025-08-27 09:46:56,472][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056752] [Batch 01312/03080] [00:16:30/00:22:14, 0.755s/it]: train_loss_raw=0.5057, running_loss=0.5052, LR=0.000100
[2025-08-27 09:47:02,525][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056760] [Batch 01320/03080] [00:16:36/00:22:08, 0.755s/it]: train_loss_raw=0.4996, running_loss=0.5046, LR=0.000100
[2025-08-27 09:47:08,681][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056768] [Batch 01328/03080] [00:16:42/00:22:02, 0.755s/it]: train_loss_raw=0.6059, running_loss=0.5051, LR=0.000100
[2025-08-27 09:47:14,724][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056776] [Batch 01336/03080] [00:16:48/00:21:56, 0.755s/it]: train_loss_raw=0.5466, running_loss=0.5079, LR=0.000100
[2025-08-27 09:47:20,741][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056784] [Batch 01344/03080] [00:16:54/00:21:50, 0.755s/it]: train_loss_raw=0.5264, running_loss=0.5050, LR=0.000100
[2025-08-27 09:47:26,851][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056792] [Batch 01352/03080] [00:17:00/00:21:44, 0.755s/it]: train_loss_raw=0.6162, running_loss=0.5064, LR=0.000100
[2025-08-27 09:47:32,844][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056800] [Batch 01360/03080] [00:17:06/00:21:38, 0.755s/it]: train_loss_raw=0.4791, running_loss=0.5030, LR=0.000100
[2025-08-27 09:47:38,992][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056808] [Batch 01368/03080] [00:17:12/00:21:32, 0.755s/it]: train_loss_raw=0.3954, running_loss=0.5014, LR=0.000100
[2025-08-27 09:47:45,055][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056816] [Batch 01376/03080] [00:17:18/00:21:26, 0.755s/it]: train_loss_raw=0.4224, running_loss=0.4983, LR=0.000100
[2025-08-27 09:47:51,116][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056824] [Batch 01384/03080] [00:17:24/00:21:20, 0.755s/it]: train_loss_raw=0.5369, running_loss=0.4995, LR=0.000100
[2025-08-27 09:47:57,095][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056832] [Batch 01392/03080] [00:17:30/00:21:14, 0.755s/it]: train_loss_raw=0.6021, running_loss=0.5013, LR=0.000100
[2025-08-27 09:48:03,129][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056840] [Batch 01400/03080] [00:17:36/00:21:08, 0.755s/it]: train_loss_raw=0.4760, running_loss=0.4992, LR=0.000100
[2025-08-27 09:48:09,127][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056848] [Batch 01408/03080] [00:17:42/00:21:02, 0.755s/it]: train_loss_raw=0.5022, running_loss=0.4991, LR=0.000100
[2025-08-27 09:48:15,177][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056856] [Batch 01416/03080] [00:17:48/00:20:56, 0.755s/it]: train_loss_raw=0.4590, running_loss=0.4988, LR=0.000100
[2025-08-27 09:48:21,246][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056864] [Batch 01424/03080] [00:17:54/00:20:50, 0.755s/it]: train_loss_raw=0.5550, running_loss=0.4990, LR=0.000100
[2025-08-27 09:48:27,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056872] [Batch 01432/03080] [00:18:01/00:20:44, 0.755s/it]: train_loss_raw=0.5016, running_loss=0.4976, LR=0.000100
[2025-08-27 09:48:33,473][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056880] [Batch 01440/03080] [00:18:07/00:20:38, 0.755s/it]: train_loss_raw=0.5214, running_loss=0.4960, LR=0.000100
[2025-08-27 09:48:39,015][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056888] [Batch 01448/03080] [00:18:12/00:20:31, 0.755s/it]: train_loss_raw=0.6181, running_loss=0.4962, LR=0.000100
[2025-08-27 09:48:44,580][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056896] [Batch 01456/03080] [00:18:18/00:20:25, 0.754s/it]: train_loss_raw=0.4651, running_loss=0.4952, LR=0.000100
[2025-08-27 09:48:50,279][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056904] [Batch 01464/03080] [00:18:23/00:20:18, 0.754s/it]: train_loss_raw=0.4135, running_loss=0.4944, LR=0.000100
[2025-08-27 09:48:55,920][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056912] [Batch 01472/03080] [00:18:29/00:20:12, 0.754s/it]: train_loss_raw=0.4963, running_loss=0.4944, LR=0.000100
[2025-08-27 09:49:01,789][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056920] [Batch 01480/03080] [00:18:35/00:20:05, 0.754s/it]: train_loss_raw=0.6444, running_loss=0.4968, LR=0.000100
[2025-08-27 09:49:07,606][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056928] [Batch 01488/03080] [00:18:41/00:19:59, 0.754s/it]: train_loss_raw=0.4671, running_loss=0.4955, LR=0.000100
[2025-08-27 09:49:13,399][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056936] [Batch 01496/03080] [00:18:47/00:19:53, 0.753s/it]: train_loss_raw=0.5366, running_loss=0.4949, LR=0.000100
[2025-08-27 09:49:18,926][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056944] [Batch 01504/03080] [00:18:52/00:19:46, 0.753s/it]: train_loss_raw=0.4509, running_loss=0.4979, LR=0.000100
[2025-08-27 09:49:24,598][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056952] [Batch 01512/03080] [00:18:58/00:19:40, 0.753s/it]: train_loss_raw=0.6453, running_loss=0.5007, LR=0.000100
[2025-08-27 09:49:30,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056960] [Batch 01520/03080] [00:19:04/00:19:34, 0.753s/it]: train_loss_raw=0.5016, running_loss=0.5017, LR=0.000100
[2025-08-27 09:49:35,787][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056968] [Batch 01528/03080] [00:19:09/00:19:27, 0.752s/it]: train_loss_raw=0.5093, running_loss=0.5028, LR=0.000100
[2025-08-27 09:49:41,433][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056976] [Batch 01536/03080] [00:19:15/00:19:21, 0.752s/it]: train_loss_raw=0.4883, running_loss=0.5028, LR=0.000100
[2025-08-27 09:49:47,314][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056984] [Batch 01544/03080] [00:19:21/00:19:14, 0.752s/it]: train_loss_raw=0.4772, running_loss=0.5022, LR=0.000100
[2025-08-27 09:49:53,201][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 056992] [Batch 01552/03080] [00:19:26/00:19:08, 0.752s/it]: train_loss_raw=0.5449, running_loss=0.5026, LR=0.000100
[2025-08-27 09:49:58,949][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057000] [Batch 01560/03080] [00:19:32/00:19:02, 0.752s/it]: train_loss_raw=0.4469, running_loss=0.5003, LR=0.000100
[2025-08-27 09:50:04,931][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057008] [Batch 01568/03080] [00:19:38/00:18:56, 0.752s/it]: train_loss_raw=0.4431, running_loss=0.5004, LR=0.000100
[2025-08-27 09:50:10,828][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057016] [Batch 01576/03080] [00:19:44/00:18:50, 0.752s/it]: train_loss_raw=0.5185, running_loss=0.5006, LR=0.000100
[2025-08-27 09:50:16,933][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057024] [Batch 01584/03080] [00:19:50/00:18:44, 0.752s/it]: train_loss_raw=0.4767, running_loss=0.5000, LR=0.000100
[2025-08-27 09:50:23,037][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057032] [Batch 01592/03080] [00:19:56/00:18:38, 0.752s/it]: train_loss_raw=0.4248, running_loss=0.4997, LR=0.000100
[2025-08-27 09:50:29,111][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057040] [Batch 01600/03080] [00:20:02/00:18:32, 0.752s/it]: train_loss_raw=0.4533, running_loss=0.4988, LR=0.000100
[2025-08-27 09:50:35,206][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057048] [Batch 01608/03080] [00:20:08/00:18:26, 0.752s/it]: train_loss_raw=0.4558, running_loss=0.5010, LR=0.000100
[2025-08-27 09:50:41,261][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057056] [Batch 01616/03080] [00:20:14/00:18:20, 0.752s/it]: train_loss_raw=0.5324, running_loss=0.5008, LR=0.000100
[2025-08-27 09:50:47,371][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057064] [Batch 01624/03080] [00:20:21/00:18:14, 0.752s/it]: train_loss_raw=0.5848, running_loss=0.4995, LR=0.000100
[2025-08-27 09:50:53,383][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057072] [Batch 01632/03080] [00:20:27/00:18:08, 0.752s/it]: train_loss_raw=0.5584, running_loss=0.5014, LR=0.000100
[2025-08-27 09:50:59,425][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057080] [Batch 01640/03080] [00:20:33/00:18:02, 0.752s/it]: train_loss_raw=0.4428, running_loss=0.4998, LR=0.000100
[2025-08-27 09:51:05,449][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057088] [Batch 01648/03080] [00:20:39/00:17:56, 0.752s/it]: train_loss_raw=0.4535, running_loss=0.4994, LR=0.000100
[2025-08-27 09:51:11,419][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057096] [Batch 01656/03080] [00:20:45/00:17:50, 0.752s/it]: train_loss_raw=0.4539, running_loss=0.4977, LR=0.000100
[2025-08-27 09:51:17,521][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057104] [Batch 01664/03080] [00:20:51/00:17:44, 0.752s/it]: train_loss_raw=0.4417, running_loss=0.4974, LR=0.000100
[2025-08-27 09:51:23,552][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057112] [Batch 01672/03080] [00:20:57/00:17:38, 0.752s/it]: train_loss_raw=0.5391, running_loss=0.4984, LR=0.000100
[2025-08-27 09:51:29,678][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057120] [Batch 01680/03080] [00:21:03/00:17:32, 0.752s/it]: train_loss_raw=0.5077, running_loss=0.4974, LR=0.000100
[2025-08-27 09:51:35,825][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057128] [Batch 01688/03080] [00:21:09/00:17:26, 0.752s/it]: train_loss_raw=0.4540, running_loss=0.4960, LR=0.000100
[2025-08-27 09:51:42,002][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057136] [Batch 01696/03080] [00:21:15/00:17:21, 0.752s/it]: train_loss_raw=0.5075, running_loss=0.4948, LR=0.000100
[2025-08-27 09:51:48,035][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057144] [Batch 01704/03080] [00:21:21/00:17:15, 0.752s/it]: train_loss_raw=0.4950, running_loss=0.4930, LR=0.000100
[2025-08-27 09:51:54,065][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057152] [Batch 01712/03080] [00:21:27/00:17:09, 0.752s/it]: train_loss_raw=0.4592, running_loss=0.4923, LR=0.000100
[2025-08-27 09:52:00,083][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057160] [Batch 01720/03080] [00:21:33/00:17:02, 0.752s/it]: train_loss_raw=0.5439, running_loss=0.4915, LR=0.000100
[2025-08-27 09:52:06,102][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057168] [Batch 01728/03080] [00:21:39/00:16:56, 0.752s/it]: train_loss_raw=0.5843, running_loss=0.4922, LR=0.000100
[2025-08-27 09:52:12,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057176] [Batch 01736/03080] [00:21:45/00:16:50, 0.752s/it]: train_loss_raw=0.6013, running_loss=0.4928, LR=0.000100
[2025-08-27 09:52:18,341][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057184] [Batch 01744/03080] [00:21:52/00:16:45, 0.752s/it]: train_loss_raw=0.4363, running_loss=0.4923, LR=0.000100
[2025-08-27 09:52:24,501][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057192] [Batch 01752/03080] [00:21:58/00:16:39, 0.752s/it]: train_loss_raw=0.4964, running_loss=0.4919, LR=0.000100
[2025-08-27 09:52:30,548][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057200] [Batch 01760/03080] [00:22:04/00:16:33, 0.752s/it]: train_loss_raw=0.5298, running_loss=0.4935, LR=0.000100
[2025-08-27 09:52:36,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057208] [Batch 01768/03080] [00:22:10/00:16:27, 0.752s/it]: train_loss_raw=0.5159, running_loss=0.4936, LR=0.000100
[2025-08-27 09:52:42,682][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057216] [Batch 01776/03080] [00:22:16/00:16:21, 0.752s/it]: train_loss_raw=0.4312, running_loss=0.4935, LR=0.000100
[2025-08-27 09:52:48,605][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057224] [Batch 01784/03080] [00:22:22/00:16:15, 0.752s/it]: train_loss_raw=0.4694, running_loss=0.4925, LR=0.000100
[2025-08-27 09:52:54,703][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057232] [Batch 01792/03080] [00:22:28/00:16:09, 0.752s/it]: train_loss_raw=0.3927, running_loss=0.4927, LR=0.000100
[2025-08-27 09:53:00,728][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057240] [Batch 01800/03080] [00:22:34/00:16:03, 0.752s/it]: train_loss_raw=0.5637, running_loss=0.4910, LR=0.000100
[2025-08-27 09:53:06,837][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057248] [Batch 01808/03080] [00:22:40/00:15:57, 0.753s/it]: train_loss_raw=0.4653, running_loss=0.4917, LR=0.000100
[2025-08-27 09:53:12,856][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057256] [Batch 01816/03080] [00:22:46/00:15:51, 0.753s/it]: train_loss_raw=0.4831, running_loss=0.4912, LR=0.000100
[2025-08-27 09:53:19,052][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057264] [Batch 01824/03080] [00:22:52/00:15:45, 0.753s/it]: train_loss_raw=0.4723, running_loss=0.4926, LR=0.000100
[2025-08-27 09:53:25,201][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057272] [Batch 01832/03080] [00:22:58/00:15:39, 0.753s/it]: train_loss_raw=0.4718, running_loss=0.4954, LR=0.000100
[2025-08-27 09:53:31,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057280] [Batch 01840/03080] [00:23:05/00:15:33, 0.753s/it]: train_loss_raw=0.4809, running_loss=0.4937, LR=0.000100
[2025-08-27 09:53:37,335][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057288] [Batch 01848/03080] [00:23:11/00:15:27, 0.753s/it]: train_loss_raw=0.4678, running_loss=0.4920, LR=0.000100
[2025-08-27 09:53:43,413][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057296] [Batch 01856/03080] [00:23:17/00:15:21, 0.753s/it]: train_loss_raw=0.4812, running_loss=0.4910, LR=0.000100
[2025-08-27 09:53:49,443][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057304] [Batch 01864/03080] [00:23:23/00:15:15, 0.753s/it]: train_loss_raw=0.4809, running_loss=0.4898, LR=0.000100
[2025-08-27 09:53:55,540][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057312] [Batch 01872/03080] [00:23:29/00:15:09, 0.753s/it]: train_loss_raw=0.4686, running_loss=0.4909, LR=0.000100
[2025-08-27 09:54:01,605][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057320] [Batch 01880/03080] [00:23:35/00:15:03, 0.753s/it]: train_loss_raw=0.3892, running_loss=0.4907, LR=0.000100
[2025-08-27 09:54:07,658][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057328] [Batch 01888/03080] [00:23:41/00:14:57, 0.753s/it]: train_loss_raw=0.5425, running_loss=0.4890, LR=0.000100
[2025-08-27 09:54:13,712][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057336] [Batch 01896/03080] [00:23:47/00:14:51, 0.753s/it]: train_loss_raw=0.4853, running_loss=0.4902, LR=0.000100
[2025-08-27 09:54:19,793][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057344] [Batch 01904/03080] [00:23:53/00:14:45, 0.753s/it]: train_loss_raw=0.5235, running_loss=0.4900, LR=0.000100
[2025-08-27 09:54:25,875][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057352] [Batch 01912/03080] [00:23:59/00:14:39, 0.753s/it]: train_loss_raw=0.6141, running_loss=0.4907, LR=0.000100
[2025-08-27 09:54:31,986][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057360] [Batch 01920/03080] [00:24:05/00:14:33, 0.753s/it]: train_loss_raw=0.5185, running_loss=0.4909, LR=0.000100
[2025-08-27 09:54:37,983][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057368] [Batch 01928/03080] [00:24:11/00:14:27, 0.753s/it]: train_loss_raw=0.5279, running_loss=0.4913, LR=0.000100
[2025-08-27 09:54:43,934][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057376] [Batch 01936/03080] [00:24:17/00:14:21, 0.753s/it]: train_loss_raw=0.6484, running_loss=0.4921, LR=0.000100
[2025-08-27 09:54:50,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057384] [Batch 01944/03080] [00:24:23/00:14:15, 0.753s/it]: train_loss_raw=0.4724, running_loss=0.4921, LR=0.000100
[2025-08-27 09:54:56,151][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057392] [Batch 01952/03080] [00:24:29/00:14:09, 0.753s/it]: train_loss_raw=0.4750, running_loss=0.4915, LR=0.000100
[2025-08-27 09:55:02,192][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057400] [Batch 01960/03080] [00:24:35/00:14:03, 0.753s/it]: train_loss_raw=0.5308, running_loss=0.4928, LR=0.000100
[2025-08-27 09:55:08,227][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057408] [Batch 01968/03080] [00:24:41/00:13:57, 0.753s/it]: train_loss_raw=0.4477, running_loss=0.4916, LR=0.000100
[2025-08-27 09:55:14,397][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057416] [Batch 01976/03080] [00:24:48/00:13:51, 0.753s/it]: train_loss_raw=0.4797, running_loss=0.4907, LR=0.000100
[2025-08-27 09:55:20,302][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057424] [Batch 01984/03080] [00:24:54/00:13:45, 0.753s/it]: train_loss_raw=0.4320, running_loss=0.4919, LR=0.000100
[2025-08-27 09:55:26,365][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057432] [Batch 01992/03080] [00:25:00/00:13:39, 0.753s/it]: train_loss_raw=0.5329, running_loss=0.4931, LR=0.000100
[2025-08-27 09:55:32,398][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057440] [Batch 02000/03080] [00:25:06/00:13:33, 0.753s/it]: train_loss_raw=0.4669, running_loss=0.4917, LR=0.000100
[2025-08-27 09:55:38,434][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057448] [Batch 02008/03080] [00:25:12/00:13:27, 0.753s/it]: train_loss_raw=0.4830, running_loss=0.4930, LR=0.000100
[2025-08-27 09:55:44,639][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057456] [Batch 02016/03080] [00:25:18/00:13:21, 0.753s/it]: train_loss_raw=0.5645, running_loss=0.4942, LR=0.000100
[2025-08-27 09:55:50,793][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057464] [Batch 02024/03080] [00:25:24/00:13:15, 0.753s/it]: train_loss_raw=0.4564, running_loss=0.4961, LR=0.000100
[2025-08-27 09:55:56,855][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057472] [Batch 02032/03080] [00:25:30/00:13:09, 0.753s/it]: train_loss_raw=0.4537, running_loss=0.4955, LR=0.000100
[2025-08-27 09:56:02,893][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057480] [Batch 02040/03080] [00:25:36/00:13:03, 0.753s/it]: train_loss_raw=0.4842, running_loss=0.4966, LR=0.000100
[2025-08-27 09:56:08,969][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057488] [Batch 02048/03080] [00:25:42/00:12:57, 0.753s/it]: train_loss_raw=0.4547, running_loss=0.4958, LR=0.000100
[2025-08-27 09:56:15,022][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057496] [Batch 02056/03080] [00:25:48/00:12:51, 0.753s/it]: train_loss_raw=0.4378, running_loss=0.4941, LR=0.000100
[2025-08-27 09:56:20,979][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057504] [Batch 02064/03080] [00:25:54/00:12:45, 0.753s/it]: train_loss_raw=0.5727, running_loss=0.4962, LR=0.000100
[2025-08-27 09:56:26,631][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057512] [Batch 02072/03080] [00:26:00/00:12:39, 0.753s/it]: train_loss_raw=0.5003, running_loss=0.4971, LR=0.000100
[2025-08-27 09:56:32,562][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057520] [Batch 02080/03080] [00:26:06/00:12:33, 0.753s/it]: train_loss_raw=0.4679, running_loss=0.4962, LR=0.000100
[2025-08-27 09:56:38,567][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057528] [Batch 02088/03080] [00:26:12/00:12:26, 0.753s/it]: train_loss_raw=0.4963, running_loss=0.4945, LR=0.000100
[2025-08-27 09:56:44,644][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057536] [Batch 02096/03080] [00:26:18/00:12:20, 0.753s/it]: train_loss_raw=0.5383, running_loss=0.4946, LR=0.000100
[2025-08-27 09:56:50,844][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057544] [Batch 02104/03080] [00:26:24/00:12:15, 0.753s/it]: train_loss_raw=0.5798, running_loss=0.4985, LR=0.000100
[2025-08-27 09:56:57,107][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057552] [Batch 02112/03080] [00:26:30/00:12:09, 0.753s/it]: train_loss_raw=0.4579, running_loss=0.4959, LR=0.000100
[2025-08-27 09:57:03,273][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057560] [Batch 02120/03080] [00:26:36/00:12:03, 0.753s/it]: train_loss_raw=0.4147, running_loss=0.4931, LR=0.000100
[2025-08-27 09:57:09,418][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057568] [Batch 02128/03080] [00:26:43/00:11:57, 0.753s/it]: train_loss_raw=0.5075, running_loss=0.4945, LR=0.000100
[2025-08-27 09:57:15,457][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057576] [Batch 02136/03080] [00:26:49/00:11:51, 0.753s/it]: train_loss_raw=0.5615, running_loss=0.4944, LR=0.000100
[2025-08-27 09:57:21,504][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057584] [Batch 02144/03080] [00:26:55/00:11:45, 0.753s/it]: train_loss_raw=0.5277, running_loss=0.4933, LR=0.000100
[2025-08-27 09:57:27,587][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057592] [Batch 02152/03080] [00:27:01/00:11:39, 0.753s/it]: train_loss_raw=0.4779, running_loss=0.4905, LR=0.000100
[2025-08-27 09:57:33,369][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057600] [Batch 02160/03080] [00:27:07/00:11:33, 0.753s/it]: train_loss_raw=0.4827, running_loss=0.4905, LR=0.000100
[2025-08-27 09:57:39,321][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057608] [Batch 02168/03080] [00:27:13/00:11:26, 0.753s/it]: train_loss_raw=0.5856, running_loss=0.4903, LR=0.000100
[2025-08-27 09:57:45,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057616] [Batch 02176/03080] [00:27:19/00:11:20, 0.753s/it]: train_loss_raw=0.4972, running_loss=0.4905, LR=0.000100
[2025-08-27 09:57:51,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057624] [Batch 02184/03080] [00:27:25/00:11:14, 0.753s/it]: train_loss_raw=0.4388, running_loss=0.4892, LR=0.000100
[2025-08-27 09:57:57,595][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057632] [Batch 02192/03080] [00:27:31/00:11:08, 0.753s/it]: train_loss_raw=0.4964, running_loss=0.4893, LR=0.000100
[2025-08-27 09:58:03,789][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057640] [Batch 02200/03080] [00:27:37/00:11:02, 0.753s/it]: train_loss_raw=0.5161, running_loss=0.4904, LR=0.000100
[2025-08-27 09:58:09,893][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057648] [Batch 02208/03080] [00:27:43/00:10:56, 0.753s/it]: train_loss_raw=0.4717, running_loss=0.4902, LR=0.000100
[2025-08-27 09:58:16,046][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057656] [Batch 02216/03080] [00:27:49/00:10:51, 0.753s/it]: train_loss_raw=0.4499, running_loss=0.4910, LR=0.000100
[2025-08-27 09:58:22,312][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057664] [Batch 02224/03080] [00:27:56/00:10:45, 0.754s/it]: train_loss_raw=0.4979, running_loss=0.4938, LR=0.000100
[2025-08-27 09:58:28,346][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057672] [Batch 02232/03080] [00:28:02/00:10:39, 0.754s/it]: train_loss_raw=0.5020, running_loss=0.4924, LR=0.000100
[2025-08-27 09:58:34,477][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057680] [Batch 02240/03080] [00:28:08/00:10:33, 0.754s/it]: train_loss_raw=0.5506, running_loss=0.4932, LR=0.000100
[2025-08-27 09:58:40,613][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057688] [Batch 02248/03080] [00:28:14/00:10:27, 0.754s/it]: train_loss_raw=0.5185, running_loss=0.4944, LR=0.000100
[2025-08-27 09:58:46,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057696] [Batch 02256/03080] [00:28:20/00:10:21, 0.754s/it]: train_loss_raw=0.4779, running_loss=0.4943, LR=0.000100
[2025-08-27 09:58:52,380][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057704] [Batch 02264/03080] [00:28:26/00:10:14, 0.754s/it]: train_loss_raw=0.5602, running_loss=0.4952, LR=0.000100
[2025-08-27 09:58:58,218][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057712] [Batch 02272/03080] [00:28:31/00:10:08, 0.753s/it]: train_loss_raw=0.4492, running_loss=0.4923, LR=0.000100
[2025-08-27 09:59:04,010][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057720] [Batch 02280/03080] [00:28:37/00:10:02, 0.753s/it]: train_loss_raw=0.4476, running_loss=0.4926, LR=0.000100
[2025-08-27 09:59:10,152][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057728] [Batch 02288/03080] [00:28:43/00:09:56, 0.753s/it]: train_loss_raw=0.4733, running_loss=0.4939, LR=0.000100
[2025-08-27 09:59:16,243][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057736] [Batch 02296/03080] [00:28:49/00:09:50, 0.753s/it]: train_loss_raw=0.5442, running_loss=0.4952, LR=0.000100
[2025-08-27 09:59:22,243][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057744] [Batch 02304/03080] [00:28:55/00:09:44, 0.753s/it]: train_loss_raw=0.5994, running_loss=0.4954, LR=0.000100
[2025-08-27 09:59:27,843][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057752] [Batch 02312/03080] [00:29:01/00:09:38, 0.753s/it]: train_loss_raw=0.5686, running_loss=0.4961, LR=0.000100
[2025-08-27 09:59:33,456][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057760] [Batch 02320/03080] [00:29:07/00:09:32, 0.753s/it]: train_loss_raw=0.4495, running_loss=0.4960, LR=0.000100
[2025-08-27 09:59:39,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057768] [Batch 02328/03080] [00:29:13/00:09:26, 0.753s/it]: train_loss_raw=0.4416, running_loss=0.4933, LR=0.000100
[2025-08-27 09:59:45,184][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057776] [Batch 02336/03080] [00:29:18/00:09:20, 0.753s/it]: train_loss_raw=0.4523, running_loss=0.4937, LR=0.000100
[2025-08-27 09:59:51,174][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057784] [Batch 02344/03080] [00:29:24/00:09:14, 0.753s/it]: train_loss_raw=0.4571, running_loss=0.4966, LR=0.000100
[2025-08-27 09:59:57,225][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057792] [Batch 02352/03080] [00:29:30/00:09:08, 0.753s/it]: train_loss_raw=0.5605, running_loss=0.4961, LR=0.000100
[2025-08-27 10:00:03,110][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057800] [Batch 02360/03080] [00:29:36/00:09:02, 0.753s/it]: train_loss_raw=0.5237, running_loss=0.4990, LR=0.000100
[2025-08-27 10:00:09,306][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057808] [Batch 02368/03080] [00:29:43/00:08:56, 0.753s/it]: train_loss_raw=0.5193, running_loss=0.5014, LR=0.000100
[2025-08-27 10:00:15,432][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057816] [Batch 02376/03080] [00:29:49/00:08:50, 0.753s/it]: train_loss_raw=0.5195, running_loss=0.5016, LR=0.000100
[2025-08-27 10:00:21,560][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057824] [Batch 02384/03080] [00:29:55/00:08:44, 0.753s/it]: train_loss_raw=0.5773, running_loss=0.4993, LR=0.000100
[2025-08-27 10:00:27,364][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057832] [Batch 02392/03080] [00:30:01/00:08:38, 0.753s/it]: train_loss_raw=0.5532, running_loss=0.4988, LR=0.000100
[2025-08-27 10:00:33,454][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057840] [Batch 02400/03080] [00:30:07/00:08:32, 0.753s/it]: train_loss_raw=0.6428, running_loss=0.4980, LR=0.000100
[2025-08-27 10:00:39,436][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057848] [Batch 02408/03080] [00:30:13/00:08:25, 0.753s/it]: train_loss_raw=0.5229, running_loss=0.4987, LR=0.000100
[2025-08-27 10:00:45,499][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057856] [Batch 02416/03080] [00:30:19/00:08:19, 0.753s/it]: train_loss_raw=0.5510, running_loss=0.4996, LR=0.000100
[2025-08-27 10:00:51,589][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057864] [Batch 02424/03080] [00:30:25/00:08:13, 0.753s/it]: train_loss_raw=0.4602, running_loss=0.4991, LR=0.000100
[2025-08-27 10:00:57,784][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057872] [Batch 02432/03080] [00:30:31/00:08:07, 0.753s/it]: train_loss_raw=0.4742, running_loss=0.4995, LR=0.000100
[2025-08-27 10:01:03,884][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057880] [Batch 02440/03080] [00:30:37/00:08:01, 0.753s/it]: train_loss_raw=0.4775, running_loss=0.4977, LR=0.000100
[2025-08-27 10:01:10,043][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057888] [Batch 02448/03080] [00:30:43/00:07:55, 0.753s/it]: train_loss_raw=0.4845, running_loss=0.4999, LR=0.000100
[2025-08-27 10:01:16,047][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057896] [Batch 02456/03080] [00:30:49/00:07:49, 0.753s/it]: train_loss_raw=0.5378, running_loss=0.4994, LR=0.000100
[2025-08-27 10:01:22,238][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057904] [Batch 02464/03080] [00:30:55/00:07:43, 0.753s/it]: train_loss_raw=0.4755, running_loss=0.4978, LR=0.000100
[2025-08-27 10:01:28,192][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057912] [Batch 02472/03080] [00:31:01/00:07:37, 0.753s/it]: train_loss_raw=0.4432, running_loss=0.4955, LR=0.000100
[2025-08-27 10:01:34,051][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057920] [Batch 02480/03080] [00:31:07/00:07:31, 0.753s/it]: train_loss_raw=0.4803, running_loss=0.4953, LR=0.000100
[2025-08-27 10:01:40,007][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057928] [Batch 02488/03080] [00:31:13/00:07:25, 0.753s/it]: train_loss_raw=0.4521, running_loss=0.4949, LR=0.000100
[2025-08-27 10:01:46,062][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057936] [Batch 02496/03080] [00:31:19/00:07:19, 0.753s/it]: train_loss_raw=0.4649, running_loss=0.4957, LR=0.000100
[2025-08-27 10:01:52,009][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057944] [Batch 02504/03080] [00:31:25/00:07:13, 0.753s/it]: train_loss_raw=0.4448, running_loss=0.4928, LR=0.000100
[2025-08-27 10:01:58,073][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057952] [Batch 02512/03080] [00:31:31/00:07:07, 0.753s/it]: train_loss_raw=0.4975, running_loss=0.4934, LR=0.000100
[2025-08-27 10:02:03,985][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057960] [Batch 02520/03080] [00:31:37/00:07:01, 0.753s/it]: train_loss_raw=0.5437, running_loss=0.4940, LR=0.000100
[2025-08-27 10:02:09,763][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057968] [Batch 02528/03080] [00:31:43/00:06:55, 0.753s/it]: train_loss_raw=0.5151, running_loss=0.4906, LR=0.000100
[2025-08-27 10:02:15,538][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057976] [Batch 02536/03080] [00:31:49/00:06:49, 0.753s/it]: train_loss_raw=0.5410, running_loss=0.4920, LR=0.000100
[2025-08-27 10:02:21,088][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057984] [Batch 02544/03080] [00:31:54/00:06:43, 0.753s/it]: train_loss_raw=0.5448, running_loss=0.4919, LR=0.000100
[2025-08-27 10:02:26,714][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 057992] [Batch 02552/03080] [00:32:00/00:06:37, 0.753s/it]: train_loss_raw=0.4475, running_loss=0.4914, LR=0.000100
[2025-08-27 10:02:32,565][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058000] [Batch 02560/03080] [00:32:06/00:06:31, 0.752s/it]: train_loss_raw=0.6037, running_loss=0.4927, LR=0.000100
[2025-08-27 10:02:42,031][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058008] [Batch 02568/03080] [00:32:15/00:06:25, 0.754s/it]: train_loss_raw=0.5096, running_loss=0.4922, LR=0.000100
[2025-08-27 10:02:47,428][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058016] [Batch 02576/03080] [00:32:21/00:06:19, 0.754s/it]: train_loss_raw=0.4559, running_loss=0.4943, LR=0.000100
[2025-08-27 10:02:53,130][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058024] [Batch 02584/03080] [00:32:26/00:06:13, 0.753s/it]: train_loss_raw=0.4714, running_loss=0.4953, LR=0.000100
[2025-08-27 10:02:58,907][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058032] [Batch 02592/03080] [00:32:32/00:06:07, 0.753s/it]: train_loss_raw=0.4821, running_loss=0.4944, LR=0.000100
[2025-08-27 10:03:04,906][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058040] [Batch 02600/03080] [00:32:38/00:06:01, 0.753s/it]: train_loss_raw=0.5167, running_loss=0.4935, LR=0.000100
[2025-08-27 10:03:10,852][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058048] [Batch 02608/03080] [00:32:44/00:05:55, 0.753s/it]: train_loss_raw=0.4483, running_loss=0.4932, LR=0.000100
[2025-08-27 10:03:16,804][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058056] [Batch 02616/03080] [00:32:50/00:05:49, 0.753s/it]: train_loss_raw=0.3741, running_loss=0.4938, LR=0.000100
[2025-08-27 10:03:22,961][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058064] [Batch 02624/03080] [00:32:56/00:05:43, 0.753s/it]: train_loss_raw=0.3768, running_loss=0.4919, LR=0.000100
[2025-08-27 10:03:29,074][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058072] [Batch 02632/03080] [00:33:02/00:05:37, 0.753s/it]: train_loss_raw=0.4744, running_loss=0.4899, LR=0.000100
[2025-08-27 10:03:35,082][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058080] [Batch 02640/03080] [00:33:08/00:05:31, 0.753s/it]: train_loss_raw=0.4395, running_loss=0.4883, LR=0.000100
[2025-08-27 10:03:41,107][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058088] [Batch 02648/03080] [00:33:14/00:05:25, 0.753s/it]: train_loss_raw=0.4650, running_loss=0.4875, LR=0.000100
[2025-08-27 10:03:47,108][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058096] [Batch 02656/03080] [00:33:20/00:05:19, 0.753s/it]: train_loss_raw=0.5307, running_loss=0.4880, LR=0.000100
[2025-08-27 10:03:52,844][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058104] [Batch 02664/03080] [00:33:26/00:05:13, 0.753s/it]: train_loss_raw=0.4782, running_loss=0.4885, LR=0.000100
[2025-08-27 10:03:58,706][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058112] [Batch 02672/03080] [00:33:32/00:05:07, 0.753s/it]: train_loss_raw=0.4709, running_loss=0.4876, LR=0.000100
[2025-08-27 10:04:04,759][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058120] [Batch 02680/03080] [00:33:38/00:05:01, 0.753s/it]: train_loss_raw=0.4539, running_loss=0.4892, LR=0.000100
[2025-08-27 10:04:10,817][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058128] [Batch 02688/03080] [00:33:44/00:04:55, 0.753s/it]: train_loss_raw=0.4702, running_loss=0.4877, LR=0.000100
[2025-08-27 10:04:16,622][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058136] [Batch 02696/03080] [00:33:50/00:04:49, 0.753s/it]: train_loss_raw=0.4730, running_loss=0.4871, LR=0.000100
[2025-08-27 10:04:22,428][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058144] [Batch 02704/03080] [00:33:56/00:04:43, 0.753s/it]: train_loss_raw=0.5457, running_loss=0.4869, LR=0.000100
[2025-08-27 10:04:28,191][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058152] [Batch 02712/03080] [00:34:01/00:04:37, 0.753s/it]: train_loss_raw=0.5564, running_loss=0.4890, LR=0.000100
[2025-08-27 10:04:34,079][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058160] [Batch 02720/03080] [00:34:07/00:04:31, 0.753s/it]: train_loss_raw=0.4957, running_loss=0.4880, LR=0.000100
[2025-08-27 10:04:39,822][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058168] [Batch 02728/03080] [00:34:13/00:04:24, 0.753s/it]: train_loss_raw=0.4719, running_loss=0.4870, LR=0.000100
[2025-08-27 10:04:45,706][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058176] [Batch 02736/03080] [00:34:19/00:04:18, 0.753s/it]: train_loss_raw=0.6541, running_loss=0.4881, LR=0.000100
[2025-08-27 10:04:51,705][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058184] [Batch 02744/03080] [00:34:25/00:04:12, 0.753s/it]: train_loss_raw=0.5027, running_loss=0.4874, LR=0.000100
[2025-08-27 10:04:57,718][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058192] [Batch 02752/03080] [00:34:31/00:04:06, 0.753s/it]: train_loss_raw=0.4599, running_loss=0.4873, LR=0.000100
[2025-08-27 10:05:03,817][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058200] [Batch 02760/03080] [00:34:37/00:04:00, 0.753s/it]: train_loss_raw=0.4401, running_loss=0.4857, LR=0.000100
[2025-08-27 10:05:09,916][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058208] [Batch 02768/03080] [00:34:43/00:03:54, 0.753s/it]: train_loss_raw=0.5397, running_loss=0.4855, LR=0.000100
[2025-08-27 10:05:15,930][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058216] [Batch 02776/03080] [00:34:49/00:03:48, 0.753s/it]: train_loss_raw=0.4870, running_loss=0.4868, LR=0.000100
[2025-08-27 10:05:22,036][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058224] [Batch 02784/03080] [00:34:55/00:03:42, 0.753s/it]: train_loss_raw=0.4280, running_loss=0.4880, LR=0.000100
[2025-08-27 10:05:28,140][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058232] [Batch 02792/03080] [00:35:01/00:03:36, 0.753s/it]: train_loss_raw=0.5267, running_loss=0.4878, LR=0.000100
[2025-08-27 10:05:34,394][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058240] [Batch 02800/03080] [00:35:08/00:03:30, 0.753s/it]: train_loss_raw=0.5481, running_loss=0.4875, LR=0.000100
[2025-08-27 10:05:40,551][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058248] [Batch 02808/03080] [00:35:14/00:03:24, 0.753s/it]: train_loss_raw=0.5258, running_loss=0.4885, LR=0.000100
[2025-08-27 10:05:46,492][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058256] [Batch 02816/03080] [00:35:20/00:03:18, 0.753s/it]: train_loss_raw=0.5418, running_loss=0.4892, LR=0.000100
[2025-08-27 10:05:52,601][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058264] [Batch 02824/03080] [00:35:26/00:03:12, 0.753s/it]: train_loss_raw=0.3829, running_loss=0.4875, LR=0.000100
[2025-08-27 10:05:58,473][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058272] [Batch 02832/03080] [00:35:32/00:03:06, 0.753s/it]: train_loss_raw=0.4235, running_loss=0.4858, LR=0.000100
[2025-08-27 10:06:04,143][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058280] [Batch 02840/03080] [00:35:37/00:03:00, 0.753s/it]: train_loss_raw=0.5307, running_loss=0.4875, LR=0.000100
[2025-08-27 10:06:10,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058288] [Batch 02848/03080] [00:35:43/00:02:54, 0.753s/it]: train_loss_raw=0.4830, running_loss=0.4889, LR=0.000100
[2025-08-27 10:06:16,451][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058296] [Batch 02856/03080] [00:35:50/00:02:48, 0.753s/it]: train_loss_raw=0.4739, running_loss=0.4878, LR=0.000100
[2025-08-27 10:06:22,321][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058304] [Batch 02864/03080] [00:35:56/00:02:42, 0.753s/it]: train_loss_raw=0.4221, running_loss=0.4870, LR=0.000100
[2025-08-27 10:06:28,251][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058312] [Batch 02872/03080] [00:36:01/00:02:36, 0.753s/it]: train_loss_raw=0.4818, running_loss=0.4898, LR=0.000100
[2025-08-27 10:06:34,358][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058320] [Batch 02880/03080] [00:36:08/00:02:30, 0.753s/it]: train_loss_raw=0.5564, running_loss=0.4876, LR=0.000100
[2025-08-27 10:06:40,409][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058328] [Batch 02888/03080] [00:36:14/00:02:24, 0.753s/it]: train_loss_raw=0.4875, running_loss=0.4887, LR=0.000100
[2025-08-27 10:06:46,102][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058336] [Batch 02896/03080] [00:36:19/00:02:18, 0.753s/it]: train_loss_raw=0.4950, running_loss=0.4895, LR=0.000100
[2025-08-27 10:06:52,798][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058344] [Batch 02904/03080] [00:36:26/00:02:12, 0.753s/it]: train_loss_raw=0.5521, running_loss=0.4923, LR=0.000100
[2025-08-27 10:06:58,771][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058352] [Batch 02912/03080] [00:36:32/00:02:06, 0.753s/it]: train_loss_raw=0.5053, running_loss=0.4918, LR=0.000100
[2025-08-27 10:07:04,662][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058360] [Batch 02920/03080] [00:36:38/00:02:00, 0.753s/it]: train_loss_raw=0.5005, running_loss=0.4934, LR=0.000100
[2025-08-27 10:07:10,769][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058368] [Batch 02928/03080] [00:36:44/00:01:54, 0.753s/it]: train_loss_raw=0.5910, running_loss=0.4939, LR=0.000100
[2025-08-27 10:07:16,708][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058376] [Batch 02936/03080] [00:36:50/00:01:48, 0.753s/it]: train_loss_raw=0.4801, running_loss=0.4947, LR=0.000100
[2025-08-27 10:07:22,644][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058384] [Batch 02944/03080] [00:36:56/00:01:42, 0.753s/it]: train_loss_raw=0.5071, running_loss=0.4955, LR=0.000100
[2025-08-27 10:07:28,414][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058392] [Batch 02952/03080] [00:37:02/00:01:36, 0.753s/it]: train_loss_raw=0.4326, running_loss=0.4963, LR=0.000100
[2025-08-27 10:07:34,189][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058400] [Batch 02960/03080] [00:37:07/00:01:30, 0.753s/it]: train_loss_raw=0.4755, running_loss=0.4948, LR=0.000100
[2025-08-27 10:07:40,102][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058408] [Batch 02968/03080] [00:37:13/00:01:24, 0.753s/it]: train_loss_raw=0.5508, running_loss=0.4945, LR=0.000100
[2025-08-27 10:07:45,941][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058416] [Batch 02976/03080] [00:37:19/00:01:18, 0.753s/it]: train_loss_raw=0.5273, running_loss=0.4950, LR=0.000100
[2025-08-27 10:07:51,718][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058424] [Batch 02984/03080] [00:37:25/00:01:12, 0.752s/it]: train_loss_raw=0.5380, running_loss=0.4956, LR=0.000100
[2025-08-27 10:07:57,708][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058432] [Batch 02992/03080] [00:37:31/00:01:06, 0.752s/it]: train_loss_raw=0.5434, running_loss=0.4961, LR=0.000100
[2025-08-27 10:08:03,789][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058440] [Batch 03000/03080] [00:37:37/00:01:00, 0.752s/it]: train_loss_raw=0.5270, running_loss=0.4937, LR=0.000100
[2025-08-27 10:08:09,857][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058448] [Batch 03008/03080] [00:37:43/00:00:54, 0.753s/it]: train_loss_raw=0.4842, running_loss=0.4926, LR=0.000100
[2025-08-27 10:08:15,901][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058456] [Batch 03016/03080] [00:37:49/00:00:48, 0.753s/it]: train_loss_raw=0.4353, running_loss=0.4909, LR=0.000100
[2025-08-27 10:08:22,102][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058464] [Batch 03024/03080] [00:37:55/00:00:42, 0.753s/it]: train_loss_raw=0.5185, running_loss=0.4909, LR=0.000100
[2025-08-27 10:08:28,240][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058472] [Batch 03032/03080] [00:38:01/00:00:36, 0.753s/it]: train_loss_raw=0.3809, running_loss=0.4909, LR=0.000100
[2025-08-27 10:08:34,381][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058480] [Batch 03040/03080] [00:38:08/00:00:30, 0.753s/it]: train_loss_raw=0.6264, running_loss=0.4936, LR=0.000100
[2025-08-27 10:08:40,174][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058488] [Batch 03048/03080] [00:38:13/00:00:24, 0.753s/it]: train_loss_raw=0.5591, running_loss=0.4949, LR=0.000100
[2025-08-27 10:08:46,319][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058496] [Batch 03056/03080] [00:38:20/00:00:18, 0.753s/it]: train_loss_raw=0.5287, running_loss=0.4962, LR=0.000100
[2025-08-27 10:08:52,306][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058504] [Batch 03064/03080] [00:38:26/00:00:12, 0.753s/it]: train_loss_raw=0.5435, running_loss=0.4945, LR=0.000100
[2025-08-27 10:08:58,334][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058512] [Batch 03072/03080] [00:38:32/00:00:06, 0.753s/it]: train_loss_raw=0.4213, running_loss=0.4941, LR=0.000100
[2025-08-27 10:09:04,361][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 058520] [Batch 03080/03080] [00:38:38/00:00:00, 0.753s/it]: train_loss_raw=0.5032, running_loss=0.4946, LR=0.000100
[2025-08-27 10:09:04,880][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-27 10:09:16,199][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00007/00310] [00:00:11/00:07:07, 1.415s/it]
[2025-08-27 10:09:27,829][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00015/00310] [00:00:22/00:07:01, 1.434s/it]
[2025-08-27 10:09:40,376][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00023/00310] [00:00:35/00:07:02, 1.479s/it]
[2025-08-27 10:09:52,123][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00031/00310] [00:00:47/00:06:50, 1.476s/it]
[2025-08-27 10:10:04,520][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00039/00310] [00:00:59/00:06:42, 1.491s/it]
[2025-08-27 10:10:17,057][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00047/00310] [00:01:12/00:06:33, 1.504s/it]
[2025-08-27 10:10:29,198][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00055/00310] [00:01:24/00:06:22, 1.506s/it]
[2025-08-27 10:10:41,378][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00063/00310] [00:01:36/00:06:10, 1.508s/it]
[2025-08-27 10:10:53,649][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00071/00310] [00:01:48/00:05:59, 1.511s/it]
[2025-08-27 10:11:05,911][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00079/00310] [00:02:01/00:05:47, 1.513s/it]
[2025-08-27 10:11:17,650][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00087/00310] [00:02:12/00:05:34, 1.509s/it]
[2025-08-27 10:11:30,094][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00095/00310] [00:02:25/00:05:23, 1.513s/it]
[2025-08-27 10:11:41,574][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00103/00310] [00:02:36/00:05:10, 1.507s/it]
[2025-08-27 10:11:54,265][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00111/00310] [00:02:49/00:04:59, 1.512s/it]
[2025-08-27 10:12:06,477][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00119/00310] [00:03:01/00:04:47, 1.513s/it]
[2025-08-27 10:12:18,655][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00127/00310] [00:03:13/00:04:35, 1.514s/it]
[2025-08-27 10:12:31,368][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00135/00310] [00:03:26/00:04:24, 1.518s/it]
[2025-08-27 10:12:43,774][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00143/00310] [00:03:38/00:04:12, 1.520s/it]
[2025-08-27 10:12:54,500][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00151/00310] [00:03:49/00:03:58, 1.511s/it]
[2025-08-27 10:13:06,574][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00159/00310] [00:04:01/00:03:46, 1.511s/it]
[2025-08-27 10:13:18,866][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00167/00310] [00:04:13/00:03:34, 1.512s/it]
[2025-08-27 10:13:30,240][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00175/00310] [00:04:25/00:03:22, 1.508s/it]
[2025-08-27 10:13:41,486][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00183/00310] [00:04:36/00:03:09, 1.503s/it]
[2025-08-27 10:13:53,322][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00191/00310] [00:04:48/00:02:57, 1.502s/it]
[2025-08-27 10:14:05,121][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00199/00310] [00:05:00/00:02:45, 1.501s/it]
[2025-08-27 10:14:16,696][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00207/00310] [00:05:11/00:02:32, 1.499s/it]
[2025-08-27 10:14:29,115][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00215/00310] [00:05:24/00:02:21, 1.501s/it]
[2025-08-27 10:14:41,262][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00223/00310] [00:05:36/00:02:09, 1.502s/it]
[2025-08-27 10:14:53,899][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00231/00310] [00:05:49/00:01:57, 1.504s/it]
[2025-08-27 10:15:05,576][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00239/00310] [00:06:00/00:01:45, 1.503s/it]
[2025-08-27 10:15:17,037][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00247/00310] [00:06:12/00:01:33, 1.501s/it]
[2025-08-27 10:15:29,449][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00255/00310] [00:06:24/00:01:21, 1.502s/it]
[2025-08-27 10:15:42,013][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00263/00310] [00:06:37/00:01:09, 1.504s/it]
[2025-08-27 10:15:53,284][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00271/00310] [00:06:48/00:00:57, 1.501s/it]
[2025-08-27 10:16:06,079][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00279/00310] [00:07:01/00:00:45, 1.504s/it]
[2025-08-27 10:16:19,028][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00287/00310] [00:07:14/00:00:33, 1.507s/it]
[2025-08-27 10:16:30,394][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00295/00310] [00:07:25/00:00:21, 1.505s/it]
[2025-08-27 10:16:43,826][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 058521] [Batch 00303/00310] [00:07:38/00:00:09, 1.510s/it]
[2025-08-27 10:16:52,896][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=0.49457, valid_loss=1.45965
[2025-08-27 10:16:52,897][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-27 10:16:52,897][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.530
[2025-08-27 10:16:52,897][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.120
[2025-08-27 10:16:52,897][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.123
[2025-08-27 10:16:52,897][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.059
[2025-08-27 10:16:52,906][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 14:50:06, remaining time 08:35:19, 00:46:50 per epoch
[2025-08-27 10:16:58,586][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058528] [Batch 00008/03080] [00:00:05/00:34:45, 0.679s/it]: train_loss_raw=0.4478, running_loss=0.5722, LR=0.000100
[2025-08-27 10:17:04,439][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058536] [Batch 00016/03080] [00:00:11/00:36:00, 0.705s/it]: train_loss_raw=0.4565, running_loss=0.5663, LR=0.000100
[2025-08-27 10:17:10,485][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058544] [Batch 00024/03080] [00:00:17/00:36:46, 0.722s/it]: train_loss_raw=0.5886, running_loss=0.5611, LR=0.000100
[2025-08-27 10:17:16,532][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058552] [Batch 00032/03080] [00:00:23/00:37:06, 0.731s/it]: train_loss_raw=0.5211, running_loss=0.5567, LR=0.000100
[2025-08-27 10:17:22,567][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058560] [Batch 00040/03080] [00:00:29/00:37:15, 0.735s/it]: train_loss_raw=0.4467, running_loss=0.5496, LR=0.000100
[2025-08-27 10:17:28,481][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058568] [Batch 00048/03080] [00:00:35/00:37:11, 0.736s/it]: train_loss_raw=0.4279, running_loss=0.5444, LR=0.000100
[2025-08-27 10:17:34,562][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058576] [Batch 00056/03080] [00:00:41/00:37:15, 0.739s/it]: train_loss_raw=0.5645, running_loss=0.5418, LR=0.000100
[2025-08-27 10:17:40,644][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058584] [Batch 00064/03080] [00:00:47/00:37:17, 0.742s/it]: train_loss_raw=0.5712, running_loss=0.5364, LR=0.000100
[2025-08-27 10:17:46,674][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058592] [Batch 00072/03080] [00:00:53/00:37:15, 0.743s/it]: train_loss_raw=0.5102, running_loss=0.5339, LR=0.000100
[2025-08-27 10:17:52,666][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058600] [Batch 00080/03080] [00:00:59/00:37:11, 0.744s/it]: train_loss_raw=0.5710, running_loss=0.5300, LR=0.000100
[2025-08-27 10:17:58,670][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058608] [Batch 00088/03080] [00:01:05/00:37:07, 0.744s/it]: train_loss_raw=0.5042, running_loss=0.5267, LR=0.000100
[2025-08-27 10:18:04,678][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058616] [Batch 00096/03080] [00:01:11/00:37:03, 0.745s/it]: train_loss_raw=0.4588, running_loss=0.5223, LR=0.000100
[2025-08-27 10:18:10,784][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058624] [Batch 00104/03080] [00:01:17/00:37:01, 0.746s/it]: train_loss_raw=0.4585, running_loss=0.5194, LR=0.000100
[2025-08-27 10:18:16,609][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058632] [Batch 00112/03080] [00:01:23/00:36:51, 0.745s/it]: train_loss_raw=0.4476, running_loss=0.5152, LR=0.000100
[2025-08-27 10:18:22,522][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058640] [Batch 00120/03080] [00:01:29/00:36:44, 0.745s/it]: train_loss_raw=0.5046, running_loss=0.5129, LR=0.000100
[2025-08-27 10:18:28,562][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058648] [Batch 00128/03080] [00:01:35/00:36:40, 0.745s/it]: train_loss_raw=0.4166, running_loss=0.5098, LR=0.000100
[2025-08-27 10:18:34,713][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058656] [Batch 00136/03080] [00:01:41/00:36:38, 0.747s/it]: train_loss_raw=0.5769, running_loss=0.5080, LR=0.000100
[2025-08-27 10:18:40,751][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058664] [Batch 00144/03080] [00:01:47/00:36:33, 0.747s/it]: train_loss_raw=0.5563, running_loss=0.5059, LR=0.000100
[2025-08-27 10:18:46,820][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058672] [Batch 00152/03080] [00:01:53/00:36:29, 0.748s/it]: train_loss_raw=0.4240, running_loss=0.5020, LR=0.000100
[2025-08-27 10:18:52,914][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058680] [Batch 00160/03080] [00:01:59/00:36:25, 0.748s/it]: train_loss_raw=0.4238, running_loss=0.5010, LR=0.000100
[2025-08-27 10:18:59,073][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058688] [Batch 00168/03080] [00:02:05/00:36:22, 0.750s/it]: train_loss_raw=0.5090, running_loss=0.5000, LR=0.000100
[2025-08-27 10:19:05,111][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058696] [Batch 00176/03080] [00:02:11/00:36:17, 0.750s/it]: train_loss_raw=0.4516, running_loss=0.5000, LR=0.000100
[2025-08-27 10:19:11,092][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058704] [Batch 00184/03080] [00:02:17/00:36:11, 0.750s/it]: train_loss_raw=0.5058, running_loss=0.4994, LR=0.000100
[2025-08-27 10:19:17,066][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058712] [Batch 00192/03080] [00:02:23/00:36:04, 0.750s/it]: train_loss_raw=0.4342, running_loss=0.5002, LR=0.000100
[2025-08-27 10:19:22,992][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058720] [Batch 00200/03080] [00:02:29/00:35:57, 0.749s/it]: train_loss_raw=0.3848, running_loss=0.4998, LR=0.000100
[2025-08-27 10:19:28,955][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058728] [Batch 00208/03080] [00:02:35/00:35:51, 0.749s/it]: train_loss_raw=0.6039, running_loss=0.5019, LR=0.000100
[2025-08-27 10:19:35,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058736] [Batch 00216/03080] [00:02:41/00:35:46, 0.749s/it]: train_loss_raw=0.4878, running_loss=0.5001, LR=0.000100
[2025-08-27 10:19:41,233][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058744] [Batch 00224/03080] [00:02:48/00:35:42, 0.750s/it]: train_loss_raw=0.5120, running_loss=0.4976, LR=0.000100
[2025-08-27 10:19:47,416][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058752] [Batch 00232/03080] [00:02:54/00:35:39, 0.751s/it]: train_loss_raw=0.3487, running_loss=0.4930, LR=0.000100
[2025-08-27 10:19:53,467][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058760] [Batch 00240/03080] [00:03:00/00:35:33, 0.751s/it]: train_loss_raw=0.5508, running_loss=0.4922, LR=0.000100
[2025-08-27 10:19:59,466][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058768] [Batch 00248/03080] [00:03:06/00:35:27, 0.751s/it]: train_loss_raw=0.4822, running_loss=0.4930, LR=0.000100
[2025-08-27 10:20:05,673][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058776] [Batch 00256/03080] [00:03:12/00:35:23, 0.752s/it]: train_loss_raw=0.4969, running_loss=0.4923, LR=0.000100
[2025-08-27 10:20:11,384][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058784] [Batch 00264/03080] [00:03:18/00:35:14, 0.751s/it]: train_loss_raw=0.4724, running_loss=0.4927, LR=0.000100
[2025-08-27 10:20:17,321][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058792] [Batch 00272/03080] [00:03:24/00:35:07, 0.751s/it]: train_loss_raw=0.5014, running_loss=0.4917, LR=0.000100
[2025-08-27 10:20:23,488][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058800] [Batch 00280/03080] [00:03:30/00:35:03, 0.751s/it]: train_loss_raw=0.4928, running_loss=0.4929, LR=0.000100
[2025-08-27 10:20:29,692][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058808] [Batch 00288/03080] [00:03:36/00:34:59, 0.752s/it]: train_loss_raw=0.4302, running_loss=0.4923, LR=0.000100
[2025-08-27 10:20:35,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058816] [Batch 00296/03080] [00:03:42/00:34:55, 0.753s/it]: train_loss_raw=0.5608, running_loss=0.4921, LR=0.000100
[2025-08-27 10:20:41,953][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058824] [Batch 00304/03080] [00:03:48/00:34:49, 0.753s/it]: train_loss_raw=0.5730, running_loss=0.4908, LR=0.000100
[2025-08-27 10:20:48,005][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058832] [Batch 00312/03080] [00:03:54/00:34:43, 0.753s/it]: train_loss_raw=0.4839, running_loss=0.4906, LR=0.000100
[2025-08-27 10:20:53,893][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058840] [Batch 00320/03080] [00:04:00/00:34:36, 0.752s/it]: train_loss_raw=0.5053, running_loss=0.4920, LR=0.000100
[2025-08-27 10:20:59,844][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058848] [Batch 00328/03080] [00:04:06/00:34:29, 0.752s/it]: train_loss_raw=0.4601, running_loss=0.4922, LR=0.000100
[2025-08-27 10:21:06,066][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058856] [Batch 00336/03080] [00:04:12/00:34:25, 0.753s/it]: train_loss_raw=0.5024, running_loss=0.4913, LR=0.000100
[2025-08-27 10:21:12,098][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058864] [Batch 00344/03080] [00:04:18/00:34:19, 0.753s/it]: train_loss_raw=0.3809, running_loss=0.4910, LR=0.000100
[2025-08-27 10:21:18,193][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058872] [Batch 00352/03080] [00:04:25/00:34:14, 0.753s/it]: train_loss_raw=0.4679, running_loss=0.4896, LR=0.000100
[2025-08-27 10:21:24,199][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058880] [Batch 00360/03080] [00:04:31/00:34:07, 0.753s/it]: train_loss_raw=0.5104, running_loss=0.4908, LR=0.000100
[2025-08-27 10:21:29,984][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058888] [Batch 00368/03080] [00:04:36/00:34:00, 0.752s/it]: train_loss_raw=0.5359, running_loss=0.4903, LR=0.000100
[2025-08-27 10:21:35,750][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058896] [Batch 00376/03080] [00:04:42/00:33:52, 0.752s/it]: train_loss_raw=0.5632, running_loss=0.4893, LR=0.000100
[2025-08-27 10:21:41,988][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058904] [Batch 00384/03080] [00:04:48/00:33:47, 0.752s/it]: train_loss_raw=0.5390, running_loss=0.4901, LR=0.000100
[2025-08-27 10:21:48,136][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058912] [Batch 00392/03080] [00:04:54/00:33:42, 0.753s/it]: train_loss_raw=0.4294, running_loss=0.4895, LR=0.000100
[2025-08-27 10:21:54,310][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058920] [Batch 00400/03080] [00:05:01/00:33:37, 0.753s/it]: train_loss_raw=0.5476, running_loss=0.4913, LR=0.000100
[2025-08-27 10:22:00,006][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058928] [Batch 00408/03080] [00:05:06/00:33:29, 0.752s/it]: train_loss_raw=0.5387, running_loss=0.4903, LR=0.000100
[2025-08-27 10:22:05,751][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058936] [Batch 00416/03080] [00:05:12/00:33:21, 0.751s/it]: train_loss_raw=0.5250, running_loss=0.4893, LR=0.000100
[2025-08-27 10:22:11,590][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058944] [Batch 00424/03080] [00:05:18/00:33:14, 0.751s/it]: train_loss_raw=0.4279, running_loss=0.4890, LR=0.000100
[2025-08-27 10:22:17,297][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058952] [Batch 00432/03080] [00:05:24/00:33:06, 0.750s/it]: train_loss_raw=0.5757, running_loss=0.4908, LR=0.000100
[2025-08-27 10:22:23,662][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058960] [Batch 00440/03080] [00:05:30/00:33:03, 0.751s/it]: train_loss_raw=0.4266, running_loss=0.4922, LR=0.000100
[2025-08-27 10:22:30,057][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058968] [Batch 00448/03080] [00:05:36/00:32:59, 0.752s/it]: train_loss_raw=0.5268, running_loss=0.4930, LR=0.000100
[2025-08-27 10:22:36,157][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058976] [Batch 00456/03080] [00:05:43/00:32:53, 0.752s/it]: train_loss_raw=0.4173, running_loss=0.4914, LR=0.000100
[2025-08-27 10:22:41,823][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058984] [Batch 00464/03080] [00:05:48/00:32:45, 0.751s/it]: train_loss_raw=0.3986, running_loss=0.4883, LR=0.000100
[2025-08-27 10:22:47,657][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 058992] [Batch 00472/03080] [00:05:54/00:32:38, 0.751s/it]: train_loss_raw=0.4411, running_loss=0.4882, LR=0.000100
[2025-08-27 10:22:53,553][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059000] [Batch 00480/03080] [00:06:00/00:32:32, 0.751s/it]: train_loss_raw=0.4743, running_loss=0.4879, LR=0.000100
[2025-08-27 10:22:59,563][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059008] [Batch 00488/03080] [00:06:06/00:32:26, 0.751s/it]: train_loss_raw=0.5312, running_loss=0.4862, LR=0.000100
[2025-08-27 10:23:05,840][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059016] [Batch 00496/03080] [00:06:12/00:32:21, 0.751s/it]: train_loss_raw=0.4403, running_loss=0.4849, LR=0.000100
[2025-08-27 10:23:11,880][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059024] [Batch 00504/03080] [00:06:18/00:32:15, 0.751s/it]: train_loss_raw=0.5758, running_loss=0.4842, LR=0.000100
[2025-08-27 10:23:17,971][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059032] [Batch 00512/03080] [00:06:24/00:32:10, 0.752s/it]: train_loss_raw=0.4506, running_loss=0.4848, LR=0.000100
[2025-08-27 10:23:24,072][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059040] [Batch 00520/03080] [00:06:30/00:32:04, 0.752s/it]: train_loss_raw=0.4886, running_loss=0.4870, LR=0.000100
[2025-08-27 10:23:30,185][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059048] [Batch 00528/03080] [00:06:37/00:31:58, 0.752s/it]: train_loss_raw=0.4976, running_loss=0.4859, LR=0.000100
[2025-08-27 10:23:36,362][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059056] [Batch 00536/03080] [00:06:43/00:31:53, 0.752s/it]: train_loss_raw=0.4616, running_loss=0.4862, LR=0.000100
[2025-08-27 10:23:42,466][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059064] [Batch 00544/03080] [00:06:49/00:31:48, 0.752s/it]: train_loss_raw=0.5125, running_loss=0.4877, LR=0.000100
[2025-08-27 10:23:48,546][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059072] [Batch 00552/03080] [00:06:55/00:31:42, 0.753s/it]: train_loss_raw=0.5079, running_loss=0.4861, LR=0.000100
[2025-08-27 10:23:54,644][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059080] [Batch 00560/03080] [00:07:01/00:31:36, 0.753s/it]: train_loss_raw=0.4416, running_loss=0.4847, LR=0.000100
[2025-08-27 10:24:00,767][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059088] [Batch 00568/03080] [00:07:07/00:31:31, 0.753s/it]: train_loss_raw=0.4001, running_loss=0.4835, LR=0.000100
[2025-08-27 10:24:06,779][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059096] [Batch 00576/03080] [00:07:13/00:31:25, 0.753s/it]: train_loss_raw=0.4252, running_loss=0.4831, LR=0.000100
[2025-08-27 10:24:12,760][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059104] [Batch 00584/03080] [00:07:19/00:31:18, 0.753s/it]: train_loss_raw=0.4036, running_loss=0.4828, LR=0.000100
[2025-08-27 10:24:18,907][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059112] [Batch 00592/03080] [00:07:25/00:31:13, 0.753s/it]: train_loss_raw=0.5494, running_loss=0.4839, LR=0.000100
[2025-08-27 10:24:25,007][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059120] [Batch 00600/03080] [00:07:31/00:31:07, 0.753s/it]: train_loss_raw=0.4127, running_loss=0.4817, LR=0.000100
[2025-08-27 10:24:31,025][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059128] [Batch 00608/03080] [00:07:37/00:31:01, 0.753s/it]: train_loss_raw=0.5241, running_loss=0.4823, LR=0.000100
[2025-08-27 10:24:37,228][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059136] [Batch 00616/03080] [00:07:44/00:30:56, 0.753s/it]: train_loss_raw=0.4160, running_loss=0.4813, LR=0.000100
[2025-08-27 10:24:43,324][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059144] [Batch 00624/03080] [00:07:50/00:30:50, 0.753s/it]: train_loss_raw=0.4492, running_loss=0.4833, LR=0.000100
[2025-08-27 10:24:49,375][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059152] [Batch 00632/03080] [00:07:56/00:30:44, 0.754s/it]: train_loss_raw=0.4545, running_loss=0.4827, LR=0.000100
[2025-08-27 10:24:55,552][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059160] [Batch 00640/03080] [00:08:02/00:30:39, 0.754s/it]: train_loss_raw=0.5017, running_loss=0.4837, LR=0.000100
[2025-08-27 10:25:01,502][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059168] [Batch 00648/03080] [00:08:08/00:30:32, 0.754s/it]: train_loss_raw=0.5623, running_loss=0.4856, LR=0.000100
[2025-08-27 10:25:07,437][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059176] [Batch 00656/03080] [00:08:14/00:30:26, 0.753s/it]: train_loss_raw=0.4894, running_loss=0.4873, LR=0.000100
[2025-08-27 10:25:12,837][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059184] [Batch 00664/03080] [00:08:19/00:30:18, 0.753s/it]: train_loss_raw=0.5321, running_loss=0.4883, LR=0.000100
[2025-08-27 10:25:18,772][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059192] [Batch 00672/03080] [00:08:25/00:30:11, 0.752s/it]: train_loss_raw=0.4162, running_loss=0.4871, LR=0.000100
[2025-08-27 10:25:24,740][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059200] [Batch 00680/03080] [00:08:31/00:30:05, 0.752s/it]: train_loss_raw=0.4396, running_loss=0.4852, LR=0.000100
[2025-08-27 10:25:30,662][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059208] [Batch 00688/03080] [00:08:37/00:29:59, 0.752s/it]: train_loss_raw=0.4340, running_loss=0.4851, LR=0.000100
[2025-08-27 10:25:36,648][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059216] [Batch 00696/03080] [00:08:43/00:29:53, 0.752s/it]: train_loss_raw=0.4485, running_loss=0.4848, LR=0.000100
[2025-08-27 10:25:42,601][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059224] [Batch 00704/03080] [00:08:49/00:29:46, 0.752s/it]: train_loss_raw=0.4780, running_loss=0.4832, LR=0.000100
[2025-08-27 10:25:48,636][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059232] [Batch 00712/03080] [00:08:55/00:29:40, 0.752s/it]: train_loss_raw=0.4922, running_loss=0.4856, LR=0.000100
[2025-08-27 10:25:54,402][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059240] [Batch 00720/03080] [00:09:01/00:29:34, 0.752s/it]: train_loss_raw=0.4434, running_loss=0.4838, LR=0.000100
[2025-08-27 10:26:00,370][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059248] [Batch 00728/03080] [00:09:07/00:29:27, 0.752s/it]: train_loss_raw=0.4729, running_loss=0.4815, LR=0.000100
[2025-08-27 10:26:06,385][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059256] [Batch 00736/03080] [00:09:13/00:29:21, 0.752s/it]: train_loss_raw=0.4552, running_loss=0.4830, LR=0.000100
[2025-08-27 10:26:12,378][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059264] [Batch 00744/03080] [00:09:19/00:29:15, 0.752s/it]: train_loss_raw=0.4894, running_loss=0.4825, LR=0.000100
[2025-08-27 10:26:18,096][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059272] [Batch 00752/03080] [00:09:24/00:29:08, 0.751s/it]: train_loss_raw=0.4249, running_loss=0.4823, LR=0.000100
[2025-08-27 10:26:23,650][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059280] [Batch 00760/03080] [00:09:30/00:29:01, 0.751s/it]: train_loss_raw=0.5081, running_loss=0.4806, LR=0.000100
[2025-08-27 10:26:29,040][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059288] [Batch 00768/03080] [00:09:35/00:28:53, 0.750s/it]: train_loss_raw=0.4112, running_loss=0.4804, LR=0.000100
[2025-08-27 10:26:34,662][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059296] [Batch 00776/03080] [00:09:41/00:28:46, 0.749s/it]: train_loss_raw=0.5480, running_loss=0.4810, LR=0.000100
[2025-08-27 10:26:40,509][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059304] [Batch 00784/03080] [00:09:47/00:28:40, 0.749s/it]: train_loss_raw=0.4979, running_loss=0.4832, LR=0.000100
[2025-08-27 10:26:46,464][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059312] [Batch 00792/03080] [00:09:53/00:28:34, 0.749s/it]: train_loss_raw=0.5395, running_loss=0.4838, LR=0.000100
[2025-08-27 10:26:52,151][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059320] [Batch 00800/03080] [00:09:58/00:28:27, 0.749s/it]: train_loss_raw=0.4918, running_loss=0.4833, LR=0.000100
[2025-08-27 10:26:58,228][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059328] [Batch 00808/03080] [00:10:05/00:28:21, 0.749s/it]: train_loss_raw=0.4971, running_loss=0.4848, LR=0.000100
[2025-08-27 10:27:03,955][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059336] [Batch 00816/03080] [00:10:10/00:28:14, 0.749s/it]: train_loss_raw=0.4624, running_loss=0.4823, LR=0.000100
[2025-08-27 10:27:09,576][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059344] [Batch 00824/03080] [00:10:16/00:28:07, 0.748s/it]: train_loss_raw=0.5224, running_loss=0.4822, LR=0.000100
[2025-08-27 10:27:15,542][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059352] [Batch 00832/03080] [00:10:22/00:28:01, 0.748s/it]: train_loss_raw=0.4415, running_loss=0.4818, LR=0.000100
[2025-08-27 10:27:21,547][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059360] [Batch 00840/03080] [00:10:28/00:27:55, 0.748s/it]: train_loss_raw=0.4951, running_loss=0.4820, LR=0.000100
[2025-08-27 10:27:27,447][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059368] [Batch 00848/03080] [00:10:34/00:27:49, 0.748s/it]: train_loss_raw=0.4778, running_loss=0.4818, LR=0.000100
[2025-08-27 10:27:33,427][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059376] [Batch 00856/03080] [00:10:40/00:27:43, 0.748s/it]: train_loss_raw=0.5028, running_loss=0.4822, LR=0.000100
[2025-08-27 10:27:39,411][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059384] [Batch 00864/03080] [00:10:46/00:27:37, 0.748s/it]: train_loss_raw=0.5341, running_loss=0.4824, LR=0.000100
[2025-08-27 10:27:45,445][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059392] [Batch 00872/03080] [00:10:52/00:27:31, 0.748s/it]: train_loss_raw=0.4755, running_loss=0.4812, LR=0.000100
[2025-08-27 10:27:51,429][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059400] [Batch 00880/03080] [00:10:58/00:27:25, 0.748s/it]: train_loss_raw=0.4914, running_loss=0.4803, LR=0.000100
[2025-08-27 10:27:57,430][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059408] [Batch 00888/03080] [00:11:04/00:27:19, 0.748s/it]: train_loss_raw=0.4450, running_loss=0.4804, LR=0.000100
[2025-08-27 10:28:03,436][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059416] [Batch 00896/03080] [00:11:10/00:27:13, 0.748s/it]: train_loss_raw=0.4656, running_loss=0.4813, LR=0.000100
[2025-08-27 10:28:09,438][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059424] [Batch 00904/03080] [00:11:16/00:27:07, 0.748s/it]: train_loss_raw=0.4396, running_loss=0.4802, LR=0.000100
[2025-08-27 10:28:15,469][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059432] [Batch 00912/03080] [00:11:22/00:27:01, 0.748s/it]: train_loss_raw=0.5249, running_loss=0.4806, LR=0.000100
[2025-08-27 10:28:21,433][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059440] [Batch 00920/03080] [00:11:28/00:26:55, 0.748s/it]: train_loss_raw=0.3802, running_loss=0.4777, LR=0.000100
[2025-08-27 10:28:27,400][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059448] [Batch 00928/03080] [00:11:34/00:26:49, 0.748s/it]: train_loss_raw=0.5734, running_loss=0.4774, LR=0.000100
[2025-08-27 10:28:33,404][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059456] [Batch 00936/03080] [00:11:40/00:26:43, 0.748s/it]: train_loss_raw=0.3631, running_loss=0.4759, LR=0.000100
[2025-08-27 10:28:39,410][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059464] [Batch 00944/03080] [00:11:46/00:26:38, 0.748s/it]: train_loss_raw=0.4423, running_loss=0.4761, LR=0.000100
[2025-08-27 10:28:45,375][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059472] [Batch 00952/03080] [00:11:52/00:26:32, 0.748s/it]: train_loss_raw=0.5585, running_loss=0.4771, LR=0.000100
[2025-08-27 10:28:51,372][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059480] [Batch 00960/03080] [00:11:58/00:26:26, 0.748s/it]: train_loss_raw=0.4521, running_loss=0.4790, LR=0.000100
[2025-08-27 10:28:57,348][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059488] [Batch 00968/03080] [00:12:04/00:26:20, 0.748s/it]: train_loss_raw=0.4161, running_loss=0.4784, LR=0.000100
[2025-08-27 10:29:03,362][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059496] [Batch 00976/03080] [00:12:10/00:26:14, 0.748s/it]: train_loss_raw=0.5044, running_loss=0.4773, LR=0.000100
[2025-08-27 10:29:09,315][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059504] [Batch 00984/03080] [00:12:16/00:26:08, 0.748s/it]: train_loss_raw=0.5079, running_loss=0.4775, LR=0.000100
[2025-08-27 10:29:15,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059512] [Batch 00992/03080] [00:12:22/00:26:02, 0.748s/it]: train_loss_raw=0.5099, running_loss=0.4779, LR=0.000100
[2025-08-27 10:29:21,255][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059520] [Batch 01000/03080] [00:12:28/00:25:56, 0.748s/it]: train_loss_raw=0.4471, running_loss=0.4772, LR=0.000100
[2025-08-27 10:29:27,273][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059528] [Batch 01008/03080] [00:12:34/00:25:50, 0.748s/it]: train_loss_raw=0.5522, running_loss=0.4763, LR=0.000100
[2025-08-27 10:29:33,291][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059536] [Batch 01016/03080] [00:12:40/00:25:44, 0.748s/it]: train_loss_raw=0.4351, running_loss=0.4755, LR=0.000100
[2025-08-27 10:29:39,290][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059544] [Batch 01024/03080] [00:12:46/00:25:38, 0.748s/it]: train_loss_raw=0.4377, running_loss=0.4744, LR=0.000100
[2025-08-27 10:29:45,285][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059552] [Batch 01032/03080] [00:12:52/00:25:32, 0.748s/it]: train_loss_raw=0.3915, running_loss=0.4741, LR=0.000100
[2025-08-27 10:29:51,316][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059560] [Batch 01040/03080] [00:12:58/00:25:26, 0.748s/it]: train_loss_raw=0.4974, running_loss=0.4752, LR=0.000100
[2025-08-27 10:29:57,273][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059568] [Batch 01048/03080] [00:13:04/00:25:20, 0.748s/it]: train_loss_raw=0.5482, running_loss=0.4780, LR=0.000100
[2025-08-27 10:30:03,273][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059576] [Batch 01056/03080] [00:13:10/00:25:14, 0.748s/it]: train_loss_raw=0.4600, running_loss=0.4775, LR=0.000100
[2025-08-27 10:30:09,288][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059584] [Batch 01064/03080] [00:13:16/00:25:08, 0.748s/it]: train_loss_raw=0.5368, running_loss=0.4794, LR=0.000100
[2025-08-27 10:30:15,314][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059592] [Batch 01072/03080] [00:13:22/00:25:02, 0.748s/it]: train_loss_raw=0.5000, running_loss=0.4809, LR=0.000100
[2025-08-27 10:30:21,302][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059600] [Batch 01080/03080] [00:13:28/00:24:56, 0.748s/it]: train_loss_raw=0.5377, running_loss=0.4808, LR=0.000100
[2025-08-27 10:30:27,301][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059608] [Batch 01088/03080] [00:13:34/00:24:50, 0.748s/it]: train_loss_raw=0.4485, running_loss=0.4818, LR=0.000100
[2025-08-27 10:30:33,274][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059616] [Batch 01096/03080] [00:13:40/00:24:44, 0.748s/it]: train_loss_raw=0.5436, running_loss=0.4840, LR=0.000100
[2025-08-27 10:30:39,291][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059624] [Batch 01104/03080] [00:13:46/00:24:38, 0.748s/it]: train_loss_raw=0.4340, running_loss=0.4828, LR=0.000100
[2025-08-27 10:30:45,431][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059632] [Batch 01112/03080] [00:13:52/00:24:32, 0.748s/it]: train_loss_raw=0.4759, running_loss=0.4829, LR=0.000100
[2025-08-27 10:30:51,243][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059640] [Batch 01120/03080] [00:13:58/00:24:26, 0.748s/it]: train_loss_raw=0.4730, running_loss=0.4852, LR=0.000100
[2025-08-27 10:30:57,196][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059648] [Batch 01128/03080] [00:14:04/00:24:20, 0.748s/it]: train_loss_raw=0.4490, running_loss=0.4855, LR=0.000100
[2025-08-27 10:31:03,151][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059656] [Batch 01136/03080] [00:14:09/00:24:14, 0.748s/it]: train_loss_raw=0.4031, running_loss=0.4829, LR=0.000100
[2025-08-27 10:31:09,114][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059664] [Batch 01144/03080] [00:14:15/00:24:08, 0.748s/it]: train_loss_raw=0.5411, running_loss=0.4834, LR=0.000100
[2025-08-27 10:31:15,120][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059672] [Batch 01152/03080] [00:14:21/00:24:02, 0.748s/it]: train_loss_raw=0.4574, running_loss=0.4830, LR=0.000100
[2025-08-27 10:31:21,122][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059680] [Batch 01160/03080] [00:14:27/00:23:56, 0.748s/it]: train_loss_raw=0.4764, running_loss=0.4838, LR=0.000100
[2025-08-27 10:31:27,182][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059688] [Batch 01168/03080] [00:14:34/00:23:50, 0.748s/it]: train_loss_raw=0.4753, running_loss=0.4831, LR=0.000100
[2025-08-27 10:31:33,374][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059696] [Batch 01176/03080] [00:14:40/00:23:45, 0.748s/it]: train_loss_raw=0.5430, running_loss=0.4844, LR=0.000100
[2025-08-27 10:31:39,466][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059704] [Batch 01184/03080] [00:14:46/00:23:39, 0.749s/it]: train_loss_raw=0.6223, running_loss=0.4835, LR=0.000100
[2025-08-27 10:31:45,549][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059712] [Batch 01192/03080] [00:14:52/00:23:33, 0.749s/it]: train_loss_raw=0.4036, running_loss=0.4832, LR=0.000100
[2025-08-27 10:31:51,591][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059720] [Batch 01200/03080] [00:14:58/00:23:27, 0.749s/it]: train_loss_raw=0.5011, running_loss=0.4851, LR=0.000100
[2025-08-27 10:31:57,679][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059728] [Batch 01208/03080] [00:15:04/00:23:21, 0.749s/it]: train_loss_raw=0.4121, running_loss=0.4838, LR=0.000100
[2025-08-27 10:32:03,726][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059736] [Batch 01216/03080] [00:15:10/00:23:15, 0.749s/it]: train_loss_raw=0.4690, running_loss=0.4854, LR=0.000100
[2025-08-27 10:32:09,751][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059744] [Batch 01224/03080] [00:15:16/00:23:09, 0.749s/it]: train_loss_raw=0.4011, running_loss=0.4843, LR=0.000100
[2025-08-27 10:32:15,497][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059752] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=0.5423, running_loss=0.4839, LR=0.000100
[2025-08-27 10:32:21,054][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059760] [Batch 01240/03080] [00:15:27/00:22:56, 0.748s/it]: train_loss_raw=0.5432, running_loss=0.4865, LR=0.000100
[2025-08-27 10:32:26,641][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059768] [Batch 01248/03080] [00:15:33/00:22:50, 0.748s/it]: train_loss_raw=0.4904, running_loss=0.4858, LR=0.000100
[2025-08-27 10:32:32,656][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059776] [Batch 01256/03080] [00:15:39/00:22:44, 0.748s/it]: train_loss_raw=0.4738, running_loss=0.4865, LR=0.000100
[2025-08-27 10:32:38,632][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059784] [Batch 01264/03080] [00:15:45/00:22:38, 0.748s/it]: train_loss_raw=0.4906, running_loss=0.4870, LR=0.000100
[2025-08-27 10:32:44,469][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059792] [Batch 01272/03080] [00:15:51/00:22:32, 0.748s/it]: train_loss_raw=0.4247, running_loss=0.4868, LR=0.000100
[2025-08-27 10:32:49,924][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059800] [Batch 01280/03080] [00:15:56/00:22:25, 0.747s/it]: train_loss_raw=0.4746, running_loss=0.4863, LR=0.000100
[2025-08-27 10:32:55,772][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059808] [Batch 01288/03080] [00:16:02/00:22:19, 0.747s/it]: train_loss_raw=0.5129, running_loss=0.4858, LR=0.000100
[2025-08-27 10:33:01,761][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059816] [Batch 01296/03080] [00:16:08/00:22:13, 0.747s/it]: train_loss_raw=0.4503, running_loss=0.4847, LR=0.000100
[2025-08-27 10:33:07,723][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059824] [Batch 01304/03080] [00:16:14/00:22:07, 0.747s/it]: train_loss_raw=0.5007, running_loss=0.4833, LR=0.000100
[2025-08-27 10:33:13,816][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059832] [Batch 01312/03080] [00:16:20/00:22:01, 0.747s/it]: train_loss_raw=0.4818, running_loss=0.4814, LR=0.000100
[2025-08-27 10:33:19,810][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059840] [Batch 01320/03080] [00:16:26/00:21:55, 0.747s/it]: train_loss_raw=0.4150, running_loss=0.4817, LR=0.000100
[2025-08-27 10:33:25,858][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059848] [Batch 01328/03080] [00:16:32/00:21:49, 0.748s/it]: train_loss_raw=0.4615, running_loss=0.4786, LR=0.000100
[2025-08-27 10:33:31,846][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059856] [Batch 01336/03080] [00:16:38/00:21:43, 0.748s/it]: train_loss_raw=0.4594, running_loss=0.4778, LR=0.000100
[2025-08-27 10:33:37,908][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059864] [Batch 01344/03080] [00:16:44/00:21:37, 0.748s/it]: train_loss_raw=0.4531, running_loss=0.4776, LR=0.000100
[2025-08-27 10:33:43,905][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059872] [Batch 01352/03080] [00:16:50/00:21:31, 0.748s/it]: train_loss_raw=0.5083, running_loss=0.4791, LR=0.000100
[2025-08-27 10:33:49,890][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059880] [Batch 01360/03080] [00:16:56/00:21:25, 0.748s/it]: train_loss_raw=0.4585, running_loss=0.4807, LR=0.000100
[2025-08-27 10:33:55,891][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059888] [Batch 01368/03080] [00:17:02/00:21:19, 0.748s/it]: train_loss_raw=0.4211, running_loss=0.4790, LR=0.000100
[2025-08-27 10:34:01,964][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059896] [Batch 01376/03080] [00:17:08/00:21:14, 0.748s/it]: train_loss_raw=0.4640, running_loss=0.4806, LR=0.000100
[2025-08-27 10:34:07,912][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059904] [Batch 01384/03080] [00:17:14/00:21:08, 0.748s/it]: train_loss_raw=0.4348, running_loss=0.4794, LR=0.000100
[2025-08-27 10:34:13,769][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059912] [Batch 01392/03080] [00:17:20/00:21:01, 0.748s/it]: train_loss_raw=0.5255, running_loss=0.4798, LR=0.000100
[2025-08-27 10:34:19,741][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059920] [Batch 01400/03080] [00:17:26/00:20:55, 0.748s/it]: train_loss_raw=0.4477, running_loss=0.4822, LR=0.000100
[2025-08-27 10:34:25,776][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059928] [Batch 01408/03080] [00:17:32/00:20:49, 0.748s/it]: train_loss_raw=0.4618, running_loss=0.4828, LR=0.000100
[2025-08-27 10:34:31,779][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059936] [Batch 01416/03080] [00:17:38/00:20:44, 0.748s/it]: train_loss_raw=0.4628, running_loss=0.4841, LR=0.000100
[2025-08-27 10:34:37,962][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059944] [Batch 01424/03080] [00:17:44/00:20:38, 0.748s/it]: train_loss_raw=0.4968, running_loss=0.4836, LR=0.000100
[2025-08-27 10:34:44,074][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059952] [Batch 01432/03080] [00:17:50/00:20:32, 0.748s/it]: train_loss_raw=0.4984, running_loss=0.4845, LR=0.000100
[2025-08-27 10:34:49,770][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059960] [Batch 01440/03080] [00:17:56/00:20:26, 0.748s/it]: train_loss_raw=0.4490, running_loss=0.4839, LR=0.000100
[2025-08-27 10:34:55,268][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059968] [Batch 01448/03080] [00:18:02/00:20:19, 0.747s/it]: train_loss_raw=0.5351, running_loss=0.4830, LR=0.000100
[2025-08-27 10:35:01,416][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059976] [Batch 01456/03080] [00:18:08/00:20:13, 0.747s/it]: train_loss_raw=0.4587, running_loss=0.4831, LR=0.000100
[2025-08-27 10:35:07,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059984] [Batch 01464/03080] [00:18:14/00:20:07, 0.747s/it]: train_loss_raw=0.4692, running_loss=0.4807, LR=0.000100
[2025-08-27 10:35:13,220][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 059992] [Batch 01472/03080] [00:18:20/00:20:01, 0.747s/it]: train_loss_raw=0.5163, running_loss=0.4801, LR=0.000100
[2025-08-27 10:35:19,171][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060000] [Batch 01480/03080] [00:18:26/00:19:55, 0.747s/it]: train_loss_raw=0.3650, running_loss=0.4772, LR=0.000100
[2025-08-27 10:35:28,588][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060008] [Batch 01488/03080] [00:18:35/00:19:53, 0.750s/it]: train_loss_raw=0.4452, running_loss=0.4771, LR=0.000100
[2025-08-27 10:35:34,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060016] [Batch 01496/03080] [00:18:41/00:19:47, 0.750s/it]: train_loss_raw=0.4780, running_loss=0.4766, LR=0.000100
[2025-08-27 10:35:40,654][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060024] [Batch 01504/03080] [00:18:47/00:19:41, 0.750s/it]: train_loss_raw=0.4974, running_loss=0.4771, LR=0.000100
[2025-08-27 10:35:46,642][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060032] [Batch 01512/03080] [00:18:53/00:19:35, 0.750s/it]: train_loss_raw=0.4563, running_loss=0.4776, LR=0.000100
[2025-08-27 10:35:52,650][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060040] [Batch 01520/03080] [00:18:59/00:19:29, 0.750s/it]: train_loss_raw=0.4764, running_loss=0.4781, LR=0.000100
[2025-08-27 10:35:58,620][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060048] [Batch 01528/03080] [00:19:05/00:19:23, 0.750s/it]: train_loss_raw=0.5940, running_loss=0.4794, LR=0.000100
[2025-08-27 10:36:04,628][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060056] [Batch 01536/03080] [00:19:11/00:19:17, 0.750s/it]: train_loss_raw=0.4714, running_loss=0.4791, LR=0.000100
[2025-08-27 10:36:10,605][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060064] [Batch 01544/03080] [00:19:17/00:19:11, 0.750s/it]: train_loss_raw=0.5471, running_loss=0.4786, LR=0.000100
[2025-08-27 10:36:16,635][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060072] [Batch 01552/03080] [00:19:23/00:19:05, 0.750s/it]: train_loss_raw=0.5144, running_loss=0.4781, LR=0.000100
[2025-08-27 10:36:22,592][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060080] [Batch 01560/03080] [00:19:29/00:18:59, 0.750s/it]: train_loss_raw=0.4838, running_loss=0.4769, LR=0.000100
[2025-08-27 10:36:28,654][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060088] [Batch 01568/03080] [00:19:35/00:18:53, 0.750s/it]: train_loss_raw=0.4509, running_loss=0.4762, LR=0.000100
[2025-08-27 10:36:34,542][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060096] [Batch 01576/03080] [00:19:41/00:18:47, 0.750s/it]: train_loss_raw=0.5251, running_loss=0.4759, LR=0.000100
[2025-08-27 10:36:40,319][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060104] [Batch 01584/03080] [00:19:47/00:18:41, 0.749s/it]: train_loss_raw=0.4591, running_loss=0.4752, LR=0.000100
[2025-08-27 10:36:45,941][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060112] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=0.3822, running_loss=0.4753, LR=0.000100
[2025-08-27 10:36:51,510][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060120] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=0.3845, running_loss=0.4735, LR=0.000100
[2025-08-27 10:36:57,204][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060128] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=0.5048, running_loss=0.4734, LR=0.000100
[2025-08-27 10:37:03,171][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060136] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=0.4766, running_loss=0.4728, LR=0.000100
[2025-08-27 10:37:09,110][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060144] [Batch 01624/03080] [00:20:15/00:18:10, 0.749s/it]: train_loss_raw=0.5385, running_loss=0.4725, LR=0.000100
[2025-08-27 10:37:15,113][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060152] [Batch 01632/03080] [00:20:21/00:18:04, 0.749s/it]: train_loss_raw=0.4830, running_loss=0.4754, LR=0.000100
[2025-08-27 10:37:21,100][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060160] [Batch 01640/03080] [00:20:27/00:17:58, 0.749s/it]: train_loss_raw=0.4297, running_loss=0.4742, LR=0.000100
[2025-08-27 10:37:27,063][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060168] [Batch 01648/03080] [00:20:33/00:17:52, 0.749s/it]: train_loss_raw=0.4410, running_loss=0.4759, LR=0.000100
[2025-08-27 10:37:33,030][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060176] [Batch 01656/03080] [00:20:39/00:17:46, 0.749s/it]: train_loss_raw=0.4841, running_loss=0.4756, LR=0.000100
[2025-08-27 10:37:38,935][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060184] [Batch 01664/03080] [00:20:45/00:17:40, 0.749s/it]: train_loss_raw=0.4965, running_loss=0.4760, LR=0.000100
[2025-08-27 10:37:44,908][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060192] [Batch 01672/03080] [00:20:51/00:17:34, 0.749s/it]: train_loss_raw=0.4237, running_loss=0.4728, LR=0.000100
[2025-08-27 10:37:50,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060200] [Batch 01680/03080] [00:20:57/00:17:28, 0.749s/it]: train_loss_raw=0.5631, running_loss=0.4742, LR=0.000100
[2025-08-27 10:37:56,907][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060208] [Batch 01688/03080] [00:21:03/00:17:22, 0.749s/it]: train_loss_raw=0.4559, running_loss=0.4737, LR=0.000100
[2025-08-27 10:38:02,957][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060216] [Batch 01696/03080] [00:21:09/00:17:16, 0.749s/it]: train_loss_raw=0.4982, running_loss=0.4741, LR=0.000100
[2025-08-27 10:38:08,974][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060224] [Batch 01704/03080] [00:21:15/00:17:10, 0.749s/it]: train_loss_raw=0.4644, running_loss=0.4750, LR=0.000100
[2025-08-27 10:38:14,992][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060232] [Batch 01712/03080] [00:21:21/00:17:04, 0.749s/it]: train_loss_raw=0.5153, running_loss=0.4752, LR=0.000100
[2025-08-27 10:38:21,002][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060240] [Batch 01720/03080] [00:21:27/00:16:58, 0.749s/it]: train_loss_raw=0.4586, running_loss=0.4732, LR=0.000100
[2025-08-27 10:38:27,019][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060248] [Batch 01728/03080] [00:21:33/00:16:52, 0.749s/it]: train_loss_raw=0.5089, running_loss=0.4715, LR=0.000100
[2025-08-27 10:38:33,012][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060256] [Batch 01736/03080] [00:21:39/00:16:46, 0.749s/it]: train_loss_raw=0.5488, running_loss=0.4741, LR=0.000100
[2025-08-27 10:38:39,041][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060264] [Batch 01744/03080] [00:21:45/00:16:40, 0.749s/it]: train_loss_raw=0.5586, running_loss=0.4754, LR=0.000100
[2025-08-27 10:38:45,028][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060272] [Batch 01752/03080] [00:21:51/00:16:34, 0.749s/it]: train_loss_raw=0.4607, running_loss=0.4764, LR=0.000100
[2025-08-27 10:38:51,040][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060280] [Batch 01760/03080] [00:21:57/00:16:28, 0.749s/it]: train_loss_raw=0.3899, running_loss=0.4755, LR=0.000100
[2025-08-27 10:38:57,051][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060288] [Batch 01768/03080] [00:22:03/00:16:22, 0.749s/it]: train_loss_raw=0.5550, running_loss=0.4774, LR=0.000100
[2025-08-27 10:39:03,057][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060296] [Batch 01776/03080] [00:22:09/00:16:16, 0.749s/it]: train_loss_raw=0.5536, running_loss=0.4770, LR=0.000100
[2025-08-27 10:39:09,111][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060304] [Batch 01784/03080] [00:22:15/00:16:10, 0.749s/it]: train_loss_raw=0.5538, running_loss=0.4772, LR=0.000100
[2025-08-27 10:39:15,133][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060312] [Batch 01792/03080] [00:22:21/00:16:04, 0.749s/it]: train_loss_raw=0.4317, running_loss=0.4788, LR=0.000100
[2025-08-27 10:39:21,121][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060320] [Batch 01800/03080] [00:22:27/00:15:58, 0.749s/it]: train_loss_raw=0.4396, running_loss=0.4771, LR=0.000100
[2025-08-27 10:39:27,131][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060328] [Batch 01808/03080] [00:22:33/00:15:52, 0.749s/it]: train_loss_raw=0.5173, running_loss=0.4781, LR=0.000100
[2025-08-27 10:39:33,168][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060336] [Batch 01816/03080] [00:22:40/00:15:46, 0.749s/it]: train_loss_raw=0.5431, running_loss=0.4772, LR=0.000100
[2025-08-27 10:39:39,175][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060344] [Batch 01824/03080] [00:22:46/00:15:40, 0.749s/it]: train_loss_raw=0.4397, running_loss=0.4746, LR=0.000100
[2025-08-27 10:39:45,187][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060352] [Batch 01832/03080] [00:22:52/00:15:34, 0.749s/it]: train_loss_raw=0.5247, running_loss=0.4759, LR=0.000100
[2025-08-27 10:39:51,076][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060360] [Batch 01840/03080] [00:22:57/00:15:28, 0.749s/it]: train_loss_raw=0.4678, running_loss=0.4758, LR=0.000100
[2025-08-27 10:39:57,057][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060368] [Batch 01848/03080] [00:23:03/00:15:22, 0.749s/it]: train_loss_raw=0.4377, running_loss=0.4759, LR=0.000100
[2025-08-27 10:40:02,780][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060376] [Batch 01856/03080] [00:23:09/00:15:16, 0.749s/it]: train_loss_raw=0.4182, running_loss=0.4745, LR=0.000100
[2025-08-27 10:40:08,706][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060384] [Batch 01864/03080] [00:23:15/00:15:10, 0.749s/it]: train_loss_raw=0.4354, running_loss=0.4698, LR=0.000100
[2025-08-27 10:40:14,750][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060392] [Batch 01872/03080] [00:23:21/00:15:04, 0.749s/it]: train_loss_raw=0.4484, running_loss=0.4703, LR=0.000100
[2025-08-27 10:40:20,848][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060400] [Batch 01880/03080] [00:23:27/00:14:58, 0.749s/it]: train_loss_raw=0.4364, running_loss=0.4699, LR=0.000100
[2025-08-27 10:40:26,856][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060408] [Batch 01888/03080] [00:23:33/00:14:52, 0.749s/it]: train_loss_raw=0.4908, running_loss=0.4708, LR=0.000100
[2025-08-27 10:40:32,908][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060416] [Batch 01896/03080] [00:23:39/00:14:46, 0.749s/it]: train_loss_raw=0.5848, running_loss=0.4708, LR=0.000100
[2025-08-27 10:40:38,894][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060424] [Batch 01904/03080] [00:23:45/00:14:40, 0.749s/it]: train_loss_raw=0.5509, running_loss=0.4713, LR=0.000100
[2025-08-27 10:40:44,899][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060432] [Batch 01912/03080] [00:23:51/00:14:34, 0.749s/it]: train_loss_raw=0.4717, running_loss=0.4701, LR=0.000100
[2025-08-27 10:40:50,837][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060440] [Batch 01920/03080] [00:23:57/00:14:28, 0.749s/it]: train_loss_raw=0.4465, running_loss=0.4708, LR=0.000100
[2025-08-27 10:40:56,839][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060448] [Batch 01928/03080] [00:24:03/00:14:22, 0.749s/it]: train_loss_raw=0.3831, running_loss=0.4704, LR=0.000100
[2025-08-27 10:41:02,860][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060456] [Batch 01936/03080] [00:24:09/00:14:16, 0.749s/it]: train_loss_raw=0.4359, running_loss=0.4705, LR=0.000100
[2025-08-27 10:41:08,978][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060464] [Batch 01944/03080] [00:24:15/00:14:10, 0.749s/it]: train_loss_raw=0.4396, running_loss=0.4698, LR=0.000100
[2025-08-27 10:41:15,004][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060472] [Batch 01952/03080] [00:24:21/00:14:04, 0.749s/it]: train_loss_raw=0.4481, running_loss=0.4698, LR=0.000100
[2025-08-27 10:41:21,169][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060480] [Batch 01960/03080] [00:24:28/00:13:58, 0.749s/it]: train_loss_raw=0.4843, running_loss=0.4702, LR=0.000100
[2025-08-27 10:41:27,396][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060488] [Batch 01968/03080] [00:24:34/00:13:53, 0.749s/it]: train_loss_raw=0.4280, running_loss=0.4708, LR=0.000100
[2025-08-27 10:41:33,471][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060496] [Batch 01976/03080] [00:24:40/00:13:47, 0.749s/it]: train_loss_raw=0.4085, running_loss=0.4695, LR=0.000100
[2025-08-27 10:41:39,475][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060504] [Batch 01984/03080] [00:24:46/00:13:41, 0.749s/it]: train_loss_raw=0.5118, running_loss=0.4699, LR=0.000100
[2025-08-27 10:41:45,446][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060512] [Batch 01992/03080] [00:24:52/00:13:35, 0.749s/it]: train_loss_raw=0.5110, running_loss=0.4699, LR=0.000100
[2025-08-27 10:41:51,383][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060520] [Batch 02000/03080] [00:24:58/00:13:29, 0.749s/it]: train_loss_raw=0.5258, running_loss=0.4678, LR=0.000100
[2025-08-27 10:41:57,320][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060528] [Batch 02008/03080] [00:25:04/00:13:23, 0.749s/it]: train_loss_raw=0.5634, running_loss=0.4693, LR=0.000100
[2025-08-27 10:42:03,307][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060536] [Batch 02016/03080] [00:25:10/00:13:17, 0.749s/it]: train_loss_raw=0.4477, running_loss=0.4693, LR=0.000100
[2025-08-27 10:42:09,282][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060544] [Batch 02024/03080] [00:25:16/00:13:11, 0.749s/it]: train_loss_raw=0.4631, running_loss=0.4664, LR=0.000100
[2025-08-27 10:42:15,308][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060552] [Batch 02032/03080] [00:25:22/00:13:05, 0.749s/it]: train_loss_raw=0.4916, running_loss=0.4684, LR=0.000100
[2025-08-27 10:42:21,365][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060560] [Batch 02040/03080] [00:25:28/00:12:59, 0.749s/it]: train_loss_raw=0.5642, running_loss=0.4705, LR=0.000100
[2025-08-27 10:42:27,400][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060568] [Batch 02048/03080] [00:25:34/00:12:53, 0.749s/it]: train_loss_raw=0.5225, running_loss=0.4731, LR=0.000100
[2025-08-27 10:42:33,404][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060576] [Batch 02056/03080] [00:25:40/00:12:47, 0.749s/it]: train_loss_raw=0.5210, running_loss=0.4761, LR=0.000100
[2025-08-27 10:42:39,388][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060584] [Batch 02064/03080] [00:25:46/00:12:41, 0.749s/it]: train_loss_raw=0.5682, running_loss=0.4779, LR=0.000100
[2025-08-27 10:42:45,448][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060592] [Batch 02072/03080] [00:25:52/00:12:35, 0.749s/it]: train_loss_raw=0.4781, running_loss=0.4770, LR=0.000100
[2025-08-27 10:42:51,524][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060600] [Batch 02080/03080] [00:25:58/00:12:29, 0.749s/it]: train_loss_raw=0.4900, running_loss=0.4779, LR=0.000100
[2025-08-27 10:42:57,563][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060608] [Batch 02088/03080] [00:26:04/00:12:23, 0.749s/it]: train_loss_raw=0.5147, running_loss=0.4769, LR=0.000100
[2025-08-27 10:43:03,624][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060616] [Batch 02096/03080] [00:26:10/00:12:17, 0.749s/it]: train_loss_raw=0.4590, running_loss=0.4769, LR=0.000100
[2025-08-27 10:43:09,625][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060624] [Batch 02104/03080] [00:26:16/00:12:11, 0.749s/it]: train_loss_raw=0.4930, running_loss=0.4771, LR=0.000100
[2025-08-27 10:43:15,628][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060632] [Batch 02112/03080] [00:26:22/00:12:05, 0.749s/it]: train_loss_raw=0.4331, running_loss=0.4789, LR=0.000100
[2025-08-27 10:43:21,649][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060640] [Batch 02120/03080] [00:26:28/00:11:59, 0.749s/it]: train_loss_raw=0.3935, running_loss=0.4764, LR=0.000100
[2025-08-27 10:43:27,709][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060648] [Batch 02128/03080] [00:26:34/00:11:53, 0.749s/it]: train_loss_raw=0.4727, running_loss=0.4777, LR=0.000100
[2025-08-27 10:43:33,737][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060656] [Batch 02136/03080] [00:26:40/00:11:47, 0.749s/it]: train_loss_raw=0.5214, running_loss=0.4804, LR=0.000100
[2025-08-27 10:43:39,736][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060664] [Batch 02144/03080] [00:26:46/00:11:41, 0.749s/it]: train_loss_raw=0.4321, running_loss=0.4775, LR=0.000100
[2025-08-27 10:43:45,791][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060672] [Batch 02152/03080] [00:26:52/00:11:35, 0.749s/it]: train_loss_raw=0.3951, running_loss=0.4777, LR=0.000100
[2025-08-27 10:43:51,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060680] [Batch 02160/03080] [00:26:58/00:11:29, 0.749s/it]: train_loss_raw=0.5146, running_loss=0.4775, LR=0.000100
[2025-08-27 10:43:58,209][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060688] [Batch 02168/03080] [00:27:05/00:11:23, 0.750s/it]: train_loss_raw=0.5788, running_loss=0.4794, LR=0.000100
[2025-08-27 10:44:04,105][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060696] [Batch 02176/03080] [00:27:10/00:11:17, 0.750s/it]: train_loss_raw=0.4649, running_loss=0.4785, LR=0.000100
[2025-08-27 10:44:09,801][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060704] [Batch 02184/03080] [00:27:16/00:11:11, 0.749s/it]: train_loss_raw=0.4540, running_loss=0.4780, LR=0.000100
[2025-08-27 10:44:15,805][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060712] [Batch 02192/03080] [00:27:22/00:11:05, 0.749s/it]: train_loss_raw=0.4336, running_loss=0.4780, LR=0.000100
[2025-08-27 10:44:21,837][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060720] [Batch 02200/03080] [00:27:28/00:10:59, 0.749s/it]: train_loss_raw=0.4772, running_loss=0.4779, LR=0.000100
[2025-08-27 10:44:27,921][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060728] [Batch 02208/03080] [00:27:34/00:10:53, 0.749s/it]: train_loss_raw=0.4304, running_loss=0.4788, LR=0.000100
[2025-08-27 10:44:33,923][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060736] [Batch 02216/03080] [00:27:40/00:10:47, 0.749s/it]: train_loss_raw=0.4363, running_loss=0.4777, LR=0.000100
[2025-08-27 10:44:40,013][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060744] [Batch 02224/03080] [00:27:46/00:10:41, 0.749s/it]: train_loss_raw=0.4888, running_loss=0.4788, LR=0.000100
[2025-08-27 10:44:46,107][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060752] [Batch 02232/03080] [00:27:52/00:10:35, 0.750s/it]: train_loss_raw=0.4665, running_loss=0.4787, LR=0.000100
[2025-08-27 10:44:52,244][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060760] [Batch 02240/03080] [00:27:59/00:10:29, 0.750s/it]: train_loss_raw=0.4940, running_loss=0.4767, LR=0.000100
[2025-08-27 10:44:58,483][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060768] [Batch 02248/03080] [00:28:05/00:10:23, 0.750s/it]: train_loss_raw=0.5960, running_loss=0.4780, LR=0.000100
[2025-08-27 10:45:04,594][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060776] [Batch 02256/03080] [00:28:11/00:10:17, 0.750s/it]: train_loss_raw=0.4390, running_loss=0.4741, LR=0.000100
[2025-08-27 10:45:10,768][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060784] [Batch 02264/03080] [00:28:17/00:10:11, 0.750s/it]: train_loss_raw=0.4302, running_loss=0.4744, LR=0.000100
[2025-08-27 10:45:16,990][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060792] [Batch 02272/03080] [00:28:23/00:10:05, 0.750s/it]: train_loss_raw=0.5457, running_loss=0.4746, LR=0.000100
[2025-08-27 10:45:23,248][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060800] [Batch 02280/03080] [00:28:30/00:10:00, 0.750s/it]: train_loss_raw=0.6126, running_loss=0.4768, LR=0.000100
[2025-08-27 10:45:29,378][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060808] [Batch 02288/03080] [00:28:36/00:09:54, 0.750s/it]: train_loss_raw=0.4837, running_loss=0.4757, LR=0.000100
[2025-08-27 10:45:35,406][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060816] [Batch 02296/03080] [00:28:42/00:09:48, 0.750s/it]: train_loss_raw=0.5122, running_loss=0.4766, LR=0.000100
[2025-08-27 10:45:41,540][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060824] [Batch 02304/03080] [00:28:48/00:09:42, 0.750s/it]: train_loss_raw=0.3678, running_loss=0.4750, LR=0.000100
[2025-08-27 10:45:47,587][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060832] [Batch 02312/03080] [00:28:54/00:09:36, 0.750s/it]: train_loss_raw=0.4313, running_loss=0.4752, LR=0.000100
[2025-08-27 10:45:53,560][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060840] [Batch 02320/03080] [00:29:00/00:09:30, 0.750s/it]: train_loss_raw=0.4380, running_loss=0.4750, LR=0.000100
[2025-08-27 10:45:59,625][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060848] [Batch 02328/03080] [00:29:06/00:09:24, 0.750s/it]: train_loss_raw=0.4501, running_loss=0.4745, LR=0.000100
[2025-08-27 10:46:05,857][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060856] [Batch 02336/03080] [00:29:12/00:09:18, 0.750s/it]: train_loss_raw=0.4918, running_loss=0.4724, LR=0.000100
[2025-08-27 10:46:11,720][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060864] [Batch 02344/03080] [00:29:18/00:09:12, 0.750s/it]: train_loss_raw=0.4130, running_loss=0.4714, LR=0.000100
[2025-08-27 10:46:17,652][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060872] [Batch 02352/03080] [00:29:24/00:09:06, 0.750s/it]: train_loss_raw=0.3898, running_loss=0.4699, LR=0.000100
[2025-08-27 10:46:23,201][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060880] [Batch 02360/03080] [00:29:30/00:09:00, 0.750s/it]: train_loss_raw=0.5306, running_loss=0.4714, LR=0.000100
[2025-08-27 10:46:29,061][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060888] [Batch 02368/03080] [00:29:35/00:08:53, 0.750s/it]: train_loss_raw=0.5868, running_loss=0.4720, LR=0.000100
[2025-08-27 10:46:34,923][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060896] [Batch 02376/03080] [00:29:41/00:08:47, 0.750s/it]: train_loss_raw=0.4006, running_loss=0.4714, LR=0.000100
[2025-08-27 10:46:40,653][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060904] [Batch 02384/03080] [00:29:47/00:08:41, 0.750s/it]: train_loss_raw=0.5495, running_loss=0.4740, LR=0.000100
[2025-08-27 10:46:46,201][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060912] [Batch 02392/03080] [00:29:53/00:08:35, 0.750s/it]: train_loss_raw=0.4707, running_loss=0.4728, LR=0.000100
[2025-08-27 10:46:52,073][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060920] [Batch 02400/03080] [00:29:58/00:08:29, 0.750s/it]: train_loss_raw=0.4985, running_loss=0.4722, LR=0.000100
[2025-08-27 10:46:57,874][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060928] [Batch 02408/03080] [00:30:04/00:08:23, 0.749s/it]: train_loss_raw=0.4123, running_loss=0.4711, LR=0.000100
[2025-08-27 10:47:03,671][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060936] [Batch 02416/03080] [00:30:10/00:08:17, 0.749s/it]: train_loss_raw=0.5541, running_loss=0.4711, LR=0.000100
[2025-08-27 10:47:09,651][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060944] [Batch 02424/03080] [00:30:16/00:08:11, 0.749s/it]: train_loss_raw=0.5299, running_loss=0.4709, LR=0.000100
[2025-08-27 10:47:15,821][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060952] [Batch 02432/03080] [00:30:22/00:08:05, 0.749s/it]: train_loss_raw=0.4680, running_loss=0.4720, LR=0.000100
[2025-08-27 10:47:21,974][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060960] [Batch 02440/03080] [00:30:28/00:07:59, 0.750s/it]: train_loss_raw=0.3276, running_loss=0.4705, LR=0.000100
[2025-08-27 10:47:27,793][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060968] [Batch 02448/03080] [00:30:34/00:07:53, 0.749s/it]: train_loss_raw=0.5430, running_loss=0.4710, LR=0.000100
[2025-08-27 10:47:33,627][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060976] [Batch 02456/03080] [00:30:40/00:07:47, 0.749s/it]: train_loss_raw=0.4856, running_loss=0.4739, LR=0.000100
[2025-08-27 10:47:39,573][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060984] [Batch 02464/03080] [00:30:46/00:07:41, 0.749s/it]: train_loss_raw=0.4411, running_loss=0.4743, LR=0.000100
[2025-08-27 10:47:45,420][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 060992] [Batch 02472/03080] [00:30:52/00:07:35, 0.749s/it]: train_loss_raw=0.4619, running_loss=0.4740, LR=0.000100
[2025-08-27 10:47:51,391][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061000] [Batch 02480/03080] [00:30:58/00:07:29, 0.749s/it]: train_loss_raw=0.5640, running_loss=0.4762, LR=0.000100
[2025-08-27 10:47:57,271][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061008] [Batch 02488/03080] [00:31:04/00:07:23, 0.749s/it]: train_loss_raw=0.4928, running_loss=0.4779, LR=0.000100
[2025-08-27 10:48:03,050][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061016] [Batch 02496/03080] [00:31:09/00:07:17, 0.749s/it]: train_loss_raw=0.5257, running_loss=0.4787, LR=0.000100
[2025-08-27 10:48:08,858][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061024] [Batch 02504/03080] [00:31:15/00:07:11, 0.749s/it]: train_loss_raw=0.4002, running_loss=0.4746, LR=0.000100
[2025-08-27 10:48:14,680][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061032] [Batch 02512/03080] [00:31:21/00:07:05, 0.749s/it]: train_loss_raw=0.4568, running_loss=0.4751, LR=0.000100
[2025-08-27 10:48:20,518][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061040] [Batch 02520/03080] [00:31:27/00:06:59, 0.749s/it]: train_loss_raw=0.5229, running_loss=0.4749, LR=0.000100
[2025-08-27 10:48:26,516][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061048] [Batch 02528/03080] [00:31:33/00:06:53, 0.749s/it]: train_loss_raw=0.4849, running_loss=0.4748, LR=0.000100
[2025-08-27 10:48:32,445][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061056] [Batch 02536/03080] [00:31:39/00:06:47, 0.749s/it]: train_loss_raw=0.4274, running_loss=0.4737, LR=0.000100
[2025-08-27 10:48:38,387][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061064] [Batch 02544/03080] [00:31:45/00:06:41, 0.749s/it]: train_loss_raw=0.4365, running_loss=0.4743, LR=0.000100
[2025-08-27 10:48:44,312][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061072] [Batch 02552/03080] [00:31:51/00:06:35, 0.749s/it]: train_loss_raw=0.5009, running_loss=0.4752, LR=0.000100
[2025-08-27 10:48:50,179][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061080] [Batch 02560/03080] [00:31:57/00:06:29, 0.749s/it]: train_loss_raw=0.4475, running_loss=0.4745, LR=0.000100
[2025-08-27 10:48:56,042][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061088] [Batch 02568/03080] [00:32:02/00:06:23, 0.749s/it]: train_loss_raw=0.5073, running_loss=0.4749, LR=0.000100
[2025-08-27 10:49:02,034][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061096] [Batch 02576/03080] [00:32:08/00:06:17, 0.749s/it]: train_loss_raw=0.4353, running_loss=0.4749, LR=0.000100
[2025-08-27 10:49:07,838][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061104] [Batch 02584/03080] [00:32:14/00:06:11, 0.749s/it]: train_loss_raw=0.4239, running_loss=0.4762, LR=0.000100
[2025-08-27 10:49:13,863][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061112] [Batch 02592/03080] [00:32:20/00:06:05, 0.749s/it]: train_loss_raw=0.4652, running_loss=0.4768, LR=0.000100
[2025-08-27 10:49:19,810][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061120] [Batch 02600/03080] [00:32:26/00:05:59, 0.749s/it]: train_loss_raw=0.4650, running_loss=0.4781, LR=0.000100
[2025-08-27 10:49:25,703][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061128] [Batch 02608/03080] [00:32:32/00:05:53, 0.749s/it]: train_loss_raw=0.4647, running_loss=0.4775, LR=0.000100
[2025-08-27 10:49:31,585][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061136] [Batch 02616/03080] [00:32:38/00:05:47, 0.749s/it]: train_loss_raw=0.4481, running_loss=0.4759, LR=0.000100
[2025-08-27 10:49:37,542][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061144] [Batch 02624/03080] [00:32:44/00:05:41, 0.749s/it]: train_loss_raw=0.4939, running_loss=0.4749, LR=0.000100
[2025-08-27 10:49:43,417][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061152] [Batch 02632/03080] [00:32:50/00:05:35, 0.749s/it]: train_loss_raw=0.3801, running_loss=0.4733, LR=0.000100
[2025-08-27 10:49:49,163][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061160] [Batch 02640/03080] [00:32:56/00:05:29, 0.748s/it]: train_loss_raw=0.4667, running_loss=0.4707, LR=0.000100
[2025-08-27 10:49:55,007][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061168] [Batch 02648/03080] [00:33:01/00:05:23, 0.748s/it]: train_loss_raw=0.4234, running_loss=0.4692, LR=0.000100
[2025-08-27 10:50:01,069][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061176] [Batch 02656/03080] [00:33:07/00:05:17, 0.748s/it]: train_loss_raw=0.4491, running_loss=0.4693, LR=0.000100
[2025-08-27 10:50:07,073][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061184] [Batch 02664/03080] [00:33:13/00:05:11, 0.748s/it]: train_loss_raw=0.4729, running_loss=0.4675, LR=0.000100
[2025-08-27 10:50:13,093][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061192] [Batch 02672/03080] [00:33:19/00:05:05, 0.748s/it]: train_loss_raw=0.5247, running_loss=0.4699, LR=0.000100
[2025-08-27 10:50:19,276][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061200] [Batch 02680/03080] [00:33:26/00:04:59, 0.749s/it]: train_loss_raw=0.5655, running_loss=0.4699, LR=0.000100
[2025-08-27 10:50:25,114][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061208] [Batch 02688/03080] [00:33:31/00:04:53, 0.748s/it]: train_loss_raw=0.4238, running_loss=0.4714, LR=0.000100
[2025-08-27 10:50:30,822][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061216] [Batch 02696/03080] [00:33:37/00:04:47, 0.748s/it]: train_loss_raw=0.4889, running_loss=0.4715, LR=0.000100
[2025-08-27 10:50:36,376][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061224] [Batch 02704/03080] [00:33:43/00:04:41, 0.748s/it]: train_loss_raw=0.4219, running_loss=0.4703, LR=0.000100
[2025-08-27 10:50:42,100][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061232] [Batch 02712/03080] [00:33:48/00:04:35, 0.748s/it]: train_loss_raw=0.4802, running_loss=0.4706, LR=0.000100
[2025-08-27 10:50:48,085][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061240] [Batch 02720/03080] [00:33:54/00:04:29, 0.748s/it]: train_loss_raw=0.4564, running_loss=0.4723, LR=0.000100
[2025-08-27 10:50:53,888][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061248] [Batch 02728/03080] [00:34:00/00:04:23, 0.748s/it]: train_loss_raw=0.4520, running_loss=0.4731, LR=0.000100
[2025-08-27 10:50:59,751][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061256] [Batch 02736/03080] [00:34:06/00:04:17, 0.748s/it]: train_loss_raw=0.4754, running_loss=0.4709, LR=0.000100
[2025-08-27 10:51:05,742][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061264] [Batch 02744/03080] [00:34:12/00:04:11, 0.748s/it]: train_loss_raw=0.3508, running_loss=0.4686, LR=0.000100
[2025-08-27 10:51:11,696][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061272] [Batch 02752/03080] [00:34:18/00:04:05, 0.748s/it]: train_loss_raw=0.3934, running_loss=0.4686, LR=0.000100
[2025-08-27 10:51:17,715][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061280] [Batch 02760/03080] [00:34:24/00:03:59, 0.748s/it]: train_loss_raw=0.4426, running_loss=0.4679, LR=0.000100
[2025-08-27 10:51:23,765][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061288] [Batch 02768/03080] [00:34:30/00:03:53, 0.748s/it]: train_loss_raw=0.4020, running_loss=0.4655, LR=0.000100
[2025-08-27 10:51:29,867][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061296] [Batch 02776/03080] [00:34:36/00:03:47, 0.748s/it]: train_loss_raw=0.4772, running_loss=0.4664, LR=0.000100
[2025-08-27 10:51:35,930][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061304] [Batch 02784/03080] [00:34:42/00:03:41, 0.748s/it]: train_loss_raw=0.4895, running_loss=0.4643, LR=0.000100
[2025-08-27 10:51:41,930][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061312] [Batch 02792/03080] [00:34:48/00:03:35, 0.748s/it]: train_loss_raw=0.3601, running_loss=0.4621, LR=0.000100
[2025-08-27 10:51:48,011][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061320] [Batch 02800/03080] [00:34:54/00:03:29, 0.748s/it]: train_loss_raw=0.4293, running_loss=0.4638, LR=0.000100
[2025-08-27 10:51:54,011][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061328] [Batch 02808/03080] [00:35:00/00:03:23, 0.748s/it]: train_loss_raw=0.3530, running_loss=0.4652, LR=0.000100
[2025-08-27 10:52:00,150][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061336] [Batch 02816/03080] [00:35:06/00:03:17, 0.748s/it]: train_loss_raw=0.4826, running_loss=0.4680, LR=0.000100
[2025-08-27 10:52:06,171][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061344] [Batch 02824/03080] [00:35:13/00:03:11, 0.748s/it]: train_loss_raw=0.4985, running_loss=0.4694, LR=0.000100
[2025-08-27 10:52:12,237][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061352] [Batch 02832/03080] [00:35:19/00:03:05, 0.748s/it]: train_loss_raw=0.4552, running_loss=0.4683, LR=0.000100
[2025-08-27 10:52:18,539][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061360] [Batch 02840/03080] [00:35:25/00:02:59, 0.748s/it]: train_loss_raw=0.5716, running_loss=0.4688, LR=0.000100
[2025-08-27 10:52:24,284][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061368] [Batch 02848/03080] [00:35:31/00:02:53, 0.748s/it]: train_loss_raw=0.4382, running_loss=0.4678, LR=0.000100
[2025-08-27 10:52:30,263][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061376] [Batch 02856/03080] [00:35:37/00:02:47, 0.748s/it]: train_loss_raw=0.4107, running_loss=0.4687, LR=0.000100
[2025-08-27 10:52:36,271][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061384] [Batch 02864/03080] [00:35:43/00:02:41, 0.748s/it]: train_loss_raw=0.5707, running_loss=0.4707, LR=0.000100
[2025-08-27 10:52:42,289][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061392] [Batch 02872/03080] [00:35:49/00:02:35, 0.748s/it]: train_loss_raw=0.4520, running_loss=0.4696, LR=0.000100
[2025-08-27 10:52:48,334][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061400] [Batch 02880/03080] [00:35:55/00:02:29, 0.748s/it]: train_loss_raw=0.5085, running_loss=0.4693, LR=0.000100
[2025-08-27 10:52:54,416][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061408] [Batch 02888/03080] [00:36:01/00:02:23, 0.748s/it]: train_loss_raw=0.4549, running_loss=0.4695, LR=0.000100
[2025-08-27 10:53:00,611][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061416] [Batch 02896/03080] [00:36:07/00:02:17, 0.748s/it]: train_loss_raw=0.3771, running_loss=0.4680, LR=0.000100
[2025-08-27 10:53:06,860][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061424] [Batch 02904/03080] [00:36:13/00:02:11, 0.749s/it]: train_loss_raw=0.4818, running_loss=0.4656, LR=0.000100
[2025-08-27 10:53:12,917][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061432] [Batch 02912/03080] [00:36:19/00:02:05, 0.749s/it]: train_loss_raw=0.4152, running_loss=0.4651, LR=0.000100
[2025-08-27 10:53:18,954][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061440] [Batch 02920/03080] [00:36:25/00:01:59, 0.749s/it]: train_loss_raw=0.4457, running_loss=0.4638, LR=0.000100
[2025-08-27 10:53:25,074][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061448] [Batch 02928/03080] [00:36:31/00:01:53, 0.749s/it]: train_loss_raw=0.4497, running_loss=0.4651, LR=0.000100
[2025-08-27 10:53:31,142][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061456] [Batch 02936/03080] [00:36:37/00:01:47, 0.749s/it]: train_loss_raw=0.4769, running_loss=0.4660, LR=0.000100
[2025-08-27 10:53:37,172][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061464] [Batch 02944/03080] [00:36:44/00:01:41, 0.749s/it]: train_loss_raw=0.4625, running_loss=0.4661, LR=0.000100
[2025-08-27 10:53:43,215][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061472] [Batch 02952/03080] [00:36:50/00:01:35, 0.749s/it]: train_loss_raw=0.4717, running_loss=0.4675, LR=0.000100
[2025-08-27 10:53:49,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061480] [Batch 02960/03080] [00:36:56/00:01:29, 0.749s/it]: train_loss_raw=0.4945, running_loss=0.4671, LR=0.000100
[2025-08-27 10:53:55,265][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061488] [Batch 02968/03080] [00:37:02/00:01:23, 0.749s/it]: train_loss_raw=0.4304, running_loss=0.4664, LR=0.000100
[2025-08-27 10:54:01,458][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061496] [Batch 02976/03080] [00:37:08/00:01:17, 0.749s/it]: train_loss_raw=0.4371, running_loss=0.4652, LR=0.000100
[2025-08-27 10:54:07,513][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061504] [Batch 02984/03080] [00:37:14/00:01:11, 0.749s/it]: train_loss_raw=0.4559, running_loss=0.4636, LR=0.000100
[2025-08-27 10:54:13,548][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061512] [Batch 02992/03080] [00:37:20/00:01:05, 0.749s/it]: train_loss_raw=0.4063, running_loss=0.4625, LR=0.000100
[2025-08-27 10:54:19,633][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061520] [Batch 03000/03080] [00:37:26/00:00:59, 0.749s/it]: train_loss_raw=0.4049, running_loss=0.4630, LR=0.000100
[2025-08-27 10:54:25,677][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061528] [Batch 03008/03080] [00:37:32/00:00:53, 0.749s/it]: train_loss_raw=0.4485, running_loss=0.4621, LR=0.000100
[2025-08-27 10:54:31,832][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061536] [Batch 03016/03080] [00:37:38/00:00:47, 0.749s/it]: train_loss_raw=0.3741, running_loss=0.4603, LR=0.000100
[2025-08-27 10:54:37,911][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061544] [Batch 03024/03080] [00:37:44/00:00:41, 0.749s/it]: train_loss_raw=0.4965, running_loss=0.4611, LR=0.000100
[2025-08-27 10:54:43,968][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061552] [Batch 03032/03080] [00:37:50/00:00:35, 0.749s/it]: train_loss_raw=0.4579, running_loss=0.4614, LR=0.000100
[2025-08-27 10:54:49,982][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061560] [Batch 03040/03080] [00:37:56/00:00:29, 0.749s/it]: train_loss_raw=0.4079, running_loss=0.4616, LR=0.000100
[2025-08-27 10:54:56,158][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061568] [Batch 03048/03080] [00:38:03/00:00:23, 0.749s/it]: train_loss_raw=0.3896, running_loss=0.4603, LR=0.000100
[2025-08-27 10:55:02,220][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061576] [Batch 03056/03080] [00:38:09/00:00:17, 0.749s/it]: train_loss_raw=0.4116, running_loss=0.4591, LR=0.000100
[2025-08-27 10:55:08,203][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061584] [Batch 03064/03080] [00:38:15/00:00:11, 0.749s/it]: train_loss_raw=0.4959, running_loss=0.4607, LR=0.000100
[2025-08-27 10:55:14,246][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061592] [Batch 03072/03080] [00:38:21/00:00:05, 0.749s/it]: train_loss_raw=0.5305, running_loss=0.4632, LR=0.000100
[2025-08-27 10:55:25,222][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 061600] [Batch 03080/03080] [00:38:32/00:00:00, 0.751s/it]: train_loss_raw=0.4251, running_loss=0.4632, LR=0.000100
[2025-08-27 10:55:25,741][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-27 10:55:37,215][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00007/00310] [00:00:11/00:07:13, 1.434s/it]
[2025-08-27 10:55:48,718][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00015/00310] [00:00:22/00:07:02, 1.436s/it]
[2025-08-27 10:56:01,262][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00023/00310] [00:00:35/00:07:03, 1.480s/it]
[2025-08-27 10:56:13,573][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00031/00310] [00:00:47/00:06:55, 1.495s/it]
[2025-08-27 10:56:25,957][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00039/00310] [00:01:00/00:06:46, 1.505s/it]
[2025-08-27 10:56:38,247][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00047/00310] [00:01:12/00:06:35, 1.511s/it]
[2025-08-27 10:56:50,152][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00055/00310] [00:01:24/00:06:22, 1.507s/it]
[2025-08-27 10:57:02,339][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00063/00310] [00:01:36/00:06:11, 1.509s/it]
[2025-08-27 10:57:14,594][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00071/00310] [00:01:48/00:05:59, 1.512s/it]
[2025-08-27 10:57:26,893][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00079/00310] [00:02:01/00:05:48, 1.514s/it]
[2025-08-27 10:57:39,595][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00087/00310] [00:02:13/00:05:37, 1.521s/it]
[2025-08-27 10:57:52,479][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00095/00310] [00:02:26/00:05:27, 1.529s/it]
[2025-08-27 10:58:05,439][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00103/00310] [00:02:39/00:05:16, 1.536s/it]
[2025-08-27 10:58:17,720][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00111/00310] [00:02:51/00:05:04, 1.536s/it]
[2025-08-27 10:58:29,355][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00119/00310] [00:03:03/00:04:50, 1.530s/it]
[2025-08-27 10:58:41,008][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00127/00310] [00:03:15/00:04:37, 1.526s/it]
[2025-08-27 10:58:53,428][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00135/00310] [00:03:27/00:04:25, 1.527s/it]
[2025-08-27 10:59:05,892][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00143/00310] [00:03:40/00:04:13, 1.529s/it]
[2025-08-27 10:59:17,572][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00151/00310] [00:03:51/00:04:00, 1.525s/it]
[2025-08-27 10:59:28,521][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00159/00310] [00:04:02/00:03:47, 1.517s/it]
[2025-08-27 10:59:40,884][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00167/00310] [00:04:15/00:03:35, 1.519s/it]
[2025-08-27 10:59:51,600][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00175/00310] [00:04:25/00:03:22, 1.511s/it]
[2025-08-27 11:00:02,900][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00183/00310] [00:04:37/00:03:09, 1.506s/it]
[2025-08-27 11:00:14,975][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00191/00310] [00:04:49/00:02:57, 1.506s/it]
[2025-08-27 11:00:27,255][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00199/00310] [00:05:01/00:02:45, 1.508s/it]
[2025-08-27 11:00:37,506][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00207/00310] [00:05:11/00:02:32, 1.499s/it]
[2025-08-27 11:00:47,492][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00215/00310] [00:05:21/00:02:20, 1.490s/it]
[2025-08-27 11:00:59,856][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00223/00310] [00:05:34/00:02:08, 1.492s/it]
[2025-08-27 11:01:12,741][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00231/00310] [00:05:47/00:01:56, 1.496s/it]
[2025-08-27 11:01:23,299][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00239/00310] [00:05:57/00:01:44, 1.490s/it]
[2025-08-27 11:01:33,127][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00247/00310] [00:06:07/00:01:31, 1.481s/it]
[2025-08-27 11:01:44,283][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00255/00310] [00:06:18/00:01:19, 1.479s/it]
[2025-08-27 11:01:56,478][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00263/00310] [00:06:30/00:01:08, 1.480s/it]
[2025-08-27 11:02:08,576][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00271/00310] [00:06:42/00:00:56, 1.481s/it]
[2025-08-27 11:02:20,505][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00279/00310] [00:06:54/00:00:44, 1.481s/it]
[2025-08-27 11:02:32,276][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00287/00310] [00:07:06/00:00:32, 1.481s/it]
[2025-08-27 11:02:43,682][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00295/00310] [00:07:17/00:00:20, 1.480s/it]
[2025-08-27 11:02:55,674][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 061601] [Batch 00303/00310] [00:07:29/00:00:08, 1.480s/it]
[2025-08-27 11:03:05,035][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=0.46317, valid_loss=1.45593
[2025-08-27 11:03:05,035][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-27 11:03:05,036][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.521
[2025-08-27 11:03:05,036][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.124
[2025-08-27 11:03:05,036][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.126
[2025-08-27 11:03:05,036][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.065
[2025-08-27 11:03:05,048][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 15:36:18, remaining time 07:48:09, 00:46:48 per epoch
[2025-08-27 11:03:10,934][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061608] [Batch 00008/03080] [00:00:05/00:35:26, 0.692s/it]: train_loss_raw=0.4699, running_loss=0.4090, LR=0.000100
[2025-08-27 11:03:17,000][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061616] [Batch 00016/03080] [00:00:11/00:37:02, 0.725s/it]: train_loss_raw=0.4826, running_loss=0.4092, LR=0.000100
[2025-08-27 11:03:23,015][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061624] [Batch 00024/03080] [00:00:17/00:37:23, 0.734s/it]: train_loss_raw=0.4554, running_loss=0.4113, LR=0.000100
[2025-08-27 11:03:29,035][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061632] [Batch 00032/03080] [00:00:23/00:37:31, 0.739s/it]: train_loss_raw=0.3769, running_loss=0.4103, LR=0.000100
[2025-08-27 11:03:35,086][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061640] [Batch 00040/03080] [00:00:29/00:37:36, 0.742s/it]: train_loss_raw=0.4519, running_loss=0.4129, LR=0.000100
[2025-08-27 11:03:41,072][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061648] [Batch 00048/03080] [00:00:35/00:37:33, 0.743s/it]: train_loss_raw=0.4360, running_loss=0.4136, LR=0.000100
[2025-08-27 11:03:47,115][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061656] [Batch 00056/03080] [00:00:41/00:37:32, 0.745s/it]: train_loss_raw=0.4469, running_loss=0.4136, LR=0.000100
[2025-08-27 11:03:53,076][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061664] [Batch 00064/03080] [00:00:47/00:37:26, 0.745s/it]: train_loss_raw=0.5891, running_loss=0.4169, LR=0.000100
[2025-08-27 11:03:59,034][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061672] [Batch 00072/03080] [00:00:53/00:37:20, 0.745s/it]: train_loss_raw=0.3687, running_loss=0.4206, LR=0.000100
[2025-08-27 11:04:05,019][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061680] [Batch 00080/03080] [00:00:59/00:37:15, 0.745s/it]: train_loss_raw=0.4057, running_loss=0.4205, LR=0.000100
[2025-08-27 11:04:10,993][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061688] [Batch 00088/03080] [00:01:05/00:37:10, 0.745s/it]: train_loss_raw=0.4616, running_loss=0.4224, LR=0.000100
[2025-08-27 11:04:16,793][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061696] [Batch 00096/03080] [00:01:11/00:36:59, 0.744s/it]: train_loss_raw=0.4049, running_loss=0.4265, LR=0.000100
[2025-08-27 11:04:22,289][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061704] [Batch 00104/03080] [00:01:16/00:36:40, 0.739s/it]: train_loss_raw=0.4256, running_loss=0.4281, LR=0.000100
[2025-08-27 11:04:28,324][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061712] [Batch 00112/03080] [00:01:22/00:36:37, 0.740s/it]: train_loss_raw=0.5028, running_loss=0.4271, LR=0.000100
[2025-08-27 11:04:34,334][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061720] [Batch 00120/03080] [00:01:28/00:36:33, 0.741s/it]: train_loss_raw=0.4327, running_loss=0.4276, LR=0.000100
[2025-08-27 11:04:40,075][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061728] [Batch 00128/03080] [00:01:34/00:36:23, 0.740s/it]: train_loss_raw=0.4299, running_loss=0.4303, LR=0.000100
[2025-08-27 11:04:45,497][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061736] [Batch 00136/03080] [00:01:40/00:36:06, 0.736s/it]: train_loss_raw=0.5046, running_loss=0.4330, LR=0.000100
[2025-08-27 11:04:51,128][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061744] [Batch 00144/03080] [00:01:45/00:35:55, 0.734s/it]: train_loss_raw=0.4557, running_loss=0.4341, LR=0.000100
[2025-08-27 11:04:57,181][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061752] [Batch 00152/03080] [00:01:51/00:35:53, 0.735s/it]: train_loss_raw=0.5198, running_loss=0.4358, LR=0.000100
[2025-08-27 11:05:03,333][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061760] [Batch 00160/03080] [00:01:57/00:35:52, 0.737s/it]: train_loss_raw=0.5091, running_loss=0.4357, LR=0.000100
[2025-08-27 11:05:09,393][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061768] [Batch 00168/03080] [00:02:03/00:35:49, 0.738s/it]: train_loss_raw=0.4967, running_loss=0.4370, LR=0.000100
[2025-08-27 11:05:15,368][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061776] [Batch 00176/03080] [00:02:09/00:35:44, 0.738s/it]: train_loss_raw=0.4798, running_loss=0.4364, LR=0.000100
[2025-08-27 11:05:21,345][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061784] [Batch 00184/03080] [00:02:15/00:35:39, 0.739s/it]: train_loss_raw=0.5388, running_loss=0.4398, LR=0.000100
[2025-08-27 11:05:27,450][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061792] [Batch 00192/03080] [00:02:22/00:35:36, 0.740s/it]: train_loss_raw=0.4578, running_loss=0.4414, LR=0.000100
[2025-08-27 11:05:33,437][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061800] [Batch 00200/03080] [00:02:28/00:35:31, 0.740s/it]: train_loss_raw=0.4518, running_loss=0.4407, LR=0.000100
[2025-08-27 11:05:39,432][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061808] [Batch 00208/03080] [00:02:34/00:35:26, 0.741s/it]: train_loss_raw=0.4646, running_loss=0.4400, LR=0.000100
[2025-08-27 11:05:45,536][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061816] [Batch 00216/03080] [00:02:40/00:35:23, 0.741s/it]: train_loss_raw=0.4425, running_loss=0.4411, LR=0.000100
[2025-08-27 11:05:51,724][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061824] [Batch 00224/03080] [00:02:46/00:35:20, 0.743s/it]: train_loss_raw=0.4220, running_loss=0.4421, LR=0.000100
[2025-08-27 11:05:57,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061832] [Batch 00232/03080] [00:02:52/00:35:18, 0.744s/it]: train_loss_raw=0.4224, running_loss=0.4434, LR=0.000100
[2025-08-27 11:06:03,984][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061840] [Batch 00240/03080] [00:02:58/00:35:13, 0.744s/it]: train_loss_raw=0.4381, running_loss=0.4418, LR=0.000100
[2025-08-27 11:06:10,094][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061848] [Batch 00248/03080] [00:03:04/00:35:09, 0.745s/it]: train_loss_raw=0.4320, running_loss=0.4421, LR=0.000100
[2025-08-27 11:06:16,076][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061856] [Batch 00256/03080] [00:03:10/00:35:03, 0.745s/it]: train_loss_raw=0.3688, running_loss=0.4428, LR=0.000100
[2025-08-27 11:06:22,184][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061864] [Batch 00264/03080] [00:03:16/00:34:59, 0.745s/it]: train_loss_raw=0.4646, running_loss=0.4444, LR=0.000100
[2025-08-27 11:06:28,204][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061872] [Batch 00272/03080] [00:03:22/00:34:53, 0.746s/it]: train_loss_raw=0.4304, running_loss=0.4445, LR=0.000100
[2025-08-27 11:06:34,298][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061880] [Batch 00280/03080] [00:03:28/00:34:49, 0.746s/it]: train_loss_raw=0.4228, running_loss=0.4453, LR=0.000100
[2025-08-27 11:06:40,301][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061888] [Batch 00288/03080] [00:03:34/00:34:43, 0.746s/it]: train_loss_raw=0.3702, running_loss=0.4428, LR=0.000100
[2025-08-27 11:06:46,367][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061896] [Batch 00296/03080] [00:03:40/00:34:38, 0.747s/it]: train_loss_raw=0.5539, running_loss=0.4435, LR=0.000100
[2025-08-27 11:06:52,286][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061904] [Batch 00304/03080] [00:03:46/00:34:31, 0.746s/it]: train_loss_raw=0.4726, running_loss=0.4421, LR=0.000100
[2025-08-27 11:06:58,404][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061912] [Batch 00312/03080] [00:03:53/00:34:27, 0.747s/it]: train_loss_raw=0.4046, running_loss=0.4415, LR=0.000100
[2025-08-27 11:07:04,546][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061920] [Batch 00320/03080] [00:03:59/00:34:22, 0.747s/it]: train_loss_raw=0.4287, running_loss=0.4393, LR=0.000100
[2025-08-27 11:07:10,766][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061928] [Batch 00328/03080] [00:04:05/00:34:18, 0.748s/it]: train_loss_raw=0.3282, running_loss=0.4378, LR=0.000100
[2025-08-27 11:07:16,875][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061936] [Batch 00336/03080] [00:04:11/00:34:13, 0.748s/it]: train_loss_raw=0.5343, running_loss=0.4389, LR=0.000100
[2025-08-27 11:07:23,042][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061944] [Batch 00344/03080] [00:04:17/00:34:09, 0.749s/it]: train_loss_raw=0.4187, running_loss=0.4391, LR=0.000100
[2025-08-27 11:07:29,321][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061952] [Batch 00352/03080] [00:04:23/00:34:05, 0.750s/it]: train_loss_raw=0.4557, running_loss=0.4401, LR=0.000100
[2025-08-27 11:07:35,691][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061960] [Batch 00360/03080] [00:04:30/00:34:02, 0.751s/it]: train_loss_raw=0.4512, running_loss=0.4399, LR=0.000100
[2025-08-27 11:07:42,022][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061968] [Batch 00368/03080] [00:04:36/00:33:58, 0.752s/it]: train_loss_raw=0.4530, running_loss=0.4424, LR=0.000100
[2025-08-27 11:07:48,157][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061976] [Batch 00376/03080] [00:04:42/00:33:53, 0.752s/it]: train_loss_raw=0.4138, running_loss=0.4421, LR=0.000100
[2025-08-27 11:07:54,274][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061984] [Batch 00384/03080] [00:04:48/00:33:48, 0.752s/it]: train_loss_raw=0.5187, running_loss=0.4418, LR=0.000100
[2025-08-27 11:08:00,268][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 061992] [Batch 00392/03080] [00:04:54/00:33:41, 0.752s/it]: train_loss_raw=0.4702, running_loss=0.4421, LR=0.000100
[2025-08-27 11:08:06,332][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062000] [Batch 00400/03080] [00:05:00/00:33:36, 0.752s/it]: train_loss_raw=0.4738, running_loss=0.4430, LR=0.000100
[2025-08-27 11:08:15,928][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062008] [Batch 00408/03080] [00:05:10/00:33:53, 0.761s/it]: train_loss_raw=0.3983, running_loss=0.4419, LR=0.000100
[2025-08-27 11:08:21,824][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062016] [Batch 00416/03080] [00:05:16/00:33:46, 0.761s/it]: train_loss_raw=0.4375, running_loss=0.4429, LR=0.000100
[2025-08-27 11:08:27,599][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062024] [Batch 00424/03080] [00:05:22/00:33:38, 0.760s/it]: train_loss_raw=0.5215, running_loss=0.4426, LR=0.000100
[2025-08-27 11:08:33,672][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062032] [Batch 00432/03080] [00:05:28/00:33:32, 0.760s/it]: train_loss_raw=0.5101, running_loss=0.4416, LR=0.000100
[2025-08-27 11:08:39,769][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062040] [Batch 00440/03080] [00:05:34/00:33:26, 0.760s/it]: train_loss_raw=0.4622, running_loss=0.4452, LR=0.000100
[2025-08-27 11:08:45,806][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062048] [Batch 00448/03080] [00:05:40/00:33:19, 0.760s/it]: train_loss_raw=0.4846, running_loss=0.4470, LR=0.000100
[2025-08-27 11:08:51,726][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062056] [Batch 00456/03080] [00:05:46/00:33:12, 0.759s/it]: train_loss_raw=0.4240, running_loss=0.4485, LR=0.000100
[2025-08-27 11:08:57,976][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062064] [Batch 00464/03080] [00:05:52/00:33:07, 0.760s/it]: train_loss_raw=0.4431, running_loss=0.4485, LR=0.000100
[2025-08-27 11:09:04,022][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062072] [Batch 00472/03080] [00:05:58/00:33:01, 0.760s/it]: train_loss_raw=0.4899, running_loss=0.4492, LR=0.000100
[2025-08-27 11:09:10,139][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062080] [Batch 00480/03080] [00:06:04/00:32:55, 0.760s/it]: train_loss_raw=0.4701, running_loss=0.4494, LR=0.000100
[2025-08-27 11:09:16,265][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062088] [Batch 00488/03080] [00:06:10/00:32:49, 0.760s/it]: train_loss_raw=0.3878, running_loss=0.4489, LR=0.000100
[2025-08-27 11:09:22,271][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062096] [Batch 00496/03080] [00:06:16/00:32:43, 0.760s/it]: train_loss_raw=0.5505, running_loss=0.4513, LR=0.000100
[2025-08-27 11:09:28,285][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062104] [Batch 00504/03080] [00:06:22/00:32:36, 0.760s/it]: train_loss_raw=0.4556, running_loss=0.4512, LR=0.000100
[2025-08-27 11:09:34,351][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062112] [Batch 00512/03080] [00:06:28/00:32:30, 0.760s/it]: train_loss_raw=0.5400, running_loss=0.4503, LR=0.000100
[2025-08-27 11:09:40,343][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062120] [Batch 00520/03080] [00:06:34/00:32:24, 0.760s/it]: train_loss_raw=0.4431, running_loss=0.4463, LR=0.000100
[2025-08-27 11:09:46,330][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062128] [Batch 00528/03080] [00:06:40/00:32:17, 0.759s/it]: train_loss_raw=0.4591, running_loss=0.4478, LR=0.000100
[2025-08-27 11:09:52,311][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062136] [Batch 00536/03080] [00:06:46/00:32:11, 0.759s/it]: train_loss_raw=0.4458, running_loss=0.4474, LR=0.000100
[2025-08-27 11:09:58,288][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062144] [Batch 00544/03080] [00:06:52/00:32:04, 0.759s/it]: train_loss_raw=0.4534, running_loss=0.4467, LR=0.000100
[2025-08-27 11:10:04,329][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062152] [Batch 00552/03080] [00:06:58/00:31:58, 0.759s/it]: train_loss_raw=0.4397, running_loss=0.4474, LR=0.000100
[2025-08-27 11:10:10,395][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062160] [Batch 00560/03080] [00:07:04/00:31:52, 0.759s/it]: train_loss_raw=0.4326, running_loss=0.4479, LR=0.000100
[2025-08-27 11:10:16,322][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062168] [Batch 00568/03080] [00:07:10/00:31:45, 0.759s/it]: train_loss_raw=0.3895, running_loss=0.4467, LR=0.000100
[2025-08-27 11:10:22,333][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062176] [Batch 00576/03080] [00:07:16/00:31:39, 0.759s/it]: train_loss_raw=0.4067, running_loss=0.4461, LR=0.000100
[2025-08-27 11:10:28,334][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062184] [Batch 00584/03080] [00:07:22/00:31:33, 0.758s/it]: train_loss_raw=0.4229, running_loss=0.4461, LR=0.000100
[2025-08-27 11:10:34,472][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062192] [Batch 00592/03080] [00:07:29/00:31:27, 0.759s/it]: train_loss_raw=0.4637, running_loss=0.4434, LR=0.000100
[2025-08-27 11:10:40,420][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062200] [Batch 00600/03080] [00:07:35/00:31:20, 0.758s/it]: train_loss_raw=0.4504, running_loss=0.4431, LR=0.000100
[2025-08-27 11:10:46,469][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062208] [Batch 00608/03080] [00:07:41/00:31:14, 0.758s/it]: train_loss_raw=0.4503, running_loss=0.4460, LR=0.000100
[2025-08-27 11:10:52,504][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062216] [Batch 00616/03080] [00:07:47/00:31:08, 0.758s/it]: train_loss_raw=0.5016, running_loss=0.4441, LR=0.000100
[2025-08-27 11:10:58,551][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062224] [Batch 00624/03080] [00:07:53/00:31:02, 0.758s/it]: train_loss_raw=0.4075, running_loss=0.4454, LR=0.000100
[2025-08-27 11:11:04,709][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062232] [Batch 00632/03080] [00:07:59/00:30:56, 0.758s/it]: train_loss_raw=0.5664, running_loss=0.4457, LR=0.000100
[2025-08-27 11:11:10,872][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062240] [Batch 00640/03080] [00:08:05/00:30:50, 0.759s/it]: train_loss_raw=0.5371, running_loss=0.4478, LR=0.000100
[2025-08-27 11:11:16,866][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062248] [Batch 00648/03080] [00:08:11/00:30:44, 0.758s/it]: train_loss_raw=0.4278, running_loss=0.4465, LR=0.000100
[2025-08-27 11:11:22,981][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062256] [Batch 00656/03080] [00:08:17/00:30:38, 0.759s/it]: train_loss_raw=0.4706, running_loss=0.4471, LR=0.000100
[2025-08-27 11:11:29,154][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062264] [Batch 00664/03080] [00:08:23/00:30:32, 0.759s/it]: train_loss_raw=0.4417, running_loss=0.4478, LR=0.000100
[2025-08-27 11:11:35,200][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062272] [Batch 00672/03080] [00:08:29/00:30:26, 0.759s/it]: train_loss_raw=0.4364, running_loss=0.4477, LR=0.000100
[2025-08-27 11:11:41,233][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062280] [Batch 00680/03080] [00:08:35/00:30:20, 0.759s/it]: train_loss_raw=0.4489, running_loss=0.4474, LR=0.000100
[2025-08-27 11:11:47,136][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062288] [Batch 00688/03080] [00:08:41/00:30:13, 0.758s/it]: train_loss_raw=0.4315, running_loss=0.4464, LR=0.000100
[2025-08-27 11:11:53,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062296] [Batch 00696/03080] [00:08:47/00:30:07, 0.758s/it]: train_loss_raw=0.4149, running_loss=0.4435, LR=0.000100
[2025-08-27 11:11:59,303][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062304] [Batch 00704/03080] [00:08:53/00:30:01, 0.758s/it]: train_loss_raw=0.3630, running_loss=0.4434, LR=0.000100
[2025-08-27 11:12:05,325][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062312] [Batch 00712/03080] [00:08:59/00:29:55, 0.758s/it]: train_loss_raw=0.3980, running_loss=0.4402, LR=0.000100
[2025-08-27 11:12:11,423][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062320] [Batch 00720/03080] [00:09:06/00:29:49, 0.758s/it]: train_loss_raw=0.4060, running_loss=0.4403, LR=0.000100
[2025-08-27 11:12:17,600][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062328] [Batch 00728/03080] [00:09:12/00:29:44, 0.759s/it]: train_loss_raw=0.4371, running_loss=0.4415, LR=0.000100
[2025-08-27 11:12:23,578][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062336] [Batch 00736/03080] [00:09:18/00:29:37, 0.758s/it]: train_loss_raw=0.4372, running_loss=0.4404, LR=0.000100
[2025-08-27 11:12:29,702][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062344] [Batch 00744/03080] [00:09:24/00:29:31, 0.758s/it]: train_loss_raw=0.3981, running_loss=0.4420, LR=0.000100
[2025-08-27 11:12:35,735][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062352] [Batch 00752/03080] [00:09:30/00:29:25, 0.758s/it]: train_loss_raw=0.4448, running_loss=0.4435, LR=0.000100
[2025-08-27 11:12:41,836][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062360] [Batch 00760/03080] [00:09:36/00:29:19, 0.758s/it]: train_loss_raw=0.5655, running_loss=0.4445, LR=0.000100
[2025-08-27 11:12:47,779][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062368] [Batch 00768/03080] [00:09:42/00:29:13, 0.758s/it]: train_loss_raw=0.4916, running_loss=0.4457, LR=0.000100
[2025-08-27 11:12:53,879][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062376] [Batch 00776/03080] [00:09:48/00:29:07, 0.758s/it]: train_loss_raw=0.4146, running_loss=0.4466, LR=0.000100
[2025-08-27 11:12:59,974][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062384] [Batch 00784/03080] [00:09:54/00:29:01, 0.758s/it]: train_loss_raw=0.3426, running_loss=0.4432, LR=0.000100
[2025-08-27 11:13:06,043][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062392] [Batch 00792/03080] [00:10:00/00:28:55, 0.758s/it]: train_loss_raw=0.4382, running_loss=0.4410, LR=0.000100
[2025-08-27 11:13:12,165][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062400] [Batch 00800/03080] [00:10:06/00:28:49, 0.758s/it]: train_loss_raw=0.4288, running_loss=0.4434, LR=0.000100
[2025-08-27 11:13:18,252][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062408] [Batch 00808/03080] [00:10:12/00:28:43, 0.758s/it]: train_loss_raw=0.4499, running_loss=0.4433, LR=0.000100
[2025-08-27 11:13:24,244][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062416] [Batch 00816/03080] [00:10:18/00:28:37, 0.758s/it]: train_loss_raw=0.4952, running_loss=0.4452, LR=0.000100
[2025-08-27 11:13:30,209][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062424] [Batch 00824/03080] [00:10:24/00:28:30, 0.758s/it]: train_loss_raw=0.4950, running_loss=0.4471, LR=0.000100
[2025-08-27 11:13:36,189][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062432] [Batch 00832/03080] [00:10:30/00:28:24, 0.758s/it]: train_loss_raw=0.4688, running_loss=0.4455, LR=0.000100
[2025-08-27 11:13:42,143][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062440] [Batch 00840/03080] [00:10:36/00:28:17, 0.758s/it]: train_loss_raw=0.4335, running_loss=0.4446, LR=0.000100
[2025-08-27 11:13:48,145][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062448] [Batch 00848/03080] [00:10:42/00:28:11, 0.758s/it]: train_loss_raw=0.4432, running_loss=0.4453, LR=0.000100
[2025-08-27 11:13:54,124][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062456] [Batch 00856/03080] [00:10:48/00:28:05, 0.758s/it]: train_loss_raw=0.4607, running_loss=0.4478, LR=0.000100
[2025-08-27 11:14:00,198][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062464] [Batch 00864/03080] [00:10:54/00:27:59, 0.758s/it]: train_loss_raw=0.4500, running_loss=0.4474, LR=0.000100
[2025-08-27 11:14:06,161][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062472] [Batch 00872/03080] [00:11:00/00:27:53, 0.758s/it]: train_loss_raw=0.3450, running_loss=0.4445, LR=0.000100
[2025-08-27 11:14:12,106][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062480] [Batch 00880/03080] [00:11:06/00:27:46, 0.758s/it]: train_loss_raw=0.3854, running_loss=0.4436, LR=0.000100
[2025-08-27 11:14:18,144][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062488] [Batch 00888/03080] [00:11:12/00:27:40, 0.758s/it]: train_loss_raw=0.3802, running_loss=0.4441, LR=0.000100
[2025-08-27 11:14:24,215][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062496] [Batch 00896/03080] [00:11:18/00:27:34, 0.758s/it]: train_loss_raw=0.4538, running_loss=0.4445, LR=0.000100
[2025-08-27 11:14:30,286][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062504] [Batch 00904/03080] [00:11:24/00:27:28, 0.758s/it]: train_loss_raw=0.3592, running_loss=0.4439, LR=0.000100
[2025-08-27 11:14:36,381][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062512] [Batch 00912/03080] [00:11:30/00:27:22, 0.758s/it]: train_loss_raw=0.4266, running_loss=0.4464, LR=0.000100
[2025-08-27 11:14:42,417][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062520] [Batch 00920/03080] [00:11:37/00:27:16, 0.758s/it]: train_loss_raw=0.4588, running_loss=0.4459, LR=0.000100
[2025-08-27 11:14:48,507][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062528] [Batch 00928/03080] [00:11:43/00:27:10, 0.758s/it]: train_loss_raw=0.4992, running_loss=0.4456, LR=0.000100
[2025-08-27 11:14:54,493][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062536] [Batch 00936/03080] [00:11:49/00:27:04, 0.758s/it]: train_loss_raw=0.4730, running_loss=0.4449, LR=0.000100
[2025-08-27 11:15:00,469][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062544] [Batch 00944/03080] [00:11:55/00:26:58, 0.757s/it]: train_loss_raw=0.5516, running_loss=0.4463, LR=0.000100
[2025-08-27 11:15:06,449][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062552] [Batch 00952/03080] [00:12:01/00:26:51, 0.757s/it]: train_loss_raw=0.4584, running_loss=0.4447, LR=0.000100
[2025-08-27 11:15:12,412][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062560] [Batch 00960/03080] [00:12:07/00:26:45, 0.757s/it]: train_loss_raw=0.4132, running_loss=0.4463, LR=0.000100
[2025-08-27 11:15:18,403][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062568] [Batch 00968/03080] [00:12:13/00:26:39, 0.757s/it]: train_loss_raw=0.4456, running_loss=0.4477, LR=0.000100
[2025-08-27 11:15:24,451][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062576] [Batch 00976/03080] [00:12:19/00:26:33, 0.757s/it]: train_loss_raw=0.4640, running_loss=0.4464, LR=0.000100
[2025-08-27 11:15:30,503][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062584] [Batch 00984/03080] [00:12:25/00:26:27, 0.757s/it]: train_loss_raw=0.4113, running_loss=0.4453, LR=0.000100
[2025-08-27 11:15:36,523][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062592] [Batch 00992/03080] [00:12:31/00:26:21, 0.757s/it]: train_loss_raw=0.5168, running_loss=0.4481, LR=0.000100
[2025-08-27 11:15:42,604][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062600] [Batch 01000/03080] [00:12:37/00:26:14, 0.757s/it]: train_loss_raw=0.4281, running_loss=0.4463, LR=0.000100
[2025-08-27 11:15:48,764][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062608] [Batch 01008/03080] [00:12:43/00:26:09, 0.757s/it]: train_loss_raw=0.3963, running_loss=0.4445, LR=0.000100
[2025-08-27 11:15:54,768][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062616] [Batch 01016/03080] [00:12:49/00:26:02, 0.757s/it]: train_loss_raw=0.4482, running_loss=0.4461, LR=0.000100
[2025-08-27 11:16:00,749][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062624] [Batch 01024/03080] [00:12:55/00:25:56, 0.757s/it]: train_loss_raw=0.4210, running_loss=0.4474, LR=0.000100
[2025-08-27 11:16:06,722][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062632] [Batch 01032/03080] [00:13:01/00:25:50, 0.757s/it]: train_loss_raw=0.4744, running_loss=0.4464, LR=0.000100
[2025-08-27 11:16:12,731][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062640] [Batch 01040/03080] [00:13:07/00:25:44, 0.757s/it]: train_loss_raw=0.5159, running_loss=0.4477, LR=0.000100
[2025-08-27 11:16:18,710][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062648] [Batch 01048/03080] [00:13:13/00:25:38, 0.757s/it]: train_loss_raw=0.4272, running_loss=0.4469, LR=0.000100
[2025-08-27 11:16:24,821][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062656] [Batch 01056/03080] [00:13:19/00:25:32, 0.757s/it]: train_loss_raw=0.4392, running_loss=0.4482, LR=0.000100
[2025-08-27 11:16:30,764][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062664] [Batch 01064/03080] [00:13:25/00:25:25, 0.757s/it]: train_loss_raw=0.5702, running_loss=0.4496, LR=0.000100
[2025-08-27 11:16:36,710][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062672] [Batch 01072/03080] [00:13:31/00:25:19, 0.757s/it]: train_loss_raw=0.5111, running_loss=0.4506, LR=0.000100
[2025-08-27 11:16:42,676][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062680] [Batch 01080/03080] [00:13:37/00:25:13, 0.757s/it]: train_loss_raw=0.4393, running_loss=0.4472, LR=0.000100
[2025-08-27 11:16:48,682][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062688] [Batch 01088/03080] [00:13:43/00:25:07, 0.757s/it]: train_loss_raw=0.4718, running_loss=0.4476, LR=0.000100
[2025-08-27 11:16:54,757][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062696] [Batch 01096/03080] [00:13:49/00:25:01, 0.757s/it]: train_loss_raw=0.4020, running_loss=0.4469, LR=0.000100
[2025-08-27 11:17:00,754][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062704] [Batch 01104/03080] [00:13:55/00:24:55, 0.757s/it]: train_loss_raw=0.3960, running_loss=0.4450, LR=0.000100
[2025-08-27 11:17:06,956][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062712] [Batch 01112/03080] [00:14:01/00:24:49, 0.757s/it]: train_loss_raw=0.4416, running_loss=0.4423, LR=0.000100
[2025-08-27 11:17:12,930][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062720] [Batch 01120/03080] [00:14:07/00:24:43, 0.757s/it]: train_loss_raw=0.3764, running_loss=0.4420, LR=0.000100
[2025-08-27 11:17:19,102][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062728] [Batch 01128/03080] [00:14:13/00:24:37, 0.757s/it]: train_loss_raw=0.4156, running_loss=0.4420, LR=0.000100
[2025-08-27 11:17:25,215][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062736] [Batch 01136/03080] [00:14:19/00:24:31, 0.757s/it]: train_loss_raw=0.3765, running_loss=0.4418, LR=0.000100
[2025-08-27 11:17:31,236][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062744] [Batch 01144/03080] [00:14:25/00:24:25, 0.757s/it]: train_loss_raw=0.4016, running_loss=0.4425, LR=0.000100
[2025-08-27 11:17:37,153][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062752] [Batch 01152/03080] [00:14:31/00:24:18, 0.757s/it]: train_loss_raw=0.4964, running_loss=0.4439, LR=0.000100
[2025-08-27 11:17:43,003][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062760] [Batch 01160/03080] [00:14:37/00:24:12, 0.757s/it]: train_loss_raw=0.5296, running_loss=0.4441, LR=0.000100
[2025-08-27 11:17:48,920][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062768] [Batch 01168/03080] [00:14:43/00:24:06, 0.756s/it]: train_loss_raw=0.3907, running_loss=0.4440, LR=0.000100
[2025-08-27 11:17:55,108][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062776] [Batch 01176/03080] [00:14:49/00:24:00, 0.757s/it]: train_loss_raw=0.4132, running_loss=0.4440, LR=0.000100
[2025-08-27 11:18:01,292][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062784] [Batch 01184/03080] [00:14:55/00:23:54, 0.757s/it]: train_loss_raw=0.3935, running_loss=0.4408, LR=0.000100
[2025-08-27 11:18:07,510][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062792] [Batch 01192/03080] [00:15:02/00:23:48, 0.757s/it]: train_loss_raw=0.4773, running_loss=0.4409, LR=0.000100
[2025-08-27 11:18:13,710][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062800] [Batch 01200/03080] [00:15:08/00:23:43, 0.757s/it]: train_loss_raw=0.4647, running_loss=0.4399, LR=0.000100
[2025-08-27 11:18:20,046][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062808] [Batch 01208/03080] [00:15:14/00:23:37, 0.757s/it]: train_loss_raw=0.4967, running_loss=0.4420, LR=0.000100
[2025-08-27 11:18:26,249][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062816] [Batch 01216/03080] [00:15:20/00:23:31, 0.757s/it]: train_loss_raw=0.4650, running_loss=0.4440, LR=0.000100
[2025-08-27 11:18:32,464][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062824] [Batch 01224/03080] [00:15:27/00:23:25, 0.757s/it]: train_loss_raw=0.4203, running_loss=0.4422, LR=0.000100
[2025-08-27 11:18:38,809][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062832] [Batch 01232/03080] [00:15:33/00:23:20, 0.758s/it]: train_loss_raw=0.4772, running_loss=0.4448, LR=0.000100
[2025-08-27 11:18:44,678][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062840] [Batch 01240/03080] [00:15:39/00:23:13, 0.757s/it]: train_loss_raw=0.4278, running_loss=0.4434, LR=0.000100
[2025-08-27 11:18:50,968][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062848] [Batch 01248/03080] [00:15:45/00:23:08, 0.758s/it]: train_loss_raw=0.3936, running_loss=0.4404, LR=0.000100
[2025-08-27 11:18:57,456][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062856] [Batch 01256/03080] [00:15:52/00:23:02, 0.758s/it]: train_loss_raw=0.3731, running_loss=0.4380, LR=0.000100
[2025-08-27 11:19:03,503][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062864] [Batch 01264/03080] [00:15:58/00:22:56, 0.758s/it]: train_loss_raw=0.4713, running_loss=0.4378, LR=0.000100
[2025-08-27 11:19:09,467][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062872] [Batch 01272/03080] [00:16:04/00:22:50, 0.758s/it]: train_loss_raw=0.4174, running_loss=0.4388, LR=0.000100
[2025-08-27 11:19:15,393][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062880] [Batch 01280/03080] [00:16:09/00:22:44, 0.758s/it]: train_loss_raw=0.4108, running_loss=0.4390, LR=0.000100
[2025-08-27 11:19:21,242][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062888] [Batch 01288/03080] [00:16:15/00:22:37, 0.758s/it]: train_loss_raw=0.4265, running_loss=0.4384, LR=0.000100
[2025-08-27 11:19:27,200][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062896] [Batch 01296/03080] [00:16:21/00:22:31, 0.758s/it]: train_loss_raw=0.3911, running_loss=0.4366, LR=0.000100
[2025-08-27 11:19:33,258][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062904] [Batch 01304/03080] [00:16:27/00:22:25, 0.758s/it]: train_loss_raw=0.4301, running_loss=0.4383, LR=0.000100
[2025-08-27 11:19:39,122][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062912] [Batch 01312/03080] [00:16:33/00:22:19, 0.757s/it]: train_loss_raw=0.4805, running_loss=0.4392, LR=0.000100
[2025-08-27 11:19:44,795][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062920] [Batch 01320/03080] [00:16:39/00:22:12, 0.757s/it]: train_loss_raw=0.4181, running_loss=0.4414, LR=0.000100
[2025-08-27 11:19:50,821][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062928] [Batch 01328/03080] [00:16:45/00:22:06, 0.757s/it]: train_loss_raw=0.4656, running_loss=0.4415, LR=0.000100
[2025-08-27 11:19:56,800][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062936] [Batch 01336/03080] [00:16:51/00:22:00, 0.757s/it]: train_loss_raw=0.4800, running_loss=0.4438, LR=0.000100
[2025-08-27 11:20:02,750][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062944] [Batch 01344/03080] [00:16:57/00:21:54, 0.757s/it]: train_loss_raw=0.3916, running_loss=0.4427, LR=0.000100
[2025-08-27 11:20:08,784][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062952] [Batch 01352/03080] [00:17:03/00:21:47, 0.757s/it]: train_loss_raw=0.4742, running_loss=0.4430, LR=0.000100
[2025-08-27 11:20:14,783][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062960] [Batch 01360/03080] [00:17:09/00:21:41, 0.757s/it]: train_loss_raw=0.4447, running_loss=0.4434, LR=0.000100
[2025-08-27 11:20:20,738][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062968] [Batch 01368/03080] [00:17:15/00:21:35, 0.757s/it]: train_loss_raw=0.4243, running_loss=0.4432, LR=0.000100
[2025-08-27 11:20:26,763][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062976] [Batch 01376/03080] [00:17:21/00:21:29, 0.757s/it]: train_loss_raw=0.4138, running_loss=0.4431, LR=0.000100
[2025-08-27 11:20:32,779][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062984] [Batch 01384/03080] [00:17:27/00:21:23, 0.757s/it]: train_loss_raw=0.4341, running_loss=0.4442, LR=0.000100
[2025-08-27 11:20:38,758][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 062992] [Batch 01392/03080] [00:17:33/00:21:17, 0.757s/it]: train_loss_raw=0.5019, running_loss=0.4435, LR=0.000100
[2025-08-27 11:20:44,709][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063000] [Batch 01400/03080] [00:17:39/00:21:11, 0.757s/it]: train_loss_raw=0.4564, running_loss=0.4429, LR=0.000100
[2025-08-27 11:20:50,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063008] [Batch 01408/03080] [00:17:45/00:21:05, 0.757s/it]: train_loss_raw=0.4659, running_loss=0.4444, LR=0.000100
[2025-08-27 11:20:56,744][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063016] [Batch 01416/03080] [00:17:51/00:20:58, 0.757s/it]: train_loss_raw=0.4099, running_loss=0.4453, LR=0.000100
[2025-08-27 11:21:02,801][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063024] [Batch 01424/03080] [00:17:57/00:20:52, 0.757s/it]: train_loss_raw=0.4432, running_loss=0.4451, LR=0.000100
[2025-08-27 11:21:08,881][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063032] [Batch 01432/03080] [00:18:03/00:20:46, 0.757s/it]: train_loss_raw=0.4423, running_loss=0.4462, LR=0.000100
[2025-08-27 11:21:14,887][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063040] [Batch 01440/03080] [00:18:09/00:20:40, 0.757s/it]: train_loss_raw=0.4373, running_loss=0.4435, LR=0.000100
[2025-08-27 11:21:20,868][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063048] [Batch 01448/03080] [00:18:15/00:20:34, 0.757s/it]: train_loss_raw=0.4493, running_loss=0.4447, LR=0.000100
[2025-08-27 11:21:26,896][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063056] [Batch 01456/03080] [00:18:21/00:20:28, 0.757s/it]: train_loss_raw=0.3769, running_loss=0.4428, LR=0.000100
[2025-08-27 11:21:32,924][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063064] [Batch 01464/03080] [00:18:27/00:20:22, 0.757s/it]: train_loss_raw=0.4134, running_loss=0.4415, LR=0.000100
[2025-08-27 11:21:38,925][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063072] [Batch 01472/03080] [00:18:33/00:20:16, 0.756s/it]: train_loss_raw=0.4188, running_loss=0.4412, LR=0.000100
[2025-08-27 11:21:44,832][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063080] [Batch 01480/03080] [00:18:39/00:20:10, 0.756s/it]: train_loss_raw=0.4991, running_loss=0.4419, LR=0.000100
[2025-08-27 11:21:50,603][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063088] [Batch 01488/03080] [00:18:45/00:20:03, 0.756s/it]: train_loss_raw=0.4507, running_loss=0.4388, LR=0.000100
[2025-08-27 11:21:56,381][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063096] [Batch 01496/03080] [00:18:50/00:19:57, 0.756s/it]: train_loss_raw=0.4963, running_loss=0.4403, LR=0.000100
[2025-08-27 11:22:02,334][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063104] [Batch 01504/03080] [00:18:56/00:19:51, 0.756s/it]: train_loss_raw=0.4287, running_loss=0.4393, LR=0.000100
[2025-08-27 11:22:08,355][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063112] [Batch 01512/03080] [00:19:02/00:19:45, 0.756s/it]: train_loss_raw=0.5030, running_loss=0.4392, LR=0.000100
[2025-08-27 11:22:14,554][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063120] [Batch 01520/03080] [00:19:09/00:19:39, 0.756s/it]: train_loss_raw=0.3864, running_loss=0.4383, LR=0.000100
[2025-08-27 11:22:20,705][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063128] [Batch 01528/03080] [00:19:15/00:19:33, 0.756s/it]: train_loss_raw=0.4208, running_loss=0.4396, LR=0.000100
[2025-08-27 11:22:26,839][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063136] [Batch 01536/03080] [00:19:21/00:19:27, 0.756s/it]: train_loss_raw=0.3682, running_loss=0.4417, LR=0.000100
[2025-08-27 11:22:32,968][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063144] [Batch 01544/03080] [00:19:27/00:19:21, 0.756s/it]: train_loss_raw=0.3972, running_loss=0.4420, LR=0.000100
[2025-08-27 11:22:38,667][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063152] [Batch 01552/03080] [00:19:33/00:19:15, 0.756s/it]: train_loss_raw=0.3848, running_loss=0.4423, LR=0.000100
[2025-08-27 11:22:44,662][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063160] [Batch 01560/03080] [00:19:39/00:19:09, 0.756s/it]: train_loss_raw=0.3991, running_loss=0.4398, LR=0.000100
[2025-08-27 11:22:50,931][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063168] [Batch 01568/03080] [00:19:45/00:19:03, 0.756s/it]: train_loss_raw=0.4618, running_loss=0.4438, LR=0.000100
[2025-08-27 11:22:56,981][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063176] [Batch 01576/03080] [00:19:51/00:18:57, 0.756s/it]: train_loss_raw=0.3871, running_loss=0.4410, LR=0.000100
[2025-08-27 11:23:02,812][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063184] [Batch 01584/03080] [00:19:57/00:18:50, 0.756s/it]: train_loss_raw=0.4562, running_loss=0.4402, LR=0.000100
[2025-08-27 11:23:08,564][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063192] [Batch 01592/03080] [00:20:03/00:18:44, 0.756s/it]: train_loss_raw=0.4278, running_loss=0.4409, LR=0.000100
[2025-08-27 11:23:14,415][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063200] [Batch 01600/03080] [00:20:09/00:18:38, 0.756s/it]: train_loss_raw=0.5041, running_loss=0.4412, LR=0.000100
[2025-08-27 11:23:20,340][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063208] [Batch 01608/03080] [00:20:14/00:18:32, 0.756s/it]: train_loss_raw=0.4347, running_loss=0.4408, LR=0.000100
[2025-08-27 11:23:26,255][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063216] [Batch 01616/03080] [00:20:20/00:18:26, 0.755s/it]: train_loss_raw=0.4943, running_loss=0.4414, LR=0.000100
[2025-08-27 11:23:32,236][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063224] [Batch 01624/03080] [00:20:26/00:18:19, 0.755s/it]: train_loss_raw=0.4340, running_loss=0.4407, LR=0.000100
[2025-08-27 11:23:38,174][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063232] [Batch 01632/03080] [00:20:32/00:18:13, 0.755s/it]: train_loss_raw=0.4960, running_loss=0.4400, LR=0.000100
[2025-08-27 11:23:44,367][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063240] [Batch 01640/03080] [00:20:38/00:18:07, 0.755s/it]: train_loss_raw=0.4791, running_loss=0.4407, LR=0.000100
[2025-08-27 11:23:50,395][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063248] [Batch 01648/03080] [00:20:45/00:18:01, 0.755s/it]: train_loss_raw=0.5169, running_loss=0.4412, LR=0.000100
[2025-08-27 11:23:56,337][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063256] [Batch 01656/03080] [00:20:50/00:17:55, 0.755s/it]: train_loss_raw=0.4926, running_loss=0.4400, LR=0.000100
[2025-08-27 11:24:02,295][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063264] [Batch 01664/03080] [00:20:56/00:17:49, 0.755s/it]: train_loss_raw=0.5282, running_loss=0.4410, LR=0.000100
[2025-08-27 11:24:08,268][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063272] [Batch 01672/03080] [00:21:02/00:17:43, 0.755s/it]: train_loss_raw=0.3498, running_loss=0.4395, LR=0.000100
[2025-08-27 11:24:14,427][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063280] [Batch 01680/03080] [00:21:09/00:17:37, 0.755s/it]: train_loss_raw=0.4060, running_loss=0.4390, LR=0.000100
[2025-08-27 11:24:20,642][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063288] [Batch 01688/03080] [00:21:15/00:17:31, 0.755s/it]: train_loss_raw=0.3983, running_loss=0.4407, LR=0.000100
[2025-08-27 11:24:26,686][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063296] [Batch 01696/03080] [00:21:21/00:17:25, 0.755s/it]: train_loss_raw=0.3654, running_loss=0.4395, LR=0.000100
[2025-08-27 11:24:32,839][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063304] [Batch 01704/03080] [00:21:27/00:17:19, 0.756s/it]: train_loss_raw=0.3955, running_loss=0.4390, LR=0.000100
[2025-08-27 11:24:38,865][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063312] [Batch 01712/03080] [00:21:33/00:17:13, 0.756s/it]: train_loss_raw=0.4864, running_loss=0.4424, LR=0.000100
[2025-08-27 11:24:44,899][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063320] [Batch 01720/03080] [00:21:39/00:17:07, 0.756s/it]: train_loss_raw=0.3606, running_loss=0.4410, LR=0.000100
[2025-08-27 11:24:50,929][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063328] [Batch 01728/03080] [00:21:45/00:17:01, 0.756s/it]: train_loss_raw=0.4849, running_loss=0.4401, LR=0.000100
[2025-08-27 11:24:56,912][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063336] [Batch 01736/03080] [00:21:51/00:16:55, 0.755s/it]: train_loss_raw=0.4317, running_loss=0.4396, LR=0.000100
[2025-08-27 11:25:02,926][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063344] [Batch 01744/03080] [00:21:57/00:16:49, 0.755s/it]: train_loss_raw=0.5402, running_loss=0.4392, LR=0.000100
[2025-08-27 11:25:08,896][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063352] [Batch 01752/03080] [00:22:03/00:16:43, 0.755s/it]: train_loss_raw=0.4944, running_loss=0.4396, LR=0.000100
[2025-08-27 11:25:15,119][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063360] [Batch 01760/03080] [00:22:09/00:16:37, 0.756s/it]: train_loss_raw=0.4541, running_loss=0.4416, LR=0.000100
[2025-08-27 11:25:21,276][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063368] [Batch 01768/03080] [00:22:15/00:16:31, 0.756s/it]: train_loss_raw=0.3822, running_loss=0.4417, LR=0.000100
[2025-08-27 11:25:27,299][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063376] [Batch 01776/03080] [00:22:21/00:16:25, 0.756s/it]: train_loss_raw=0.4008, running_loss=0.4413, LR=0.000100
[2025-08-27 11:25:33,363][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063384] [Batch 01784/03080] [00:22:27/00:16:19, 0.756s/it]: train_loss_raw=0.3844, running_loss=0.4388, LR=0.000100
[2025-08-27 11:25:39,276][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063392] [Batch 01792/03080] [00:22:33/00:16:13, 0.756s/it]: train_loss_raw=0.4427, running_loss=0.4399, LR=0.000100
[2025-08-27 11:25:45,258][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063400] [Batch 01800/03080] [00:22:39/00:16:07, 0.755s/it]: train_loss_raw=0.5293, running_loss=0.4418, LR=0.000100
[2025-08-27 11:25:51,295][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063408] [Batch 01808/03080] [00:22:45/00:16:00, 0.755s/it]: train_loss_raw=0.4109, running_loss=0.4426, LR=0.000100
[2025-08-27 11:25:57,421][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063416] [Batch 01816/03080] [00:22:52/00:15:54, 0.756s/it]: train_loss_raw=0.4198, running_loss=0.4441, LR=0.000100
[2025-08-27 11:26:03,508][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063424] [Batch 01824/03080] [00:22:58/00:15:48, 0.756s/it]: train_loss_raw=0.4417, running_loss=0.4430, LR=0.000100
[2025-08-27 11:26:09,580][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063432] [Batch 01832/03080] [00:23:04/00:15:42, 0.756s/it]: train_loss_raw=0.4208, running_loss=0.4441, LR=0.000100
[2025-08-27 11:26:15,540][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063440] [Batch 01840/03080] [00:23:10/00:15:36, 0.756s/it]: train_loss_raw=0.4097, running_loss=0.4441, LR=0.000100
[2025-08-27 11:26:21,715][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063448] [Batch 01848/03080] [00:23:16/00:15:30, 0.756s/it]: train_loss_raw=0.4995, running_loss=0.4446, LR=0.000100
[2025-08-27 11:26:27,766][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063456] [Batch 01856/03080] [00:23:22/00:15:24, 0.756s/it]: train_loss_raw=0.4139, running_loss=0.4437, LR=0.000100
[2025-08-27 11:26:33,910][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063464] [Batch 01864/03080] [00:23:28/00:15:18, 0.756s/it]: train_loss_raw=0.3569, running_loss=0.4430, LR=0.000100
[2025-08-27 11:26:39,845][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063472] [Batch 01872/03080] [00:23:34/00:15:12, 0.756s/it]: train_loss_raw=0.5222, running_loss=0.4431, LR=0.000100
[2025-08-27 11:26:45,854][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063480] [Batch 01880/03080] [00:23:40/00:15:06, 0.756s/it]: train_loss_raw=0.4617, running_loss=0.4425, LR=0.000100
[2025-08-27 11:26:51,787][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063488] [Batch 01888/03080] [00:23:46/00:15:00, 0.756s/it]: train_loss_raw=0.4272, running_loss=0.4407, LR=0.000100
[2025-08-27 11:26:57,699][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063496] [Batch 01896/03080] [00:23:52/00:14:54, 0.755s/it]: train_loss_raw=0.5239, running_loss=0.4430, LR=0.000100
[2025-08-27 11:27:03,744][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063504] [Batch 01904/03080] [00:23:58/00:14:48, 0.755s/it]: train_loss_raw=0.4282, running_loss=0.4410, LR=0.000100
[2025-08-27 11:27:09,762][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063512] [Batch 01912/03080] [00:24:04/00:14:42, 0.755s/it]: train_loss_raw=0.4384, running_loss=0.4424, LR=0.000100
[2025-08-27 11:27:15,774][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063520] [Batch 01920/03080] [00:24:10/00:14:36, 0.755s/it]: train_loss_raw=0.4484, running_loss=0.4446, LR=0.000100
[2025-08-27 11:27:21,788][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063528] [Batch 01928/03080] [00:24:16/00:14:30, 0.755s/it]: train_loss_raw=0.4870, running_loss=0.4458, LR=0.000100
[2025-08-27 11:27:27,876][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063536] [Batch 01936/03080] [00:24:22/00:14:24, 0.755s/it]: train_loss_raw=0.4367, running_loss=0.4473, LR=0.000100
[2025-08-27 11:27:34,031][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063544] [Batch 01944/03080] [00:24:28/00:14:18, 0.755s/it]: train_loss_raw=0.4472, running_loss=0.4456, LR=0.000100
[2025-08-27 11:27:39,701][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063552] [Batch 01952/03080] [00:24:34/00:14:11, 0.755s/it]: train_loss_raw=0.4432, running_loss=0.4458, LR=0.000100
[2025-08-27 11:27:45,242][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063560] [Batch 01960/03080] [00:24:39/00:14:05, 0.755s/it]: train_loss_raw=0.4950, running_loss=0.4445, LR=0.000100
[2025-08-27 11:27:51,184][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063568] [Batch 01968/03080] [00:24:45/00:13:59, 0.755s/it]: train_loss_raw=0.3589, running_loss=0.4430, LR=0.000100
[2025-08-27 11:27:57,271][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063576] [Batch 01976/03080] [00:24:51/00:13:53, 0.755s/it]: train_loss_raw=0.4752, running_loss=0.4415, LR=0.000100
[2025-08-27 11:28:03,269][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063584] [Batch 01984/03080] [00:24:57/00:13:47, 0.755s/it]: train_loss_raw=0.5316, running_loss=0.4418, LR=0.000100
[2025-08-27 11:28:09,327][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063592] [Batch 01992/03080] [00:25:03/00:13:41, 0.755s/it]: train_loss_raw=0.4161, running_loss=0.4422, LR=0.000100
[2025-08-27 11:28:15,394][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063600] [Batch 02000/03080] [00:25:09/00:13:35, 0.755s/it]: train_loss_raw=0.4217, running_loss=0.4429, LR=0.000100
[2025-08-27 11:28:21,431][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063608] [Batch 02008/03080] [00:25:16/00:13:29, 0.755s/it]: train_loss_raw=0.4322, running_loss=0.4425, LR=0.000100
[2025-08-27 11:28:27,896][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063616] [Batch 02016/03080] [00:25:22/00:13:23, 0.755s/it]: train_loss_raw=0.5033, running_loss=0.4430, LR=0.000100
[2025-08-27 11:28:34,012][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063624] [Batch 02024/03080] [00:25:28/00:13:17, 0.755s/it]: train_loss_raw=0.4002, running_loss=0.4442, LR=0.000100
[2025-08-27 11:28:40,220][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063632] [Batch 02032/03080] [00:25:34/00:13:11, 0.755s/it]: train_loss_raw=0.4244, running_loss=0.4430, LR=0.000100
[2025-08-27 11:28:45,643][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063640] [Batch 02040/03080] [00:25:40/00:13:05, 0.755s/it]: train_loss_raw=0.4298, running_loss=0.4427, LR=0.000100
[2025-08-27 11:28:51,725][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063648] [Batch 02048/03080] [00:25:46/00:12:59, 0.755s/it]: train_loss_raw=0.4425, running_loss=0.4415, LR=0.000100
[2025-08-27 11:28:57,677][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063656] [Batch 02056/03080] [00:25:52/00:12:53, 0.755s/it]: train_loss_raw=0.3775, running_loss=0.4421, LR=0.000100
[2025-08-27 11:29:03,654][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063664] [Batch 02064/03080] [00:25:58/00:12:47, 0.755s/it]: train_loss_raw=0.4565, running_loss=0.4420, LR=0.000100
[2025-08-27 11:29:09,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063672] [Batch 02072/03080] [00:26:04/00:12:41, 0.755s/it]: train_loss_raw=0.4306, running_loss=0.4418, LR=0.000100
[2025-08-27 11:29:15,790][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063680] [Batch 02080/03080] [00:26:10/00:12:34, 0.755s/it]: train_loss_raw=0.4179, running_loss=0.4421, LR=0.000100
[2025-08-27 11:29:21,941][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063688] [Batch 02088/03080] [00:26:16/00:12:29, 0.755s/it]: train_loss_raw=0.4219, running_loss=0.4424, LR=0.000100
[2025-08-27 11:29:28,036][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063696] [Batch 02096/03080] [00:26:22/00:12:22, 0.755s/it]: train_loss_raw=0.4286, running_loss=0.4427, LR=0.000100
[2025-08-27 11:29:34,005][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063704] [Batch 02104/03080] [00:26:28/00:12:16, 0.755s/it]: train_loss_raw=0.4630, running_loss=0.4421, LR=0.000100
[2025-08-27 11:29:40,048][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063712] [Batch 02112/03080] [00:26:34/00:12:10, 0.755s/it]: train_loss_raw=0.4023, running_loss=0.4419, LR=0.000100
[2025-08-27 11:29:46,018][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063720] [Batch 02120/03080] [00:26:40/00:12:04, 0.755s/it]: train_loss_raw=0.5072, running_loss=0.4433, LR=0.000100
[2025-08-27 11:29:52,077][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063728] [Batch 02128/03080] [00:26:46/00:11:58, 0.755s/it]: train_loss_raw=0.4992, running_loss=0.4434, LR=0.000100
[2025-08-27 11:29:58,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063736] [Batch 02136/03080] [00:26:52/00:11:52, 0.755s/it]: train_loss_raw=0.4328, running_loss=0.4443, LR=0.000100
[2025-08-27 11:30:04,121][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063744] [Batch 02144/03080] [00:26:58/00:11:46, 0.755s/it]: train_loss_raw=0.5354, running_loss=0.4452, LR=0.000100
[2025-08-27 11:30:10,105][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063752] [Batch 02152/03080] [00:27:04/00:11:40, 0.755s/it]: train_loss_raw=0.5128, running_loss=0.4457, LR=0.000100
[2025-08-27 11:30:16,109][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063760] [Batch 02160/03080] [00:27:10/00:11:34, 0.755s/it]: train_loss_raw=0.3434, running_loss=0.4448, LR=0.000100
[2025-08-27 11:30:22,081][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063768] [Batch 02168/03080] [00:27:16/00:11:28, 0.755s/it]: train_loss_raw=0.5087, running_loss=0.4449, LR=0.000100
[2025-08-27 11:30:27,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063776] [Batch 02176/03080] [00:27:22/00:11:22, 0.755s/it]: train_loss_raw=0.4129, running_loss=0.4446, LR=0.000100
[2025-08-27 11:30:33,377][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063784] [Batch 02184/03080] [00:27:27/00:11:16, 0.755s/it]: train_loss_raw=0.4263, running_loss=0.4435, LR=0.000100
[2025-08-27 11:30:39,513][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063792] [Batch 02192/03080] [00:27:34/00:11:10, 0.755s/it]: train_loss_raw=0.3903, running_loss=0.4437, LR=0.000100
[2025-08-27 11:30:45,599][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063800] [Batch 02200/03080] [00:27:40/00:11:04, 0.755s/it]: train_loss_raw=0.4058, running_loss=0.4419, LR=0.000100
[2025-08-27 11:30:51,607][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063808] [Batch 02208/03080] [00:27:46/00:10:58, 0.755s/it]: train_loss_raw=0.4058, running_loss=0.4425, LR=0.000100
[2025-08-27 11:30:57,659][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063816] [Batch 02216/03080] [00:27:52/00:10:52, 0.755s/it]: train_loss_raw=0.4591, running_loss=0.4431, LR=0.000100
[2025-08-27 11:31:03,654][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063824] [Batch 02224/03080] [00:27:58/00:10:45, 0.755s/it]: train_loss_raw=0.5312, running_loss=0.4425, LR=0.000100
[2025-08-27 11:31:09,634][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063832] [Batch 02232/03080] [00:28:04/00:10:39, 0.755s/it]: train_loss_raw=0.4232, running_loss=0.4441, LR=0.000100
[2025-08-27 11:31:15,718][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063840] [Batch 02240/03080] [00:28:10/00:10:33, 0.755s/it]: train_loss_raw=0.4596, running_loss=0.4452, LR=0.000100
[2025-08-27 11:31:21,784][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063848] [Batch 02248/03080] [00:28:16/00:10:27, 0.755s/it]: train_loss_raw=0.4131, running_loss=0.4439, LR=0.000100
[2025-08-27 11:31:27,895][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063856] [Batch 02256/03080] [00:28:22/00:10:21, 0.755s/it]: train_loss_raw=0.4826, running_loss=0.4433, LR=0.000100
[2025-08-27 11:31:33,922][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063864] [Batch 02264/03080] [00:28:28/00:10:15, 0.755s/it]: train_loss_raw=0.4382, running_loss=0.4413, LR=0.000100
[2025-08-27 11:31:39,993][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063872] [Batch 02272/03080] [00:28:34/00:10:09, 0.755s/it]: train_loss_raw=0.4622, running_loss=0.4431, LR=0.000100
[2025-08-27 11:31:46,233][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063880] [Batch 02280/03080] [00:28:40/00:10:03, 0.755s/it]: train_loss_raw=0.4402, running_loss=0.4415, LR=0.000100
[2025-08-27 11:31:52,301][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063888] [Batch 02288/03080] [00:28:46/00:09:57, 0.755s/it]: train_loss_raw=0.5038, running_loss=0.4420, LR=0.000100
[2025-08-27 11:31:58,393][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063896] [Batch 02296/03080] [00:28:52/00:09:51, 0.755s/it]: train_loss_raw=0.4765, running_loss=0.4433, LR=0.000100
[2025-08-27 11:32:04,380][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063904] [Batch 02304/03080] [00:28:58/00:09:45, 0.755s/it]: train_loss_raw=0.4329, running_loss=0.4441, LR=0.000100
[2025-08-27 11:32:10,405][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063912] [Batch 02312/03080] [00:29:05/00:09:39, 0.755s/it]: train_loss_raw=0.5178, running_loss=0.4416, LR=0.000100
[2025-08-27 11:32:16,433][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063920] [Batch 02320/03080] [00:29:11/00:09:33, 0.755s/it]: train_loss_raw=0.4474, running_loss=0.4435, LR=0.000100
[2025-08-27 11:32:22,504][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063928] [Batch 02328/03080] [00:29:17/00:09:27, 0.755s/it]: train_loss_raw=0.3976, running_loss=0.4420, LR=0.000100
[2025-08-27 11:32:28,581][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063936] [Batch 02336/03080] [00:29:23/00:09:21, 0.755s/it]: train_loss_raw=0.3899, running_loss=0.4439, LR=0.000100
[2025-08-27 11:32:34,576][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063944] [Batch 02344/03080] [00:29:29/00:09:15, 0.755s/it]: train_loss_raw=0.4962, running_loss=0.4444, LR=0.000100
[2025-08-27 11:32:40,650][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063952] [Batch 02352/03080] [00:29:35/00:09:09, 0.755s/it]: train_loss_raw=0.4256, running_loss=0.4449, LR=0.000100
[2025-08-27 11:32:46,666][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063960] [Batch 02360/03080] [00:29:41/00:09:03, 0.755s/it]: train_loss_raw=0.4697, running_loss=0.4456, LR=0.000100
[2025-08-27 11:32:52,730][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063968] [Batch 02368/03080] [00:29:47/00:08:57, 0.755s/it]: train_loss_raw=0.4414, running_loss=0.4435, LR=0.000100
[2025-08-27 11:32:58,664][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063976] [Batch 02376/03080] [00:29:53/00:08:51, 0.755s/it]: train_loss_raw=0.4459, running_loss=0.4432, LR=0.000100
[2025-08-27 11:33:04,137][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063984] [Batch 02384/03080] [00:29:58/00:08:45, 0.755s/it]: train_loss_raw=0.4937, running_loss=0.4446, LR=0.000100
[2025-08-27 11:33:09,546][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 063992] [Batch 02392/03080] [00:30:04/00:08:38, 0.754s/it]: train_loss_raw=0.4400, running_loss=0.4464, LR=0.000100
[2025-08-27 11:33:14,953][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064000] [Batch 02400/03080] [00:30:09/00:08:32, 0.754s/it]: train_loss_raw=0.4737, running_loss=0.4461, LR=0.000100
[2025-08-27 11:33:24,453][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064008] [Batch 02408/03080] [00:30:19/00:08:27, 0.755s/it]: train_loss_raw=0.4869, running_loss=0.4467, LR=0.000100
[2025-08-27 11:33:30,415][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064016] [Batch 02416/03080] [00:30:25/00:08:21, 0.755s/it]: train_loss_raw=0.5224, running_loss=0.4472, LR=0.000100
[2025-08-27 11:33:36,425][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064024] [Batch 02424/03080] [00:30:31/00:08:15, 0.755s/it]: train_loss_raw=0.4993, running_loss=0.4484, LR=0.000100
[2025-08-27 11:33:42,446][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064032] [Batch 02432/03080] [00:30:37/00:08:09, 0.755s/it]: train_loss_raw=0.4658, running_loss=0.4484, LR=0.000100
[2025-08-27 11:33:48,515][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064040] [Batch 02440/03080] [00:30:43/00:08:03, 0.755s/it]: train_loss_raw=0.4657, running_loss=0.4469, LR=0.000100
[2025-08-27 11:33:54,699][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064048] [Batch 02448/03080] [00:30:49/00:07:57, 0.755s/it]: train_loss_raw=0.4200, running_loss=0.4465, LR=0.000100
[2025-08-27 11:34:00,797][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064056] [Batch 02456/03080] [00:30:55/00:07:51, 0.755s/it]: train_loss_raw=0.5122, running_loss=0.4483, LR=0.000100
[2025-08-27 11:34:06,858][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064064] [Batch 02464/03080] [00:31:01/00:07:45, 0.755s/it]: train_loss_raw=0.4148, running_loss=0.4444, LR=0.000100
[2025-08-27 11:34:12,850][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064072] [Batch 02472/03080] [00:31:07/00:07:39, 0.755s/it]: train_loss_raw=0.4297, running_loss=0.4443, LR=0.000100
[2025-08-27 11:34:18,877][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064080] [Batch 02480/03080] [00:31:13/00:07:33, 0.755s/it]: train_loss_raw=0.4193, running_loss=0.4440, LR=0.000100
[2025-08-27 11:34:24,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064088] [Batch 02488/03080] [00:31:19/00:07:27, 0.755s/it]: train_loss_raw=0.4228, running_loss=0.4459, LR=0.000100
[2025-08-27 11:34:30,784][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064096] [Batch 02496/03080] [00:31:25/00:07:21, 0.755s/it]: train_loss_raw=0.4519, running_loss=0.4455, LR=0.000100
[2025-08-27 11:34:36,202][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064104] [Batch 02504/03080] [00:31:30/00:07:14, 0.755s/it]: train_loss_raw=0.4852, running_loss=0.4464, LR=0.000100
[2025-08-27 11:34:41,955][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064112] [Batch 02512/03080] [00:31:36/00:07:08, 0.755s/it]: train_loss_raw=0.4257, running_loss=0.4453, LR=0.000100
[2025-08-27 11:34:47,963][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064120] [Batch 02520/03080] [00:31:42/00:07:02, 0.755s/it]: train_loss_raw=0.5580, running_loss=0.4456, LR=0.000100
[2025-08-27 11:34:53,985][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064128] [Batch 02528/03080] [00:31:48/00:06:56, 0.755s/it]: train_loss_raw=0.4344, running_loss=0.4427, LR=0.000100
[2025-08-27 11:34:59,986][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064136] [Batch 02536/03080] [00:31:54/00:06:50, 0.755s/it]: train_loss_raw=0.4098, running_loss=0.4416, LR=0.000100
[2025-08-27 11:35:05,911][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064144] [Batch 02544/03080] [00:32:00/00:06:44, 0.755s/it]: train_loss_raw=0.4420, running_loss=0.4416, LR=0.000100
[2025-08-27 11:35:11,880][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064152] [Batch 02552/03080] [00:32:06/00:06:38, 0.755s/it]: train_loss_raw=0.4477, running_loss=0.4427, LR=0.000100
[2025-08-27 11:35:17,859][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064160] [Batch 02560/03080] [00:32:12/00:06:32, 0.755s/it]: train_loss_raw=0.4855, running_loss=0.4405, LR=0.000100
[2025-08-27 11:35:23,858][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064168] [Batch 02568/03080] [00:32:18/00:06:26, 0.755s/it]: train_loss_raw=0.4511, running_loss=0.4431, LR=0.000100
[2025-08-27 11:35:29,863][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064176] [Batch 02576/03080] [00:32:24/00:06:20, 0.755s/it]: train_loss_raw=0.5136, running_loss=0.4407, LR=0.000100
[2025-08-27 11:35:35,854][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064184] [Batch 02584/03080] [00:32:30/00:06:14, 0.755s/it]: train_loss_raw=0.4031, running_loss=0.4410, LR=0.000100
[2025-08-27 11:35:41,845][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064192] [Batch 02592/03080] [00:32:36/00:06:08, 0.755s/it]: train_loss_raw=0.4063, running_loss=0.4388, LR=0.000100
[2025-08-27 11:35:47,844][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064200] [Batch 02600/03080] [00:32:42/00:06:02, 0.755s/it]: train_loss_raw=0.4263, running_loss=0.4381, LR=0.000100
[2025-08-27 11:35:53,965][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064208] [Batch 02608/03080] [00:32:48/00:05:56, 0.755s/it]: train_loss_raw=0.4013, running_loss=0.4383, LR=0.000100
[2025-08-27 11:35:59,919][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064216] [Batch 02616/03080] [00:32:54/00:05:50, 0.755s/it]: train_loss_raw=0.4563, running_loss=0.4407, LR=0.000100
[2025-08-27 11:36:05,877][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064224] [Batch 02624/03080] [00:33:00/00:05:44, 0.755s/it]: train_loss_raw=0.4317, running_loss=0.4398, LR=0.000100
[2025-08-27 11:36:11,893][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064232] [Batch 02632/03080] [00:33:06/00:05:38, 0.755s/it]: train_loss_raw=0.4671, running_loss=0.4402, LR=0.000100
[2025-08-27 11:36:17,967][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064240] [Batch 02640/03080] [00:33:12/00:05:32, 0.755s/it]: train_loss_raw=0.3260, running_loss=0.4393, LR=0.000100
[2025-08-27 11:36:24,048][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064248] [Batch 02648/03080] [00:33:18/00:05:26, 0.755s/it]: train_loss_raw=0.4661, running_loss=0.4388, LR=0.000100
[2025-08-27 11:36:30,041][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064256] [Batch 02656/03080] [00:33:24/00:05:20, 0.755s/it]: train_loss_raw=0.5053, running_loss=0.4409, LR=0.000100
[2025-08-27 11:36:36,131][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064264] [Batch 02664/03080] [00:33:30/00:05:13, 0.755s/it]: train_loss_raw=0.4373, running_loss=0.4404, LR=0.000100
[2025-08-27 11:36:42,189][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064272] [Batch 02672/03080] [00:33:36/00:05:07, 0.755s/it]: train_loss_raw=0.3994, running_loss=0.4411, LR=0.000100
[2025-08-27 11:36:48,251][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064280] [Batch 02680/03080] [00:33:42/00:05:01, 0.755s/it]: train_loss_raw=0.4699, running_loss=0.4414, LR=0.000100
[2025-08-27 11:36:54,396][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064288] [Batch 02688/03080] [00:33:49/00:04:55, 0.755s/it]: train_loss_raw=0.3991, running_loss=0.4433, LR=0.000100
[2025-08-27 11:37:00,356][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064296] [Batch 02696/03080] [00:33:54/00:04:49, 0.755s/it]: train_loss_raw=0.5467, running_loss=0.4443, LR=0.000100
[2025-08-27 11:37:06,359][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064304] [Batch 02704/03080] [00:34:00/00:04:43, 0.755s/it]: train_loss_raw=0.4928, running_loss=0.4436, LR=0.000100
[2025-08-27 11:37:12,559][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064312] [Batch 02712/03080] [00:34:07/00:04:37, 0.755s/it]: train_loss_raw=0.4127, running_loss=0.4427, LR=0.000100
[2025-08-27 11:37:18,819][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064320] [Batch 02720/03080] [00:34:13/00:04:31, 0.755s/it]: train_loss_raw=0.4287, running_loss=0.4402, LR=0.000100
[2025-08-27 11:37:24,886][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064328] [Batch 02728/03080] [00:34:19/00:04:25, 0.755s/it]: train_loss_raw=0.3789, running_loss=0.4381, LR=0.000100
[2025-08-27 11:37:31,043][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064336] [Batch 02736/03080] [00:34:25/00:04:19, 0.755s/it]: train_loss_raw=0.4210, running_loss=0.4390, LR=0.000100
[2025-08-27 11:37:37,126][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064344] [Batch 02744/03080] [00:34:31/00:04:13, 0.755s/it]: train_loss_raw=0.4704, running_loss=0.4384, LR=0.000100
[2025-08-27 11:37:43,381][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064352] [Batch 02752/03080] [00:34:37/00:04:07, 0.755s/it]: train_loss_raw=0.5383, running_loss=0.4396, LR=0.000100
[2025-08-27 11:37:49,547][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064360] [Batch 02760/03080] [00:34:44/00:04:01, 0.755s/it]: train_loss_raw=0.3623, running_loss=0.4396, LR=0.000100
[2025-08-27 11:37:55,561][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064368] [Batch 02768/03080] [00:34:50/00:03:55, 0.755s/it]: train_loss_raw=0.4164, running_loss=0.4393, LR=0.000100
[2025-08-27 11:38:01,630][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064376] [Batch 02776/03080] [00:34:56/00:03:49, 0.755s/it]: train_loss_raw=0.4629, running_loss=0.4395, LR=0.000100
[2025-08-27 11:38:07,588][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064384] [Batch 02784/03080] [00:35:02/00:03:43, 0.755s/it]: train_loss_raw=0.5010, running_loss=0.4403, LR=0.000100
[2025-08-27 11:38:13,529][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064392] [Batch 02792/03080] [00:35:08/00:03:37, 0.755s/it]: train_loss_raw=0.3751, running_loss=0.4386, LR=0.000100
[2025-08-27 11:38:19,510][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064400] [Batch 02800/03080] [00:35:14/00:03:31, 0.755s/it]: train_loss_raw=0.4541, running_loss=0.4381, LR=0.000100
[2025-08-27 11:38:25,569][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064408] [Batch 02808/03080] [00:35:20/00:03:25, 0.755s/it]: train_loss_raw=0.3686, running_loss=0.4375, LR=0.000100
[2025-08-27 11:38:31,804][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064416] [Batch 02816/03080] [00:35:26/00:03:19, 0.755s/it]: train_loss_raw=0.4055, running_loss=0.4373, LR=0.000100
[2025-08-27 11:38:37,763][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064424] [Batch 02824/03080] [00:35:32/00:03:13, 0.755s/it]: train_loss_raw=0.4782, running_loss=0.4385, LR=0.000100
[2025-08-27 11:38:43,458][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064432] [Batch 02832/03080] [00:35:38/00:03:07, 0.755s/it]: train_loss_raw=0.4555, running_loss=0.4364, LR=0.000100
[2025-08-27 11:38:49,440][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064440] [Batch 02840/03080] [00:35:44/00:03:01, 0.755s/it]: train_loss_raw=0.4145, running_loss=0.4359, LR=0.000100
[2025-08-27 11:38:55,488][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064448] [Batch 02848/03080] [00:35:50/00:02:55, 0.755s/it]: train_loss_raw=0.4273, running_loss=0.4365, LR=0.000100
[2025-08-27 11:39:01,531][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064456] [Batch 02856/03080] [00:35:56/00:02:49, 0.755s/it]: train_loss_raw=0.4383, running_loss=0.4398, LR=0.000100
[2025-08-27 11:39:07,524][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064464] [Batch 02864/03080] [00:36:02/00:02:43, 0.755s/it]: train_loss_raw=0.5335, running_loss=0.4400, LR=0.000100
[2025-08-27 11:39:13,612][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064472] [Batch 02872/03080] [00:36:08/00:02:37, 0.755s/it]: train_loss_raw=0.5108, running_loss=0.4413, LR=0.000100
[2025-08-27 11:39:19,633][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064480] [Batch 02880/03080] [00:36:14/00:02:30, 0.755s/it]: train_loss_raw=0.4767, running_loss=0.4401, LR=0.000100
[2025-08-27 11:39:25,665][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064488] [Batch 02888/03080] [00:36:20/00:02:24, 0.755s/it]: train_loss_raw=0.4074, running_loss=0.4400, LR=0.000100
[2025-08-27 11:39:31,693][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064496] [Batch 02896/03080] [00:36:26/00:02:18, 0.755s/it]: train_loss_raw=0.5340, running_loss=0.4423, LR=0.000100
[2025-08-27 11:39:37,681][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064504] [Batch 02904/03080] [00:36:32/00:02:12, 0.755s/it]: train_loss_raw=0.4610, running_loss=0.4436, LR=0.000100
[2025-08-27 11:39:43,724][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064512] [Batch 02912/03080] [00:36:38/00:02:06, 0.755s/it]: train_loss_raw=0.4109, running_loss=0.4425, LR=0.000100
[2025-08-27 11:39:49,819][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064520] [Batch 02920/03080] [00:36:44/00:02:00, 0.755s/it]: train_loss_raw=0.5066, running_loss=0.4443, LR=0.000100
[2025-08-27 11:39:55,781][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064528] [Batch 02928/03080] [00:36:50/00:01:54, 0.755s/it]: train_loss_raw=0.4032, running_loss=0.4421, LR=0.000100
[2025-08-27 11:40:01,725][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064536] [Batch 02936/03080] [00:36:56/00:01:48, 0.755s/it]: train_loss_raw=0.3837, running_loss=0.4407, LR=0.000100
[2025-08-27 11:40:07,316][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064544] [Batch 02944/03080] [00:37:01/00:01:42, 0.755s/it]: train_loss_raw=0.4683, running_loss=0.4404, LR=0.000100
[2025-08-27 11:40:12,912][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064552] [Batch 02952/03080] [00:37:07/00:01:36, 0.755s/it]: train_loss_raw=0.4647, running_loss=0.4421, LR=0.000100
[2025-08-27 11:40:18,686][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064560] [Batch 02960/03080] [00:37:13/00:01:30, 0.754s/it]: train_loss_raw=0.4909, running_loss=0.4435, LR=0.000100
[2025-08-27 11:40:24,424][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064568] [Batch 02968/03080] [00:37:19/00:01:24, 0.754s/it]: train_loss_raw=0.5535, running_loss=0.4439, LR=0.000100
[2025-08-27 11:40:30,017][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064576] [Batch 02976/03080] [00:37:24/00:01:18, 0.754s/it]: train_loss_raw=0.3922, running_loss=0.4449, LR=0.000100
[2025-08-27 11:40:35,789][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064584] [Batch 02984/03080] [00:37:30/00:01:12, 0.754s/it]: train_loss_raw=0.5021, running_loss=0.4450, LR=0.000100
[2025-08-27 11:40:41,299][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064592] [Batch 02992/03080] [00:37:35/00:01:06, 0.754s/it]: train_loss_raw=0.4823, running_loss=0.4493, LR=0.000100
[2025-08-27 11:40:46,862][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064600] [Batch 03000/03080] [00:37:41/00:01:00, 0.754s/it]: train_loss_raw=0.4508, running_loss=0.4494, LR=0.000100
[2025-08-27 11:40:52,939][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064608] [Batch 03008/03080] [00:37:47/00:00:54, 0.754s/it]: train_loss_raw=0.3876, running_loss=0.4473, LR=0.000100
[2025-08-27 11:40:58,910][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064616] [Batch 03016/03080] [00:37:53/00:00:48, 0.754s/it]: train_loss_raw=0.4680, running_loss=0.4467, LR=0.000100
[2025-08-27 11:41:04,840][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064624] [Batch 03024/03080] [00:37:59/00:00:42, 0.754s/it]: train_loss_raw=0.5622, running_loss=0.4457, LR=0.000100
[2025-08-27 11:41:10,875][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064632] [Batch 03032/03080] [00:38:05/00:00:36, 0.754s/it]: train_loss_raw=0.4155, running_loss=0.4461, LR=0.000100
[2025-08-27 11:41:16,791][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064640] [Batch 03040/03080] [00:38:11/00:00:30, 0.754s/it]: train_loss_raw=0.3712, running_loss=0.4443, LR=0.000100
[2025-08-27 11:41:22,588][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064648] [Batch 03048/03080] [00:38:17/00:00:24, 0.754s/it]: train_loss_raw=0.5363, running_loss=0.4454, LR=0.000100
[2025-08-27 11:41:28,341][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064656] [Batch 03056/03080] [00:38:22/00:00:18, 0.754s/it]: train_loss_raw=0.5312, running_loss=0.4460, LR=0.000100
[2025-08-27 11:41:34,324][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064664] [Batch 03064/03080] [00:38:28/00:00:12, 0.754s/it]: train_loss_raw=0.4202, running_loss=0.4463, LR=0.000100
[2025-08-27 11:41:40,135][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064672] [Batch 03072/03080] [00:38:34/00:00:06, 0.753s/it]: train_loss_raw=0.4791, running_loss=0.4450, LR=0.000100
[2025-08-27 11:41:45,642][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 064680] [Batch 03080/03080] [00:38:40/00:00:00, 0.753s/it]: train_loss_raw=0.4474, running_loss=0.4440, LR=0.000100
[2025-08-27 11:41:46,172][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-27 11:41:58,044][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00007/00310] [00:00:11/00:07:28, 1.484s/it]
[2025-08-27 11:42:10,223][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00015/00310] [00:00:24/00:07:21, 1.503s/it]
[2025-08-27 11:42:22,016][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00023/00310] [00:00:35/00:07:07, 1.493s/it]
[2025-08-27 11:42:34,316][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00031/00310] [00:00:48/00:06:58, 1.504s/it]
[2025-08-27 11:42:46,693][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00039/00310] [00:01:00/00:06:48, 1.513s/it]
[2025-08-27 11:42:58,411][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00047/00310] [00:01:12/00:06:34, 1.505s/it]
[2025-08-27 11:43:10,879][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00055/00310] [00:01:24/00:06:24, 1.513s/it]
[2025-08-27 11:43:22,462][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00063/00310] [00:01:36/00:06:10, 1.505s/it]
[2025-08-27 11:43:34,925][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00071/00310] [00:01:48/00:05:59, 1.510s/it]
[2025-08-27 11:43:46,852][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00079/00310] [00:02:00/00:05:46, 1.508s/it]
[2025-08-27 11:43:58,745][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00087/00310] [00:02:12/00:05:34, 1.507s/it]
[2025-08-27 11:44:10,736][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00095/00310] [00:02:24/00:05:22, 1.506s/it]
[2025-08-27 11:44:22,734][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00103/00310] [00:02:36/00:05:10, 1.505s/it]
[2025-08-27 11:44:35,074][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00111/00310] [00:02:48/00:04:58, 1.508s/it]
[2025-08-27 11:44:47,456][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00119/00310] [00:03:01/00:04:47, 1.511s/it]
[2025-08-27 11:44:59,380][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00127/00310] [00:03:13/00:04:34, 1.509s/it]
[2025-08-27 11:45:11,807][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00135/00310] [00:03:25/00:04:23, 1.512s/it]
[2025-08-27 11:45:23,896][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00143/00310] [00:03:37/00:04:10, 1.512s/it]
[2025-08-27 11:45:35,599][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00151/00310] [00:03:49/00:03:58, 1.509s/it]
[2025-08-27 11:45:47,473][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00159/00310] [00:04:01/00:03:46, 1.508s/it]
[2025-08-27 11:46:00,107][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00167/00310] [00:04:13/00:03:34, 1.512s/it]
[2025-08-27 11:46:09,881][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00175/00310] [00:04:23/00:03:20, 1.498s/it]
[2025-08-27 11:46:20,699][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00183/00310] [00:04:34/00:03:07, 1.492s/it]
[2025-08-27 11:46:32,030][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00191/00310] [00:04:45/00:02:55, 1.489s/it]
[2025-08-27 11:46:43,891][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00199/00310] [00:04:57/00:02:43, 1.489s/it]
[2025-08-27 11:46:55,163][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00207/00310] [00:05:08/00:02:31, 1.486s/it]
[2025-08-27 11:47:05,899][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00215/00310] [00:05:19/00:02:19, 1.480s/it]
[2025-08-27 11:47:18,073][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00223/00310] [00:05:31/00:02:07, 1.482s/it]
[2025-08-27 11:47:30,450][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00231/00310] [00:05:44/00:01:55, 1.484s/it]
[2025-08-27 11:47:42,032][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00239/00310] [00:05:55/00:01:43, 1.483s/it]
[2025-08-27 11:47:51,903][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00247/00310] [00:06:05/00:01:31, 1.475s/it]
[2025-08-27 11:48:03,428][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00255/00310] [00:06:17/00:01:19, 1.474s/it]
[2025-08-27 11:48:15,400][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00263/00310] [00:06:29/00:01:07, 1.474s/it]
[2025-08-27 11:48:27,216][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00271/00310] [00:06:41/00:00:56, 1.474s/it]
[2025-08-27 11:48:39,063][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00279/00310] [00:06:52/00:00:44, 1.475s/it]
[2025-08-27 11:48:51,660][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00287/00310] [00:07:05/00:00:32, 1.477s/it]
[2025-08-27 11:49:02,508][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00295/00310] [00:07:16/00:00:20, 1.474s/it]
[2025-08-27 11:49:14,749][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 064681] [Batch 00303/00310] [00:07:28/00:00:08, 1.476s/it]
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=0.44404, valid_loss=1.43881
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.510
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.129
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.132
[2025-08-27 11:49:24,246][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.068
[2025-08-27 11:49:24,261][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 16:22:38, remaining time 07:01:07, 00:46:47 per epoch
[2025-08-27 11:49:29,915][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064688] [Batch 00008/03080] [00:00:05/00:34:26, 0.673s/it]: train_loss_raw=0.3945, running_loss=0.4147, LR=0.000100
[2025-08-27 11:49:35,863][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064696] [Batch 00016/03080] [00:00:11/00:36:09, 0.708s/it]: train_loss_raw=0.5928, running_loss=0.4167, LR=0.000100
[2025-08-27 11:49:41,816][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064704] [Batch 00024/03080] [00:00:17/00:36:40, 0.720s/it]: train_loss_raw=0.3935, running_loss=0.4194, LR=0.000100
[2025-08-27 11:49:47,743][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064712] [Batch 00032/03080] [00:00:23/00:36:50, 0.725s/it]: train_loss_raw=0.4192, running_loss=0.4222, LR=0.000100
[2025-08-27 11:49:53,851][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064720] [Batch 00040/03080] [00:00:29/00:37:08, 0.733s/it]: train_loss_raw=0.4090, running_loss=0.4220, LR=0.000100
[2025-08-27 11:50:00,019][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064728] [Batch 00048/03080] [00:00:35/00:37:21, 0.739s/it]: train_loss_raw=0.5087, running_loss=0.4225, LR=0.000100
[2025-08-27 11:50:05,962][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064736] [Batch 00056/03080] [00:00:41/00:37:17, 0.740s/it]: train_loss_raw=0.3309, running_loss=0.4243, LR=0.000100
[2025-08-27 11:50:12,031][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064744] [Batch 00064/03080] [00:00:47/00:37:18, 0.742s/it]: train_loss_raw=0.4393, running_loss=0.4251, LR=0.000100
[2025-08-27 11:50:18,048][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064752] [Batch 00072/03080] [00:00:53/00:37:15, 0.743s/it]: train_loss_raw=0.4652, running_loss=0.4262, LR=0.000100
[2025-08-27 11:50:24,193][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064760] [Batch 00080/03080] [00:00:59/00:37:17, 0.746s/it]: train_loss_raw=0.4290, running_loss=0.4275, LR=0.000100
[2025-08-27 11:50:30,289][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064768] [Batch 00088/03080] [00:01:05/00:37:15, 0.747s/it]: train_loss_raw=0.5652, running_loss=0.4293, LR=0.000100
[2025-08-27 11:50:36,333][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064776] [Batch 00096/03080] [00:01:11/00:37:11, 0.748s/it]: train_loss_raw=0.4157, running_loss=0.4309, LR=0.000100
[2025-08-27 11:50:42,336][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064784] [Batch 00104/03080] [00:01:17/00:37:06, 0.748s/it]: train_loss_raw=0.4416, running_loss=0.4304, LR=0.000100
[2025-08-27 11:50:48,307][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064792] [Batch 00112/03080] [00:01:23/00:36:59, 0.748s/it]: train_loss_raw=0.4307, running_loss=0.4304, LR=0.000100
[2025-08-27 11:50:54,317][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064800] [Batch 00120/03080] [00:01:29/00:36:54, 0.748s/it]: train_loss_raw=0.4360, running_loss=0.4327, LR=0.000100
[2025-08-27 11:51:00,384][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064808] [Batch 00128/03080] [00:01:35/00:36:50, 0.749s/it]: train_loss_raw=0.3423, running_loss=0.4311, LR=0.000100
[2025-08-27 11:51:06,358][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064816] [Batch 00136/03080] [00:01:41/00:36:44, 0.749s/it]: train_loss_raw=0.4094, running_loss=0.4300, LR=0.000100
[2025-08-27 11:51:12,494][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064824] [Batch 00144/03080] [00:01:47/00:36:41, 0.750s/it]: train_loss_raw=0.4497, running_loss=0.4323, LR=0.000100
[2025-08-27 11:51:18,521][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064832] [Batch 00152/03080] [00:01:53/00:36:35, 0.750s/it]: train_loss_raw=0.4245, running_loss=0.4314, LR=0.000100
[2025-08-27 11:51:24,539][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064840] [Batch 00160/03080] [00:02:00/00:36:30, 0.750s/it]: train_loss_raw=0.4977, running_loss=0.4333, LR=0.000100
[2025-08-27 11:51:30,735][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064848] [Batch 00168/03080] [00:02:06/00:36:27, 0.751s/it]: train_loss_raw=0.4935, running_loss=0.4352, LR=0.000100
[2025-08-27 11:51:36,825][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064856] [Batch 00176/03080] [00:02:12/00:36:22, 0.752s/it]: train_loss_raw=0.4472, running_loss=0.4352, LR=0.000100
[2025-08-27 11:51:42,794][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064864] [Batch 00184/03080] [00:02:18/00:36:16, 0.751s/it]: train_loss_raw=0.3930, running_loss=0.4338, LR=0.000100
[2025-08-27 11:51:48,781][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064872] [Batch 00192/03080] [00:02:24/00:36:09, 0.751s/it]: train_loss_raw=0.4688, running_loss=0.4323, LR=0.000100
[2025-08-27 11:51:54,727][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064880] [Batch 00200/03080] [00:02:30/00:36:02, 0.751s/it]: train_loss_raw=0.3927, running_loss=0.4305, LR=0.000100
[2025-08-27 11:52:00,813][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064888] [Batch 00208/03080] [00:02:36/00:35:57, 0.751s/it]: train_loss_raw=0.4374, running_loss=0.4312, LR=0.000100
[2025-08-27 11:52:06,572][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064896] [Batch 00216/03080] [00:02:42/00:35:48, 0.750s/it]: train_loss_raw=0.4873, running_loss=0.4322, LR=0.000100
[2025-08-27 11:52:12,702][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064904] [Batch 00224/03080] [00:02:48/00:35:44, 0.751s/it]: train_loss_raw=0.4062, running_loss=0.4341, LR=0.000100
[2025-08-27 11:52:18,832][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064912] [Batch 00232/03080] [00:02:54/00:35:39, 0.751s/it]: train_loss_raw=0.4214, running_loss=0.4353, LR=0.000100
[2025-08-27 11:52:25,026][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064920] [Batch 00240/03080] [00:03:00/00:35:35, 0.752s/it]: train_loss_raw=0.4835, running_loss=0.4373, LR=0.000100
[2025-08-27 11:52:30,998][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064928] [Batch 00248/03080] [00:03:06/00:35:29, 0.752s/it]: train_loss_raw=0.4424, running_loss=0.4380, LR=0.000100
[2025-08-27 11:52:37,032][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064936] [Batch 00256/03080] [00:03:12/00:35:23, 0.752s/it]: train_loss_raw=0.3814, running_loss=0.4380, LR=0.000100
[2025-08-27 11:52:43,157][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064944] [Batch 00264/03080] [00:03:18/00:35:18, 0.752s/it]: train_loss_raw=0.4601, running_loss=0.4380, LR=0.000100
[2025-08-27 11:52:49,262][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064952] [Batch 00272/03080] [00:03:24/00:35:13, 0.753s/it]: train_loss_raw=0.3827, running_loss=0.4390, LR=0.000100
[2025-08-27 11:52:55,156][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064960] [Batch 00280/03080] [00:03:30/00:35:06, 0.752s/it]: train_loss_raw=0.4918, running_loss=0.4382, LR=0.000100
[2025-08-27 11:53:01,144][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064968] [Batch 00288/03080] [00:03:36/00:34:59, 0.752s/it]: train_loss_raw=0.4548, running_loss=0.4406, LR=0.000100
[2025-08-27 11:53:07,086][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064976] [Batch 00296/03080] [00:03:42/00:34:53, 0.752s/it]: train_loss_raw=0.3434, running_loss=0.4395, LR=0.000100
[2025-08-27 11:53:13,115][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064984] [Batch 00304/03080] [00:03:48/00:34:47, 0.752s/it]: train_loss_raw=0.5058, running_loss=0.4396, LR=0.000100
[2025-08-27 11:53:19,085][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 064992] [Batch 00312/03080] [00:03:54/00:34:40, 0.752s/it]: train_loss_raw=0.4458, running_loss=0.4384, LR=0.000100
[2025-08-27 11:53:25,096][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065000] [Batch 00320/03080] [00:04:00/00:34:34, 0.752s/it]: train_loss_raw=0.4179, running_loss=0.4392, LR=0.000100
[2025-08-27 11:53:31,109][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065008] [Batch 00328/03080] [00:04:06/00:34:28, 0.752s/it]: train_loss_raw=0.4108, running_loss=0.4379, LR=0.000100
[2025-08-27 11:53:37,150][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065016] [Batch 00336/03080] [00:04:12/00:34:23, 0.752s/it]: train_loss_raw=0.4111, running_loss=0.4391, LR=0.000100
[2025-08-27 11:53:43,197][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065024] [Batch 00344/03080] [00:04:18/00:34:17, 0.752s/it]: train_loss_raw=0.3454, running_loss=0.4367, LR=0.000100
[2025-08-27 11:53:49,124][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065032] [Batch 00352/03080] [00:04:24/00:34:10, 0.752s/it]: train_loss_raw=0.4516, running_loss=0.4401, LR=0.000100
[2025-08-27 11:53:54,688][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065040] [Batch 00360/03080] [00:04:30/00:34:01, 0.750s/it]: train_loss_raw=0.4248, running_loss=0.4384, LR=0.000100
[2025-08-27 11:54:00,358][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065048] [Batch 00368/03080] [00:04:35/00:33:52, 0.750s/it]: train_loss_raw=0.4312, running_loss=0.4388, LR=0.000100
[2025-08-27 11:54:06,380][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065056] [Batch 00376/03080] [00:04:41/00:33:46, 0.750s/it]: train_loss_raw=0.4300, running_loss=0.4397, LR=0.000100
[2025-08-27 11:54:12,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065064] [Batch 00384/03080] [00:04:47/00:33:41, 0.750s/it]: train_loss_raw=0.4909, running_loss=0.4378, LR=0.000100
[2025-08-27 11:54:18,476][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065072] [Batch 00392/03080] [00:04:53/00:33:35, 0.750s/it]: train_loss_raw=0.4786, running_loss=0.4379, LR=0.000100
[2025-08-27 11:54:24,545][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065080] [Batch 00400/03080] [00:05:00/00:33:30, 0.750s/it]: train_loss_raw=0.4342, running_loss=0.4367, LR=0.000100
[2025-08-27 11:54:30,644][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065088] [Batch 00408/03080] [00:05:06/00:33:24, 0.750s/it]: train_loss_raw=0.3829, running_loss=0.4362, LR=0.000100
[2025-08-27 11:54:36,637][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065096] [Batch 00416/03080] [00:05:12/00:33:18, 0.750s/it]: train_loss_raw=0.4278, running_loss=0.4346, LR=0.000100
[2025-08-27 11:54:42,599][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065104] [Batch 00424/03080] [00:05:18/00:33:12, 0.750s/it]: train_loss_raw=0.3822, running_loss=0.4333, LR=0.000100
[2025-08-27 11:54:48,678][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065112] [Batch 00432/03080] [00:05:24/00:33:06, 0.750s/it]: train_loss_raw=0.4034, running_loss=0.4339, LR=0.000100
[2025-08-27 11:54:54,630][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065120] [Batch 00440/03080] [00:05:30/00:33:00, 0.750s/it]: train_loss_raw=0.4457, running_loss=0.4323, LR=0.000100
[2025-08-27 11:55:00,609][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065128] [Batch 00448/03080] [00:05:36/00:32:54, 0.750s/it]: train_loss_raw=0.3895, running_loss=0.4326, LR=0.000100
[2025-08-27 11:55:06,582][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065136] [Batch 00456/03080] [00:05:42/00:32:48, 0.750s/it]: train_loss_raw=0.4719, running_loss=0.4339, LR=0.000100
[2025-08-27 11:55:12,593][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065144] [Batch 00464/03080] [00:05:48/00:32:42, 0.750s/it]: train_loss_raw=0.5166, running_loss=0.4326, LR=0.000100
[2025-08-27 11:55:18,539][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065152] [Batch 00472/03080] [00:05:54/00:32:36, 0.750s/it]: train_loss_raw=0.4158, running_loss=0.4312, LR=0.000100
[2025-08-27 11:55:24,280][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065160] [Batch 00480/03080] [00:05:59/00:32:28, 0.749s/it]: train_loss_raw=0.4003, running_loss=0.4321, LR=0.000100
[2025-08-27 11:55:30,160][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065168] [Batch 00488/03080] [00:06:05/00:32:22, 0.749s/it]: train_loss_raw=0.4678, running_loss=0.4309, LR=0.000100
[2025-08-27 11:55:36,203][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065176] [Batch 00496/03080] [00:06:11/00:32:16, 0.749s/it]: train_loss_raw=0.4105, running_loss=0.4317, LR=0.000100
[2025-08-27 11:55:42,206][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065184] [Batch 00504/03080] [00:06:17/00:32:10, 0.749s/it]: train_loss_raw=0.3970, running_loss=0.4332, LR=0.000100
[2025-08-27 11:55:48,238][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065192] [Batch 00512/03080] [00:06:23/00:32:04, 0.749s/it]: train_loss_raw=0.3764, running_loss=0.4327, LR=0.000100
[2025-08-27 11:55:54,271][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065200] [Batch 00520/03080] [00:06:29/00:31:58, 0.749s/it]: train_loss_raw=0.3898, running_loss=0.4321, LR=0.000100
[2025-08-27 11:56:00,359][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065208] [Batch 00528/03080] [00:06:35/00:31:53, 0.750s/it]: train_loss_raw=0.4028, running_loss=0.4355, LR=0.000100
[2025-08-27 11:56:06,431][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065216] [Batch 00536/03080] [00:06:41/00:31:47, 0.750s/it]: train_loss_raw=0.4304, running_loss=0.4356, LR=0.000100
[2025-08-27 11:56:12,427][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065224] [Batch 00544/03080] [00:06:47/00:31:41, 0.750s/it]: train_loss_raw=0.3733, running_loss=0.4324, LR=0.000100
[2025-08-27 11:56:18,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065232] [Batch 00552/03080] [00:06:53/00:31:35, 0.750s/it]: train_loss_raw=0.4356, running_loss=0.4345, LR=0.000100
[2025-08-27 11:56:24,400][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065240] [Batch 00560/03080] [00:06:59/00:31:29, 0.750s/it]: train_loss_raw=0.4982, running_loss=0.4333, LR=0.000100
[2025-08-27 11:56:30,375][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065248] [Batch 00568/03080] [00:07:05/00:31:23, 0.750s/it]: train_loss_raw=0.4325, running_loss=0.4338, LR=0.000100
[2025-08-27 11:56:36,371][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065256] [Batch 00576/03080] [00:07:11/00:31:17, 0.750s/it]: train_loss_raw=0.4882, running_loss=0.4355, LR=0.000100
[2025-08-27 11:56:42,471][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065264] [Batch 00584/03080] [00:07:17/00:31:11, 0.750s/it]: train_loss_raw=0.3742, running_loss=0.4353, LR=0.000100
[2025-08-27 11:56:48,565][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065272] [Batch 00592/03080] [00:07:24/00:31:06, 0.750s/it]: train_loss_raw=0.4573, running_loss=0.4350, LR=0.000100
[2025-08-27 11:56:54,558][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065280] [Batch 00600/03080] [00:07:30/00:31:00, 0.750s/it]: train_loss_raw=0.4156, running_loss=0.4349, LR=0.000100
[2025-08-27 11:57:00,542][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065288] [Batch 00608/03080] [00:07:36/00:30:54, 0.750s/it]: train_loss_raw=0.4697, running_loss=0.4369, LR=0.000100
[2025-08-27 11:57:06,535][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065296] [Batch 00616/03080] [00:07:42/00:30:48, 0.750s/it]: train_loss_raw=0.3730, running_loss=0.4351, LR=0.000100
[2025-08-27 11:57:12,570][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065304] [Batch 00624/03080] [00:07:48/00:30:42, 0.750s/it]: train_loss_raw=0.4077, running_loss=0.4334, LR=0.000100
[2025-08-27 11:57:18,633][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065312] [Batch 00632/03080] [00:07:54/00:30:36, 0.750s/it]: train_loss_raw=0.5783, running_loss=0.4332, LR=0.000100
[2025-08-27 11:57:24,620][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065320] [Batch 00640/03080] [00:08:00/00:30:30, 0.750s/it]: train_loss_raw=0.3723, running_loss=0.4309, LR=0.000100
[2025-08-27 11:57:30,612][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065328] [Batch 00648/03080] [00:08:06/00:30:24, 0.750s/it]: train_loss_raw=0.3845, running_loss=0.4305, LR=0.000100
[2025-08-27 11:57:36,603][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065336] [Batch 00656/03080] [00:08:12/00:30:18, 0.750s/it]: train_loss_raw=0.3906, running_loss=0.4292, LR=0.000100
[2025-08-27 11:57:42,579][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065344] [Batch 00664/03080] [00:08:18/00:30:12, 0.750s/it]: train_loss_raw=0.4260, running_loss=0.4279, LR=0.000100
[2025-08-27 11:57:48,281][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065352] [Batch 00672/03080] [00:08:23/00:30:05, 0.750s/it]: train_loss_raw=0.3509, running_loss=0.4268, LR=0.000100
[2025-08-27 11:57:54,013][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065360] [Batch 00680/03080] [00:08:29/00:29:58, 0.749s/it]: train_loss_raw=0.3825, running_loss=0.4271, LR=0.000100
[2025-08-27 11:57:59,991][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065368] [Batch 00688/03080] [00:08:35/00:29:52, 0.749s/it]: train_loss_raw=0.3938, running_loss=0.4293, LR=0.000100
[2025-08-27 11:58:06,039][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065376] [Batch 00696/03080] [00:08:41/00:29:46, 0.749s/it]: train_loss_raw=0.4359, running_loss=0.4292, LR=0.000100
[2025-08-27 11:58:12,155][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065384] [Batch 00704/03080] [00:08:47/00:29:40, 0.749s/it]: train_loss_raw=0.4388, running_loss=0.4299, LR=0.000100
[2025-08-27 11:58:18,115][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065392] [Batch 00712/03080] [00:08:53/00:29:34, 0.749s/it]: train_loss_raw=0.4287, running_loss=0.4328, LR=0.000100
[2025-08-27 11:58:24,185][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065400] [Batch 00720/03080] [00:08:59/00:29:28, 0.750s/it]: train_loss_raw=0.4528, running_loss=0.4342, LR=0.000100
[2025-08-27 11:58:30,218][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065408] [Batch 00728/03080] [00:09:05/00:29:22, 0.750s/it]: train_loss_raw=0.4429, running_loss=0.4356, LR=0.000100
[2025-08-27 11:58:36,235][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065416] [Batch 00736/03080] [00:09:11/00:29:17, 0.750s/it]: train_loss_raw=0.4718, running_loss=0.4377, LR=0.000100
[2025-08-27 11:58:42,165][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065424] [Batch 00744/03080] [00:09:17/00:29:10, 0.750s/it]: train_loss_raw=0.3205, running_loss=0.4357, LR=0.000100
[2025-08-27 11:58:47,966][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065432] [Batch 00752/03080] [00:09:23/00:29:04, 0.749s/it]: train_loss_raw=0.5209, running_loss=0.4363, LR=0.000100
[2025-08-27 11:58:53,923][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065440] [Batch 00760/03080] [00:09:29/00:28:58, 0.749s/it]: train_loss_raw=0.3456, running_loss=0.4364, LR=0.000100
[2025-08-27 11:58:59,890][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065448] [Batch 00768/03080] [00:09:35/00:28:52, 0.749s/it]: train_loss_raw=0.4355, running_loss=0.4369, LR=0.000100
[2025-08-27 11:59:05,901][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065456] [Batch 00776/03080] [00:09:41/00:28:46, 0.749s/it]: train_loss_raw=0.3840, running_loss=0.4351, LR=0.000100
[2025-08-27 11:59:11,921][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065464] [Batch 00784/03080] [00:09:47/00:28:40, 0.749s/it]: train_loss_raw=0.3782, running_loss=0.4326, LR=0.000100
[2025-08-27 11:59:18,017][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065472] [Batch 00792/03080] [00:09:53/00:28:34, 0.749s/it]: train_loss_raw=0.3451, running_loss=0.4303, LR=0.000100
[2025-08-27 11:59:24,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065480] [Batch 00800/03080] [00:09:59/00:28:28, 0.749s/it]: train_loss_raw=0.4258, running_loss=0.4307, LR=0.000100
[2025-08-27 11:59:30,116][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065488] [Batch 00808/03080] [00:10:05/00:28:22, 0.749s/it]: train_loss_raw=0.3899, running_loss=0.4319, LR=0.000100
[2025-08-27 11:59:36,105][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065496] [Batch 00816/03080] [00:10:11/00:28:16, 0.749s/it]: train_loss_raw=0.3471, running_loss=0.4311, LR=0.000100
[2025-08-27 11:59:42,090][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065504] [Batch 00824/03080] [00:10:17/00:28:10, 0.749s/it]: train_loss_raw=0.4232, running_loss=0.4316, LR=0.000100
[2025-08-27 11:59:48,161][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065512] [Batch 00832/03080] [00:10:23/00:28:04, 0.750s/it]: train_loss_raw=0.4398, running_loss=0.4317, LR=0.000100
[2025-08-27 11:59:54,158][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065520] [Batch 00840/03080] [00:10:29/00:27:58, 0.750s/it]: train_loss_raw=0.5212, running_loss=0.4314, LR=0.000100
[2025-08-27 12:00:00,170][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065528] [Batch 00848/03080] [00:10:35/00:27:53, 0.750s/it]: train_loss_raw=0.4248, running_loss=0.4331, LR=0.000100
[2025-08-27 12:00:06,122][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065536] [Batch 00856/03080] [00:10:41/00:27:46, 0.750s/it]: train_loss_raw=0.4960, running_loss=0.4332, LR=0.000100
[2025-08-27 12:00:12,114][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065544] [Batch 00864/03080] [00:10:47/00:27:40, 0.750s/it]: train_loss_raw=0.5151, running_loss=0.4350, LR=0.000100
[2025-08-27 12:00:18,099][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065552] [Batch 00872/03080] [00:10:53/00:27:34, 0.750s/it]: train_loss_raw=0.4153, running_loss=0.4360, LR=0.000100
[2025-08-27 12:00:24,063][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065560] [Batch 00880/03080] [00:10:59/00:27:28, 0.749s/it]: train_loss_raw=0.4071, running_loss=0.4396, LR=0.000100
[2025-08-27 12:00:30,015][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065568] [Batch 00888/03080] [00:11:05/00:27:22, 0.749s/it]: train_loss_raw=0.3785, running_loss=0.4404, LR=0.000100
[2025-08-27 12:00:36,017][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065576] [Batch 00896/03080] [00:11:11/00:27:16, 0.749s/it]: train_loss_raw=0.4090, running_loss=0.4398, LR=0.000100
[2025-08-27 12:00:42,081][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065584] [Batch 00904/03080] [00:11:17/00:27:10, 0.749s/it]: train_loss_raw=0.4132, running_loss=0.4369, LR=0.000100
[2025-08-27 12:00:48,058][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065592] [Batch 00912/03080] [00:11:23/00:27:04, 0.749s/it]: train_loss_raw=0.4186, running_loss=0.4345, LR=0.000100
[2025-08-27 12:00:54,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065600] [Batch 00920/03080] [00:11:29/00:26:58, 0.749s/it]: train_loss_raw=0.4503, running_loss=0.4370, LR=0.000100
[2025-08-27 12:01:00,154][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065608] [Batch 00928/03080] [00:11:35/00:26:53, 0.750s/it]: train_loss_raw=0.4509, running_loss=0.4382, LR=0.000100
[2025-08-27 12:01:06,208][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065616] [Batch 00936/03080] [00:11:41/00:26:47, 0.750s/it]: train_loss_raw=0.5068, running_loss=0.4383, LR=0.000100
[2025-08-27 12:01:12,165][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065624] [Batch 00944/03080] [00:11:47/00:26:41, 0.750s/it]: train_loss_raw=0.4525, running_loss=0.4360, LR=0.000100
[2025-08-27 12:01:18,169][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065632] [Batch 00952/03080] [00:11:53/00:26:35, 0.750s/it]: train_loss_raw=0.5273, running_loss=0.4372, LR=0.000100
[2025-08-27 12:01:24,111][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065640] [Batch 00960/03080] [00:11:59/00:26:29, 0.750s/it]: train_loss_raw=0.3364, running_loss=0.4369, LR=0.000100
[2025-08-27 12:01:30,070][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065648] [Batch 00968/03080] [00:12:05/00:26:22, 0.750s/it]: train_loss_raw=0.4645, running_loss=0.4381, LR=0.000100
[2025-08-27 12:01:35,619][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065656] [Batch 00976/03080] [00:12:11/00:26:16, 0.749s/it]: train_loss_raw=0.4306, running_loss=0.4391, LR=0.000100
[2025-08-27 12:01:41,497][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065664] [Batch 00984/03080] [00:12:16/00:26:09, 0.749s/it]: train_loss_raw=0.4657, running_loss=0.4391, LR=0.000100
[2025-08-27 12:01:47,129][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065672] [Batch 00992/03080] [00:12:22/00:26:03, 0.749s/it]: train_loss_raw=0.4399, running_loss=0.4390, LR=0.000100
[2025-08-27 12:01:52,777][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065680] [Batch 01000/03080] [00:12:28/00:25:56, 0.748s/it]: train_loss_raw=0.5489, running_loss=0.4396, LR=0.000100
[2025-08-27 12:01:58,254][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065688] [Batch 01008/03080] [00:12:33/00:25:49, 0.748s/it]: train_loss_raw=0.4108, running_loss=0.4407, LR=0.000100
[2025-08-27 12:02:03,846][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065696] [Batch 01016/03080] [00:12:39/00:25:42, 0.747s/it]: train_loss_raw=0.3920, running_loss=0.4391, LR=0.000100
[2025-08-27 12:02:09,757][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065704] [Batch 01024/03080] [00:12:45/00:25:36, 0.747s/it]: train_loss_raw=0.4454, running_loss=0.4380, LR=0.000100
[2025-08-27 12:02:15,801][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065712] [Batch 01032/03080] [00:12:51/00:25:30, 0.747s/it]: train_loss_raw=0.4814, running_loss=0.4403, LR=0.000100
[2025-08-27 12:02:21,900][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065720] [Batch 01040/03080] [00:12:57/00:25:24, 0.747s/it]: train_loss_raw=0.5396, running_loss=0.4417, LR=0.000100
[2025-08-27 12:02:27,869][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065728] [Batch 01048/03080] [00:13:03/00:25:18, 0.747s/it]: train_loss_raw=0.4083, running_loss=0.4408, LR=0.000100
[2025-08-27 12:02:33,858][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065736] [Batch 01056/03080] [00:13:09/00:25:12, 0.747s/it]: train_loss_raw=0.4513, running_loss=0.4407, LR=0.000100
[2025-08-27 12:02:39,859][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065744] [Batch 01064/03080] [00:13:15/00:25:06, 0.747s/it]: train_loss_raw=0.4577, running_loss=0.4416, LR=0.000100
[2025-08-27 12:02:45,877][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065752] [Batch 01072/03080] [00:13:21/00:25:01, 0.748s/it]: train_loss_raw=0.4917, running_loss=0.4428, LR=0.000100
[2025-08-27 12:02:51,983][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065760] [Batch 01080/03080] [00:13:27/00:24:55, 0.748s/it]: train_loss_raw=0.4166, running_loss=0.4416, LR=0.000100
[2025-08-27 12:02:58,022][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065768] [Batch 01088/03080] [00:13:33/00:24:49, 0.748s/it]: train_loss_raw=0.5077, running_loss=0.4402, LR=0.000100
[2025-08-27 12:03:03,980][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065776] [Batch 01096/03080] [00:13:39/00:24:43, 0.748s/it]: train_loss_raw=0.4561, running_loss=0.4404, LR=0.000100
[2025-08-27 12:03:09,849][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065784] [Batch 01104/03080] [00:13:45/00:24:37, 0.748s/it]: train_loss_raw=0.4446, running_loss=0.4418, LR=0.000100
[2025-08-27 12:03:16,069][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065792] [Batch 01112/03080] [00:13:51/00:24:31, 0.748s/it]: train_loss_raw=0.4339, running_loss=0.4422, LR=0.000100
[2025-08-27 12:03:22,226][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065800] [Batch 01120/03080] [00:13:57/00:24:25, 0.748s/it]: train_loss_raw=0.3632, running_loss=0.4380, LR=0.000100
[2025-08-27 12:03:28,250][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065808] [Batch 01128/03080] [00:14:03/00:24:20, 0.748s/it]: train_loss_raw=0.4756, running_loss=0.4379, LR=0.000100
[2025-08-27 12:03:34,256][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065816] [Batch 01136/03080] [00:14:09/00:24:14, 0.748s/it]: train_loss_raw=0.4116, running_loss=0.4386, LR=0.000100
[2025-08-27 12:03:40,229][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065824] [Batch 01144/03080] [00:14:15/00:24:08, 0.748s/it]: train_loss_raw=0.4699, running_loss=0.4370, LR=0.000100
[2025-08-27 12:03:46,327][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065832] [Batch 01152/03080] [00:14:21/00:24:02, 0.748s/it]: train_loss_raw=0.3865, running_loss=0.4363, LR=0.000100
[2025-08-27 12:03:52,308][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065840] [Batch 01160/03080] [00:14:27/00:23:56, 0.748s/it]: train_loss_raw=0.4146, running_loss=0.4355, LR=0.000100
[2025-08-27 12:03:58,272][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065848] [Batch 01168/03080] [00:14:33/00:23:50, 0.748s/it]: train_loss_raw=0.3997, running_loss=0.4367, LR=0.000100
[2025-08-27 12:04:04,359][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065856] [Batch 01176/03080] [00:14:39/00:23:44, 0.748s/it]: train_loss_raw=0.3903, running_loss=0.4346, LR=0.000100
[2025-08-27 12:04:10,607][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065864] [Batch 01184/03080] [00:14:46/00:23:38, 0.748s/it]: train_loss_raw=0.4113, running_loss=0.4350, LR=0.000100
[2025-08-27 12:04:16,638][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065872] [Batch 01192/03080] [00:14:52/00:23:32, 0.748s/it]: train_loss_raw=0.4327, running_loss=0.4342, LR=0.000100
[2025-08-27 12:04:22,675][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065880] [Batch 01200/03080] [00:14:58/00:23:27, 0.748s/it]: train_loss_raw=0.4602, running_loss=0.4311, LR=0.000100
[2025-08-27 12:04:28,718][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065888] [Batch 01208/03080] [00:15:04/00:23:21, 0.748s/it]: train_loss_raw=0.3397, running_loss=0.4325, LR=0.000100
[2025-08-27 12:04:34,686][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065896] [Batch 01216/03080] [00:15:10/00:23:15, 0.748s/it]: train_loss_raw=0.4219, running_loss=0.4318, LR=0.000100
[2025-08-27 12:04:40,684][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065904] [Batch 01224/03080] [00:15:16/00:23:09, 0.748s/it]: train_loss_raw=0.3506, running_loss=0.4329, LR=0.000100
[2025-08-27 12:04:46,745][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065912] [Batch 01232/03080] [00:15:22/00:23:03, 0.749s/it]: train_loss_raw=0.4676, running_loss=0.4326, LR=0.000100
[2025-08-27 12:04:52,857][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065920] [Batch 01240/03080] [00:15:28/00:22:57, 0.749s/it]: train_loss_raw=0.3739, running_loss=0.4321, LR=0.000100
[2025-08-27 12:04:58,952][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065928] [Batch 01248/03080] [00:15:34/00:22:51, 0.749s/it]: train_loss_raw=0.3696, running_loss=0.4336, LR=0.000100
[2025-08-27 12:05:04,975][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065936] [Batch 01256/03080] [00:15:40/00:22:45, 0.749s/it]: train_loss_raw=0.5642, running_loss=0.4337, LR=0.000100
[2025-08-27 12:05:10,946][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065944] [Batch 01264/03080] [00:15:46/00:22:39, 0.749s/it]: train_loss_raw=0.4530, running_loss=0.4332, LR=0.000100
[2025-08-27 12:05:16,965][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065952] [Batch 01272/03080] [00:15:52/00:22:33, 0.749s/it]: train_loss_raw=0.4150, running_loss=0.4313, LR=0.000100
[2025-08-27 12:05:23,075][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065960] [Batch 01280/03080] [00:15:58/00:22:27, 0.749s/it]: train_loss_raw=0.4619, running_loss=0.4305, LR=0.000100
[2025-08-27 12:05:29,080][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065968] [Batch 01288/03080] [00:16:04/00:22:21, 0.749s/it]: train_loss_raw=0.4214, running_loss=0.4303, LR=0.000100
[2025-08-27 12:05:35,026][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065976] [Batch 01296/03080] [00:16:10/00:22:15, 0.749s/it]: train_loss_raw=0.5207, running_loss=0.4327, LR=0.000100
[2025-08-27 12:05:41,031][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065984] [Batch 01304/03080] [00:16:16/00:22:09, 0.749s/it]: train_loss_raw=0.4409, running_loss=0.4333, LR=0.000100
[2025-08-27 12:05:46,998][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 065992] [Batch 01312/03080] [00:16:22/00:22:03, 0.749s/it]: train_loss_raw=0.3827, running_loss=0.4348, LR=0.000100
[2025-08-27 12:05:53,055][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066000] [Batch 01320/03080] [00:16:28/00:21:58, 0.749s/it]: train_loss_raw=0.5108, running_loss=0.4357, LR=0.000100
[2025-08-27 12:06:02,544][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066008] [Batch 01328/03080] [00:16:38/00:21:56, 0.752s/it]: train_loss_raw=0.4642, running_loss=0.4370, LR=0.000100
[2025-08-27 12:06:08,567][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066016] [Batch 01336/03080] [00:16:44/00:21:50, 0.752s/it]: train_loss_raw=0.4024, running_loss=0.4371, LR=0.000100
[2025-08-27 12:06:14,516][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066024] [Batch 01344/03080] [00:16:49/00:21:44, 0.751s/it]: train_loss_raw=0.4353, running_loss=0.4373, LR=0.000100
[2025-08-27 12:06:20,464][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066032] [Batch 01352/03080] [00:16:55/00:21:38, 0.751s/it]: train_loss_raw=0.5063, running_loss=0.4387, LR=0.000100
[2025-08-27 12:06:26,461][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066040] [Batch 01360/03080] [00:17:01/00:21:32, 0.751s/it]: train_loss_raw=0.4288, running_loss=0.4397, LR=0.000100
[2025-08-27 12:06:32,865][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066048] [Batch 01368/03080] [00:17:08/00:21:26, 0.752s/it]: train_loss_raw=0.4449, running_loss=0.4417, LR=0.000100
[2025-08-27 12:06:38,874][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066056] [Batch 01376/03080] [00:17:14/00:21:20, 0.752s/it]: train_loss_raw=0.5258, running_loss=0.4398, LR=0.000100
[2025-08-27 12:06:44,924][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066064] [Batch 01384/03080] [00:17:20/00:21:14, 0.752s/it]: train_loss_raw=0.4350, running_loss=0.4410, LR=0.000100
[2025-08-27 12:06:51,008][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066072] [Batch 01392/03080] [00:17:26/00:21:08, 0.752s/it]: train_loss_raw=0.3880, running_loss=0.4409, LR=0.000100
[2025-08-27 12:06:57,104][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066080] [Batch 01400/03080] [00:17:32/00:21:03, 0.752s/it]: train_loss_raw=0.4259, running_loss=0.4395, LR=0.000100
[2025-08-27 12:07:03,131][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066088] [Batch 01408/03080] [00:17:38/00:20:57, 0.752s/it]: train_loss_raw=0.4122, running_loss=0.4367, LR=0.000100
[2025-08-27 12:07:09,082][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066096] [Batch 01416/03080] [00:17:44/00:20:50, 0.752s/it]: train_loss_raw=0.4349, running_loss=0.4344, LR=0.000100
[2025-08-27 12:07:15,082][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066104] [Batch 01424/03080] [00:17:50/00:20:44, 0.752s/it]: train_loss_raw=0.4858, running_loss=0.4335, LR=0.000100
[2025-08-27 12:07:21,081][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066112] [Batch 01432/03080] [00:17:56/00:20:38, 0.752s/it]: train_loss_raw=0.3757, running_loss=0.4332, LR=0.000100
[2025-08-27 12:07:27,098][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066120] [Batch 01440/03080] [00:18:02/00:20:32, 0.752s/it]: train_loss_raw=0.5020, running_loss=0.4373, LR=0.000100
[2025-08-27 12:07:33,070][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066128] [Batch 01448/03080] [00:18:08/00:20:26, 0.752s/it]: train_loss_raw=0.5991, running_loss=0.4376, LR=0.000100
[2025-08-27 12:07:39,067][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066136] [Batch 01456/03080] [00:18:14/00:20:20, 0.752s/it]: train_loss_raw=0.4982, running_loss=0.4371, LR=0.000100
[2025-08-27 12:07:45,136][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066144] [Batch 01464/03080] [00:18:20/00:20:14, 0.752s/it]: train_loss_raw=0.4691, running_loss=0.4385, LR=0.000100
[2025-08-27 12:07:51,185][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066152] [Batch 01472/03080] [00:18:26/00:20:08, 0.752s/it]: train_loss_raw=0.4386, running_loss=0.4376, LR=0.000100
[2025-08-27 12:07:57,181][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066160] [Batch 01480/03080] [00:18:32/00:20:02, 0.752s/it]: train_loss_raw=0.4825, running_loss=0.4358, LR=0.000100
[2025-08-27 12:08:03,189][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066168] [Batch 01488/03080] [00:18:38/00:19:56, 0.752s/it]: train_loss_raw=0.4933, running_loss=0.4385, LR=0.000100
[2025-08-27 12:08:09,267][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066176] [Batch 01496/03080] [00:18:44/00:19:50, 0.752s/it]: train_loss_raw=0.4083, running_loss=0.4390, LR=0.000100
[2025-08-27 12:08:15,237][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066184] [Batch 01504/03080] [00:18:50/00:19:44, 0.752s/it]: train_loss_raw=0.3282, running_loss=0.4350, LR=0.000100
[2025-08-27 12:08:21,276][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066192] [Batch 01512/03080] [00:18:56/00:19:38, 0.752s/it]: train_loss_raw=0.4994, running_loss=0.4347, LR=0.000100
[2025-08-27 12:08:27,332][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066200] [Batch 01520/03080] [00:19:02/00:19:32, 0.752s/it]: train_loss_raw=0.5061, running_loss=0.4336, LR=0.000100
[2025-08-27 12:08:33,319][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066208] [Batch 01528/03080] [00:19:08/00:19:26, 0.752s/it]: train_loss_raw=0.4781, running_loss=0.4312, LR=0.000100
[2025-08-27 12:08:39,381][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066216] [Batch 01536/03080] [00:19:14/00:19:20, 0.752s/it]: train_loss_raw=0.4534, running_loss=0.4296, LR=0.000100
[2025-08-27 12:08:45,542][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066224] [Batch 01544/03080] [00:19:21/00:19:14, 0.752s/it]: train_loss_raw=0.4368, running_loss=0.4294, LR=0.000100
[2025-08-27 12:08:51,513][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066232] [Batch 01552/03080] [00:19:26/00:19:08, 0.752s/it]: train_loss_raw=0.3840, running_loss=0.4309, LR=0.000100
[2025-08-27 12:08:57,510][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066240] [Batch 01560/03080] [00:19:32/00:19:02, 0.752s/it]: train_loss_raw=0.4615, running_loss=0.4334, LR=0.000100
[2025-08-27 12:09:03,724][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066248] [Batch 01568/03080] [00:19:39/00:18:57, 0.752s/it]: train_loss_raw=0.4284, running_loss=0.4339, LR=0.000100
[2025-08-27 12:09:09,733][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066256] [Batch 01576/03080] [00:19:45/00:18:51, 0.752s/it]: train_loss_raw=0.4620, running_loss=0.4337, LR=0.000100
[2025-08-27 12:09:15,727][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066264] [Batch 01584/03080] [00:19:51/00:18:45, 0.752s/it]: train_loss_raw=0.4889, running_loss=0.4369, LR=0.000100
[2025-08-27 12:09:21,710][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066272] [Batch 01592/03080] [00:19:57/00:18:38, 0.752s/it]: train_loss_raw=0.4360, running_loss=0.4368, LR=0.000100
[2025-08-27 12:09:27,803][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066280] [Batch 01600/03080] [00:20:03/00:18:33, 0.752s/it]: train_loss_raw=0.4269, running_loss=0.4370, LR=0.000100
[2025-08-27 12:09:33,835][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066288] [Batch 01608/03080] [00:20:09/00:18:27, 0.752s/it]: train_loss_raw=0.4788, running_loss=0.4357, LR=0.000100
[2025-08-27 12:09:39,896][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066296] [Batch 01616/03080] [00:20:15/00:18:21, 0.752s/it]: train_loss_raw=0.4055, running_loss=0.4376, LR=0.000100
[2025-08-27 12:09:45,889][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066304] [Batch 01624/03080] [00:20:21/00:18:15, 0.752s/it]: train_loss_raw=0.4096, running_loss=0.4368, LR=0.000100
[2025-08-27 12:09:52,030][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066312] [Batch 01632/03080] [00:20:27/00:18:09, 0.752s/it]: train_loss_raw=0.4284, running_loss=0.4354, LR=0.000100
[2025-08-27 12:09:58,009][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066320] [Batch 01640/03080] [00:20:33/00:18:03, 0.752s/it]: train_loss_raw=0.4579, running_loss=0.4338, LR=0.000100
[2025-08-27 12:10:04,028][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066328] [Batch 01648/03080] [00:20:39/00:17:57, 0.752s/it]: train_loss_raw=0.4824, running_loss=0.4320, LR=0.000100
[2025-08-27 12:10:10,043][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066336] [Batch 01656/03080] [00:20:45/00:17:51, 0.752s/it]: train_loss_raw=0.4215, running_loss=0.4328, LR=0.000100
[2025-08-27 12:10:16,093][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066344] [Batch 01664/03080] [00:20:51/00:17:45, 0.752s/it]: train_loss_raw=0.4155, running_loss=0.4342, LR=0.000100
[2025-08-27 12:10:22,089][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066352] [Batch 01672/03080] [00:20:57/00:17:38, 0.752s/it]: train_loss_raw=0.4818, running_loss=0.4349, LR=0.000100
[2025-08-27 12:10:28,080][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066360] [Batch 01680/03080] [00:21:03/00:17:32, 0.752s/it]: train_loss_raw=0.4538, running_loss=0.4348, LR=0.000100
[2025-08-27 12:10:34,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066368] [Batch 01688/03080] [00:21:09/00:17:26, 0.752s/it]: train_loss_raw=0.4644, running_loss=0.4351, LR=0.000100
[2025-08-27 12:10:40,206][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066376] [Batch 01696/03080] [00:21:15/00:17:20, 0.752s/it]: train_loss_raw=0.5733, running_loss=0.4337, LR=0.000100
[2025-08-27 12:10:46,262][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066384] [Batch 01704/03080] [00:21:21/00:17:15, 0.752s/it]: train_loss_raw=0.4296, running_loss=0.4335, LR=0.000100
[2025-08-27 12:10:52,256][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066392] [Batch 01712/03080] [00:21:27/00:17:08, 0.752s/it]: train_loss_raw=0.3889, running_loss=0.4311, LR=0.000100
[2025-08-27 12:10:58,226][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066400] [Batch 01720/03080] [00:21:33/00:17:02, 0.752s/it]: train_loss_raw=0.4383, running_loss=0.4310, LR=0.000100
[2025-08-27 12:11:04,301][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066408] [Batch 01728/03080] [00:21:39/00:16:56, 0.752s/it]: train_loss_raw=0.3455, running_loss=0.4287, LR=0.000100
[2025-08-27 12:11:10,364][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066416] [Batch 01736/03080] [00:21:45/00:16:50, 0.752s/it]: train_loss_raw=0.4181, running_loss=0.4285, LR=0.000100
[2025-08-27 12:11:16,445][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066424] [Batch 01744/03080] [00:21:51/00:16:44, 0.752s/it]: train_loss_raw=0.4126, running_loss=0.4287, LR=0.000100
[2025-08-27 12:11:22,386][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066432] [Batch 01752/03080] [00:21:57/00:16:38, 0.752s/it]: train_loss_raw=0.3262, running_loss=0.4284, LR=0.000100
[2025-08-27 12:11:28,337][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066440] [Batch 01760/03080] [00:22:03/00:16:32, 0.752s/it]: train_loss_raw=0.3569, running_loss=0.4291, LR=0.000100
[2025-08-27 12:11:34,291][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066448] [Batch 01768/03080] [00:22:09/00:16:26, 0.752s/it]: train_loss_raw=0.3557, running_loss=0.4277, LR=0.000100
[2025-08-27 12:11:40,025][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066456] [Batch 01776/03080] [00:22:15/00:16:20, 0.752s/it]: train_loss_raw=0.4449, running_loss=0.4283, LR=0.000100
[2025-08-27 12:11:46,013][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066464] [Batch 01784/03080] [00:22:21/00:16:14, 0.752s/it]: train_loss_raw=0.3756, running_loss=0.4264, LR=0.000100
[2025-08-27 12:11:52,217][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066472] [Batch 01792/03080] [00:22:27/00:16:08, 0.752s/it]: train_loss_raw=0.4328, running_loss=0.4278, LR=0.000100
[2025-08-27 12:11:58,274][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066480] [Batch 01800/03080] [00:22:33/00:16:02, 0.752s/it]: train_loss_raw=0.4895, running_loss=0.4250, LR=0.000100
[2025-08-27 12:12:04,270][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066488] [Batch 01808/03080] [00:22:39/00:15:56, 0.752s/it]: train_loss_raw=0.3113, running_loss=0.4261, LR=0.000100
[2025-08-27 12:12:10,427][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066496] [Batch 01816/03080] [00:22:45/00:15:50, 0.752s/it]: train_loss_raw=0.4525, running_loss=0.4273, LR=0.000100
[2025-08-27 12:12:16,552][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066504] [Batch 01824/03080] [00:22:52/00:15:44, 0.752s/it]: train_loss_raw=0.3676, running_loss=0.4261, LR=0.000100
[2025-08-27 12:12:22,592][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066512] [Batch 01832/03080] [00:22:58/00:15:38, 0.752s/it]: train_loss_raw=0.3762, running_loss=0.4269, LR=0.000100
[2025-08-27 12:12:28,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066520] [Batch 01840/03080] [00:23:03/00:15:32, 0.752s/it]: train_loss_raw=0.4069, running_loss=0.4263, LR=0.000100
[2025-08-27 12:12:34,476][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066528] [Batch 01848/03080] [00:23:09/00:15:26, 0.752s/it]: train_loss_raw=0.3745, running_loss=0.4252, LR=0.000100
[2025-08-27 12:12:40,548][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066536] [Batch 01856/03080] [00:23:16/00:15:20, 0.752s/it]: train_loss_raw=0.3449, running_loss=0.4244, LR=0.000100
[2025-08-27 12:12:46,669][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066544] [Batch 01864/03080] [00:23:22/00:15:14, 0.752s/it]: train_loss_raw=0.4162, running_loss=0.4255, LR=0.000100
[2025-08-27 12:12:52,714][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066552] [Batch 01872/03080] [00:23:28/00:15:08, 0.752s/it]: train_loss_raw=0.4500, running_loss=0.4266, LR=0.000100
[2025-08-27 12:12:58,685][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066560] [Batch 01880/03080] [00:23:34/00:15:02, 0.752s/it]: train_loss_raw=0.4718, running_loss=0.4276, LR=0.000100
[2025-08-27 12:13:04,610][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066568] [Batch 01888/03080] [00:23:40/00:14:56, 0.752s/it]: train_loss_raw=0.4452, running_loss=0.4267, LR=0.000100
[2025-08-27 12:13:10,617][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066576] [Batch 01896/03080] [00:23:46/00:14:50, 0.752s/it]: train_loss_raw=0.3711, running_loss=0.4269, LR=0.000100
[2025-08-27 12:13:16,762][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066584] [Batch 01904/03080] [00:23:52/00:14:44, 0.752s/it]: train_loss_raw=0.4564, running_loss=0.4268, LR=0.000100
[2025-08-27 12:13:22,796][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066592] [Batch 01912/03080] [00:23:58/00:14:38, 0.752s/it]: train_loss_raw=0.4466, running_loss=0.4272, LR=0.000100
[2025-08-27 12:13:28,884][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066600] [Batch 01920/03080] [00:24:04/00:14:32, 0.752s/it]: train_loss_raw=0.4388, running_loss=0.4289, LR=0.000100
[2025-08-27 12:13:34,878][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066608] [Batch 01928/03080] [00:24:10/00:14:26, 0.752s/it]: train_loss_raw=0.3395, running_loss=0.4269, LR=0.000100
[2025-08-27 12:13:40,887][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066616] [Batch 01936/03080] [00:24:16/00:14:20, 0.752s/it]: train_loss_raw=0.4079, running_loss=0.4287, LR=0.000100
[2025-08-27 12:13:46,861][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066624] [Batch 01944/03080] [00:24:22/00:14:14, 0.752s/it]: train_loss_raw=0.4935, running_loss=0.4318, LR=0.000100
[2025-08-27 12:13:52,842][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066632] [Batch 01952/03080] [00:24:28/00:14:08, 0.752s/it]: train_loss_raw=0.3851, running_loss=0.4330, LR=0.000100
[2025-08-27 12:13:58,834][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066640] [Batch 01960/03080] [00:24:34/00:14:02, 0.752s/it]: train_loss_raw=0.3631, running_loss=0.4321, LR=0.000100
[2025-08-27 12:14:04,868][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066648] [Batch 01968/03080] [00:24:40/00:13:56, 0.752s/it]: train_loss_raw=0.3869, running_loss=0.4320, LR=0.000100
[2025-08-27 12:14:10,910][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066656] [Batch 01976/03080] [00:24:46/00:13:50, 0.752s/it]: train_loss_raw=0.4874, running_loss=0.4334, LR=0.000100
[2025-08-27 12:14:16,915][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066664] [Batch 01984/03080] [00:24:52/00:13:44, 0.752s/it]: train_loss_raw=0.5092, running_loss=0.4328, LR=0.000100
[2025-08-27 12:14:22,927][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066672] [Batch 01992/03080] [00:24:58/00:13:38, 0.752s/it]: train_loss_raw=0.4400, running_loss=0.4322, LR=0.000100
[2025-08-27 12:14:28,482][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066680] [Batch 02000/03080] [00:25:03/00:13:32, 0.752s/it]: train_loss_raw=0.3569, running_loss=0.4313, LR=0.000100
[2025-08-27 12:14:33,897][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066688] [Batch 02008/03080] [00:25:09/00:13:25, 0.752s/it]: train_loss_raw=0.4371, running_loss=0.4338, LR=0.000100
[2025-08-27 12:14:39,431][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066696] [Batch 02016/03080] [00:25:14/00:13:19, 0.751s/it]: train_loss_raw=0.4147, running_loss=0.4331, LR=0.000100
[2025-08-27 12:14:45,169][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066704] [Batch 02024/03080] [00:25:20/00:13:13, 0.751s/it]: train_loss_raw=0.4185, running_loss=0.4321, LR=0.000100
[2025-08-27 12:14:50,572][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066712] [Batch 02032/03080] [00:25:26/00:13:07, 0.751s/it]: train_loss_raw=0.3724, running_loss=0.4327, LR=0.000100
[2025-08-27 12:14:56,365][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066720] [Batch 02040/03080] [00:25:31/00:13:00, 0.751s/it]: train_loss_raw=0.4514, running_loss=0.4301, LR=0.000100
[2025-08-27 12:15:02,161][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066728] [Batch 02048/03080] [00:25:37/00:12:54, 0.751s/it]: train_loss_raw=0.3860, running_loss=0.4312, LR=0.000100
[2025-08-27 12:15:08,140][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066736] [Batch 02056/03080] [00:25:43/00:12:48, 0.751s/it]: train_loss_raw=0.4012, running_loss=0.4312, LR=0.000100
[2025-08-27 12:15:14,126][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066744] [Batch 02064/03080] [00:25:49/00:12:42, 0.751s/it]: train_loss_raw=0.5566, running_loss=0.4313, LR=0.000100
[2025-08-27 12:15:20,160][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066752] [Batch 02072/03080] [00:25:55/00:12:36, 0.751s/it]: train_loss_raw=0.4004, running_loss=0.4300, LR=0.000100
[2025-08-27 12:15:26,123][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066760] [Batch 02080/03080] [00:26:01/00:12:30, 0.751s/it]: train_loss_raw=0.3811, running_loss=0.4278, LR=0.000100
[2025-08-27 12:15:32,167][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066768] [Batch 02088/03080] [00:26:07/00:12:24, 0.751s/it]: train_loss_raw=0.4378, running_loss=0.4278, LR=0.000100
[2025-08-27 12:15:38,140][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066776] [Batch 02096/03080] [00:26:13/00:12:18, 0.751s/it]: train_loss_raw=0.4541, running_loss=0.4261, LR=0.000100
[2025-08-27 12:15:44,170][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066784] [Batch 02104/03080] [00:26:19/00:12:12, 0.751s/it]: train_loss_raw=0.3837, running_loss=0.4246, LR=0.000100
[2025-08-27 12:15:50,191][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066792] [Batch 02112/03080] [00:26:25/00:12:06, 0.751s/it]: train_loss_raw=0.4219, running_loss=0.4258, LR=0.000100
[2025-08-27 12:15:56,437][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066800] [Batch 02120/03080] [00:26:31/00:12:00, 0.751s/it]: train_loss_raw=0.3727, running_loss=0.4252, LR=0.000100
[2025-08-27 12:16:02,672][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066808] [Batch 02128/03080] [00:26:38/00:11:54, 0.751s/it]: train_loss_raw=0.4521, running_loss=0.4215, LR=0.000100
[2025-08-27 12:16:08,686][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066816] [Batch 02136/03080] [00:26:44/00:11:48, 0.751s/it]: train_loss_raw=0.4388, running_loss=0.4228, LR=0.000100
[2025-08-27 12:16:14,698][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066824] [Batch 02144/03080] [00:26:50/00:11:42, 0.751s/it]: train_loss_raw=0.4793, running_loss=0.4262, LR=0.000100
[2025-08-27 12:16:20,736][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066832] [Batch 02152/03080] [00:26:56/00:11:36, 0.751s/it]: train_loss_raw=0.4177, running_loss=0.4235, LR=0.000100
[2025-08-27 12:16:26,778][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066840] [Batch 02160/03080] [00:27:02/00:11:30, 0.751s/it]: train_loss_raw=0.4095, running_loss=0.4225, LR=0.000100
[2025-08-27 12:16:32,614][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066848] [Batch 02168/03080] [00:27:08/00:11:24, 0.751s/it]: train_loss_raw=0.4087, running_loss=0.4217, LR=0.000100
[2025-08-27 12:16:38,684][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066856] [Batch 02176/03080] [00:27:14/00:11:18, 0.751s/it]: train_loss_raw=0.3743, running_loss=0.4236, LR=0.000100
[2025-08-27 12:16:44,778][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066864] [Batch 02184/03080] [00:27:20/00:11:12, 0.751s/it]: train_loss_raw=0.3741, running_loss=0.4265, LR=0.000100
[2025-08-27 12:16:50,846][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066872] [Batch 02192/03080] [00:27:26/00:11:06, 0.751s/it]: train_loss_raw=0.4487, running_loss=0.4275, LR=0.000100
[2025-08-27 12:16:56,676][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066880] [Batch 02200/03080] [00:27:32/00:11:00, 0.751s/it]: train_loss_raw=0.3914, running_loss=0.4254, LR=0.000100
[2025-08-27 12:17:02,308][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066888] [Batch 02208/03080] [00:27:37/00:10:54, 0.751s/it]: train_loss_raw=0.3892, running_loss=0.4243, LR=0.000100
[2025-08-27 12:17:08,205][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066896] [Batch 02216/03080] [00:27:43/00:10:48, 0.751s/it]: train_loss_raw=0.3150, running_loss=0.4219, LR=0.000100
[2025-08-27 12:17:13,954][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066904] [Batch 02224/03080] [00:27:49/00:10:42, 0.751s/it]: train_loss_raw=0.4040, running_loss=0.4190, LR=0.000100
[2025-08-27 12:17:19,938][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066912] [Batch 02232/03080] [00:27:55/00:10:36, 0.751s/it]: train_loss_raw=0.4760, running_loss=0.4208, LR=0.000100
[2025-08-27 12:17:25,942][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066920] [Batch 02240/03080] [00:28:01/00:10:30, 0.751s/it]: train_loss_raw=0.4583, running_loss=0.4194, LR=0.000100
[2025-08-27 12:17:32,077][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066928] [Batch 02248/03080] [00:28:07/00:10:24, 0.751s/it]: train_loss_raw=0.4513, running_loss=0.4201, LR=0.000100
[2025-08-27 12:17:38,059][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066936] [Batch 02256/03080] [00:28:13/00:10:18, 0.751s/it]: train_loss_raw=0.4435, running_loss=0.4202, LR=0.000100
[2025-08-27 12:17:44,137][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066944] [Batch 02264/03080] [00:28:19/00:10:12, 0.751s/it]: train_loss_raw=0.5030, running_loss=0.4242, LR=0.000100
[2025-08-27 12:17:50,305][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066952] [Batch 02272/03080] [00:28:25/00:10:06, 0.751s/it]: train_loss_raw=0.4652, running_loss=0.4265, LR=0.000100
[2025-08-27 12:17:56,375][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066960] [Batch 02280/03080] [00:28:31/00:10:00, 0.751s/it]: train_loss_raw=0.3606, running_loss=0.4255, LR=0.000100
[2025-08-27 12:18:02,447][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066968] [Batch 02288/03080] [00:28:37/00:09:54, 0.751s/it]: train_loss_raw=0.4598, running_loss=0.4253, LR=0.000100
[2025-08-27 12:18:08,420][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066976] [Batch 02296/03080] [00:28:43/00:09:48, 0.751s/it]: train_loss_raw=0.4717, running_loss=0.4269, LR=0.000100
[2025-08-27 12:18:14,364][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066984] [Batch 02304/03080] [00:28:49/00:09:42, 0.751s/it]: train_loss_raw=0.3846, running_loss=0.4249, LR=0.000100
[2025-08-27 12:18:20,382][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 066992] [Batch 02312/03080] [00:28:55/00:09:36, 0.751s/it]: train_loss_raw=0.4675, running_loss=0.4239, LR=0.000100
[2025-08-27 12:18:26,367][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067000] [Batch 02320/03080] [00:29:01/00:09:30, 0.751s/it]: train_loss_raw=0.3888, running_loss=0.4216, LR=0.000100
[2025-08-27 12:18:32,361][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067008] [Batch 02328/03080] [00:29:07/00:09:24, 0.751s/it]: train_loss_raw=0.5020, running_loss=0.4239, LR=0.000100
[2025-08-27 12:18:38,328][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067016] [Batch 02336/03080] [00:29:13/00:09:18, 0.751s/it]: train_loss_raw=0.3831, running_loss=0.4245, LR=0.000100
[2025-08-27 12:18:44,307][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067024] [Batch 02344/03080] [00:29:19/00:09:12, 0.751s/it]: train_loss_raw=0.4614, running_loss=0.4243, LR=0.000100
[2025-08-27 12:18:50,337][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067032] [Batch 02352/03080] [00:29:25/00:09:06, 0.751s/it]: train_loss_raw=0.5431, running_loss=0.4251, LR=0.000100
[2025-08-27 12:18:56,540][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067040] [Batch 02360/03080] [00:29:32/00:09:00, 0.751s/it]: train_loss_raw=0.4276, running_loss=0.4263, LR=0.000100
[2025-08-27 12:19:02,550][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067048] [Batch 02368/03080] [00:29:38/00:08:54, 0.751s/it]: train_loss_raw=0.3711, running_loss=0.4259, LR=0.000100
[2025-08-27 12:19:08,596][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067056] [Batch 02376/03080] [00:29:44/00:08:48, 0.751s/it]: train_loss_raw=0.4646, running_loss=0.4269, LR=0.000100
[2025-08-27 12:19:14,610][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067064] [Batch 02384/03080] [00:29:50/00:08:42, 0.751s/it]: train_loss_raw=0.3735, running_loss=0.4275, LR=0.000100
[2025-08-27 12:19:20,603][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067072] [Batch 02392/03080] [00:29:56/00:08:36, 0.751s/it]: train_loss_raw=0.4833, running_loss=0.4265, LR=0.000100
[2025-08-27 12:19:26,623][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067080] [Batch 02400/03080] [00:30:02/00:08:30, 0.751s/it]: train_loss_raw=0.3740, running_loss=0.4256, LR=0.000100
[2025-08-27 12:19:32,803][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067088] [Batch 02408/03080] [00:30:08/00:08:24, 0.751s/it]: train_loss_raw=0.4941, running_loss=0.4252, LR=0.000100
[2025-08-27 12:19:38,843][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067096] [Batch 02416/03080] [00:30:14/00:08:18, 0.751s/it]: train_loss_raw=0.4007, running_loss=0.4257, LR=0.000100
[2025-08-27 12:19:44,868][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067104] [Batch 02424/03080] [00:30:20/00:08:12, 0.751s/it]: train_loss_raw=0.4125, running_loss=0.4235, LR=0.000100
[2025-08-27 12:19:50,890][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067112] [Batch 02432/03080] [00:30:26/00:08:06, 0.751s/it]: train_loss_raw=0.4117, running_loss=0.4244, LR=0.000100
[2025-08-27 12:19:56,873][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067120] [Batch 02440/03080] [00:30:32/00:08:00, 0.751s/it]: train_loss_raw=0.3618, running_loss=0.4244, LR=0.000100
[2025-08-27 12:20:02,869][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067128] [Batch 02448/03080] [00:30:38/00:07:54, 0.751s/it]: train_loss_raw=0.4272, running_loss=0.4235, LR=0.000100
[2025-08-27 12:20:08,814][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067136] [Batch 02456/03080] [00:30:44/00:07:48, 0.751s/it]: train_loss_raw=0.4228, running_loss=0.4232, LR=0.000100
[2025-08-27 12:20:14,811][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067144] [Batch 02464/03080] [00:30:50/00:07:42, 0.751s/it]: train_loss_raw=0.3907, running_loss=0.4231, LR=0.000100
[2025-08-27 12:20:20,810][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067152] [Batch 02472/03080] [00:30:56/00:07:36, 0.751s/it]: train_loss_raw=0.3983, running_loss=0.4236, LR=0.000100
[2025-08-27 12:20:26,804][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067160] [Batch 02480/03080] [00:31:02/00:07:30, 0.751s/it]: train_loss_raw=0.4424, running_loss=0.4274, LR=0.000100
[2025-08-27 12:20:32,817][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067168] [Batch 02488/03080] [00:31:08/00:07:24, 0.751s/it]: train_loss_raw=0.4985, running_loss=0.4301, LR=0.000100
[2025-08-27 12:20:38,910][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067176] [Batch 02496/03080] [00:31:14/00:07:18, 0.751s/it]: train_loss_raw=0.5173, running_loss=0.4312, LR=0.000100
[2025-08-27 12:20:44,989][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067184] [Batch 02504/03080] [00:31:20/00:07:12, 0.751s/it]: train_loss_raw=0.4543, running_loss=0.4321, LR=0.000100
[2025-08-27 12:20:51,008][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067192] [Batch 02512/03080] [00:31:26/00:07:06, 0.751s/it]: train_loss_raw=0.4247, running_loss=0.4337, LR=0.000100
[2025-08-27 12:20:56,994][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067200] [Batch 02520/03080] [00:31:32/00:07:00, 0.751s/it]: train_loss_raw=0.5104, running_loss=0.4362, LR=0.000100
[2025-08-27 12:21:03,027][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067208] [Batch 02528/03080] [00:31:38/00:06:54, 0.751s/it]: train_loss_raw=0.3341, running_loss=0.4335, LR=0.000100
[2025-08-27 12:21:09,065][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067216] [Batch 02536/03080] [00:31:44/00:06:48, 0.751s/it]: train_loss_raw=0.4416, running_loss=0.4331, LR=0.000100
[2025-08-27 12:21:15,170][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067224] [Batch 02544/03080] [00:31:50/00:06:42, 0.751s/it]: train_loss_raw=0.3935, running_loss=0.4299, LR=0.000100
[2025-08-27 12:21:21,359][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067232] [Batch 02552/03080] [00:31:56/00:06:36, 0.751s/it]: train_loss_raw=0.3932, running_loss=0.4301, LR=0.000100
[2025-08-27 12:21:27,450][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067240] [Batch 02560/03080] [00:32:02/00:06:30, 0.751s/it]: train_loss_raw=0.3932, running_loss=0.4291, LR=0.000100
[2025-08-27 12:21:33,425][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067248] [Batch 02568/03080] [00:32:08/00:06:24, 0.751s/it]: train_loss_raw=0.4740, running_loss=0.4294, LR=0.000100
[2025-08-27 12:21:39,451][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067256] [Batch 02576/03080] [00:32:14/00:06:18, 0.751s/it]: train_loss_raw=0.4213, running_loss=0.4297, LR=0.000100
[2025-08-27 12:21:45,443][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067264] [Batch 02584/03080] [00:32:20/00:06:12, 0.751s/it]: train_loss_raw=0.4549, running_loss=0.4292, LR=0.000100
[2025-08-27 12:21:51,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067272] [Batch 02592/03080] [00:32:26/00:06:06, 0.751s/it]: train_loss_raw=0.4084, running_loss=0.4273, LR=0.000100
[2025-08-27 12:21:57,376][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067280] [Batch 02600/03080] [00:32:32/00:06:00, 0.751s/it]: train_loss_raw=0.4721, running_loss=0.4280, LR=0.000100
[2025-08-27 12:22:03,393][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067288] [Batch 02608/03080] [00:32:38/00:05:54, 0.751s/it]: train_loss_raw=0.4618, running_loss=0.4306, LR=0.000100
[2025-08-27 12:22:09,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067296] [Batch 02616/03080] [00:32:44/00:05:48, 0.751s/it]: train_loss_raw=0.3847, running_loss=0.4291, LR=0.000100
[2025-08-27 12:22:15,501][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067304] [Batch 02624/03080] [00:32:50/00:05:42, 0.751s/it]: train_loss_raw=0.4646, running_loss=0.4283, LR=0.000100
[2025-08-27 12:22:21,564][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067312] [Batch 02632/03080] [00:32:57/00:05:36, 0.751s/it]: train_loss_raw=0.3113, running_loss=0.4268, LR=0.000100
[2025-08-27 12:22:27,512][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067320] [Batch 02640/03080] [00:33:02/00:05:30, 0.751s/it]: train_loss_raw=0.3987, running_loss=0.4273, LR=0.000100
[2025-08-27 12:22:33,449][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067328] [Batch 02648/03080] [00:33:08/00:05:24, 0.751s/it]: train_loss_raw=0.3998, running_loss=0.4265, LR=0.000100
[2025-08-27 12:22:39,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067336] [Batch 02656/03080] [00:33:14/00:05:18, 0.751s/it]: train_loss_raw=0.4189, running_loss=0.4262, LR=0.000100
[2025-08-27 12:22:45,420][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067344] [Batch 02664/03080] [00:33:20/00:05:12, 0.751s/it]: train_loss_raw=0.4267, running_loss=0.4252, LR=0.000100
[2025-08-27 12:22:51,451][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067352] [Batch 02672/03080] [00:33:26/00:05:06, 0.751s/it]: train_loss_raw=0.3895, running_loss=0.4250, LR=0.000100
[2025-08-27 12:22:57,674][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067360] [Batch 02680/03080] [00:33:33/00:05:00, 0.751s/it]: train_loss_raw=0.4700, running_loss=0.4264, LR=0.000100
[2025-08-27 12:23:03,684][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067368] [Batch 02688/03080] [00:33:39/00:04:54, 0.751s/it]: train_loss_raw=0.5384, running_loss=0.4269, LR=0.000100
[2025-08-27 12:23:09,671][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067376] [Batch 02696/03080] [00:33:45/00:04:48, 0.751s/it]: train_loss_raw=0.4593, running_loss=0.4285, LR=0.000100
[2025-08-27 12:23:15,626][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067384] [Batch 02704/03080] [00:33:51/00:04:42, 0.751s/it]: train_loss_raw=0.3804, running_loss=0.4276, LR=0.000100
[2025-08-27 12:23:21,676][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067392] [Batch 02712/03080] [00:33:57/00:04:36, 0.751s/it]: train_loss_raw=0.4226, running_loss=0.4270, LR=0.000100
[2025-08-27 12:23:27,740][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067400] [Batch 02720/03080] [00:34:03/00:04:30, 0.751s/it]: train_loss_raw=0.5453, running_loss=0.4268, LR=0.000100
[2025-08-27 12:23:33,769][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067408] [Batch 02728/03080] [00:34:09/00:04:24, 0.751s/it]: train_loss_raw=0.4816, running_loss=0.4257, LR=0.000100
[2025-08-27 12:23:39,747][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067416] [Batch 02736/03080] [00:34:15/00:04:18, 0.751s/it]: train_loss_raw=0.3247, running_loss=0.4246, LR=0.000100
[2025-08-27 12:23:45,695][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067424] [Batch 02744/03080] [00:34:21/00:04:12, 0.751s/it]: train_loss_raw=0.4353, running_loss=0.4262, LR=0.000100
[2025-08-27 12:23:51,788][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067432] [Batch 02752/03080] [00:34:27/00:04:06, 0.751s/it]: train_loss_raw=0.3912, running_loss=0.4259, LR=0.000100
[2025-08-27 12:23:57,867][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067440] [Batch 02760/03080] [00:34:33/00:04:00, 0.751s/it]: train_loss_raw=0.4255, running_loss=0.4275, LR=0.000100
[2025-08-27 12:24:03,902][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067448] [Batch 02768/03080] [00:34:39/00:03:54, 0.751s/it]: train_loss_raw=0.4581, running_loss=0.4286, LR=0.000100
[2025-08-27 12:24:09,806][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067456] [Batch 02776/03080] [00:34:45/00:03:48, 0.751s/it]: train_loss_raw=0.4382, running_loss=0.4273, LR=0.000100
[2025-08-27 12:24:15,866][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067464] [Batch 02784/03080] [00:34:51/00:03:42, 0.751s/it]: train_loss_raw=0.4629, running_loss=0.4260, LR=0.000100
[2025-08-27 12:24:21,846][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067472] [Batch 02792/03080] [00:34:57/00:03:36, 0.751s/it]: train_loss_raw=0.3410, running_loss=0.4250, LR=0.000100
[2025-08-27 12:24:27,867][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067480] [Batch 02800/03080] [00:35:03/00:03:30, 0.751s/it]: train_loss_raw=0.3828, running_loss=0.4247, LR=0.000100
[2025-08-27 12:24:33,946][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067488] [Batch 02808/03080] [00:35:09/00:03:24, 0.751s/it]: train_loss_raw=0.3973, running_loss=0.4233, LR=0.000100
[2025-08-27 12:24:39,924][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067496] [Batch 02816/03080] [00:35:15/00:03:18, 0.751s/it]: train_loss_raw=0.3753, running_loss=0.4229, LR=0.000100
[2025-08-27 12:24:45,903][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067504] [Batch 02824/03080] [00:35:21/00:03:12, 0.751s/it]: train_loss_raw=0.3940, running_loss=0.4251, LR=0.000100
[2025-08-27 12:24:51,883][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067512] [Batch 02832/03080] [00:35:27/00:03:06, 0.751s/it]: train_loss_raw=0.3532, running_loss=0.4250, LR=0.000100
[2025-08-27 12:24:57,879][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067520] [Batch 02840/03080] [00:35:33/00:03:00, 0.751s/it]: train_loss_raw=0.4136, running_loss=0.4257, LR=0.000100
[2025-08-27 12:25:03,638][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067528] [Batch 02848/03080] [00:35:39/00:02:54, 0.751s/it]: train_loss_raw=0.4103, running_loss=0.4255, LR=0.000100
[2025-08-27 12:25:09,588][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067536] [Batch 02856/03080] [00:35:45/00:02:48, 0.751s/it]: train_loss_raw=0.4061, running_loss=0.4276, LR=0.000100
[2025-08-27 12:25:15,146][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067544] [Batch 02864/03080] [00:35:50/00:02:42, 0.751s/it]: train_loss_raw=0.4873, running_loss=0.4276, LR=0.000100
[2025-08-27 12:25:21,087][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067552] [Batch 02872/03080] [00:35:56/00:02:36, 0.751s/it]: train_loss_raw=0.4371, running_loss=0.4276, LR=0.000100
[2025-08-27 12:25:27,090][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067560] [Batch 02880/03080] [00:36:02/00:02:30, 0.751s/it]: train_loss_raw=0.5350, running_loss=0.4298, LR=0.000100
[2025-08-27 12:25:33,062][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067568] [Batch 02888/03080] [00:36:08/00:02:24, 0.751s/it]: train_loss_raw=0.4704, running_loss=0.4299, LR=0.000100
[2025-08-27 12:25:38,826][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067576] [Batch 02896/03080] [00:36:14/00:02:18, 0.751s/it]: train_loss_raw=0.4559, running_loss=0.4298, LR=0.000100
[2025-08-27 12:25:44,400][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067584] [Batch 02904/03080] [00:36:19/00:02:12, 0.751s/it]: train_loss_raw=0.3964, running_loss=0.4297, LR=0.000100
[2025-08-27 12:25:50,390][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067592] [Batch 02912/03080] [00:36:25/00:02:06, 0.751s/it]: train_loss_raw=0.4555, running_loss=0.4317, LR=0.000100
[2025-08-27 12:25:56,563][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067600] [Batch 02920/03080] [00:36:32/00:02:00, 0.751s/it]: train_loss_raw=0.4346, running_loss=0.4299, LR=0.000100
[2025-08-27 12:26:02,641][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067608] [Batch 02928/03080] [00:36:38/00:01:54, 0.751s/it]: train_loss_raw=0.3981, running_loss=0.4300, LR=0.000100
[2025-08-27 12:26:08,702][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067616] [Batch 02936/03080] [00:36:44/00:01:48, 0.751s/it]: train_loss_raw=0.4502, running_loss=0.4298, LR=0.000100
[2025-08-27 12:26:14,642][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067624] [Batch 02944/03080] [00:36:50/00:01:42, 0.751s/it]: train_loss_raw=0.3451, running_loss=0.4301, LR=0.000100
[2025-08-27 12:26:20,721][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067632] [Batch 02952/03080] [00:36:56/00:01:36, 0.751s/it]: train_loss_raw=0.4845, running_loss=0.4294, LR=0.000100
[2025-08-27 12:26:27,002][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067640] [Batch 02960/03080] [00:37:02/00:01:30, 0.751s/it]: train_loss_raw=0.3437, running_loss=0.4264, LR=0.000100
[2025-08-27 12:26:33,182][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067648] [Batch 02968/03080] [00:37:08/00:01:24, 0.751s/it]: train_loss_raw=0.5088, running_loss=0.4267, LR=0.000100
[2025-08-27 12:26:39,217][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067656] [Batch 02976/03080] [00:37:14/00:01:18, 0.751s/it]: train_loss_raw=0.3983, running_loss=0.4248, LR=0.000100
[2025-08-27 12:26:45,189][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067664] [Batch 02984/03080] [00:37:20/00:01:12, 0.751s/it]: train_loss_raw=0.4772, running_loss=0.4248, LR=0.000100
[2025-08-27 12:26:51,337][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067672] [Batch 02992/03080] [00:37:26/00:01:06, 0.751s/it]: train_loss_raw=0.4756, running_loss=0.4284, LR=0.000100
[2025-08-27 12:26:57,242][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067680] [Batch 03000/03080] [00:37:32/00:01:00, 0.751s/it]: train_loss_raw=0.4049, running_loss=0.4264, LR=0.000100
[2025-08-27 12:27:03,187][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067688] [Batch 03008/03080] [00:37:38/00:00:54, 0.751s/it]: train_loss_raw=0.4545, running_loss=0.4268, LR=0.000100
[2025-08-27 12:27:09,169][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067696] [Batch 03016/03080] [00:37:44/00:00:48, 0.751s/it]: train_loss_raw=0.4300, running_loss=0.4267, LR=0.000100
[2025-08-27 12:27:15,227][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067704] [Batch 03024/03080] [00:37:50/00:00:42, 0.751s/it]: train_loss_raw=0.4140, running_loss=0.4288, LR=0.000100
[2025-08-27 12:27:21,674][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067712] [Batch 03032/03080] [00:37:57/00:00:36, 0.751s/it]: train_loss_raw=0.4998, running_loss=0.4300, LR=0.000100
[2025-08-27 12:27:28,010][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067720] [Batch 03040/03080] [00:38:03/00:00:30, 0.751s/it]: train_loss_raw=0.4397, running_loss=0.4291, LR=0.000100
[2025-08-27 12:27:34,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067728] [Batch 03048/03080] [00:38:09/00:00:24, 0.751s/it]: train_loss_raw=0.3812, running_loss=0.4294, LR=0.000100
[2025-08-27 12:27:39,973][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067736] [Batch 03056/03080] [00:38:15/00:00:18, 0.751s/it]: train_loss_raw=0.4345, running_loss=0.4300, LR=0.000100
[2025-08-27 12:27:46,026][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067744] [Batch 03064/03080] [00:38:21/00:00:12, 0.751s/it]: train_loss_raw=0.3965, running_loss=0.4313, LR=0.000100
[2025-08-27 12:27:51,993][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067752] [Batch 03072/03080] [00:38:27/00:00:06, 0.751s/it]: train_loss_raw=0.4622, running_loss=0.4285, LR=0.000100
[2025-08-27 12:28:02,468][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 067760] [Batch 03080/03080] [00:38:37/00:00:00, 0.753s/it]: train_loss_raw=0.3595, running_loss=0.4306, LR=0.000100
[2025-08-27 12:28:02,987][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-27 12:28:14,755][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00007/00310] [00:00:11/00:07:24, 1.471s/it]
[2025-08-27 12:28:26,549][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00015/00310] [00:00:23/00:07:12, 1.473s/it]
[2025-08-27 12:28:38,377][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00023/00310] [00:00:35/00:07:01, 1.475s/it]
[2025-08-27 12:28:49,357][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00031/00310] [00:00:46/00:06:42, 1.449s/it]
[2025-08-27 12:29:00,307][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00039/00310] [00:00:57/00:06:26, 1.433s/it]
[2025-08-27 12:29:12,045][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00047/00310] [00:01:09/00:06:16, 1.439s/it]
[2025-08-27 12:29:24,147][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00055/00310] [00:01:21/00:06:08, 1.449s/it]
[2025-08-27 12:29:35,710][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00063/00310] [00:01:32/00:05:56, 1.449s/it]
[2025-08-27 12:29:47,782][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00071/00310] [00:01:44/00:05:46, 1.455s/it]
[2025-08-27 12:30:00,251][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00079/00310] [00:01:57/00:05:37, 1.466s/it]
[2025-08-27 12:30:12,540][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00087/00310] [00:02:09/00:05:26, 1.472s/it]
[2025-08-27 12:30:24,764][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00095/00310] [00:02:21/00:05:16, 1.477s/it]
[2025-08-27 12:30:37,294][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00103/00310] [00:02:34/00:05:05, 1.484s/it]
[2025-08-27 12:30:49,602][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00111/00310] [00:02:46/00:04:54, 1.488s/it]
[2025-08-27 12:31:01,824][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00119/00310] [00:02:58/00:04:43, 1.490s/it]
[2025-08-27 12:31:13,945][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00127/00310] [00:03:10/00:04:31, 1.492s/it]
[2025-08-27 12:31:26,165][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00135/00310] [00:03:23/00:04:19, 1.494s/it]
[2025-08-27 12:31:38,034][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00143/00310] [00:03:35/00:04:07, 1.493s/it]
[2025-08-27 12:31:49,202][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00151/00310] [00:03:46/00:03:55, 1.488s/it]
[2025-08-27 12:32:00,361][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00159/00310] [00:03:57/00:03:42, 1.484s/it]
[2025-08-27 12:32:11,701][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00167/00310] [00:04:08/00:03:30, 1.480s/it]
[2025-08-27 12:32:23,641][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00175/00310] [00:04:20/00:03:18, 1.481s/it]
[2025-08-27 12:32:34,578][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00183/00310] [00:04:31/00:03:05, 1.476s/it]
[2025-08-27 12:32:46,056][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00191/00310] [00:04:43/00:02:53, 1.474s/it]
[2025-08-27 12:32:57,901][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00199/00310] [00:04:54/00:02:42, 1.475s/it]
[2025-08-27 12:33:09,302][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00207/00310] [00:05:06/00:02:30, 1.473s/it]
[2025-08-27 12:33:20,369][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00215/00310] [00:05:17/00:02:18, 1.469s/it]
[2025-08-27 12:33:32,162][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00223/00310] [00:05:29/00:02:06, 1.470s/it]
[2025-08-27 12:33:44,931][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00231/00310] [00:05:41/00:01:54, 1.474s/it]
[2025-08-27 12:33:56,905][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00239/00310] [00:05:53/00:01:43, 1.475s/it]
[2025-08-27 12:34:08,024][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00247/00310] [00:06:05/00:01:31, 1.472s/it]
[2025-08-27 12:34:20,670][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00255/00310] [00:06:17/00:01:19, 1.475s/it]
[2025-08-27 12:34:32,862][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00263/00310] [00:06:29/00:01:07, 1.477s/it]
[2025-08-27 12:34:44,265][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00271/00310] [00:06:41/00:00:56, 1.475s/it]
[2025-08-27 12:34:56,325][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00279/00310] [00:06:53/00:00:44, 1.476s/it]
[2025-08-27 12:35:09,124][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00287/00310] [00:07:06/00:00:32, 1.480s/it]
[2025-08-27 12:35:20,691][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00295/00310] [00:07:17/00:00:20, 1.479s/it]
[2025-08-27 12:35:32,752][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 067761] [Batch 00303/00310] [00:07:29/00:00:08, 1.479s/it]
[2025-08-27 12:35:41,320][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=0.43057, valid_loss=1.42850
[2025-08-27 12:35:41,321][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-27 12:35:41,321][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.503
[2025-08-27 12:35:41,321][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.137
[2025-08-27 12:35:41,321][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.140
[2025-08-27 12:35:41,321][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.075
[2025-08-27 12:35:41,335][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 17:08:55, remaining time 06:14:09, 00:46:46 per epoch
[2025-08-27 12:35:46,768][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067768] [Batch 00008/03080] [00:00:05/00:33:11, 0.648s/it]: train_loss_raw=0.3796, running_loss=0.4644, LR=0.000100
[2025-08-27 12:35:52,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067776] [Batch 00016/03080] [00:00:10/00:34:52, 0.683s/it]: train_loss_raw=0.4123, running_loss=0.4578, LR=0.000100
[2025-08-27 12:35:58,364][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067784] [Batch 00024/03080] [00:00:16/00:35:37, 0.699s/it]: train_loss_raw=0.2813, running_loss=0.4512, LR=0.000100
[2025-08-27 12:36:04,218][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067792] [Batch 00032/03080] [00:00:22/00:35:56, 0.707s/it]: train_loss_raw=0.3518, running_loss=0.4475, LR=0.000100
[2025-08-27 12:36:10,082][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067800] [Batch 00040/03080] [00:00:28/00:36:06, 0.713s/it]: train_loss_raw=0.4181, running_loss=0.4437, LR=0.000100
[2025-08-27 12:36:15,929][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067808] [Batch 00048/03080] [00:00:34/00:36:09, 0.716s/it]: train_loss_raw=0.3322, running_loss=0.4383, LR=0.000100
[2025-08-27 12:36:21,705][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067816] [Batch 00056/03080] [00:00:40/00:36:06, 0.716s/it]: train_loss_raw=0.4245, running_loss=0.4378, LR=0.000100
[2025-08-27 12:36:27,460][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067824] [Batch 00064/03080] [00:00:45/00:36:02, 0.717s/it]: train_loss_raw=0.3660, running_loss=0.4344, LR=0.000100
[2025-08-27 12:36:33,240][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067832] [Batch 00072/03080] [00:00:51/00:35:58, 0.717s/it]: train_loss_raw=0.5103, running_loss=0.4321, LR=0.000100
[2025-08-27 12:36:39,102][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067840] [Batch 00080/03080] [00:00:57/00:35:57, 0.719s/it]: train_loss_raw=0.3988, running_loss=0.4297, LR=0.000100
[2025-08-27 12:36:44,966][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067848] [Batch 00088/03080] [00:01:03/00:35:55, 0.720s/it]: train_loss_raw=0.3429, running_loss=0.4262, LR=0.000100
[2025-08-27 12:36:50,885][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067856] [Batch 00096/03080] [00:01:09/00:35:54, 0.722s/it]: train_loss_raw=0.3811, running_loss=0.4229, LR=0.000100
[2025-08-27 12:36:56,691][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067864] [Batch 00104/03080] [00:01:15/00:35:49, 0.722s/it]: train_loss_raw=0.4343, running_loss=0.4218, LR=0.000100
[2025-08-27 12:37:02,472][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067872] [Batch 00112/03080] [00:01:20/00:35:43, 0.722s/it]: train_loss_raw=0.4233, running_loss=0.4196, LR=0.000100
[2025-08-27 12:37:08,335][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067880] [Batch 00120/03080] [00:01:26/00:35:39, 0.723s/it]: train_loss_raw=0.4037, running_loss=0.4172, LR=0.000100
[2025-08-27 12:37:14,180][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067888] [Batch 00128/03080] [00:01:32/00:35:35, 0.723s/it]: train_loss_raw=0.4443, running_loss=0.4159, LR=0.000100
[2025-08-27 12:37:20,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067896] [Batch 00136/03080] [00:01:38/00:35:33, 0.725s/it]: train_loss_raw=0.4576, running_loss=0.4133, LR=0.000100
[2025-08-27 12:37:26,073][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067904] [Batch 00144/03080] [00:01:44/00:35:30, 0.726s/it]: train_loss_raw=0.3860, running_loss=0.4111, LR=0.000100
[2025-08-27 12:37:31,821][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067912] [Batch 00152/03080] [00:01:50/00:35:23, 0.725s/it]: train_loss_raw=0.4063, running_loss=0.4117, LR=0.000100
[2025-08-27 12:37:37,582][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067920] [Batch 00160/03080] [00:01:56/00:35:17, 0.725s/it]: train_loss_raw=0.3409, running_loss=0.4119, LR=0.000100
[2025-08-27 12:37:43,420][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067928] [Batch 00168/03080] [00:02:01/00:35:11, 0.725s/it]: train_loss_raw=0.4606, running_loss=0.4104, LR=0.000100
[2025-08-27 12:37:49,132][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067936] [Batch 00176/03080] [00:02:07/00:35:04, 0.725s/it]: train_loss_raw=0.3777, running_loss=0.4101, LR=0.000100
[2025-08-27 12:37:54,617][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067944] [Batch 00184/03080] [00:02:13/00:34:53, 0.723s/it]: train_loss_raw=0.3082, running_loss=0.4075, LR=0.000100
[2025-08-27 12:38:00,337][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067952] [Batch 00192/03080] [00:02:18/00:34:47, 0.723s/it]: train_loss_raw=0.3909, running_loss=0.4077, LR=0.000100
[2025-08-27 12:38:06,192][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067960] [Batch 00200/03080] [00:02:24/00:34:42, 0.723s/it]: train_loss_raw=0.4507, running_loss=0.4079, LR=0.000100
[2025-08-27 12:38:11,978][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067968] [Batch 00208/03080] [00:02:30/00:34:36, 0.723s/it]: train_loss_raw=0.3775, running_loss=0.4057, LR=0.000100
[2025-08-27 12:38:17,800][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067976] [Batch 00216/03080] [00:02:36/00:34:31, 0.723s/it]: train_loss_raw=0.3763, running_loss=0.4079, LR=0.000100
[2025-08-27 12:38:23,526][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067984] [Batch 00224/03080] [00:02:41/00:34:24, 0.723s/it]: train_loss_raw=0.4359, running_loss=0.4074, LR=0.000100
[2025-08-27 12:38:29,282][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 067992] [Batch 00232/03080] [00:02:47/00:34:18, 0.723s/it]: train_loss_raw=0.3367, running_loss=0.4059, LR=0.000100
[2025-08-27 12:38:35,038][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068000] [Batch 00240/03080] [00:02:53/00:34:12, 0.723s/it]: train_loss_raw=0.3421, running_loss=0.4060, LR=0.000100
[2025-08-27 12:38:44,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068008] [Batch 00248/03080] [00:03:02/00:34:48, 0.737s/it]: train_loss_raw=0.4346, running_loss=0.4052, LR=0.000100
[2025-08-27 12:38:50,341][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068016] [Batch 00256/03080] [00:03:08/00:34:42, 0.737s/it]: train_loss_raw=0.3958, running_loss=0.4072, LR=0.000100
[2025-08-27 12:38:56,147][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068024] [Batch 00264/03080] [00:03:14/00:34:35, 0.737s/it]: train_loss_raw=0.3507, running_loss=0.4062, LR=0.000100
[2025-08-27 12:39:01,948][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068032] [Batch 00272/03080] [00:03:20/00:34:28, 0.737s/it]: train_loss_raw=0.4653, running_loss=0.4085, LR=0.000100
[2025-08-27 12:39:07,891][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068040] [Batch 00280/03080] [00:03:26/00:34:23, 0.737s/it]: train_loss_raw=0.3998, running_loss=0.4085, LR=0.000100
[2025-08-27 12:39:13,759][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068048] [Batch 00288/03080] [00:03:32/00:34:16, 0.737s/it]: train_loss_raw=0.4706, running_loss=0.4109, LR=0.000100
[2025-08-27 12:39:19,500][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068056] [Batch 00296/03080] [00:03:37/00:34:09, 0.736s/it]: train_loss_raw=0.4932, running_loss=0.4108, LR=0.000100
[2025-08-27 12:39:25,425][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068064] [Batch 00304/03080] [00:03:43/00:34:04, 0.736s/it]: train_loss_raw=0.3835, running_loss=0.4088, LR=0.000100
[2025-08-27 12:39:31,215][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068072] [Batch 00312/03080] [00:03:49/00:33:57, 0.736s/it]: train_loss_raw=0.3826, running_loss=0.4111, LR=0.000100
[2025-08-27 12:39:36,936][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068080] [Batch 00320/03080] [00:03:55/00:33:49, 0.735s/it]: train_loss_raw=0.4247, running_loss=0.4098, LR=0.000100
[2025-08-27 12:39:42,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068088] [Batch 00328/03080] [00:04:00/00:33:41, 0.735s/it]: train_loss_raw=0.3806, running_loss=0.4083, LR=0.000100
[2025-08-27 12:39:48,266][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068096] [Batch 00336/03080] [00:04:06/00:33:34, 0.734s/it]: train_loss_raw=0.3593, running_loss=0.4079, LR=0.000100
[2025-08-27 12:39:54,001][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068104] [Batch 00344/03080] [00:04:12/00:33:27, 0.734s/it]: train_loss_raw=0.4325, running_loss=0.4067, LR=0.000100
[2025-08-27 12:39:59,810][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068112] [Batch 00352/03080] [00:04:18/00:33:21, 0.734s/it]: train_loss_raw=0.4464, running_loss=0.4077, LR=0.000100
[2025-08-27 12:40:05,616][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068120] [Batch 00360/03080] [00:04:24/00:33:14, 0.733s/it]: train_loss_raw=0.3918, running_loss=0.4072, LR=0.000100
[2025-08-27 12:40:11,286][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068128] [Batch 00368/03080] [00:04:29/00:33:07, 0.733s/it]: train_loss_raw=0.4722, running_loss=0.4086, LR=0.000100
[2025-08-27 12:40:17,064][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068136] [Batch 00376/03080] [00:04:35/00:33:01, 0.733s/it]: train_loss_raw=0.4465, running_loss=0.4085, LR=0.000100
[2025-08-27 12:40:22,900][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068144] [Batch 00384/03080] [00:04:41/00:32:55, 0.733s/it]: train_loss_raw=0.4355, running_loss=0.4079, LR=0.000100
[2025-08-27 12:40:28,650][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068152] [Batch 00392/03080] [00:04:47/00:32:48, 0.732s/it]: train_loss_raw=0.4535, running_loss=0.4075, LR=0.000100
[2025-08-27 12:40:34,589][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068160] [Batch 00400/03080] [00:04:53/00:32:43, 0.733s/it]: train_loss_raw=0.4431, running_loss=0.4074, LR=0.000100
[2025-08-27 12:40:40,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068168] [Batch 00408/03080] [00:04:58/00:32:37, 0.733s/it]: train_loss_raw=0.3262, running_loss=0.4064, LR=0.000100
[2025-08-27 12:40:46,459][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068176] [Batch 00416/03080] [00:05:04/00:32:32, 0.733s/it]: train_loss_raw=0.4317, running_loss=0.4055, LR=0.000100
[2025-08-27 12:40:52,294][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068184] [Batch 00424/03080] [00:05:10/00:32:26, 0.733s/it]: train_loss_raw=0.3245, running_loss=0.4031, LR=0.000100
[2025-08-27 12:40:58,251][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068192] [Batch 00432/03080] [00:05:16/00:32:21, 0.733s/it]: train_loss_raw=0.3972, running_loss=0.4026, LR=0.000100
[2025-08-27 12:41:04,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068200] [Batch 00440/03080] [00:05:22/00:32:15, 0.733s/it]: train_loss_raw=0.3350, running_loss=0.4023, LR=0.000100
[2025-08-27 12:41:09,907][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068208] [Batch 00448/03080] [00:05:28/00:32:08, 0.733s/it]: train_loss_raw=0.3970, running_loss=0.4004, LR=0.000100
[2025-08-27 12:41:15,695][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068216] [Batch 00456/03080] [00:05:34/00:32:02, 0.733s/it]: train_loss_raw=0.4253, running_loss=0.4002, LR=0.000100
[2025-08-27 12:41:21,358][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068224] [Batch 00464/03080] [00:05:39/00:31:55, 0.732s/it]: train_loss_raw=0.3590, running_loss=0.3994, LR=0.000100
[2025-08-27 12:41:26,879][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068232] [Batch 00472/03080] [00:05:45/00:31:47, 0.732s/it]: train_loss_raw=0.3276, running_loss=0.3993, LR=0.000100
[2025-08-27 12:41:32,447][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068240] [Batch 00480/03080] [00:05:50/00:31:40, 0.731s/it]: train_loss_raw=0.3705, running_loss=0.3988, LR=0.000100
[2025-08-27 12:41:38,135][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068248] [Batch 00488/03080] [00:05:56/00:31:33, 0.731s/it]: train_loss_raw=0.3717, running_loss=0.3992, LR=0.000100
[2025-08-27 12:41:44,122][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068256] [Batch 00496/03080] [00:06:02/00:31:28, 0.731s/it]: train_loss_raw=0.3435, running_loss=0.3984, LR=0.000100
[2025-08-27 12:41:49,915][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068264] [Batch 00504/03080] [00:06:08/00:31:22, 0.731s/it]: train_loss_raw=0.3098, running_loss=0.3983, LR=0.000100
[2025-08-27 12:41:55,550][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068272] [Batch 00512/03080] [00:06:13/00:31:15, 0.730s/it]: train_loss_raw=0.3649, running_loss=0.3991, LR=0.000100
[2025-08-27 12:42:01,027][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068280] [Batch 00520/03080] [00:06:19/00:31:08, 0.730s/it]: train_loss_raw=0.3918, running_loss=0.3985, LR=0.000100
[2025-08-27 12:42:07,010][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068288] [Batch 00528/03080] [00:06:25/00:31:02, 0.730s/it]: train_loss_raw=0.3351, running_loss=0.3963, LR=0.000100
[2025-08-27 12:42:12,811][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068296] [Batch 00536/03080] [00:06:31/00:30:56, 0.730s/it]: train_loss_raw=0.3281, running_loss=0.3947, LR=0.000100
[2025-08-27 12:42:18,411][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068304] [Batch 00544/03080] [00:06:36/00:30:49, 0.729s/it]: train_loss_raw=0.5060, running_loss=0.3965, LR=0.000100
[2025-08-27 12:42:23,865][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068312] [Batch 00552/03080] [00:06:42/00:30:42, 0.729s/it]: train_loss_raw=0.4866, running_loss=0.3980, LR=0.000100
[2025-08-27 12:42:29,765][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068320] [Batch 00560/03080] [00:06:48/00:30:36, 0.729s/it]: train_loss_raw=0.4130, running_loss=0.3996, LR=0.000100
[2025-08-27 12:42:35,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068328] [Batch 00568/03080] [00:06:53/00:30:30, 0.729s/it]: train_loss_raw=0.3313, running_loss=0.3993, LR=0.000100
[2025-08-27 12:42:41,206][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068336] [Batch 00576/03080] [00:06:59/00:30:24, 0.729s/it]: train_loss_raw=0.4018, running_loss=0.3992, LR=0.000100
[2025-08-27 12:42:46,847][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068344] [Batch 00584/03080] [00:07:05/00:30:17, 0.728s/it]: train_loss_raw=0.4196, running_loss=0.3990, LR=0.000100
[2025-08-27 12:42:52,675][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068352] [Batch 00592/03080] [00:07:11/00:30:11, 0.728s/it]: train_loss_raw=0.3410, running_loss=0.3984, LR=0.000100
[2025-08-27 12:42:58,602][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068360] [Batch 00600/03080] [00:07:17/00:30:06, 0.728s/it]: train_loss_raw=0.5010, running_loss=0.4017, LR=0.000100
[2025-08-27 12:43:04,539][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068368] [Batch 00608/03080] [00:07:22/00:30:00, 0.729s/it]: train_loss_raw=0.3572, running_loss=0.4013, LR=0.000100
[2025-08-27 12:43:10,299][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068376] [Batch 00616/03080] [00:07:28/00:29:54, 0.728s/it]: train_loss_raw=0.4112, running_loss=0.4023, LR=0.000100
[2025-08-27 12:43:16,005][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068384] [Batch 00624/03080] [00:07:34/00:29:48, 0.728s/it]: train_loss_raw=0.4407, running_loss=0.4033, LR=0.000100
[2025-08-27 12:43:21,769][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068392] [Batch 00632/03080] [00:07:40/00:29:42, 0.728s/it]: train_loss_raw=0.3458, running_loss=0.4032, LR=0.000100
[2025-08-27 12:43:27,536][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068400] [Batch 00640/03080] [00:07:45/00:29:36, 0.728s/it]: train_loss_raw=0.3315, running_loss=0.4013, LR=0.000100
[2025-08-27 12:43:33,350][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068408] [Batch 00648/03080] [00:07:51/00:29:30, 0.728s/it]: train_loss_raw=0.3398, running_loss=0.4010, LR=0.000100
[2025-08-27 12:43:39,144][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068416] [Batch 00656/03080] [00:07:57/00:29:24, 0.728s/it]: train_loss_raw=0.4033, running_loss=0.4032, LR=0.000100
[2025-08-27 12:43:44,746][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068424] [Batch 00664/03080] [00:08:03/00:29:18, 0.728s/it]: train_loss_raw=0.4284, running_loss=0.4032, LR=0.000100
[2025-08-27 12:43:50,473][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068432] [Batch 00672/03080] [00:08:08/00:29:11, 0.728s/it]: train_loss_raw=0.4450, running_loss=0.4023, LR=0.000100
[2025-08-27 12:43:56,202][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068440] [Batch 00680/03080] [00:08:14/00:29:05, 0.727s/it]: train_loss_raw=0.4587, running_loss=0.4050, LR=0.000100
[2025-08-27 12:44:02,014][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068448] [Batch 00688/03080] [00:08:20/00:28:59, 0.727s/it]: train_loss_raw=0.4731, running_loss=0.4042, LR=0.000100
[2025-08-27 12:44:07,976][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068456] [Batch 00696/03080] [00:08:26/00:28:54, 0.728s/it]: train_loss_raw=0.4161, running_loss=0.4063, LR=0.000100
[2025-08-27 12:44:13,862][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068464] [Batch 00704/03080] [00:08:32/00:28:48, 0.728s/it]: train_loss_raw=0.4624, running_loss=0.4088, LR=0.000100
[2025-08-27 12:44:19,779][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068472] [Batch 00712/03080] [00:08:38/00:28:43, 0.728s/it]: train_loss_raw=0.4198, running_loss=0.4091, LR=0.000100
[2025-08-27 12:44:25,675][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068480] [Batch 00720/03080] [00:08:44/00:28:37, 0.728s/it]: train_loss_raw=0.3170, running_loss=0.4087, LR=0.000100
[2025-08-27 12:44:31,495][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068488] [Batch 00728/03080] [00:08:49/00:28:32, 0.728s/it]: train_loss_raw=0.4483, running_loss=0.4105, LR=0.000100
[2025-08-27 12:44:37,375][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068496] [Batch 00736/03080] [00:08:55/00:28:26, 0.728s/it]: train_loss_raw=0.3716, running_loss=0.4083, LR=0.000100
[2025-08-27 12:44:43,186][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068504] [Batch 00744/03080] [00:09:01/00:28:20, 0.728s/it]: train_loss_raw=0.4004, running_loss=0.4060, LR=0.000100
[2025-08-27 12:44:49,063][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068512] [Batch 00752/03080] [00:09:07/00:28:14, 0.728s/it]: train_loss_raw=0.4447, running_loss=0.4066, LR=0.000100
[2025-08-27 12:44:54,853][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068520] [Batch 00760/03080] [00:09:13/00:28:08, 0.728s/it]: train_loss_raw=0.3783, running_loss=0.4075, LR=0.000100
[2025-08-27 12:45:00,607][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068528] [Batch 00768/03080] [00:09:19/00:28:02, 0.728s/it]: train_loss_raw=0.4110, running_loss=0.4086, LR=0.000100
[2025-08-27 12:45:06,372][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068536] [Batch 00776/03080] [00:09:24/00:27:56, 0.728s/it]: train_loss_raw=0.3902, running_loss=0.4065, LR=0.000100
[2025-08-27 12:45:12,233][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068544] [Batch 00784/03080] [00:09:30/00:27:51, 0.728s/it]: train_loss_raw=0.4214, running_loss=0.4070, LR=0.000100
[2025-08-27 12:45:18,185][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068552] [Batch 00792/03080] [00:09:36/00:27:45, 0.728s/it]: train_loss_raw=0.4103, running_loss=0.4071, LR=0.000100
[2025-08-27 12:45:24,056][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068560] [Batch 00800/03080] [00:09:42/00:27:40, 0.728s/it]: train_loss_raw=0.2913, running_loss=0.4076, LR=0.000100
[2025-08-27 12:45:29,824][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068568] [Batch 00808/03080] [00:09:48/00:27:34, 0.728s/it]: train_loss_raw=0.4150, running_loss=0.4074, LR=0.000100
[2025-08-27 12:45:35,538][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068576] [Batch 00816/03080] [00:09:53/00:27:27, 0.728s/it]: train_loss_raw=0.4002, running_loss=0.4056, LR=0.000100
[2025-08-27 12:45:41,278][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068584] [Batch 00824/03080] [00:09:59/00:27:21, 0.728s/it]: train_loss_raw=0.3358, running_loss=0.4058, LR=0.000100
[2025-08-27 12:45:47,022][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068592] [Batch 00832/03080] [00:10:05/00:27:15, 0.728s/it]: train_loss_raw=0.4099, running_loss=0.4077, LR=0.000100
[2025-08-27 12:45:52,777][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068600] [Batch 00840/03080] [00:10:11/00:27:09, 0.728s/it]: train_loss_raw=0.5309, running_loss=0.4087, LR=0.000100
[2025-08-27 12:45:58,531][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068608] [Batch 00848/03080] [00:10:16/00:27:03, 0.728s/it]: train_loss_raw=0.4802, running_loss=0.4096, LR=0.000100
[2025-08-27 12:46:04,366][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068616] [Batch 00856/03080] [00:10:22/00:26:58, 0.728s/it]: train_loss_raw=0.4701, running_loss=0.4097, LR=0.000100
[2025-08-27 12:46:10,339][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068624] [Batch 00864/03080] [00:10:28/00:26:52, 0.728s/it]: train_loss_raw=0.4087, running_loss=0.4092, LR=0.000100
[2025-08-27 12:46:16,265][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068632] [Batch 00872/03080] [00:10:34/00:26:47, 0.728s/it]: train_loss_raw=0.3968, running_loss=0.4085, LR=0.000100
[2025-08-27 12:46:21,939][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068640] [Batch 00880/03080] [00:10:40/00:26:40, 0.728s/it]: train_loss_raw=0.4424, running_loss=0.4079, LR=0.000100
[2025-08-27 12:46:27,766][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068648] [Batch 00888/03080] [00:10:46/00:26:35, 0.728s/it]: train_loss_raw=0.4461, running_loss=0.4084, LR=0.000100
[2025-08-27 12:46:33,692][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068656] [Batch 00896/03080] [00:10:52/00:26:29, 0.728s/it]: train_loss_raw=0.4004, running_loss=0.4075, LR=0.000100
[2025-08-27 12:46:39,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068664] [Batch 00904/03080] [00:10:57/00:26:23, 0.728s/it]: train_loss_raw=0.4728, running_loss=0.4078, LR=0.000100
[2025-08-27 12:46:45,294][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068672] [Batch 00912/03080] [00:11:03/00:26:17, 0.728s/it]: train_loss_raw=0.3365, running_loss=0.4064, LR=0.000100
[2025-08-27 12:46:51,050][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068680] [Batch 00920/03080] [00:11:09/00:26:11, 0.728s/it]: train_loss_raw=0.4025, running_loss=0.4066, LR=0.000100
[2025-08-27 12:46:56,888][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068688] [Batch 00928/03080] [00:11:15/00:26:06, 0.728s/it]: train_loss_raw=0.4379, running_loss=0.4047, LR=0.000100
[2025-08-27 12:47:02,790][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068696] [Batch 00936/03080] [00:11:21/00:26:00, 0.728s/it]: train_loss_raw=0.4225, running_loss=0.4035, LR=0.000100
[2025-08-27 12:47:08,587][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068704] [Batch 00944/03080] [00:11:27/00:25:54, 0.728s/it]: train_loss_raw=0.3926, running_loss=0.4046, LR=0.000100
[2025-08-27 12:47:14,500][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068712] [Batch 00952/03080] [00:11:32/00:25:48, 0.728s/it]: train_loss_raw=0.4659, running_loss=0.4049, LR=0.000100
[2025-08-27 12:47:20,275][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068720] [Batch 00960/03080] [00:11:38/00:25:42, 0.728s/it]: train_loss_raw=0.4691, running_loss=0.4057, LR=0.000100
[2025-08-27 12:47:26,083][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068728] [Batch 00968/03080] [00:11:44/00:25:37, 0.728s/it]: train_loss_raw=0.3967, running_loss=0.4069, LR=0.000100
[2025-08-27 12:47:31,869][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068736] [Batch 00976/03080] [00:11:50/00:25:31, 0.728s/it]: train_loss_raw=0.3042, running_loss=0.4054, LR=0.000100
[2025-08-27 12:47:37,775][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068744] [Batch 00984/03080] [00:11:56/00:25:25, 0.728s/it]: train_loss_raw=0.3833, running_loss=0.4061, LR=0.000100
[2025-08-27 12:47:43,694][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068752] [Batch 00992/03080] [00:12:02/00:25:19, 0.728s/it]: train_loss_raw=0.4092, running_loss=0.4061, LR=0.000100
[2025-08-27 12:47:49,487][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068760] [Batch 01000/03080] [00:12:07/00:25:14, 0.728s/it]: train_loss_raw=0.4610, running_loss=0.4040, LR=0.000100
[2025-08-27 12:47:55,222][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068768] [Batch 01008/03080] [00:12:13/00:25:08, 0.728s/it]: train_loss_raw=0.4973, running_loss=0.4053, LR=0.000100
[2025-08-27 12:48:01,140][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068776] [Batch 01016/03080] [00:12:19/00:25:02, 0.728s/it]: train_loss_raw=0.4161, running_loss=0.4044, LR=0.000100
[2025-08-27 12:48:06,715][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068784] [Batch 01024/03080] [00:12:25/00:24:56, 0.728s/it]: train_loss_raw=0.3145, running_loss=0.4033, LR=0.000100
[2025-08-27 12:48:12,567][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068792] [Batch 01032/03080] [00:12:30/00:24:50, 0.728s/it]: train_loss_raw=0.4209, running_loss=0.4027, LR=0.000100
[2025-08-27 12:48:18,388][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068800] [Batch 01040/03080] [00:12:36/00:24:44, 0.728s/it]: train_loss_raw=0.4031, running_loss=0.4033, LR=0.000100
[2025-08-27 12:48:24,116][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068808] [Batch 01048/03080] [00:12:42/00:24:38, 0.728s/it]: train_loss_raw=0.3786, running_loss=0.4011, LR=0.000100
[2025-08-27 12:48:29,904][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068816] [Batch 01056/03080] [00:12:48/00:24:32, 0.728s/it]: train_loss_raw=0.4122, running_loss=0.4019, LR=0.000100
[2025-08-27 12:48:35,844][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068824] [Batch 01064/03080] [00:12:54/00:24:27, 0.728s/it]: train_loss_raw=0.3481, running_loss=0.4004, LR=0.000100
[2025-08-27 12:48:41,702][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068832] [Batch 01072/03080] [00:13:00/00:24:21, 0.728s/it]: train_loss_raw=0.4121, running_loss=0.4011, LR=0.000100
[2025-08-27 12:48:47,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068840] [Batch 01080/03080] [00:13:05/00:24:15, 0.728s/it]: train_loss_raw=0.4270, running_loss=0.4005, LR=0.000100
[2025-08-27 12:48:53,493][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068848] [Batch 01088/03080] [00:13:11/00:24:09, 0.728s/it]: train_loss_raw=0.4148, running_loss=0.3996, LR=0.000100
[2025-08-27 12:48:59,350][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068856] [Batch 01096/03080] [00:13:17/00:24:04, 0.728s/it]: train_loss_raw=0.3576, running_loss=0.4010, LR=0.000100
[2025-08-27 12:49:05,218][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068864] [Batch 01104/03080] [00:13:23/00:23:58, 0.728s/it]: train_loss_raw=0.3592, running_loss=0.4007, LR=0.000100
[2025-08-27 12:49:10,818][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068872] [Batch 01112/03080] [00:13:29/00:23:52, 0.728s/it]: train_loss_raw=0.3514, running_loss=0.4027, LR=0.000100
[2025-08-27 12:49:16,697][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068880] [Batch 01120/03080] [00:13:35/00:23:46, 0.728s/it]: train_loss_raw=0.3662, running_loss=0.4034, LR=0.000100
[2025-08-27 12:49:22,431][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068888] [Batch 01128/03080] [00:13:40/00:23:40, 0.728s/it]: train_loss_raw=0.4310, running_loss=0.4041, LR=0.000100
[2025-08-27 12:49:28,344][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068896] [Batch 01136/03080] [00:13:46/00:23:34, 0.728s/it]: train_loss_raw=0.4299, running_loss=0.4032, LR=0.000100
[2025-08-27 12:49:34,089][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068904] [Batch 01144/03080] [00:13:52/00:23:28, 0.728s/it]: train_loss_raw=0.4541, running_loss=0.4024, LR=0.000100
[2025-08-27 12:49:39,535][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068912] [Batch 01152/03080] [00:13:57/00:23:22, 0.727s/it]: train_loss_raw=0.3657, running_loss=0.4008, LR=0.000100
[2025-08-27 12:49:44,961][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068920] [Batch 01160/03080] [00:14:03/00:23:15, 0.727s/it]: train_loss_raw=0.4087, running_loss=0.4021, LR=0.000100
[2025-08-27 12:49:50,390][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068928] [Batch 01168/03080] [00:14:08/00:23:09, 0.727s/it]: train_loss_raw=0.3961, running_loss=0.4035, LR=0.000100
[2025-08-27 12:49:55,935][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068936] [Batch 01176/03080] [00:14:14/00:23:03, 0.726s/it]: train_loss_raw=0.4111, running_loss=0.4044, LR=0.000100
[2025-08-27 12:50:01,385][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068944] [Batch 01184/03080] [00:14:19/00:22:56, 0.726s/it]: train_loss_raw=0.3581, running_loss=0.4044, LR=0.000100
[2025-08-27 12:50:06,923][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068952] [Batch 01192/03080] [00:14:25/00:22:50, 0.726s/it]: train_loss_raw=0.4250, running_loss=0.4052, LR=0.000100
[2025-08-27 12:50:12,873][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068960] [Batch 01200/03080] [00:14:31/00:22:45, 0.726s/it]: train_loss_raw=0.3818, running_loss=0.4047, LR=0.000100
[2025-08-27 12:50:18,659][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068968] [Batch 01208/03080] [00:14:37/00:22:39, 0.726s/it]: train_loss_raw=0.4783, running_loss=0.4057, LR=0.000100
[2025-08-27 12:50:24,337][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068976] [Batch 01216/03080] [00:14:42/00:22:33, 0.726s/it]: train_loss_raw=0.4694, running_loss=0.4066, LR=0.000100
[2025-08-27 12:50:30,219][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068984] [Batch 01224/03080] [00:14:48/00:22:27, 0.726s/it]: train_loss_raw=0.4256, running_loss=0.4075, LR=0.000100
[2025-08-27 12:50:36,251][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 068992] [Batch 01232/03080] [00:14:54/00:22:22, 0.726s/it]: train_loss_raw=0.4688, running_loss=0.4081, LR=0.000100
[2025-08-27 12:50:42,010][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069000] [Batch 01240/03080] [00:15:00/00:22:16, 0.726s/it]: train_loss_raw=0.4409, running_loss=0.4086, LR=0.000100
[2025-08-27 12:50:47,758][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069008] [Batch 01248/03080] [00:15:06/00:22:10, 0.726s/it]: train_loss_raw=0.3803, running_loss=0.4106, LR=0.000100
[2025-08-27 12:50:53,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069016] [Batch 01256/03080] [00:15:11/00:22:04, 0.726s/it]: train_loss_raw=0.3557, running_loss=0.4088, LR=0.000100
[2025-08-27 12:50:59,196][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069024] [Batch 01264/03080] [00:15:17/00:21:58, 0.726s/it]: train_loss_raw=0.4398, running_loss=0.4131, LR=0.000100
[2025-08-27 12:51:04,959][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069032] [Batch 01272/03080] [00:15:23/00:21:52, 0.726s/it]: train_loss_raw=0.3354, running_loss=0.4113, LR=0.000100
[2025-08-27 12:51:10,737][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069040] [Batch 01280/03080] [00:15:29/00:21:46, 0.726s/it]: train_loss_raw=0.3322, running_loss=0.4118, LR=0.000100
[2025-08-27 12:51:16,550][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069048] [Batch 01288/03080] [00:15:34/00:21:40, 0.726s/it]: train_loss_raw=0.4591, running_loss=0.4141, LR=0.000100
[2025-08-27 12:51:22,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069056] [Batch 01296/03080] [00:15:40/00:21:35, 0.726s/it]: train_loss_raw=0.4538, running_loss=0.4152, LR=0.000100
[2025-08-27 12:51:28,379][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069064] [Batch 01304/03080] [00:15:46/00:21:29, 0.726s/it]: train_loss_raw=0.4061, running_loss=0.4135, LR=0.000100
[2025-08-27 12:51:34,231][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069072] [Batch 01312/03080] [00:15:52/00:21:23, 0.726s/it]: train_loss_raw=0.3924, running_loss=0.4130, LR=0.000100
[2025-08-27 12:51:39,970][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069080] [Batch 01320/03080] [00:15:58/00:21:17, 0.726s/it]: train_loss_raw=0.4104, running_loss=0.4121, LR=0.000100
[2025-08-27 12:51:45,841][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069088] [Batch 01328/03080] [00:16:04/00:21:12, 0.726s/it]: train_loss_raw=0.3658, running_loss=0.4084, LR=0.000100
[2025-08-27 12:51:51,751][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069096] [Batch 01336/03080] [00:16:10/00:21:06, 0.726s/it]: train_loss_raw=0.4283, running_loss=0.4098, LR=0.000100
[2025-08-27 12:51:57,508][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069104] [Batch 01344/03080] [00:16:15/00:21:00, 0.726s/it]: train_loss_raw=0.4471, running_loss=0.4098, LR=0.000100
[2025-08-27 12:52:03,372][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069112] [Batch 01352/03080] [00:16:21/00:20:54, 0.726s/it]: train_loss_raw=0.3514, running_loss=0.4100, LR=0.000100
[2025-08-27 12:52:09,274][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069120] [Batch 01360/03080] [00:16:27/00:20:49, 0.726s/it]: train_loss_raw=0.4152, running_loss=0.4085, LR=0.000100
[2025-08-27 12:52:15,215][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069128] [Batch 01368/03080] [00:16:33/00:20:43, 0.726s/it]: train_loss_raw=0.3989, running_loss=0.4088, LR=0.000100
[2025-08-27 12:52:20,949][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069136] [Batch 01376/03080] [00:16:39/00:20:37, 0.726s/it]: train_loss_raw=0.3687, running_loss=0.4069, LR=0.000100
[2025-08-27 12:52:26,725][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069144] [Batch 01384/03080] [00:16:45/00:20:31, 0.726s/it]: train_loss_raw=0.4880, running_loss=0.4070, LR=0.000100
[2025-08-27 12:52:32,509][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069152] [Batch 01392/03080] [00:16:50/00:20:25, 0.726s/it]: train_loss_raw=0.4159, running_loss=0.4070, LR=0.000100
[2025-08-27 12:52:38,304][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069160] [Batch 01400/03080] [00:16:56/00:20:20, 0.726s/it]: train_loss_raw=0.4091, running_loss=0.4084, LR=0.000100
[2025-08-27 12:52:43,813][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069168] [Batch 01408/03080] [00:17:02/00:20:13, 0.726s/it]: train_loss_raw=0.3669, running_loss=0.4068, LR=0.000100
[2025-08-27 12:52:49,653][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069176] [Batch 01416/03080] [00:17:08/00:20:08, 0.726s/it]: train_loss_raw=0.3582, running_loss=0.4056, LR=0.000100
[2025-08-27 12:52:55,393][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069184] [Batch 01424/03080] [00:17:13/00:20:02, 0.726s/it]: train_loss_raw=0.4140, running_loss=0.4051, LR=0.000100
[2025-08-27 12:53:01,218][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069192] [Batch 01432/03080] [00:17:19/00:19:56, 0.726s/it]: train_loss_raw=0.4705, running_loss=0.4038, LR=0.000100
[2025-08-27 12:53:07,006][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069200] [Batch 01440/03080] [00:17:25/00:19:50, 0.726s/it]: train_loss_raw=0.4402, running_loss=0.4027, LR=0.000100
[2025-08-27 12:53:12,967][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069208] [Batch 01448/03080] [00:17:31/00:19:44, 0.726s/it]: train_loss_raw=0.3683, running_loss=0.4011, LR=0.000100
[2025-08-27 12:53:18,894][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069216] [Batch 01456/03080] [00:17:37/00:19:39, 0.726s/it]: train_loss_raw=0.2900, running_loss=0.4001, LR=0.000100
[2025-08-27 12:53:24,629][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069224] [Batch 01464/03080] [00:17:43/00:19:33, 0.726s/it]: train_loss_raw=0.4249, running_loss=0.4008, LR=0.000100
[2025-08-27 12:53:30,367][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069232] [Batch 01472/03080] [00:17:48/00:19:27, 0.726s/it]: train_loss_raw=0.4073, running_loss=0.3986, LR=0.000100
[2025-08-27 12:53:36,380][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069240] [Batch 01480/03080] [00:17:54/00:19:21, 0.726s/it]: train_loss_raw=0.4216, running_loss=0.3969, LR=0.000100
[2025-08-27 12:53:42,540][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069248] [Batch 01488/03080] [00:18:00/00:19:16, 0.726s/it]: train_loss_raw=0.3819, running_loss=0.3962, LR=0.000100
[2025-08-27 12:53:48,647][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069256] [Batch 01496/03080] [00:18:07/00:19:11, 0.727s/it]: train_loss_raw=0.4073, running_loss=0.3996, LR=0.000100
[2025-08-27 12:53:54,405][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069264] [Batch 01504/03080] [00:18:12/00:19:05, 0.727s/it]: train_loss_raw=0.4030, running_loss=0.4010, LR=0.000100
[2025-08-27 12:54:00,123][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069272] [Batch 01512/03080] [00:18:18/00:18:59, 0.727s/it]: train_loss_raw=0.4593, running_loss=0.4009, LR=0.000100
[2025-08-27 12:54:06,278][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069280] [Batch 01520/03080] [00:18:24/00:18:53, 0.727s/it]: train_loss_raw=0.4307, running_loss=0.4033, LR=0.000100
[2025-08-27 12:54:12,124][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069288] [Batch 01528/03080] [00:18:30/00:18:47, 0.727s/it]: train_loss_raw=0.4408, running_loss=0.4061, LR=0.000100
[2025-08-27 12:54:17,916][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069296] [Batch 01536/03080] [00:18:36/00:18:42, 0.727s/it]: train_loss_raw=0.3597, running_loss=0.4065, LR=0.000100
[2025-08-27 12:54:23,660][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069304] [Batch 01544/03080] [00:18:42/00:18:36, 0.727s/it]: train_loss_raw=0.3750, running_loss=0.4069, LR=0.000100
[2025-08-27 12:54:29,384][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069312] [Batch 01552/03080] [00:18:47/00:18:30, 0.727s/it]: train_loss_raw=0.3948, running_loss=0.4033, LR=0.000100
[2025-08-27 12:54:35,145][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069320] [Batch 01560/03080] [00:18:53/00:18:24, 0.727s/it]: train_loss_raw=0.4694, running_loss=0.4023, LR=0.000100
[2025-08-27 12:54:41,023][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069328] [Batch 01568/03080] [00:18:59/00:18:18, 0.727s/it]: train_loss_raw=0.4029, running_loss=0.4014, LR=0.000100
[2025-08-27 12:54:46,919][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069336] [Batch 01576/03080] [00:19:05/00:18:13, 0.727s/it]: train_loss_raw=0.4067, running_loss=0.4009, LR=0.000100
[2025-08-27 12:54:52,886][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069344] [Batch 01584/03080] [00:19:11/00:18:07, 0.727s/it]: train_loss_raw=0.4813, running_loss=0.4013, LR=0.000100
[2025-08-27 12:54:58,510][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069352] [Batch 01592/03080] [00:19:16/00:18:01, 0.727s/it]: train_loss_raw=0.3057, running_loss=0.4012, LR=0.000100
[2025-08-27 12:55:04,312][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069360] [Batch 01600/03080] [00:19:22/00:17:55, 0.727s/it]: train_loss_raw=0.4208, running_loss=0.4016, LR=0.000100
[2025-08-27 12:55:10,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069368] [Batch 01608/03080] [00:19:28/00:17:49, 0.727s/it]: train_loss_raw=0.3724, running_loss=0.4002, LR=0.000100
[2025-08-27 12:55:16,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069376] [Batch 01616/03080] [00:19:34/00:17:43, 0.727s/it]: train_loss_raw=0.3784, running_loss=0.3997, LR=0.000100
[2025-08-27 12:55:21,749][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069384] [Batch 01624/03080] [00:19:40/00:17:38, 0.727s/it]: train_loss_raw=0.4951, running_loss=0.4018, LR=0.000100
[2025-08-27 12:55:27,495][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069392] [Batch 01632/03080] [00:19:45/00:17:32, 0.727s/it]: train_loss_raw=0.3580, running_loss=0.4031, LR=0.000100
[2025-08-27 12:55:33,292][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069400] [Batch 01640/03080] [00:19:51/00:17:26, 0.727s/it]: train_loss_raw=0.3906, running_loss=0.4030, LR=0.000100
[2025-08-27 12:55:39,069][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069408] [Batch 01648/03080] [00:19:57/00:17:20, 0.727s/it]: train_loss_raw=0.4653, running_loss=0.4028, LR=0.000100
[2025-08-27 12:55:44,790][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069416] [Batch 01656/03080] [00:20:03/00:17:14, 0.727s/it]: train_loss_raw=0.3591, running_loss=0.4029, LR=0.000100
[2025-08-27 12:55:50,544][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069424] [Batch 01664/03080] [00:20:08/00:17:08, 0.727s/it]: train_loss_raw=0.4076, running_loss=0.4032, LR=0.000100
[2025-08-27 12:55:56,451][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069432] [Batch 01672/03080] [00:20:14/00:17:03, 0.727s/it]: train_loss_raw=0.3950, running_loss=0.4013, LR=0.000100
[2025-08-27 12:56:02,237][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069440] [Batch 01680/03080] [00:20:20/00:16:57, 0.727s/it]: train_loss_raw=0.3704, running_loss=0.4014, LR=0.000100
[2025-08-27 12:56:07,954][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069448] [Batch 01688/03080] [00:20:26/00:16:51, 0.727s/it]: train_loss_raw=0.3944, running_loss=0.4023, LR=0.000100
[2025-08-27 12:56:13,856][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069456] [Batch 01696/03080] [00:20:32/00:16:45, 0.727s/it]: train_loss_raw=0.5392, running_loss=0.4028, LR=0.000100
[2025-08-27 12:56:19,911][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069464] [Batch 01704/03080] [00:20:38/00:16:39, 0.727s/it]: train_loss_raw=0.3562, running_loss=0.3994, LR=0.000100
[2025-08-27 12:56:25,763][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069472] [Batch 01712/03080] [00:20:44/00:16:34, 0.727s/it]: train_loss_raw=0.4451, running_loss=0.4005, LR=0.000100
[2025-08-27 12:56:31,684][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069480] [Batch 01720/03080] [00:20:50/00:16:28, 0.727s/it]: train_loss_raw=0.3838, running_loss=0.4023, LR=0.000100
[2025-08-27 12:56:37,733][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069488] [Batch 01728/03080] [00:20:56/00:16:22, 0.727s/it]: train_loss_raw=0.4672, running_loss=0.4053, LR=0.000100
[2025-08-27 12:56:43,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069496] [Batch 01736/03080] [00:21:01/00:16:17, 0.727s/it]: train_loss_raw=0.4397, running_loss=0.4070, LR=0.000100
[2025-08-27 12:56:49,305][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069504] [Batch 01744/03080] [00:21:07/00:16:11, 0.727s/it]: train_loss_raw=0.3937, running_loss=0.4083, LR=0.000100
[2025-08-27 12:56:55,346][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069512] [Batch 01752/03080] [00:21:13/00:16:05, 0.727s/it]: train_loss_raw=0.4032, running_loss=0.4069, LR=0.000100
[2025-08-27 12:57:01,318][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069520] [Batch 01760/03080] [00:21:19/00:15:59, 0.727s/it]: train_loss_raw=0.3427, running_loss=0.4078, LR=0.000100
[2025-08-27 12:57:07,026][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069528] [Batch 01768/03080] [00:21:25/00:15:53, 0.727s/it]: train_loss_raw=0.4408, running_loss=0.4079, LR=0.000100
[2025-08-27 12:57:12,744][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069536] [Batch 01776/03080] [00:21:31/00:15:48, 0.727s/it]: train_loss_raw=0.3892, running_loss=0.4076, LR=0.000100
[2025-08-27 12:57:18,458][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069544] [Batch 01784/03080] [00:21:36/00:15:42, 0.727s/it]: train_loss_raw=0.3824, running_loss=0.4096, LR=0.000100
[2025-08-27 12:57:24,171][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069552] [Batch 01792/03080] [00:21:42/00:15:36, 0.727s/it]: train_loss_raw=0.3652, running_loss=0.4073, LR=0.000100
[2025-08-27 12:57:29,880][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069560] [Batch 01800/03080] [00:21:48/00:15:30, 0.727s/it]: train_loss_raw=0.3584, running_loss=0.4055, LR=0.000100
[2025-08-27 12:57:35,617][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069568] [Batch 01808/03080] [00:21:54/00:15:24, 0.727s/it]: train_loss_raw=0.4170, running_loss=0.4060, LR=0.000100
[2025-08-27 12:57:41,478][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069576] [Batch 01816/03080] [00:21:59/00:15:18, 0.727s/it]: train_loss_raw=0.4225, running_loss=0.4069, LR=0.000100
[2025-08-27 12:57:47,209][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069584] [Batch 01824/03080] [00:22:05/00:15:12, 0.727s/it]: train_loss_raw=0.3653, running_loss=0.4049, LR=0.000100
[2025-08-27 12:57:53,047][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069592] [Batch 01832/03080] [00:22:11/00:15:07, 0.727s/it]: train_loss_raw=0.3572, running_loss=0.4036, LR=0.000100
[2025-08-27 12:57:58,792][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069600] [Batch 01840/03080] [00:22:17/00:15:01, 0.727s/it]: train_loss_raw=0.3750, running_loss=0.4049, LR=0.000100
[2025-08-27 12:58:04,505][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069608] [Batch 01848/03080] [00:22:22/00:14:55, 0.727s/it]: train_loss_raw=0.3863, running_loss=0.4025, LR=0.000100
[2025-08-27 12:58:10,234][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069616] [Batch 01856/03080] [00:22:28/00:14:49, 0.727s/it]: train_loss_raw=0.3378, running_loss=0.4041, LR=0.000100
[2025-08-27 12:58:15,845][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069624] [Batch 01864/03080] [00:22:34/00:14:43, 0.727s/it]: train_loss_raw=0.4086, running_loss=0.4038, LR=0.000100
[2025-08-27 12:58:21,412][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069632] [Batch 01872/03080] [00:22:39/00:14:37, 0.726s/it]: train_loss_raw=0.3219, running_loss=0.4005, LR=0.000100
[2025-08-27 12:58:26,858][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069640] [Batch 01880/03080] [00:22:45/00:14:31, 0.726s/it]: train_loss_raw=0.4193, running_loss=0.4015, LR=0.000100
[2025-08-27 12:58:32,379][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069648] [Batch 01888/03080] [00:22:50/00:14:25, 0.726s/it]: train_loss_raw=0.4137, running_loss=0.4018, LR=0.000100
[2025-08-27 12:58:38,226][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069656] [Batch 01896/03080] [00:22:56/00:14:19, 0.726s/it]: train_loss_raw=0.4633, running_loss=0.4015, LR=0.000100
[2025-08-27 12:58:43,968][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069664] [Batch 01904/03080] [00:23:02/00:14:13, 0.726s/it]: train_loss_raw=0.3663, running_loss=0.4014, LR=0.000100
[2025-08-27 12:58:49,782][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069672] [Batch 01912/03080] [00:23:08/00:14:08, 0.726s/it]: train_loss_raw=0.3924, running_loss=0.4007, LR=0.000100
[2025-08-27 12:58:55,757][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069680] [Batch 01920/03080] [00:23:14/00:14:02, 0.726s/it]: train_loss_raw=0.4273, running_loss=0.4003, LR=0.000100
[2025-08-27 12:59:01,626][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069688] [Batch 01928/03080] [00:23:20/00:13:56, 0.726s/it]: train_loss_raw=0.4303, running_loss=0.4004, LR=0.000100
[2025-08-27 12:59:07,578][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069696] [Batch 01936/03080] [00:23:25/00:13:50, 0.726s/it]: train_loss_raw=0.3682, running_loss=0.4013, LR=0.000100
[2025-08-27 12:59:13,564][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069704] [Batch 01944/03080] [00:23:31/00:13:45, 0.726s/it]: train_loss_raw=0.3090, running_loss=0.4008, LR=0.000100
[2025-08-27 12:59:19,308][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069712] [Batch 01952/03080] [00:23:37/00:13:39, 0.726s/it]: train_loss_raw=0.4711, running_loss=0.4010, LR=0.000100
[2025-08-27 12:59:25,032][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069720] [Batch 01960/03080] [00:23:43/00:13:33, 0.726s/it]: train_loss_raw=0.3946, running_loss=0.4026, LR=0.000100
[2025-08-27 12:59:30,879][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069728] [Batch 01968/03080] [00:23:49/00:13:27, 0.726s/it]: train_loss_raw=0.4476, running_loss=0.4043, LR=0.000100
[2025-08-27 12:59:36,628][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069736] [Batch 01976/03080] [00:23:55/00:13:21, 0.726s/it]: train_loss_raw=0.4183, running_loss=0.4047, LR=0.000100
[2025-08-27 12:59:42,430][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069744] [Batch 01984/03080] [00:24:00/00:13:15, 0.726s/it]: train_loss_raw=0.3815, running_loss=0.4051, LR=0.000100
[2025-08-27 12:59:48,217][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069752] [Batch 01992/03080] [00:24:06/00:13:10, 0.726s/it]: train_loss_raw=0.5061, running_loss=0.4060, LR=0.000100
[2025-08-27 12:59:54,061][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069760] [Batch 02000/03080] [00:24:12/00:13:04, 0.726s/it]: train_loss_raw=0.4004, running_loss=0.4072, LR=0.000100
[2025-08-27 12:59:59,595][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069768] [Batch 02008/03080] [00:24:18/00:12:58, 0.726s/it]: train_loss_raw=0.3372, running_loss=0.4061, LR=0.000100
[2025-08-27 13:00:05,493][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069776] [Batch 02016/03080] [00:24:23/00:12:52, 0.726s/it]: train_loss_raw=0.3602, running_loss=0.4049, LR=0.000100
[2025-08-27 13:00:11,226][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069784] [Batch 02024/03080] [00:24:29/00:12:46, 0.726s/it]: train_loss_raw=0.4312, running_loss=0.4037, LR=0.000100
[2025-08-27 13:00:17,035][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069792] [Batch 02032/03080] [00:24:35/00:12:40, 0.726s/it]: train_loss_raw=0.3443, running_loss=0.4032, LR=0.000100
[2025-08-27 13:00:22,767][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069800] [Batch 02040/03080] [00:24:41/00:12:35, 0.726s/it]: train_loss_raw=0.4136, running_loss=0.4036, LR=0.000100
[2025-08-27 13:00:28,637][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069808] [Batch 02048/03080] [00:24:47/00:12:29, 0.726s/it]: train_loss_raw=0.4488, running_loss=0.4027, LR=0.000100
[2025-08-27 13:00:34,395][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069816] [Batch 02056/03080] [00:24:52/00:12:23, 0.726s/it]: train_loss_raw=0.3607, running_loss=0.4033, LR=0.000100
[2025-08-27 13:00:40,206][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069824] [Batch 02064/03080] [00:24:58/00:12:17, 0.726s/it]: train_loss_raw=0.3213, running_loss=0.4037, LR=0.000100
[2025-08-27 13:00:46,093][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069832] [Batch 02072/03080] [00:25:04/00:12:11, 0.726s/it]: train_loss_raw=0.4205, running_loss=0.4041, LR=0.000100
[2025-08-27 13:00:52,058][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069840] [Batch 02080/03080] [00:25:10/00:12:06, 0.726s/it]: train_loss_raw=0.4425, running_loss=0.4049, LR=0.000100
[2025-08-27 13:00:58,063][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069848] [Batch 02088/03080] [00:25:16/00:12:00, 0.726s/it]: train_loss_raw=0.3490, running_loss=0.4033, LR=0.000100
[2025-08-27 13:01:04,192][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069856] [Batch 02096/03080] [00:25:22/00:11:54, 0.726s/it]: train_loss_raw=0.4340, running_loss=0.4040, LR=0.000100
[2025-08-27 13:01:10,259][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069864] [Batch 02104/03080] [00:25:28/00:11:49, 0.727s/it]: train_loss_raw=0.4626, running_loss=0.4042, LR=0.000100
[2025-08-27 13:01:16,251][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069872] [Batch 02112/03080] [00:25:34/00:11:43, 0.727s/it]: train_loss_raw=0.3707, running_loss=0.4060, LR=0.000100
[2025-08-27 13:01:22,205][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069880] [Batch 02120/03080] [00:25:40/00:11:37, 0.727s/it]: train_loss_raw=0.4663, running_loss=0.4062, LR=0.000100
[2025-08-27 13:01:28,152][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069888] [Batch 02128/03080] [00:25:46/00:11:31, 0.727s/it]: train_loss_raw=0.3596, running_loss=0.4062, LR=0.000100
[2025-08-27 13:01:34,110][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069896] [Batch 02136/03080] [00:25:52/00:11:26, 0.727s/it]: train_loss_raw=0.3091, running_loss=0.4051, LR=0.000100
[2025-08-27 13:01:40,073][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069904] [Batch 02144/03080] [00:25:58/00:11:20, 0.727s/it]: train_loss_raw=0.3791, running_loss=0.4051, LR=0.000100
[2025-08-27 13:01:46,150][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069912] [Batch 02152/03080] [00:26:04/00:11:14, 0.727s/it]: train_loss_raw=0.4047, running_loss=0.4065, LR=0.000100
[2025-08-27 13:01:52,209][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069920] [Batch 02160/03080] [00:26:10/00:11:08, 0.727s/it]: train_loss_raw=0.4542, running_loss=0.4074, LR=0.000100
[2025-08-27 13:01:58,199][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069928] [Batch 02168/03080] [00:26:16/00:11:03, 0.727s/it]: train_loss_raw=0.4167, running_loss=0.4064, LR=0.000100
[2025-08-27 13:02:04,180][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069936] [Batch 02176/03080] [00:26:22/00:10:57, 0.727s/it]: train_loss_raw=0.4331, running_loss=0.4063, LR=0.000100
[2025-08-27 13:02:10,157][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069944] [Batch 02184/03080] [00:26:28/00:10:51, 0.727s/it]: train_loss_raw=0.5043, running_loss=0.4063, LR=0.000100
[2025-08-27 13:02:16,083][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069952] [Batch 02192/03080] [00:26:34/00:10:45, 0.727s/it]: train_loss_raw=0.3780, running_loss=0.4057, LR=0.000100
[2025-08-27 13:02:22,244][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069960] [Batch 02200/03080] [00:26:40/00:10:40, 0.728s/it]: train_loss_raw=0.3664, running_loss=0.4047, LR=0.000100
[2025-08-27 13:02:28,322][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069968] [Batch 02208/03080] [00:26:46/00:10:34, 0.728s/it]: train_loss_raw=0.3845, running_loss=0.4054, LR=0.000100
[2025-08-27 13:02:34,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069976] [Batch 02216/03080] [00:26:52/00:10:28, 0.728s/it]: train_loss_raw=0.3229, running_loss=0.4055, LR=0.000100
[2025-08-27 13:02:40,307][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069984] [Batch 02224/03080] [00:26:58/00:10:23, 0.728s/it]: train_loss_raw=0.2851, running_loss=0.4045, LR=0.000100
[2025-08-27 13:02:46,302][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 069992] [Batch 02232/03080] [00:27:04/00:10:17, 0.728s/it]: train_loss_raw=0.3435, running_loss=0.4036, LR=0.000100
[2025-08-27 13:02:52,292][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070000] [Batch 02240/03080] [00:27:10/00:10:11, 0.728s/it]: train_loss_raw=0.3530, running_loss=0.4037, LR=0.000100
[2025-08-27 13:03:02,160][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070008] [Batch 02248/03080] [00:27:20/00:10:07, 0.730s/it]: train_loss_raw=0.3346, running_loss=0.4034, LR=0.000100
[2025-08-27 13:03:08,106][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070016] [Batch 02256/03080] [00:27:26/00:10:01, 0.730s/it]: train_loss_raw=0.3215, running_loss=0.4033, LR=0.000100
[2025-08-27 13:03:14,280][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070024] [Batch 02264/03080] [00:27:32/00:09:55, 0.730s/it]: train_loss_raw=0.3918, running_loss=0.4033, LR=0.000100
[2025-08-27 13:03:20,398][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070032] [Batch 02272/03080] [00:27:38/00:09:49, 0.730s/it]: train_loss_raw=0.4262, running_loss=0.4031, LR=0.000100
[2025-08-27 13:03:26,529][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070040] [Batch 02280/03080] [00:27:44/00:09:44, 0.730s/it]: train_loss_raw=0.4241, running_loss=0.4042, LR=0.000100
[2025-08-27 13:03:32,503][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070048] [Batch 02288/03080] [00:27:50/00:09:38, 0.730s/it]: train_loss_raw=0.3629, running_loss=0.4054, LR=0.000100
[2025-08-27 13:03:38,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070056] [Batch 02296/03080] [00:27:56/00:09:32, 0.730s/it]: train_loss_raw=0.3274, running_loss=0.4039, LR=0.000100
[2025-08-27 13:03:44,339][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070064] [Batch 02304/03080] [00:28:02/00:09:26, 0.730s/it]: train_loss_raw=0.4398, running_loss=0.4062, LR=0.000100
[2025-08-27 13:03:49,840][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070072] [Batch 02312/03080] [00:28:08/00:09:20, 0.730s/it]: train_loss_raw=0.4088, running_loss=0.4062, LR=0.000100
[2025-08-27 13:03:55,339][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070080] [Batch 02320/03080] [00:28:13/00:09:14, 0.730s/it]: train_loss_raw=0.3887, running_loss=0.4052, LR=0.000100
[2025-08-27 13:04:01,039][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070088] [Batch 02328/03080] [00:28:19/00:09:08, 0.730s/it]: train_loss_raw=0.4458, running_loss=0.4074, LR=0.000100
[2025-08-27 13:04:06,924][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070096] [Batch 02336/03080] [00:28:25/00:09:03, 0.730s/it]: train_loss_raw=0.2865, running_loss=0.4069, LR=0.000100
[2025-08-27 13:04:12,853][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070104] [Batch 02344/03080] [00:28:31/00:08:57, 0.730s/it]: train_loss_raw=0.4685, running_loss=0.4066, LR=0.000100
[2025-08-27 13:04:18,303][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070112] [Batch 02352/03080] [00:28:36/00:08:51, 0.730s/it]: train_loss_raw=0.4330, running_loss=0.4064, LR=0.000100
[2025-08-27 13:04:24,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070120] [Batch 02360/03080] [00:28:42/00:08:45, 0.730s/it]: train_loss_raw=0.3803, running_loss=0.4072, LR=0.000100
[2025-08-27 13:04:30,091][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070128] [Batch 02368/03080] [00:28:48/00:08:39, 0.730s/it]: train_loss_raw=0.4361, running_loss=0.4062, LR=0.000100
[2025-08-27 13:04:36,092][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070136] [Batch 02376/03080] [00:28:54/00:08:33, 0.730s/it]: train_loss_raw=0.3825, running_loss=0.4051, LR=0.000100
[2025-08-27 13:04:42,054][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070144] [Batch 02384/03080] [00:29:00/00:08:28, 0.730s/it]: train_loss_raw=0.3728, running_loss=0.4054, LR=0.000100
[2025-08-27 13:04:47,999][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070152] [Batch 02392/03080] [00:29:06/00:08:22, 0.730s/it]: train_loss_raw=0.3670, running_loss=0.4038, LR=0.000100
[2025-08-27 13:04:53,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070160] [Batch 02400/03080] [00:29:12/00:08:16, 0.730s/it]: train_loss_raw=0.4648, running_loss=0.4044, LR=0.000100
[2025-08-27 13:04:59,856][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070168] [Batch 02408/03080] [00:29:18/00:08:10, 0.730s/it]: train_loss_raw=0.3652, running_loss=0.4024, LR=0.000100
[2025-08-27 13:05:05,855][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070176] [Batch 02416/03080] [00:29:24/00:08:04, 0.730s/it]: train_loss_raw=0.3560, running_loss=0.4023, LR=0.000100
[2025-08-27 13:05:11,845][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070184] [Batch 02424/03080] [00:29:30/00:07:59, 0.730s/it]: train_loss_raw=0.3270, running_loss=0.4018, LR=0.000100
[2025-08-27 13:05:17,880][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070192] [Batch 02432/03080] [00:29:36/00:07:53, 0.730s/it]: train_loss_raw=0.4189, running_loss=0.4008, LR=0.000100
[2025-08-27 13:05:23,862][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070200] [Batch 02440/03080] [00:29:42/00:07:47, 0.730s/it]: train_loss_raw=0.4901, running_loss=0.4007, LR=0.000100
[2025-08-27 13:05:29,709][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070208] [Batch 02448/03080] [00:29:48/00:07:41, 0.730s/it]: train_loss_raw=0.4065, running_loss=0.4024, LR=0.000100
[2025-08-27 13:05:35,125][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070216] [Batch 02456/03080] [00:29:53/00:07:35, 0.730s/it]: train_loss_raw=0.3588, running_loss=0.4033, LR=0.000100
[2025-08-27 13:05:40,706][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070224] [Batch 02464/03080] [00:29:59/00:07:29, 0.730s/it]: train_loss_raw=0.4387, running_loss=0.4049, LR=0.000100
[2025-08-27 13:05:46,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070232] [Batch 02472/03080] [00:30:04/00:07:23, 0.730s/it]: train_loss_raw=0.3321, running_loss=0.4046, LR=0.000100
[2025-08-27 13:05:51,750][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070240] [Batch 02480/03080] [00:30:10/00:07:17, 0.730s/it]: train_loss_raw=0.4584, running_loss=0.4043, LR=0.000100
[2025-08-27 13:05:57,560][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070248] [Batch 02488/03080] [00:30:15/00:07:12, 0.730s/it]: train_loss_raw=0.3895, running_loss=0.4036, LR=0.000100
[2025-08-27 13:06:03,659][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070256] [Batch 02496/03080] [00:30:22/00:07:06, 0.730s/it]: train_loss_raw=0.3966, running_loss=0.4023, LR=0.000100
[2025-08-27 13:06:09,691][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070264] [Batch 02504/03080] [00:30:28/00:07:00, 0.730s/it]: train_loss_raw=0.4757, running_loss=0.4011, LR=0.000100
[2025-08-27 13:06:15,805][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070272] [Batch 02512/03080] [00:30:34/00:06:54, 0.730s/it]: train_loss_raw=0.4156, running_loss=0.4016, LR=0.000100
[2025-08-27 13:06:21,808][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070280] [Batch 02520/03080] [00:30:40/00:06:48, 0.730s/it]: train_loss_raw=0.4221, running_loss=0.4012, LR=0.000100
[2025-08-27 13:06:27,875][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070288] [Batch 02528/03080] [00:30:46/00:06:43, 0.730s/it]: train_loss_raw=0.4903, running_loss=0.4031, LR=0.000100
[2025-08-27 13:06:33,923][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070296] [Batch 02536/03080] [00:30:52/00:06:37, 0.730s/it]: train_loss_raw=0.3686, running_loss=0.4019, LR=0.000100
[2025-08-27 13:06:39,921][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070304] [Batch 02544/03080] [00:30:58/00:06:31, 0.730s/it]: train_loss_raw=0.4195, running_loss=0.4044, LR=0.000100
[2025-08-27 13:06:45,926][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070312] [Batch 02552/03080] [00:31:04/00:06:25, 0.731s/it]: train_loss_raw=0.4357, running_loss=0.4048, LR=0.000100
[2025-08-27 13:06:51,967][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070320] [Batch 02560/03080] [00:31:10/00:06:19, 0.731s/it]: train_loss_raw=0.4139, running_loss=0.4030, LR=0.000100
[2025-08-27 13:06:57,996][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070328] [Batch 02568/03080] [00:31:16/00:06:14, 0.731s/it]: train_loss_raw=0.3977, running_loss=0.4035, LR=0.000100
[2025-08-27 13:07:03,983][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070336] [Batch 02576/03080] [00:31:22/00:06:08, 0.731s/it]: train_loss_raw=0.4413, running_loss=0.4029, LR=0.000100
[2025-08-27 13:07:09,984][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070344] [Batch 02584/03080] [00:31:28/00:06:02, 0.731s/it]: train_loss_raw=0.4065, running_loss=0.3995, LR=0.000100
[2025-08-27 13:07:15,932][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070352] [Batch 02592/03080] [00:31:34/00:05:56, 0.731s/it]: train_loss_raw=0.3995, running_loss=0.3997, LR=0.000100
[2025-08-27 13:07:21,943][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070360] [Batch 02600/03080] [00:31:40/00:05:50, 0.731s/it]: train_loss_raw=0.4282, running_loss=0.4020, LR=0.000100
[2025-08-27 13:07:27,949][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070368] [Batch 02608/03080] [00:31:46/00:05:45, 0.731s/it]: train_loss_raw=0.4246, running_loss=0.3998, LR=0.000100
[2025-08-27 13:07:33,962][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070376] [Batch 02616/03080] [00:31:52/00:05:39, 0.731s/it]: train_loss_raw=0.4288, running_loss=0.4013, LR=0.000100
[2025-08-27 13:07:39,936][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070384] [Batch 02624/03080] [00:31:58/00:05:33, 0.731s/it]: train_loss_raw=0.3653, running_loss=0.4032, LR=0.000100
[2025-08-27 13:07:45,986][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070392] [Batch 02632/03080] [00:32:04/00:05:27, 0.731s/it]: train_loss_raw=0.4618, running_loss=0.4031, LR=0.000100
[2025-08-27 13:07:52,115][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070400] [Batch 02640/03080] [00:32:10/00:05:21, 0.731s/it]: train_loss_raw=0.4838, running_loss=0.4051, LR=0.000100
[2025-08-27 13:07:58,113][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070408] [Batch 02648/03080] [00:32:16/00:05:15, 0.731s/it]: train_loss_raw=0.3733, running_loss=0.4066, LR=0.000100
[2025-08-27 13:08:04,113][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070416] [Batch 02656/03080] [00:32:22/00:05:10, 0.731s/it]: train_loss_raw=0.3642, running_loss=0.4048, LR=0.000100
[2025-08-27 13:08:10,111][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070424] [Batch 02664/03080] [00:32:28/00:05:04, 0.731s/it]: train_loss_raw=0.3919, running_loss=0.4059, LR=0.000100
[2025-08-27 13:08:16,106][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070432] [Batch 02672/03080] [00:32:34/00:04:58, 0.731s/it]: train_loss_raw=0.3768, running_loss=0.4056, LR=0.000100
[2025-08-27 13:08:22,151][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070440] [Batch 02680/03080] [00:32:40/00:04:52, 0.732s/it]: train_loss_raw=0.4606, running_loss=0.4050, LR=0.000100
[2025-08-27 13:08:27,700][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070448] [Batch 02688/03080] [00:32:46/00:04:46, 0.731s/it]: train_loss_raw=0.4027, running_loss=0.4043, LR=0.000100
[2025-08-27 13:08:33,426][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070456] [Batch 02696/03080] [00:32:51/00:04:40, 0.731s/it]: train_loss_raw=0.3700, running_loss=0.4056, LR=0.000100
[2025-08-27 13:08:39,417][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070464] [Batch 02704/03080] [00:32:57/00:04:35, 0.731s/it]: train_loss_raw=0.3560, running_loss=0.4052, LR=0.000100
[2025-08-27 13:08:45,422][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070472] [Batch 02712/03080] [00:33:03/00:04:29, 0.732s/it]: train_loss_raw=0.4225, running_loss=0.4056, LR=0.000100
[2025-08-27 13:08:51,391][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070480] [Batch 02720/03080] [00:33:09/00:04:23, 0.732s/it]: train_loss_raw=0.4444, running_loss=0.4055, LR=0.000100
[2025-08-27 13:08:57,404][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070488] [Batch 02728/03080] [00:33:15/00:04:17, 0.732s/it]: train_loss_raw=0.4099, running_loss=0.4057, LR=0.000100
[2025-08-27 13:09:03,480][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070496] [Batch 02736/03080] [00:33:21/00:04:11, 0.732s/it]: train_loss_raw=0.3357, running_loss=0.4047, LR=0.000100
[2025-08-27 13:09:09,596][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070504] [Batch 02744/03080] [00:33:28/00:04:05, 0.732s/it]: train_loss_raw=0.3740, running_loss=0.4021, LR=0.000100
[2025-08-27 13:09:15,599][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070512] [Batch 02752/03080] [00:33:34/00:04:00, 0.732s/it]: train_loss_raw=0.4045, running_loss=0.4026, LR=0.000100
[2025-08-27 13:09:21,556][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070520] [Batch 02760/03080] [00:33:39/00:03:54, 0.732s/it]: train_loss_raw=0.3287, running_loss=0.4007, LR=0.000100
[2025-08-27 13:09:27,585][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070528] [Batch 02768/03080] [00:33:46/00:03:48, 0.732s/it]: train_loss_raw=0.3164, running_loss=0.3993, LR=0.000100
[2025-08-27 13:09:33,552][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070536] [Batch 02776/03080] [00:33:51/00:03:42, 0.732s/it]: train_loss_raw=0.3270, running_loss=0.3991, LR=0.000100
[2025-08-27 13:09:39,465][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070544] [Batch 02784/03080] [00:33:57/00:03:36, 0.732s/it]: train_loss_raw=0.3682, running_loss=0.3993, LR=0.000100
[2025-08-27 13:09:45,479][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070552] [Batch 02792/03080] [00:34:03/00:03:30, 0.732s/it]: train_loss_raw=0.3579, running_loss=0.3992, LR=0.000100
[2025-08-27 13:09:51,485][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070560] [Batch 02800/03080] [00:34:09/00:03:24, 0.732s/it]: train_loss_raw=0.4402, running_loss=0.4003, LR=0.000100
[2025-08-27 13:09:57,357][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070568] [Batch 02808/03080] [00:34:15/00:03:19, 0.732s/it]: train_loss_raw=0.3505, running_loss=0.4005, LR=0.000100
[2025-08-27 13:10:03,397][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070576] [Batch 02816/03080] [00:34:21/00:03:13, 0.732s/it]: train_loss_raw=0.4289, running_loss=0.4021, LR=0.000100
[2025-08-27 13:10:09,475][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070584] [Batch 02824/03080] [00:34:27/00:03:07, 0.732s/it]: train_loss_raw=0.3416, running_loss=0.4016, LR=0.000100
[2025-08-27 13:10:15,670][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070592] [Batch 02832/03080] [00:34:34/00:03:01, 0.732s/it]: train_loss_raw=0.4162, running_loss=0.4003, LR=0.000100
[2025-08-27 13:10:21,597][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070600] [Batch 02840/03080] [00:34:40/00:02:55, 0.732s/it]: train_loss_raw=0.3436, running_loss=0.3995, LR=0.000100
[2025-08-27 13:10:27,698][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070608] [Batch 02848/03080] [00:34:46/00:02:49, 0.732s/it]: train_loss_raw=0.3954, running_loss=0.4013, LR=0.000100
[2025-08-27 13:10:33,529][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070616] [Batch 02856/03080] [00:34:51/00:02:44, 0.732s/it]: train_loss_raw=0.4029, running_loss=0.4010, LR=0.000100
[2025-08-27 13:10:39,471][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070624] [Batch 02864/03080] [00:34:57/00:02:38, 0.733s/it]: train_loss_raw=0.3560, running_loss=0.4015, LR=0.000100
[2025-08-27 13:10:45,455][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070632] [Batch 02872/03080] [00:35:03/00:02:32, 0.733s/it]: train_loss_raw=0.3794, running_loss=0.4026, LR=0.000100
[2025-08-27 13:10:51,453][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070640] [Batch 02880/03080] [00:35:09/00:02:26, 0.733s/it]: train_loss_raw=0.3669, running_loss=0.4026, LR=0.000100
[2025-08-27 13:10:57,587][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070648] [Batch 02888/03080] [00:35:16/00:02:20, 0.733s/it]: train_loss_raw=0.4066, running_loss=0.4012, LR=0.000100
[2025-08-27 13:11:03,651][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070656] [Batch 02896/03080] [00:35:22/00:02:14, 0.733s/it]: train_loss_raw=0.3310, running_loss=0.4022, LR=0.000100
[2025-08-27 13:11:09,649][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070664] [Batch 02904/03080] [00:35:28/00:02:08, 0.733s/it]: train_loss_raw=0.3645, running_loss=0.4016, LR=0.000100
[2025-08-27 13:11:15,822][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070672] [Batch 02912/03080] [00:35:34/00:02:03, 0.733s/it]: train_loss_raw=0.4413, running_loss=0.4011, LR=0.000100
[2025-08-27 13:11:21,821][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070680] [Batch 02920/03080] [00:35:40/00:01:57, 0.733s/it]: train_loss_raw=0.4017, running_loss=0.4026, LR=0.000100
[2025-08-27 13:11:27,835][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070688] [Batch 02928/03080] [00:35:46/00:01:51, 0.733s/it]: train_loss_raw=0.4514, running_loss=0.4011, LR=0.000100
[2025-08-27 13:11:33,964][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070696] [Batch 02936/03080] [00:35:52/00:01:45, 0.733s/it]: train_loss_raw=0.4046, running_loss=0.4006, LR=0.000100
[2025-08-27 13:11:40,030][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070704] [Batch 02944/03080] [00:35:58/00:01:39, 0.733s/it]: train_loss_raw=0.3700, running_loss=0.3999, LR=0.000100
[2025-08-27 13:11:46,319][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070712] [Batch 02952/03080] [00:36:04/00:01:33, 0.733s/it]: train_loss_raw=0.3737, running_loss=0.4008, LR=0.000100
[2025-08-27 13:11:52,574][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070720] [Batch 02960/03080] [00:36:10/00:01:28, 0.733s/it]: train_loss_raw=0.3984, running_loss=0.4030, LR=0.000100
[2025-08-27 13:11:58,749][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070728] [Batch 02968/03080] [00:36:17/00:01:22, 0.734s/it]: train_loss_raw=0.3358, running_loss=0.4013, LR=0.000100
[2025-08-27 13:12:04,972][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070736] [Batch 02976/03080] [00:36:23/00:01:16, 0.734s/it]: train_loss_raw=0.4396, running_loss=0.4014, LR=0.000100
[2025-08-27 13:12:11,044][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070744] [Batch 02984/03080] [00:36:29/00:01:10, 0.734s/it]: train_loss_raw=0.3366, running_loss=0.4007, LR=0.000100
[2025-08-27 13:12:17,132][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070752] [Batch 02992/03080] [00:36:35/00:01:04, 0.734s/it]: train_loss_raw=0.3976, running_loss=0.3994, LR=0.000100
[2025-08-27 13:12:23,125][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070760] [Batch 03000/03080] [00:36:41/00:00:58, 0.734s/it]: train_loss_raw=0.2737, running_loss=0.3975, LR=0.000100
[2025-08-27 13:12:29,119][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070768] [Batch 03008/03080] [00:36:47/00:00:52, 0.734s/it]: train_loss_raw=0.3620, running_loss=0.3975, LR=0.000100
[2025-08-27 13:12:35,093][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070776] [Batch 03016/03080] [00:36:53/00:00:46, 0.734s/it]: train_loss_raw=0.4475, running_loss=0.3949, LR=0.000100
[2025-08-27 13:12:41,093][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070784] [Batch 03024/03080] [00:36:59/00:00:41, 0.734s/it]: train_loss_raw=0.4544, running_loss=0.3966, LR=0.000100
[2025-08-27 13:12:47,197][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070792] [Batch 03032/03080] [00:37:05/00:00:35, 0.734s/it]: train_loss_raw=0.3655, running_loss=0.3978, LR=0.000100
[2025-08-27 13:12:53,292][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070800] [Batch 03040/03080] [00:37:11/00:00:29, 0.734s/it]: train_loss_raw=0.3636, running_loss=0.3971, LR=0.000100
[2025-08-27 13:12:59,416][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070808] [Batch 03048/03080] [00:37:17/00:00:23, 0.734s/it]: train_loss_raw=0.3371, running_loss=0.3964, LR=0.000100
[2025-08-27 13:13:05,323][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070816] [Batch 03056/03080] [00:37:23/00:00:17, 0.734s/it]: train_loss_raw=0.3537, running_loss=0.3982, LR=0.000100
[2025-08-27 13:13:10,774][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070824] [Batch 03064/03080] [00:37:29/00:00:11, 0.734s/it]: train_loss_raw=0.3799, running_loss=0.3981, LR=0.000100
[2025-08-27 13:13:16,297][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070832] [Batch 03072/03080] [00:37:34/00:00:05, 0.734s/it]: train_loss_raw=0.4081, running_loss=0.3983, LR=0.000100
[2025-08-27 13:13:22,324][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 070840] [Batch 03080/03080] [00:37:40/00:00:00, 0.734s/it]: train_loss_raw=0.3945, running_loss=0.3963, LR=0.000100
[2025-08-27 13:13:22,854][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-27 13:13:34,181][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00007/00310] [00:00:11/00:07:07, 1.416s/it]
[2025-08-27 13:13:46,441][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00015/00310] [00:00:23/00:07:13, 1.474s/it]
[2025-08-27 13:13:59,218][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00023/00310] [00:00:36/00:07:13, 1.515s/it]
[2025-08-27 13:14:11,306][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00031/00310] [00:00:48/00:07:00, 1.514s/it]
[2025-08-27 13:14:23,406][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00039/00310] [00:01:00/00:06:48, 1.514s/it]
[2025-08-27 13:14:35,660][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00047/00310] [00:01:12/00:06:37, 1.517s/it]
[2025-08-27 13:14:47,374][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00055/00310] [00:01:24/00:06:23, 1.509s/it]
[2025-08-27 13:14:59,360][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00063/00310] [00:01:36/00:06:10, 1.508s/it]
[2025-08-27 13:15:10,377][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00071/00310] [00:01:47/00:05:55, 1.493s/it]
[2025-08-27 13:15:21,146][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00079/00310] [00:01:58/00:05:40, 1.479s/it]
[2025-08-27 13:15:33,290][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00087/00310] [00:02:10/00:05:29, 1.482s/it]
[2025-08-27 13:15:45,522][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00095/00310] [00:02:22/00:05:18, 1.486s/it]
[2025-08-27 13:15:57,656][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00103/00310] [00:02:34/00:05:06, 1.488s/it]
[2025-08-27 13:16:10,221][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00111/00310] [00:02:47/00:04:55, 1.494s/it]
[2025-08-27 13:16:21,940][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00119/00310] [00:02:59/00:04:43, 1.492s/it]
[2025-08-27 13:16:34,203][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00127/00310] [00:03:11/00:04:32, 1.495s/it]
[2025-08-27 13:16:46,485][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00135/00310] [00:03:23/00:04:20, 1.497s/it]
[2025-08-27 13:16:57,857][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00143/00310] [00:03:35/00:04:07, 1.493s/it]
[2025-08-27 13:17:09,632][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00151/00310] [00:03:46/00:03:55, 1.492s/it]
[2025-08-27 13:17:20,899][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00159/00310] [00:03:58/00:03:43, 1.488s/it]
[2025-08-27 13:17:32,901][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00167/00310] [00:04:10/00:03:31, 1.488s/it]
[2025-08-27 13:17:42,827][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00175/00310] [00:04:19/00:03:17, 1.477s/it]
[2025-08-27 13:17:52,633][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00183/00310] [00:04:29/00:03:04, 1.466s/it]
[2025-08-27 13:18:03,663][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00191/00310] [00:04:40/00:02:52, 1.463s/it]
[2025-08-27 13:18:15,487][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00199/00310] [00:04:52/00:02:40, 1.463s/it]
[2025-08-27 13:18:26,913][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00207/00310] [00:05:04/00:02:29, 1.462s/it]
[2025-08-27 13:18:37,991][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00215/00310] [00:05:15/00:02:17, 1.459s/it]
[2025-08-27 13:18:49,603][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00223/00310] [00:05:26/00:02:05, 1.459s/it]
[2025-08-27 13:19:00,620][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00231/00310] [00:05:37/00:01:53, 1.456s/it]
[2025-08-27 13:19:12,667][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00239/00310] [00:05:49/00:01:42, 1.458s/it]
[2025-08-27 13:19:24,019][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00247/00310] [00:06:01/00:01:30, 1.456s/it]
[2025-08-27 13:19:35,667][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00255/00310] [00:06:12/00:01:18, 1.456s/it]
[2025-08-27 13:19:47,511][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00263/00310] [00:06:24/00:01:07, 1.457s/it]
[2025-08-27 13:19:59,475][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00271/00310] [00:06:36/00:00:55, 1.458s/it]
[2025-08-27 13:20:10,821][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00279/00310] [00:06:47/00:00:43, 1.457s/it]
[2025-08-27 13:20:23,990][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00287/00310] [00:07:01/00:00:32, 1.462s/it]
[2025-08-27 13:20:35,336][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00295/00310] [00:07:12/00:00:20, 1.461s/it]
[2025-08-27 13:20:47,710][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 070841] [Batch 00303/00310] [00:07:24/00:00:08, 1.463s/it]
[2025-08-27 13:20:56,793][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=0.39629, valid_loss=1.43769
[2025-08-27 13:20:56,793][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-27 13:20:56,794][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.494
[2025-08-27 13:20:56,794][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.140
[2025-08-27 13:20:56,794][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.143
[2025-08-27 13:20:56,794][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.079
[2025-08-27 13:20:56,803][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 17:54:10, remaining time 05:26:55, 00:46:42 per epoch
[2025-08-27 13:21:02,458][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070848] [Batch 00008/03080] [00:00:05/00:34:20, 0.671s/it]: train_loss_raw=0.4326, running_loss=0.4799, LR=0.000100
[2025-08-27 13:21:08,521][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070856] [Batch 00016/03080] [00:00:11/00:36:28, 0.714s/it]: train_loss_raw=0.4666, running_loss=0.4747, LR=0.000100
[2025-08-27 13:21:14,541][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070864] [Batch 00024/03080] [00:00:17/00:37:01, 0.727s/it]: train_loss_raw=0.4308, running_loss=0.4690, LR=0.000100
[2025-08-27 13:21:20,539][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070872] [Batch 00032/03080] [00:00:23/00:37:13, 0.733s/it]: train_loss_raw=0.3749, running_loss=0.4645, LR=0.000100
[2025-08-27 13:21:26,523][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070880] [Batch 00040/03080] [00:00:29/00:37:16, 0.736s/it]: train_loss_raw=0.4911, running_loss=0.4613, LR=0.000100
[2025-08-27 13:21:32,513][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070888] [Batch 00048/03080] [00:00:35/00:37:17, 0.738s/it]: train_loss_raw=0.4245, running_loss=0.4560, LR=0.000100
[2025-08-27 13:21:38,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070896] [Batch 00056/03080] [00:00:41/00:37:17, 0.740s/it]: train_loss_raw=0.3929, running_loss=0.4516, LR=0.000100
[2025-08-27 13:21:44,547][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070904] [Batch 00064/03080] [00:00:47/00:37:16, 0.741s/it]: train_loss_raw=0.4321, running_loss=0.4477, LR=0.000100
[2025-08-27 13:21:50,566][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070912] [Batch 00072/03080] [00:00:53/00:37:13, 0.743s/it]: train_loss_raw=0.4570, running_loss=0.4434, LR=0.000100
[2025-08-27 13:21:56,545][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070920] [Batch 00080/03080] [00:00:59/00:37:09, 0.743s/it]: train_loss_raw=0.4814, running_loss=0.4418, LR=0.000100
[2025-08-27 13:22:02,547][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070928] [Batch 00088/03080] [00:01:05/00:37:05, 0.744s/it]: train_loss_raw=0.3848, running_loss=0.4384, LR=0.000100
[2025-08-27 13:22:08,595][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070936] [Batch 00096/03080] [00:01:11/00:37:02, 0.745s/it]: train_loss_raw=0.4022, running_loss=0.4331, LR=0.000100
[2025-08-27 13:22:14,016][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070944] [Batch 00104/03080] [00:01:16/00:36:41, 0.740s/it]: train_loss_raw=0.3856, running_loss=0.4302, LR=0.000100
[2025-08-27 13:22:19,437][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070952] [Batch 00112/03080] [00:01:22/00:36:22, 0.735s/it]: train_loss_raw=0.4407, running_loss=0.4294, LR=0.000100
[2025-08-27 13:22:25,414][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070960] [Batch 00120/03080] [00:01:28/00:36:18, 0.736s/it]: train_loss_raw=0.4735, running_loss=0.4273, LR=0.000100
[2025-08-27 13:22:30,895][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070968] [Batch 00128/03080] [00:01:33/00:36:03, 0.733s/it]: train_loss_raw=0.3278, running_loss=0.4260, LR=0.000100
[2025-08-27 13:22:36,851][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070976] [Batch 00136/03080] [00:01:39/00:35:59, 0.734s/it]: train_loss_raw=0.3689, running_loss=0.4253, LR=0.000100
[2025-08-27 13:22:42,868][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070984] [Batch 00144/03080] [00:01:45/00:35:56, 0.735s/it]: train_loss_raw=0.3553, running_loss=0.4209, LR=0.000100
[2025-08-27 13:22:48,941][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 070992] [Batch 00152/03080] [00:01:51/00:35:54, 0.736s/it]: train_loss_raw=0.4099, running_loss=0.4208, LR=0.000100
[2025-08-27 13:22:55,000][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071000] [Batch 00160/03080] [00:01:57/00:35:51, 0.737s/it]: train_loss_raw=0.4299, running_loss=0.4204, LR=0.000100
[2025-08-27 13:23:00,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071008] [Batch 00168/03080] [00:02:03/00:35:47, 0.737s/it]: train_loss_raw=0.3579, running_loss=0.4192, LR=0.000100
[2025-08-27 13:23:06,574][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071016] [Batch 00176/03080] [00:02:09/00:35:36, 0.736s/it]: train_loss_raw=0.3511, running_loss=0.4188, LR=0.000100
[2025-08-27 13:23:12,579][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071024] [Batch 00184/03080] [00:02:15/00:35:32, 0.736s/it]: train_loss_raw=0.3868, running_loss=0.4172, LR=0.000100
[2025-08-27 13:23:18,563][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071032] [Batch 00192/03080] [00:02:21/00:35:27, 0.737s/it]: train_loss_raw=0.4529, running_loss=0.4166, LR=0.000100
[2025-08-27 13:23:24,521][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071040] [Batch 00200/03080] [00:02:27/00:35:22, 0.737s/it]: train_loss_raw=0.3498, running_loss=0.4147, LR=0.000100
[2025-08-27 13:23:30,506][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071048] [Batch 00208/03080] [00:02:33/00:35:18, 0.738s/it]: train_loss_raw=0.4014, running_loss=0.4135, LR=0.000100
[2025-08-27 13:23:36,521][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071056] [Batch 00216/03080] [00:02:39/00:35:13, 0.738s/it]: train_loss_raw=0.4339, running_loss=0.4130, LR=0.000100
[2025-08-27 13:23:42,499][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071064] [Batch 00224/03080] [00:02:45/00:35:08, 0.738s/it]: train_loss_raw=0.3826, running_loss=0.4123, LR=0.000100
[2025-08-27 13:23:48,504][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071072] [Batch 00232/03080] [00:02:51/00:35:04, 0.739s/it]: train_loss_raw=0.3790, running_loss=0.4110, LR=0.000100
[2025-08-27 13:23:54,652][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071080] [Batch 00240/03080] [00:02:57/00:35:01, 0.740s/it]: train_loss_raw=0.4587, running_loss=0.4101, LR=0.000100
[2025-08-27 13:24:00,642][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071088] [Batch 00248/03080] [00:03:03/00:34:56, 0.740s/it]: train_loss_raw=0.4797, running_loss=0.4097, LR=0.000100
[2025-08-27 13:24:06,697][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071096] [Batch 00256/03080] [00:03:09/00:34:51, 0.741s/it]: train_loss_raw=0.3783, running_loss=0.4093, LR=0.000100
[2025-08-27 13:24:12,706][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071104] [Batch 00264/03080] [00:03:15/00:34:46, 0.741s/it]: train_loss_raw=0.4018, running_loss=0.4105, LR=0.000100
[2025-08-27 13:24:18,772][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071112] [Batch 00272/03080] [00:03:21/00:34:42, 0.741s/it]: train_loss_raw=0.4161, running_loss=0.4099, LR=0.000100
[2025-08-27 13:24:24,764][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071120] [Batch 00280/03080] [00:03:27/00:34:36, 0.742s/it]: train_loss_raw=0.3804, running_loss=0.4081, LR=0.000100
[2025-08-27 13:24:30,790][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071128] [Batch 00288/03080] [00:03:33/00:34:31, 0.742s/it]: train_loss_raw=0.4211, running_loss=0.4080, LR=0.000100
[2025-08-27 13:24:36,898][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071136] [Batch 00296/03080] [00:03:39/00:34:27, 0.743s/it]: train_loss_raw=0.4659, running_loss=0.4067, LR=0.000100
[2025-08-27 13:24:42,881][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071144] [Batch 00304/03080] [00:03:45/00:34:21, 0.743s/it]: train_loss_raw=0.4475, running_loss=0.4070, LR=0.000100
[2025-08-27 13:24:49,127][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071152] [Batch 00312/03080] [00:03:52/00:34:18, 0.744s/it]: train_loss_raw=0.4658, running_loss=0.4057, LR=0.000100
[2025-08-27 13:24:55,142][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071160] [Batch 00320/03080] [00:03:58/00:34:13, 0.744s/it]: train_loss_raw=0.3977, running_loss=0.4055, LR=0.000100
[2025-08-27 13:25:01,129][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071168] [Batch 00328/03080] [00:04:04/00:34:07, 0.744s/it]: train_loss_raw=0.3867, running_loss=0.4042, LR=0.000100
[2025-08-27 13:25:07,143][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071176] [Batch 00336/03080] [00:04:10/00:34:02, 0.744s/it]: train_loss_raw=0.4021, running_loss=0.4033, LR=0.000100
[2025-08-27 13:25:12,936][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071184] [Batch 00344/03080] [00:04:15/00:33:54, 0.744s/it]: train_loss_raw=0.3772, running_loss=0.4042, LR=0.000100
[2025-08-27 13:25:18,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071192] [Batch 00352/03080] [00:04:21/00:33:49, 0.744s/it]: train_loss_raw=0.4584, running_loss=0.4034, LR=0.000100
[2025-08-27 13:25:25,144][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071200] [Batch 00360/03080] [00:04:28/00:33:45, 0.745s/it]: train_loss_raw=0.3941, running_loss=0.4020, LR=0.000100
[2025-08-27 13:25:31,198][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071208] [Batch 00368/03080] [00:04:34/00:33:40, 0.745s/it]: train_loss_raw=0.4477, running_loss=0.4013, LR=0.000100
[2025-08-27 13:25:37,179][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071216] [Batch 00376/03080] [00:04:40/00:33:34, 0.745s/it]: train_loss_raw=0.4014, running_loss=0.4007, LR=0.000100
[2025-08-27 13:25:43,200][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071224] [Batch 00384/03080] [00:04:46/00:33:28, 0.745s/it]: train_loss_raw=0.3423, running_loss=0.4009, LR=0.000100
[2025-08-27 13:25:49,216][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071232] [Batch 00392/03080] [00:04:52/00:33:23, 0.745s/it]: train_loss_raw=0.4343, running_loss=0.4030, LR=0.000100
[2025-08-27 13:25:55,237][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071240] [Batch 00400/03080] [00:04:58/00:33:17, 0.745s/it]: train_loss_raw=0.3620, running_loss=0.4017, LR=0.000100
[2025-08-27 13:26:01,314][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071248] [Batch 00408/03080] [00:05:04/00:33:12, 0.746s/it]: train_loss_raw=0.3671, running_loss=0.4009, LR=0.000100
[2025-08-27 13:26:07,302][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071256] [Batch 00416/03080] [00:05:10/00:33:06, 0.746s/it]: train_loss_raw=0.3922, running_loss=0.4012, LR=0.000100
[2025-08-27 13:26:13,279][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071264] [Batch 00424/03080] [00:05:16/00:33:00, 0.746s/it]: train_loss_raw=0.3516, running_loss=0.4006, LR=0.000100
[2025-08-27 13:26:19,139][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071272] [Batch 00432/03080] [00:05:22/00:32:54, 0.745s/it]: train_loss_raw=0.3800, running_loss=0.3986, LR=0.000100
[2025-08-27 13:26:24,713][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071280] [Batch 00440/03080] [00:05:27/00:32:45, 0.745s/it]: train_loss_raw=0.3758, running_loss=0.4003, LR=0.000100
[2025-08-27 13:26:30,138][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071288] [Batch 00448/03080] [00:05:33/00:32:36, 0.743s/it]: train_loss_raw=0.4095, running_loss=0.4007, LR=0.000100
[2025-08-27 13:26:36,175][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071296] [Batch 00456/03080] [00:05:39/00:32:31, 0.744s/it]: train_loss_raw=0.4374, running_loss=0.4002, LR=0.000100
[2025-08-27 13:26:42,240][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071304] [Batch 00464/03080] [00:05:45/00:32:25, 0.744s/it]: train_loss_raw=0.3572, running_loss=0.3997, LR=0.000100
[2025-08-27 13:26:48,204][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071312] [Batch 00472/03080] [00:05:51/00:32:20, 0.744s/it]: train_loss_raw=0.3197, running_loss=0.3988, LR=0.000100
[2025-08-27 13:26:54,209][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071320] [Batch 00480/03080] [00:05:57/00:32:14, 0.744s/it]: train_loss_raw=0.3508, running_loss=0.3982, LR=0.000100
[2025-08-27 13:27:00,225][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071328] [Batch 00488/03080] [00:06:03/00:32:08, 0.744s/it]: train_loss_raw=0.4295, running_loss=0.4007, LR=0.000100
[2025-08-27 13:27:06,217][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071336] [Batch 00496/03080] [00:06:09/00:32:03, 0.744s/it]: train_loss_raw=0.3313, running_loss=0.4014, LR=0.000100
[2025-08-27 13:27:12,194][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071344] [Batch 00504/03080] [00:06:15/00:31:57, 0.744s/it]: train_loss_raw=0.3635, running_loss=0.4001, LR=0.000100
[2025-08-27 13:27:18,185][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071352] [Batch 00512/03080] [00:06:21/00:31:51, 0.744s/it]: train_loss_raw=0.3746, running_loss=0.3988, LR=0.000100
[2025-08-27 13:27:24,247][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071360] [Batch 00520/03080] [00:06:27/00:31:45, 0.745s/it]: train_loss_raw=0.3050, running_loss=0.3990, LR=0.000100
[2025-08-27 13:27:30,238][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071368] [Batch 00528/03080] [00:06:33/00:31:40, 0.745s/it]: train_loss_raw=0.4435, running_loss=0.3972, LR=0.000100
[2025-08-27 13:27:36,218][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071376] [Batch 00536/03080] [00:06:39/00:31:34, 0.745s/it]: train_loss_raw=0.4148, running_loss=0.3991, LR=0.000100
[2025-08-27 13:27:42,196][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071384] [Batch 00544/03080] [00:06:45/00:31:28, 0.745s/it]: train_loss_raw=0.4313, running_loss=0.4002, LR=0.000100
[2025-08-27 13:27:48,342][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071392] [Batch 00552/03080] [00:06:51/00:31:23, 0.745s/it]: train_loss_raw=0.3978, running_loss=0.4009, LR=0.000100
[2025-08-27 13:27:54,448][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071400] [Batch 00560/03080] [00:06:57/00:31:18, 0.745s/it]: train_loss_raw=0.4266, running_loss=0.4023, LR=0.000100
[2025-08-27 13:28:00,475][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071408] [Batch 00568/03080] [00:07:03/00:31:12, 0.745s/it]: train_loss_raw=0.3516, running_loss=0.4000, LR=0.000100
[2025-08-27 13:28:06,509][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071416] [Batch 00576/03080] [00:07:09/00:31:06, 0.746s/it]: train_loss_raw=0.4470, running_loss=0.4001, LR=0.000100
[2025-08-27 13:28:12,513][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071424] [Batch 00584/03080] [00:07:15/00:31:00, 0.746s/it]: train_loss_raw=0.4298, running_loss=0.3984, LR=0.000100
[2025-08-27 13:28:18,555][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071432] [Batch 00592/03080] [00:07:21/00:30:55, 0.746s/it]: train_loss_raw=0.4579, running_loss=0.3998, LR=0.000100
[2025-08-27 13:28:24,567][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071440] [Batch 00600/03080] [00:07:27/00:30:49, 0.746s/it]: train_loss_raw=0.4397, running_loss=0.3997, LR=0.000100
[2025-08-27 13:28:30,568][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071448] [Batch 00608/03080] [00:07:33/00:30:43, 0.746s/it]: train_loss_raw=0.4603, running_loss=0.4006, LR=0.000100
[2025-08-27 13:28:36,604][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071456] [Batch 00616/03080] [00:07:39/00:30:38, 0.746s/it]: train_loss_raw=0.3359, running_loss=0.3994, LR=0.000100
[2025-08-27 13:28:42,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071464] [Batch 00624/03080] [00:07:45/00:30:31, 0.746s/it]: train_loss_raw=0.3787, running_loss=0.3989, LR=0.000100
[2025-08-27 13:28:48,370][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071472] [Batch 00632/03080] [00:07:51/00:30:25, 0.746s/it]: train_loss_raw=0.4108, running_loss=0.3979, LR=0.000100
[2025-08-27 13:28:54,484][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071480] [Batch 00640/03080] [00:07:57/00:30:20, 0.746s/it]: train_loss_raw=0.4816, running_loss=0.3982, LR=0.000100
[2025-08-27 13:29:00,537][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071488] [Batch 00648/03080] [00:08:03/00:30:14, 0.746s/it]: train_loss_raw=0.3709, running_loss=0.3976, LR=0.000100
[2025-08-27 13:29:06,613][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071496] [Batch 00656/03080] [00:08:09/00:30:08, 0.746s/it]: train_loss_raw=0.4333, running_loss=0.3991, LR=0.000100
[2025-08-27 13:29:12,662][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071504] [Batch 00664/03080] [00:08:15/00:30:03, 0.746s/it]: train_loss_raw=0.4478, running_loss=0.3966, LR=0.000100
[2025-08-27 13:29:18,714][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071512] [Batch 00672/03080] [00:08:21/00:29:57, 0.746s/it]: train_loss_raw=0.3985, running_loss=0.3965, LR=0.000100
[2025-08-27 13:29:24,820][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071520] [Batch 00680/03080] [00:08:27/00:29:51, 0.747s/it]: train_loss_raw=0.3717, running_loss=0.3982, LR=0.000100
[2025-08-27 13:29:30,812][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071528] [Batch 00688/03080] [00:08:33/00:29:46, 0.747s/it]: train_loss_raw=0.4005, running_loss=0.3975, LR=0.000100
[2025-08-27 13:29:36,902][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071536] [Batch 00696/03080] [00:08:39/00:29:40, 0.747s/it]: train_loss_raw=0.3612, running_loss=0.3987, LR=0.000100
[2025-08-27 13:29:42,885][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071544] [Batch 00704/03080] [00:08:45/00:29:34, 0.747s/it]: train_loss_raw=0.4683, running_loss=0.3990, LR=0.000100
[2025-08-27 13:29:48,950][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071552] [Batch 00712/03080] [00:08:51/00:29:28, 0.747s/it]: train_loss_raw=0.4145, running_loss=0.3997, LR=0.000100
[2025-08-27 13:29:54,983][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071560] [Batch 00720/03080] [00:08:57/00:29:23, 0.747s/it]: train_loss_raw=0.4846, running_loss=0.4018, LR=0.000100
[2025-08-27 13:30:01,041][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071568] [Batch 00728/03080] [00:09:03/00:29:17, 0.747s/it]: train_loss_raw=0.4721, running_loss=0.4019, LR=0.000100
[2025-08-27 13:30:07,072][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071576] [Batch 00736/03080] [00:09:09/00:29:11, 0.747s/it]: train_loss_raw=0.4056, running_loss=0.4014, LR=0.000100
[2025-08-27 13:30:13,098][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071584] [Batch 00744/03080] [00:09:16/00:29:05, 0.747s/it]: train_loss_raw=0.3569, running_loss=0.3996, LR=0.000100
[2025-08-27 13:30:19,208][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071592] [Batch 00752/03080] [00:09:22/00:29:00, 0.747s/it]: train_loss_raw=0.5041, running_loss=0.4023, LR=0.000100
[2025-08-27 13:30:25,226][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071600] [Batch 00760/03080] [00:09:28/00:28:54, 0.748s/it]: train_loss_raw=0.3357, running_loss=0.4005, LR=0.000100
[2025-08-27 13:30:31,302][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071608] [Batch 00768/03080] [00:09:34/00:28:48, 0.748s/it]: train_loss_raw=0.4236, running_loss=0.4000, LR=0.000100
[2025-08-27 13:30:37,316][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071616] [Batch 00776/03080] [00:09:40/00:28:42, 0.748s/it]: train_loss_raw=0.3310, running_loss=0.3983, LR=0.000100
[2025-08-27 13:30:43,320][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071624] [Batch 00784/03080] [00:09:46/00:28:36, 0.748s/it]: train_loss_raw=0.4539, running_loss=0.3979, LR=0.000100
[2025-08-27 13:30:49,538][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071632] [Batch 00792/03080] [00:09:52/00:28:31, 0.748s/it]: train_loss_raw=0.3570, running_loss=0.3976, LR=0.000100
[2025-08-27 13:30:55,569][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071640] [Batch 00800/03080] [00:09:58/00:28:25, 0.748s/it]: train_loss_raw=0.4513, running_loss=0.3975, LR=0.000100
[2025-08-27 13:31:01,559][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071648] [Batch 00808/03080] [00:10:04/00:28:19, 0.748s/it]: train_loss_raw=0.3950, running_loss=0.3958, LR=0.000100
[2025-08-27 13:31:07,653][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071656] [Batch 00816/03080] [00:10:10/00:28:14, 0.748s/it]: train_loss_raw=0.3851, running_loss=0.3960, LR=0.000100
[2025-08-27 13:31:13,707][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071664] [Batch 00824/03080] [00:10:16/00:28:08, 0.748s/it]: train_loss_raw=0.3478, running_loss=0.3958, LR=0.000100
[2025-08-27 13:31:19,730][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071672] [Batch 00832/03080] [00:10:22/00:28:02, 0.748s/it]: train_loss_raw=0.4439, running_loss=0.4006, LR=0.000100
[2025-08-27 13:31:25,855][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071680] [Batch 00840/03080] [00:10:28/00:27:56, 0.749s/it]: train_loss_raw=0.4104, running_loss=0.4017, LR=0.000100
[2025-08-27 13:31:32,063][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071688] [Batch 00848/03080] [00:10:34/00:27:51, 0.749s/it]: train_loss_raw=0.4165, running_loss=0.4036, LR=0.000100
[2025-08-27 13:31:38,097][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071696] [Batch 00856/03080] [00:10:41/00:27:45, 0.749s/it]: train_loss_raw=0.3874, running_loss=0.4042, LR=0.000100
[2025-08-27 13:31:44,192][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071704] [Batch 00864/03080] [00:10:47/00:27:39, 0.749s/it]: train_loss_raw=0.3938, running_loss=0.4041, LR=0.000100
[2025-08-27 13:31:50,262][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071712] [Batch 00872/03080] [00:10:53/00:27:33, 0.749s/it]: train_loss_raw=0.3428, running_loss=0.4034, LR=0.000100
[2025-08-27 13:31:56,296][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071720] [Batch 00880/03080] [00:10:59/00:27:28, 0.749s/it]: train_loss_raw=0.4067, running_loss=0.4037, LR=0.000100
[2025-08-27 13:32:01,886][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071728] [Batch 00888/03080] [00:11:04/00:27:21, 0.749s/it]: train_loss_raw=0.4609, running_loss=0.4032, LR=0.000100
[2025-08-27 13:32:08,094][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071736] [Batch 00896/03080] [00:11:11/00:27:15, 0.749s/it]: train_loss_raw=0.4021, running_loss=0.4040, LR=0.000100
[2025-08-27 13:32:14,100][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071744] [Batch 00904/03080] [00:11:17/00:27:09, 0.749s/it]: train_loss_raw=0.4495, running_loss=0.4031, LR=0.000100
[2025-08-27 13:32:20,194][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071752] [Batch 00912/03080] [00:11:23/00:27:03, 0.749s/it]: train_loss_raw=0.4098, running_loss=0.4037, LR=0.000100
[2025-08-27 13:32:26,257][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071760] [Batch 00920/03080] [00:11:29/00:26:58, 0.749s/it]: train_loss_raw=0.3460, running_loss=0.4015, LR=0.000100
[2025-08-27 13:32:32,307][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071768] [Batch 00928/03080] [00:11:35/00:26:52, 0.749s/it]: train_loss_raw=0.3408, running_loss=0.3998, LR=0.000100
[2025-08-27 13:32:38,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071776] [Batch 00936/03080] [00:11:41/00:26:46, 0.749s/it]: train_loss_raw=0.4130, running_loss=0.4010, LR=0.000100
[2025-08-27 13:32:44,551][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071784] [Batch 00944/03080] [00:11:47/00:26:40, 0.749s/it]: train_loss_raw=0.3891, running_loss=0.4007, LR=0.000100
[2025-08-27 13:32:50,636][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071792] [Batch 00952/03080] [00:11:53/00:26:34, 0.750s/it]: train_loss_raw=0.3204, running_loss=0.3990, LR=0.000100
[2025-08-27 13:32:56,734][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071800] [Batch 00960/03080] [00:11:59/00:26:29, 0.750s/it]: train_loss_raw=0.4816, running_loss=0.3989, LR=0.000100
[2025-08-27 13:33:02,810][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071808] [Batch 00968/03080] [00:12:05/00:26:23, 0.750s/it]: train_loss_raw=0.3978, running_loss=0.3994, LR=0.000100
[2025-08-27 13:33:08,842][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071816] [Batch 00976/03080] [00:12:11/00:26:17, 0.750s/it]: train_loss_raw=0.3716, running_loss=0.3981, LR=0.000100
[2025-08-27 13:33:15,091][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071824] [Batch 00984/03080] [00:12:17/00:26:11, 0.750s/it]: train_loss_raw=0.4031, running_loss=0.3995, LR=0.000100
[2025-08-27 13:33:21,277][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071832] [Batch 00992/03080] [00:12:24/00:26:06, 0.750s/it]: train_loss_raw=0.4085, running_loss=0.4018, LR=0.000100
[2025-08-27 13:33:27,368][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071840] [Batch 01000/03080] [00:12:30/00:26:00, 0.750s/it]: train_loss_raw=0.5700, running_loss=0.4053, LR=0.000100
[2025-08-27 13:33:33,494][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071848] [Batch 01008/03080] [00:12:36/00:25:54, 0.750s/it]: train_loss_raw=0.4271, running_loss=0.4026, LR=0.000100
[2025-08-27 13:33:39,338][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071856] [Batch 01016/03080] [00:12:42/00:25:48, 0.750s/it]: train_loss_raw=0.4328, running_loss=0.4048, LR=0.000100
[2025-08-27 13:33:44,841][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071864] [Batch 01024/03080] [00:12:47/00:25:41, 0.750s/it]: train_loss_raw=0.3853, running_loss=0.4045, LR=0.000100
[2025-08-27 13:33:50,530][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071872] [Batch 01032/03080] [00:12:53/00:25:34, 0.749s/it]: train_loss_raw=0.3638, running_loss=0.4035, LR=0.000100
[2025-08-27 13:33:56,581][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071880] [Batch 01040/03080] [00:12:59/00:25:28, 0.750s/it]: train_loss_raw=0.4506, running_loss=0.4013, LR=0.000100
[2025-08-27 13:34:02,582][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071888] [Batch 01048/03080] [00:13:05/00:25:23, 0.750s/it]: train_loss_raw=0.4301, running_loss=0.4029, LR=0.000100
[2025-08-27 13:34:08,623][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071896] [Batch 01056/03080] [00:13:11/00:25:17, 0.750s/it]: train_loss_raw=0.4539, running_loss=0.4035, LR=0.000100
[2025-08-27 13:34:14,439][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071904] [Batch 01064/03080] [00:13:17/00:25:10, 0.749s/it]: train_loss_raw=0.3574, running_loss=0.4033, LR=0.000100
[2025-08-27 13:34:20,500][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071912] [Batch 01072/03080] [00:13:23/00:25:04, 0.749s/it]: train_loss_raw=0.3882, running_loss=0.4004, LR=0.000100
[2025-08-27 13:34:26,549][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071920] [Batch 01080/03080] [00:13:29/00:24:58, 0.749s/it]: train_loss_raw=0.3610, running_loss=0.3981, LR=0.000100
[2025-08-27 13:34:32,546][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071928] [Batch 01088/03080] [00:13:35/00:24:52, 0.749s/it]: train_loss_raw=0.3991, running_loss=0.3973, LR=0.000100
[2025-08-27 13:34:38,610][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071936] [Batch 01096/03080] [00:13:41/00:24:47, 0.750s/it]: train_loss_raw=0.3458, running_loss=0.3977, LR=0.000100
[2025-08-27 13:34:44,638][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071944] [Batch 01104/03080] [00:13:47/00:24:41, 0.750s/it]: train_loss_raw=0.4526, running_loss=0.3977, LR=0.000100
[2025-08-27 13:34:50,665][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071952] [Batch 01112/03080] [00:13:53/00:24:35, 0.750s/it]: train_loss_raw=0.3284, running_loss=0.3977, LR=0.000100
[2025-08-27 13:34:56,738][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071960] [Batch 01120/03080] [00:13:59/00:24:29, 0.750s/it]: train_loss_raw=0.3085, running_loss=0.3978, LR=0.000100
[2025-08-27 13:35:02,838][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071968] [Batch 01128/03080] [00:14:05/00:24:23, 0.750s/it]: train_loss_raw=0.4371, running_loss=0.3965, LR=0.000100
[2025-08-27 13:35:08,851][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071976] [Batch 01136/03080] [00:14:11/00:24:17, 0.750s/it]: train_loss_raw=0.4439, running_loss=0.3983, LR=0.000100
[2025-08-27 13:35:14,947][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071984] [Batch 01144/03080] [00:14:17/00:24:11, 0.750s/it]: train_loss_raw=0.3634, running_loss=0.3969, LR=0.000100
[2025-08-27 13:35:21,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 071992] [Batch 01152/03080] [00:14:24/00:24:06, 0.750s/it]: train_loss_raw=0.4292, running_loss=0.3972, LR=0.000100
[2025-08-27 13:35:26,683][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072000] [Batch 01160/03080] [00:14:29/00:23:59, 0.750s/it]: train_loss_raw=0.3597, running_loss=0.3965, LR=0.000100
[2025-08-27 13:35:36,593][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072008] [Batch 01168/03080] [00:14:39/00:23:59, 0.753s/it]: train_loss_raw=0.4192, running_loss=0.3958, LR=0.000100
[2025-08-27 13:35:42,653][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072016] [Batch 01176/03080] [00:14:45/00:23:53, 0.753s/it]: train_loss_raw=0.3995, running_loss=0.3959, LR=0.000100
[2025-08-27 13:35:48,739][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072024] [Batch 01184/03080] [00:14:51/00:23:47, 0.753s/it]: train_loss_raw=0.4235, running_loss=0.3973, LR=0.000100
[2025-08-27 13:35:54,781][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072032] [Batch 01192/03080] [00:14:57/00:23:41, 0.753s/it]: train_loss_raw=0.4358, running_loss=0.3994, LR=0.000100
[2025-08-27 13:36:00,869][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072040] [Batch 01200/03080] [00:15:03/00:23:35, 0.753s/it]: train_loss_raw=0.4144, running_loss=0.4011, LR=0.000100
[2025-08-27 13:36:06,924][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072048] [Batch 01208/03080] [00:15:09/00:23:29, 0.753s/it]: train_loss_raw=0.4368, running_loss=0.4008, LR=0.000100
[2025-08-27 13:36:12,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072056] [Batch 01216/03080] [00:15:15/00:23:23, 0.753s/it]: train_loss_raw=0.2946, running_loss=0.4011, LR=0.000100
[2025-08-27 13:36:19,066][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072064] [Batch 01224/03080] [00:15:21/00:23:18, 0.753s/it]: train_loss_raw=0.3345, running_loss=0.4002, LR=0.000100
[2025-08-27 13:36:25,055][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072072] [Batch 01232/03080] [00:15:27/00:23:11, 0.753s/it]: train_loss_raw=0.4116, running_loss=0.4016, LR=0.000100
[2025-08-27 13:36:31,085][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072080] [Batch 01240/03080] [00:15:33/00:23:05, 0.753s/it]: train_loss_raw=0.4587, running_loss=0.4022, LR=0.000100
[2025-08-27 13:36:37,194][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072088] [Batch 01248/03080] [00:15:40/00:23:00, 0.753s/it]: train_loss_raw=0.4068, running_loss=0.4031, LR=0.000100
[2025-08-27 13:36:43,197][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072096] [Batch 01256/03080] [00:15:46/00:22:53, 0.753s/it]: train_loss_raw=0.3859, running_loss=0.4026, LR=0.000100
[2025-08-27 13:36:49,196][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072104] [Batch 01264/03080] [00:15:52/00:22:47, 0.753s/it]: train_loss_raw=0.3864, running_loss=0.4028, LR=0.000100
[2025-08-27 13:36:55,262][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072112] [Batch 01272/03080] [00:15:58/00:22:41, 0.753s/it]: train_loss_raw=0.4201, running_loss=0.4016, LR=0.000100
[2025-08-27 13:37:01,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072120] [Batch 01280/03080] [00:16:04/00:22:35, 0.753s/it]: train_loss_raw=0.4077, running_loss=0.4026, LR=0.000100
[2025-08-27 13:37:07,423][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072128] [Batch 01288/03080] [00:16:10/00:22:30, 0.753s/it]: train_loss_raw=0.3920, running_loss=0.4026, LR=0.000100
[2025-08-27 13:37:13,424][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072136] [Batch 01296/03080] [00:16:16/00:22:23, 0.753s/it]: train_loss_raw=0.4643, running_loss=0.4012, LR=0.000100
[2025-08-27 13:37:19,439][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072144] [Batch 01304/03080] [00:16:22/00:22:17, 0.753s/it]: train_loss_raw=0.3753, running_loss=0.3999, LR=0.000100
[2025-08-27 13:37:25,222][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072152] [Batch 01312/03080] [00:16:28/00:22:11, 0.753s/it]: train_loss_raw=0.4325, running_loss=0.4001, LR=0.000100
[2025-08-27 13:37:30,838][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072160] [Batch 01320/03080] [00:16:33/00:22:04, 0.753s/it]: train_loss_raw=0.4500, running_loss=0.4003, LR=0.000100
[2025-08-27 13:37:36,751][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072168] [Batch 01328/03080] [00:16:39/00:21:58, 0.753s/it]: train_loss_raw=0.4691, running_loss=0.4008, LR=0.000100
[2025-08-27 13:37:42,785][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072176] [Batch 01336/03080] [00:16:45/00:21:52, 0.753s/it]: train_loss_raw=0.3396, running_loss=0.3993, LR=0.000100
[2025-08-27 13:37:48,681][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072184] [Batch 01344/03080] [00:16:51/00:21:46, 0.753s/it]: train_loss_raw=0.4033, running_loss=0.3999, LR=0.000100
[2025-08-27 13:37:54,133][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072192] [Batch 01352/03080] [00:16:57/00:21:39, 0.752s/it]: train_loss_raw=0.3126, running_loss=0.3989, LR=0.000100
[2025-08-27 13:37:59,631][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072200] [Batch 01360/03080] [00:17:02/00:21:33, 0.752s/it]: train_loss_raw=0.3699, running_loss=0.3994, LR=0.000100
[2025-08-27 13:38:05,283][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072208] [Batch 01368/03080] [00:17:08/00:21:26, 0.752s/it]: train_loss_raw=0.3784, running_loss=0.4004, LR=0.000100
[2025-08-27 13:38:11,179][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072216] [Batch 01376/03080] [00:17:14/00:21:20, 0.752s/it]: train_loss_raw=0.3585, running_loss=0.3971, LR=0.000100
[2025-08-27 13:38:17,199][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072224] [Batch 01384/03080] [00:17:20/00:21:14, 0.752s/it]: train_loss_raw=0.4417, running_loss=0.3975, LR=0.000100
[2025-08-27 13:38:23,182][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072232] [Batch 01392/03080] [00:17:26/00:21:08, 0.752s/it]: train_loss_raw=0.3395, running_loss=0.3984, LR=0.000100
[2025-08-27 13:38:28,718][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072240] [Batch 01400/03080] [00:17:31/00:21:01, 0.751s/it]: train_loss_raw=0.4734, running_loss=0.3964, LR=0.000100
[2025-08-27 13:38:34,173][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072248] [Batch 01408/03080] [00:17:37/00:20:55, 0.751s/it]: train_loss_raw=0.3732, running_loss=0.3962, LR=0.000100
[2025-08-27 13:38:39,629][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072256] [Batch 01416/03080] [00:17:42/00:20:48, 0.750s/it]: train_loss_raw=0.3431, running_loss=0.3955, LR=0.000100
[2025-08-27 13:38:45,178][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072264] [Batch 01424/03080] [00:17:48/00:20:42, 0.750s/it]: train_loss_raw=0.4944, running_loss=0.3969, LR=0.000100
[2025-08-27 13:38:51,250][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072272] [Batch 01432/03080] [00:17:54/00:20:36, 0.750s/it]: train_loss_raw=0.4403, running_loss=0.4003, LR=0.000100
[2025-08-27 13:38:57,337][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072280] [Batch 01440/03080] [00:18:00/00:20:30, 0.750s/it]: train_loss_raw=0.4699, running_loss=0.3992, LR=0.000100
[2025-08-27 13:39:03,505][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072288] [Batch 01448/03080] [00:18:06/00:20:24, 0.750s/it]: train_loss_raw=0.4387, running_loss=0.4008, LR=0.000100
[2025-08-27 13:39:09,757][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072296] [Batch 01456/03080] [00:18:12/00:20:18, 0.750s/it]: train_loss_raw=0.3083, running_loss=0.4001, LR=0.000100
[2025-08-27 13:39:15,805][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072304] [Batch 01464/03080] [00:18:18/00:20:12, 0.750s/it]: train_loss_raw=0.4048, running_loss=0.4000, LR=0.000100
[2025-08-27 13:39:21,790][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072312] [Batch 01472/03080] [00:18:24/00:20:06, 0.750s/it]: train_loss_raw=0.3329, running_loss=0.4001, LR=0.000100
[2025-08-27 13:39:27,190][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072320] [Batch 01480/03080] [00:18:30/00:20:00, 0.750s/it]: train_loss_raw=0.4540, running_loss=0.3998, LR=0.000100
[2025-08-27 13:39:32,601][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072328] [Batch 01488/03080] [00:18:35/00:19:53, 0.750s/it]: train_loss_raw=0.4047, running_loss=0.4001, LR=0.000100
[2025-08-27 13:39:38,007][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072336] [Batch 01496/03080] [00:18:40/00:19:46, 0.749s/it]: train_loss_raw=0.4793, running_loss=0.4007, LR=0.000100
[2025-08-27 13:39:43,592][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072344] [Batch 01504/03080] [00:18:46/00:19:40, 0.749s/it]: train_loss_raw=0.4572, running_loss=0.4008, LR=0.000100
[2025-08-27 13:39:49,624][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072352] [Batch 01512/03080] [00:18:52/00:19:34, 0.749s/it]: train_loss_raw=0.4096, running_loss=0.4012, LR=0.000100
[2025-08-27 13:39:55,536][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072360] [Batch 01520/03080] [00:18:58/00:19:28, 0.749s/it]: train_loss_raw=0.3538, running_loss=0.3989, LR=0.000100
[2025-08-27 13:40:01,664][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072368] [Batch 01528/03080] [00:19:04/00:19:22, 0.749s/it]: train_loss_raw=0.3710, running_loss=0.3961, LR=0.000100
[2025-08-27 13:40:07,731][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072376] [Batch 01536/03080] [00:19:10/00:19:16, 0.749s/it]: train_loss_raw=0.3069, running_loss=0.3953, LR=0.000100
[2025-08-27 13:40:13,776][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072384] [Batch 01544/03080] [00:19:16/00:19:10, 0.749s/it]: train_loss_raw=0.3830, running_loss=0.3949, LR=0.000100
[2025-08-27 13:40:19,797][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072392] [Batch 01552/03080] [00:19:22/00:19:04, 0.749s/it]: train_loss_raw=0.4256, running_loss=0.3955, LR=0.000100
[2025-08-27 13:40:25,956][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072400] [Batch 01560/03080] [00:19:28/00:18:58, 0.749s/it]: train_loss_raw=0.4014, running_loss=0.3952, LR=0.000100
[2025-08-27 13:40:31,964][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072408] [Batch 01568/03080] [00:19:34/00:18:52, 0.749s/it]: train_loss_raw=0.4424, running_loss=0.3952, LR=0.000100
[2025-08-27 13:40:38,005][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072416] [Batch 01576/03080] [00:19:40/00:18:46, 0.749s/it]: train_loss_raw=0.3882, running_loss=0.3934, LR=0.000100
[2025-08-27 13:40:43,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072424] [Batch 01584/03080] [00:19:46/00:18:40, 0.749s/it]: train_loss_raw=0.3350, running_loss=0.3908, LR=0.000100
[2025-08-27 13:40:49,610][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072432] [Batch 01592/03080] [00:19:52/00:18:34, 0.749s/it]: train_loss_raw=0.3307, running_loss=0.3918, LR=0.000100
[2025-08-27 13:40:55,728][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072440] [Batch 01600/03080] [00:19:58/00:18:28, 0.749s/it]: train_loss_raw=0.3705, running_loss=0.3925, LR=0.000100
[2025-08-27 13:41:01,715][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072448] [Batch 01608/03080] [00:20:04/00:18:22, 0.749s/it]: train_loss_raw=0.4621, running_loss=0.3945, LR=0.000100
[2025-08-27 13:41:07,698][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072456] [Batch 01616/03080] [00:20:10/00:18:16, 0.749s/it]: train_loss_raw=0.4016, running_loss=0.3957, LR=0.000100
[2025-08-27 13:41:13,674][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072464] [Batch 01624/03080] [00:20:16/00:18:10, 0.749s/it]: train_loss_raw=0.3903, running_loss=0.3928, LR=0.000100
[2025-08-27 13:41:19,625][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072472] [Batch 01632/03080] [00:20:22/00:18:04, 0.749s/it]: train_loss_raw=0.4048, running_loss=0.3925, LR=0.000100
[2025-08-27 13:41:25,215][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072480] [Batch 01640/03080] [00:20:28/00:17:58, 0.749s/it]: train_loss_raw=0.5964, running_loss=0.3959, LR=0.000100
[2025-08-27 13:41:30,658][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072488] [Batch 01648/03080] [00:20:33/00:17:51, 0.749s/it]: train_loss_raw=0.4529, running_loss=0.3973, LR=0.000100
[2025-08-27 13:41:36,226][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072496] [Batch 01656/03080] [00:20:39/00:17:45, 0.748s/it]: train_loss_raw=0.3820, running_loss=0.3979, LR=0.000100
[2025-08-27 13:41:42,296][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072504] [Batch 01664/03080] [00:20:45/00:17:39, 0.748s/it]: train_loss_raw=0.3704, running_loss=0.3983, LR=0.000100
[2025-08-27 13:41:48,297][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072512] [Batch 01672/03080] [00:20:51/00:17:33, 0.748s/it]: train_loss_raw=0.4869, running_loss=0.4002, LR=0.000100
[2025-08-27 13:41:54,359][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072520] [Batch 01680/03080] [00:20:57/00:17:27, 0.748s/it]: train_loss_raw=0.4390, running_loss=0.3999, LR=0.000100
[2025-08-27 13:42:00,389][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072528] [Batch 01688/03080] [00:21:03/00:17:21, 0.748s/it]: train_loss_raw=0.3851, running_loss=0.3992, LR=0.000100
[2025-08-27 13:42:06,526][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072536] [Batch 01696/03080] [00:21:09/00:17:15, 0.748s/it]: train_loss_raw=0.3815, running_loss=0.4003, LR=0.000100
[2025-08-27 13:42:12,717][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072544] [Batch 01704/03080] [00:21:15/00:17:10, 0.749s/it]: train_loss_raw=0.3913, running_loss=0.4001, LR=0.000100
[2025-08-27 13:42:18,795][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072552] [Batch 01712/03080] [00:21:21/00:17:04, 0.749s/it]: train_loss_raw=0.3712, running_loss=0.4011, LR=0.000100
[2025-08-27 13:42:24,893][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072560] [Batch 01720/03080] [00:21:27/00:16:58, 0.749s/it]: train_loss_raw=0.4105, running_loss=0.4012, LR=0.000100
[2025-08-27 13:42:30,976][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072568] [Batch 01728/03080] [00:21:33/00:16:52, 0.749s/it]: train_loss_raw=0.3937, running_loss=0.4021, LR=0.000100
[2025-08-27 13:42:37,097][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072576] [Batch 01736/03080] [00:21:40/00:16:46, 0.749s/it]: train_loss_raw=0.4130, running_loss=0.3996, LR=0.000100
[2025-08-27 13:42:43,227][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072584] [Batch 01744/03080] [00:21:46/00:16:40, 0.749s/it]: train_loss_raw=0.3919, running_loss=0.3998, LR=0.000100
[2025-08-27 13:42:49,374][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072592] [Batch 01752/03080] [00:21:52/00:16:34, 0.749s/it]: train_loss_raw=0.4240, running_loss=0.3993, LR=0.000100
[2025-08-27 13:42:54,821][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072600] [Batch 01760/03080] [00:21:57/00:16:28, 0.749s/it]: train_loss_raw=0.3428, running_loss=0.3969, LR=0.000100
[2025-08-27 13:43:00,789][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072608] [Batch 01768/03080] [00:22:03/00:16:22, 0.749s/it]: train_loss_raw=0.4273, running_loss=0.3957, LR=0.000100
[2025-08-27 13:43:06,965][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072616] [Batch 01776/03080] [00:22:09/00:16:16, 0.749s/it]: train_loss_raw=0.3676, running_loss=0.3944, LR=0.000100
[2025-08-27 13:43:13,116][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072624] [Batch 01784/03080] [00:22:16/00:16:10, 0.749s/it]: train_loss_raw=0.3397, running_loss=0.3931, LR=0.000100
[2025-08-27 13:43:19,182][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072632] [Batch 01792/03080] [00:22:22/00:16:04, 0.749s/it]: train_loss_raw=0.4062, running_loss=0.3929, LR=0.000100
[2025-08-27 13:43:25,211][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072640] [Batch 01800/03080] [00:22:28/00:15:58, 0.749s/it]: train_loss_raw=0.4182, running_loss=0.3911, LR=0.000100
[2025-08-27 13:43:31,223][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072648] [Batch 01808/03080] [00:22:34/00:15:52, 0.749s/it]: train_loss_raw=0.3878, running_loss=0.3886, LR=0.000100
[2025-08-27 13:43:37,115][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072656] [Batch 01816/03080] [00:22:40/00:15:46, 0.749s/it]: train_loss_raw=0.3668, running_loss=0.3889, LR=0.000100
[2025-08-27 13:43:43,173][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072664] [Batch 01824/03080] [00:22:46/00:15:40, 0.749s/it]: train_loss_raw=0.2771, running_loss=0.3901, LR=0.000100
[2025-08-27 13:43:49,244][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072672] [Batch 01832/03080] [00:22:52/00:15:34, 0.749s/it]: train_loss_raw=0.4541, running_loss=0.3910, LR=0.000100
[2025-08-27 13:43:55,315][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072680] [Batch 01840/03080] [00:22:58/00:15:28, 0.749s/it]: train_loss_raw=0.3613, running_loss=0.3904, LR=0.000100
[2025-08-27 13:44:01,463][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072688] [Batch 01848/03080] [00:23:04/00:15:22, 0.749s/it]: train_loss_raw=0.4555, running_loss=0.3932, LR=0.000100
[2025-08-27 13:44:07,513][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072696] [Batch 01856/03080] [00:23:10/00:15:16, 0.749s/it]: train_loss_raw=0.3866, running_loss=0.3946, LR=0.000100
[2025-08-27 13:44:13,578][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072704] [Batch 01864/03080] [00:23:16/00:15:11, 0.749s/it]: train_loss_raw=0.4034, running_loss=0.3928, LR=0.000100
[2025-08-27 13:44:19,720][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072712] [Batch 01872/03080] [00:23:22/00:15:05, 0.749s/it]: train_loss_raw=0.4052, running_loss=0.3906, LR=0.000100
[2025-08-27 13:44:25,830][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072720] [Batch 01880/03080] [00:23:28/00:14:59, 0.749s/it]: train_loss_raw=0.4038, running_loss=0.3906, LR=0.000100
[2025-08-27 13:44:31,917][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072728] [Batch 01888/03080] [00:23:34/00:14:53, 0.749s/it]: train_loss_raw=0.3499, running_loss=0.3915, LR=0.000100
[2025-08-27 13:44:38,032][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072736] [Batch 01896/03080] [00:23:40/00:14:47, 0.749s/it]: train_loss_raw=0.4068, running_loss=0.3928, LR=0.000100
[2025-08-27 13:44:44,125][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072744] [Batch 01904/03080] [00:23:47/00:14:41, 0.749s/it]: train_loss_raw=0.4104, running_loss=0.3935, LR=0.000100
[2025-08-27 13:44:50,211][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072752] [Batch 01912/03080] [00:23:53/00:14:35, 0.750s/it]: train_loss_raw=0.5107, running_loss=0.3952, LR=0.000100
[2025-08-27 13:44:56,249][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072760] [Batch 01920/03080] [00:23:59/00:14:29, 0.750s/it]: train_loss_raw=0.4087, running_loss=0.3953, LR=0.000100
[2025-08-27 13:45:02,172][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072768] [Batch 01928/03080] [00:24:05/00:14:23, 0.750s/it]: train_loss_raw=0.3470, running_loss=0.3941, LR=0.000100
[2025-08-27 13:45:07,922][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072776] [Batch 01936/03080] [00:24:10/00:14:17, 0.749s/it]: train_loss_raw=0.4499, running_loss=0.3933, LR=0.000100
[2025-08-27 13:45:13,949][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072784] [Batch 01944/03080] [00:24:16/00:14:11, 0.749s/it]: train_loss_raw=0.3431, running_loss=0.3914, LR=0.000100
[2025-08-27 13:45:19,843][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072792] [Batch 01952/03080] [00:24:22/00:14:05, 0.749s/it]: train_loss_raw=0.4508, running_loss=0.3930, LR=0.000100
[2025-08-27 13:45:25,948][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072800] [Batch 01960/03080] [00:24:28/00:13:59, 0.749s/it]: train_loss_raw=0.4401, running_loss=0.3927, LR=0.000100
[2025-08-27 13:45:32,026][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072808] [Batch 01968/03080] [00:24:34/00:13:53, 0.749s/it]: train_loss_raw=0.4107, running_loss=0.3922, LR=0.000100
[2025-08-27 13:45:38,049][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072816] [Batch 01976/03080] [00:24:40/00:13:47, 0.749s/it]: train_loss_raw=0.3827, running_loss=0.3915, LR=0.000100
[2025-08-27 13:45:44,077][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072824] [Batch 01984/03080] [00:24:46/00:13:41, 0.749s/it]: train_loss_raw=0.4196, running_loss=0.3919, LR=0.000100
[2025-08-27 13:45:50,185][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072832] [Batch 01992/03080] [00:24:53/00:13:35, 0.750s/it]: train_loss_raw=0.4125, running_loss=0.3924, LR=0.000100
[2025-08-27 13:45:56,335][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072840] [Batch 02000/03080] [00:24:59/00:13:29, 0.750s/it]: train_loss_raw=0.4832, running_loss=0.3950, LR=0.000100
[2025-08-27 13:46:02,348][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072848] [Batch 02008/03080] [00:25:05/00:13:23, 0.750s/it]: train_loss_raw=0.3818, running_loss=0.3951, LR=0.000100
[2025-08-27 13:46:08,425][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072856] [Batch 02016/03080] [00:25:11/00:13:17, 0.750s/it]: train_loss_raw=0.4759, running_loss=0.3943, LR=0.000100
[2025-08-27 13:46:14,493][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072864] [Batch 02024/03080] [00:25:17/00:13:11, 0.750s/it]: train_loss_raw=0.3786, running_loss=0.3989, LR=0.000100
[2025-08-27 13:46:20,552][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072872] [Batch 02032/03080] [00:25:23/00:13:05, 0.750s/it]: train_loss_raw=0.4071, running_loss=0.3994, LR=0.000100
[2025-08-27 13:46:26,618][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072880] [Batch 02040/03080] [00:25:29/00:12:59, 0.750s/it]: train_loss_raw=0.3703, running_loss=0.3978, LR=0.000100
[2025-08-27 13:46:32,668][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072888] [Batch 02048/03080] [00:25:35/00:12:53, 0.750s/it]: train_loss_raw=0.3883, running_loss=0.3988, LR=0.000100
[2025-08-27 13:46:38,715][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072896] [Batch 02056/03080] [00:25:41/00:12:47, 0.750s/it]: train_loss_raw=0.4536, running_loss=0.4018, LR=0.000100
[2025-08-27 13:46:44,739][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072904] [Batch 02064/03080] [00:25:47/00:12:41, 0.750s/it]: train_loss_raw=0.4121, running_loss=0.4003, LR=0.000100
[2025-08-27 13:46:50,925][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072912] [Batch 02072/03080] [00:25:53/00:12:35, 0.750s/it]: train_loss_raw=0.3896, running_loss=0.4006, LR=0.000100
[2025-08-27 13:46:56,934][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072920] [Batch 02080/03080] [00:25:59/00:12:29, 0.750s/it]: train_loss_raw=0.3877, running_loss=0.4015, LR=0.000100
[2025-08-27 13:47:03,032][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072928] [Batch 02088/03080] [00:26:05/00:12:23, 0.750s/it]: train_loss_raw=0.3549, running_loss=0.4012, LR=0.000100
[2025-08-27 13:47:09,099][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072936] [Batch 02096/03080] [00:26:12/00:12:18, 0.750s/it]: train_loss_raw=0.4569, running_loss=0.4017, LR=0.000100
[2025-08-27 13:47:15,162][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072944] [Batch 02104/03080] [00:26:18/00:12:12, 0.750s/it]: train_loss_raw=0.3870, running_loss=0.4006, LR=0.000100
[2025-08-27 13:47:21,338][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072952] [Batch 02112/03080] [00:26:24/00:12:06, 0.750s/it]: train_loss_raw=0.3902, running_loss=0.4010, LR=0.000100
[2025-08-27 13:47:27,510][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072960] [Batch 02120/03080] [00:26:30/00:12:00, 0.750s/it]: train_loss_raw=0.4084, running_loss=0.3995, LR=0.000100
[2025-08-27 13:47:33,615][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072968] [Batch 02128/03080] [00:26:36/00:11:54, 0.750s/it]: train_loss_raw=0.4737, running_loss=0.3999, LR=0.000100
[2025-08-27 13:47:39,757][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072976] [Batch 02136/03080] [00:26:42/00:11:48, 0.750s/it]: train_loss_raw=0.3774, running_loss=0.3997, LR=0.000100
[2025-08-27 13:47:45,772][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072984] [Batch 02144/03080] [00:26:48/00:11:42, 0.750s/it]: train_loss_raw=0.3686, running_loss=0.3978, LR=0.000100
[2025-08-27 13:47:51,981][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 072992] [Batch 02152/03080] [00:26:54/00:11:36, 0.750s/it]: train_loss_raw=0.3457, running_loss=0.3980, LR=0.000100
[2025-08-27 13:47:58,330][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073000] [Batch 02160/03080] [00:27:01/00:11:30, 0.751s/it]: train_loss_raw=0.3246, running_loss=0.3984, LR=0.000100
[2025-08-27 13:48:04,384][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073008] [Batch 02168/03080] [00:27:07/00:11:24, 0.751s/it]: train_loss_raw=0.4133, running_loss=0.3984, LR=0.000100
[2025-08-27 13:48:10,551][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073016] [Batch 02176/03080] [00:27:13/00:11:18, 0.751s/it]: train_loss_raw=0.4459, running_loss=0.3974, LR=0.000100
[2025-08-27 13:48:16,594][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073024] [Batch 02184/03080] [00:27:19/00:11:12, 0.751s/it]: train_loss_raw=0.4780, running_loss=0.3964, LR=0.000100
[2025-08-27 13:48:22,614][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073032] [Batch 02192/03080] [00:27:25/00:11:06, 0.751s/it]: train_loss_raw=0.4153, running_loss=0.3961, LR=0.000100
[2025-08-27 13:48:28,661][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073040] [Batch 02200/03080] [00:27:31/00:11:00, 0.751s/it]: train_loss_raw=0.3700, running_loss=0.3943, LR=0.000100
[2025-08-27 13:48:34,711][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073048] [Batch 02208/03080] [00:27:37/00:10:54, 0.751s/it]: train_loss_raw=0.4374, running_loss=0.3938, LR=0.000100
[2025-08-27 13:48:40,762][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073056] [Batch 02216/03080] [00:27:43/00:10:48, 0.751s/it]: train_loss_raw=0.3949, running_loss=0.3958, LR=0.000100
[2025-08-27 13:48:46,639][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073064] [Batch 02224/03080] [00:27:49/00:10:42, 0.751s/it]: train_loss_raw=0.4973, running_loss=0.3961, LR=0.000100
[2025-08-27 13:48:52,684][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073072] [Batch 02232/03080] [00:27:55/00:10:36, 0.751s/it]: train_loss_raw=0.3789, running_loss=0.3966, LR=0.000100
[2025-08-27 13:48:58,718][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073080] [Batch 02240/03080] [00:28:01/00:10:30, 0.751s/it]: train_loss_raw=0.3397, running_loss=0.3963, LR=0.000100
[2025-08-27 13:49:04,831][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073088] [Batch 02248/03080] [00:28:07/00:10:24, 0.751s/it]: train_loss_raw=0.3696, running_loss=0.3981, LR=0.000100
[2025-08-27 13:49:10,854][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073096] [Batch 02256/03080] [00:28:13/00:10:18, 0.751s/it]: train_loss_raw=0.4027, running_loss=0.3982, LR=0.000100
[2025-08-27 13:49:16,833][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073104] [Batch 02264/03080] [00:28:19/00:10:12, 0.751s/it]: train_loss_raw=0.4531, running_loss=0.3991, LR=0.000100
[2025-08-27 13:49:22,858][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073112] [Batch 02272/03080] [00:28:25/00:10:06, 0.751s/it]: train_loss_raw=0.3487, running_loss=0.3978, LR=0.000100
[2025-08-27 13:49:28,962][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073120] [Batch 02280/03080] [00:28:31/00:10:00, 0.751s/it]: train_loss_raw=0.3892, running_loss=0.3957, LR=0.000100
[2025-08-27 13:49:34,998][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073128] [Batch 02288/03080] [00:28:37/00:09:54, 0.751s/it]: train_loss_raw=0.3263, running_loss=0.3919, LR=0.000100
[2025-08-27 13:49:40,793][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073136] [Batch 02296/03080] [00:28:43/00:09:48, 0.751s/it]: train_loss_raw=0.4338, running_loss=0.3922, LR=0.000100
[2025-08-27 13:49:46,823][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073144] [Batch 02304/03080] [00:28:49/00:09:42, 0.751s/it]: train_loss_raw=0.3505, running_loss=0.3931, LR=0.000100
[2025-08-27 13:49:52,883][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073152] [Batch 02312/03080] [00:28:55/00:09:36, 0.751s/it]: train_loss_raw=0.4744, running_loss=0.3937, LR=0.000100
[2025-08-27 13:49:59,036][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073160] [Batch 02320/03080] [00:29:01/00:09:30, 0.751s/it]: train_loss_raw=0.4884, running_loss=0.3954, LR=0.000100
[2025-08-27 13:50:05,083][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073168] [Batch 02328/03080] [00:29:07/00:09:24, 0.751s/it]: train_loss_raw=0.3624, running_loss=0.3963, LR=0.000100
[2025-08-27 13:50:11,224][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073176] [Batch 02336/03080] [00:29:14/00:09:18, 0.751s/it]: train_loss_raw=0.3073, running_loss=0.3944, LR=0.000100
[2025-08-27 13:50:17,320][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073184] [Batch 02344/03080] [00:29:20/00:09:12, 0.751s/it]: train_loss_raw=0.4730, running_loss=0.3980, LR=0.000100
[2025-08-27 13:50:23,342][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073192] [Batch 02352/03080] [00:29:26/00:09:06, 0.751s/it]: train_loss_raw=0.3666, running_loss=0.3962, LR=0.000100
[2025-08-27 13:50:29,376][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073200] [Batch 02360/03080] [00:29:32/00:09:00, 0.751s/it]: train_loss_raw=0.4209, running_loss=0.3970, LR=0.000100
[2025-08-27 13:50:35,426][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073208] [Batch 02368/03080] [00:29:38/00:08:54, 0.751s/it]: train_loss_raw=0.4988, running_loss=0.3980, LR=0.000100
[2025-08-27 13:50:41,444][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073216] [Batch 02376/03080] [00:29:44/00:08:48, 0.751s/it]: train_loss_raw=0.3973, running_loss=0.3964, LR=0.000100
[2025-08-27 13:50:47,467][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073224] [Batch 02384/03080] [00:29:50/00:08:42, 0.751s/it]: train_loss_raw=0.4672, running_loss=0.3967, LR=0.000100
[2025-08-27 13:50:53,449][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073232] [Batch 02392/03080] [00:29:56/00:08:36, 0.751s/it]: train_loss_raw=0.3107, running_loss=0.3955, LR=0.000100
[2025-08-27 13:50:59,541][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073240] [Batch 02400/03080] [00:30:02/00:08:30, 0.751s/it]: train_loss_raw=0.3674, running_loss=0.3932, LR=0.000100
[2025-08-27 13:51:05,607][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073248] [Batch 02408/03080] [00:30:08/00:08:24, 0.751s/it]: train_loss_raw=0.4118, running_loss=0.3945, LR=0.000100
[2025-08-27 13:51:11,345][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073256] [Batch 02416/03080] [00:30:14/00:08:18, 0.751s/it]: train_loss_raw=0.3425, running_loss=0.3942, LR=0.000100
[2025-08-27 13:51:16,977][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073264] [Batch 02424/03080] [00:30:19/00:08:12, 0.751s/it]: train_loss_raw=0.3664, running_loss=0.3938, LR=0.000100
[2025-08-27 13:51:22,588][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073272] [Batch 02432/03080] [00:30:25/00:08:06, 0.751s/it]: train_loss_raw=0.3591, running_loss=0.3925, LR=0.000100
[2025-08-27 13:51:28,759][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073280] [Batch 02440/03080] [00:30:31/00:08:00, 0.751s/it]: train_loss_raw=0.3762, running_loss=0.3919, LR=0.000100
[2025-08-27 13:51:34,746][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073288] [Batch 02448/03080] [00:30:37/00:07:54, 0.751s/it]: train_loss_raw=0.3597, running_loss=0.3919, LR=0.000100
[2025-08-27 13:51:40,742][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073296] [Batch 02456/03080] [00:30:43/00:07:48, 0.751s/it]: train_loss_raw=0.3764, running_loss=0.3928, LR=0.000100
[2025-08-27 13:51:46,745][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073304] [Batch 02464/03080] [00:30:49/00:07:42, 0.751s/it]: train_loss_raw=0.3065, running_loss=0.3923, LR=0.000100
[2025-08-27 13:51:52,758][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073312] [Batch 02472/03080] [00:30:55/00:07:36, 0.751s/it]: train_loss_raw=0.3921, running_loss=0.3911, LR=0.000100
[2025-08-27 13:51:58,768][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073320] [Batch 02480/03080] [00:31:01/00:07:30, 0.751s/it]: train_loss_raw=0.4173, running_loss=0.3927, LR=0.000100
[2025-08-27 13:52:04,770][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073328] [Batch 02488/03080] [00:31:07/00:07:24, 0.751s/it]: train_loss_raw=0.3386, running_loss=0.3924, LR=0.000100
[2025-08-27 13:52:10,826][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073336] [Batch 02496/03080] [00:31:13/00:07:18, 0.751s/it]: train_loss_raw=0.4135, running_loss=0.3921, LR=0.000100
[2025-08-27 13:52:16,910][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073344] [Batch 02504/03080] [00:31:19/00:07:12, 0.751s/it]: train_loss_raw=0.4972, running_loss=0.3969, LR=0.000100
[2025-08-27 13:52:22,914][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073352] [Batch 02512/03080] [00:31:25/00:07:06, 0.751s/it]: train_loss_raw=0.3825, running_loss=0.3962, LR=0.000100
[2025-08-27 13:52:28,914][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073360] [Batch 02520/03080] [00:31:31/00:07:00, 0.751s/it]: train_loss_raw=0.4447, running_loss=0.3960, LR=0.000100
[2025-08-27 13:52:34,671][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073368] [Batch 02528/03080] [00:31:37/00:06:54, 0.751s/it]: train_loss_raw=0.3966, running_loss=0.3948, LR=0.000100
[2025-08-27 13:52:40,643][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073376] [Batch 02536/03080] [00:31:43/00:06:48, 0.751s/it]: train_loss_raw=0.3704, running_loss=0.3922, LR=0.000100
[2025-08-27 13:52:47,061][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073384] [Batch 02544/03080] [00:31:49/00:06:42, 0.751s/it]: train_loss_raw=0.4420, running_loss=0.3924, LR=0.000100
[2025-08-27 13:52:52,985][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073392] [Batch 02552/03080] [00:31:55/00:06:36, 0.751s/it]: train_loss_raw=0.3345, running_loss=0.3925, LR=0.000100
[2025-08-27 13:52:59,049][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073400] [Batch 02560/03080] [00:32:01/00:06:30, 0.751s/it]: train_loss_raw=0.4223, running_loss=0.3935, LR=0.000100
[2025-08-27 13:53:05,147][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073408] [Batch 02568/03080] [00:32:08/00:06:24, 0.751s/it]: train_loss_raw=0.3230, running_loss=0.3925, LR=0.000100
[2025-08-27 13:53:11,443][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073416] [Batch 02576/03080] [00:32:14/00:06:18, 0.751s/it]: train_loss_raw=0.3898, running_loss=0.3924, LR=0.000100
[2025-08-27 13:53:17,654][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073424] [Batch 02584/03080] [00:32:20/00:06:12, 0.751s/it]: train_loss_raw=0.4458, running_loss=0.3915, LR=0.000100
[2025-08-27 13:53:23,695][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073432] [Batch 02592/03080] [00:32:26/00:06:06, 0.751s/it]: train_loss_raw=0.3951, running_loss=0.3923, LR=0.000100
[2025-08-27 13:53:29,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073440] [Batch 02600/03080] [00:32:32/00:06:00, 0.751s/it]: train_loss_raw=0.3480, running_loss=0.3917, LR=0.000100
[2025-08-27 13:53:35,847][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073448] [Batch 02608/03080] [00:32:38/00:05:54, 0.751s/it]: train_loss_raw=0.4073, running_loss=0.3932, LR=0.000100
[2025-08-27 13:53:41,705][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073456] [Batch 02616/03080] [00:32:44/00:05:48, 0.751s/it]: train_loss_raw=0.4850, running_loss=0.3947, LR=0.000100
[2025-08-27 13:53:47,454][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073464] [Batch 02624/03080] [00:32:50/00:05:42, 0.751s/it]: train_loss_raw=0.3918, running_loss=0.3951, LR=0.000100
[2025-08-27 13:53:53,494][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073472] [Batch 02632/03080] [00:32:56/00:05:36, 0.751s/it]: train_loss_raw=0.3787, running_loss=0.3932, LR=0.000100
[2025-08-27 13:53:59,543][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073480] [Batch 02640/03080] [00:33:02/00:05:30, 0.751s/it]: train_loss_raw=0.3611, running_loss=0.3923, LR=0.000100
[2025-08-27 13:54:05,588][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073488] [Batch 02648/03080] [00:33:08/00:05:24, 0.751s/it]: train_loss_raw=0.3541, running_loss=0.3939, LR=0.000100
[2025-08-27 13:54:11,678][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073496] [Batch 02656/03080] [00:33:14/00:05:18, 0.751s/it]: train_loss_raw=0.3646, running_loss=0.3936, LR=0.000100
[2025-08-27 13:54:17,772][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073504] [Batch 02664/03080] [00:33:20/00:05:12, 0.751s/it]: train_loss_raw=0.3536, running_loss=0.3921, LR=0.000100
[2025-08-27 13:54:23,819][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073512] [Batch 02672/03080] [00:33:26/00:05:06, 0.751s/it]: train_loss_raw=0.3323, running_loss=0.3904, LR=0.000100
[2025-08-27 13:54:29,886][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073520] [Batch 02680/03080] [00:33:32/00:05:00, 0.751s/it]: train_loss_raw=0.3228, running_loss=0.3911, LR=0.000100
[2025-08-27 13:54:35,894][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073528] [Batch 02688/03080] [00:33:38/00:04:54, 0.751s/it]: train_loss_raw=0.3807, running_loss=0.3893, LR=0.000100
[2025-08-27 13:54:42,011][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073536] [Batch 02696/03080] [00:33:44/00:04:48, 0.751s/it]: train_loss_raw=0.3792, running_loss=0.3877, LR=0.000100
[2025-08-27 13:54:48,224][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073544] [Batch 02704/03080] [00:33:51/00:04:42, 0.751s/it]: train_loss_raw=0.3753, running_loss=0.3891, LR=0.000100
[2025-08-27 13:54:54,294][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073552] [Batch 02712/03080] [00:33:57/00:04:36, 0.751s/it]: train_loss_raw=0.4216, running_loss=0.3912, LR=0.000100
[2025-08-27 13:55:00,378][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073560] [Batch 02720/03080] [00:34:03/00:04:30, 0.751s/it]: train_loss_raw=0.4108, running_loss=0.3933, LR=0.000100
[2025-08-27 13:55:06,487][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073568] [Batch 02728/03080] [00:34:09/00:04:24, 0.751s/it]: train_loss_raw=0.4336, running_loss=0.3922, LR=0.000100
[2025-08-27 13:55:12,541][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073576] [Batch 02736/03080] [00:34:15/00:04:18, 0.751s/it]: train_loss_raw=0.3722, running_loss=0.3934, LR=0.000100
[2025-08-27 13:55:18,688][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073584] [Batch 02744/03080] [00:34:21/00:04:12, 0.751s/it]: train_loss_raw=0.3953, running_loss=0.3925, LR=0.000100
[2025-08-27 13:55:24,710][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073592] [Batch 02752/03080] [00:34:27/00:04:06, 0.751s/it]: train_loss_raw=0.3810, running_loss=0.3950, LR=0.000100
[2025-08-27 13:55:30,786][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073600] [Batch 02760/03080] [00:34:33/00:04:00, 0.751s/it]: train_loss_raw=0.3331, running_loss=0.3962, LR=0.000100
[2025-08-27 13:55:36,865][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073608] [Batch 02768/03080] [00:34:39/00:03:54, 0.751s/it]: train_loss_raw=0.4652, running_loss=0.3961, LR=0.000100
[2025-08-27 13:55:42,889][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073616] [Batch 02776/03080] [00:34:45/00:03:48, 0.751s/it]: train_loss_raw=0.3446, running_loss=0.3950, LR=0.000100
[2025-08-27 13:55:48,964][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073624] [Batch 02784/03080] [00:34:51/00:03:42, 0.751s/it]: train_loss_raw=0.4178, running_loss=0.3955, LR=0.000100
[2025-08-27 13:55:54,982][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073632] [Batch 02792/03080] [00:34:57/00:03:36, 0.751s/it]: train_loss_raw=0.4331, running_loss=0.3951, LR=0.000100
[2025-08-27 13:56:01,018][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073640] [Batch 02800/03080] [00:35:03/00:03:30, 0.751s/it]: train_loss_raw=0.4006, running_loss=0.3954, LR=0.000100
[2025-08-27 13:56:07,038][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073648] [Batch 02808/03080] [00:35:09/00:03:24, 0.751s/it]: train_loss_raw=0.3867, running_loss=0.3937, LR=0.000100
[2025-08-27 13:56:13,164][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073656] [Batch 02816/03080] [00:35:16/00:03:18, 0.751s/it]: train_loss_raw=0.3679, running_loss=0.3928, LR=0.000100
[2025-08-27 13:56:19,157][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073664] [Batch 02824/03080] [00:35:22/00:03:12, 0.751s/it]: train_loss_raw=0.4787, running_loss=0.3964, LR=0.000100
[2025-08-27 13:56:25,213][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073672] [Batch 02832/03080] [00:35:28/00:03:06, 0.751s/it]: train_loss_raw=0.3947, running_loss=0.3967, LR=0.000100
[2025-08-27 13:56:31,029][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073680] [Batch 02840/03080] [00:35:33/00:03:00, 0.751s/it]: train_loss_raw=0.3349, running_loss=0.3951, LR=0.000100
[2025-08-27 13:56:36,692][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073688] [Batch 02848/03080] [00:35:39/00:02:54, 0.751s/it]: train_loss_raw=0.3219, running_loss=0.3948, LR=0.000100
[2025-08-27 13:56:42,257][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073696] [Batch 02856/03080] [00:35:45/00:02:48, 0.751s/it]: train_loss_raw=0.4150, running_loss=0.3952, LR=0.000100
[2025-08-27 13:56:47,822][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073704] [Batch 02864/03080] [00:35:50/00:02:42, 0.751s/it]: train_loss_raw=0.3862, running_loss=0.3933, LR=0.000100
[2025-08-27 13:56:53,473][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073712] [Batch 02872/03080] [00:35:56/00:02:36, 0.751s/it]: train_loss_raw=0.3654, running_loss=0.3913, LR=0.000100
[2025-08-27 13:56:59,517][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073720] [Batch 02880/03080] [00:36:02/00:02:30, 0.751s/it]: train_loss_raw=0.4233, running_loss=0.3916, LR=0.000100
[2025-08-27 13:57:05,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073728] [Batch 02888/03080] [00:36:08/00:02:24, 0.751s/it]: train_loss_raw=0.3619, running_loss=0.3915, LR=0.000100
[2025-08-27 13:57:11,666][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073736] [Batch 02896/03080] [00:36:14/00:02:18, 0.751s/it]: train_loss_raw=0.4451, running_loss=0.3941, LR=0.000100
[2025-08-27 13:57:17,694][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073744] [Batch 02904/03080] [00:36:20/00:02:12, 0.751s/it]: train_loss_raw=0.4081, running_loss=0.3950, LR=0.000100
[2025-08-27 13:57:23,600][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073752] [Batch 02912/03080] [00:36:26/00:02:06, 0.751s/it]: train_loss_raw=0.3890, running_loss=0.3940, LR=0.000100
[2025-08-27 13:57:29,578][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073760] [Batch 02920/03080] [00:36:32/00:02:00, 0.751s/it]: train_loss_raw=0.3714, running_loss=0.3936, LR=0.000100
[2025-08-27 13:57:35,115][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073768] [Batch 02928/03080] [00:36:38/00:01:54, 0.751s/it]: train_loss_raw=0.3258, running_loss=0.3917, LR=0.000100
[2025-08-27 13:57:40,503][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073776] [Batch 02936/03080] [00:36:43/00:01:48, 0.750s/it]: train_loss_raw=0.3447, running_loss=0.3899, LR=0.000100
[2025-08-27 13:57:46,307][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073784] [Batch 02944/03080] [00:36:49/00:01:42, 0.750s/it]: train_loss_raw=0.4103, running_loss=0.3917, LR=0.000100
[2025-08-27 13:57:52,456][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073792] [Batch 02952/03080] [00:36:55/00:01:36, 0.750s/it]: train_loss_raw=0.4534, running_loss=0.3931, LR=0.000100
[2025-08-27 13:57:58,426][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073800] [Batch 02960/03080] [00:37:01/00:01:30, 0.750s/it]: train_loss_raw=0.4910, running_loss=0.3938, LR=0.000100
[2025-08-27 13:58:04,505][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073808] [Batch 02968/03080] [00:37:07/00:01:24, 0.750s/it]: train_loss_raw=0.3708, running_loss=0.3913, LR=0.000100
[2025-08-27 13:58:10,472][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073816] [Batch 02976/03080] [00:37:13/00:01:18, 0.750s/it]: train_loss_raw=0.3385, running_loss=0.3899, LR=0.000100
[2025-08-27 13:58:16,326][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073824] [Batch 02984/03080] [00:37:19/00:01:12, 0.750s/it]: train_loss_raw=0.4267, running_loss=0.3880, LR=0.000100
[2025-08-27 13:58:22,335][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073832] [Batch 02992/03080] [00:37:25/00:01:06, 0.750s/it]: train_loss_raw=0.3553, running_loss=0.3895, LR=0.000100
[2025-08-27 13:58:28,246][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073840] [Batch 03000/03080] [00:37:31/00:01:00, 0.750s/it]: train_loss_raw=0.4019, running_loss=0.3880, LR=0.000100
[2025-08-27 13:58:33,973][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073848] [Batch 03008/03080] [00:37:36/00:00:54, 0.750s/it]: train_loss_raw=0.4621, running_loss=0.3877, LR=0.000100
[2025-08-27 13:58:39,906][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073856] [Batch 03016/03080] [00:37:42/00:00:48, 0.750s/it]: train_loss_raw=0.4276, running_loss=0.3881, LR=0.000100
[2025-08-27 13:58:45,713][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073864] [Batch 03024/03080] [00:37:48/00:00:42, 0.750s/it]: train_loss_raw=0.4011, running_loss=0.3866, LR=0.000100
[2025-08-27 13:58:51,590][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073872] [Batch 03032/03080] [00:37:54/00:00:36, 0.750s/it]: train_loss_raw=0.3753, running_loss=0.3875, LR=0.000100
[2025-08-27 13:58:57,126][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073880] [Batch 03040/03080] [00:38:00/00:00:30, 0.750s/it]: train_loss_raw=0.3633, running_loss=0.3861, LR=0.000100
[2025-08-27 13:59:03,215][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073888] [Batch 03048/03080] [00:38:06/00:00:24, 0.750s/it]: train_loss_raw=0.4035, running_loss=0.3850, LR=0.000100
[2025-08-27 13:59:09,158][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073896] [Batch 03056/03080] [00:38:12/00:00:18, 0.750s/it]: train_loss_raw=0.4106, running_loss=0.3863, LR=0.000100
[2025-08-27 13:59:15,163][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073904] [Batch 03064/03080] [00:38:18/00:00:12, 0.750s/it]: train_loss_raw=0.4622, running_loss=0.3895, LR=0.000100
[2025-08-27 13:59:21,220][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073912] [Batch 03072/03080] [00:38:24/00:00:06, 0.750s/it]: train_loss_raw=0.3784, running_loss=0.3894, LR=0.000100
[2025-08-27 13:59:35,765][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 073920] [Batch 03080/03080] [00:38:38/00:00:00, 0.753s/it]: train_loss_raw=0.3547, running_loss=0.3887, LR=0.000100
[2025-08-27 13:59:36,238][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-27 13:59:47,534][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00007/00310] [00:00:11/00:07:06, 1.412s/it]
[2025-08-27 13:59:59,164][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00015/00310] [00:00:22/00:07:01, 1.433s/it]
[2025-08-27 14:00:11,166][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00023/00310] [00:00:34/00:06:56, 1.455s/it]
[2025-08-27 14:00:23,378][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00031/00310] [00:00:47/00:06:49, 1.473s/it]
[2025-08-27 14:00:35,237][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00039/00310] [00:00:58/00:06:38, 1.475s/it]
[2025-08-27 14:00:47,130][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00047/00310] [00:01:10/00:06:26, 1.477s/it]
[2025-08-27 14:00:59,198][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00055/00310] [00:01:22/00:06:16, 1.481s/it]
[2025-08-27 14:01:11,403][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00063/00310] [00:01:35/00:06:05, 1.487s/it]
[2025-08-27 14:01:23,581][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00071/00310] [00:01:47/00:05:54, 1.491s/it]
[2025-08-27 14:01:35,682][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00079/00310] [00:01:59/00:05:43, 1.493s/it]
[2025-08-27 14:01:47,535][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00087/00310] [00:02:11/00:05:31, 1.492s/it]
[2025-08-27 14:01:59,556][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00095/00310] [00:02:23/00:05:19, 1.493s/it]
[2025-08-27 14:02:11,808][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00103/00310] [00:02:35/00:05:08, 1.496s/it]
[2025-08-27 14:02:24,009][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00111/00310] [00:02:47/00:04:56, 1.498s/it]
[2025-08-27 14:02:36,144][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00119/00310] [00:02:59/00:04:44, 1.499s/it]
[2025-08-27 14:02:47,092][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00127/00310] [00:03:10/00:04:31, 1.491s/it]
[2025-08-27 14:02:58,459][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00135/00310] [00:03:22/00:04:18, 1.487s/it]
[2025-08-27 14:03:09,641][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00143/00310] [00:03:33/00:04:06, 1.482s/it]
[2025-08-27 14:03:20,197][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00151/00310] [00:03:43/00:03:52, 1.473s/it]
[2025-08-27 14:03:30,494][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00159/00310] [00:03:54/00:03:39, 1.464s/it]
[2025-08-27 14:03:42,802][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00167/00310] [00:04:06/00:03:28, 1.468s/it]
[2025-08-27 14:03:53,785][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00175/00310] [00:04:17/00:03:16, 1.463s/it]
[2025-08-27 14:04:04,677][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00183/00310] [00:04:28/00:03:03, 1.459s/it]
[2025-08-27 14:04:15,328][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00191/00310] [00:04:39/00:02:51, 1.454s/it]
[2025-08-27 14:04:27,173][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00199/00310] [00:04:50/00:02:40, 1.455s/it]
[2025-08-27 14:04:38,723][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00207/00310] [00:05:02/00:02:28, 1.454s/it]
[2025-08-27 14:04:50,377][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00215/00310] [00:05:14/00:02:16, 1.454s/it]
[2025-08-27 14:05:02,657][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00223/00310] [00:05:26/00:02:05, 1.457s/it]
[2025-08-27 14:05:14,293][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00231/00310] [00:05:38/00:01:53, 1.457s/it]
[2025-08-27 14:05:26,367][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00239/00310] [00:05:50/00:01:42, 1.459s/it]
[2025-08-27 14:05:36,716][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00247/00310] [00:06:00/00:01:30, 1.454s/it]
[2025-08-27 14:05:48,384][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00255/00310] [00:06:12/00:01:18, 1.454s/it]
[2025-08-27 14:06:01,199][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00263/00310] [00:06:24/00:01:07, 1.458s/it]
[2025-08-27 14:06:13,200][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00271/00310] [00:06:36/00:00:55, 1.459s/it]
[2025-08-27 14:06:24,865][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00279/00310] [00:06:48/00:00:43, 1.459s/it]
[2025-08-27 14:06:36,665][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00287/00310] [00:07:00/00:00:32, 1.460s/it]
[2025-08-27 14:06:48,209][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00295/00310] [00:07:11/00:00:20, 1.459s/it]
[2025-08-27 14:06:59,922][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 073921] [Batch 00303/00310] [00:07:23/00:00:08, 1.459s/it]
[2025-08-27 14:07:08,206][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=0.38867, valid_loss=1.45430
[2025-08-27 14:07:08,207][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-27 14:07:08,207][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.497
[2025-08-27 14:07:08,207][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.144
[2025-08-27 14:07:08,207][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.147
[2025-08-27 14:07:08,207][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.077
[2025-08-27 14:07:08,217][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 18:40:22, remaining time 04:40:05, 00:46:40 per epoch
[2025-08-27 14:07:13,943][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073928] [Batch 00008/03080] [00:00:05/00:35:24, 0.692s/it]: train_loss_raw=0.3107, running_loss=0.3646, LR=0.000100
[2025-08-27 14:07:20,129][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073936] [Batch 00016/03080] [00:00:11/00:37:24, 0.732s/it]: train_loss_raw=0.3625, running_loss=0.3636, LR=0.000100
[2025-08-27 14:07:26,243][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073944] [Batch 00024/03080] [00:00:17/00:37:50, 0.743s/it]: train_loss_raw=0.4726, running_loss=0.3654, LR=0.000100
[2025-08-27 14:07:32,294][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073952] [Batch 00032/03080] [00:00:23/00:37:54, 0.746s/it]: train_loss_raw=0.4185, running_loss=0.3647, LR=0.000100
[2025-08-27 14:07:37,778][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073960] [Batch 00040/03080] [00:00:29/00:37:11, 0.734s/it]: train_loss_raw=0.3264, running_loss=0.3657, LR=0.000100
[2025-08-27 14:07:43,386][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073968] [Batch 00048/03080] [00:00:34/00:36:49, 0.729s/it]: train_loss_raw=0.3676, running_loss=0.3649, LR=0.000100
[2025-08-27 14:07:49,245][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073976] [Batch 00056/03080] [00:00:40/00:36:45, 0.729s/it]: train_loss_raw=0.3622, running_loss=0.3662, LR=0.000100
[2025-08-27 14:07:54,899][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073984] [Batch 00064/03080] [00:00:46/00:36:30, 0.726s/it]: train_loss_raw=0.3653, running_loss=0.3670, LR=0.000100
[2025-08-27 14:08:00,900][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 073992] [Batch 00072/03080] [00:00:52/00:36:32, 0.729s/it]: train_loss_raw=0.3899, running_loss=0.3664, LR=0.000100
[2025-08-27 14:08:06,943][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074000] [Batch 00080/03080] [00:00:58/00:36:35, 0.732s/it]: train_loss_raw=0.3628, running_loss=0.3646, LR=0.000100
[2025-08-27 14:08:16,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074008] [Batch 00088/03080] [00:01:07/00:38:31, 0.773s/it]: train_loss_raw=0.2952, running_loss=0.3638, LR=0.000100
[2025-08-27 14:08:22,416][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074016] [Batch 00096/03080] [00:01:14/00:38:20, 0.771s/it]: train_loss_raw=0.3964, running_loss=0.3636, LR=0.000100
[2025-08-27 14:08:28,631][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074024] [Batch 00104/03080] [00:01:20/00:38:15, 0.771s/it]: train_loss_raw=0.3608, running_loss=0.3639, LR=0.000100
[2025-08-27 14:08:34,724][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074032] [Batch 00112/03080] [00:01:26/00:38:07, 0.771s/it]: train_loss_raw=0.3019, running_loss=0.3648, LR=0.000100
[2025-08-27 14:08:40,721][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074040] [Batch 00120/03080] [00:01:32/00:37:57, 0.769s/it]: train_loss_raw=0.2947, running_loss=0.3661, LR=0.000100
[2025-08-27 14:08:46,766][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074048] [Batch 00128/03080] [00:01:38/00:37:48, 0.768s/it]: train_loss_raw=0.4086, running_loss=0.3657, LR=0.000100
[2025-08-27 14:08:52,879][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074056] [Batch 00136/03080] [00:01:44/00:37:41, 0.768s/it]: train_loss_raw=0.3494, running_loss=0.3655, LR=0.000100
[2025-08-27 14:08:58,910][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074064] [Batch 00144/03080] [00:01:50/00:37:32, 0.767s/it]: train_loss_raw=0.4138, running_loss=0.3677, LR=0.000100
[2025-08-27 14:09:04,858][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074072] [Batch 00152/03080] [00:01:56/00:37:23, 0.766s/it]: train_loss_raw=0.3612, running_loss=0.3671, LR=0.000100
[2025-08-27 14:09:10,778][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074080] [Batch 00160/03080] [00:02:02/00:37:13, 0.765s/it]: train_loss_raw=0.4224, running_loss=0.3676, LR=0.000100
[2025-08-27 14:09:16,888][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074088] [Batch 00168/03080] [00:02:08/00:37:06, 0.765s/it]: train_loss_raw=0.3645, running_loss=0.3681, LR=0.000100
[2025-08-27 14:09:22,797][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074096] [Batch 00176/03080] [00:02:14/00:36:57, 0.764s/it]: train_loss_raw=0.2847, running_loss=0.3651, LR=0.000100
[2025-08-27 14:09:28,794][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074104] [Batch 00184/03080] [00:02:20/00:36:49, 0.763s/it]: train_loss_raw=0.4192, running_loss=0.3648, LR=0.000100
[2025-08-27 14:09:34,513][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074112] [Batch 00192/03080] [00:02:26/00:36:37, 0.761s/it]: train_loss_raw=0.3203, running_loss=0.3655, LR=0.000100
[2025-08-27 14:09:40,297][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074120] [Batch 00200/03080] [00:02:31/00:36:27, 0.759s/it]: train_loss_raw=0.4559, running_loss=0.3678, LR=0.000100
[2025-08-27 14:09:46,345][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074128] [Batch 00208/03080] [00:02:37/00:36:20, 0.759s/it]: train_loss_raw=0.3197, running_loss=0.3687, LR=0.000100
[2025-08-27 14:09:52,491][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074136] [Batch 00216/03080] [00:02:44/00:36:15, 0.760s/it]: train_loss_raw=0.3764, running_loss=0.3693, LR=0.000100
[2025-08-27 14:09:58,528][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074144] [Batch 00224/03080] [00:02:50/00:36:09, 0.759s/it]: train_loss_raw=0.3594, running_loss=0.3699, LR=0.000100
[2025-08-27 14:10:04,659][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074152] [Batch 00232/03080] [00:02:56/00:36:03, 0.760s/it]: train_loss_raw=0.3585, running_loss=0.3691, LR=0.000100
[2025-08-27 14:10:10,695][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074160] [Batch 00240/03080] [00:03:02/00:35:57, 0.760s/it]: train_loss_raw=0.3938, running_loss=0.3691, LR=0.000100
[2025-08-27 14:10:16,883][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074168] [Batch 00248/03080] [00:03:08/00:35:52, 0.760s/it]: train_loss_raw=0.3361, running_loss=0.3681, LR=0.000100
[2025-08-27 14:10:22,760][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074176] [Batch 00256/03080] [00:03:14/00:35:43, 0.759s/it]: train_loss_raw=0.3409, running_loss=0.3684, LR=0.000100
[2025-08-27 14:10:28,761][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074184] [Batch 00264/03080] [00:03:20/00:35:37, 0.759s/it]: train_loss_raw=0.3879, running_loss=0.3708, LR=0.000100
[2025-08-27 14:10:34,809][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074192] [Batch 00272/03080] [00:03:26/00:35:30, 0.759s/it]: train_loss_raw=0.4136, running_loss=0.3702, LR=0.000100
[2025-08-27 14:10:40,857][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074200] [Batch 00280/03080] [00:03:32/00:35:24, 0.759s/it]: train_loss_raw=0.4175, running_loss=0.3705, LR=0.000100
[2025-08-27 14:10:46,939][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074208] [Batch 00288/03080] [00:03:38/00:35:18, 0.759s/it]: train_loss_raw=0.4106, running_loss=0.3718, LR=0.000100
[2025-08-27 14:10:53,068][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074216] [Batch 00296/03080] [00:03:44/00:35:13, 0.759s/it]: train_loss_raw=0.3995, running_loss=0.3697, LR=0.000100
[2025-08-27 14:10:59,211][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074224] [Batch 00304/03080] [00:03:50/00:35:07, 0.759s/it]: train_loss_raw=0.3738, running_loss=0.3692, LR=0.000100
[2025-08-27 14:11:05,292][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074232] [Batch 00312/03080] [00:03:56/00:35:01, 0.759s/it]: train_loss_raw=0.4150, running_loss=0.3689, LR=0.000100
[2025-08-27 14:11:11,314][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074240] [Batch 00320/03080] [00:04:02/00:34:55, 0.759s/it]: train_loss_raw=0.4020, running_loss=0.3686, LR=0.000100
[2025-08-27 14:11:17,437][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074248] [Batch 00328/03080] [00:04:09/00:34:49, 0.759s/it]: train_loss_raw=0.3456, running_loss=0.3696, LR=0.000100
[2025-08-27 14:11:23,543][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074256] [Batch 00336/03080] [00:04:15/00:34:43, 0.759s/it]: train_loss_raw=0.3804, running_loss=0.3689, LR=0.000100
[2025-08-27 14:11:29,690][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074264] [Batch 00344/03080] [00:04:21/00:34:38, 0.760s/it]: train_loss_raw=0.4271, running_loss=0.3709, LR=0.000100
[2025-08-27 14:11:35,779][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074272] [Batch 00352/03080] [00:04:27/00:34:32, 0.760s/it]: train_loss_raw=0.4092, running_loss=0.3701, LR=0.000100
[2025-08-27 14:11:41,835][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074280] [Batch 00360/03080] [00:04:33/00:34:25, 0.760s/it]: train_loss_raw=0.4065, running_loss=0.3698, LR=0.000100
[2025-08-27 14:11:47,996][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074288] [Batch 00368/03080] [00:04:39/00:34:20, 0.760s/it]: train_loss_raw=0.4196, running_loss=0.3699, LR=0.000100
[2025-08-27 14:11:54,049][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074296] [Batch 00376/03080] [00:04:45/00:34:14, 0.760s/it]: train_loss_raw=0.3436, running_loss=0.3699, LR=0.000100
[2025-08-27 14:12:00,123][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074304] [Batch 00384/03080] [00:04:51/00:34:08, 0.760s/it]: train_loss_raw=0.3545, running_loss=0.3691, LR=0.000100
[2025-08-27 14:12:06,237][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074312] [Batch 00392/03080] [00:04:57/00:34:02, 0.760s/it]: train_loss_raw=0.4014, running_loss=0.3682, LR=0.000100
[2025-08-27 14:12:12,344][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074320] [Batch 00400/03080] [00:05:03/00:33:56, 0.760s/it]: train_loss_raw=0.3144, running_loss=0.3683, LR=0.000100
[2025-08-27 14:12:18,533][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074328] [Batch 00408/03080] [00:05:10/00:33:51, 0.760s/it]: train_loss_raw=0.3169, running_loss=0.3684, LR=0.000100
[2025-08-27 14:12:24,621][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074336] [Batch 00416/03080] [00:05:16/00:33:44, 0.760s/it]: train_loss_raw=0.4144, running_loss=0.3692, LR=0.000100
[2025-08-27 14:12:30,705][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074344] [Batch 00424/03080] [00:05:22/00:33:38, 0.760s/it]: train_loss_raw=0.4297, running_loss=0.3674, LR=0.000100
[2025-08-27 14:12:36,845][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074352] [Batch 00432/03080] [00:05:28/00:33:33, 0.760s/it]: train_loss_raw=0.3223, running_loss=0.3672, LR=0.000100
[2025-08-27 14:12:42,925][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074360] [Batch 00440/03080] [00:05:34/00:33:27, 0.760s/it]: train_loss_raw=0.4031, running_loss=0.3665, LR=0.000100
[2025-08-27 14:12:49,009][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074368] [Batch 00448/03080] [00:05:40/00:33:21, 0.760s/it]: train_loss_raw=0.4161, running_loss=0.3667, LR=0.000100
[2025-08-27 14:12:55,180][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074376] [Batch 00456/03080] [00:05:46/00:33:15, 0.760s/it]: train_loss_raw=0.4010, running_loss=0.3667, LR=0.000100
[2025-08-27 14:13:01,330][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074384] [Batch 00464/03080] [00:05:52/00:33:09, 0.761s/it]: train_loss_raw=0.3201, running_loss=0.3673, LR=0.000100
[2025-08-27 14:13:07,559][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074392] [Batch 00472/03080] [00:05:59/00:33:04, 0.761s/it]: train_loss_raw=0.2769, running_loss=0.3651, LR=0.000100
[2025-08-27 14:13:13,641][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074400] [Batch 00480/03080] [00:06:05/00:32:58, 0.761s/it]: train_loss_raw=0.3384, running_loss=0.3637, LR=0.000100
[2025-08-27 14:13:19,707][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074408] [Batch 00488/03080] [00:06:11/00:32:52, 0.761s/it]: train_loss_raw=0.2466, running_loss=0.3626, LR=0.000100
[2025-08-27 14:13:25,741][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074416] [Batch 00496/03080] [00:06:17/00:32:45, 0.761s/it]: train_loss_raw=0.3297, running_loss=0.3607, LR=0.000100
[2025-08-27 14:13:31,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074424] [Batch 00504/03080] [00:06:23/00:32:39, 0.760s/it]: train_loss_raw=0.2789, running_loss=0.3604, LR=0.000100
[2025-08-27 14:13:37,299][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074432] [Batch 00512/03080] [00:06:28/00:32:30, 0.760s/it]: train_loss_raw=0.4317, running_loss=0.3624, LR=0.000100
[2025-08-27 14:13:42,850][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074440] [Batch 00520/03080] [00:06:34/00:32:21, 0.759s/it]: train_loss_raw=0.3979, running_loss=0.3625, LR=0.000100
[2025-08-27 14:13:48,868][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074448] [Batch 00528/03080] [00:06:40/00:32:15, 0.758s/it]: train_loss_raw=0.3487, running_loss=0.3623, LR=0.000100
[2025-08-27 14:13:54,799][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074456] [Batch 00536/03080] [00:06:46/00:32:08, 0.758s/it]: train_loss_raw=0.4119, running_loss=0.3639, LR=0.000100
[2025-08-27 14:14:00,923][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074464] [Batch 00544/03080] [00:06:52/00:32:03, 0.758s/it]: train_loss_raw=0.4877, running_loss=0.3668, LR=0.000100
[2025-08-27 14:14:07,074][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074472] [Batch 00552/03080] [00:06:58/00:31:57, 0.758s/it]: train_loss_raw=0.3365, running_loss=0.3665, LR=0.000100
[2025-08-27 14:14:13,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074480] [Batch 00560/03080] [00:07:04/00:31:51, 0.758s/it]: train_loss_raw=0.3514, running_loss=0.3663, LR=0.000100
[2025-08-27 14:14:19,188][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074488] [Batch 00568/03080] [00:07:10/00:31:45, 0.758s/it]: train_loss_raw=0.4033, running_loss=0.3668, LR=0.000100
[2025-08-27 14:14:25,349][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074496] [Batch 00576/03080] [00:07:16/00:31:39, 0.759s/it]: train_loss_raw=0.3585, running_loss=0.3676, LR=0.000100
[2025-08-27 14:14:31,419][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074504] [Batch 00584/03080] [00:07:23/00:31:33, 0.759s/it]: train_loss_raw=0.3445, running_loss=0.3680, LR=0.000100
[2025-08-27 14:14:37,557][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074512] [Batch 00592/03080] [00:07:29/00:31:27, 0.759s/it]: train_loss_raw=0.3882, running_loss=0.3680, LR=0.000100
[2025-08-27 14:14:43,751][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074520] [Batch 00600/03080] [00:07:35/00:31:22, 0.759s/it]: train_loss_raw=0.3543, running_loss=0.3671, LR=0.000100
[2025-08-27 14:14:49,793][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074528] [Batch 00608/03080] [00:07:41/00:31:15, 0.759s/it]: train_loss_raw=0.4652, running_loss=0.3702, LR=0.000100
[2025-08-27 14:14:55,901][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074536] [Batch 00616/03080] [00:07:47/00:31:09, 0.759s/it]: train_loss_raw=0.3693, running_loss=0.3703, LR=0.000100
[2025-08-27 14:15:02,012][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074544] [Batch 00624/03080] [00:07:53/00:31:04, 0.759s/it]: train_loss_raw=0.3707, running_loss=0.3727, LR=0.000100
[2025-08-27 14:15:08,094][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074552] [Batch 00632/03080] [00:07:59/00:30:58, 0.759s/it]: train_loss_raw=0.3766, running_loss=0.3732, LR=0.000100
[2025-08-27 14:15:13,764][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074560] [Batch 00640/03080] [00:08:05/00:30:50, 0.758s/it]: train_loss_raw=0.4040, running_loss=0.3752, LR=0.000100
[2025-08-27 14:15:19,691][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074568] [Batch 00648/03080] [00:08:11/00:30:43, 0.758s/it]: train_loss_raw=0.3897, running_loss=0.3753, LR=0.000100
[2025-08-27 14:15:25,782][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074576] [Batch 00656/03080] [00:08:17/00:30:37, 0.758s/it]: train_loss_raw=0.2627, running_loss=0.3737, LR=0.000100
[2025-08-27 14:15:31,554][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074584] [Batch 00664/03080] [00:08:23/00:30:30, 0.758s/it]: train_loss_raw=0.3525, running_loss=0.3742, LR=0.000100
[2025-08-27 14:15:37,606][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074592] [Batch 00672/03080] [00:08:29/00:30:24, 0.758s/it]: train_loss_raw=0.4232, running_loss=0.3733, LR=0.000100
[2025-08-27 14:15:43,682][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074600] [Batch 00680/03080] [00:08:35/00:30:18, 0.758s/it]: train_loss_raw=0.3088, running_loss=0.3704, LR=0.000100
[2025-08-27 14:15:49,987][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074608] [Batch 00688/03080] [00:08:41/00:30:13, 0.758s/it]: train_loss_raw=0.3944, running_loss=0.3715, LR=0.000100
[2025-08-27 14:15:56,073][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074616] [Batch 00696/03080] [00:08:47/00:30:07, 0.758s/it]: train_loss_raw=0.3369, running_loss=0.3683, LR=0.000100
[2025-08-27 14:16:02,200][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074624] [Batch 00704/03080] [00:08:53/00:30:01, 0.758s/it]: train_loss_raw=0.3721, running_loss=0.3677, LR=0.000100
[2025-08-27 14:16:08,157][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074632] [Batch 00712/03080] [00:08:59/00:29:55, 0.758s/it]: train_loss_raw=0.3498, running_loss=0.3703, LR=0.000100
[2025-08-27 14:16:14,231][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074640] [Batch 00720/03080] [00:09:05/00:29:49, 0.758s/it]: train_loss_raw=0.3902, running_loss=0.3685, LR=0.000100
[2025-08-27 14:16:20,181][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074648] [Batch 00728/03080] [00:09:11/00:29:42, 0.758s/it]: train_loss_raw=0.3659, running_loss=0.3679, LR=0.000100
[2025-08-27 14:16:25,662][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074656] [Batch 00736/03080] [00:09:17/00:29:34, 0.757s/it]: train_loss_raw=0.4320, running_loss=0.3699, LR=0.000100
[2025-08-27 14:16:31,537][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074664] [Batch 00744/03080] [00:09:23/00:29:28, 0.757s/it]: train_loss_raw=0.4048, running_loss=0.3686, LR=0.000100
[2025-08-27 14:16:37,563][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074672] [Batch 00752/03080] [00:09:29/00:29:21, 0.757s/it]: train_loss_raw=0.4607, running_loss=0.3690, LR=0.000100
[2025-08-27 14:16:43,699][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074680] [Batch 00760/03080] [00:09:35/00:29:16, 0.757s/it]: train_loss_raw=0.3864, running_loss=0.3715, LR=0.000100
[2025-08-27 14:16:49,830][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074688] [Batch 00768/03080] [00:09:41/00:29:10, 0.757s/it]: train_loss_raw=0.3987, running_loss=0.3713, LR=0.000100
[2025-08-27 14:16:56,002][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074696] [Batch 00776/03080] [00:09:47/00:29:04, 0.757s/it]: train_loss_raw=0.3989, running_loss=0.3711, LR=0.000100
[2025-08-27 14:17:02,168][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074704] [Batch 00784/03080] [00:09:53/00:28:58, 0.757s/it]: train_loss_raw=0.3890, running_loss=0.3715, LR=0.000100
[2025-08-27 14:17:08,283][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074712] [Batch 00792/03080] [00:09:59/00:28:52, 0.757s/it]: train_loss_raw=0.4474, running_loss=0.3700, LR=0.000100
[2025-08-27 14:17:14,297][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074720] [Batch 00800/03080] [00:10:05/00:28:46, 0.757s/it]: train_loss_raw=0.4230, running_loss=0.3717, LR=0.000100
[2025-08-27 14:17:20,363][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074728] [Batch 00808/03080] [00:10:11/00:28:40, 0.757s/it]: train_loss_raw=0.3410, running_loss=0.3717, LR=0.000100
[2025-08-27 14:17:26,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074736] [Batch 00816/03080] [00:10:17/00:28:34, 0.757s/it]: train_loss_raw=0.3481, running_loss=0.3691, LR=0.000100
[2025-08-27 14:17:32,573][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074744] [Batch 00824/03080] [00:10:24/00:28:28, 0.757s/it]: train_loss_raw=0.3657, running_loss=0.3680, LR=0.000100
[2025-08-27 14:17:38,770][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074752] [Batch 00832/03080] [00:10:30/00:28:23, 0.758s/it]: train_loss_raw=0.4382, running_loss=0.3701, LR=0.000100
[2025-08-27 14:17:44,833][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074760] [Batch 00840/03080] [00:10:36/00:28:17, 0.758s/it]: train_loss_raw=0.3658, running_loss=0.3684, LR=0.000100
[2025-08-27 14:17:50,846][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074768] [Batch 00848/03080] [00:10:42/00:28:10, 0.758s/it]: train_loss_raw=0.2856, running_loss=0.3666, LR=0.000100
[2025-08-27 14:17:56,871][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074776] [Batch 00856/03080] [00:10:48/00:28:04, 0.758s/it]: train_loss_raw=0.3577, running_loss=0.3673, LR=0.000100
[2025-08-27 14:18:02,895][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074784] [Batch 00864/03080] [00:10:54/00:27:58, 0.758s/it]: train_loss_raw=0.3710, running_loss=0.3676, LR=0.000100
[2025-08-27 14:18:08,901][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074792] [Batch 00872/03080] [00:11:00/00:27:52, 0.757s/it]: train_loss_raw=0.3438, running_loss=0.3683, LR=0.000100
[2025-08-27 14:18:14,950][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074800] [Batch 00880/03080] [00:11:06/00:27:46, 0.757s/it]: train_loss_raw=0.3754, running_loss=0.3694, LR=0.000100
[2025-08-27 14:18:21,051][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074808] [Batch 00888/03080] [00:11:12/00:27:40, 0.757s/it]: train_loss_raw=0.3643, running_loss=0.3682, LR=0.000100
[2025-08-27 14:18:27,064][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074816] [Batch 00896/03080] [00:11:18/00:27:34, 0.757s/it]: train_loss_raw=0.3435, running_loss=0.3680, LR=0.000100
[2025-08-27 14:18:33,060][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074824] [Batch 00904/03080] [00:11:24/00:27:28, 0.757s/it]: train_loss_raw=0.3146, running_loss=0.3669, LR=0.000100
[2025-08-27 14:18:39,086][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074832] [Batch 00912/03080] [00:11:30/00:27:21, 0.757s/it]: train_loss_raw=0.4037, running_loss=0.3667, LR=0.000100
[2025-08-27 14:18:45,118][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074840] [Batch 00920/03080] [00:11:36/00:27:15, 0.757s/it]: train_loss_raw=0.4023, running_loss=0.3671, LR=0.000100
[2025-08-27 14:18:51,170][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074848] [Batch 00928/03080] [00:11:42/00:27:09, 0.757s/it]: train_loss_raw=0.4144, running_loss=0.3701, LR=0.000100
[2025-08-27 14:18:57,282][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074856] [Batch 00936/03080] [00:11:48/00:27:03, 0.757s/it]: train_loss_raw=0.3526, running_loss=0.3715, LR=0.000100
[2025-08-27 14:19:03,347][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074864] [Batch 00944/03080] [00:11:54/00:26:57, 0.757s/it]: train_loss_raw=0.4291, running_loss=0.3731, LR=0.000100
[2025-08-27 14:19:09,251][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074872] [Batch 00952/03080] [00:12:00/00:26:51, 0.757s/it]: train_loss_raw=0.3647, running_loss=0.3710, LR=0.000100
[2025-08-27 14:19:15,053][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074880] [Batch 00960/03080] [00:12:06/00:26:44, 0.757s/it]: train_loss_raw=0.3760, running_loss=0.3705, LR=0.000100
[2025-08-27 14:19:21,052][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074888] [Batch 00968/03080] [00:12:12/00:26:38, 0.757s/it]: train_loss_raw=0.4436, running_loss=0.3734, LR=0.000100
[2025-08-27 14:19:27,072][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074896] [Batch 00976/03080] [00:12:18/00:26:32, 0.757s/it]: train_loss_raw=0.3191, running_loss=0.3721, LR=0.000100
[2025-08-27 14:19:33,120][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074904] [Batch 00984/03080] [00:12:24/00:26:26, 0.757s/it]: train_loss_raw=0.3654, running_loss=0.3723, LR=0.000100
[2025-08-27 14:19:39,150][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074912] [Batch 00992/03080] [00:12:30/00:26:20, 0.757s/it]: train_loss_raw=0.3510, running_loss=0.3714, LR=0.000100
[2025-08-27 14:19:44,935][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074920] [Batch 01000/03080] [00:12:36/00:26:13, 0.757s/it]: train_loss_raw=0.3888, running_loss=0.3740, LR=0.000100
[2025-08-27 14:19:50,754][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074928] [Batch 01008/03080] [00:12:42/00:26:07, 0.756s/it]: train_loss_raw=0.3966, running_loss=0.3747, LR=0.000100
[2025-08-27 14:19:56,701][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074936] [Batch 01016/03080] [00:12:48/00:26:00, 0.756s/it]: train_loss_raw=0.4274, running_loss=0.3757, LR=0.000100
[2025-08-27 14:20:02,841][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074944] [Batch 01024/03080] [00:12:54/00:25:54, 0.756s/it]: train_loss_raw=0.3953, running_loss=0.3766, LR=0.000100
[2025-08-27 14:20:08,749][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074952] [Batch 01032/03080] [00:13:00/00:25:48, 0.756s/it]: train_loss_raw=0.3427, running_loss=0.3773, LR=0.000100
[2025-08-27 14:20:14,789][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074960] [Batch 01040/03080] [00:13:06/00:25:42, 0.756s/it]: train_loss_raw=0.3262, running_loss=0.3780, LR=0.000100
[2025-08-27 14:20:20,820][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074968] [Batch 01048/03080] [00:13:12/00:25:36, 0.756s/it]: train_loss_raw=0.3360, running_loss=0.3773, LR=0.000100
[2025-08-27 14:20:26,811][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074976] [Batch 01056/03080] [00:13:18/00:25:30, 0.756s/it]: train_loss_raw=0.4147, running_loss=0.3763, LR=0.000100
[2025-08-27 14:20:32,898][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074984] [Batch 01064/03080] [00:13:24/00:25:24, 0.756s/it]: train_loss_raw=0.3497, running_loss=0.3747, LR=0.000100
[2025-08-27 14:20:38,981][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 074992] [Batch 01072/03080] [00:13:30/00:25:18, 0.756s/it]: train_loss_raw=0.3957, running_loss=0.3771, LR=0.000100
[2025-08-27 14:20:45,075][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075000] [Batch 01080/03080] [00:13:36/00:25:12, 0.756s/it]: train_loss_raw=0.4379, running_loss=0.3773, LR=0.000100
[2025-08-27 14:20:51,155][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075008] [Batch 01088/03080] [00:13:42/00:25:06, 0.756s/it]: train_loss_raw=0.3900, running_loss=0.3752, LR=0.000100
[2025-08-27 14:20:57,227][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075016] [Batch 01096/03080] [00:13:48/00:25:00, 0.756s/it]: train_loss_raw=0.3216, running_loss=0.3734, LR=0.000100
[2025-08-27 14:21:03,310][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075024] [Batch 01104/03080] [00:13:54/00:24:54, 0.756s/it]: train_loss_raw=0.4021, running_loss=0.3729, LR=0.000100
[2025-08-27 14:21:09,505][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075032] [Batch 01112/03080] [00:14:01/00:24:48, 0.756s/it]: train_loss_raw=0.4502, running_loss=0.3729, LR=0.000100
[2025-08-27 14:21:15,707][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075040] [Batch 01120/03080] [00:14:07/00:24:42, 0.757s/it]: train_loss_raw=0.2921, running_loss=0.3718, LR=0.000100
[2025-08-27 14:21:21,806][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075048] [Batch 01128/03080] [00:14:13/00:24:36, 0.757s/it]: train_loss_raw=0.3585, running_loss=0.3707, LR=0.000100
[2025-08-27 14:21:27,803][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075056] [Batch 01136/03080] [00:14:19/00:24:30, 0.757s/it]: train_loss_raw=0.4315, running_loss=0.3715, LR=0.000100
[2025-08-27 14:21:33,883][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075064] [Batch 01144/03080] [00:14:25/00:24:24, 0.757s/it]: train_loss_raw=0.3901, running_loss=0.3700, LR=0.000100
[2025-08-27 14:21:39,959][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075072] [Batch 01152/03080] [00:14:31/00:24:18, 0.757s/it]: train_loss_raw=0.4743, running_loss=0.3715, LR=0.000100
[2025-08-27 14:21:46,038][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075080] [Batch 01160/03080] [00:14:37/00:24:12, 0.757s/it]: train_loss_raw=0.4089, running_loss=0.3726, LR=0.000100
[2025-08-27 14:21:52,048][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075088] [Batch 01168/03080] [00:14:43/00:24:06, 0.757s/it]: train_loss_raw=0.4189, running_loss=0.3736, LR=0.000100
[2025-08-27 14:21:58,081][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075096] [Batch 01176/03080] [00:14:49/00:24:00, 0.757s/it]: train_loss_raw=0.3221, running_loss=0.3703, LR=0.000100
[2025-08-27 14:22:04,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075104] [Batch 01184/03080] [00:14:55/00:23:54, 0.757s/it]: train_loss_raw=0.3893, running_loss=0.3705, LR=0.000100
[2025-08-27 14:22:10,184][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075112] [Batch 01192/03080] [00:15:01/00:23:48, 0.757s/it]: train_loss_raw=0.4458, running_loss=0.3725, LR=0.000100
[2025-08-27 14:22:16,222][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075120] [Batch 01200/03080] [00:15:07/00:23:42, 0.757s/it]: train_loss_raw=0.3106, running_loss=0.3708, LR=0.000100
[2025-08-27 14:22:22,214][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075128] [Batch 01208/03080] [00:15:13/00:23:36, 0.756s/it]: train_loss_raw=0.3459, running_loss=0.3708, LR=0.000100
[2025-08-27 14:22:27,815][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075136] [Batch 01216/03080] [00:15:19/00:23:29, 0.756s/it]: train_loss_raw=0.3439, running_loss=0.3726, LR=0.000100
[2025-08-27 14:22:33,337][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075144] [Batch 01224/03080] [00:15:24/00:23:22, 0.756s/it]: train_loss_raw=0.3766, running_loss=0.3715, LR=0.000100
[2025-08-27 14:22:39,163][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075152] [Batch 01232/03080] [00:15:30/00:23:16, 0.755s/it]: train_loss_raw=0.3003, running_loss=0.3723, LR=0.000100
[2025-08-27 14:22:45,141][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075160] [Batch 01240/03080] [00:15:36/00:23:09, 0.755s/it]: train_loss_raw=0.3585, running_loss=0.3729, LR=0.000100
[2025-08-27 14:22:51,147][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075168] [Batch 01248/03080] [00:15:42/00:23:03, 0.755s/it]: train_loss_raw=0.4699, running_loss=0.3725, LR=0.000100
[2025-08-27 14:22:57,141][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075176] [Batch 01256/03080] [00:15:48/00:22:57, 0.755s/it]: train_loss_raw=0.4117, running_loss=0.3734, LR=0.000100
[2025-08-27 14:23:03,115][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075184] [Batch 01264/03080] [00:15:54/00:22:51, 0.755s/it]: train_loss_raw=0.3550, running_loss=0.3718, LR=0.000100
[2025-08-27 14:23:09,157][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075192] [Batch 01272/03080] [00:16:00/00:22:45, 0.755s/it]: train_loss_raw=0.4009, running_loss=0.3711, LR=0.000100
[2025-08-27 14:23:15,297][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075200] [Batch 01280/03080] [00:16:06/00:22:39, 0.755s/it]: train_loss_raw=0.3729, running_loss=0.3720, LR=0.000100
[2025-08-27 14:23:21,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075208] [Batch 01288/03080] [00:16:12/00:22:33, 0.755s/it]: train_loss_raw=0.3617, running_loss=0.3717, LR=0.000100
[2025-08-27 14:23:27,467][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075216] [Batch 01296/03080] [00:16:19/00:22:27, 0.755s/it]: train_loss_raw=0.3281, running_loss=0.3699, LR=0.000100
[2025-08-27 14:23:33,490][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075224] [Batch 01304/03080] [00:16:25/00:22:21, 0.755s/it]: train_loss_raw=0.3920, running_loss=0.3683, LR=0.000100
[2025-08-27 14:23:39,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075232] [Batch 01312/03080] [00:16:30/00:22:15, 0.755s/it]: train_loss_raw=0.3649, running_loss=0.3679, LR=0.000100
[2025-08-27 14:23:44,861][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075240] [Batch 01320/03080] [00:16:36/00:22:08, 0.755s/it]: train_loss_raw=0.3507, running_loss=0.3713, LR=0.000100
[2025-08-27 14:23:50,841][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075248] [Batch 01328/03080] [00:16:42/00:22:02, 0.755s/it]: train_loss_raw=0.5379, running_loss=0.3725, LR=0.000100
[2025-08-27 14:23:56,344][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075256] [Batch 01336/03080] [00:16:47/00:21:55, 0.754s/it]: train_loss_raw=0.3864, running_loss=0.3744, LR=0.000100
[2025-08-27 14:24:02,308][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075264] [Batch 01344/03080] [00:16:53/00:21:49, 0.754s/it]: train_loss_raw=0.4076, running_loss=0.3760, LR=0.000100
[2025-08-27 14:24:08,361][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075272] [Batch 01352/03080] [00:16:59/00:21:43, 0.754s/it]: train_loss_raw=0.3670, running_loss=0.3749, LR=0.000100
[2025-08-27 14:24:14,336][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075280] [Batch 01360/03080] [00:17:05/00:21:37, 0.754s/it]: train_loss_raw=0.2637, running_loss=0.3744, LR=0.000100
[2025-08-27 14:24:20,371][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075288] [Batch 01368/03080] [00:17:11/00:21:31, 0.754s/it]: train_loss_raw=0.3524, running_loss=0.3751, LR=0.000100
[2025-08-27 14:24:26,543][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075296] [Batch 01376/03080] [00:17:18/00:21:25, 0.754s/it]: train_loss_raw=0.3159, running_loss=0.3737, LR=0.000100
[2025-08-27 14:24:32,571][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075304] [Batch 01384/03080] [00:17:24/00:21:19, 0.754s/it]: train_loss_raw=0.2665, running_loss=0.3723, LR=0.000100
[2025-08-27 14:24:38,527][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075312] [Batch 01392/03080] [00:17:30/00:21:13, 0.754s/it]: train_loss_raw=0.3255, running_loss=0.3724, LR=0.000100
[2025-08-27 14:24:44,475][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075320] [Batch 01400/03080] [00:17:36/00:21:07, 0.754s/it]: train_loss_raw=0.3029, running_loss=0.3707, LR=0.000100
[2025-08-27 14:24:50,515][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075328] [Batch 01408/03080] [00:17:42/00:21:01, 0.754s/it]: train_loss_raw=0.3600, running_loss=0.3687, LR=0.000100
[2025-08-27 14:24:56,607][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075336] [Batch 01416/03080] [00:17:48/00:20:55, 0.754s/it]: train_loss_raw=0.3942, running_loss=0.3698, LR=0.000100
[2025-08-27 14:25:02,604][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075344] [Batch 01424/03080] [00:17:54/00:20:49, 0.754s/it]: train_loss_raw=0.3818, running_loss=0.3688, LR=0.000100
[2025-08-27 14:25:08,615][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075352] [Batch 01432/03080] [00:18:00/00:20:43, 0.754s/it]: train_loss_raw=0.3804, running_loss=0.3693, LR=0.000100
[2025-08-27 14:25:14,593][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075360] [Batch 01440/03080] [00:18:06/00:20:37, 0.754s/it]: train_loss_raw=0.4798, running_loss=0.3714, LR=0.000100
[2025-08-27 14:25:20,327][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075368] [Batch 01448/03080] [00:18:11/00:20:30, 0.754s/it]: train_loss_raw=0.3257, running_loss=0.3712, LR=0.000100
[2025-08-27 14:25:25,737][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075376] [Batch 01456/03080] [00:18:17/00:20:23, 0.754s/it]: train_loss_raw=0.4103, running_loss=0.3735, LR=0.000100
[2025-08-27 14:25:31,164][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075384] [Batch 01464/03080] [00:18:22/00:20:17, 0.753s/it]: train_loss_raw=0.3503, running_loss=0.3728, LR=0.000100
[2025-08-27 14:25:37,046][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075392] [Batch 01472/03080] [00:18:28/00:20:11, 0.753s/it]: train_loss_raw=0.3745, running_loss=0.3726, LR=0.000100
[2025-08-27 14:25:43,068][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075400] [Batch 01480/03080] [00:18:34/00:20:05, 0.753s/it]: train_loss_raw=0.3956, running_loss=0.3724, LR=0.000100
[2025-08-27 14:25:48,866][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075408] [Batch 01488/03080] [00:18:40/00:19:58, 0.753s/it]: train_loss_raw=0.3578, running_loss=0.3732, LR=0.000100
[2025-08-27 14:25:54,730][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075416] [Batch 01496/03080] [00:18:46/00:19:52, 0.753s/it]: train_loss_raw=0.3902, running_loss=0.3726, LR=0.000100
[2025-08-27 14:26:00,902][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075424] [Batch 01504/03080] [00:18:52/00:19:46, 0.753s/it]: train_loss_raw=0.3951, running_loss=0.3708, LR=0.000100
[2025-08-27 14:26:07,003][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075432] [Batch 01512/03080] [00:18:58/00:19:40, 0.753s/it]: train_loss_raw=0.3568, running_loss=0.3702, LR=0.000100
[2025-08-27 14:26:12,976][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075440] [Batch 01520/03080] [00:19:04/00:19:34, 0.753s/it]: train_loss_raw=0.3681, running_loss=0.3708, LR=0.000100
[2025-08-27 14:26:18,949][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075448] [Batch 01528/03080] [00:19:10/00:19:28, 0.753s/it]: train_loss_raw=0.4059, running_loss=0.3731, LR=0.000100
[2025-08-27 14:26:24,915][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075456] [Batch 01536/03080] [00:19:16/00:19:22, 0.753s/it]: train_loss_raw=0.4490, running_loss=0.3716, LR=0.000100
[2025-08-27 14:26:30,932][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075464] [Batch 01544/03080] [00:19:22/00:19:16, 0.753s/it]: train_loss_raw=0.3711, running_loss=0.3728, LR=0.000100
[2025-08-27 14:26:36,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075472] [Batch 01552/03080] [00:19:28/00:19:10, 0.753s/it]: train_loss_raw=0.4127, running_loss=0.3728, LR=0.000100
[2025-08-27 14:26:43,011][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075480] [Batch 01560/03080] [00:19:34/00:19:04, 0.753s/it]: train_loss_raw=0.3066, running_loss=0.3741, LR=0.000100
[2025-08-27 14:26:49,114][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075488] [Batch 01568/03080] [00:19:40/00:18:58, 0.753s/it]: train_loss_raw=0.3612, running_loss=0.3749, LR=0.000100
[2025-08-27 14:26:55,213][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075496] [Batch 01576/03080] [00:19:46/00:18:52, 0.753s/it]: train_loss_raw=0.3674, running_loss=0.3763, LR=0.000100
[2025-08-27 14:27:01,231][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075504] [Batch 01584/03080] [00:19:52/00:18:46, 0.753s/it]: train_loss_raw=0.4046, running_loss=0.3776, LR=0.000100
[2025-08-27 14:27:07,398][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075512] [Batch 01592/03080] [00:19:58/00:18:40, 0.753s/it]: train_loss_raw=0.3734, running_loss=0.3786, LR=0.000100
[2025-08-27 14:27:13,392][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075520] [Batch 01600/03080] [00:20:04/00:18:34, 0.753s/it]: train_loss_raw=0.3567, running_loss=0.3791, LR=0.000100
[2025-08-27 14:27:18,859][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075528] [Batch 01608/03080] [00:20:10/00:18:28, 0.753s/it]: train_loss_raw=0.3563, running_loss=0.3789, LR=0.000100
[2025-08-27 14:27:24,454][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075536] [Batch 01616/03080] [00:20:16/00:18:21, 0.753s/it]: train_loss_raw=0.4491, running_loss=0.3787, LR=0.000100
[2025-08-27 14:27:30,476][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075544] [Batch 01624/03080] [00:20:22/00:18:15, 0.753s/it]: train_loss_raw=0.3656, running_loss=0.3779, LR=0.000100
[2025-08-27 14:27:36,355][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075552] [Batch 01632/03080] [00:20:27/00:18:09, 0.752s/it]: train_loss_raw=0.3139, running_loss=0.3774, LR=0.000100
[2025-08-27 14:27:42,416][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075560] [Batch 01640/03080] [00:20:34/00:18:03, 0.752s/it]: train_loss_raw=0.4375, running_loss=0.3763, LR=0.000100
[2025-08-27 14:27:48,591][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075568] [Batch 01648/03080] [00:20:40/00:17:57, 0.753s/it]: train_loss_raw=0.3004, running_loss=0.3762, LR=0.000100
[2025-08-27 14:27:54,710][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075576] [Batch 01656/03080] [00:20:46/00:17:51, 0.753s/it]: train_loss_raw=0.3275, running_loss=0.3780, LR=0.000100
[2025-08-27 14:28:00,782][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075584] [Batch 01664/03080] [00:20:52/00:17:45, 0.753s/it]: train_loss_raw=0.4037, running_loss=0.3780, LR=0.000100
[2025-08-27 14:28:06,745][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075592] [Batch 01672/03080] [00:20:58/00:17:39, 0.753s/it]: train_loss_raw=0.2852, running_loss=0.3769, LR=0.000100
[2025-08-27 14:28:12,708][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075600] [Batch 01680/03080] [00:21:04/00:17:33, 0.753s/it]: train_loss_raw=0.3480, running_loss=0.3763, LR=0.000100
[2025-08-27 14:28:18,641][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075608] [Batch 01688/03080] [00:21:10/00:17:27, 0.753s/it]: train_loss_raw=0.3169, running_loss=0.3761, LR=0.000100
[2025-08-27 14:28:24,579][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075616] [Batch 01696/03080] [00:21:16/00:17:21, 0.752s/it]: train_loss_raw=0.3769, running_loss=0.3751, LR=0.000100
[2025-08-27 14:28:30,605][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075624] [Batch 01704/03080] [00:21:22/00:17:15, 0.752s/it]: train_loss_raw=0.3630, running_loss=0.3751, LR=0.000100
[2025-08-27 14:28:36,835][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075632] [Batch 01712/03080] [00:21:28/00:17:09, 0.753s/it]: train_loss_raw=0.2885, running_loss=0.3743, LR=0.000100
[2025-08-27 14:28:42,975][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075640] [Batch 01720/03080] [00:21:34/00:17:03, 0.753s/it]: train_loss_raw=0.3508, running_loss=0.3740, LR=0.000100
[2025-08-27 14:28:49,155][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075648] [Batch 01728/03080] [00:21:40/00:16:57, 0.753s/it]: train_loss_raw=0.3426, running_loss=0.3746, LR=0.000100
[2025-08-27 14:28:55,194][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075656] [Batch 01736/03080] [00:21:46/00:16:51, 0.753s/it]: train_loss_raw=0.3505, running_loss=0.3751, LR=0.000100
[2025-08-27 14:29:01,194][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075664] [Batch 01744/03080] [00:21:52/00:16:45, 0.753s/it]: train_loss_raw=0.4590, running_loss=0.3747, LR=0.000100
[2025-08-27 14:29:07,225][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075672] [Batch 01752/03080] [00:21:58/00:16:39, 0.753s/it]: train_loss_raw=0.4376, running_loss=0.3753, LR=0.000100
[2025-08-27 14:29:13,400][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075680] [Batch 01760/03080] [00:22:04/00:16:33, 0.753s/it]: train_loss_raw=0.4025, running_loss=0.3757, LR=0.000100
[2025-08-27 14:29:19,439][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075688] [Batch 01768/03080] [00:22:11/00:16:27, 0.753s/it]: train_loss_raw=0.4260, running_loss=0.3758, LR=0.000100
[2025-08-27 14:29:25,484][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075696] [Batch 01776/03080] [00:22:17/00:16:21, 0.753s/it]: train_loss_raw=0.3499, running_loss=0.3770, LR=0.000100
[2025-08-27 14:29:31,365][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075704] [Batch 01784/03080] [00:22:22/00:16:15, 0.753s/it]: train_loss_raw=0.3616, running_loss=0.3768, LR=0.000100
[2025-08-27 14:29:37,272][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075712] [Batch 01792/03080] [00:22:28/00:16:09, 0.753s/it]: train_loss_raw=0.3265, running_loss=0.3764, LR=0.000100
[2025-08-27 14:29:43,033][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075720] [Batch 01800/03080] [00:22:34/00:16:03, 0.753s/it]: train_loss_raw=0.3614, running_loss=0.3745, LR=0.000100
[2025-08-27 14:29:49,009][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075728] [Batch 01808/03080] [00:22:40/00:15:57, 0.753s/it]: train_loss_raw=0.3927, running_loss=0.3756, LR=0.000100
[2025-08-27 14:29:54,937][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075736] [Batch 01816/03080] [00:22:46/00:15:51, 0.752s/it]: train_loss_raw=0.3417, running_loss=0.3765, LR=0.000100
[2025-08-27 14:30:00,929][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075744] [Batch 01824/03080] [00:22:52/00:15:45, 0.752s/it]: train_loss_raw=0.3247, running_loss=0.3731, LR=0.000100
[2025-08-27 14:30:06,891][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075752] [Batch 01832/03080] [00:22:58/00:15:39, 0.752s/it]: train_loss_raw=0.4183, running_loss=0.3736, LR=0.000100
[2025-08-27 14:30:12,813][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075760] [Batch 01840/03080] [00:23:04/00:15:32, 0.752s/it]: train_loss_raw=0.3209, running_loss=0.3728, LR=0.000100
[2025-08-27 14:30:18,792][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075768] [Batch 01848/03080] [00:23:10/00:15:26, 0.752s/it]: train_loss_raw=0.4014, running_loss=0.3707, LR=0.000100
[2025-08-27 14:30:24,739][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075776] [Batch 01856/03080] [00:23:16/00:15:20, 0.752s/it]: train_loss_raw=0.3093, running_loss=0.3677, LR=0.000100
[2025-08-27 14:30:30,709][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075784] [Batch 01864/03080] [00:23:22/00:15:14, 0.752s/it]: train_loss_raw=0.3843, running_loss=0.3685, LR=0.000100
[2025-08-27 14:30:36,690][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075792] [Batch 01872/03080] [00:23:28/00:15:08, 0.752s/it]: train_loss_raw=0.3911, running_loss=0.3678, LR=0.000100
[2025-08-27 14:30:42,720][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075800] [Batch 01880/03080] [00:23:34/00:15:02, 0.752s/it]: train_loss_raw=0.3787, running_loss=0.3658, LR=0.000100
[2025-08-27 14:30:48,748][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075808] [Batch 01888/03080] [00:23:40/00:14:56, 0.752s/it]: train_loss_raw=0.2949, running_loss=0.3677, LR=0.000100
[2025-08-27 14:30:54,828][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075816] [Batch 01896/03080] [00:23:46/00:14:50, 0.752s/it]: train_loss_raw=0.3969, running_loss=0.3686, LR=0.000100
[2025-08-27 14:31:00,802][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075824] [Batch 01904/03080] [00:23:52/00:14:44, 0.752s/it]: train_loss_raw=0.3983, running_loss=0.3679, LR=0.000100
[2025-08-27 14:31:06,678][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075832] [Batch 01912/03080] [00:23:58/00:14:38, 0.752s/it]: train_loss_raw=0.3666, running_loss=0.3673, LR=0.000100
[2025-08-27 14:31:12,651][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075840] [Batch 01920/03080] [00:24:04/00:14:32, 0.752s/it]: train_loss_raw=0.4064, running_loss=0.3670, LR=0.000100
[2025-08-27 14:31:18,560][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075848] [Batch 01928/03080] [00:24:10/00:14:26, 0.752s/it]: train_loss_raw=0.3636, running_loss=0.3662, LR=0.000100
[2025-08-27 14:31:24,523][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075856] [Batch 01936/03080] [00:24:16/00:14:20, 0.752s/it]: train_loss_raw=0.3580, running_loss=0.3667, LR=0.000100
[2025-08-27 14:31:30,627][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075864] [Batch 01944/03080] [00:24:22/00:14:14, 0.752s/it]: train_loss_raw=0.3724, running_loss=0.3673, LR=0.000100
[2025-08-27 14:31:36,720][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075872] [Batch 01952/03080] [00:24:28/00:14:08, 0.752s/it]: train_loss_raw=0.3869, running_loss=0.3674, LR=0.000100
[2025-08-27 14:31:42,711][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075880] [Batch 01960/03080] [00:24:34/00:14:02, 0.752s/it]: train_loss_raw=0.3337, running_loss=0.3678, LR=0.000100
[2025-08-27 14:31:48,920][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075888] [Batch 01968/03080] [00:24:40/00:13:56, 0.752s/it]: train_loss_raw=0.4256, running_loss=0.3693, LR=0.000100
[2025-08-27 14:31:55,139][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075896] [Batch 01976/03080] [00:24:46/00:13:50, 0.752s/it]: train_loss_raw=0.3709, running_loss=0.3702, LR=0.000100
[2025-08-27 14:32:01,014][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075904] [Batch 01984/03080] [00:24:52/00:13:44, 0.752s/it]: train_loss_raw=0.4168, running_loss=0.3705, LR=0.000100
[2025-08-27 14:32:07,131][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075912] [Batch 01992/03080] [00:24:58/00:13:38, 0.752s/it]: train_loss_raw=0.3203, running_loss=0.3706, LR=0.000100
[2025-08-27 14:32:13,110][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075920] [Batch 02000/03080] [00:25:04/00:13:32, 0.752s/it]: train_loss_raw=0.3074, running_loss=0.3686, LR=0.000100
[2025-08-27 14:32:19,189][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075928] [Batch 02008/03080] [00:25:10/00:13:26, 0.752s/it]: train_loss_raw=0.3748, running_loss=0.3689, LR=0.000100
[2025-08-27 14:32:25,242][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075936] [Batch 02016/03080] [00:25:16/00:13:20, 0.752s/it]: train_loss_raw=0.4236, running_loss=0.3693, LR=0.000100
[2025-08-27 14:32:31,314][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075944] [Batch 02024/03080] [00:25:22/00:13:14, 0.752s/it]: train_loss_raw=0.3351, running_loss=0.3707, LR=0.000100
[2025-08-27 14:32:37,426][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075952] [Batch 02032/03080] [00:25:29/00:13:08, 0.752s/it]: train_loss_raw=0.3314, running_loss=0.3694, LR=0.000100
[2025-08-27 14:32:43,411][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075960] [Batch 02040/03080] [00:25:35/00:13:02, 0.752s/it]: train_loss_raw=0.3856, running_loss=0.3703, LR=0.000100
[2025-08-27 14:32:49,247][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075968] [Batch 02048/03080] [00:25:40/00:12:56, 0.752s/it]: train_loss_raw=0.4101, running_loss=0.3724, LR=0.000100
[2025-08-27 14:32:55,179][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075976] [Batch 02056/03080] [00:25:46/00:12:50, 0.752s/it]: train_loss_raw=0.2868, running_loss=0.3707, LR=0.000100
[2025-08-27 14:33:01,342][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075984] [Batch 02064/03080] [00:25:52/00:12:44, 0.752s/it]: train_loss_raw=0.4140, running_loss=0.3726, LR=0.000100
[2025-08-27 14:33:07,397][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 075992] [Batch 02072/03080] [00:25:58/00:12:38, 0.752s/it]: train_loss_raw=0.3886, running_loss=0.3737, LR=0.000100
[2025-08-27 14:33:13,387][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076000] [Batch 02080/03080] [00:26:04/00:12:32, 0.752s/it]: train_loss_raw=0.3204, running_loss=0.3734, LR=0.000100
[2025-08-27 14:33:23,568][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076008] [Batch 02088/03080] [00:26:15/00:12:28, 0.754s/it]: train_loss_raw=0.4083, running_loss=0.3748, LR=0.000100
[2025-08-27 14:33:29,124][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076016] [Batch 02096/03080] [00:26:20/00:12:22, 0.754s/it]: train_loss_raw=0.3820, running_loss=0.3759, LR=0.000100
[2025-08-27 14:33:34,959][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076024] [Batch 02104/03080] [00:26:26/00:12:15, 0.754s/it]: train_loss_raw=0.3731, running_loss=0.3743, LR=0.000100
[2025-08-27 14:33:41,013][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076032] [Batch 02112/03080] [00:26:32/00:12:09, 0.754s/it]: train_loss_raw=0.2729, running_loss=0.3748, LR=0.000100
[2025-08-27 14:33:47,353][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076040] [Batch 02120/03080] [00:26:38/00:12:04, 0.754s/it]: train_loss_raw=0.2858, running_loss=0.3729, LR=0.000100
[2025-08-27 14:33:53,376][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076048] [Batch 02128/03080] [00:26:44/00:11:58, 0.754s/it]: train_loss_raw=0.2841, running_loss=0.3711, LR=0.000100
[2025-08-27 14:33:59,258][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076056] [Batch 02136/03080] [00:26:50/00:11:51, 0.754s/it]: train_loss_raw=0.2948, running_loss=0.3724, LR=0.000100
[2025-08-27 14:34:04,867][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076064] [Batch 02144/03080] [00:26:56/00:11:45, 0.754s/it]: train_loss_raw=0.3506, running_loss=0.3743, LR=0.000100
[2025-08-27 14:34:10,838][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076072] [Batch 02152/03080] [00:27:02/00:11:39, 0.754s/it]: train_loss_raw=0.3997, running_loss=0.3739, LR=0.000100
[2025-08-27 14:34:16,267][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076080] [Batch 02160/03080] [00:27:07/00:11:33, 0.754s/it]: train_loss_raw=0.2816, running_loss=0.3719, LR=0.000100
[2025-08-27 14:34:22,017][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076088] [Batch 02168/03080] [00:27:13/00:11:27, 0.754s/it]: train_loss_raw=0.3748, running_loss=0.3698, LR=0.000100
[2025-08-27 14:34:27,963][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076096] [Batch 02176/03080] [00:27:19/00:11:21, 0.753s/it]: train_loss_raw=0.3091, running_loss=0.3688, LR=0.000100
[2025-08-27 14:34:33,990][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076104] [Batch 02184/03080] [00:27:25/00:11:15, 0.753s/it]: train_loss_raw=0.3743, running_loss=0.3699, LR=0.000100
[2025-08-27 14:34:39,790][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076112] [Batch 02192/03080] [00:27:31/00:11:08, 0.753s/it]: train_loss_raw=0.4018, running_loss=0.3723, LR=0.000100
[2025-08-27 14:34:45,850][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076120] [Batch 02200/03080] [00:27:37/00:11:02, 0.753s/it]: train_loss_raw=0.3585, running_loss=0.3719, LR=0.000100
[2025-08-27 14:34:51,558][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076128] [Batch 02208/03080] [00:27:43/00:10:56, 0.753s/it]: train_loss_raw=0.3697, running_loss=0.3728, LR=0.000100
[2025-08-27 14:34:57,537][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076136] [Batch 02216/03080] [00:27:49/00:10:50, 0.753s/it]: train_loss_raw=0.3266, running_loss=0.3724, LR=0.000100
[2025-08-27 14:35:03,712][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076144] [Batch 02224/03080] [00:27:55/00:10:44, 0.753s/it]: train_loss_raw=0.3539, running_loss=0.3733, LR=0.000100
[2025-08-27 14:35:09,991][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076152] [Batch 02232/03080] [00:28:01/00:10:38, 0.753s/it]: train_loss_raw=0.3942, running_loss=0.3747, LR=0.000100
[2025-08-27 14:35:16,026][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076160] [Batch 02240/03080] [00:28:07/00:10:32, 0.753s/it]: train_loss_raw=0.3658, running_loss=0.3770, LR=0.000100
[2025-08-27 14:35:22,000][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076168] [Batch 02248/03080] [00:28:13/00:10:26, 0.753s/it]: train_loss_raw=0.3819, running_loss=0.3758, LR=0.000100
[2025-08-27 14:35:27,911][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076176] [Batch 02256/03080] [00:28:19/00:10:20, 0.753s/it]: train_loss_raw=0.3228, running_loss=0.3735, LR=0.000100
[2025-08-27 14:35:33,810][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076184] [Batch 02264/03080] [00:28:25/00:10:14, 0.753s/it]: train_loss_raw=0.3387, running_loss=0.3730, LR=0.000100
[2025-08-27 14:35:39,847][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076192] [Batch 02272/03080] [00:28:31/00:10:08, 0.753s/it]: train_loss_raw=0.3312, running_loss=0.3736, LR=0.000100
[2025-08-27 14:35:45,811][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076200] [Batch 02280/03080] [00:28:37/00:10:02, 0.753s/it]: train_loss_raw=0.3768, running_loss=0.3719, LR=0.000100
[2025-08-27 14:35:51,849][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076208] [Batch 02288/03080] [00:28:43/00:09:56, 0.753s/it]: train_loss_raw=0.3249, running_loss=0.3727, LR=0.000100
[2025-08-27 14:35:57,887][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076216] [Batch 02296/03080] [00:28:49/00:09:50, 0.753s/it]: train_loss_raw=0.4085, running_loss=0.3716, LR=0.000100
[2025-08-27 14:36:03,963][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076224] [Batch 02304/03080] [00:28:55/00:09:44, 0.753s/it]: train_loss_raw=0.3647, running_loss=0.3732, LR=0.000100
[2025-08-27 14:36:09,616][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076232] [Batch 02312/03080] [00:29:01/00:09:38, 0.753s/it]: train_loss_raw=0.3259, running_loss=0.3730, LR=0.000100
[2025-08-27 14:36:15,272][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076240] [Batch 02320/03080] [00:29:06/00:09:32, 0.753s/it]: train_loss_raw=0.3155, running_loss=0.3722, LR=0.000100
[2025-08-27 14:36:20,808][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076248] [Batch 02328/03080] [00:29:12/00:09:26, 0.753s/it]: train_loss_raw=0.3864, running_loss=0.3723, LR=0.000100
[2025-08-27 14:36:26,580][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076256] [Batch 02336/03080] [00:29:18/00:09:19, 0.753s/it]: train_loss_raw=0.3840, running_loss=0.3714, LR=0.000100
[2025-08-27 14:36:32,628][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076264] [Batch 02344/03080] [00:29:24/00:09:13, 0.753s/it]: train_loss_raw=0.4270, running_loss=0.3730, LR=0.000100
[2025-08-27 14:36:38,713][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076272] [Batch 02352/03080] [00:29:30/00:09:07, 0.753s/it]: train_loss_raw=0.4035, running_loss=0.3738, LR=0.000100
[2025-08-27 14:36:44,700][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076280] [Batch 02360/03080] [00:29:36/00:09:01, 0.753s/it]: train_loss_raw=0.3634, running_loss=0.3745, LR=0.000100
[2025-08-27 14:36:50,712][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076288] [Batch 02368/03080] [00:29:42/00:08:55, 0.753s/it]: train_loss_raw=0.3533, running_loss=0.3739, LR=0.000100
[2025-08-27 14:36:56,765][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076296] [Batch 02376/03080] [00:29:48/00:08:49, 0.753s/it]: train_loss_raw=0.3127, running_loss=0.3720, LR=0.000100
[2025-08-27 14:37:02,900][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076304] [Batch 02384/03080] [00:29:54/00:08:43, 0.753s/it]: train_loss_raw=0.4092, running_loss=0.3721, LR=0.000100
[2025-08-27 14:37:09,078][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076312] [Batch 02392/03080] [00:30:00/00:08:37, 0.753s/it]: train_loss_raw=0.3442, running_loss=0.3715, LR=0.000100
[2025-08-27 14:37:15,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076320] [Batch 02400/03080] [00:30:06/00:08:31, 0.753s/it]: train_loss_raw=0.3428, running_loss=0.3723, LR=0.000100
[2025-08-27 14:37:21,209][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076328] [Batch 02408/03080] [00:30:12/00:08:25, 0.753s/it]: train_loss_raw=0.3322, running_loss=0.3722, LR=0.000100
[2025-08-27 14:37:27,107][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076336] [Batch 02416/03080] [00:30:18/00:08:19, 0.753s/it]: train_loss_raw=0.3443, running_loss=0.3709, LR=0.000100
[2025-08-27 14:37:33,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076344] [Batch 02424/03080] [00:30:24/00:08:13, 0.753s/it]: train_loss_raw=0.3989, running_loss=0.3719, LR=0.000100
[2025-08-27 14:37:39,117][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076352] [Batch 02432/03080] [00:30:30/00:08:07, 0.753s/it]: train_loss_raw=0.3565, running_loss=0.3724, LR=0.000100
[2025-08-27 14:37:44,926][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076360] [Batch 02440/03080] [00:30:36/00:08:01, 0.753s/it]: train_loss_raw=0.3633, running_loss=0.3720, LR=0.000100
[2025-08-27 14:37:50,880][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076368] [Batch 02448/03080] [00:30:42/00:07:55, 0.753s/it]: train_loss_raw=0.4289, running_loss=0.3750, LR=0.000100
[2025-08-27 14:37:56,828][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076376] [Batch 02456/03080] [00:30:48/00:07:49, 0.753s/it]: train_loss_raw=0.3969, running_loss=0.3748, LR=0.000100
[2025-08-27 14:38:02,893][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076384] [Batch 02464/03080] [00:30:54/00:07:43, 0.753s/it]: train_loss_raw=0.3739, running_loss=0.3747, LR=0.000100
[2025-08-27 14:38:08,986][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076392] [Batch 02472/03080] [00:31:00/00:07:37, 0.753s/it]: train_loss_raw=0.2346, running_loss=0.3727, LR=0.000100
[2025-08-27 14:38:15,007][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076400] [Batch 02480/03080] [00:31:06/00:07:31, 0.753s/it]: train_loss_raw=0.3255, running_loss=0.3735, LR=0.000100
[2025-08-27 14:38:21,024][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076408] [Batch 02488/03080] [00:31:12/00:07:25, 0.753s/it]: train_loss_raw=0.3321, running_loss=0.3731, LR=0.000100
[2025-08-27 14:38:27,097][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076416] [Batch 02496/03080] [00:31:18/00:07:19, 0.753s/it]: train_loss_raw=0.3628, running_loss=0.3718, LR=0.000100
[2025-08-27 14:38:33,227][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076424] [Batch 02504/03080] [00:31:24/00:07:13, 0.753s/it]: train_loss_raw=0.3614, running_loss=0.3700, LR=0.000100
[2025-08-27 14:38:39,350][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076432] [Batch 02512/03080] [00:31:30/00:07:07, 0.753s/it]: train_loss_raw=0.3332, running_loss=0.3705, LR=0.000100
[2025-08-27 14:38:45,440][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076440] [Batch 02520/03080] [00:31:37/00:07:01, 0.753s/it]: train_loss_raw=0.3854, running_loss=0.3703, LR=0.000100
[2025-08-27 14:38:51,494][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076448] [Batch 02528/03080] [00:31:43/00:06:55, 0.753s/it]: train_loss_raw=0.4213, running_loss=0.3715, LR=0.000100
[2025-08-27 14:38:57,469][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076456] [Batch 02536/03080] [00:31:49/00:06:49, 0.753s/it]: train_loss_raw=0.4420, running_loss=0.3723, LR=0.000100
[2025-08-27 14:39:03,625][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076464] [Batch 02544/03080] [00:31:55/00:06:43, 0.753s/it]: train_loss_raw=0.3154, running_loss=0.3717, LR=0.000100
[2025-08-27 14:39:09,556][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076472] [Batch 02552/03080] [00:32:01/00:06:37, 0.753s/it]: train_loss_raw=0.3575, running_loss=0.3721, LR=0.000100
[2025-08-27 14:39:15,192][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076480] [Batch 02560/03080] [00:32:06/00:06:31, 0.753s/it]: train_loss_raw=0.3749, running_loss=0.3731, LR=0.000100
[2025-08-27 14:39:21,265][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076488] [Batch 02568/03080] [00:32:12/00:06:25, 0.753s/it]: train_loss_raw=0.4646, running_loss=0.3742, LR=0.000100
[2025-08-27 14:39:27,255][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076496] [Batch 02576/03080] [00:32:18/00:06:19, 0.753s/it]: train_loss_raw=0.3669, running_loss=0.3740, LR=0.000100
[2025-08-27 14:39:33,345][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076504] [Batch 02584/03080] [00:32:24/00:06:13, 0.753s/it]: train_loss_raw=0.3432, running_loss=0.3739, LR=0.000100
[2025-08-27 14:39:39,284][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076512] [Batch 02592/03080] [00:32:30/00:06:07, 0.753s/it]: train_loss_raw=0.3780, running_loss=0.3745, LR=0.000100
[2025-08-27 14:39:44,835][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076520] [Batch 02600/03080] [00:32:36/00:06:01, 0.752s/it]: train_loss_raw=0.4031, running_loss=0.3740, LR=0.000100
[2025-08-27 14:39:50,680][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076528] [Batch 02608/03080] [00:32:42/00:05:55, 0.752s/it]: train_loss_raw=0.3367, running_loss=0.3736, LR=0.000100
[2025-08-27 14:39:56,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076536] [Batch 02616/03080] [00:32:47/00:05:49, 0.752s/it]: train_loss_raw=0.3509, running_loss=0.3725, LR=0.000100
[2025-08-27 14:40:02,374][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076544] [Batch 02624/03080] [00:32:53/00:05:43, 0.752s/it]: train_loss_raw=0.3497, running_loss=0.3699, LR=0.000100
[2025-08-27 14:40:08,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076552] [Batch 02632/03080] [00:32:59/00:05:37, 0.752s/it]: train_loss_raw=0.3748, running_loss=0.3705, LR=0.000100
[2025-08-27 14:40:13,801][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076560] [Batch 02640/03080] [00:33:05/00:05:30, 0.752s/it]: train_loss_raw=0.3877, running_loss=0.3701, LR=0.000100
[2025-08-27 14:40:19,518][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076568] [Batch 02648/03080] [00:33:11/00:05:24, 0.752s/it]: train_loss_raw=0.3067, running_loss=0.3695, LR=0.000100
[2025-08-27 14:40:25,410][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076576] [Batch 02656/03080] [00:33:17/00:05:18, 0.752s/it]: train_loss_raw=0.3310, running_loss=0.3702, LR=0.000100
[2025-08-27 14:40:30,826][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076584] [Batch 02664/03080] [00:33:22/00:05:12, 0.752s/it]: train_loss_raw=0.3315, running_loss=0.3705, LR=0.000100
[2025-08-27 14:40:36,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076592] [Batch 02672/03080] [00:33:28/00:05:06, 0.752s/it]: train_loss_raw=0.3791, running_loss=0.3702, LR=0.000100
[2025-08-27 14:40:42,189][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076600] [Batch 02680/03080] [00:33:33/00:05:00, 0.751s/it]: train_loss_raw=0.4282, running_loss=0.3697, LR=0.000100
[2025-08-27 14:40:48,129][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076608] [Batch 02688/03080] [00:33:39/00:04:54, 0.751s/it]: train_loss_raw=0.3598, running_loss=0.3687, LR=0.000100
[2025-08-27 14:40:53,820][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076616] [Batch 02696/03080] [00:33:45/00:04:48, 0.751s/it]: train_loss_raw=0.3265, running_loss=0.3737, LR=0.000100
[2025-08-27 14:40:59,365][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076624] [Batch 02704/03080] [00:33:50/00:04:42, 0.751s/it]: train_loss_raw=0.3751, running_loss=0.3716, LR=0.000100
[2025-08-27 14:41:05,099][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076632] [Batch 02712/03080] [00:33:56/00:04:36, 0.751s/it]: train_loss_raw=0.2927, running_loss=0.3702, LR=0.000100
[2025-08-27 14:41:11,338][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076640] [Batch 02720/03080] [00:34:02/00:04:30, 0.751s/it]: train_loss_raw=0.3438, running_loss=0.3724, LR=0.000100
[2025-08-27 14:41:17,236][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076648] [Batch 02728/03080] [00:34:08/00:04:24, 0.751s/it]: train_loss_raw=0.4094, running_loss=0.3736, LR=0.000100
[2025-08-27 14:41:23,170][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076656] [Batch 02736/03080] [00:34:14/00:04:18, 0.751s/it]: train_loss_raw=0.4038, running_loss=0.3753, LR=0.000100
[2025-08-27 14:41:28,670][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076664] [Batch 02744/03080] [00:34:20/00:04:12, 0.751s/it]: train_loss_raw=0.3179, running_loss=0.3748, LR=0.000100
[2025-08-27 14:41:34,656][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076672] [Batch 02752/03080] [00:34:26/00:04:06, 0.751s/it]: train_loss_raw=0.4244, running_loss=0.3748, LR=0.000100
[2025-08-27 14:41:40,648][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076680] [Batch 02760/03080] [00:34:32/00:04:00, 0.751s/it]: train_loss_raw=0.3388, running_loss=0.3730, LR=0.000100
[2025-08-27 14:41:46,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076688] [Batch 02768/03080] [00:34:37/00:03:54, 0.751s/it]: train_loss_raw=0.4156, running_loss=0.3732, LR=0.000100
[2025-08-27 14:41:52,427][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076696] [Batch 02776/03080] [00:34:44/00:03:48, 0.751s/it]: train_loss_raw=0.3661, running_loss=0.3743, LR=0.000100
[2025-08-27 14:41:58,539][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076704] [Batch 02784/03080] [00:34:50/00:03:42, 0.751s/it]: train_loss_raw=0.4022, running_loss=0.3750, LR=0.000100
[2025-08-27 14:42:04,833][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076712] [Batch 02792/03080] [00:34:56/00:03:36, 0.751s/it]: train_loss_raw=0.4239, running_loss=0.3753, LR=0.000100
[2025-08-27 14:42:10,779][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076720] [Batch 02800/03080] [00:35:02/00:03:30, 0.751s/it]: train_loss_raw=0.3994, running_loss=0.3754, LR=0.000100
[2025-08-27 14:42:16,663][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076728] [Batch 02808/03080] [00:35:08/00:03:24, 0.751s/it]: train_loss_raw=0.3889, running_loss=0.3749, LR=0.000100
[2025-08-27 14:42:22,536][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076736] [Batch 02816/03080] [00:35:14/00:03:18, 0.751s/it]: train_loss_raw=0.3548, running_loss=0.3748, LR=0.000100
[2025-08-27 14:42:28,544][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076744] [Batch 02824/03080] [00:35:20/00:03:12, 0.751s/it]: train_loss_raw=0.3334, running_loss=0.3712, LR=0.000100
[2025-08-27 14:42:34,092][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076752] [Batch 02832/03080] [00:35:25/00:03:06, 0.751s/it]: train_loss_raw=0.3700, running_loss=0.3724, LR=0.000100
[2025-08-27 14:42:39,687][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076760] [Batch 02840/03080] [00:35:31/00:03:00, 0.750s/it]: train_loss_raw=0.3445, running_loss=0.3734, LR=0.000100
[2025-08-27 14:42:45,728][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076768] [Batch 02848/03080] [00:35:37/00:02:54, 0.750s/it]: train_loss_raw=0.3858, running_loss=0.3735, LR=0.000100
[2025-08-27 14:42:51,612][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076776] [Batch 02856/03080] [00:35:43/00:02:48, 0.750s/it]: train_loss_raw=0.3885, running_loss=0.3750, LR=0.000100
[2025-08-27 14:42:57,821][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076784] [Batch 02864/03080] [00:35:49/00:02:42, 0.750s/it]: train_loss_raw=0.3278, running_loss=0.3741, LR=0.000100
[2025-08-27 14:43:03,877][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076792] [Batch 02872/03080] [00:35:55/00:02:36, 0.751s/it]: train_loss_raw=0.3829, running_loss=0.3752, LR=0.000100
[2025-08-27 14:43:09,882][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076800] [Batch 02880/03080] [00:36:01/00:02:30, 0.751s/it]: train_loss_raw=0.2985, running_loss=0.3724, LR=0.000100
[2025-08-27 14:43:15,809][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076808] [Batch 02888/03080] [00:36:07/00:02:24, 0.750s/it]: train_loss_raw=0.3493, running_loss=0.3720, LR=0.000100
[2025-08-27 14:43:22,069][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076816] [Batch 02896/03080] [00:36:13/00:02:18, 0.751s/it]: train_loss_raw=0.3356, running_loss=0.3715, LR=0.000100
[2025-08-27 14:43:28,181][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076824] [Batch 02904/03080] [00:36:19/00:02:12, 0.751s/it]: train_loss_raw=0.4594, running_loss=0.3724, LR=0.000100
[2025-08-27 14:43:34,538][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076832] [Batch 02912/03080] [00:36:26/00:02:06, 0.751s/it]: train_loss_raw=0.3364, running_loss=0.3721, LR=0.000100
[2025-08-27 14:43:40,663][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076840] [Batch 02920/03080] [00:36:32/00:02:00, 0.751s/it]: train_loss_raw=0.3385, running_loss=0.3707, LR=0.000100
[2025-08-27 14:43:46,717][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076848] [Batch 02928/03080] [00:36:38/00:01:54, 0.751s/it]: train_loss_raw=0.3630, running_loss=0.3692, LR=0.000100
[2025-08-27 14:43:52,786][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076856] [Batch 02936/03080] [00:36:44/00:01:48, 0.751s/it]: train_loss_raw=0.2910, running_loss=0.3684, LR=0.000100
[2025-08-27 14:43:58,847][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076864] [Batch 02944/03080] [00:36:50/00:01:42, 0.751s/it]: train_loss_raw=0.3609, running_loss=0.3682, LR=0.000100
[2025-08-27 14:44:04,705][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076872] [Batch 02952/03080] [00:36:56/00:01:36, 0.751s/it]: train_loss_raw=0.4403, running_loss=0.3696, LR=0.000100
[2025-08-27 14:44:10,414][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076880] [Batch 02960/03080] [00:37:02/00:01:30, 0.751s/it]: train_loss_raw=0.5152, running_loss=0.3714, LR=0.000100
[2025-08-27 14:44:16,575][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076888] [Batch 02968/03080] [00:37:08/00:01:24, 0.751s/it]: train_loss_raw=0.3582, running_loss=0.3696, LR=0.000100
[2025-08-27 14:44:22,736][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076896] [Batch 02976/03080] [00:37:14/00:01:18, 0.751s/it]: train_loss_raw=0.3548, running_loss=0.3708, LR=0.000100
[2025-08-27 14:44:28,847][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076904] [Batch 02984/03080] [00:37:20/00:01:12, 0.751s/it]: train_loss_raw=0.2958, running_loss=0.3693, LR=0.000100
[2025-08-27 14:44:34,666][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076912] [Batch 02992/03080] [00:37:26/00:01:06, 0.751s/it]: train_loss_raw=0.3593, running_loss=0.3691, LR=0.000100
[2025-08-27 14:44:40,693][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076920] [Batch 03000/03080] [00:37:32/00:01:00, 0.751s/it]: train_loss_raw=0.3874, running_loss=0.3702, LR=0.000100
[2025-08-27 14:44:46,571][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076928] [Batch 03008/03080] [00:37:38/00:00:54, 0.751s/it]: train_loss_raw=0.3340, running_loss=0.3710, LR=0.000100
[2025-08-27 14:44:52,777][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076936] [Batch 03016/03080] [00:37:44/00:00:48, 0.751s/it]: train_loss_raw=0.3125, running_loss=0.3708, LR=0.000100
[2025-08-27 14:44:58,957][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076944] [Batch 03024/03080] [00:37:50/00:00:42, 0.751s/it]: train_loss_raw=0.4283, running_loss=0.3713, LR=0.000100
[2025-08-27 14:45:04,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076952] [Batch 03032/03080] [00:37:56/00:00:36, 0.751s/it]: train_loss_raw=0.3280, running_loss=0.3721, LR=0.000100
[2025-08-27 14:45:10,775][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076960] [Batch 03040/03080] [00:38:02/00:00:30, 0.751s/it]: train_loss_raw=0.4084, running_loss=0.3721, LR=0.000100
[2025-08-27 14:45:16,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076968] [Batch 03048/03080] [00:38:08/00:00:24, 0.751s/it]: train_loss_raw=0.3992, running_loss=0.3734, LR=0.000100
[2025-08-27 14:45:22,859][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076976] [Batch 03056/03080] [00:38:14/00:00:18, 0.751s/it]: train_loss_raw=0.3820, running_loss=0.3703, LR=0.000100
[2025-08-27 14:45:28,947][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076984] [Batch 03064/03080] [00:38:20/00:00:12, 0.751s/it]: train_loss_raw=0.4186, running_loss=0.3689, LR=0.000100
[2025-08-27 14:45:34,552][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 076992] [Batch 03072/03080] [00:38:26/00:00:06, 0.751s/it]: train_loss_raw=0.3515, running_loss=0.3697, LR=0.000100
[2025-08-27 14:45:40,622][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 077000] [Batch 03080/03080] [00:38:32/00:00:00, 0.751s/it]: train_loss_raw=0.3396, running_loss=0.3695, LR=0.000100
[2025-08-27 14:45:41,151][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-27 14:45:52,423][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00007/00310] [00:00:11/00:07:05, 1.409s/it]
[2025-08-27 14:46:04,732][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00015/00310] [00:00:23/00:07:13, 1.474s/it]
[2025-08-27 14:46:17,168][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00023/00310] [00:00:36/00:07:09, 1.501s/it]
[2025-08-27 14:46:29,463][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00031/00310] [00:00:48/00:06:59, 1.510s/it]
[2025-08-27 14:46:41,032][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00039/00310] [00:00:59/00:06:44, 1.497s/it]
[2025-08-27 14:46:52,933][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00047/00310] [00:01:11/00:06:31, 1.495s/it]
[2025-08-27 14:47:05,337][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00055/00310] [00:01:24/00:06:21, 1.503s/it]
[2025-08-27 14:47:17,023][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00063/00310] [00:01:35/00:06:08, 1.498s/it]
[2025-08-27 14:47:28,541][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00071/00310] [00:01:47/00:05:54, 1.492s/it]
[2025-08-27 14:47:40,160][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00079/00310] [00:01:59/00:05:42, 1.488s/it]
[2025-08-27 14:47:52,363][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00087/00310] [00:02:11/00:05:31, 1.491s/it]
[2025-08-27 14:48:04,283][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00095/00310] [00:02:23/00:05:19, 1.491s/it]
[2025-08-27 14:48:16,355][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00103/00310] [00:02:35/00:05:07, 1.492s/it]
[2025-08-27 14:48:28,985][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00111/00310] [00:02:47/00:04:56, 1.499s/it]
[2025-08-27 14:48:40,914][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00119/00310] [00:02:59/00:04:44, 1.498s/it]
[2025-08-27 14:48:53,236][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00127/00310] [00:03:12/00:04:33, 1.501s/it]
[2025-08-27 14:49:05,053][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00135/00310] [00:03:23/00:04:20, 1.499s/it]
[2025-08-27 14:49:18,121][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00143/00310] [00:03:36/00:04:10, 1.507s/it]
[2025-08-27 14:49:28,092][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00151/00310] [00:03:46/00:03:55, 1.493s/it]
[2025-08-27 14:49:39,064][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00159/00310] [00:03:57/00:03:43, 1.487s/it]
[2025-08-27 14:49:51,557][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00167/00310] [00:04:10/00:03:31, 1.491s/it]
[2025-08-27 14:50:00,780][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00175/00310] [00:04:19/00:03:17, 1.475s/it]
[2025-08-27 14:50:11,646][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00183/00310] [00:04:30/00:03:05, 1.470s/it]
[2025-08-27 14:50:23,070][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00191/00310] [00:04:41/00:02:53, 1.468s/it]
[2025-08-27 14:50:34,442][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00199/00310] [00:04:53/00:02:41, 1.466s/it]
[2025-08-27 14:50:44,134][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00207/00310] [00:05:02/00:02:28, 1.457s/it]
[2025-08-27 14:50:54,540][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00215/00310] [00:05:13/00:02:16, 1.451s/it]
[2025-08-27 14:51:06,016][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00223/00310] [00:05:24/00:02:04, 1.450s/it]
[2025-08-27 14:51:18,819][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00231/00310] [00:05:37/00:01:53, 1.455s/it]
[2025-08-27 14:51:30,939][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00239/00310] [00:05:49/00:01:42, 1.457s/it]
[2025-08-27 14:51:41,340][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00247/00310] [00:06:00/00:01:30, 1.452s/it]
[2025-08-27 14:51:52,269][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00255/00310] [00:06:11/00:01:18, 1.450s/it]
[2025-08-27 14:52:03,707][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00263/00310] [00:06:22/00:01:06, 1.449s/it]
[2025-08-27 14:52:15,429][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00271/00310] [00:06:34/00:00:55, 1.450s/it]
[2025-08-27 14:52:26,802][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00279/00310] [00:06:45/00:00:43, 1.449s/it]
[2025-08-27 14:52:38,587][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00287/00310] [00:06:57/00:00:31, 1.449s/it]
[2025-08-27 14:52:48,622][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00295/00310] [00:07:07/00:00:20, 1.444s/it]
[2025-08-27 14:53:00,780][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 077001] [Batch 00303/00310] [00:07:19/00:00:08, 1.446s/it]
[2025-08-27 14:53:09,954][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.36948, valid_loss=1.44750
[2025-08-27 14:53:09,954][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-27 14:53:09,954][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.488
[2025-08-27 14:53:09,954][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.150
[2025-08-27 14:53:09,954][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.154
[2025-08-27 14:53:09,955][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.082
[2025-08-27 14:53:09,970][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 19:26:23, remaining time 03:53:16, 00:46:39 per epoch
[2025-08-27 14:53:15,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077008] [Batch 00008/03080] [00:00:05/00:35:27, 0.692s/it]: train_loss_raw=0.3682, running_loss=0.3985, LR=0.000100
[2025-08-27 14:53:22,061][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077016] [Batch 00016/03080] [00:00:11/00:37:40, 0.738s/it]: train_loss_raw=0.3338, running_loss=0.3955, LR=0.000100
[2025-08-27 14:53:27,623][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077024] [Batch 00024/03080] [00:00:17/00:36:51, 0.724s/it]: train_loss_raw=0.3680, running_loss=0.3929, LR=0.000100
[2025-08-27 14:53:33,650][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077032] [Batch 00032/03080] [00:00:23/00:37:08, 0.731s/it]: train_loss_raw=0.2660, running_loss=0.3904, LR=0.000100
[2025-08-27 14:53:39,309][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077040] [Batch 00040/03080] [00:00:29/00:36:48, 0.726s/it]: train_loss_raw=0.3937, running_loss=0.3895, LR=0.000100
[2025-08-27 14:53:45,337][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077048] [Batch 00048/03080] [00:00:35/00:36:55, 0.731s/it]: train_loss_raw=0.3732, running_loss=0.3886, LR=0.000100
[2025-08-27 14:53:51,121][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077056] [Batch 00056/03080] [00:00:40/00:36:46, 0.730s/it]: train_loss_raw=0.4210, running_loss=0.3884, LR=0.000100
[2025-08-27 14:53:56,927][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077064] [Batch 00064/03080] [00:00:46/00:36:39, 0.729s/it]: train_loss_raw=0.3160, running_loss=0.3878, LR=0.000100
[2025-08-27 14:54:02,678][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077072] [Batch 00072/03080] [00:00:52/00:36:30, 0.728s/it]: train_loss_raw=0.4168, running_loss=0.3868, LR=0.000100
[2025-08-27 14:54:08,185][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077080] [Batch 00080/03080] [00:00:57/00:36:12, 0.724s/it]: train_loss_raw=0.4101, running_loss=0.3866, LR=0.000100
[2025-08-27 14:54:13,815][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077088] [Batch 00088/03080] [00:01:03/00:36:01, 0.722s/it]: train_loss_raw=0.4210, running_loss=0.3852, LR=0.000100
[2025-08-27 14:54:19,782][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077096] [Batch 00096/03080] [00:01:09/00:36:01, 0.724s/it]: train_loss_raw=0.3728, running_loss=0.3835, LR=0.000100
[2025-08-27 14:54:25,799][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077104] [Batch 00104/03080] [00:01:15/00:36:01, 0.726s/it]: train_loss_raw=0.3773, running_loss=0.3832, LR=0.000100
[2025-08-27 14:54:31,760][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077112] [Batch 00112/03080] [00:01:21/00:35:59, 0.728s/it]: train_loss_raw=0.3155, running_loss=0.3797, LR=0.000100
[2025-08-27 14:54:37,757][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077120] [Batch 00120/03080] [00:01:27/00:35:58, 0.729s/it]: train_loss_raw=0.3296, running_loss=0.3809, LR=0.000100
[2025-08-27 14:54:43,777][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077128] [Batch 00128/03080] [00:01:33/00:35:56, 0.731s/it]: train_loss_raw=0.4333, running_loss=0.3808, LR=0.000100
[2025-08-27 14:54:49,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077136] [Batch 00136/03080] [00:01:39/00:35:45, 0.729s/it]: train_loss_raw=0.3780, running_loss=0.3825, LR=0.000100
[2025-08-27 14:54:55,262][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077144] [Batch 00144/03080] [00:01:45/00:35:40, 0.729s/it]: train_loss_raw=0.4046, running_loss=0.3819, LR=0.000100
[2025-08-27 14:55:00,723][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077152] [Batch 00152/03080] [00:01:50/00:35:27, 0.727s/it]: train_loss_raw=0.4287, running_loss=0.3818, LR=0.000100
[2025-08-27 14:55:06,385][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077160] [Batch 00160/03080] [00:01:56/00:35:19, 0.726s/it]: train_loss_raw=0.4074, running_loss=0.3812, LR=0.000100
[2025-08-27 14:55:11,965][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077168] [Batch 00168/03080] [00:02:01/00:35:09, 0.724s/it]: train_loss_raw=0.3626, running_loss=0.3798, LR=0.000100
[2025-08-27 14:55:17,354][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077176] [Batch 00176/03080] [00:02:07/00:34:57, 0.722s/it]: train_loss_raw=0.3655, running_loss=0.3779, LR=0.000100
[2025-08-27 14:55:23,066][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077184] [Batch 00184/03080] [00:02:12/00:34:50, 0.722s/it]: train_loss_raw=0.3822, running_loss=0.3763, LR=0.000100
[2025-08-27 14:55:28,530][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077192] [Batch 00192/03080] [00:02:18/00:34:39, 0.720s/it]: train_loss_raw=0.2532, running_loss=0.3747, LR=0.000100
[2025-08-27 14:55:34,414][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077200] [Batch 00200/03080] [00:02:24/00:34:35, 0.721s/it]: train_loss_raw=0.4132, running_loss=0.3733, LR=0.000100
[2025-08-27 14:55:40,415][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077208] [Batch 00208/03080] [00:02:30/00:34:33, 0.722s/it]: train_loss_raw=0.2985, running_loss=0.3742, LR=0.000100
[2025-08-27 14:55:46,392][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077216] [Batch 00216/03080] [00:02:36/00:34:30, 0.723s/it]: train_loss_raw=0.3610, running_loss=0.3749, LR=0.000100
[2025-08-27 14:55:52,399][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077224] [Batch 00224/03080] [00:02:42/00:34:27, 0.724s/it]: train_loss_raw=0.3616, running_loss=0.3736, LR=0.000100
[2025-08-27 14:55:58,400][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077232] [Batch 00232/03080] [00:02:48/00:34:24, 0.725s/it]: train_loss_raw=0.4431, running_loss=0.3761, LR=0.000100
[2025-08-27 14:56:04,362][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077240] [Batch 00240/03080] [00:02:54/00:34:20, 0.725s/it]: train_loss_raw=0.3771, running_loss=0.3751, LR=0.000100
[2025-08-27 14:56:10,355][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077248] [Batch 00248/03080] [00:03:00/00:34:16, 0.726s/it]: train_loss_raw=0.4329, running_loss=0.3741, LR=0.000100
[2025-08-27 14:56:15,983][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077256] [Batch 00256/03080] [00:03:05/00:34:08, 0.725s/it]: train_loss_raw=0.3067, running_loss=0.3731, LR=0.000100
[2025-08-27 14:56:21,875][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077264] [Batch 00264/03080] [00:03:11/00:34:03, 0.726s/it]: train_loss_raw=0.4314, running_loss=0.3760, LR=0.000100
[2025-08-27 14:56:27,905][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077272] [Batch 00272/03080] [00:03:17/00:34:00, 0.727s/it]: train_loss_raw=0.4088, running_loss=0.3746, LR=0.000100
[2025-08-27 14:56:34,044][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077280] [Batch 00280/03080] [00:03:23/00:33:57, 0.728s/it]: train_loss_raw=0.3915, running_loss=0.3758, LR=0.000100
[2025-08-27 14:56:39,747][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077288] [Batch 00288/03080] [00:03:29/00:33:50, 0.727s/it]: train_loss_raw=0.2917, running_loss=0.3745, LR=0.000100
[2025-08-27 14:56:45,195][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077296] [Batch 00296/03080] [00:03:34/00:33:41, 0.726s/it]: train_loss_raw=0.3553, running_loss=0.3730, LR=0.000100
[2025-08-27 14:56:50,986][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077304] [Batch 00304/03080] [00:03:40/00:33:35, 0.726s/it]: train_loss_raw=0.3472, running_loss=0.3717, LR=0.000100
[2025-08-27 14:56:56,402][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077312] [Batch 00312/03080] [00:03:46/00:33:26, 0.725s/it]: train_loss_raw=0.4057, running_loss=0.3704, LR=0.000100
[2025-08-27 14:57:01,877][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077320] [Batch 00320/03080] [00:03:51/00:33:17, 0.724s/it]: train_loss_raw=0.3963, running_loss=0.3692, LR=0.000100
[2025-08-27 14:57:07,863][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077328] [Batch 00328/03080] [00:03:57/00:33:13, 0.724s/it]: train_loss_raw=0.3493, running_loss=0.3689, LR=0.000100
[2025-08-27 14:57:13,863][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077336] [Batch 00336/03080] [00:04:03/00:33:09, 0.725s/it]: train_loss_raw=0.3728, running_loss=0.3694, LR=0.000100
[2025-08-27 14:57:19,976][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077344] [Batch 00344/03080] [00:04:09/00:33:06, 0.726s/it]: train_loss_raw=0.3671, running_loss=0.3700, LR=0.000100
[2025-08-27 14:57:25,683][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077352] [Batch 00352/03080] [00:04:15/00:32:59, 0.726s/it]: train_loss_raw=0.4777, running_loss=0.3694, LR=0.000100
[2025-08-27 14:57:31,222][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077360] [Batch 00360/03080] [00:04:20/00:32:51, 0.725s/it]: train_loss_raw=0.3818, running_loss=0.3689, LR=0.000100
[2025-08-27 14:57:36,648][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077368] [Batch 00368/03080] [00:04:26/00:32:43, 0.724s/it]: train_loss_raw=0.3029, running_loss=0.3674, LR=0.000100
[2025-08-27 14:57:42,366][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077376] [Batch 00376/03080] [00:04:32/00:32:36, 0.724s/it]: train_loss_raw=0.3745, running_loss=0.3672, LR=0.000100
[2025-08-27 14:57:48,098][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077384] [Batch 00384/03080] [00:04:37/00:32:30, 0.724s/it]: train_loss_raw=0.3556, running_loss=0.3661, LR=0.000100
[2025-08-27 14:57:53,957][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077392] [Batch 00392/03080] [00:04:43/00:32:25, 0.724s/it]: train_loss_raw=0.3615, running_loss=0.3678, LR=0.000100
[2025-08-27 14:57:59,734][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077400] [Batch 00400/03080] [00:04:49/00:32:19, 0.724s/it]: train_loss_raw=0.3217, running_loss=0.3655, LR=0.000100
[2025-08-27 14:58:05,344][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077408] [Batch 00408/03080] [00:04:55/00:32:12, 0.723s/it]: train_loss_raw=0.4769, running_loss=0.3657, LR=0.000100
[2025-08-27 14:58:11,319][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077416] [Batch 00416/03080] [00:05:01/00:32:07, 0.724s/it]: train_loss_raw=0.3390, running_loss=0.3667, LR=0.000100
[2025-08-27 14:58:17,427][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077424] [Batch 00424/03080] [00:05:07/00:32:04, 0.724s/it]: train_loss_raw=0.3468, running_loss=0.3680, LR=0.000100
[2025-08-27 14:58:23,614][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077432] [Batch 00432/03080] [00:05:13/00:32:00, 0.725s/it]: train_loss_raw=0.4414, running_loss=0.3703, LR=0.000100
[2025-08-27 14:58:29,820][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077440] [Batch 00440/03080] [00:05:19/00:31:57, 0.726s/it]: train_loss_raw=0.3952, running_loss=0.3707, LR=0.000100
[2025-08-27 14:58:35,666][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077448] [Batch 00448/03080] [00:05:25/00:31:51, 0.726s/it]: train_loss_raw=0.3139, running_loss=0.3696, LR=0.000100
[2025-08-27 14:58:41,752][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077456] [Batch 00456/03080] [00:05:31/00:31:47, 0.727s/it]: train_loss_raw=0.3447, running_loss=0.3686, LR=0.000100
[2025-08-27 14:58:47,432][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077464] [Batch 00464/03080] [00:05:37/00:31:40, 0.727s/it]: train_loss_raw=0.4071, running_loss=0.3686, LR=0.000100
[2025-08-27 14:58:53,041][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077472] [Batch 00472/03080] [00:05:42/00:31:34, 0.726s/it]: train_loss_raw=0.4016, running_loss=0.3703, LR=0.000100
[2025-08-27 14:58:58,724][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077480] [Batch 00480/03080] [00:05:48/00:31:27, 0.726s/it]: train_loss_raw=0.3503, running_loss=0.3720, LR=0.000100
[2025-08-27 14:59:04,794][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077488] [Batch 00488/03080] [00:05:54/00:31:23, 0.727s/it]: train_loss_raw=0.3478, running_loss=0.3721, LR=0.000100
[2025-08-27 14:59:10,723][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077496] [Batch 00496/03080] [00:06:00/00:31:17, 0.727s/it]: train_loss_raw=0.3605, running_loss=0.3719, LR=0.000100
[2025-08-27 14:59:16,676][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077504] [Batch 00504/03080] [00:06:06/00:31:12, 0.727s/it]: train_loss_raw=0.4181, running_loss=0.3728, LR=0.000100
[2025-08-27 14:59:22,892][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077512] [Batch 00512/03080] [00:06:12/00:31:09, 0.728s/it]: train_loss_raw=0.3746, running_loss=0.3709, LR=0.000100
[2025-08-27 14:59:29,033][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077520] [Batch 00520/03080] [00:06:18/00:31:04, 0.728s/it]: train_loss_raw=0.3786, running_loss=0.3714, LR=0.000100
[2025-08-27 14:59:35,093][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077528] [Batch 00528/03080] [00:06:24/00:31:00, 0.729s/it]: train_loss_raw=0.3766, running_loss=0.3708, LR=0.000100
[2025-08-27 14:59:41,066][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077536] [Batch 00536/03080] [00:06:30/00:30:54, 0.729s/it]: train_loss_raw=0.4487, running_loss=0.3726, LR=0.000100
[2025-08-27 14:59:47,109][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077544] [Batch 00544/03080] [00:06:36/00:30:50, 0.730s/it]: train_loss_raw=0.3778, running_loss=0.3713, LR=0.000100
[2025-08-27 14:59:53,218][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077552] [Batch 00552/03080] [00:06:42/00:30:45, 0.730s/it]: train_loss_raw=0.3334, running_loss=0.3713, LR=0.000100
[2025-08-27 14:59:59,393][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077560] [Batch 00560/03080] [00:06:49/00:30:41, 0.731s/it]: train_loss_raw=0.3306, running_loss=0.3717, LR=0.000100
[2025-08-27 15:00:05,470][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077568] [Batch 00568/03080] [00:06:55/00:30:36, 0.731s/it]: train_loss_raw=0.3588, running_loss=0.3727, LR=0.000100
[2025-08-27 15:00:11,709][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077576] [Batch 00576/03080] [00:07:01/00:30:32, 0.732s/it]: train_loss_raw=0.3331, running_loss=0.3721, LR=0.000100
[2025-08-27 15:00:17,357][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077584] [Batch 00584/03080] [00:07:07/00:30:25, 0.731s/it]: train_loss_raw=0.4251, running_loss=0.3713, LR=0.000100
[2025-08-27 15:00:23,550][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077592] [Batch 00592/03080] [00:07:13/00:30:21, 0.732s/it]: train_loss_raw=0.3992, running_loss=0.3718, LR=0.000100
[2025-08-27 15:00:29,597][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077600] [Batch 00600/03080] [00:07:19/00:30:15, 0.732s/it]: train_loss_raw=0.4394, running_loss=0.3707, LR=0.000100
[2025-08-27 15:00:35,686][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077608] [Batch 00608/03080] [00:07:25/00:30:11, 0.733s/it]: train_loss_raw=0.4715, running_loss=0.3713, LR=0.000100
[2025-08-27 15:00:41,738][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077616] [Batch 00616/03080] [00:07:31/00:30:05, 0.733s/it]: train_loss_raw=0.4101, running_loss=0.3713, LR=0.000100
[2025-08-27 15:00:47,870][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077624] [Batch 00624/03080] [00:07:37/00:30:01, 0.733s/it]: train_loss_raw=0.4723, running_loss=0.3740, LR=0.000100
[2025-08-27 15:00:53,916][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077632] [Batch 00632/03080] [00:07:43/00:29:55, 0.734s/it]: train_loss_raw=0.3893, running_loss=0.3754, LR=0.000100
[2025-08-27 15:01:00,054][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077640] [Batch 00640/03080] [00:07:49/00:29:51, 0.734s/it]: train_loss_raw=0.3043, running_loss=0.3747, LR=0.000100
[2025-08-27 15:01:05,856][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077648] [Batch 00648/03080] [00:07:55/00:29:44, 0.734s/it]: train_loss_raw=0.3899, running_loss=0.3736, LR=0.000100
[2025-08-27 15:01:11,751][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077656] [Batch 00656/03080] [00:08:01/00:29:39, 0.734s/it]: train_loss_raw=0.3238, running_loss=0.3724, LR=0.000100
[2025-08-27 15:01:17,905][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077664] [Batch 00664/03080] [00:08:07/00:29:34, 0.734s/it]: train_loss_raw=0.2926, running_loss=0.3721, LR=0.000100
[2025-08-27 15:01:23,906][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077672] [Batch 00672/03080] [00:08:13/00:29:28, 0.735s/it]: train_loss_raw=0.3164, running_loss=0.3707, LR=0.000100
[2025-08-27 15:01:29,933][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077680] [Batch 00680/03080] [00:08:19/00:29:23, 0.735s/it]: train_loss_raw=0.3621, running_loss=0.3721, LR=0.000100
[2025-08-27 15:01:36,046][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077688] [Batch 00688/03080] [00:08:25/00:29:18, 0.735s/it]: train_loss_raw=0.4220, running_loss=0.3724, LR=0.000100
[2025-08-27 15:01:42,099][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077696] [Batch 00696/03080] [00:08:31/00:29:13, 0.735s/it]: train_loss_raw=0.3367, running_loss=0.3695, LR=0.000100
[2025-08-27 15:01:48,124][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077704] [Batch 00704/03080] [00:08:37/00:29:07, 0.736s/it]: train_loss_raw=0.3925, running_loss=0.3707, LR=0.000100
[2025-08-27 15:01:53,993][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077712] [Batch 00712/03080] [00:08:43/00:29:01, 0.736s/it]: train_loss_raw=0.3301, running_loss=0.3712, LR=0.000100
[2025-08-27 15:02:00,120][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077720] [Batch 00720/03080] [00:08:49/00:28:56, 0.736s/it]: train_loss_raw=0.3424, running_loss=0.3707, LR=0.000100
[2025-08-27 15:02:06,112][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077728] [Batch 00728/03080] [00:08:55/00:28:51, 0.736s/it]: train_loss_raw=0.3558, running_loss=0.3713, LR=0.000100
[2025-08-27 15:02:12,228][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077736] [Batch 00736/03080] [00:09:01/00:28:46, 0.736s/it]: train_loss_raw=0.4649, running_loss=0.3735, LR=0.000100
[2025-08-27 15:02:18,239][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077744] [Batch 00744/03080] [00:09:07/00:28:40, 0.737s/it]: train_loss_raw=0.2850, running_loss=0.3750, LR=0.000100
[2025-08-27 15:02:24,049][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077752] [Batch 00752/03080] [00:09:13/00:28:34, 0.736s/it]: train_loss_raw=0.4489, running_loss=0.3750, LR=0.000100
[2025-08-27 15:02:29,772][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077760] [Batch 00760/03080] [00:09:19/00:28:27, 0.736s/it]: train_loss_raw=0.3866, running_loss=0.3735, LR=0.000100
[2025-08-27 15:02:35,865][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077768] [Batch 00768/03080] [00:09:25/00:28:22, 0.736s/it]: train_loss_raw=0.3200, running_loss=0.3722, LR=0.000100
[2025-08-27 15:02:41,987][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077776] [Batch 00776/03080] [00:09:31/00:28:17, 0.737s/it]: train_loss_raw=0.2975, running_loss=0.3721, LR=0.000100
[2025-08-27 15:02:47,699][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077784] [Batch 00784/03080] [00:09:37/00:28:11, 0.737s/it]: train_loss_raw=0.3698, running_loss=0.3726, LR=0.000100
[2025-08-27 15:02:53,238][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077792] [Batch 00792/03080] [00:09:42/00:28:04, 0.736s/it]: train_loss_raw=0.3087, running_loss=0.3711, LR=0.000100
[2025-08-27 15:02:58,769][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077800] [Batch 00800/03080] [00:09:48/00:27:57, 0.736s/it]: train_loss_raw=0.3427, running_loss=0.3717, LR=0.000100
[2025-08-27 15:03:04,545][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077808] [Batch 00808/03080] [00:09:54/00:27:51, 0.736s/it]: train_loss_raw=0.4245, running_loss=0.3729, LR=0.000100
[2025-08-27 15:03:10,479][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077816] [Batch 00816/03080] [00:10:00/00:27:45, 0.736s/it]: train_loss_raw=0.3388, running_loss=0.3724, LR=0.000100
[2025-08-27 15:03:16,416][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077824] [Batch 00824/03080] [00:10:06/00:27:39, 0.736s/it]: train_loss_raw=0.4742, running_loss=0.3714, LR=0.000100
[2025-08-27 15:03:22,258][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077832] [Batch 00832/03080] [00:10:12/00:27:33, 0.736s/it]: train_loss_raw=0.3793, running_loss=0.3707, LR=0.000100
[2025-08-27 15:03:28,369][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077840] [Batch 00840/03080] [00:10:18/00:27:28, 0.736s/it]: train_loss_raw=0.4405, running_loss=0.3699, LR=0.000100
[2025-08-27 15:03:34,200][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077848] [Batch 00848/03080] [00:10:23/00:27:22, 0.736s/it]: train_loss_raw=0.3008, running_loss=0.3673, LR=0.000100
[2025-08-27 15:03:40,210][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077856] [Batch 00856/03080] [00:10:29/00:27:16, 0.736s/it]: train_loss_raw=0.3845, running_loss=0.3691, LR=0.000100
[2025-08-27 15:03:46,187][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077864] [Batch 00864/03080] [00:10:35/00:27:11, 0.736s/it]: train_loss_raw=0.3325, running_loss=0.3701, LR=0.000100
[2025-08-27 15:03:52,281][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077872] [Batch 00872/03080] [00:10:42/00:27:05, 0.736s/it]: train_loss_raw=0.4478, running_loss=0.3705, LR=0.000100
[2025-08-27 15:03:58,492][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077880] [Batch 00880/03080] [00:10:48/00:27:00, 0.737s/it]: train_loss_raw=0.3804, running_loss=0.3710, LR=0.000100
[2025-08-27 15:04:04,499][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077888] [Batch 00888/03080] [00:10:54/00:26:54, 0.737s/it]: train_loss_raw=0.3456, running_loss=0.3695, LR=0.000100
[2025-08-27 15:04:10,444][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077896] [Batch 00896/03080] [00:11:00/00:26:49, 0.737s/it]: train_loss_raw=0.3836, running_loss=0.3703, LR=0.000100
[2025-08-27 15:04:16,290][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077904] [Batch 00904/03080] [00:11:06/00:26:43, 0.737s/it]: train_loss_raw=0.4865, running_loss=0.3713, LR=0.000100
[2025-08-27 15:04:21,928][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077912] [Batch 00912/03080] [00:11:11/00:26:36, 0.736s/it]: train_loss_raw=0.3581, running_loss=0.3692, LR=0.000100
[2025-08-27 15:04:27,886][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077920] [Batch 00920/03080] [00:11:17/00:26:30, 0.737s/it]: train_loss_raw=0.4156, running_loss=0.3672, LR=0.000100
[2025-08-27 15:04:33,538][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077928] [Batch 00928/03080] [00:11:23/00:26:24, 0.736s/it]: train_loss_raw=0.3562, running_loss=0.3696, LR=0.000100
[2025-08-27 15:04:39,236][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077936] [Batch 00936/03080] [00:11:28/00:26:18, 0.736s/it]: train_loss_raw=0.4422, running_loss=0.3699, LR=0.000100
[2025-08-27 15:04:44,913][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077944] [Batch 00944/03080] [00:11:34/00:26:11, 0.736s/it]: train_loss_raw=0.4158, running_loss=0.3685, LR=0.000100
[2025-08-27 15:04:51,073][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077952] [Batch 00952/03080] [00:11:40/00:26:06, 0.736s/it]: train_loss_raw=0.3908, running_loss=0.3701, LR=0.000100
[2025-08-27 15:04:57,100][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077960] [Batch 00960/03080] [00:11:46/00:26:00, 0.736s/it]: train_loss_raw=0.3478, running_loss=0.3708, LR=0.000100
[2025-08-27 15:05:03,104][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077968] [Batch 00968/03080] [00:11:52/00:25:55, 0.736s/it]: train_loss_raw=0.3501, running_loss=0.3710, LR=0.000100
[2025-08-27 15:05:09,126][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077976] [Batch 00976/03080] [00:11:58/00:25:49, 0.737s/it]: train_loss_raw=0.3543, running_loss=0.3704, LR=0.000100
[2025-08-27 15:05:15,137][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077984] [Batch 00984/03080] [00:12:04/00:25:44, 0.737s/it]: train_loss_raw=0.3920, running_loss=0.3689, LR=0.000100
[2025-08-27 15:05:21,252][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 077992] [Batch 00992/03080] [00:12:10/00:25:38, 0.737s/it]: train_loss_raw=0.3769, running_loss=0.3674, LR=0.000100
[2025-08-27 15:05:27,367][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078000] [Batch 01000/03080] [00:12:17/00:25:33, 0.737s/it]: train_loss_raw=0.3294, running_loss=0.3696, LR=0.000100
[2025-08-27 15:05:36,318][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078008] [Batch 01008/03080] [00:12:26/00:25:33, 0.740s/it]: train_loss_raw=0.3238, running_loss=0.3692, LR=0.000100
[2025-08-27 15:05:41,969][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078016] [Batch 01016/03080] [00:12:31/00:25:27, 0.740s/it]: train_loss_raw=0.3307, running_loss=0.3674, LR=0.000100
[2025-08-27 15:05:47,995][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078024] [Batch 01024/03080] [00:12:37/00:25:21, 0.740s/it]: train_loss_raw=0.3965, running_loss=0.3693, LR=0.000100
[2025-08-27 15:05:53,962][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078032] [Batch 01032/03080] [00:12:43/00:25:15, 0.740s/it]: train_loss_raw=0.3630, running_loss=0.3687, LR=0.000100
[2025-08-27 15:05:59,993][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078040] [Batch 01040/03080] [00:12:49/00:25:09, 0.740s/it]: train_loss_raw=0.3586, running_loss=0.3669, LR=0.000100
[2025-08-27 15:06:06,029][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078048] [Batch 01048/03080] [00:12:55/00:25:04, 0.740s/it]: train_loss_raw=0.2902, running_loss=0.3648, LR=0.000100
[2025-08-27 15:06:12,110][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078056] [Batch 01056/03080] [00:13:01/00:24:58, 0.740s/it]: train_loss_raw=0.3677, running_loss=0.3645, LR=0.000100
[2025-08-27 15:06:18,095][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078064] [Batch 01064/03080] [00:13:07/00:24:52, 0.740s/it]: train_loss_raw=0.3825, running_loss=0.3645, LR=0.000100
[2025-08-27 15:06:23,778][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078072] [Batch 01072/03080] [00:13:13/00:24:46, 0.740s/it]: train_loss_raw=0.3057, running_loss=0.3646, LR=0.000100
[2025-08-27 15:06:29,913][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078080] [Batch 01080/03080] [00:13:19/00:24:40, 0.740s/it]: train_loss_raw=0.4362, running_loss=0.3650, LR=0.000100
[2025-08-27 15:06:35,919][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078088] [Batch 01088/03080] [00:13:25/00:24:35, 0.740s/it]: train_loss_raw=0.3838, running_loss=0.3648, LR=0.000100
[2025-08-27 15:06:41,639][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078096] [Batch 01096/03080] [00:13:31/00:24:28, 0.740s/it]: train_loss_raw=0.3018, running_loss=0.3666, LR=0.000100
[2025-08-27 15:06:47,196][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078104] [Batch 01104/03080] [00:13:36/00:24:22, 0.740s/it]: train_loss_raw=0.3758, running_loss=0.3649, LR=0.000100
[2025-08-27 15:06:52,966][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078112] [Batch 01112/03080] [00:13:42/00:24:16, 0.740s/it]: train_loss_raw=0.3251, running_loss=0.3648, LR=0.000100
[2025-08-27 15:06:58,634][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078120] [Batch 01120/03080] [00:13:48/00:24:09, 0.740s/it]: train_loss_raw=0.3508, running_loss=0.3659, LR=0.000100
[2025-08-27 15:07:04,207][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078128] [Batch 01128/03080] [00:13:53/00:24:03, 0.739s/it]: train_loss_raw=0.3728, running_loss=0.3656, LR=0.000100
[2025-08-27 15:07:09,944][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078136] [Batch 01136/03080] [00:13:59/00:23:56, 0.739s/it]: train_loss_raw=0.3647, running_loss=0.3648, LR=0.000100
[2025-08-27 15:07:15,945][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078144] [Batch 01144/03080] [00:14:05/00:23:51, 0.739s/it]: train_loss_raw=0.3189, running_loss=0.3659, LR=0.000100
[2025-08-27 15:07:21,605][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078152] [Batch 01152/03080] [00:14:11/00:23:44, 0.739s/it]: train_loss_raw=0.3626, running_loss=0.3670, LR=0.000100
[2025-08-27 15:07:27,215][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078160] [Batch 01160/03080] [00:14:16/00:23:38, 0.739s/it]: train_loss_raw=0.4765, running_loss=0.3686, LR=0.000100
[2025-08-27 15:07:32,865][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078168] [Batch 01168/03080] [00:14:22/00:23:32, 0.739s/it]: train_loss_raw=0.3425, running_loss=0.3696, LR=0.000100
[2025-08-27 15:07:38,894][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078176] [Batch 01176/03080] [00:14:28/00:23:26, 0.739s/it]: train_loss_raw=0.3310, running_loss=0.3700, LR=0.000100
[2025-08-27 15:07:44,468][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078184] [Batch 01184/03080] [00:14:34/00:23:19, 0.738s/it]: train_loss_raw=0.3695, running_loss=0.3721, LR=0.000100
[2025-08-27 15:07:50,227][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078192] [Batch 01192/03080] [00:14:39/00:23:13, 0.738s/it]: train_loss_raw=0.3429, running_loss=0.3724, LR=0.000100
[2025-08-27 15:07:56,234][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078200] [Batch 01200/03080] [00:14:45/00:23:08, 0.738s/it]: train_loss_raw=0.4568, running_loss=0.3725, LR=0.000100
[2025-08-27 15:08:01,695][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078208] [Batch 01208/03080] [00:14:51/00:23:01, 0.738s/it]: train_loss_raw=0.3040, running_loss=0.3729, LR=0.000100
[2025-08-27 15:08:07,347][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078216] [Batch 01216/03080] [00:14:57/00:22:55, 0.738s/it]: train_loss_raw=0.3081, running_loss=0.3741, LR=0.000100
[2025-08-27 15:08:13,119][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078224] [Batch 01224/03080] [00:15:02/00:22:49, 0.738s/it]: train_loss_raw=0.3761, running_loss=0.3727, LR=0.000100
[2025-08-27 15:08:18,883][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078232] [Batch 01232/03080] [00:15:08/00:22:42, 0.738s/it]: train_loss_raw=0.3563, running_loss=0.3736, LR=0.000100
[2025-08-27 15:08:24,432][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078240] [Batch 01240/03080] [00:15:14/00:22:36, 0.737s/it]: train_loss_raw=0.3304, running_loss=0.3718, LR=0.000100
[2025-08-27 15:08:30,045][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078248] [Batch 01248/03080] [00:15:19/00:22:30, 0.737s/it]: train_loss_raw=0.3447, running_loss=0.3716, LR=0.000100
[2025-08-27 15:08:36,027][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078256] [Batch 01256/03080] [00:15:25/00:22:24, 0.737s/it]: train_loss_raw=0.3498, running_loss=0.3706, LR=0.000100
[2025-08-27 15:08:41,456][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078264] [Batch 01264/03080] [00:15:31/00:22:17, 0.737s/it]: train_loss_raw=0.4296, running_loss=0.3712, LR=0.000100
[2025-08-27 15:08:46,885][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078272] [Batch 01272/03080] [00:15:36/00:22:11, 0.736s/it]: train_loss_raw=0.4607, running_loss=0.3722, LR=0.000100
[2025-08-27 15:08:52,724][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078280] [Batch 01280/03080] [00:15:42/00:22:05, 0.736s/it]: train_loss_raw=0.4392, running_loss=0.3711, LR=0.000100
[2025-08-27 15:08:58,706][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078288] [Batch 01288/03080] [00:15:48/00:21:59, 0.736s/it]: train_loss_raw=0.3313, running_loss=0.3710, LR=0.000100
[2025-08-27 15:09:04,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078296] [Batch 01296/03080] [00:15:54/00:21:53, 0.736s/it]: train_loss_raw=0.3244, running_loss=0.3699, LR=0.000100
[2025-08-27 15:09:09,866][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078304] [Batch 01304/03080] [00:15:59/00:21:46, 0.736s/it]: train_loss_raw=0.3696, running_loss=0.3695, LR=0.000100
[2025-08-27 15:09:15,834][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078312] [Batch 01312/03080] [00:16:05/00:21:41, 0.736s/it]: train_loss_raw=0.3712, running_loss=0.3701, LR=0.000100
[2025-08-27 15:09:21,940][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078320] [Batch 01320/03080] [00:16:11/00:21:35, 0.736s/it]: train_loss_raw=0.3725, running_loss=0.3698, LR=0.000100
[2025-08-27 15:09:27,807][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078328] [Batch 01328/03080] [00:16:17/00:21:29, 0.736s/it]: train_loss_raw=0.3389, running_loss=0.3697, LR=0.000100
[2025-08-27 15:09:33,736][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078336] [Batch 01336/03080] [00:16:23/00:21:23, 0.736s/it]: train_loss_raw=0.3752, running_loss=0.3693, LR=0.000100
[2025-08-27 15:09:39,104][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078344] [Batch 01344/03080] [00:16:28/00:21:17, 0.736s/it]: train_loss_raw=0.3139, running_loss=0.3682, LR=0.000100
[2025-08-27 15:09:44,893][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078352] [Batch 01352/03080] [00:16:34/00:21:11, 0.736s/it]: train_loss_raw=0.3802, running_loss=0.3699, LR=0.000100
[2025-08-27 15:09:50,746][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078360] [Batch 01360/03080] [00:16:40/00:21:05, 0.736s/it]: train_loss_raw=0.4068, running_loss=0.3718, LR=0.000100
[2025-08-27 15:09:56,673][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078368] [Batch 01368/03080] [00:16:46/00:20:59, 0.736s/it]: train_loss_raw=0.5116, running_loss=0.3723, LR=0.000100
[2025-08-27 15:10:02,746][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078376] [Batch 01376/03080] [00:16:52/00:20:53, 0.736s/it]: train_loss_raw=0.3525, running_loss=0.3741, LR=0.000100
[2025-08-27 15:10:08,648][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078384] [Batch 01384/03080] [00:16:58/00:20:47, 0.736s/it]: train_loss_raw=0.3127, running_loss=0.3733, LR=0.000100
[2025-08-27 15:10:14,728][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078392] [Batch 01392/03080] [00:17:04/00:20:42, 0.736s/it]: train_loss_raw=0.3695, running_loss=0.3733, LR=0.000100
[2025-08-27 15:10:20,531][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078400] [Batch 01400/03080] [00:17:10/00:20:36, 0.736s/it]: train_loss_raw=0.3406, running_loss=0.3740, LR=0.000100
[2025-08-27 15:10:26,629][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078408] [Batch 01408/03080] [00:17:16/00:20:30, 0.736s/it]: train_loss_raw=0.3422, running_loss=0.3734, LR=0.000100
[2025-08-27 15:10:32,612][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078416] [Batch 01416/03080] [00:17:22/00:20:24, 0.736s/it]: train_loss_raw=0.3495, running_loss=0.3725, LR=0.000100
[2025-08-27 15:10:38,207][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078424] [Batch 01424/03080] [00:17:27/00:20:18, 0.736s/it]: train_loss_raw=0.3916, running_loss=0.3728, LR=0.000100
[2025-08-27 15:10:44,001][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078432] [Batch 01432/03080] [00:17:33/00:20:12, 0.736s/it]: train_loss_raw=0.3827, running_loss=0.3712, LR=0.000100
[2025-08-27 15:10:50,006][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078440] [Batch 01440/03080] [00:17:39/00:20:06, 0.736s/it]: train_loss_raw=0.3982, running_loss=0.3701, LR=0.000100
[2025-08-27 15:10:56,057][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078448] [Batch 01448/03080] [00:17:45/00:20:01, 0.736s/it]: train_loss_raw=0.4732, running_loss=0.3699, LR=0.000100
[2025-08-27 15:11:02,153][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078456] [Batch 01456/03080] [00:17:51/00:19:55, 0.736s/it]: train_loss_raw=0.3891, running_loss=0.3707, LR=0.000100
[2025-08-27 15:11:08,141][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078464] [Batch 01464/03080] [00:17:57/00:19:49, 0.736s/it]: train_loss_raw=0.3105, running_loss=0.3699, LR=0.000100
[2025-08-27 15:11:13,736][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078472] [Batch 01472/03080] [00:18:03/00:19:43, 0.736s/it]: train_loss_raw=0.3809, running_loss=0.3727, LR=0.000100
[2025-08-27 15:11:19,758][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078480] [Batch 01480/03080] [00:18:09/00:19:37, 0.736s/it]: train_loss_raw=0.3111, running_loss=0.3722, LR=0.000100
[2025-08-27 15:11:25,763][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078488] [Batch 01488/03080] [00:18:15/00:19:32, 0.736s/it]: train_loss_raw=0.2998, running_loss=0.3715, LR=0.000100
[2025-08-27 15:11:31,459][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078496] [Batch 01496/03080] [00:18:21/00:19:25, 0.736s/it]: train_loss_raw=0.3783, running_loss=0.3708, LR=0.000100
[2025-08-27 15:11:37,373][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078504] [Batch 01504/03080] [00:18:27/00:19:20, 0.736s/it]: train_loss_raw=0.3596, running_loss=0.3700, LR=0.000100
[2025-08-27 15:11:43,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078512] [Batch 01512/03080] [00:18:33/00:19:14, 0.736s/it]: train_loss_raw=0.3678, running_loss=0.3712, LR=0.000100
[2025-08-27 15:11:49,264][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078520] [Batch 01520/03080] [00:18:39/00:19:08, 0.736s/it]: train_loss_raw=0.3700, running_loss=0.3690, LR=0.000100
[2025-08-27 15:11:54,750][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078528] [Batch 01528/03080] [00:18:44/00:19:02, 0.736s/it]: train_loss_raw=0.3436, running_loss=0.3687, LR=0.000100
[2025-08-27 15:12:00,850][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078536] [Batch 01536/03080] [00:18:50/00:18:56, 0.736s/it]: train_loss_raw=0.4182, running_loss=0.3692, LR=0.000100
[2025-08-27 15:12:06,934][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078544] [Batch 01544/03080] [00:18:56/00:18:50, 0.736s/it]: train_loss_raw=0.2972, running_loss=0.3698, LR=0.000100
[2025-08-27 15:12:12,977][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078552] [Batch 01552/03080] [00:19:02/00:18:45, 0.736s/it]: train_loss_raw=0.3901, running_loss=0.3694, LR=0.000100
[2025-08-27 15:12:18,947][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078560] [Batch 01560/03080] [00:19:08/00:18:39, 0.736s/it]: train_loss_raw=0.3506, running_loss=0.3679, LR=0.000100
[2025-08-27 15:12:24,820][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078568] [Batch 01568/03080] [00:19:14/00:18:33, 0.736s/it]: train_loss_raw=0.3693, running_loss=0.3667, LR=0.000100
[2025-08-27 15:12:30,533][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078576] [Batch 01576/03080] [00:19:20/00:18:27, 0.736s/it]: train_loss_raw=0.3724, running_loss=0.3655, LR=0.000100
[2025-08-27 15:12:36,618][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078584] [Batch 01584/03080] [00:19:26/00:18:21, 0.736s/it]: train_loss_raw=0.3213, running_loss=0.3659, LR=0.000100
[2025-08-27 15:12:42,172][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078592] [Batch 01592/03080] [00:19:31/00:18:15, 0.736s/it]: train_loss_raw=0.4058, running_loss=0.3654, LR=0.000100
[2025-08-27 15:12:48,209][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078600] [Batch 01600/03080] [00:19:37/00:18:09, 0.736s/it]: train_loss_raw=0.4450, running_loss=0.3675, LR=0.000100
[2025-08-27 15:12:54,254][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078608] [Batch 01608/03080] [00:19:43/00:18:03, 0.736s/it]: train_loss_raw=0.3978, running_loss=0.3673, LR=0.000100
[2025-08-27 15:13:00,116][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078616] [Batch 01616/03080] [00:19:49/00:17:57, 0.736s/it]: train_loss_raw=0.3968, running_loss=0.3673, LR=0.000100
[2025-08-27 15:13:05,959][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078624] [Batch 01624/03080] [00:19:55/00:17:52, 0.736s/it]: train_loss_raw=0.3436, running_loss=0.3676, LR=0.000100
[2025-08-27 15:13:11,729][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078632] [Batch 01632/03080] [00:20:01/00:17:46, 0.736s/it]: train_loss_raw=0.3460, running_loss=0.3660, LR=0.000100
[2025-08-27 15:13:17,759][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078640] [Batch 01640/03080] [00:20:07/00:17:40, 0.736s/it]: train_loss_raw=0.3582, running_loss=0.3648, LR=0.000100
[2025-08-27 15:13:23,797][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078648] [Batch 01648/03080] [00:20:13/00:17:34, 0.736s/it]: train_loss_raw=0.3659, running_loss=0.3651, LR=0.000100
[2025-08-27 15:13:29,900][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078656] [Batch 01656/03080] [00:20:19/00:17:28, 0.736s/it]: train_loss_raw=0.3825, running_loss=0.3666, LR=0.000100
[2025-08-27 15:13:35,815][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078664] [Batch 01664/03080] [00:20:25/00:17:22, 0.737s/it]: train_loss_raw=0.4875, running_loss=0.3674, LR=0.000100
[2025-08-27 15:13:41,317][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078672] [Batch 01672/03080] [00:20:31/00:17:16, 0.736s/it]: train_loss_raw=0.4288, running_loss=0.3680, LR=0.000100
[2025-08-27 15:13:47,482][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078680] [Batch 01680/03080] [00:20:37/00:17:11, 0.736s/it]: train_loss_raw=0.3855, running_loss=0.3697, LR=0.000100
[2025-08-27 15:13:53,524][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078688] [Batch 01688/03080] [00:20:43/00:17:05, 0.737s/it]: train_loss_raw=0.4449, running_loss=0.3701, LR=0.000100
[2025-08-27 15:13:59,359][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078696] [Batch 01696/03080] [00:20:49/00:16:59, 0.736s/it]: train_loss_raw=0.3521, running_loss=0.3719, LR=0.000100
[2025-08-27 15:14:05,218][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078704] [Batch 01704/03080] [00:20:54/00:16:53, 0.736s/it]: train_loss_raw=0.4228, running_loss=0.3708, LR=0.000100
[2025-08-27 15:14:11,223][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078712] [Batch 01712/03080] [00:21:00/00:16:47, 0.737s/it]: train_loss_raw=0.3799, running_loss=0.3700, LR=0.000100
[2025-08-27 15:14:17,327][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078720] [Batch 01720/03080] [00:21:07/00:16:41, 0.737s/it]: train_loss_raw=0.3953, running_loss=0.3712, LR=0.000100
[2025-08-27 15:14:23,452][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078728] [Batch 01728/03080] [00:21:13/00:16:36, 0.737s/it]: train_loss_raw=0.3561, running_loss=0.3699, LR=0.000100
[2025-08-27 15:14:29,482][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078736] [Batch 01736/03080] [00:21:19/00:16:30, 0.737s/it]: train_loss_raw=0.3859, running_loss=0.3713, LR=0.000100
[2025-08-27 15:14:35,123][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078744] [Batch 01744/03080] [00:21:24/00:16:24, 0.737s/it]: train_loss_raw=0.3905, running_loss=0.3736, LR=0.000100
[2025-08-27 15:14:41,169][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078752] [Batch 01752/03080] [00:21:30/00:16:18, 0.737s/it]: train_loss_raw=0.2862, running_loss=0.3733, LR=0.000100
[2025-08-27 15:14:47,011][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078760] [Batch 01760/03080] [00:21:36/00:16:12, 0.737s/it]: train_loss_raw=0.3787, running_loss=0.3721, LR=0.000100
[2025-08-27 15:14:53,051][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078768] [Batch 01768/03080] [00:21:42/00:16:06, 0.737s/it]: train_loss_raw=0.3833, running_loss=0.3710, LR=0.000100
[2025-08-27 15:14:58,763][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078776] [Batch 01776/03080] [00:21:48/00:16:00, 0.737s/it]: train_loss_raw=0.2938, running_loss=0.3702, LR=0.000100
[2025-08-27 15:15:04,412][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078784] [Batch 01784/03080] [00:21:54/00:15:54, 0.737s/it]: train_loss_raw=0.4624, running_loss=0.3709, LR=0.000100
[2025-08-27 15:15:09,824][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078792] [Batch 01792/03080] [00:21:59/00:15:48, 0.736s/it]: train_loss_raw=0.3774, running_loss=0.3705, LR=0.000100
[2025-08-27 15:15:15,933][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078800] [Batch 01800/03080] [00:22:05/00:15:42, 0.736s/it]: train_loss_raw=0.3208, running_loss=0.3703, LR=0.000100
[2025-08-27 15:15:22,126][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078808] [Batch 01808/03080] [00:22:11/00:15:37, 0.737s/it]: train_loss_raw=0.4430, running_loss=0.3732, LR=0.000100
[2025-08-27 15:15:27,986][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078816] [Batch 01816/03080] [00:22:17/00:15:31, 0.737s/it]: train_loss_raw=0.3692, running_loss=0.3727, LR=0.000100
[2025-08-27 15:15:33,806][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078824] [Batch 01824/03080] [00:22:23/00:15:25, 0.737s/it]: train_loss_raw=0.3242, running_loss=0.3720, LR=0.000100
[2025-08-27 15:15:39,683][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078832] [Batch 01832/03080] [00:22:29/00:15:19, 0.737s/it]: train_loss_raw=0.3239, running_loss=0.3700, LR=0.000100
[2025-08-27 15:15:45,561][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078840] [Batch 01840/03080] [00:22:35/00:15:13, 0.737s/it]: train_loss_raw=0.4044, running_loss=0.3702, LR=0.000100
[2025-08-27 15:15:51,290][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078848] [Batch 01848/03080] [00:22:41/00:15:07, 0.736s/it]: train_loss_raw=0.2819, running_loss=0.3697, LR=0.000100
[2025-08-27 15:15:56,767][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078856] [Batch 01856/03080] [00:22:46/00:15:01, 0.736s/it]: train_loss_raw=0.2935, running_loss=0.3671, LR=0.000100
[2025-08-27 15:16:02,617][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078864] [Batch 01864/03080] [00:22:52/00:14:55, 0.736s/it]: train_loss_raw=0.3622, running_loss=0.3656, LR=0.000100
[2025-08-27 15:16:08,237][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078872] [Batch 01872/03080] [00:22:57/00:14:49, 0.736s/it]: train_loss_raw=0.3790, running_loss=0.3663, LR=0.000100
[2025-08-27 15:16:13,841][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078880] [Batch 01880/03080] [00:23:03/00:14:43, 0.736s/it]: train_loss_raw=0.3327, running_loss=0.3666, LR=0.000100
[2025-08-27 15:16:19,726][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078888] [Batch 01888/03080] [00:23:09/00:14:37, 0.736s/it]: train_loss_raw=0.3517, running_loss=0.3677, LR=0.000100
[2025-08-27 15:16:25,582][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078896] [Batch 01896/03080] [00:23:15/00:14:31, 0.736s/it]: train_loss_raw=0.3693, running_loss=0.3687, LR=0.000100
[2025-08-27 15:16:31,705][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078904] [Batch 01904/03080] [00:23:21/00:14:25, 0.736s/it]: train_loss_raw=0.3372, running_loss=0.3670, LR=0.000100
[2025-08-27 15:16:37,721][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078912] [Batch 01912/03080] [00:23:27/00:14:19, 0.736s/it]: train_loss_raw=0.3375, running_loss=0.3678, LR=0.000100
[2025-08-27 15:16:43,786][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078920] [Batch 01920/03080] [00:23:33/00:14:14, 0.736s/it]: train_loss_raw=0.4305, running_loss=0.3668, LR=0.000100
[2025-08-27 15:16:49,790][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078928] [Batch 01928/03080] [00:23:39/00:14:08, 0.736s/it]: train_loss_raw=0.2590, running_loss=0.3669, LR=0.000100
[2025-08-27 15:16:55,596][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078936] [Batch 01936/03080] [00:23:45/00:14:02, 0.736s/it]: train_loss_raw=0.3744, running_loss=0.3661, LR=0.000100
[2025-08-27 15:17:01,594][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078944] [Batch 01944/03080] [00:23:51/00:13:56, 0.736s/it]: train_loss_raw=0.3637, running_loss=0.3666, LR=0.000100
[2025-08-27 15:17:07,283][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078952] [Batch 01952/03080] [00:23:57/00:13:50, 0.736s/it]: train_loss_raw=0.3310, running_loss=0.3667, LR=0.000100
[2025-08-27 15:17:13,206][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078960] [Batch 01960/03080] [00:24:02/00:13:44, 0.736s/it]: train_loss_raw=0.3717, running_loss=0.3661, LR=0.000100
[2025-08-27 15:17:19,256][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078968] [Batch 01968/03080] [00:24:09/00:13:38, 0.736s/it]: train_loss_raw=0.3585, running_loss=0.3682, LR=0.000100
[2025-08-27 15:17:25,160][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078976] [Batch 01976/03080] [00:24:14/00:13:32, 0.736s/it]: train_loss_raw=0.3646, running_loss=0.3665, LR=0.000100
[2025-08-27 15:17:31,084][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078984] [Batch 01984/03080] [00:24:20/00:13:26, 0.736s/it]: train_loss_raw=0.3479, running_loss=0.3669, LR=0.000100
[2025-08-27 15:17:36,833][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 078992] [Batch 01992/03080] [00:24:26/00:13:21, 0.736s/it]: train_loss_raw=0.3263, running_loss=0.3656, LR=0.000100
[2025-08-27 15:17:42,897][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079000] [Batch 02000/03080] [00:24:32/00:13:15, 0.736s/it]: train_loss_raw=0.3757, running_loss=0.3662, LR=0.000100
[2025-08-27 15:17:48,288][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079008] [Batch 02008/03080] [00:24:38/00:13:09, 0.736s/it]: train_loss_raw=0.3288, running_loss=0.3668, LR=0.000100
[2025-08-27 15:17:53,844][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079016] [Batch 02016/03080] [00:24:43/00:13:03, 0.736s/it]: train_loss_raw=0.3895, running_loss=0.3667, LR=0.000100
[2025-08-27 15:17:59,793][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079024] [Batch 02024/03080] [00:24:49/00:12:57, 0.736s/it]: train_loss_raw=0.4283, running_loss=0.3653, LR=0.000100
[2025-08-27 15:18:05,879][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079032] [Batch 02032/03080] [00:24:55/00:12:51, 0.736s/it]: train_loss_raw=0.4428, running_loss=0.3644, LR=0.000100
[2025-08-27 15:18:11,847][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079040] [Batch 02040/03080] [00:25:01/00:12:45, 0.736s/it]: train_loss_raw=0.3550, running_loss=0.3645, LR=0.000100
[2025-08-27 15:18:17,824][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079048] [Batch 02048/03080] [00:25:07/00:12:39, 0.736s/it]: train_loss_raw=0.3785, running_loss=0.3656, LR=0.000100
[2025-08-27 15:18:23,784][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079056] [Batch 02056/03080] [00:25:13/00:12:33, 0.736s/it]: train_loss_raw=0.3516, running_loss=0.3658, LR=0.000100
[2025-08-27 15:18:29,404][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079064] [Batch 02064/03080] [00:25:19/00:12:27, 0.736s/it]: train_loss_raw=0.4009, running_loss=0.3649, LR=0.000100
[2025-08-27 15:18:35,147][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079072] [Batch 02072/03080] [00:25:24/00:12:21, 0.736s/it]: train_loss_raw=0.3357, running_loss=0.3641, LR=0.000100
[2025-08-27 15:18:40,971][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079080] [Batch 02080/03080] [00:25:30/00:12:15, 0.736s/it]: train_loss_raw=0.3841, running_loss=0.3644, LR=0.000100
[2025-08-27 15:18:46,926][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079088] [Batch 02088/03080] [00:25:36/00:12:10, 0.736s/it]: train_loss_raw=0.4577, running_loss=0.3652, LR=0.000100
[2025-08-27 15:18:52,726][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079096] [Batch 02096/03080] [00:25:42/00:12:04, 0.736s/it]: train_loss_raw=0.3809, running_loss=0.3657, LR=0.000100
[2025-08-27 15:18:58,540][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079104] [Batch 02104/03080] [00:25:48/00:11:58, 0.736s/it]: train_loss_raw=0.3716, running_loss=0.3642, LR=0.000100
[2025-08-27 15:19:03,921][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079112] [Batch 02112/03080] [00:25:53/00:11:52, 0.736s/it]: train_loss_raw=0.3363, running_loss=0.3635, LR=0.000100
[2025-08-27 15:19:09,876][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079120] [Batch 02120/03080] [00:25:59/00:11:46, 0.736s/it]: train_loss_raw=0.4020, running_loss=0.3616, LR=0.000100
[2025-08-27 15:19:15,883][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079128] [Batch 02128/03080] [00:26:05/00:11:40, 0.736s/it]: train_loss_raw=0.3173, running_loss=0.3604, LR=0.000100
[2025-08-27 15:19:21,954][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079136] [Batch 02136/03080] [00:26:11/00:11:34, 0.736s/it]: train_loss_raw=0.4213, running_loss=0.3622, LR=0.000100
[2025-08-27 15:19:27,622][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079144] [Batch 02144/03080] [00:26:17/00:11:28, 0.736s/it]: train_loss_raw=0.3748, running_loss=0.3636, LR=0.000100
[2025-08-27 15:19:33,510][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079152] [Batch 02152/03080] [00:26:23/00:11:22, 0.736s/it]: train_loss_raw=0.3934, running_loss=0.3659, LR=0.000100
[2025-08-27 15:19:39,156][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079160] [Batch 02160/03080] [00:26:28/00:11:16, 0.736s/it]: train_loss_raw=0.3347, running_loss=0.3664, LR=0.000100
[2025-08-27 15:19:44,536][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079168] [Batch 02168/03080] [00:26:34/00:11:10, 0.735s/it]: train_loss_raw=0.3768, running_loss=0.3668, LR=0.000100
[2025-08-27 15:19:50,213][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079176] [Batch 02176/03080] [00:26:39/00:11:04, 0.735s/it]: train_loss_raw=0.3236, running_loss=0.3678, LR=0.000100
[2025-08-27 15:19:55,711][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079184] [Batch 02184/03080] [00:26:45/00:10:58, 0.735s/it]: train_loss_raw=0.4151, running_loss=0.3667, LR=0.000100
[2025-08-27 15:20:01,757][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079192] [Batch 02192/03080] [00:26:51/00:10:52, 0.735s/it]: train_loss_raw=0.3350, running_loss=0.3684, LR=0.000100
[2025-08-27 15:20:07,884][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079200] [Batch 02200/03080] [00:26:57/00:10:47, 0.735s/it]: train_loss_raw=0.4505, running_loss=0.3702, LR=0.000100
[2025-08-27 15:20:13,860][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079208] [Batch 02208/03080] [00:27:03/00:10:41, 0.735s/it]: train_loss_raw=0.3466, running_loss=0.3704, LR=0.000100
[2025-08-27 15:20:19,823][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079216] [Batch 02216/03080] [00:27:09/00:10:35, 0.735s/it]: train_loss_raw=0.3818, running_loss=0.3698, LR=0.000100
[2025-08-27 15:20:25,654][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079224] [Batch 02224/03080] [00:27:15/00:10:29, 0.735s/it]: train_loss_raw=0.3649, running_loss=0.3703, LR=0.000100
[2025-08-27 15:20:31,255][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079232] [Batch 02232/03080] [00:27:20/00:10:23, 0.735s/it]: train_loss_raw=0.3644, running_loss=0.3706, LR=0.000100
[2025-08-27 15:20:36,965][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079240] [Batch 02240/03080] [00:27:26/00:10:17, 0.735s/it]: train_loss_raw=0.4343, running_loss=0.3702, LR=0.000100
[2025-08-27 15:20:43,048][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079248] [Batch 02248/03080] [00:27:32/00:10:11, 0.735s/it]: train_loss_raw=0.3418, running_loss=0.3708, LR=0.000100
[2025-08-27 15:20:48,814][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079256] [Batch 02256/03080] [00:27:38/00:10:05, 0.735s/it]: train_loss_raw=0.3367, running_loss=0.3705, LR=0.000100
[2025-08-27 15:20:54,802][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079264] [Batch 02264/03080] [00:27:44/00:09:59, 0.735s/it]: train_loss_raw=0.4544, running_loss=0.3710, LR=0.000100
[2025-08-27 15:21:00,881][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079272] [Batch 02272/03080] [00:27:50/00:09:54, 0.735s/it]: train_loss_raw=0.4276, running_loss=0.3722, LR=0.000100
[2025-08-27 15:21:06,888][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079280] [Batch 02280/03080] [00:27:56/00:09:48, 0.735s/it]: train_loss_raw=0.4507, running_loss=0.3712, LR=0.000100
[2025-08-27 15:21:12,846][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079288] [Batch 02288/03080] [00:28:02/00:09:42, 0.735s/it]: train_loss_raw=0.3850, running_loss=0.3715, LR=0.000100
[2025-08-27 15:21:18,932][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079296] [Batch 02296/03080] [00:28:08/00:09:36, 0.735s/it]: train_loss_raw=0.3081, running_loss=0.3697, LR=0.000100
[2025-08-27 15:21:24,939][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079304] [Batch 02304/03080] [00:28:14/00:09:30, 0.736s/it]: train_loss_raw=0.4211, running_loss=0.3682, LR=0.000100
[2025-08-27 15:21:31,102][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079312] [Batch 02312/03080] [00:28:20/00:09:24, 0.736s/it]: train_loss_raw=0.4603, running_loss=0.3707, LR=0.000100
[2025-08-27 15:21:37,291][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079320] [Batch 02320/03080] [00:28:27/00:09:19, 0.736s/it]: train_loss_raw=0.3612, running_loss=0.3701, LR=0.000100
[2025-08-27 15:21:43,302][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079328] [Batch 02328/03080] [00:28:33/00:09:13, 0.736s/it]: train_loss_raw=0.3598, running_loss=0.3707, LR=0.000100
[2025-08-27 15:21:48,925][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079336] [Batch 02336/03080] [00:28:38/00:09:07, 0.736s/it]: train_loss_raw=0.3941, running_loss=0.3695, LR=0.000100
[2025-08-27 15:21:54,656][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079344] [Batch 02344/03080] [00:28:44/00:09:01, 0.736s/it]: train_loss_raw=0.3695, running_loss=0.3686, LR=0.000100
[2025-08-27 15:22:00,661][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079352] [Batch 02352/03080] [00:28:50/00:08:55, 0.736s/it]: train_loss_raw=0.3043, running_loss=0.3683, LR=0.000100
[2025-08-27 15:22:06,668][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079360] [Batch 02360/03080] [00:28:56/00:08:49, 0.736s/it]: train_loss_raw=0.3696, running_loss=0.3672, LR=0.000100
[2025-08-27 15:22:12,372][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079368] [Batch 02368/03080] [00:29:02/00:08:43, 0.736s/it]: train_loss_raw=0.3423, running_loss=0.3676, LR=0.000100
[2025-08-27 15:22:18,360][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079376] [Batch 02376/03080] [00:29:08/00:08:37, 0.736s/it]: train_loss_raw=0.4089, running_loss=0.3676, LR=0.000100
[2025-08-27 15:22:24,551][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079384] [Batch 02384/03080] [00:29:14/00:08:32, 0.736s/it]: train_loss_raw=0.3370, running_loss=0.3665, LR=0.000100
[2025-08-27 15:22:30,016][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079392] [Batch 02392/03080] [00:29:19/00:08:26, 0.736s/it]: train_loss_raw=0.3348, running_loss=0.3657, LR=0.000100
[2025-08-27 15:22:36,045][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079400] [Batch 02400/03080] [00:29:25/00:08:20, 0.736s/it]: train_loss_raw=0.3897, running_loss=0.3641, LR=0.000100
[2025-08-27 15:22:42,060][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079408] [Batch 02408/03080] [00:29:31/00:08:14, 0.736s/it]: train_loss_raw=0.3686, running_loss=0.3646, LR=0.000100
[2025-08-27 15:22:48,045][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079416] [Batch 02416/03080] [00:29:37/00:08:08, 0.736s/it]: train_loss_raw=0.3781, running_loss=0.3665, LR=0.000100
[2025-08-27 15:22:53,768][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079424] [Batch 02424/03080] [00:29:43/00:08:02, 0.736s/it]: train_loss_raw=0.3566, running_loss=0.3667, LR=0.000100
[2025-08-27 15:22:59,753][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079432] [Batch 02432/03080] [00:29:49/00:07:56, 0.736s/it]: train_loss_raw=0.4062, running_loss=0.3666, LR=0.000100
[2025-08-27 15:23:05,741][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079440] [Batch 02440/03080] [00:29:55/00:07:50, 0.736s/it]: train_loss_raw=0.4244, running_loss=0.3672, LR=0.000100
[2025-08-27 15:23:11,356][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079448] [Batch 02448/03080] [00:30:01/00:07:44, 0.736s/it]: train_loss_raw=0.3737, running_loss=0.3671, LR=0.000100
[2025-08-27 15:23:17,263][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079456] [Batch 02456/03080] [00:30:07/00:07:39, 0.736s/it]: train_loss_raw=0.3882, running_loss=0.3664, LR=0.000100
[2025-08-27 15:23:23,345][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079464] [Batch 02464/03080] [00:30:13/00:07:33, 0.736s/it]: train_loss_raw=0.2845, running_loss=0.3662, LR=0.000100
[2025-08-27 15:23:29,423][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079472] [Batch 02472/03080] [00:30:19/00:07:27, 0.736s/it]: train_loss_raw=0.3024, running_loss=0.3664, LR=0.000100
[2025-08-27 15:23:35,544][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079480] [Batch 02480/03080] [00:30:25/00:07:21, 0.736s/it]: train_loss_raw=0.3253, running_loss=0.3651, LR=0.000100
[2025-08-27 15:23:41,402][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079488] [Batch 02488/03080] [00:30:31/00:07:15, 0.736s/it]: train_loss_raw=0.3270, running_loss=0.3635, LR=0.000100
[2025-08-27 15:23:47,186][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079496] [Batch 02496/03080] [00:30:36/00:07:09, 0.736s/it]: train_loss_raw=0.3410, running_loss=0.3646, LR=0.000100
[2025-08-27 15:23:52,809][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079504] [Batch 02504/03080] [00:30:42/00:07:03, 0.736s/it]: train_loss_raw=0.3556, running_loss=0.3629, LR=0.000100
[2025-08-27 15:23:58,519][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079512] [Batch 02512/03080] [00:30:48/00:06:57, 0.736s/it]: train_loss_raw=0.2988, running_loss=0.3626, LR=0.000100
[2025-08-27 15:24:04,395][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079520] [Batch 02520/03080] [00:30:54/00:06:52, 0.736s/it]: train_loss_raw=0.3826, running_loss=0.3631, LR=0.000100
[2025-08-27 15:24:10,349][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079528] [Batch 02528/03080] [00:31:00/00:06:46, 0.736s/it]: train_loss_raw=0.3549, running_loss=0.3651, LR=0.000100
[2025-08-27 15:24:16,487][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079536] [Batch 02536/03080] [00:31:06/00:06:40, 0.736s/it]: train_loss_raw=0.2933, running_loss=0.3650, LR=0.000100
[2025-08-27 15:24:22,331][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079544] [Batch 02544/03080] [00:31:12/00:06:34, 0.736s/it]: train_loss_raw=0.4233, running_loss=0.3677, LR=0.000100
[2025-08-27 15:24:28,481][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079552] [Batch 02552/03080] [00:31:18/00:06:28, 0.736s/it]: train_loss_raw=0.3772, running_loss=0.3676, LR=0.000100
[2025-08-27 15:24:34,094][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079560] [Batch 02560/03080] [00:31:23/00:06:22, 0.736s/it]: train_loss_raw=0.2953, running_loss=0.3675, LR=0.000100
[2025-08-27 15:24:40,201][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079568] [Batch 02568/03080] [00:31:29/00:06:16, 0.736s/it]: train_loss_raw=0.3543, running_loss=0.3676, LR=0.000100
[2025-08-27 15:24:46,297][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079576] [Batch 02576/03080] [00:31:36/00:06:10, 0.736s/it]: train_loss_raw=0.3096, running_loss=0.3665, LR=0.000100
[2025-08-27 15:24:52,233][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079584] [Batch 02584/03080] [00:31:41/00:06:05, 0.736s/it]: train_loss_raw=0.4506, running_loss=0.3672, LR=0.000100
[2025-08-27 15:24:58,084][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079592] [Batch 02592/03080] [00:31:47/00:05:59, 0.736s/it]: train_loss_raw=0.3872, running_loss=0.3668, LR=0.000100
[2025-08-27 15:25:04,257][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079600] [Batch 02600/03080] [00:31:54/00:05:53, 0.736s/it]: train_loss_raw=0.3500, running_loss=0.3682, LR=0.000100
[2025-08-27 15:25:10,299][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079608] [Batch 02608/03080] [00:32:00/00:05:47, 0.736s/it]: train_loss_raw=0.4592, running_loss=0.3681, LR=0.000100
[2025-08-27 15:25:16,482][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079616] [Batch 02616/03080] [00:32:06/00:05:41, 0.736s/it]: train_loss_raw=0.3592, running_loss=0.3682, LR=0.000100
[2025-08-27 15:25:22,589][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079624] [Batch 02624/03080] [00:32:12/00:05:35, 0.736s/it]: train_loss_raw=0.4382, running_loss=0.3681, LR=0.000100
[2025-08-27 15:25:28,501][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079632] [Batch 02632/03080] [00:32:18/00:05:29, 0.736s/it]: train_loss_raw=0.3545, running_loss=0.3658, LR=0.000100
[2025-08-27 15:25:34,609][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079640] [Batch 02640/03080] [00:32:24/00:05:24, 0.736s/it]: train_loss_raw=0.3843, running_loss=0.3637, LR=0.000100
[2025-08-27 15:25:40,676][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079648] [Batch 02648/03080] [00:32:30/00:05:18, 0.737s/it]: train_loss_raw=0.3379, running_loss=0.3647, LR=0.000100
[2025-08-27 15:25:46,589][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079656] [Batch 02656/03080] [00:32:36/00:05:12, 0.737s/it]: train_loss_raw=0.3689, running_loss=0.3645, LR=0.000100
[2025-08-27 15:25:52,388][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079664] [Batch 02664/03080] [00:32:42/00:05:06, 0.737s/it]: train_loss_raw=0.4578, running_loss=0.3641, LR=0.000100
[2025-08-27 15:25:58,118][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079672] [Batch 02672/03080] [00:32:47/00:05:00, 0.736s/it]: train_loss_raw=0.3610, running_loss=0.3623, LR=0.000100
[2025-08-27 15:26:04,083][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079680] [Batch 02680/03080] [00:32:53/00:04:54, 0.737s/it]: train_loss_raw=0.3516, running_loss=0.3615, LR=0.000100
[2025-08-27 15:26:10,195][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079688] [Batch 02688/03080] [00:32:59/00:04:48, 0.737s/it]: train_loss_raw=0.3304, running_loss=0.3630, LR=0.000100
[2025-08-27 15:26:16,213][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079696] [Batch 02696/03080] [00:33:05/00:04:42, 0.737s/it]: train_loss_raw=0.3410, running_loss=0.3630, LR=0.000100
[2025-08-27 15:26:22,352][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079704] [Batch 02704/03080] [00:33:12/00:04:37, 0.737s/it]: train_loss_raw=0.3246, running_loss=0.3658, LR=0.000100
[2025-08-27 15:26:28,213][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079712] [Batch 02712/03080] [00:33:17/00:04:31, 0.737s/it]: train_loss_raw=0.3676, running_loss=0.3663, LR=0.000100
[2025-08-27 15:26:34,225][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079720] [Batch 02720/03080] [00:33:23/00:04:25, 0.737s/it]: train_loss_raw=0.4235, running_loss=0.3680, LR=0.000100
[2025-08-27 15:26:40,144][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079728] [Batch 02728/03080] [00:33:29/00:04:19, 0.737s/it]: train_loss_raw=0.3718, running_loss=0.3670, LR=0.000100
[2025-08-27 15:26:46,255][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079736] [Batch 02736/03080] [00:33:35/00:04:13, 0.737s/it]: train_loss_raw=0.3267, running_loss=0.3662, LR=0.000100
[2025-08-27 15:26:51,813][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079744] [Batch 02744/03080] [00:33:41/00:04:07, 0.737s/it]: train_loss_raw=0.3484, running_loss=0.3653, LR=0.000100
[2025-08-27 15:26:57,837][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079752] [Batch 02752/03080] [00:33:47/00:04:01, 0.737s/it]: train_loss_raw=0.4068, running_loss=0.3652, LR=0.000100
[2025-08-27 15:27:03,354][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079760] [Batch 02760/03080] [00:33:53/00:03:55, 0.737s/it]: train_loss_raw=0.3358, running_loss=0.3649, LR=0.000100
[2025-08-27 15:27:09,316][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079768] [Batch 02768/03080] [00:33:59/00:03:49, 0.737s/it]: train_loss_raw=0.4299, running_loss=0.3657, LR=0.000100
[2025-08-27 15:27:15,332][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079776] [Batch 02776/03080] [00:34:05/00:03:43, 0.737s/it]: train_loss_raw=0.3451, running_loss=0.3667, LR=0.000100
[2025-08-27 15:27:21,236][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079784] [Batch 02784/03080] [00:34:10/00:03:38, 0.737s/it]: train_loss_raw=0.2903, running_loss=0.3650, LR=0.000100
[2025-08-27 15:27:27,015][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079792] [Batch 02792/03080] [00:34:16/00:03:32, 0.737s/it]: train_loss_raw=0.3368, running_loss=0.3644, LR=0.000100
[2025-08-27 15:27:33,125][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079800] [Batch 02800/03080] [00:34:22/00:03:26, 0.737s/it]: train_loss_raw=0.3022, running_loss=0.3619, LR=0.000100
[2025-08-27 15:27:38,887][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079808] [Batch 02808/03080] [00:34:28/00:03:20, 0.737s/it]: train_loss_raw=0.2822, running_loss=0.3603, LR=0.000100
[2025-08-27 15:27:44,634][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079816] [Batch 02816/03080] [00:34:34/00:03:14, 0.737s/it]: train_loss_raw=0.3224, running_loss=0.3581, LR=0.000100
[2025-08-27 15:27:50,419][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079824] [Batch 02824/03080] [00:34:40/00:03:08, 0.737s/it]: train_loss_raw=0.3875, running_loss=0.3578, LR=0.000100
[2025-08-27 15:27:56,393][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079832] [Batch 02832/03080] [00:34:46/00:03:02, 0.737s/it]: train_loss_raw=0.3248, running_loss=0.3570, LR=0.000100
[2025-08-27 15:28:02,670][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079840] [Batch 02840/03080] [00:34:52/00:02:56, 0.737s/it]: train_loss_raw=0.4860, running_loss=0.3607, LR=0.000100
[2025-08-27 15:28:08,769][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079848] [Batch 02848/03080] [00:34:58/00:02:50, 0.737s/it]: train_loss_raw=0.3347, running_loss=0.3597, LR=0.000100
[2025-08-27 15:28:14,735][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079856] [Batch 02856/03080] [00:35:04/00:02:45, 0.737s/it]: train_loss_raw=0.4206, running_loss=0.3621, LR=0.000100
[2025-08-27 15:28:20,899][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079864] [Batch 02864/03080] [00:35:10/00:02:39, 0.737s/it]: train_loss_raw=0.3474, running_loss=0.3616, LR=0.000100
[2025-08-27 15:28:27,024][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079872] [Batch 02872/03080] [00:35:16/00:02:33, 0.737s/it]: train_loss_raw=0.3935, running_loss=0.3626, LR=0.000100
[2025-08-27 15:28:32,788][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079880] [Batch 02880/03080] [00:35:22/00:02:27, 0.737s/it]: train_loss_raw=0.3219, running_loss=0.3649, LR=0.000100
[2025-08-27 15:28:38,802][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079888] [Batch 02888/03080] [00:35:28/00:02:21, 0.737s/it]: train_loss_raw=0.3377, running_loss=0.3648, LR=0.000100
[2025-08-27 15:28:44,953][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079896] [Batch 02896/03080] [00:35:34/00:02:15, 0.737s/it]: train_loss_raw=0.3441, running_loss=0.3636, LR=0.000100
[2025-08-27 15:28:51,006][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079904] [Batch 02904/03080] [00:35:40/00:02:09, 0.737s/it]: train_loss_raw=0.2988, running_loss=0.3625, LR=0.000100
[2025-08-27 15:28:56,930][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079912] [Batch 02912/03080] [00:35:46/00:02:03, 0.737s/it]: train_loss_raw=0.4049, running_loss=0.3636, LR=0.000100
[2025-08-27 15:29:02,340][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079920] [Batch 02920/03080] [00:35:52/00:01:57, 0.737s/it]: train_loss_raw=0.3453, running_loss=0.3637, LR=0.000100
[2025-08-27 15:29:08,220][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079928] [Batch 02928/03080] [00:35:57/00:01:52, 0.737s/it]: train_loss_raw=0.3394, running_loss=0.3648, LR=0.000100
[2025-08-27 15:29:14,120][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079936] [Batch 02936/03080] [00:36:03/00:01:46, 0.737s/it]: train_loss_raw=0.4335, running_loss=0.3649, LR=0.000100
[2025-08-27 15:29:19,617][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079944] [Batch 02944/03080] [00:36:09/00:01:40, 0.737s/it]: train_loss_raw=0.3644, running_loss=0.3656, LR=0.000100
[2025-08-27 15:29:25,450][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079952] [Batch 02952/03080] [00:36:15/00:01:34, 0.737s/it]: train_loss_raw=0.3858, running_loss=0.3664, LR=0.000100
[2025-08-27 15:29:31,553][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079960] [Batch 02960/03080] [00:36:21/00:01:28, 0.737s/it]: train_loss_raw=0.3414, running_loss=0.3632, LR=0.000100
[2025-08-27 15:29:37,698][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079968] [Batch 02968/03080] [00:36:27/00:01:22, 0.737s/it]: train_loss_raw=0.3706, running_loss=0.3634, LR=0.000100
[2025-08-27 15:29:43,862][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079976] [Batch 02976/03080] [00:36:33/00:01:16, 0.737s/it]: train_loss_raw=0.4275, running_loss=0.3641, LR=0.000100
[2025-08-27 15:29:49,974][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079984] [Batch 02984/03080] [00:36:39/00:01:10, 0.737s/it]: train_loss_raw=0.3221, running_loss=0.3635, LR=0.000100
[2025-08-27 15:29:56,094][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 079992] [Batch 02992/03080] [00:36:45/00:01:04, 0.737s/it]: train_loss_raw=0.4886, running_loss=0.3630, LR=0.000100
[2025-08-27 15:30:01,539][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080000] [Batch 03000/03080] [00:36:51/00:00:58, 0.737s/it]: train_loss_raw=0.3352, running_loss=0.3619, LR=0.000100
[2025-08-27 15:30:11,164][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080008] [Batch 03008/03080] [00:37:00/00:00:53, 0.738s/it]: train_loss_raw=0.3997, running_loss=0.3649, LR=0.000100
[2025-08-27 15:30:16,996][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080016] [Batch 03016/03080] [00:37:06/00:00:47, 0.738s/it]: train_loss_raw=0.4274, running_loss=0.3670, LR=0.000100
[2025-08-27 15:30:22,828][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080024] [Batch 03024/03080] [00:37:12/00:00:41, 0.738s/it]: train_loss_raw=0.3551, running_loss=0.3679, LR=0.000100
[2025-08-27 15:30:28,557][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080032] [Batch 03032/03080] [00:37:18/00:00:35, 0.738s/it]: train_loss_raw=0.2809, running_loss=0.3642, LR=0.000100
[2025-08-27 15:30:34,595][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080040] [Batch 03040/03080] [00:37:24/00:00:29, 0.738s/it]: train_loss_raw=0.3766, running_loss=0.3634, LR=0.000100
[2025-08-27 15:30:40,375][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080048] [Batch 03048/03080] [00:37:30/00:00:23, 0.738s/it]: train_loss_raw=0.3354, running_loss=0.3619, LR=0.000100
[2025-08-27 15:30:46,163][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080056] [Batch 03056/03080] [00:37:35/00:00:17, 0.738s/it]: train_loss_raw=0.4053, running_loss=0.3634, LR=0.000100
[2025-08-27 15:30:51,892][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080064] [Batch 03064/03080] [00:37:41/00:00:11, 0.738s/it]: train_loss_raw=0.2851, running_loss=0.3637, LR=0.000100
[2025-08-27 15:30:57,431][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080072] [Batch 03072/03080] [00:37:47/00:00:05, 0.738s/it]: train_loss_raw=0.3395, running_loss=0.3626, LR=0.000100
[2025-08-27 15:31:09,923][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 080080] [Batch 03080/03080] [00:37:59/00:00:00, 0.740s/it]: train_loss_raw=0.3531, running_loss=0.3616, LR=0.000100
[2025-08-27 15:31:10,394][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-27 15:31:20,910][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00007/00310] [00:00:10/00:06:36, 1.314s/it]
[2025-08-27 15:31:33,248][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00015/00310] [00:00:22/00:06:59, 1.428s/it]
[2025-08-27 15:31:44,544][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00023/00310] [00:00:34/00:06:46, 1.423s/it]
[2025-08-27 15:31:56,439][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00031/00310] [00:00:46/00:06:40, 1.439s/it]
[2025-08-27 15:32:08,808][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00039/00310] [00:00:58/00:06:34, 1.460s/it]
[2025-08-27 15:32:20,764][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00047/00310] [00:01:10/00:06:24, 1.466s/it]
[2025-08-27 15:32:32,398][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00055/00310] [00:01:22/00:06:11, 1.464s/it]
[2025-08-27 15:32:44,684][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00063/00310] [00:01:34/00:06:02, 1.473s/it]
[2025-08-27 15:32:57,044][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00071/00310] [00:01:46/00:05:52, 1.481s/it]
[2025-08-27 15:33:08,968][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00079/00310] [00:01:58/00:05:40, 1.482s/it]
[2025-08-27 15:33:19,955][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00087/00310] [00:02:09/00:05:26, 1.472s/it]
[2025-08-27 15:33:32,038][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00095/00310] [00:02:21/00:05:15, 1.475s/it]
[2025-08-27 15:33:44,149][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00103/00310] [00:02:33/00:05:04, 1.478s/it]
[2025-08-27 15:33:56,493][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00111/00310] [00:02:46/00:04:53, 1.483s/it]
[2025-08-27 15:34:08,188][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00119/00310] [00:02:57/00:04:41, 1.482s/it]
[2025-08-27 15:34:19,944][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00127/00310] [00:03:09/00:04:29, 1.481s/it]
[2025-08-27 15:34:31,984][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00135/00310] [00:03:21/00:04:17, 1.482s/it]
[2025-08-27 15:34:42,868][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00143/00310] [00:03:32/00:04:04, 1.476s/it]
[2025-08-27 15:34:54,014][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00151/00310] [00:03:43/00:03:52, 1.471s/it]
[2025-08-27 15:35:04,708][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00159/00310] [00:03:54/00:03:39, 1.464s/it]
[2025-08-27 15:35:16,725][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00167/00310] [00:04:06/00:03:28, 1.466s/it]
[2025-08-27 15:35:27,533][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00175/00310] [00:04:17/00:03:15, 1.461s/it]
[2025-08-27 15:35:38,399][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00183/00310] [00:04:28/00:03:03, 1.457s/it]
[2025-08-27 15:35:50,512][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00191/00310] [00:04:40/00:02:52, 1.459s/it]
[2025-08-27 15:36:01,308][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00199/00310] [00:04:50/00:02:40, 1.455s/it]
[2025-08-27 15:36:11,609][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00207/00310] [00:05:01/00:02:27, 1.448s/it]
[2025-08-27 15:36:23,077][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00215/00310] [00:05:12/00:02:16, 1.448s/it]
[2025-08-27 15:36:33,938][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00223/00310] [00:05:23/00:02:04, 1.444s/it]
[2025-08-27 15:36:44,780][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00231/00310] [00:05:34/00:01:52, 1.441s/it]
[2025-08-27 15:36:55,860][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00239/00310] [00:05:45/00:01:40, 1.439s/it]
[2025-08-27 15:37:06,727][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00247/00310] [00:05:56/00:01:29, 1.437s/it]
[2025-08-27 15:37:18,828][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00255/00310] [00:06:08/00:01:17, 1.439s/it]
[2025-08-27 15:37:30,742][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00263/00310] [00:06:20/00:01:06, 1.441s/it]
[2025-08-27 15:37:41,494][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00271/00310] [00:06:31/00:00:54, 1.438s/it]
[2025-08-27 15:37:51,967][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00279/00310] [00:06:41/00:00:43, 1.434s/it]
[2025-08-27 15:38:03,009][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00287/00310] [00:06:52/00:00:31, 1.433s/it]
[2025-08-27 15:38:14,199][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00295/00310] [00:07:03/00:00:20, 1.432s/it]
[2025-08-27 15:38:25,839][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 080081] [Batch 00303/00310] [00:07:15/00:00:08, 1.432s/it]
[2025-08-27 15:38:35,040][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.36165, valid_loss=1.42135
[2025-08-27 15:38:35,040][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-27 15:38:35,040][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.478
[2025-08-27 15:38:35,041][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.155
[2025-08-27 15:38:35,041][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.158
[2025-08-27 15:38:35,042][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.086
[2025-08-27 15:38:35,058][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 20:11:48, remaining time 03:06:25, 00:46:36 per epoch
[2025-08-27 15:38:44,212][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080088] [Batch 00008/03080] [00:00:05/00:36:26, 0.712s/it]: train_loss_raw=0.3494, running_loss=0.2947, LR=0.000100
[2025-08-27 15:38:50,318][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080096] [Batch 00016/03080] [00:00:11/00:37:39, 0.737s/it]: train_loss_raw=0.2654, running_loss=0.2989, LR=0.000100
[2025-08-27 15:38:56,674][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080104] [Batch 00024/03080] [00:00:18/00:38:31, 0.756s/it]: train_loss_raw=0.3364, running_loss=0.3035, LR=0.000100
[2025-08-27 15:39:02,762][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080112] [Batch 00032/03080] [00:00:24/00:38:29, 0.758s/it]: train_loss_raw=0.3695, running_loss=0.3083, LR=0.000100
[2025-08-27 15:39:08,807][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080120] [Batch 00040/03080] [00:00:30/00:38:21, 0.757s/it]: train_loss_raw=0.3495, running_loss=0.3099, LR=0.000100
[2025-08-27 15:39:14,767][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080128] [Batch 00048/03080] [00:00:36/00:38:09, 0.755s/it]: train_loss_raw=0.3940, running_loss=0.3148, LR=0.000100
[2025-08-27 15:39:20,619][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080136] [Batch 00056/03080] [00:00:42/00:37:53, 0.752s/it]: train_loss_raw=0.2579, running_loss=0.3165, LR=0.000100
[2025-08-27 15:39:26,570][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080144] [Batch 00064/03080] [00:00:48/00:37:44, 0.751s/it]: train_loss_raw=0.2939, running_loss=0.3192, LR=0.000100
[2025-08-27 15:39:32,486][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080152] [Batch 00072/03080] [00:00:53/00:37:34, 0.750s/it]: train_loss_raw=0.2311, running_loss=0.3194, LR=0.000100
[2025-08-27 15:39:38,231][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080160] [Batch 00080/03080] [00:00:59/00:37:19, 0.746s/it]: train_loss_raw=0.3992, running_loss=0.3194, LR=0.000100
[2025-08-27 15:39:44,255][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080168] [Batch 00088/03080] [00:01:05/00:37:15, 0.747s/it]: train_loss_raw=0.3113, running_loss=0.3197, LR=0.000100
[2025-08-27 15:39:50,292][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080176] [Batch 00096/03080] [00:01:11/00:37:10, 0.748s/it]: train_loss_raw=0.3144, running_loss=0.3231, LR=0.000100
[2025-08-27 15:39:56,084][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080184] [Batch 00104/03080] [00:01:17/00:36:59, 0.746s/it]: train_loss_raw=0.2677, running_loss=0.3240, LR=0.000100
[2025-08-27 15:40:02,108][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080192] [Batch 00112/03080] [00:01:23/00:36:55, 0.746s/it]: train_loss_raw=0.3605, running_loss=0.3253, LR=0.000100
[2025-08-27 15:40:08,140][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080200] [Batch 00120/03080] [00:01:29/00:36:50, 0.747s/it]: train_loss_raw=0.3450, running_loss=0.3272, LR=0.000100
[2025-08-27 15:40:14,108][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080208] [Batch 00128/03080] [00:01:35/00:36:44, 0.747s/it]: train_loss_raw=0.4102, running_loss=0.3299, LR=0.000100
[2025-08-27 15:40:19,847][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080216] [Batch 00136/03080] [00:01:41/00:36:33, 0.745s/it]: train_loss_raw=0.2551, running_loss=0.3304, LR=0.000100
[2025-08-27 15:40:25,423][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080224] [Batch 00144/03080] [00:01:46/00:36:19, 0.742s/it]: train_loss_raw=0.3055, running_loss=0.3312, LR=0.000100
[2025-08-27 15:40:31,242][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080232] [Batch 00152/03080] [00:01:52/00:36:11, 0.742s/it]: train_loss_raw=0.3703, running_loss=0.3323, LR=0.000100
[2025-08-27 15:40:37,004][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080240] [Batch 00160/03080] [00:01:58/00:36:02, 0.741s/it]: train_loss_raw=0.3998, running_loss=0.3327, LR=0.000100
[2025-08-27 15:40:43,046][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080248] [Batch 00168/03080] [00:02:04/00:35:58, 0.741s/it]: train_loss_raw=0.3032, running_loss=0.3343, LR=0.000100
[2025-08-27 15:40:48,623][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080256] [Batch 00176/03080] [00:02:10/00:35:46, 0.739s/it]: train_loss_raw=0.3340, running_loss=0.3338, LR=0.000100
[2025-08-27 15:40:54,323][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080264] [Batch 00184/03080] [00:02:15/00:35:37, 0.738s/it]: train_loss_raw=0.3365, running_loss=0.3329, LR=0.000100
[2025-08-27 15:40:59,870][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080272] [Batch 00192/03080] [00:02:21/00:35:26, 0.736s/it]: train_loss_raw=0.3970, running_loss=0.3340, LR=0.000100
[2025-08-27 15:41:05,917][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080280] [Batch 00200/03080] [00:02:27/00:35:22, 0.737s/it]: train_loss_raw=0.3630, running_loss=0.3345, LR=0.000100
[2025-08-27 15:41:11,710][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080288] [Batch 00208/03080] [00:02:33/00:35:15, 0.736s/it]: train_loss_raw=0.3419, running_loss=0.3348, LR=0.000100
[2025-08-27 15:41:17,643][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080296] [Batch 00216/03080] [00:02:39/00:35:09, 0.737s/it]: train_loss_raw=0.3603, running_loss=0.3364, LR=0.000100
[2025-08-27 15:41:23,627][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080304] [Batch 00224/03080] [00:02:45/00:35:05, 0.737s/it]: train_loss_raw=0.2757, running_loss=0.3371, LR=0.000100
[2025-08-27 15:41:29,678][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080312] [Batch 00232/03080] [00:02:51/00:35:01, 0.738s/it]: train_loss_raw=0.4717, running_loss=0.3407, LR=0.000100
[2025-08-27 15:41:35,570][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080320] [Batch 00240/03080] [00:02:57/00:34:55, 0.738s/it]: train_loss_raw=0.2971, running_loss=0.3395, LR=0.000100
[2025-08-27 15:41:41,568][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080328] [Batch 00248/03080] [00:03:03/00:34:50, 0.738s/it]: train_loss_raw=0.3277, running_loss=0.3379, LR=0.000100
[2025-08-27 15:41:47,601][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080336] [Batch 00256/03080] [00:03:09/00:34:45, 0.739s/it]: train_loss_raw=0.3373, running_loss=0.3371, LR=0.000100
[2025-08-27 15:41:53,326][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080344] [Batch 00264/03080] [00:03:14/00:34:37, 0.738s/it]: train_loss_raw=0.3451, running_loss=0.3389, LR=0.000100
[2025-08-27 15:41:59,175][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080352] [Batch 00272/03080] [00:03:20/00:34:31, 0.738s/it]: train_loss_raw=0.3295, running_loss=0.3410, LR=0.000100
[2025-08-27 15:42:05,172][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080360] [Batch 00280/03080] [00:03:26/00:34:26, 0.738s/it]: train_loss_raw=0.2935, running_loss=0.3404, LR=0.000100
[2025-08-27 15:42:11,205][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080368] [Batch 00288/03080] [00:03:32/00:34:21, 0.738s/it]: train_loss_raw=0.3073, running_loss=0.3428, LR=0.000100
[2025-08-27 15:42:17,415][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080376] [Batch 00296/03080] [00:03:38/00:34:18, 0.740s/it]: train_loss_raw=0.3933, running_loss=0.3427, LR=0.000100
[2025-08-27 15:42:22,986][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080384] [Batch 00304/03080] [00:03:44/00:34:09, 0.738s/it]: train_loss_raw=0.4233, running_loss=0.3442, LR=0.000100
[2025-08-27 15:42:28,402][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080392] [Batch 00312/03080] [00:03:49/00:33:59, 0.737s/it]: train_loss_raw=0.3817, running_loss=0.3451, LR=0.000100
[2025-08-27 15:42:33,932][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080400] [Batch 00320/03080] [00:03:55/00:33:50, 0.736s/it]: train_loss_raw=0.2923, running_loss=0.3441, LR=0.000100
[2025-08-27 15:42:39,847][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080408] [Batch 00328/03080] [00:04:01/00:33:44, 0.736s/it]: train_loss_raw=0.3561, running_loss=0.3439, LR=0.000100
[2025-08-27 15:42:45,808][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080416] [Batch 00336/03080] [00:04:07/00:33:39, 0.736s/it]: train_loss_raw=0.3110, running_loss=0.3439, LR=0.000100
[2025-08-27 15:42:51,478][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080424] [Batch 00344/03080] [00:04:12/00:33:31, 0.735s/it]: train_loss_raw=0.2807, running_loss=0.3435, LR=0.000100
[2025-08-27 15:42:56,903][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080432] [Batch 00352/03080] [00:04:18/00:33:22, 0.734s/it]: train_loss_raw=0.3244, running_loss=0.3438, LR=0.000100
[2025-08-27 15:43:02,888][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080440] [Batch 00360/03080] [00:04:24/00:33:17, 0.734s/it]: train_loss_raw=0.2996, running_loss=0.3424, LR=0.000100
[2025-08-27 15:43:09,090][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080448] [Batch 00368/03080] [00:04:30/00:33:13, 0.735s/it]: train_loss_raw=0.3785, running_loss=0.3419, LR=0.000100
[2025-08-27 15:43:14,874][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080456] [Batch 00376/03080] [00:04:36/00:33:07, 0.735s/it]: train_loss_raw=0.3205, running_loss=0.3429, LR=0.000100
[2025-08-27 15:43:20,757][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080464] [Batch 00384/03080] [00:04:42/00:33:01, 0.735s/it]: train_loss_raw=0.3823, running_loss=0.3436, LR=0.000100
[2025-08-27 15:43:26,460][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080472] [Batch 00392/03080] [00:04:47/00:32:54, 0.735s/it]: train_loss_raw=0.3225, running_loss=0.3437, LR=0.000100
[2025-08-27 15:43:31,899][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080480] [Batch 00400/03080] [00:04:53/00:32:45, 0.733s/it]: train_loss_raw=0.3277, running_loss=0.3421, LR=0.000100
[2025-08-27 15:43:37,635][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080488] [Batch 00408/03080] [00:04:59/00:32:38, 0.733s/it]: train_loss_raw=0.4215, running_loss=0.3424, LR=0.000100
[2025-08-27 15:43:43,112][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080496] [Batch 00416/03080] [00:05:04/00:32:30, 0.732s/it]: train_loss_raw=0.3135, running_loss=0.3429, LR=0.000100
[2025-08-27 15:43:48,909][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080504] [Batch 00424/03080] [00:05:10/00:32:24, 0.732s/it]: train_loss_raw=0.3901, running_loss=0.3428, LR=0.000100
[2025-08-27 15:43:54,454][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080512] [Batch 00432/03080] [00:05:15/00:32:16, 0.731s/it]: train_loss_raw=0.2765, running_loss=0.3427, LR=0.000100
[2025-08-27 15:44:00,541][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080520] [Batch 00440/03080] [00:05:22/00:32:12, 0.732s/it]: train_loss_raw=0.3275, running_loss=0.3405, LR=0.000100
[2025-08-27 15:44:06,545][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080528] [Batch 00448/03080] [00:05:28/00:32:07, 0.732s/it]: train_loss_raw=0.3195, running_loss=0.3403, LR=0.000100
[2025-08-27 15:44:12,504][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080536] [Batch 00456/03080] [00:05:33/00:32:01, 0.732s/it]: train_loss_raw=0.2848, running_loss=0.3396, LR=0.000100
[2025-08-27 15:44:18,511][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080544] [Batch 00464/03080] [00:05:39/00:31:56, 0.733s/it]: train_loss_raw=0.3502, running_loss=0.3390, LR=0.000100
[2025-08-27 15:44:24,159][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080552] [Batch 00472/03080] [00:05:45/00:31:49, 0.732s/it]: train_loss_raw=0.3053, running_loss=0.3369, LR=0.000100
[2025-08-27 15:44:29,976][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080560] [Batch 00480/03080] [00:05:51/00:31:43, 0.732s/it]: train_loss_raw=0.3569, running_loss=0.3377, LR=0.000100
[2025-08-27 15:44:35,388][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080568] [Batch 00488/03080] [00:05:56/00:31:35, 0.731s/it]: train_loss_raw=0.3105, running_loss=0.3380, LR=0.000100
[2025-08-27 15:44:40,922][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080576] [Batch 00496/03080] [00:06:02/00:31:28, 0.731s/it]: train_loss_raw=0.3560, running_loss=0.3394, LR=0.000100
[2025-08-27 15:44:46,835][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080584] [Batch 00504/03080] [00:06:08/00:31:22, 0.731s/it]: train_loss_raw=0.3003, running_loss=0.3388, LR=0.000100
[2025-08-27 15:44:52,580][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080592] [Batch 00512/03080] [00:06:14/00:31:16, 0.731s/it]: train_loss_raw=0.4254, running_loss=0.3402, LR=0.000100
[2025-08-27 15:44:58,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080600] [Batch 00520/03080] [00:06:20/00:31:11, 0.731s/it]: train_loss_raw=0.2757, running_loss=0.3378, LR=0.000100
[2025-08-27 15:45:04,683][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080608] [Batch 00528/03080] [00:06:26/00:31:06, 0.731s/it]: train_loss_raw=0.3565, running_loss=0.3376, LR=0.000100
[2025-08-27 15:45:10,699][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080616] [Batch 00536/03080] [00:06:32/00:31:01, 0.732s/it]: train_loss_raw=0.3097, running_loss=0.3373, LR=0.000100
[2025-08-27 15:45:16,710][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080624] [Batch 00544/03080] [00:06:38/00:30:56, 0.732s/it]: train_loss_raw=0.4122, running_loss=0.3385, LR=0.000100
[2025-08-27 15:45:22,559][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080632] [Batch 00552/03080] [00:06:44/00:30:50, 0.732s/it]: train_loss_raw=0.3198, running_loss=0.3382, LR=0.000100
[2025-08-27 15:45:28,436][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080640] [Batch 00560/03080] [00:06:49/00:30:44, 0.732s/it]: train_loss_raw=0.3232, running_loss=0.3378, LR=0.000100
[2025-08-27 15:45:34,239][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080648] [Batch 00568/03080] [00:06:55/00:30:38, 0.732s/it]: train_loss_raw=0.3756, running_loss=0.3384, LR=0.000100
[2025-08-27 15:45:39,802][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080656] [Batch 00576/03080] [00:07:01/00:30:31, 0.731s/it]: train_loss_raw=0.4139, running_loss=0.3387, LR=0.000100
[2025-08-27 15:45:45,504][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080664] [Batch 00584/03080] [00:07:06/00:30:24, 0.731s/it]: train_loss_raw=0.3467, running_loss=0.3400, LR=0.000100
[2025-08-27 15:45:51,485][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080672] [Batch 00592/03080] [00:07:12/00:30:19, 0.731s/it]: train_loss_raw=0.3999, running_loss=0.3396, LR=0.000100
[2025-08-27 15:45:57,665][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080680] [Batch 00600/03080] [00:07:19/00:30:15, 0.732s/it]: train_loss_raw=0.3713, running_loss=0.3395, LR=0.000100
[2025-08-27 15:46:03,682][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080688] [Batch 00608/03080] [00:07:25/00:30:09, 0.732s/it]: train_loss_raw=0.3293, running_loss=0.3394, LR=0.000100
[2025-08-27 15:46:09,615][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080696] [Batch 00616/03080] [00:07:31/00:30:04, 0.732s/it]: train_loss_raw=0.2987, running_loss=0.3386, LR=0.000100
[2025-08-27 15:46:15,387][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080704] [Batch 00624/03080] [00:07:36/00:29:58, 0.732s/it]: train_loss_raw=0.4034, running_loss=0.3392, LR=0.000100
[2025-08-27 15:46:21,027][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080712] [Batch 00632/03080] [00:07:42/00:29:51, 0.732s/it]: train_loss_raw=0.4196, running_loss=0.3417, LR=0.000100
[2025-08-27 15:46:26,649][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080720] [Batch 00640/03080] [00:07:48/00:29:44, 0.731s/it]: train_loss_raw=0.3703, running_loss=0.3429, LR=0.000100
[2025-08-27 15:46:32,739][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080728] [Batch 00648/03080] [00:07:54/00:29:39, 0.732s/it]: train_loss_raw=0.4275, running_loss=0.3428, LR=0.000100
[2025-08-27 15:46:38,835][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080736] [Batch 00656/03080] [00:08:00/00:29:34, 0.732s/it]: train_loss_raw=0.3646, running_loss=0.3429, LR=0.000100
[2025-08-27 15:46:44,554][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080744] [Batch 00664/03080] [00:08:06/00:29:28, 0.732s/it]: train_loss_raw=0.3342, running_loss=0.3423, LR=0.000100
[2025-08-27 15:46:50,214][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080752] [Batch 00672/03080] [00:08:11/00:29:21, 0.732s/it]: train_loss_raw=0.3062, running_loss=0.3411, LR=0.000100
[2025-08-27 15:46:55,936][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080760] [Batch 00680/03080] [00:08:17/00:29:15, 0.731s/it]: train_loss_raw=0.3017, running_loss=0.3419, LR=0.000100
[2025-08-27 15:47:01,906][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080768] [Batch 00688/03080] [00:08:23/00:29:10, 0.732s/it]: train_loss_raw=0.3887, running_loss=0.3405, LR=0.000100
[2025-08-27 15:47:07,939][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080776] [Batch 00696/03080] [00:08:29/00:29:04, 0.732s/it]: train_loss_raw=0.3585, running_loss=0.3429, LR=0.000100
[2025-08-27 15:47:13,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080784] [Batch 00704/03080] [00:08:34/00:28:57, 0.731s/it]: train_loss_raw=0.2714, running_loss=0.3432, LR=0.000100
[2025-08-27 15:47:19,321][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080792] [Batch 00712/03080] [00:08:40/00:28:52, 0.731s/it]: train_loss_raw=0.3749, running_loss=0.3432, LR=0.000100
[2025-08-27 15:47:25,172][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080800] [Batch 00720/03080] [00:08:46/00:28:46, 0.731s/it]: train_loss_raw=0.3791, running_loss=0.3433, LR=0.000100
[2025-08-27 15:47:31,169][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080808] [Batch 00728/03080] [00:08:52/00:28:40, 0.732s/it]: train_loss_raw=0.3588, running_loss=0.3433, LR=0.000100
[2025-08-27 15:47:37,026][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080816] [Batch 00736/03080] [00:08:58/00:28:35, 0.732s/it]: train_loss_raw=0.3043, running_loss=0.3420, LR=0.000100
[2025-08-27 15:47:43,278][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080824] [Batch 00744/03080] [00:09:04/00:28:30, 0.732s/it]: train_loss_raw=0.2759, running_loss=0.3417, LR=0.000100
[2025-08-27 15:47:49,367][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080832] [Batch 00752/03080] [00:09:10/00:28:25, 0.733s/it]: train_loss_raw=0.4020, running_loss=0.3415, LR=0.000100
[2025-08-27 15:47:55,345][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080840] [Batch 00760/03080] [00:09:16/00:28:19, 0.733s/it]: train_loss_raw=0.3680, running_loss=0.3404, LR=0.000100
[2025-08-27 15:48:01,345][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080848] [Batch 00768/03080] [00:09:22/00:28:14, 0.733s/it]: train_loss_raw=0.3780, running_loss=0.3387, LR=0.000100
[2025-08-27 15:48:07,321][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080856] [Batch 00776/03080] [00:09:28/00:28:08, 0.733s/it]: train_loss_raw=0.3489, running_loss=0.3376, LR=0.000100
[2025-08-27 15:48:12,991][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080864] [Batch 00784/03080] [00:09:34/00:28:02, 0.733s/it]: train_loss_raw=0.3514, running_loss=0.3386, LR=0.000100
[2025-08-27 15:48:18,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080872] [Batch 00792/03080] [00:09:40/00:27:56, 0.733s/it]: train_loss_raw=0.4440, running_loss=0.3411, LR=0.000100
[2025-08-27 15:48:24,774][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080880] [Batch 00800/03080] [00:09:46/00:27:50, 0.733s/it]: train_loss_raw=0.3452, running_loss=0.3408, LR=0.000100
[2025-08-27 15:48:30,695][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080888] [Batch 00808/03080] [00:09:52/00:27:45, 0.733s/it]: train_loss_raw=0.3121, running_loss=0.3419, LR=0.000100
[2025-08-27 15:48:36,744][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080896] [Batch 00816/03080] [00:09:58/00:27:39, 0.733s/it]: train_loss_raw=0.3552, running_loss=0.3438, LR=0.000100
[2025-08-27 15:48:42,708][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080904] [Batch 00824/03080] [00:10:04/00:27:34, 0.733s/it]: train_loss_raw=0.3327, running_loss=0.3445, LR=0.000100
[2025-08-27 15:48:48,375][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080912] [Batch 00832/03080] [00:10:09/00:27:27, 0.733s/it]: train_loss_raw=0.3177, running_loss=0.3436, LR=0.000100
[2025-08-27 15:48:54,421][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080920] [Batch 00840/03080] [00:10:15/00:27:22, 0.733s/it]: train_loss_raw=0.3304, running_loss=0.3434, LR=0.000100
[2025-08-27 15:49:00,445][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080928] [Batch 00848/03080] [00:10:21/00:27:16, 0.733s/it]: train_loss_raw=0.4296, running_loss=0.3457, LR=0.000100
[2025-08-27 15:49:06,300][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080936] [Batch 00856/03080] [00:10:27/00:27:11, 0.733s/it]: train_loss_raw=0.3515, running_loss=0.3458, LR=0.000100
[2025-08-27 15:49:11,910][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080944] [Batch 00864/03080] [00:10:33/00:27:04, 0.733s/it]: train_loss_raw=0.3785, running_loss=0.3454, LR=0.000100
[2025-08-27 15:49:17,798][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080952] [Batch 00872/03080] [00:10:39/00:26:58, 0.733s/it]: train_loss_raw=0.3404, running_loss=0.3463, LR=0.000100
[2025-08-27 15:49:23,668][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080960] [Batch 00880/03080] [00:10:45/00:26:52, 0.733s/it]: train_loss_raw=0.3451, running_loss=0.3465, LR=0.000100
[2025-08-27 15:49:29,162][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080968] [Batch 00888/03080] [00:10:50/00:26:46, 0.733s/it]: train_loss_raw=0.3520, running_loss=0.3466, LR=0.000100
[2025-08-27 15:49:34,820][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080976] [Batch 00896/03080] [00:10:56/00:26:39, 0.732s/it]: train_loss_raw=0.2714, running_loss=0.3456, LR=0.000100
[2025-08-27 15:49:40,832][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080984] [Batch 00904/03080] [00:11:02/00:26:34, 0.733s/it]: train_loss_raw=0.3180, running_loss=0.3457, LR=0.000100
[2025-08-27 15:49:46,306][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 080992] [Batch 00912/03080] [00:11:07/00:26:27, 0.732s/it]: train_loss_raw=0.3827, running_loss=0.3467, LR=0.000100
[2025-08-27 15:49:51,774][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081000] [Batch 00920/03080] [00:11:13/00:26:20, 0.732s/it]: train_loss_raw=0.3131, running_loss=0.3479, LR=0.000100
[2025-08-27 15:49:57,267][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081008] [Batch 00928/03080] [00:11:18/00:26:13, 0.731s/it]: train_loss_raw=0.4260, running_loss=0.3491, LR=0.000100
[2025-08-27 15:50:03,143][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081016] [Batch 00936/03080] [00:11:24/00:26:08, 0.731s/it]: train_loss_raw=0.3378, running_loss=0.3469, LR=0.000100
[2025-08-27 15:50:09,038][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081024] [Batch 00944/03080] [00:11:30/00:26:02, 0.731s/it]: train_loss_raw=0.4123, running_loss=0.3475, LR=0.000100
[2025-08-27 15:50:14,561][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081032] [Batch 00952/03080] [00:11:36/00:25:55, 0.731s/it]: train_loss_raw=0.3426, running_loss=0.3466, LR=0.000100
[2025-08-27 15:50:20,553][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081040] [Batch 00960/03080] [00:11:42/00:25:50, 0.731s/it]: train_loss_raw=0.3794, running_loss=0.3463, LR=0.000100
[2025-08-27 15:50:26,340][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081048] [Batch 00968/03080] [00:11:47/00:25:44, 0.731s/it]: train_loss_raw=0.4350, running_loss=0.3468, LR=0.000100
[2025-08-27 15:50:31,939][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081056] [Batch 00976/03080] [00:11:53/00:25:37, 0.731s/it]: train_loss_raw=0.3745, running_loss=0.3468, LR=0.000100
[2025-08-27 15:50:37,597][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081064] [Batch 00984/03080] [00:11:59/00:25:31, 0.731s/it]: train_loss_raw=0.3278, running_loss=0.3469, LR=0.000100
[2025-08-27 15:50:43,460][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081072] [Batch 00992/03080] [00:12:04/00:25:25, 0.731s/it]: train_loss_raw=0.3247, running_loss=0.3454, LR=0.000100
[2025-08-27 15:50:49,562][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081080] [Batch 01000/03080] [00:12:11/00:25:20, 0.731s/it]: train_loss_raw=0.3299, running_loss=0.3472, LR=0.000100
[2025-08-27 15:50:55,261][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081088] [Batch 01008/03080] [00:12:16/00:25:14, 0.731s/it]: train_loss_raw=0.2748, running_loss=0.3458, LR=0.000100
[2025-08-27 15:51:01,229][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081096] [Batch 01016/03080] [00:12:22/00:25:08, 0.731s/it]: train_loss_raw=0.3850, running_loss=0.3454, LR=0.000100
[2025-08-27 15:51:06,875][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081104] [Batch 01024/03080] [00:12:28/00:25:02, 0.731s/it]: train_loss_raw=0.3634, running_loss=0.3448, LR=0.000100
[2025-08-27 15:51:12,622][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081112] [Batch 01032/03080] [00:12:34/00:24:56, 0.731s/it]: train_loss_raw=0.2708, running_loss=0.3451, LR=0.000100
[2025-08-27 15:51:18,015][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081120] [Batch 01040/03080] [00:12:39/00:24:49, 0.730s/it]: train_loss_raw=0.3436, running_loss=0.3446, LR=0.000100
[2025-08-27 15:51:23,425][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081128] [Batch 01048/03080] [00:12:44/00:24:43, 0.730s/it]: train_loss_raw=0.4144, running_loss=0.3439, LR=0.000100
[2025-08-27 15:51:29,207][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081136] [Batch 01056/03080] [00:12:50/00:24:37, 0.730s/it]: train_loss_raw=0.2930, running_loss=0.3449, LR=0.000100
[2025-08-27 15:51:35,113][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081144] [Batch 01064/03080] [00:12:56/00:24:31, 0.730s/it]: train_loss_raw=0.3209, running_loss=0.3428, LR=0.000100
[2025-08-27 15:51:41,177][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081152] [Batch 01072/03080] [00:13:02/00:24:26, 0.730s/it]: train_loss_raw=0.3358, running_loss=0.3426, LR=0.000100
[2025-08-27 15:51:47,117][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081160] [Batch 01080/03080] [00:13:08/00:24:20, 0.730s/it]: train_loss_raw=0.3350, running_loss=0.3431, LR=0.000100
[2025-08-27 15:51:52,861][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081168] [Batch 01088/03080] [00:13:14/00:24:14, 0.730s/it]: train_loss_raw=0.3413, running_loss=0.3417, LR=0.000100
[2025-08-27 15:51:58,776][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081176] [Batch 01096/03080] [00:13:20/00:24:08, 0.730s/it]: train_loss_raw=0.3420, running_loss=0.3413, LR=0.000100
[2025-08-27 15:52:04,642][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081184] [Batch 01104/03080] [00:13:26/00:24:02, 0.730s/it]: train_loss_raw=0.3486, running_loss=0.3417, LR=0.000100
[2025-08-27 15:52:10,462][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081192] [Batch 01112/03080] [00:13:31/00:23:56, 0.730s/it]: train_loss_raw=0.3026, running_loss=0.3405, LR=0.000100
[2025-08-27 15:52:16,459][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081200] [Batch 01120/03080] [00:13:37/00:23:51, 0.730s/it]: train_loss_raw=0.3616, running_loss=0.3428, LR=0.000100
[2025-08-27 15:52:22,447][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081208] [Batch 01128/03080] [00:13:43/00:23:45, 0.730s/it]: train_loss_raw=0.3493, running_loss=0.3426, LR=0.000100
[2025-08-27 15:52:28,448][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081216] [Batch 01136/03080] [00:13:49/00:23:40, 0.731s/it]: train_loss_raw=0.3370, running_loss=0.3416, LR=0.000100
[2025-08-27 15:52:34,755][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081224] [Batch 01144/03080] [00:13:56/00:23:35, 0.731s/it]: train_loss_raw=0.2880, running_loss=0.3427, LR=0.000100
[2025-08-27 15:52:40,793][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081232] [Batch 01152/03080] [00:14:02/00:23:29, 0.731s/it]: train_loss_raw=0.3309, running_loss=0.3416, LR=0.000100
[2025-08-27 15:52:46,172][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081240] [Batch 01160/03080] [00:14:07/00:23:23, 0.731s/it]: train_loss_raw=0.3497, running_loss=0.3429, LR=0.000100
[2025-08-27 15:52:51,889][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081248] [Batch 01168/03080] [00:14:13/00:23:16, 0.731s/it]: train_loss_raw=0.3227, running_loss=0.3425, LR=0.000100
[2025-08-27 15:52:57,527][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081256] [Batch 01176/03080] [00:14:19/00:23:10, 0.730s/it]: train_loss_raw=0.3214, running_loss=0.3431, LR=0.000100
[2025-08-27 15:53:03,266][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081264] [Batch 01184/03080] [00:14:24/00:23:04, 0.730s/it]: train_loss_raw=0.4273, running_loss=0.3440, LR=0.000100
[2025-08-27 15:53:08,759][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081272] [Batch 01192/03080] [00:14:30/00:22:58, 0.730s/it]: train_loss_raw=0.4049, running_loss=0.3424, LR=0.000100
[2025-08-27 15:53:14,600][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081280] [Batch 01200/03080] [00:14:36/00:22:52, 0.730s/it]: train_loss_raw=0.3479, running_loss=0.3450, LR=0.000100
[2025-08-27 15:53:20,537][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081288] [Batch 01208/03080] [00:14:42/00:22:46, 0.730s/it]: train_loss_raw=0.3690, running_loss=0.3436, LR=0.000100
[2025-08-27 15:53:26,300][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081296] [Batch 01216/03080] [00:14:47/00:22:40, 0.730s/it]: train_loss_raw=0.3457, running_loss=0.3436, LR=0.000100
[2025-08-27 15:53:31,673][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081304] [Batch 01224/03080] [00:14:53/00:22:34, 0.730s/it]: train_loss_raw=0.3852, running_loss=0.3432, LR=0.000100
[2025-08-27 15:53:37,288][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081312] [Batch 01232/03080] [00:14:58/00:22:28, 0.730s/it]: train_loss_raw=0.3104, running_loss=0.3432, LR=0.000100
[2025-08-27 15:53:43,201][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081320] [Batch 01240/03080] [00:15:04/00:22:22, 0.730s/it]: train_loss_raw=0.3182, running_loss=0.3436, LR=0.000100
[2025-08-27 15:53:49,178][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081328] [Batch 01248/03080] [00:15:10/00:22:16, 0.730s/it]: train_loss_raw=0.3788, running_loss=0.3431, LR=0.000100
[2025-08-27 15:53:54,949][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081336] [Batch 01256/03080] [00:15:16/00:22:10, 0.730s/it]: train_loss_raw=0.3686, running_loss=0.3442, LR=0.000100
[2025-08-27 15:54:01,066][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081344] [Batch 01264/03080] [00:15:22/00:22:05, 0.730s/it]: train_loss_raw=0.3453, running_loss=0.3429, LR=0.000100
[2025-08-27 15:54:06,697][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081352] [Batch 01272/03080] [00:15:28/00:21:59, 0.730s/it]: train_loss_raw=0.2842, running_loss=0.3433, LR=0.000100
[2025-08-27 15:54:12,384][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081360] [Batch 01280/03080] [00:15:33/00:21:53, 0.730s/it]: train_loss_raw=0.3537, running_loss=0.3455, LR=0.000100
[2025-08-27 15:54:18,394][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081368] [Batch 01288/03080] [00:15:39/00:21:47, 0.730s/it]: train_loss_raw=0.2697, running_loss=0.3442, LR=0.000100
[2025-08-27 15:54:24,548][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081376] [Batch 01296/03080] [00:15:46/00:21:42, 0.730s/it]: train_loss_raw=0.3121, running_loss=0.3448, LR=0.000100
[2025-08-27 15:54:30,327][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081384] [Batch 01304/03080] [00:15:51/00:21:36, 0.730s/it]: train_loss_raw=0.3968, running_loss=0.3484, LR=0.000100
[2025-08-27 15:54:36,308][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081392] [Batch 01312/03080] [00:15:57/00:21:30, 0.730s/it]: train_loss_raw=0.4084, running_loss=0.3482, LR=0.000100
[2025-08-27 15:54:41,983][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081400] [Batch 01320/03080] [00:16:03/00:21:24, 0.730s/it]: train_loss_raw=0.3124, running_loss=0.3476, LR=0.000100
[2025-08-27 15:54:48,141][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081408] [Batch 01328/03080] [00:16:09/00:21:19, 0.730s/it]: train_loss_raw=0.3822, running_loss=0.3483, LR=0.000100
[2025-08-27 15:54:54,160][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081416] [Batch 01336/03080] [00:16:15/00:21:13, 0.730s/it]: train_loss_raw=0.4223, running_loss=0.3481, LR=0.000100
[2025-08-27 15:55:00,113][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081424] [Batch 01344/03080] [00:16:21/00:21:07, 0.730s/it]: train_loss_raw=0.3039, running_loss=0.3479, LR=0.000100
[2025-08-27 15:55:05,939][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081432] [Batch 01352/03080] [00:16:27/00:21:02, 0.730s/it]: train_loss_raw=0.3490, running_loss=0.3492, LR=0.000100
[2025-08-27 15:55:11,748][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081440] [Batch 01360/03080] [00:16:33/00:20:56, 0.730s/it]: train_loss_raw=0.3322, running_loss=0.3488, LR=0.000100
[2025-08-27 15:55:17,718][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081448] [Batch 01368/03080] [00:16:39/00:20:50, 0.730s/it]: train_loss_raw=0.3655, running_loss=0.3475, LR=0.000100
[2025-08-27 15:55:23,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081456] [Batch 01376/03080] [00:16:45/00:20:44, 0.730s/it]: train_loss_raw=0.3243, running_loss=0.3466, LR=0.000100
[2025-08-27 15:55:29,215][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081464] [Batch 01384/03080] [00:16:50/00:20:38, 0.730s/it]: train_loss_raw=0.3096, running_loss=0.3458, LR=0.000100
[2025-08-27 15:55:35,415][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081472] [Batch 01392/03080] [00:16:56/00:20:33, 0.731s/it]: train_loss_raw=0.4278, running_loss=0.3477, LR=0.000100
[2025-08-27 15:55:41,681][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081480] [Batch 01400/03080] [00:17:03/00:20:27, 0.731s/it]: train_loss_raw=0.3056, running_loss=0.3449, LR=0.000100
[2025-08-27 15:55:47,764][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081488] [Batch 01408/03080] [00:17:09/00:20:22, 0.731s/it]: train_loss_raw=0.4093, running_loss=0.3450, LR=0.000100
[2025-08-27 15:55:53,747][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081496] [Batch 01416/03080] [00:17:15/00:20:16, 0.731s/it]: train_loss_raw=0.3864, running_loss=0.3474, LR=0.000100
[2025-08-27 15:55:59,580][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081504] [Batch 01424/03080] [00:17:21/00:20:10, 0.731s/it]: train_loss_raw=0.2868, running_loss=0.3457, LR=0.000100
[2025-08-27 15:56:05,246][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081512] [Batch 01432/03080] [00:17:26/00:20:04, 0.731s/it]: train_loss_raw=0.3528, running_loss=0.3469, LR=0.000100
[2025-08-27 15:56:10,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081520] [Batch 01440/03080] [00:17:32/00:19:58, 0.731s/it]: train_loss_raw=0.3114, running_loss=0.3486, LR=0.000100
[2025-08-27 15:56:16,152][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081528] [Batch 01448/03080] [00:17:37/00:19:52, 0.730s/it]: train_loss_raw=0.3978, running_loss=0.3465, LR=0.000100
[2025-08-27 15:56:21,734][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081536] [Batch 01456/03080] [00:17:43/00:19:45, 0.730s/it]: train_loss_raw=0.3563, running_loss=0.3457, LR=0.000100
[2025-08-27 15:56:27,609][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081544] [Batch 01464/03080] [00:17:49/00:19:40, 0.730s/it]: train_loss_raw=0.3417, running_loss=0.3455, LR=0.000100
[2025-08-27 15:56:33,523][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081552] [Batch 01472/03080] [00:17:55/00:19:34, 0.730s/it]: train_loss_raw=0.4102, running_loss=0.3468, LR=0.000100
[2025-08-27 15:56:39,238][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081560] [Batch 01480/03080] [00:18:00/00:19:28, 0.730s/it]: train_loss_raw=0.4343, running_loss=0.3470, LR=0.000100
[2025-08-27 15:56:44,619][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081568] [Batch 01488/03080] [00:18:06/00:19:22, 0.730s/it]: train_loss_raw=0.3111, running_loss=0.3469, LR=0.000100
[2025-08-27 15:56:50,226][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081576] [Batch 01496/03080] [00:18:11/00:19:15, 0.730s/it]: train_loss_raw=0.4067, running_loss=0.3476, LR=0.000100
[2025-08-27 15:56:55,712][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081584] [Batch 01504/03080] [00:18:17/00:19:09, 0.730s/it]: train_loss_raw=0.3235, running_loss=0.3462, LR=0.000100
[2025-08-27 15:57:01,492][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081592] [Batch 01512/03080] [00:18:22/00:19:03, 0.729s/it]: train_loss_raw=0.3807, running_loss=0.3450, LR=0.000100
[2025-08-27 15:57:07,359][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081600] [Batch 01520/03080] [00:18:28/00:18:58, 0.729s/it]: train_loss_raw=0.4260, running_loss=0.3463, LR=0.000100
[2025-08-27 15:57:13,229][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081608] [Batch 01528/03080] [00:18:34/00:18:52, 0.730s/it]: train_loss_raw=0.3817, running_loss=0.3459, LR=0.000100
[2025-08-27 15:57:18,706][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081616] [Batch 01536/03080] [00:18:40/00:18:46, 0.729s/it]: train_loss_raw=0.3418, running_loss=0.3467, LR=0.000100
[2025-08-27 15:57:24,334][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081624] [Batch 01544/03080] [00:18:45/00:18:39, 0.729s/it]: train_loss_raw=0.2703, running_loss=0.3472, LR=0.000100
[2025-08-27 15:57:30,305][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081632] [Batch 01552/03080] [00:18:51/00:18:34, 0.729s/it]: train_loss_raw=0.3336, running_loss=0.3459, LR=0.000100
[2025-08-27 15:57:36,290][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081640] [Batch 01560/03080] [00:18:57/00:18:28, 0.729s/it]: train_loss_raw=0.2815, running_loss=0.3434, LR=0.000100
[2025-08-27 15:57:42,175][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081648] [Batch 01568/03080] [00:19:03/00:18:22, 0.729s/it]: train_loss_raw=0.3482, running_loss=0.3471, LR=0.000100
[2025-08-27 15:57:47,710][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081656] [Batch 01576/03080] [00:19:09/00:18:16, 0.729s/it]: train_loss_raw=0.3477, running_loss=0.3459, LR=0.000100
[2025-08-27 15:57:53,089][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081664] [Batch 01584/03080] [00:19:14/00:18:10, 0.729s/it]: train_loss_raw=0.3409, running_loss=0.3449, LR=0.000100
[2025-08-27 15:57:58,609][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081672] [Batch 01592/03080] [00:19:20/00:18:04, 0.729s/it]: train_loss_raw=0.3362, running_loss=0.3438, LR=0.000100
[2025-08-27 15:58:04,493][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081680] [Batch 01600/03080] [00:19:25/00:17:58, 0.729s/it]: train_loss_raw=0.3880, running_loss=0.3461, LR=0.000100
[2025-08-27 15:58:10,576][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081688] [Batch 01608/03080] [00:19:32/00:17:52, 0.729s/it]: train_loss_raw=0.3548, running_loss=0.3478, LR=0.000100
[2025-08-27 15:58:16,477][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081696] [Batch 01616/03080] [00:19:37/00:17:47, 0.729s/it]: train_loss_raw=0.2942, running_loss=0.3471, LR=0.000100
[2025-08-27 15:58:22,295][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081704] [Batch 01624/03080] [00:19:43/00:17:41, 0.729s/it]: train_loss_raw=0.3369, running_loss=0.3487, LR=0.000100
[2025-08-27 15:58:27,921][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081712] [Batch 01632/03080] [00:19:49/00:17:35, 0.729s/it]: train_loss_raw=0.3992, running_loss=0.3473, LR=0.000100
[2025-08-27 15:58:33,842][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081720] [Batch 01640/03080] [00:19:55/00:17:29, 0.729s/it]: train_loss_raw=0.3703, running_loss=0.3507, LR=0.000100
[2025-08-27 15:58:39,798][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081728] [Batch 01648/03080] [00:20:01/00:17:23, 0.729s/it]: train_loss_raw=0.3560, running_loss=0.3487, LR=0.000100
[2025-08-27 15:58:45,755][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081736] [Batch 01656/03080] [00:20:07/00:17:18, 0.729s/it]: train_loss_raw=0.2860, running_loss=0.3457, LR=0.000100
[2025-08-27 15:58:51,664][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081744] [Batch 01664/03080] [00:20:13/00:17:12, 0.729s/it]: train_loss_raw=0.3722, running_loss=0.3474, LR=0.000100
[2025-08-27 15:58:57,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081752] [Batch 01672/03080] [00:20:19/00:17:06, 0.729s/it]: train_loss_raw=0.3342, running_loss=0.3444, LR=0.000100
[2025-08-27 15:59:03,480][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081760] [Batch 01680/03080] [00:20:24/00:17:00, 0.729s/it]: train_loss_raw=0.3793, running_loss=0.3467, LR=0.000100
[2025-08-27 15:59:09,453][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081768] [Batch 01688/03080] [00:20:30/00:16:55, 0.729s/it]: train_loss_raw=0.3072, running_loss=0.3463, LR=0.000100
[2025-08-27 15:59:15,356][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081776] [Batch 01696/03080] [00:20:36/00:16:49, 0.729s/it]: train_loss_raw=0.4083, running_loss=0.3481, LR=0.000100
[2025-08-27 15:59:21,331][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081784] [Batch 01704/03080] [00:20:42/00:16:43, 0.729s/it]: train_loss_raw=0.3153, running_loss=0.3486, LR=0.000100
[2025-08-27 15:59:27,358][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081792] [Batch 01712/03080] [00:20:48/00:16:37, 0.729s/it]: train_loss_raw=0.4411, running_loss=0.3495, LR=0.000100
[2025-08-27 15:59:33,114][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081800] [Batch 01720/03080] [00:20:54/00:16:32, 0.729s/it]: train_loss_raw=0.3377, running_loss=0.3498, LR=0.000100
[2025-08-27 15:59:38,556][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081808] [Batch 01728/03080] [00:21:00/00:16:25, 0.729s/it]: train_loss_raw=0.3438, running_loss=0.3489, LR=0.000100
[2025-08-27 15:59:44,558][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081816] [Batch 01736/03080] [00:21:06/00:16:20, 0.729s/it]: train_loss_raw=0.3545, running_loss=0.3491, LR=0.000100
[2025-08-27 15:59:50,543][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081824] [Batch 01744/03080] [00:21:12/00:16:14, 0.729s/it]: train_loss_raw=0.3928, running_loss=0.3511, LR=0.000100
[2025-08-27 15:59:56,049][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081832] [Batch 01752/03080] [00:21:17/00:16:08, 0.729s/it]: train_loss_raw=0.3347, running_loss=0.3516, LR=0.000100
[2025-08-27 16:00:01,528][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081840] [Batch 01760/03080] [00:21:23/00:16:02, 0.729s/it]: train_loss_raw=0.3724, running_loss=0.3507, LR=0.000100
[2025-08-27 16:00:07,240][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081848] [Batch 01768/03080] [00:21:28/00:15:56, 0.729s/it]: train_loss_raw=0.4227, running_loss=0.3521, LR=0.000100
[2025-08-27 16:00:12,889][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081856] [Batch 01776/03080] [00:21:34/00:15:50, 0.729s/it]: train_loss_raw=0.3951, running_loss=0.3514, LR=0.000100
[2025-08-27 16:00:18,714][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081864] [Batch 01784/03080] [00:21:40/00:15:44, 0.729s/it]: train_loss_raw=0.3843, running_loss=0.3508, LR=0.000100
[2025-08-27 16:00:24,194][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081872] [Batch 01792/03080] [00:21:45/00:15:38, 0.729s/it]: train_loss_raw=0.3320, running_loss=0.3491, LR=0.000100
[2025-08-27 16:00:29,837][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081880] [Batch 01800/03080] [00:21:51/00:15:32, 0.729s/it]: train_loss_raw=0.2999, running_loss=0.3473, LR=0.000100
[2025-08-27 16:00:35,776][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081888] [Batch 01808/03080] [00:21:57/00:15:26, 0.729s/it]: train_loss_raw=0.3437, running_loss=0.3470, LR=0.000100
[2025-08-27 16:00:41,569][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081896] [Batch 01816/03080] [00:22:03/00:15:20, 0.729s/it]: train_loss_raw=0.3334, running_loss=0.3471, LR=0.000100
[2025-08-27 16:00:47,306][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081904] [Batch 01824/03080] [00:22:08/00:15:14, 0.729s/it]: train_loss_raw=0.3349, running_loss=0.3476, LR=0.000100
[2025-08-27 16:00:52,751][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081912] [Batch 01832/03080] [00:22:14/00:15:08, 0.728s/it]: train_loss_raw=0.3200, running_loss=0.3464, LR=0.000100
[2025-08-27 16:00:58,219][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081920] [Batch 01840/03080] [00:22:19/00:15:02, 0.728s/it]: train_loss_raw=0.3165, running_loss=0.3445, LR=0.000100
[2025-08-27 16:01:03,903][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081928] [Batch 01848/03080] [00:22:25/00:14:56, 0.728s/it]: train_loss_raw=0.3678, running_loss=0.3444, LR=0.000100
[2025-08-27 16:01:09,682][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081936] [Batch 01856/03080] [00:22:31/00:14:51, 0.728s/it]: train_loss_raw=0.3747, running_loss=0.3437, LR=0.000100
[2025-08-27 16:01:15,471][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081944] [Batch 01864/03080] [00:22:36/00:14:45, 0.728s/it]: train_loss_raw=0.3426, running_loss=0.3448, LR=0.000100
[2025-08-27 16:01:21,283][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081952] [Batch 01872/03080] [00:22:42/00:14:39, 0.728s/it]: train_loss_raw=0.3325, running_loss=0.3439, LR=0.000100
[2025-08-27 16:01:27,025][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081960] [Batch 01880/03080] [00:22:48/00:14:33, 0.728s/it]: train_loss_raw=0.3267, running_loss=0.3445, LR=0.000100
[2025-08-27 16:01:32,801][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081968] [Batch 01888/03080] [00:22:54/00:14:27, 0.728s/it]: train_loss_raw=0.3137, running_loss=0.3443, LR=0.000100
[2025-08-27 16:01:38,705][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081976] [Batch 01896/03080] [00:23:00/00:14:21, 0.728s/it]: train_loss_raw=0.2954, running_loss=0.3425, LR=0.000100
[2025-08-27 16:01:44,773][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081984] [Batch 01904/03080] [00:23:06/00:14:16, 0.728s/it]: train_loss_raw=0.3541, running_loss=0.3431, LR=0.000100
[2025-08-27 16:01:50,756][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 081992] [Batch 01912/03080] [00:23:12/00:14:10, 0.728s/it]: train_loss_raw=0.3416, running_loss=0.3416, LR=0.000100
[2025-08-27 16:01:57,030][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082000] [Batch 01920/03080] [00:23:18/00:14:04, 0.728s/it]: train_loss_raw=0.3054, running_loss=0.3411, LR=0.000100
[2025-08-27 16:02:05,814][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082008] [Batch 01928/03080] [00:23:27/00:14:00, 0.730s/it]: train_loss_raw=0.3509, running_loss=0.3385, LR=0.000100
[2025-08-27 16:02:11,492][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082016] [Batch 01936/03080] [00:23:32/00:13:54, 0.730s/it]: train_loss_raw=0.3072, running_loss=0.3370, LR=0.000100
[2025-08-27 16:02:17,298][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082024] [Batch 01944/03080] [00:23:38/00:13:49, 0.730s/it]: train_loss_raw=0.4883, running_loss=0.3406, LR=0.000100
[2025-08-27 16:02:22,770][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082032] [Batch 01952/03080] [00:23:44/00:13:43, 0.730s/it]: train_loss_raw=0.3186, running_loss=0.3400, LR=0.000100
[2025-08-27 16:02:28,931][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082040] [Batch 01960/03080] [00:23:50/00:13:37, 0.730s/it]: train_loss_raw=0.3176, running_loss=0.3392, LR=0.000100
[2025-08-27 16:02:34,979][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082048] [Batch 01968/03080] [00:23:56/00:13:31, 0.730s/it]: train_loss_raw=0.3253, running_loss=0.3378, LR=0.000100
[2025-08-27 16:02:40,606][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082056] [Batch 01976/03080] [00:24:02/00:13:25, 0.730s/it]: train_loss_raw=0.3610, running_loss=0.3367, LR=0.000100
[2025-08-27 16:02:46,518][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082064] [Batch 01984/03080] [00:24:07/00:13:19, 0.730s/it]: train_loss_raw=0.3533, running_loss=0.3401, LR=0.000100
[2025-08-27 16:02:52,415][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082072] [Batch 01992/03080] [00:24:13/00:13:14, 0.730s/it]: train_loss_raw=0.3260, running_loss=0.3400, LR=0.000100
[2025-08-27 16:02:58,381][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082080] [Batch 02000/03080] [00:24:19/00:13:08, 0.730s/it]: train_loss_raw=0.2985, running_loss=0.3387, LR=0.000100
[2025-08-27 16:03:04,159][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082088] [Batch 02008/03080] [00:24:25/00:13:02, 0.730s/it]: train_loss_raw=0.3383, running_loss=0.3411, LR=0.000100
[2025-08-27 16:03:10,164][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082096] [Batch 02016/03080] [00:24:31/00:12:56, 0.730s/it]: train_loss_raw=0.3502, running_loss=0.3428, LR=0.000100
[2025-08-27 16:03:16,182][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082104] [Batch 02024/03080] [00:24:37/00:12:50, 0.730s/it]: train_loss_raw=0.2857, running_loss=0.3435, LR=0.000100
[2025-08-27 16:03:22,135][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082112] [Batch 02032/03080] [00:24:43/00:12:45, 0.730s/it]: train_loss_raw=0.3148, running_loss=0.3434, LR=0.000100
[2025-08-27 16:03:28,171][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082120] [Batch 02040/03080] [00:24:49/00:12:39, 0.730s/it]: train_loss_raw=0.3829, running_loss=0.3440, LR=0.000100
[2025-08-27 16:03:34,125][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082128] [Batch 02048/03080] [00:24:55/00:12:33, 0.730s/it]: train_loss_raw=0.2528, running_loss=0.3428, LR=0.000100
[2025-08-27 16:03:40,035][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082136] [Batch 02056/03080] [00:25:01/00:12:27, 0.730s/it]: train_loss_raw=0.3662, running_loss=0.3418, LR=0.000100
[2025-08-27 16:03:46,048][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082144] [Batch 02064/03080] [00:25:07/00:12:22, 0.730s/it]: train_loss_raw=0.4210, running_loss=0.3436, LR=0.000100
[2025-08-27 16:03:51,987][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082152] [Batch 02072/03080] [00:25:13/00:12:16, 0.730s/it]: train_loss_raw=0.4061, running_loss=0.3451, LR=0.000100
[2025-08-27 16:03:57,922][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082160] [Batch 02080/03080] [00:25:19/00:12:10, 0.730s/it]: train_loss_raw=0.3445, running_loss=0.3449, LR=0.000100
[2025-08-27 16:04:03,754][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082168] [Batch 02088/03080] [00:25:25/00:12:04, 0.730s/it]: train_loss_raw=0.2766, running_loss=0.3447, LR=0.000100
[2025-08-27 16:04:09,400][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082176] [Batch 02096/03080] [00:25:30/00:11:58, 0.730s/it]: train_loss_raw=0.3968, running_loss=0.3445, LR=0.000100
[2025-08-27 16:04:15,175][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082184] [Batch 02104/03080] [00:25:36/00:11:52, 0.730s/it]: train_loss_raw=0.3813, running_loss=0.3447, LR=0.000100
[2025-08-27 16:04:20,898][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082192] [Batch 02112/03080] [00:25:42/00:11:46, 0.730s/it]: train_loss_raw=0.3624, running_loss=0.3444, LR=0.000100
[2025-08-27 16:04:26,667][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082200] [Batch 02120/03080] [00:25:48/00:11:41, 0.730s/it]: train_loss_raw=0.3480, running_loss=0.3440, LR=0.000100
[2025-08-27 16:04:32,641][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082208] [Batch 02128/03080] [00:25:54/00:11:35, 0.730s/it]: train_loss_raw=0.3669, running_loss=0.3470, LR=0.000100
[2025-08-27 16:04:38,546][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082216] [Batch 02136/03080] [00:26:00/00:11:29, 0.730s/it]: train_loss_raw=0.3217, running_loss=0.3464, LR=0.000100
[2025-08-27 16:04:44,285][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082224] [Batch 02144/03080] [00:26:05/00:11:23, 0.730s/it]: train_loss_raw=0.3205, running_loss=0.3460, LR=0.000100
[2025-08-27 16:04:50,365][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082232] [Batch 02152/03080] [00:26:11/00:11:17, 0.730s/it]: train_loss_raw=0.2922, running_loss=0.3452, LR=0.000100
[2025-08-27 16:04:56,327][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082240] [Batch 02160/03080] [00:26:17/00:11:12, 0.730s/it]: train_loss_raw=0.3266, running_loss=0.3453, LR=0.000100
[2025-08-27 16:05:02,290][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082248] [Batch 02168/03080] [00:26:23/00:11:06, 0.731s/it]: train_loss_raw=0.4139, running_loss=0.3482, LR=0.000100
[2025-08-27 16:05:08,307][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082256] [Batch 02176/03080] [00:26:29/00:11:00, 0.731s/it]: train_loss_raw=0.4482, running_loss=0.3503, LR=0.000100
[2025-08-27 16:05:14,090][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082264] [Batch 02184/03080] [00:26:35/00:10:54, 0.731s/it]: train_loss_raw=0.3549, running_loss=0.3508, LR=0.000100
[2025-08-27 16:05:19,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082272] [Batch 02192/03080] [00:26:41/00:10:48, 0.731s/it]: train_loss_raw=0.3724, running_loss=0.3496, LR=0.000100
[2025-08-27 16:05:25,838][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082280] [Batch 02200/03080] [00:26:47/00:10:42, 0.731s/it]: train_loss_raw=0.3761, running_loss=0.3500, LR=0.000100
[2025-08-27 16:05:31,630][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082288] [Batch 02208/03080] [00:26:53/00:10:37, 0.731s/it]: train_loss_raw=0.2434, running_loss=0.3482, LR=0.000100
[2025-08-27 16:05:37,594][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082296] [Batch 02216/03080] [00:26:59/00:10:31, 0.731s/it]: train_loss_raw=0.3993, running_loss=0.3477, LR=0.000100
[2025-08-27 16:05:43,368][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082304] [Batch 02224/03080] [00:27:04/00:10:25, 0.731s/it]: train_loss_raw=0.3569, running_loss=0.3501, LR=0.000100
[2025-08-27 16:05:49,170][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082312] [Batch 02232/03080] [00:27:10/00:10:19, 0.731s/it]: train_loss_raw=0.4222, running_loss=0.3512, LR=0.000100
[2025-08-27 16:05:55,127][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082320] [Batch 02240/03080] [00:27:16/00:10:13, 0.731s/it]: train_loss_raw=0.3173, running_loss=0.3510, LR=0.000100
[2025-08-27 16:06:00,876][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082328] [Batch 02248/03080] [00:27:22/00:10:07, 0.731s/it]: train_loss_raw=0.4228, running_loss=0.3534, LR=0.000100
[2025-08-27 16:06:06,506][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082336] [Batch 02256/03080] [00:27:27/00:10:01, 0.730s/it]: train_loss_raw=0.2876, running_loss=0.3533, LR=0.000100
[2025-08-27 16:06:12,310][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082344] [Batch 02264/03080] [00:27:33/00:09:56, 0.730s/it]: train_loss_raw=0.3796, running_loss=0.3529, LR=0.000100
[2025-08-27 16:06:17,992][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082352] [Batch 02272/03080] [00:27:39/00:09:50, 0.730s/it]: train_loss_raw=0.3575, running_loss=0.3527, LR=0.000100
[2025-08-27 16:06:23,800][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082360] [Batch 02280/03080] [00:27:45/00:09:44, 0.730s/it]: train_loss_raw=0.4075, running_loss=0.3516, LR=0.000100
[2025-08-27 16:06:29,729][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082368] [Batch 02288/03080] [00:27:51/00:09:38, 0.730s/it]: train_loss_raw=0.2689, running_loss=0.3505, LR=0.000100
[2025-08-27 16:06:35,739][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082376] [Batch 02296/03080] [00:27:57/00:09:32, 0.730s/it]: train_loss_raw=0.3969, running_loss=0.3498, LR=0.000100
[2025-08-27 16:06:41,655][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082384] [Batch 02304/03080] [00:28:03/00:09:26, 0.731s/it]: train_loss_raw=0.4079, running_loss=0.3505, LR=0.000100
[2025-08-27 16:06:47,608][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082392] [Batch 02312/03080] [00:28:09/00:09:21, 0.731s/it]: train_loss_raw=0.2747, running_loss=0.3480, LR=0.000100
[2025-08-27 16:06:53,490][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082400] [Batch 02320/03080] [00:28:14/00:09:15, 0.731s/it]: train_loss_raw=0.3275, running_loss=0.3468, LR=0.000100
[2025-08-27 16:06:59,161][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082408] [Batch 02328/03080] [00:28:20/00:09:09, 0.731s/it]: train_loss_raw=0.3650, running_loss=0.3474, LR=0.000100
[2025-08-27 16:07:05,260][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082416] [Batch 02336/03080] [00:28:26/00:09:03, 0.731s/it]: train_loss_raw=0.4298, running_loss=0.3461, LR=0.000100
[2025-08-27 16:07:11,187][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082424] [Batch 02344/03080] [00:28:32/00:08:57, 0.731s/it]: train_loss_raw=0.3245, running_loss=0.3464, LR=0.000100
[2025-08-27 16:07:17,123][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082432] [Batch 02352/03080] [00:28:38/00:08:51, 0.731s/it]: train_loss_raw=0.3801, running_loss=0.3442, LR=0.000100
[2025-08-27 16:07:23,035][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082440] [Batch 02360/03080] [00:28:44/00:08:46, 0.731s/it]: train_loss_raw=0.2914, running_loss=0.3450, LR=0.000100
[2025-08-27 16:07:28,781][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082448] [Batch 02368/03080] [00:28:50/00:08:40, 0.731s/it]: train_loss_raw=0.3671, running_loss=0.3442, LR=0.000100
[2025-08-27 16:07:34,671][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082456] [Batch 02376/03080] [00:28:56/00:08:34, 0.731s/it]: train_loss_raw=0.3757, running_loss=0.3440, LR=0.000100
[2025-08-27 16:07:40,569][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082464] [Batch 02384/03080] [00:29:02/00:08:28, 0.731s/it]: train_loss_raw=0.3738, running_loss=0.3423, LR=0.000100
[2025-08-27 16:07:46,594][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082472] [Batch 02392/03080] [00:29:08/00:08:22, 0.731s/it]: train_loss_raw=0.3661, running_loss=0.3405, LR=0.000100
[2025-08-27 16:07:52,345][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082480] [Batch 02400/03080] [00:29:13/00:08:16, 0.731s/it]: train_loss_raw=0.3715, running_loss=0.3387, LR=0.000100
[2025-08-27 16:07:58,232][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082488] [Batch 02408/03080] [00:29:19/00:08:11, 0.731s/it]: train_loss_raw=0.3593, running_loss=0.3389, LR=0.000100
[2025-08-27 16:08:04,181][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082496] [Batch 02416/03080] [00:29:25/00:08:05, 0.731s/it]: train_loss_raw=0.4039, running_loss=0.3394, LR=0.000100
[2025-08-27 16:08:10,118][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082504] [Batch 02424/03080] [00:29:31/00:07:59, 0.731s/it]: train_loss_raw=0.3333, running_loss=0.3398, LR=0.000100
[2025-08-27 16:08:16,140][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082512] [Batch 02432/03080] [00:29:37/00:07:53, 0.731s/it]: train_loss_raw=0.2938, running_loss=0.3394, LR=0.000100
[2025-08-27 16:08:22,098][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082520] [Batch 02440/03080] [00:29:43/00:07:47, 0.731s/it]: train_loss_raw=0.3368, running_loss=0.3392, LR=0.000100
[2025-08-27 16:08:27,821][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082528] [Batch 02448/03080] [00:29:49/00:07:41, 0.731s/it]: train_loss_raw=0.3534, running_loss=0.3386, LR=0.000100
[2025-08-27 16:08:33,664][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082536] [Batch 02456/03080] [00:29:55/00:07:36, 0.731s/it]: train_loss_raw=0.2981, running_loss=0.3397, LR=0.000100
[2025-08-27 16:08:39,696][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082544] [Batch 02464/03080] [00:30:01/00:07:30, 0.731s/it]: train_loss_raw=0.3835, running_loss=0.3405, LR=0.000100
[2025-08-27 16:08:45,361][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082552] [Batch 02472/03080] [00:30:06/00:07:24, 0.731s/it]: train_loss_raw=0.4303, running_loss=0.3430, LR=0.000100
[2025-08-27 16:08:51,262][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082560] [Batch 02480/03080] [00:30:12/00:07:18, 0.731s/it]: train_loss_raw=0.3553, running_loss=0.3432, LR=0.000100
[2025-08-27 16:08:57,229][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082568] [Batch 02488/03080] [00:30:18/00:07:12, 0.731s/it]: train_loss_raw=0.3799, running_loss=0.3445, LR=0.000100
[2025-08-27 16:09:03,258][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082576] [Batch 02496/03080] [00:30:24/00:07:06, 0.731s/it]: train_loss_raw=0.3665, running_loss=0.3466, LR=0.000100
[2025-08-27 16:09:09,179][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082584] [Batch 02504/03080] [00:30:30/00:07:01, 0.731s/it]: train_loss_raw=0.3670, running_loss=0.3464, LR=0.000100
[2025-08-27 16:09:14,877][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082592] [Batch 02512/03080] [00:30:36/00:06:55, 0.731s/it]: train_loss_raw=0.3466, running_loss=0.3476, LR=0.000100
[2025-08-27 16:09:20,836][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082600] [Batch 02520/03080] [00:30:42/00:06:49, 0.731s/it]: train_loss_raw=0.2916, running_loss=0.3479, LR=0.000100
[2025-08-27 16:09:26,801][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082608] [Batch 02528/03080] [00:30:48/00:06:43, 0.731s/it]: train_loss_raw=0.3083, running_loss=0.3493, LR=0.000100
[2025-08-27 16:09:32,252][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082616] [Batch 02536/03080] [00:30:53/00:06:37, 0.731s/it]: train_loss_raw=0.3772, running_loss=0.3495, LR=0.000100
[2025-08-27 16:09:38,188][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082624] [Batch 02544/03080] [00:30:59/00:06:31, 0.731s/it]: train_loss_raw=0.3570, running_loss=0.3476, LR=0.000100
[2025-08-27 16:09:43,902][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082632] [Batch 02552/03080] [00:31:05/00:06:25, 0.731s/it]: train_loss_raw=0.3748, running_loss=0.3468, LR=0.000100
[2025-08-27 16:09:49,803][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082640] [Batch 02560/03080] [00:31:11/00:06:20, 0.731s/it]: train_loss_raw=0.3675, running_loss=0.3449, LR=0.000100
[2025-08-27 16:09:55,815][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082648] [Batch 02568/03080] [00:31:17/00:06:14, 0.731s/it]: train_loss_raw=0.2564, running_loss=0.3439, LR=0.000100
[2025-08-27 16:10:01,688][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082656] [Batch 02576/03080] [00:31:23/00:06:08, 0.731s/it]: train_loss_raw=0.4370, running_loss=0.3441, LR=0.000100
[2025-08-27 16:10:07,614][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082664] [Batch 02584/03080] [00:31:29/00:06:02, 0.731s/it]: train_loss_raw=0.3153, running_loss=0.3440, LR=0.000100
[2025-08-27 16:10:13,588][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082672] [Batch 02592/03080] [00:31:35/00:05:56, 0.731s/it]: train_loss_raw=0.3421, running_loss=0.3449, LR=0.000100
[2025-08-27 16:10:19,565][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082680] [Batch 02600/03080] [00:31:41/00:05:50, 0.731s/it]: train_loss_raw=0.3819, running_loss=0.3450, LR=0.000100
[2025-08-27 16:10:25,394][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082688] [Batch 02608/03080] [00:31:46/00:05:45, 0.731s/it]: train_loss_raw=0.3159, running_loss=0.3442, LR=0.000100
[2025-08-27 16:10:31,373][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082696] [Batch 02616/03080] [00:31:52/00:05:39, 0.731s/it]: train_loss_raw=0.3917, running_loss=0.3447, LR=0.000100
[2025-08-27 16:10:37,410][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082704] [Batch 02624/03080] [00:31:58/00:05:33, 0.731s/it]: train_loss_raw=0.4009, running_loss=0.3463, LR=0.000100
[2025-08-27 16:10:43,334][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082712] [Batch 02632/03080] [00:32:04/00:05:27, 0.731s/it]: train_loss_raw=0.4079, running_loss=0.3492, LR=0.000100
[2025-08-27 16:10:49,335][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082720] [Batch 02640/03080] [00:32:10/00:05:21, 0.731s/it]: train_loss_raw=0.3351, running_loss=0.3497, LR=0.000100
[2025-08-27 16:10:55,405][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082728] [Batch 02648/03080] [00:32:16/00:05:15, 0.731s/it]: train_loss_raw=0.3959, running_loss=0.3490, LR=0.000100
[2025-08-27 16:11:01,402][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082736] [Batch 02656/03080] [00:32:22/00:05:10, 0.732s/it]: train_loss_raw=0.3279, running_loss=0.3488, LR=0.000100
[2025-08-27 16:11:07,258][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082744] [Batch 02664/03080] [00:32:28/00:05:04, 0.732s/it]: train_loss_raw=0.3689, running_loss=0.3490, LR=0.000100
[2025-08-27 16:11:13,255][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082752] [Batch 02672/03080] [00:32:34/00:04:58, 0.732s/it]: train_loss_raw=0.3517, running_loss=0.3494, LR=0.000100
[2025-08-27 16:11:19,175][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082760] [Batch 02680/03080] [00:32:40/00:04:52, 0.732s/it]: train_loss_raw=0.3346, running_loss=0.3474, LR=0.000100
[2025-08-27 16:11:25,000][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082768] [Batch 02688/03080] [00:32:46/00:04:46, 0.732s/it]: train_loss_raw=0.3625, running_loss=0.3475, LR=0.000100
[2025-08-27 16:11:31,022][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082776] [Batch 02696/03080] [00:32:52/00:04:40, 0.732s/it]: train_loss_raw=0.3055, running_loss=0.3467, LR=0.000100
[2025-08-27 16:11:37,054][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082784] [Batch 02704/03080] [00:32:58/00:04:35, 0.732s/it]: train_loss_raw=0.2943, running_loss=0.3443, LR=0.000100
[2025-08-27 16:11:43,017][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082792] [Batch 02712/03080] [00:33:04/00:04:29, 0.732s/it]: train_loss_raw=0.3601, running_loss=0.3445, LR=0.000100
[2025-08-27 16:11:48,669][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082800] [Batch 02720/03080] [00:33:10/00:04:23, 0.732s/it]: train_loss_raw=0.3590, running_loss=0.3447, LR=0.000100
[2025-08-27 16:11:54,625][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082808] [Batch 02728/03080] [00:33:16/00:04:17, 0.732s/it]: train_loss_raw=0.3279, running_loss=0.3446, LR=0.000100
[2025-08-27 16:12:00,653][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082816] [Batch 02736/03080] [00:33:22/00:04:11, 0.732s/it]: train_loss_raw=0.3515, running_loss=0.3461, LR=0.000100
[2025-08-27 16:12:06,387][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082824] [Batch 02744/03080] [00:33:27/00:04:05, 0.732s/it]: train_loss_raw=0.3898, running_loss=0.3478, LR=0.000100
[2025-08-27 16:12:11,966][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082832] [Batch 02752/03080] [00:33:33/00:03:59, 0.732s/it]: train_loss_raw=0.4066, running_loss=0.3489, LR=0.000100
[2025-08-27 16:12:17,697][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082840] [Batch 02760/03080] [00:33:39/00:03:54, 0.732s/it]: train_loss_raw=0.3694, running_loss=0.3496, LR=0.000100
[2025-08-27 16:12:23,535][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082848] [Batch 02768/03080] [00:33:45/00:03:48, 0.732s/it]: train_loss_raw=0.3592, running_loss=0.3485, LR=0.000100
[2025-08-27 16:12:29,277][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082856] [Batch 02776/03080] [00:33:50/00:03:42, 0.732s/it]: train_loss_raw=0.4063, running_loss=0.3485, LR=0.000100
[2025-08-27 16:12:35,092][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082864] [Batch 02784/03080] [00:33:56/00:03:36, 0.732s/it]: train_loss_raw=0.2647, running_loss=0.3445, LR=0.000100
[2025-08-27 16:12:40,932][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082872] [Batch 02792/03080] [00:34:02/00:03:30, 0.732s/it]: train_loss_raw=0.3831, running_loss=0.3445, LR=0.000100
[2025-08-27 16:12:46,859][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082880] [Batch 02800/03080] [00:34:08/00:03:24, 0.732s/it]: train_loss_raw=0.4345, running_loss=0.3451, LR=0.000100
[2025-08-27 16:12:52,528][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082888] [Batch 02808/03080] [00:34:14/00:03:18, 0.731s/it]: train_loss_raw=0.3175, running_loss=0.3442, LR=0.000100
[2025-08-27 16:12:58,454][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082896] [Batch 02816/03080] [00:34:19/00:03:13, 0.732s/it]: train_loss_raw=0.4206, running_loss=0.3466, LR=0.000100
[2025-08-27 16:13:04,574][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082904] [Batch 02824/03080] [00:34:26/00:03:07, 0.732s/it]: train_loss_raw=0.2800, running_loss=0.3471, LR=0.000100
[2025-08-27 16:13:10,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082912] [Batch 02832/03080] [00:34:32/00:03:01, 0.732s/it]: train_loss_raw=0.3232, running_loss=0.3460, LR=0.000100
[2025-08-27 16:13:16,611][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082920] [Batch 02840/03080] [00:34:38/00:02:55, 0.732s/it]: train_loss_raw=0.3097, running_loss=0.3462, LR=0.000100
[2025-08-27 16:13:22,606][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082928] [Batch 02848/03080] [00:34:44/00:02:49, 0.732s/it]: train_loss_raw=0.2982, running_loss=0.3458, LR=0.000100
[2025-08-27 16:13:28,600][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082936] [Batch 02856/03080] [00:34:50/00:02:43, 0.732s/it]: train_loss_raw=0.3819, running_loss=0.3479, LR=0.000100
[2025-08-27 16:13:34,530][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082944] [Batch 02864/03080] [00:34:56/00:02:38, 0.732s/it]: train_loss_raw=0.3156, running_loss=0.3492, LR=0.000100
[2025-08-27 16:13:40,173][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082952] [Batch 02872/03080] [00:35:01/00:02:32, 0.732s/it]: train_loss_raw=0.4103, running_loss=0.3509, LR=0.000100
[2025-08-27 16:13:46,251][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082960] [Batch 02880/03080] [00:35:07/00:02:26, 0.732s/it]: train_loss_raw=0.3448, running_loss=0.3482, LR=0.000100
[2025-08-27 16:13:52,295][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082968] [Batch 02888/03080] [00:35:13/00:02:20, 0.732s/it]: train_loss_raw=0.3862, running_loss=0.3494, LR=0.000100
[2025-08-27 16:13:58,280][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082976] [Batch 02896/03080] [00:35:19/00:02:14, 0.732s/it]: train_loss_raw=0.3428, running_loss=0.3480, LR=0.000100
[2025-08-27 16:14:04,252][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082984] [Batch 02904/03080] [00:35:25/00:02:08, 0.732s/it]: train_loss_raw=0.3190, running_loss=0.3470, LR=0.000100
[2025-08-27 16:14:10,235][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 082992] [Batch 02912/03080] [00:35:31/00:02:02, 0.732s/it]: train_loss_raw=0.3395, running_loss=0.3463, LR=0.000100
[2025-08-27 16:14:16,008][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083000] [Batch 02920/03080] [00:35:37/00:01:57, 0.732s/it]: train_loss_raw=0.3380, running_loss=0.3471, LR=0.000100
[2025-08-27 16:14:21,454][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083008] [Batch 02928/03080] [00:35:42/00:01:51, 0.732s/it]: train_loss_raw=0.3909, running_loss=0.3466, LR=0.000100
[2025-08-27 16:14:27,039][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083016] [Batch 02936/03080] [00:35:48/00:01:45, 0.732s/it]: train_loss_raw=0.3774, running_loss=0.3480, LR=0.000100
[2025-08-27 16:14:32,946][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083024] [Batch 02944/03080] [00:35:54/00:01:39, 0.732s/it]: train_loss_raw=0.3335, running_loss=0.3491, LR=0.000100
[2025-08-27 16:14:38,743][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083032] [Batch 02952/03080] [00:36:00/00:01:33, 0.732s/it]: train_loss_raw=0.3425, running_loss=0.3485, LR=0.000100
[2025-08-27 16:14:44,224][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083040] [Batch 02960/03080] [00:36:05/00:01:27, 0.732s/it]: train_loss_raw=0.3840, running_loss=0.3494, LR=0.000100
[2025-08-27 16:14:49,951][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083048] [Batch 02968/03080] [00:36:11/00:01:21, 0.732s/it]: train_loss_raw=0.3142, running_loss=0.3487, LR=0.000100
[2025-08-27 16:14:55,775][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083056] [Batch 02976/03080] [00:36:17/00:01:16, 0.732s/it]: train_loss_raw=0.4291, running_loss=0.3481, LR=0.000100
[2025-08-27 16:15:01,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083064] [Batch 02984/03080] [00:36:23/00:01:10, 0.732s/it]: train_loss_raw=0.3487, running_loss=0.3495, LR=0.000100
[2025-08-27 16:15:07,632][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083072] [Batch 02992/03080] [00:36:29/00:01:04, 0.732s/it]: train_loss_raw=0.3377, running_loss=0.3496, LR=0.000100
[2025-08-27 16:15:13,870][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083080] [Batch 03000/03080] [00:36:35/00:00:58, 0.732s/it]: train_loss_raw=0.3389, running_loss=0.3502, LR=0.000100
[2025-08-27 16:15:19,604][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083088] [Batch 03008/03080] [00:36:41/00:00:52, 0.732s/it]: train_loss_raw=0.2591, running_loss=0.3489, LR=0.000100
[2025-08-27 16:15:25,635][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083096] [Batch 03016/03080] [00:36:47/00:00:46, 0.732s/it]: train_loss_raw=0.3240, running_loss=0.3499, LR=0.000100
[2025-08-27 16:15:31,640][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083104] [Batch 03024/03080] [00:36:53/00:00:40, 0.732s/it]: train_loss_raw=0.2922, running_loss=0.3474, LR=0.000100
[2025-08-27 16:15:37,654][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083112] [Batch 03032/03080] [00:36:59/00:00:35, 0.732s/it]: train_loss_raw=0.3381, running_loss=0.3481, LR=0.000100
[2025-08-27 16:15:43,703][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083120] [Batch 03040/03080] [00:37:05/00:00:29, 0.732s/it]: train_loss_raw=0.3696, running_loss=0.3483, LR=0.000100
[2025-08-27 16:15:49,659][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083128] [Batch 03048/03080] [00:37:11/00:00:23, 0.732s/it]: train_loss_raw=0.3719, running_loss=0.3474, LR=0.000100
[2025-08-27 16:15:55,607][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083136] [Batch 03056/03080] [00:37:17/00:00:17, 0.732s/it]: train_loss_raw=0.3384, running_loss=0.3470, LR=0.000100
[2025-08-27 16:16:01,558][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083144] [Batch 03064/03080] [00:37:23/00:00:11, 0.732s/it]: train_loss_raw=0.4000, running_loss=0.3466, LR=0.000100
[2025-08-27 16:16:07,408][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083152] [Batch 03072/03080] [00:37:28/00:00:05, 0.732s/it]: train_loss_raw=0.4039, running_loss=0.3448, LR=0.000100
[2025-08-27 16:16:13,397][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 083160] [Batch 03080/03080] [00:37:34/00:00:00, 0.732s/it]: train_loss_raw=0.2715, running_loss=0.3436, LR=0.000100
[2025-08-27 16:16:13,922][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-27 16:16:25,543][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00007/00310] [00:00:11/00:07:18, 1.453s/it]
[2025-08-27 16:16:37,526][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00015/00310] [00:00:23/00:07:13, 1.475s/it]
[2025-08-27 16:16:48,428][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00023/00310] [00:00:34/00:06:51, 1.438s/it]
[2025-08-27 16:17:00,506][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00031/00310] [00:00:46/00:06:44, 1.456s/it]
[2025-08-27 16:17:12,372][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00039/00310] [00:00:58/00:06:34, 1.461s/it]
[2025-08-27 16:17:24,003][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00047/00310] [00:01:10/00:06:22, 1.460s/it]
[2025-08-27 16:17:36,215][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00055/00310] [00:01:22/00:06:13, 1.470s/it]
[2025-08-27 16:17:48,440][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00063/00310] [00:01:34/00:06:03, 1.477s/it]
[2025-08-27 16:18:00,146][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00071/00310] [00:01:46/00:05:51, 1.475s/it]
[2025-08-27 16:18:12,504][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00079/00310] [00:01:58/00:05:40, 1.482s/it]
[2025-08-27 16:18:24,388][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00087/00310] [00:02:10/00:05:29, 1.483s/it]
[2025-08-27 16:18:36,621][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00095/00310] [00:02:22/00:05:18, 1.486s/it]
[2025-08-27 16:18:48,874][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00103/00310] [00:02:34/00:05:06, 1.490s/it]
[2025-08-27 16:19:00,963][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00111/00310] [00:02:47/00:04:55, 1.491s/it]
[2025-08-27 16:19:12,523][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00119/00310] [00:02:58/00:04:42, 1.488s/it]
[2025-08-27 16:19:24,182][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00127/00310] [00:03:10/00:04:30, 1.486s/it]
[2025-08-27 16:19:36,507][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00135/00310] [00:03:22/00:04:19, 1.490s/it]
[2025-08-27 16:19:48,600][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00143/00310] [00:03:34/00:04:07, 1.491s/it]
[2025-08-27 16:19:58,689][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00151/00310] [00:03:44/00:03:53, 1.479s/it]
[2025-08-27 16:20:09,093][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00159/00310] [00:03:55/00:03:40, 1.470s/it]
[2025-08-27 16:20:21,115][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00167/00310] [00:04:07/00:03:28, 1.471s/it]
[2025-08-27 16:20:30,878][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00175/00310] [00:04:16/00:03:15, 1.460s/it]
[2025-08-27 16:20:40,611][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00183/00310] [00:04:26/00:03:02, 1.449s/it]
[2025-08-27 16:20:51,551][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00191/00310] [00:04:37/00:02:50, 1.446s/it]
[2025-08-27 16:21:02,872][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00199/00310] [00:04:48/00:02:38, 1.445s/it]
[2025-08-27 16:21:13,875][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00207/00310] [00:04:59/00:02:27, 1.442s/it]
[2025-08-27 16:21:24,583][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00215/00310] [00:05:10/00:02:15, 1.438s/it]
[2025-08-27 16:21:36,241][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00223/00310] [00:05:22/00:02:03, 1.439s/it]
[2025-08-27 16:21:48,238][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00231/00310] [00:05:34/00:01:52, 1.441s/it]
[2025-08-27 16:21:59,721][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00239/00310] [00:05:45/00:01:40, 1.441s/it]
[2025-08-27 16:22:10,922][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00247/00310] [00:05:56/00:01:29, 1.440s/it]
[2025-08-27 16:22:23,277][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00255/00310] [00:06:09/00:01:17, 1.443s/it]
[2025-08-27 16:22:35,172][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00263/00310] [00:06:21/00:01:06, 1.444s/it]
[2025-08-27 16:22:46,205][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00271/00310] [00:06:32/00:00:54, 1.442s/it]
[2025-08-27 16:22:57,272][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00279/00310] [00:06:43/00:00:43, 1.441s/it]
[2025-08-27 16:23:08,846][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00287/00310] [00:06:54/00:00:31, 1.441s/it]
[2025-08-27 16:23:19,425][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00295/00310] [00:07:05/00:00:20, 1.438s/it]
[2025-08-27 16:23:31,315][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 083161] [Batch 00303/00310] [00:07:17/00:00:08, 1.439s/it]
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.34357, valid_loss=1.43141
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.480
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.154
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.157
[2025-08-27 16:23:40,331][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.088
[2025-08-27 16:23:40,341][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 20:56:54, remaining time 02:19:39, 00:46:33 per epoch
[2025-08-27 16:23:46,064][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083168] [Batch 00008/03080] [00:00:05/00:34:52, 0.681s/it]: train_loss_raw=0.3624, running_loss=0.3986, LR=0.000100
[2025-08-27 16:23:52,229][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083176] [Batch 00016/03080] [00:00:11/00:37:04, 0.726s/it]: train_loss_raw=0.3629, running_loss=0.3958, LR=0.000100
[2025-08-27 16:23:58,320][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083184] [Batch 00024/03080] [00:00:17/00:37:34, 0.738s/it]: train_loss_raw=0.3451, running_loss=0.3928, LR=0.000100
[2025-08-27 16:24:04,383][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083192] [Batch 00032/03080] [00:00:23/00:37:43, 0.743s/it]: train_loss_raw=0.2798, running_loss=0.3887, LR=0.000100
[2025-08-27 16:24:10,463][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083200] [Batch 00040/03080] [00:00:29/00:37:48, 0.746s/it]: train_loss_raw=0.2838, running_loss=0.3858, LR=0.000100
[2025-08-27 16:24:16,437][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083208] [Batch 00048/03080] [00:00:35/00:37:42, 0.746s/it]: train_loss_raw=0.3403, running_loss=0.3842, LR=0.000100
[2025-08-27 16:24:22,292][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083216] [Batch 00056/03080] [00:00:41/00:37:30, 0.744s/it]: train_loss_raw=0.3745, running_loss=0.3817, LR=0.000100
[2025-08-27 16:24:28,189][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083224] [Batch 00064/03080] [00:00:47/00:37:21, 0.743s/it]: train_loss_raw=0.3705, running_loss=0.3779, LR=0.000100
[2025-08-27 16:24:34,181][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083232] [Batch 00072/03080] [00:00:53/00:37:17, 0.744s/it]: train_loss_raw=0.2900, running_loss=0.3736, LR=0.000100
[2025-08-27 16:24:39,973][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083240] [Batch 00080/03080] [00:00:59/00:37:05, 0.742s/it]: train_loss_raw=0.3501, running_loss=0.3710, LR=0.000100
[2025-08-27 16:24:45,786][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083248] [Batch 00088/03080] [00:01:05/00:36:55, 0.741s/it]: train_loss_raw=0.3739, running_loss=0.3672, LR=0.000100
[2025-08-27 16:24:51,577][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083256] [Batch 00096/03080] [00:01:10/00:36:45, 0.739s/it]: train_loss_raw=0.3255, running_loss=0.3653, LR=0.000100
[2025-08-27 16:24:57,524][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083264] [Batch 00104/03080] [00:01:16/00:36:40, 0.740s/it]: train_loss_raw=0.3088, running_loss=0.3645, LR=0.000100
[2025-08-27 16:25:03,550][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083272] [Batch 00112/03080] [00:01:22/00:36:37, 0.741s/it]: train_loss_raw=0.4142, running_loss=0.3624, LR=0.000100
[2025-08-27 16:25:09,468][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083280] [Batch 00120/03080] [00:01:28/00:36:31, 0.740s/it]: train_loss_raw=0.2718, running_loss=0.3598, LR=0.000100
[2025-08-27 16:25:15,216][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083288] [Batch 00128/03080] [00:01:34/00:36:21, 0.739s/it]: train_loss_raw=0.2644, running_loss=0.3575, LR=0.000100
[2025-08-27 16:25:21,008][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083296] [Batch 00136/03080] [00:01:40/00:36:13, 0.738s/it]: train_loss_raw=0.3585, running_loss=0.3584, LR=0.000100
[2025-08-27 16:25:26,909][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083304] [Batch 00144/03080] [00:01:46/00:36:07, 0.738s/it]: train_loss_raw=0.3171, running_loss=0.3565, LR=0.000100
[2025-08-27 16:25:32,824][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083312] [Batch 00152/03080] [00:01:52/00:36:01, 0.738s/it]: train_loss_raw=0.3909, running_loss=0.3587, LR=0.000100
[2025-08-27 16:25:38,677][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083320] [Batch 00160/03080] [00:01:58/00:35:54, 0.738s/it]: train_loss_raw=0.3641, running_loss=0.3583, LR=0.000100
[2025-08-27 16:25:44,710][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083328] [Batch 00168/03080] [00:02:04/00:35:51, 0.739s/it]: train_loss_raw=0.2678, running_loss=0.3550, LR=0.000100
[2025-08-27 16:25:50,722][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083336] [Batch 00176/03080] [00:02:10/00:35:46, 0.739s/it]: train_loss_raw=0.3533, running_loss=0.3553, LR=0.000100
[2025-08-27 16:25:56,728][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083344] [Batch 00184/03080] [00:02:16/00:35:42, 0.740s/it]: train_loss_raw=0.2916, running_loss=0.3530, LR=0.000100
[2025-08-27 16:26:02,743][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083352] [Batch 00192/03080] [00:02:22/00:35:37, 0.740s/it]: train_loss_raw=0.3552, running_loss=0.3555, LR=0.000100
[2025-08-27 16:26:08,674][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083360] [Batch 00200/03080] [00:02:28/00:35:32, 0.740s/it]: train_loss_raw=0.2973, running_loss=0.3525, LR=0.000100
[2025-08-27 16:26:14,635][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083368] [Batch 00208/03080] [00:02:34/00:35:26, 0.740s/it]: train_loss_raw=0.3639, running_loss=0.3491, LR=0.000100
[2025-08-27 16:26:20,662][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083376] [Batch 00216/03080] [00:02:40/00:35:22, 0.741s/it]: train_loss_raw=0.3059, running_loss=0.3506, LR=0.000100
[2025-08-27 16:26:26,477][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083384] [Batch 00224/03080] [00:02:45/00:35:14, 0.740s/it]: train_loss_raw=0.3387, running_loss=0.3506, LR=0.000100
[2025-08-27 16:26:32,305][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083392] [Batch 00232/03080] [00:02:51/00:35:07, 0.740s/it]: train_loss_raw=0.3577, running_loss=0.3499, LR=0.000100
[2025-08-27 16:26:38,302][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083400] [Batch 00240/03080] [00:02:57/00:35:02, 0.740s/it]: train_loss_raw=0.2913, running_loss=0.3473, LR=0.000100
[2025-08-27 16:26:44,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083408] [Batch 00248/03080] [00:03:03/00:34:55, 0.740s/it]: train_loss_raw=0.3265, running_loss=0.3454, LR=0.000100
[2025-08-27 16:26:49,618][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083416] [Batch 00256/03080] [00:03:09/00:34:44, 0.738s/it]: train_loss_raw=0.3576, running_loss=0.3436, LR=0.000100
[2025-08-27 16:26:55,427][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083424] [Batch 00264/03080] [00:03:14/00:34:38, 0.738s/it]: train_loss_raw=0.2890, running_loss=0.3443, LR=0.000100
[2025-08-27 16:27:01,413][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083432] [Batch 00272/03080] [00:03:20/00:34:32, 0.738s/it]: train_loss_raw=0.3693, running_loss=0.3436, LR=0.000100
[2025-08-27 16:27:07,052][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083440] [Batch 00280/03080] [00:03:26/00:34:24, 0.737s/it]: train_loss_raw=0.4078, running_loss=0.3436, LR=0.000100
[2025-08-27 16:27:12,926][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083448] [Batch 00288/03080] [00:03:32/00:34:18, 0.737s/it]: train_loss_raw=0.3005, running_loss=0.3445, LR=0.000100
[2025-08-27 16:27:18,826][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083456] [Batch 00296/03080] [00:03:38/00:34:12, 0.737s/it]: train_loss_raw=0.3557, running_loss=0.3448, LR=0.000100
[2025-08-27 16:27:24,705][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083464] [Batch 00304/03080] [00:03:44/00:34:06, 0.737s/it]: train_loss_raw=0.3943, running_loss=0.3444, LR=0.000100
[2025-08-27 16:27:30,670][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083472] [Batch 00312/03080] [00:03:50/00:34:01, 0.737s/it]: train_loss_raw=0.4223, running_loss=0.3465, LR=0.000100
[2025-08-27 16:27:36,646][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083480] [Batch 00320/03080] [00:03:56/00:33:55, 0.738s/it]: train_loss_raw=0.3466, running_loss=0.3458, LR=0.000100
[2025-08-27 16:27:42,367][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083488] [Batch 00328/03080] [00:04:01/00:33:48, 0.737s/it]: train_loss_raw=0.2782, running_loss=0.3463, LR=0.000100
[2025-08-27 16:27:48,338][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083496] [Batch 00336/03080] [00:04:07/00:33:43, 0.737s/it]: train_loss_raw=0.3884, running_loss=0.3484, LR=0.000100
[2025-08-27 16:27:54,150][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083504] [Batch 00344/03080] [00:04:13/00:33:36, 0.737s/it]: train_loss_raw=0.3685, running_loss=0.3483, LR=0.000100
[2025-08-27 16:27:59,543][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083512] [Batch 00352/03080] [00:04:18/00:33:26, 0.736s/it]: train_loss_raw=0.2828, running_loss=0.3477, LR=0.000100
[2025-08-27 16:28:05,434][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083520] [Batch 00360/03080] [00:04:24/00:33:20, 0.736s/it]: train_loss_raw=0.2928, running_loss=0.3471, LR=0.000100
[2025-08-27 16:28:11,409][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083528] [Batch 00368/03080] [00:04:30/00:33:15, 0.736s/it]: train_loss_raw=0.3243, running_loss=0.3478, LR=0.000100
[2025-08-27 16:28:17,430][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083536] [Batch 00376/03080] [00:04:36/00:33:10, 0.736s/it]: train_loss_raw=0.3412, running_loss=0.3493, LR=0.000100
[2025-08-27 16:28:23,414][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083544] [Batch 00384/03080] [00:04:42/00:33:05, 0.736s/it]: train_loss_raw=0.3277, running_loss=0.3482, LR=0.000100
[2025-08-27 16:28:29,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083552] [Batch 00392/03080] [00:04:48/00:33:00, 0.737s/it]: train_loss_raw=0.4073, running_loss=0.3475, LR=0.000100
[2025-08-27 16:28:35,491][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083560] [Batch 00400/03080] [00:04:54/00:32:55, 0.737s/it]: train_loss_raw=0.3383, running_loss=0.3480, LR=0.000100
[2025-08-27 16:28:41,180][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083568] [Batch 00408/03080] [00:05:00/00:32:48, 0.737s/it]: train_loss_raw=0.3411, running_loss=0.3474, LR=0.000100
[2025-08-27 16:28:47,123][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083576] [Batch 00416/03080] [00:05:06/00:32:42, 0.737s/it]: train_loss_raw=0.3679, running_loss=0.3465, LR=0.000100
[2025-08-27 16:28:52,837][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083584] [Batch 00424/03080] [00:05:12/00:32:35, 0.736s/it]: train_loss_raw=0.4047, running_loss=0.3470, LR=0.000100
[2025-08-27 16:28:58,276][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083592] [Batch 00432/03080] [00:05:17/00:32:27, 0.735s/it]: train_loss_raw=0.3214, running_loss=0.3444, LR=0.000100
[2025-08-27 16:29:04,093][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083600] [Batch 00440/03080] [00:05:23/00:32:20, 0.735s/it]: train_loss_raw=0.2941, running_loss=0.3431, LR=0.000100
[2025-08-27 16:29:09,853][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083608] [Batch 00448/03080] [00:05:29/00:32:14, 0.735s/it]: train_loss_raw=0.3800, running_loss=0.3451, LR=0.000100
[2025-08-27 16:29:15,706][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083616] [Batch 00456/03080] [00:05:35/00:32:08, 0.735s/it]: train_loss_raw=0.3832, running_loss=0.3474, LR=0.000100
[2025-08-27 16:29:21,741][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083624] [Batch 00464/03080] [00:05:41/00:32:03, 0.735s/it]: train_loss_raw=0.3119, running_loss=0.3479, LR=0.000100
[2025-08-27 16:29:27,702][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083632] [Batch 00472/03080] [00:05:47/00:31:57, 0.735s/it]: train_loss_raw=0.4334, running_loss=0.3475, LR=0.000100
[2025-08-27 16:29:33,420][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083640] [Batch 00480/03080] [00:05:52/00:31:51, 0.735s/it]: train_loss_raw=0.3150, running_loss=0.3466, LR=0.000100
[2025-08-27 16:29:39,213][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083648] [Batch 00488/03080] [00:05:58/00:31:44, 0.735s/it]: train_loss_raw=0.2663, running_loss=0.3464, LR=0.000100
[2025-08-27 16:29:45,082][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083656] [Batch 00496/03080] [00:06:04/00:31:38, 0.735s/it]: train_loss_raw=0.3817, running_loss=0.3484, LR=0.000100
[2025-08-27 16:29:50,553][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083664] [Batch 00504/03080] [00:06:09/00:31:30, 0.734s/it]: train_loss_raw=0.3088, running_loss=0.3486, LR=0.000100
[2025-08-27 16:29:56,389][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083672] [Batch 00512/03080] [00:06:15/00:31:24, 0.734s/it]: train_loss_raw=0.2698, running_loss=0.3487, LR=0.000100
[2025-08-27 16:30:02,110][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083680] [Batch 00520/03080] [00:06:21/00:31:18, 0.734s/it]: train_loss_raw=0.3957, running_loss=0.3487, LR=0.000100
[2025-08-27 16:30:07,878][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083688] [Batch 00528/03080] [00:06:27/00:31:11, 0.733s/it]: train_loss_raw=0.3482, running_loss=0.3490, LR=0.000100
[2025-08-27 16:30:13,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083696] [Batch 00536/03080] [00:06:33/00:31:05, 0.733s/it]: train_loss_raw=0.3588, running_loss=0.3493, LR=0.000100
[2025-08-27 16:30:19,477][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083704] [Batch 00544/03080] [00:06:38/00:30:59, 0.733s/it]: train_loss_raw=0.3317, running_loss=0.3491, LR=0.000100
[2025-08-27 16:30:25,212][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083712] [Batch 00552/03080] [00:06:44/00:30:52, 0.733s/it]: train_loss_raw=0.3323, running_loss=0.3485, LR=0.000100
[2025-08-27 16:30:30,638][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083720] [Batch 00560/03080] [00:06:50/00:30:45, 0.732s/it]: train_loss_raw=0.4469, running_loss=0.3510, LR=0.000100
[2025-08-27 16:30:36,249][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083728] [Batch 00568/03080] [00:06:55/00:30:38, 0.732s/it]: train_loss_raw=0.3127, running_loss=0.3506, LR=0.000100
[2025-08-27 16:30:41,792][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083736] [Batch 00576/03080] [00:07:01/00:30:30, 0.731s/it]: train_loss_raw=0.3225, running_loss=0.3491, LR=0.000100
[2025-08-27 16:30:47,378][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083744] [Batch 00584/03080] [00:07:06/00:30:23, 0.731s/it]: train_loss_raw=0.4022, running_loss=0.3499, LR=0.000100
[2025-08-27 16:30:53,075][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083752] [Batch 00592/03080] [00:07:12/00:30:17, 0.731s/it]: train_loss_raw=0.4441, running_loss=0.3489, LR=0.000100
[2025-08-27 16:30:58,585][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083760] [Batch 00600/03080] [00:07:17/00:30:10, 0.730s/it]: train_loss_raw=0.3633, running_loss=0.3486, LR=0.000100
[2025-08-27 16:31:04,417][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083768] [Batch 00608/03080] [00:07:23/00:30:04, 0.730s/it]: train_loss_raw=0.3198, running_loss=0.3471, LR=0.000100
[2025-08-27 16:31:10,131][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083776] [Batch 00616/03080] [00:07:29/00:29:58, 0.730s/it]: train_loss_raw=0.4088, running_loss=0.3461, LR=0.000100
[2025-08-27 16:31:16,073][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083784] [Batch 00624/03080] [00:07:35/00:29:52, 0.730s/it]: train_loss_raw=0.3137, running_loss=0.3454, LR=0.000100
[2025-08-27 16:31:21,552][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083792] [Batch 00632/03080] [00:07:40/00:29:45, 0.729s/it]: train_loss_raw=0.3074, running_loss=0.3436, LR=0.000100
[2025-08-27 16:31:27,446][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083800] [Batch 00640/03080] [00:07:46/00:29:39, 0.729s/it]: train_loss_raw=0.2713, running_loss=0.3426, LR=0.000100
[2025-08-27 16:31:33,411][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083808] [Batch 00648/03080] [00:07:52/00:29:34, 0.730s/it]: train_loss_raw=0.3313, running_loss=0.3439, LR=0.000100
[2025-08-27 16:31:39,318][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083816] [Batch 00656/03080] [00:07:58/00:29:28, 0.730s/it]: train_loss_raw=0.2651, running_loss=0.3431, LR=0.000100
[2025-08-27 16:31:44,874][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083824] [Batch 00664/03080] [00:08:04/00:29:22, 0.729s/it]: train_loss_raw=0.2565, running_loss=0.3415, LR=0.000100
[2025-08-27 16:31:50,686][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083832] [Batch 00672/03080] [00:08:10/00:29:16, 0.729s/it]: train_loss_raw=0.2817, running_loss=0.3416, LR=0.000100
[2025-08-27 16:31:56,086][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083840] [Batch 00680/03080] [00:08:15/00:29:08, 0.729s/it]: train_loss_raw=0.2961, running_loss=0.3406, LR=0.000100
[2025-08-27 16:32:01,731][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083848] [Batch 00688/03080] [00:08:21/00:29:02, 0.728s/it]: train_loss_raw=0.2767, running_loss=0.3399, LR=0.000100
[2025-08-27 16:32:07,578][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083856] [Batch 00696/03080] [00:08:26/00:28:56, 0.728s/it]: train_loss_raw=0.3219, running_loss=0.3398, LR=0.000100
[2025-08-27 16:32:13,653][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083864] [Batch 00704/03080] [00:08:33/00:28:51, 0.729s/it]: train_loss_raw=0.3734, running_loss=0.3412, LR=0.000100
[2025-08-27 16:32:19,319][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083872] [Batch 00712/03080] [00:08:38/00:28:45, 0.729s/it]: train_loss_raw=0.3339, running_loss=0.3419, LR=0.000100
[2025-08-27 16:32:24,938][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083880] [Batch 00720/03080] [00:08:44/00:28:38, 0.728s/it]: train_loss_raw=0.2949, running_loss=0.3440, LR=0.000100
[2025-08-27 16:32:30,943][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083888] [Batch 00728/03080] [00:08:50/00:28:33, 0.728s/it]: train_loss_raw=0.3393, running_loss=0.3449, LR=0.000100
[2025-08-27 16:32:36,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083896] [Batch 00736/03080] [00:08:55/00:28:26, 0.728s/it]: train_loss_raw=0.3630, running_loss=0.3440, LR=0.000100
[2025-08-27 16:32:42,469][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083904] [Batch 00744/03080] [00:09:01/00:28:21, 0.728s/it]: train_loss_raw=0.2555, running_loss=0.3444, LR=0.000100
[2025-08-27 16:32:48,347][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083912] [Batch 00752/03080] [00:09:07/00:28:15, 0.728s/it]: train_loss_raw=0.3362, running_loss=0.3447, LR=0.000100
[2025-08-27 16:32:54,365][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083920] [Batch 00760/03080] [00:09:13/00:28:10, 0.729s/it]: train_loss_raw=0.3680, running_loss=0.3457, LR=0.000100
[2025-08-27 16:33:00,210][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083928] [Batch 00768/03080] [00:09:19/00:28:04, 0.729s/it]: train_loss_raw=0.3417, running_loss=0.3446, LR=0.000100
[2025-08-27 16:33:06,094][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083936] [Batch 00776/03080] [00:09:25/00:27:58, 0.729s/it]: train_loss_raw=0.3243, running_loss=0.3436, LR=0.000100
[2025-08-27 16:33:11,915][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083944] [Batch 00784/03080] [00:09:31/00:27:53, 0.729s/it]: train_loss_raw=0.3158, running_loss=0.3445, LR=0.000100
[2025-08-27 16:33:17,513][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083952] [Batch 00792/03080] [00:09:36/00:27:46, 0.728s/it]: train_loss_raw=0.2835, running_loss=0.3444, LR=0.000100
[2025-08-27 16:33:23,483][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083960] [Batch 00800/03080] [00:09:42/00:27:41, 0.729s/it]: train_loss_raw=0.2858, running_loss=0.3429, LR=0.000100
[2025-08-27 16:33:29,212][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083968] [Batch 00808/03080] [00:09:48/00:27:35, 0.728s/it]: train_loss_raw=0.3369, running_loss=0.3420, LR=0.000100
[2025-08-27 16:33:35,066][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083976] [Batch 00816/03080] [00:09:54/00:27:29, 0.728s/it]: train_loss_raw=0.3293, running_loss=0.3411, LR=0.000100
[2025-08-27 16:33:40,510][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083984] [Batch 00824/03080] [00:09:59/00:27:22, 0.728s/it]: train_loss_raw=0.2881, running_loss=0.3388, LR=0.000100
[2025-08-27 16:33:45,913][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 083992] [Batch 00832/03080] [00:10:05/00:27:15, 0.728s/it]: train_loss_raw=0.3167, running_loss=0.3396, LR=0.000100
[2025-08-27 16:33:51,333][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084000] [Batch 00840/03080] [00:10:10/00:27:08, 0.727s/it]: train_loss_raw=0.2631, running_loss=0.3392, LR=0.000100
[2025-08-27 16:34:00,636][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084008] [Batch 00848/03080] [00:10:20/00:27:11, 0.731s/it]: train_loss_raw=0.3305, running_loss=0.3378, LR=0.000100
[2025-08-27 16:34:06,203][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084016] [Batch 00856/03080] [00:10:25/00:27:05, 0.731s/it]: train_loss_raw=0.2973, running_loss=0.3367, LR=0.000100
[2025-08-27 16:34:12,069][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084024] [Batch 00864/03080] [00:10:31/00:26:59, 0.731s/it]: train_loss_raw=0.3195, running_loss=0.3373, LR=0.000100
[2025-08-27 16:34:17,782][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084032] [Batch 00872/03080] [00:10:37/00:26:53, 0.731s/it]: train_loss_raw=0.4262, running_loss=0.3373, LR=0.000100
[2025-08-27 16:34:23,428][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084040] [Batch 00880/03080] [00:10:42/00:26:47, 0.730s/it]: train_loss_raw=0.3710, running_loss=0.3377, LR=0.000100
[2025-08-27 16:34:28,844][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084048] [Batch 00888/03080] [00:10:48/00:26:40, 0.730s/it]: train_loss_raw=0.3010, running_loss=0.3362, LR=0.000100
[2025-08-27 16:34:34,507][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084056] [Batch 00896/03080] [00:10:53/00:26:33, 0.730s/it]: train_loss_raw=0.2558, running_loss=0.3339, LR=0.000100
[2025-08-27 16:34:39,971][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084064] [Batch 00904/03080] [00:10:59/00:26:27, 0.729s/it]: train_loss_raw=0.3037, running_loss=0.3346, LR=0.000100
[2025-08-27 16:34:45,882][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084072] [Batch 00912/03080] [00:11:05/00:26:21, 0.729s/it]: train_loss_raw=0.3550, running_loss=0.3349, LR=0.000100
[2025-08-27 16:34:51,954][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084080] [Batch 00920/03080] [00:11:11/00:26:16, 0.730s/it]: train_loss_raw=0.3396, running_loss=0.3362, LR=0.000100
[2025-08-27 16:34:57,750][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084088] [Batch 00928/03080] [00:11:17/00:26:10, 0.730s/it]: train_loss_raw=0.3065, running_loss=0.3373, LR=0.000100
[2025-08-27 16:35:03,432][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084096] [Batch 00936/03080] [00:11:22/00:26:04, 0.730s/it]: train_loss_raw=0.3723, running_loss=0.3388, LR=0.000100
[2025-08-27 16:35:09,043][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084104] [Batch 00944/03080] [00:11:28/00:25:57, 0.729s/it]: train_loss_raw=0.4339, running_loss=0.3403, LR=0.000100
[2025-08-27 16:35:14,658][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084112] [Batch 00952/03080] [00:11:34/00:25:51, 0.729s/it]: train_loss_raw=0.3558, running_loss=0.3408, LR=0.000100
[2025-08-27 16:35:20,772][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084120] [Batch 00960/03080] [00:11:40/00:25:46, 0.729s/it]: train_loss_raw=0.3570, running_loss=0.3399, LR=0.000100
[2025-08-27 16:35:26,274][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084128] [Batch 00968/03080] [00:11:45/00:25:39, 0.729s/it]: train_loss_raw=0.3788, running_loss=0.3397, LR=0.000100
[2025-08-27 16:35:32,210][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084136] [Batch 00976/03080] [00:11:51/00:25:34, 0.729s/it]: train_loss_raw=0.3132, running_loss=0.3407, LR=0.000100
[2025-08-27 16:35:38,212][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084144] [Batch 00984/03080] [00:11:57/00:25:28, 0.729s/it]: train_loss_raw=0.2839, running_loss=0.3389, LR=0.000100
[2025-08-27 16:35:43,830][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084152] [Batch 00992/03080] [00:12:03/00:25:22, 0.729s/it]: train_loss_raw=0.3786, running_loss=0.3385, LR=0.000100
[2025-08-27 16:35:49,815][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084160] [Batch 01000/03080] [00:12:09/00:25:16, 0.729s/it]: train_loss_raw=0.3469, running_loss=0.3378, LR=0.000100
[2025-08-27 16:35:55,842][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084168] [Batch 01008/03080] [00:12:15/00:25:11, 0.729s/it]: train_loss_raw=0.4400, running_loss=0.3391, LR=0.000100
[2025-08-27 16:36:01,502][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084176] [Batch 01016/03080] [00:12:20/00:25:05, 0.729s/it]: train_loss_raw=0.4082, running_loss=0.3401, LR=0.000100
[2025-08-27 16:36:07,295][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084184] [Batch 01024/03080] [00:12:26/00:24:59, 0.729s/it]: train_loss_raw=0.2825, running_loss=0.3393, LR=0.000100
[2025-08-27 16:36:12,912][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084192] [Batch 01032/03080] [00:12:32/00:24:52, 0.729s/it]: train_loss_raw=0.3972, running_loss=0.3417, LR=0.000100
[2025-08-27 16:36:18,570][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084200] [Batch 01040/03080] [00:12:37/00:24:46, 0.729s/it]: train_loss_raw=0.3498, running_loss=0.3421, LR=0.000100
[2025-08-27 16:36:24,219][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084208] [Batch 01048/03080] [00:12:43/00:24:40, 0.729s/it]: train_loss_raw=0.3332, running_loss=0.3431, LR=0.000100
[2025-08-27 16:36:29,858][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084216] [Batch 01056/03080] [00:12:49/00:24:34, 0.728s/it]: train_loss_raw=0.3547, running_loss=0.3418, LR=0.000100
[2025-08-27 16:36:35,559][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084224] [Batch 01064/03080] [00:12:54/00:24:28, 0.728s/it]: train_loss_raw=0.2670, running_loss=0.3417, LR=0.000100
[2025-08-27 16:36:41,392][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084232] [Batch 01072/03080] [00:13:00/00:24:22, 0.728s/it]: train_loss_raw=0.3570, running_loss=0.3411, LR=0.000100
[2025-08-27 16:36:47,429][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084240] [Batch 01080/03080] [00:13:06/00:24:17, 0.729s/it]: train_loss_raw=0.3691, running_loss=0.3426, LR=0.000100
[2025-08-27 16:36:53,300][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084248] [Batch 01088/03080] [00:13:12/00:24:11, 0.729s/it]: train_loss_raw=0.4276, running_loss=0.3430, LR=0.000100
[2025-08-27 16:36:58,792][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084256] [Batch 01096/03080] [00:13:18/00:24:04, 0.728s/it]: train_loss_raw=0.3609, running_loss=0.3415, LR=0.000100
[2025-08-27 16:37:04,930][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084264] [Batch 01104/03080] [00:13:24/00:23:59, 0.729s/it]: train_loss_raw=0.3080, running_loss=0.3423, LR=0.000100
[2025-08-27 16:37:10,333][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084272] [Batch 01112/03080] [00:13:29/00:23:53, 0.728s/it]: train_loss_raw=0.3553, running_loss=0.3411, LR=0.000100
[2025-08-27 16:37:16,070][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084280] [Batch 01120/03080] [00:13:35/00:23:47, 0.728s/it]: train_loss_raw=0.3800, running_loss=0.3403, LR=0.000100
[2025-08-27 16:37:21,954][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084288] [Batch 01128/03080] [00:13:41/00:23:41, 0.728s/it]: train_loss_raw=0.3080, running_loss=0.3408, LR=0.000100
[2025-08-27 16:37:27,325][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084296] [Batch 01136/03080] [00:13:46/00:23:34, 0.728s/it]: train_loss_raw=0.3670, running_loss=0.3420, LR=0.000100
[2025-08-27 16:37:32,861][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084304] [Batch 01144/03080] [00:13:52/00:23:28, 0.727s/it]: train_loss_raw=0.2603, running_loss=0.3408, LR=0.000100
[2025-08-27 16:37:38,853][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084312] [Batch 01152/03080] [00:13:58/00:23:22, 0.728s/it]: train_loss_raw=0.3555, running_loss=0.3391, LR=0.000100
[2025-08-27 16:37:44,639][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084320] [Batch 01160/03080] [00:14:04/00:23:17, 0.728s/it]: train_loss_raw=0.4728, running_loss=0.3405, LR=0.000100
[2025-08-27 16:37:50,414][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084328] [Batch 01168/03080] [00:14:09/00:23:11, 0.728s/it]: train_loss_raw=0.3218, running_loss=0.3398, LR=0.000100
[2025-08-27 16:37:56,061][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084336] [Batch 01176/03080] [00:14:15/00:23:05, 0.727s/it]: train_loss_raw=0.3179, running_loss=0.3398, LR=0.000100
[2025-08-27 16:38:01,942][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084344] [Batch 01184/03080] [00:14:21/00:22:59, 0.727s/it]: train_loss_raw=0.2711, running_loss=0.3387, LR=0.000100
[2025-08-27 16:38:07,859][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084352] [Batch 01192/03080] [00:14:27/00:22:53, 0.728s/it]: train_loss_raw=0.3911, running_loss=0.3390, LR=0.000100
[2025-08-27 16:38:13,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084360] [Batch 01200/03080] [00:14:33/00:22:47, 0.728s/it]: train_loss_raw=0.3836, running_loss=0.3390, LR=0.000100
[2025-08-27 16:38:19,642][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084368] [Batch 01208/03080] [00:14:39/00:22:42, 0.728s/it]: train_loss_raw=0.3654, running_loss=0.3396, LR=0.000100
[2025-08-27 16:38:25,414][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084376] [Batch 01216/03080] [00:14:44/00:22:36, 0.728s/it]: train_loss_raw=0.3670, running_loss=0.3394, LR=0.000100
[2025-08-27 16:38:31,436][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084384] [Batch 01224/03080] [00:14:50/00:22:30, 0.728s/it]: train_loss_raw=0.2652, running_loss=0.3418, LR=0.000100
[2025-08-27 16:38:37,496][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084392] [Batch 01232/03080] [00:14:56/00:22:25, 0.728s/it]: train_loss_raw=0.3512, running_loss=0.3418, LR=0.000100
[2025-08-27 16:38:43,219][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084400] [Batch 01240/03080] [00:15:02/00:22:19, 0.728s/it]: train_loss_raw=0.3906, running_loss=0.3419, LR=0.000100
[2025-08-27 16:38:48,648][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084408] [Batch 01248/03080] [00:15:08/00:22:12, 0.728s/it]: train_loss_raw=0.4573, running_loss=0.3452, LR=0.000100
[2025-08-27 16:38:54,393][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084416] [Batch 01256/03080] [00:15:13/00:22:07, 0.728s/it]: train_loss_raw=0.3645, running_loss=0.3466, LR=0.000100
[2025-08-27 16:38:59,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084424] [Batch 01264/03080] [00:15:19/00:22:00, 0.727s/it]: train_loss_raw=0.3231, running_loss=0.3461, LR=0.000100
[2025-08-27 16:39:05,300][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084432] [Batch 01272/03080] [00:15:24/00:21:54, 0.727s/it]: train_loss_raw=0.3349, running_loss=0.3459, LR=0.000100
[2025-08-27 16:39:11,029][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084440] [Batch 01280/03080] [00:15:30/00:21:48, 0.727s/it]: train_loss_raw=0.3775, running_loss=0.3461, LR=0.000100
[2025-08-27 16:39:16,758][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084448] [Batch 01288/03080] [00:15:36/00:21:42, 0.727s/it]: train_loss_raw=0.3520, running_loss=0.3448, LR=0.000100
[2025-08-27 16:39:22,153][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084456] [Batch 01296/03080] [00:15:41/00:21:36, 0.726s/it]: train_loss_raw=0.2722, running_loss=0.3432, LR=0.000100
[2025-08-27 16:39:27,771][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084464] [Batch 01304/03080] [00:15:47/00:21:29, 0.726s/it]: train_loss_raw=0.3881, running_loss=0.3437, LR=0.000100
[2025-08-27 16:39:33,482][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084472] [Batch 01312/03080] [00:15:52/00:21:24, 0.726s/it]: train_loss_raw=0.4299, running_loss=0.3467, LR=0.000100
[2025-08-27 16:39:39,321][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084480] [Batch 01320/03080] [00:15:58/00:21:18, 0.726s/it]: train_loss_raw=0.3965, running_loss=0.3468, LR=0.000100
[2025-08-27 16:39:44,774][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084488] [Batch 01328/03080] [00:16:04/00:21:11, 0.726s/it]: train_loss_raw=0.3295, running_loss=0.3457, LR=0.000100
[2025-08-27 16:39:50,364][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084496] [Batch 01336/03080] [00:16:09/00:21:05, 0.726s/it]: train_loss_raw=0.3287, running_loss=0.3469, LR=0.000100
[2025-08-27 16:39:56,310][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084504] [Batch 01344/03080] [00:16:15/00:21:00, 0.726s/it]: train_loss_raw=0.4273, running_loss=0.3483, LR=0.000100
[2025-08-27 16:40:02,465][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084512] [Batch 01352/03080] [00:16:21/00:20:54, 0.726s/it]: train_loss_raw=0.3790, running_loss=0.3477, LR=0.000100
[2025-08-27 16:40:08,671][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084520] [Batch 01360/03080] [00:16:28/00:20:49, 0.727s/it]: train_loss_raw=0.3160, running_loss=0.3470, LR=0.000100
[2025-08-27 16:40:14,842][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084528] [Batch 01368/03080] [00:16:34/00:20:44, 0.727s/it]: train_loss_raw=0.3725, running_loss=0.3467, LR=0.000100
[2025-08-27 16:40:20,801][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084536] [Batch 01376/03080] [00:16:40/00:20:38, 0.727s/it]: train_loss_raw=0.3111, running_loss=0.3468, LR=0.000100
[2025-08-27 16:40:26,888][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084544] [Batch 01384/03080] [00:16:46/00:20:33, 0.727s/it]: train_loss_raw=0.2864, running_loss=0.3458, LR=0.000100
[2025-08-27 16:40:32,840][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084552] [Batch 01392/03080] [00:16:52/00:20:27, 0.727s/it]: train_loss_raw=0.3827, running_loss=0.3462, LR=0.000100
[2025-08-27 16:40:38,951][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084560] [Batch 01400/03080] [00:16:58/00:20:22, 0.727s/it]: train_loss_raw=0.3780, running_loss=0.3475, LR=0.000100
[2025-08-27 16:40:44,745][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084568] [Batch 01408/03080] [00:17:04/00:20:16, 0.727s/it]: train_loss_raw=0.4140, running_loss=0.3500, LR=0.000100
[2025-08-27 16:40:50,543][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084576] [Batch 01416/03080] [00:17:09/00:20:10, 0.727s/it]: train_loss_raw=0.2806, running_loss=0.3477, LR=0.000100
[2025-08-27 16:40:56,320][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084584] [Batch 01424/03080] [00:17:15/00:20:04, 0.727s/it]: train_loss_raw=0.3655, running_loss=0.3502, LR=0.000100
[2025-08-27 16:41:02,395][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084592] [Batch 01432/03080] [00:17:21/00:19:58, 0.728s/it]: train_loss_raw=0.3566, running_loss=0.3495, LR=0.000100
[2025-08-27 16:41:08,200][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084600] [Batch 01440/03080] [00:17:27/00:19:53, 0.727s/it]: train_loss_raw=0.3959, running_loss=0.3478, LR=0.000100
[2025-08-27 16:41:14,232][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084608] [Batch 01448/03080] [00:17:33/00:19:47, 0.728s/it]: train_loss_raw=0.4456, running_loss=0.3479, LR=0.000100
[2025-08-27 16:41:20,461][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084616] [Batch 01456/03080] [00:17:39/00:19:42, 0.728s/it]: train_loss_raw=0.3591, running_loss=0.3483, LR=0.000100
[2025-08-27 16:41:26,671][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084624] [Batch 01464/03080] [00:17:46/00:19:36, 0.728s/it]: train_loss_raw=0.3306, running_loss=0.3466, LR=0.000100
[2025-08-27 16:41:32,569][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084632] [Batch 01472/03080] [00:17:51/00:19:30, 0.728s/it]: train_loss_raw=0.3350, running_loss=0.3446, LR=0.000100
[2025-08-27 16:41:38,605][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084640] [Batch 01480/03080] [00:17:57/00:19:25, 0.728s/it]: train_loss_raw=0.3370, running_loss=0.3443, LR=0.000100
[2025-08-27 16:41:44,309][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084648] [Batch 01488/03080] [00:18:03/00:19:19, 0.728s/it]: train_loss_raw=0.3705, running_loss=0.3456, LR=0.000100
[2025-08-27 16:41:50,129][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084656] [Batch 01496/03080] [00:18:09/00:19:13, 0.728s/it]: train_loss_raw=0.3097, running_loss=0.3440, LR=0.000100
[2025-08-27 16:41:55,895][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084664] [Batch 01504/03080] [00:18:15/00:19:07, 0.728s/it]: train_loss_raw=0.3242, running_loss=0.3446, LR=0.000100
[2025-08-27 16:42:01,810][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084672] [Batch 01512/03080] [00:18:21/00:19:01, 0.728s/it]: train_loss_raw=0.3590, running_loss=0.3460, LR=0.000100
[2025-08-27 16:42:07,672][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084680] [Batch 01520/03080] [00:18:27/00:18:56, 0.728s/it]: train_loss_raw=0.3532, running_loss=0.3448, LR=0.000100
[2025-08-27 16:42:13,530][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084688] [Batch 01528/03080] [00:18:32/00:18:50, 0.728s/it]: train_loss_raw=0.3500, running_loss=0.3437, LR=0.000100
[2025-08-27 16:42:19,664][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084696] [Batch 01536/03080] [00:18:39/00:18:44, 0.729s/it]: train_loss_raw=0.4248, running_loss=0.3433, LR=0.000100
[2025-08-27 16:42:25,809][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084704] [Batch 01544/03080] [00:18:45/00:18:39, 0.729s/it]: train_loss_raw=0.3376, running_loss=0.3439, LR=0.000100
[2025-08-27 16:42:31,989][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084712] [Batch 01552/03080] [00:18:51/00:18:33, 0.729s/it]: train_loss_raw=0.3583, running_loss=0.3446, LR=0.000100
[2025-08-27 16:42:37,985][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084720] [Batch 01560/03080] [00:18:57/00:18:28, 0.729s/it]: train_loss_raw=0.4102, running_loss=0.3454, LR=0.000100
[2025-08-27 16:42:44,041][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084728] [Batch 01568/03080] [00:19:03/00:18:22, 0.729s/it]: train_loss_raw=0.2918, running_loss=0.3461, LR=0.000100
[2025-08-27 16:42:50,140][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084736] [Batch 01576/03080] [00:19:09/00:18:17, 0.729s/it]: train_loss_raw=0.3958, running_loss=0.3458, LR=0.000100
[2025-08-27 16:42:56,003][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084744] [Batch 01584/03080] [00:19:15/00:18:11, 0.729s/it]: train_loss_raw=0.3500, running_loss=0.3436, LR=0.000100
[2025-08-27 16:43:01,748][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084752] [Batch 01592/03080] [00:19:21/00:18:05, 0.729s/it]: train_loss_raw=0.2747, running_loss=0.3417, LR=0.000100
[2025-08-27 16:43:07,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084760] [Batch 01600/03080] [00:19:27/00:17:59, 0.730s/it]: train_loss_raw=0.3514, running_loss=0.3409, LR=0.000100
[2025-08-27 16:43:13,783][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084768] [Batch 01608/03080] [00:19:33/00:17:53, 0.730s/it]: train_loss_raw=0.4227, running_loss=0.3420, LR=0.000100
[2025-08-27 16:43:19,701][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084776] [Batch 01616/03080] [00:19:39/00:17:48, 0.730s/it]: train_loss_raw=0.4081, running_loss=0.3437, LR=0.000100
[2025-08-27 16:43:25,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084784] [Batch 01624/03080] [00:19:44/00:17:42, 0.730s/it]: train_loss_raw=0.3167, running_loss=0.3443, LR=0.000100
[2025-08-27 16:43:31,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084792] [Batch 01632/03080] [00:19:50/00:17:36, 0.730s/it]: train_loss_raw=0.3792, running_loss=0.3456, LR=0.000100
[2025-08-27 16:43:37,550][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084800] [Batch 01640/03080] [00:19:56/00:17:30, 0.730s/it]: train_loss_raw=0.3066, running_loss=0.3453, LR=0.000100
[2025-08-27 16:43:43,258][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084808] [Batch 01648/03080] [00:20:02/00:17:25, 0.730s/it]: train_loss_raw=0.3378, running_loss=0.3453, LR=0.000100
[2025-08-27 16:43:49,399][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084816] [Batch 01656/03080] [00:20:08/00:17:19, 0.730s/it]: train_loss_raw=0.3224, running_loss=0.3457, LR=0.000100
[2025-08-27 16:43:55,190][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084824] [Batch 01664/03080] [00:20:14/00:17:13, 0.730s/it]: train_loss_raw=0.4182, running_loss=0.3444, LR=0.000100
[2025-08-27 16:44:01,216][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084832] [Batch 01672/03080] [00:20:20/00:17:07, 0.730s/it]: train_loss_raw=0.3616, running_loss=0.3451, LR=0.000100
[2025-08-27 16:44:06,819][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084840] [Batch 01680/03080] [00:20:26/00:17:01, 0.730s/it]: train_loss_raw=0.3312, running_loss=0.3444, LR=0.000100
[2025-08-27 16:44:12,420][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084848] [Batch 01688/03080] [00:20:31/00:16:55, 0.730s/it]: train_loss_raw=0.3087, running_loss=0.3405, LR=0.000100
[2025-08-27 16:44:18,469][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084856] [Batch 01696/03080] [00:20:37/00:16:50, 0.730s/it]: train_loss_raw=0.3571, running_loss=0.3386, LR=0.000100
[2025-08-27 16:44:24,241][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084864] [Batch 01704/03080] [00:20:43/00:16:44, 0.730s/it]: train_loss_raw=0.3722, running_loss=0.3390, LR=0.000100
[2025-08-27 16:44:29,925][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084872] [Batch 01712/03080] [00:20:49/00:16:38, 0.730s/it]: train_loss_raw=0.3613, running_loss=0.3407, LR=0.000100
[2025-08-27 16:44:35,471][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084880] [Batch 01720/03080] [00:20:54/00:16:32, 0.730s/it]: train_loss_raw=0.3656, running_loss=0.3422, LR=0.000100
[2025-08-27 16:44:40,948][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084888] [Batch 01728/03080] [00:21:00/00:16:26, 0.729s/it]: train_loss_raw=0.2715, running_loss=0.3404, LR=0.000100
[2025-08-27 16:44:46,353][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084896] [Batch 01736/03080] [00:21:05/00:16:19, 0.729s/it]: train_loss_raw=0.3521, running_loss=0.3404, LR=0.000100
[2025-08-27 16:44:52,021][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084904] [Batch 01744/03080] [00:21:11/00:16:13, 0.729s/it]: train_loss_raw=0.3872, running_loss=0.3400, LR=0.000100
[2025-08-27 16:44:57,754][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084912] [Batch 01752/03080] [00:21:17/00:16:08, 0.729s/it]: train_loss_raw=0.3773, running_loss=0.3388, LR=0.000100
[2025-08-27 16:45:03,492][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084920] [Batch 01760/03080] [00:21:22/00:16:02, 0.729s/it]: train_loss_raw=0.3674, running_loss=0.3385, LR=0.000100
[2025-08-27 16:45:09,251][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084928] [Batch 01768/03080] [00:21:28/00:15:56, 0.729s/it]: train_loss_raw=0.3711, running_loss=0.3387, LR=0.000100
[2025-08-27 16:45:15,199][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084936] [Batch 01776/03080] [00:21:34/00:15:50, 0.729s/it]: train_loss_raw=0.3721, running_loss=0.3418, LR=0.000100
[2025-08-27 16:45:21,164][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084944] [Batch 01784/03080] [00:21:40/00:15:44, 0.729s/it]: train_loss_raw=0.3219, running_loss=0.3417, LR=0.000100
[2025-08-27 16:45:26,877][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084952] [Batch 01792/03080] [00:21:46/00:15:38, 0.729s/it]: train_loss_raw=0.3520, running_loss=0.3425, LR=0.000100
[2025-08-27 16:45:32,621][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084960] [Batch 01800/03080] [00:21:52/00:15:32, 0.729s/it]: train_loss_raw=0.3479, running_loss=0.3445, LR=0.000100
[2025-08-27 16:45:38,752][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084968] [Batch 01808/03080] [00:21:58/00:15:27, 0.729s/it]: train_loss_raw=0.4028, running_loss=0.3444, LR=0.000100
[2025-08-27 16:45:44,556][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084976] [Batch 01816/03080] [00:22:03/00:15:21, 0.729s/it]: train_loss_raw=0.4063, running_loss=0.3439, LR=0.000100
[2025-08-27 16:45:50,304][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084984] [Batch 01824/03080] [00:22:09/00:15:15, 0.729s/it]: train_loss_raw=0.4392, running_loss=0.3455, LR=0.000100
[2025-08-27 16:45:55,958][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 084992] [Batch 01832/03080] [00:22:15/00:15:09, 0.729s/it]: train_loss_raw=0.3296, running_loss=0.3467, LR=0.000100
[2025-08-27 16:46:01,753][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085000] [Batch 01840/03080] [00:22:21/00:15:03, 0.729s/it]: train_loss_raw=0.2821, running_loss=0.3443, LR=0.000100
[2025-08-27 16:46:07,645][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085008] [Batch 01848/03080] [00:22:27/00:14:58, 0.729s/it]: train_loss_raw=0.3673, running_loss=0.3445, LR=0.000100
[2025-08-27 16:46:13,342][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085016] [Batch 01856/03080] [00:22:32/00:14:52, 0.729s/it]: train_loss_raw=0.3562, running_loss=0.3468, LR=0.000100
[2025-08-27 16:46:19,278][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085024] [Batch 01864/03080] [00:22:38/00:14:46, 0.729s/it]: train_loss_raw=0.3793, running_loss=0.3447, LR=0.000100
[2025-08-27 16:46:25,208][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085032] [Batch 01872/03080] [00:22:44/00:14:40, 0.729s/it]: train_loss_raw=0.3461, running_loss=0.3458, LR=0.000100
[2025-08-27 16:46:31,015][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085040] [Batch 01880/03080] [00:22:50/00:14:34, 0.729s/it]: train_loss_raw=0.3084, running_loss=0.3449, LR=0.000100
[2025-08-27 16:46:36,851][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085048] [Batch 01888/03080] [00:22:56/00:14:28, 0.729s/it]: train_loss_raw=0.3606, running_loss=0.3438, LR=0.000100
[2025-08-27 16:46:42,686][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085056] [Batch 01896/03080] [00:23:02/00:14:23, 0.729s/it]: train_loss_raw=0.3917, running_loss=0.3435, LR=0.000100
[2025-08-27 16:46:48,511][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085064] [Batch 01904/03080] [00:23:07/00:14:17, 0.729s/it]: train_loss_raw=0.2464, running_loss=0.3438, LR=0.000100
[2025-08-27 16:46:53,955][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085072] [Batch 01912/03080] [00:23:13/00:14:11, 0.729s/it]: train_loss_raw=0.3594, running_loss=0.3425, LR=0.000100
[2025-08-27 16:46:59,395][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085080] [Batch 01920/03080] [00:23:18/00:14:05, 0.729s/it]: train_loss_raw=0.4680, running_loss=0.3431, LR=0.000100
[2025-08-27 16:47:04,811][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085088] [Batch 01928/03080] [00:23:24/00:13:59, 0.728s/it]: train_loss_raw=0.3977, running_loss=0.3423, LR=0.000100
[2025-08-27 16:47:10,501][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085096] [Batch 01936/03080] [00:23:29/00:13:53, 0.728s/it]: train_loss_raw=0.3170, running_loss=0.3426, LR=0.000100
[2025-08-27 16:47:16,510][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085104] [Batch 01944/03080] [00:23:35/00:13:47, 0.728s/it]: train_loss_raw=0.3337, running_loss=0.3428, LR=0.000100
[2025-08-27 16:47:22,375][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085112] [Batch 01952/03080] [00:23:41/00:13:41, 0.728s/it]: train_loss_raw=0.3018, running_loss=0.3405, LR=0.000100
[2025-08-27 16:47:28,183][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085120] [Batch 01960/03080] [00:23:47/00:13:35, 0.728s/it]: train_loss_raw=0.3603, running_loss=0.3406, LR=0.000100
[2025-08-27 16:47:33,912][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085128] [Batch 01968/03080] [00:23:53/00:13:29, 0.728s/it]: train_loss_raw=0.3669, running_loss=0.3410, LR=0.000100
[2025-08-27 16:47:39,483][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085136] [Batch 01976/03080] [00:23:58/00:13:23, 0.728s/it]: train_loss_raw=0.4291, running_loss=0.3432, LR=0.000100
[2025-08-27 16:47:45,488][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085144] [Batch 01984/03080] [00:24:04/00:13:18, 0.728s/it]: train_loss_raw=0.2775, running_loss=0.3427, LR=0.000100
[2025-08-27 16:47:51,294][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085152] [Batch 01992/03080] [00:24:10/00:13:12, 0.728s/it]: train_loss_raw=0.2583, running_loss=0.3415, LR=0.000100
[2025-08-27 16:47:56,928][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085160] [Batch 02000/03080] [00:24:16/00:13:06, 0.728s/it]: train_loss_raw=0.3325, running_loss=0.3408, LR=0.000100
[2025-08-27 16:48:02,491][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085168] [Batch 02008/03080] [00:24:21/00:13:00, 0.728s/it]: train_loss_raw=0.3654, running_loss=0.3407, LR=0.000100
[2025-08-27 16:48:08,149][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085176] [Batch 02016/03080] [00:24:27/00:12:54, 0.728s/it]: train_loss_raw=0.2863, running_loss=0.3413, LR=0.000100
[2025-08-27 16:48:13,938][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085184] [Batch 02024/03080] [00:24:33/00:12:48, 0.728s/it]: train_loss_raw=0.3376, running_loss=0.3420, LR=0.000100
[2025-08-27 16:48:19,728][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085192] [Batch 02032/03080] [00:24:39/00:12:42, 0.728s/it]: train_loss_raw=0.3424, running_loss=0.3421, LR=0.000100
[2025-08-27 16:48:25,698][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085200] [Batch 02040/03080] [00:24:45/00:12:37, 0.728s/it]: train_loss_raw=0.2951, running_loss=0.3408, LR=0.000100
[2025-08-27 16:48:31,104][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085208] [Batch 02048/03080] [00:24:50/00:12:31, 0.728s/it]: train_loss_raw=0.3687, running_loss=0.3392, LR=0.000100
[2025-08-27 16:48:36,557][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085216] [Batch 02056/03080] [00:24:55/00:12:25, 0.728s/it]: train_loss_raw=0.3578, running_loss=0.3393, LR=0.000100
[2025-08-27 16:48:42,362][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085224] [Batch 02064/03080] [00:25:01/00:12:19, 0.728s/it]: train_loss_raw=0.3564, running_loss=0.3383, LR=0.000100
[2025-08-27 16:48:48,225][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085232] [Batch 02072/03080] [00:25:07/00:12:13, 0.728s/it]: train_loss_raw=0.3038, running_loss=0.3394, LR=0.000100
[2025-08-27 16:48:53,933][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085240] [Batch 02080/03080] [00:25:13/00:12:07, 0.728s/it]: train_loss_raw=0.2863, running_loss=0.3401, LR=0.000100
[2025-08-27 16:48:59,786][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085248] [Batch 02088/03080] [00:25:19/00:12:01, 0.728s/it]: train_loss_raw=0.2772, running_loss=0.3395, LR=0.000100
[2025-08-27 16:49:05,639][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085256] [Batch 02096/03080] [00:25:25/00:11:55, 0.728s/it]: train_loss_raw=0.3848, running_loss=0.3412, LR=0.000100
[2025-08-27 16:49:11,459][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085264] [Batch 02104/03080] [00:25:30/00:11:50, 0.728s/it]: train_loss_raw=0.3639, running_loss=0.3424, LR=0.000100
[2025-08-27 16:49:17,279][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085272] [Batch 02112/03080] [00:25:36/00:11:44, 0.728s/it]: train_loss_raw=0.4494, running_loss=0.3417, LR=0.000100
[2025-08-27 16:49:23,276][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085280] [Batch 02120/03080] [00:25:42/00:11:38, 0.728s/it]: train_loss_raw=0.3513, running_loss=0.3424, LR=0.000100
[2025-08-27 16:49:29,063][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085288] [Batch 02128/03080] [00:25:48/00:11:32, 0.728s/it]: train_loss_raw=0.4167, running_loss=0.3428, LR=0.000100
[2025-08-27 16:49:34,903][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085296] [Batch 02136/03080] [00:25:54/00:11:26, 0.728s/it]: train_loss_raw=0.3886, running_loss=0.3433, LR=0.000100
[2025-08-27 16:49:40,748][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085304] [Batch 02144/03080] [00:26:00/00:11:21, 0.728s/it]: train_loss_raw=0.4329, running_loss=0.3438, LR=0.000100
[2025-08-27 16:49:46,444][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085312] [Batch 02152/03080] [00:26:05/00:11:15, 0.728s/it]: train_loss_raw=0.3387, running_loss=0.3440, LR=0.000100
[2025-08-27 16:49:52,378][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085320] [Batch 02160/03080] [00:26:11/00:11:09, 0.728s/it]: train_loss_raw=0.3720, running_loss=0.3459, LR=0.000100
[2025-08-27 16:49:58,399][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085328] [Batch 02168/03080] [00:26:17/00:11:03, 0.728s/it]: train_loss_raw=0.3026, running_loss=0.3439, LR=0.000100
[2025-08-27 16:50:04,108][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085336] [Batch 02176/03080] [00:26:23/00:10:57, 0.728s/it]: train_loss_raw=0.3068, running_loss=0.3440, LR=0.000100
[2025-08-27 16:50:10,120][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085344] [Batch 02184/03080] [00:26:29/00:10:52, 0.728s/it]: train_loss_raw=0.3115, running_loss=0.3423, LR=0.000100
[2025-08-27 16:50:15,861][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085352] [Batch 02192/03080] [00:26:35/00:10:46, 0.728s/it]: train_loss_raw=0.4383, running_loss=0.3418, LR=0.000100
[2025-08-27 16:50:21,813][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085360] [Batch 02200/03080] [00:26:41/00:10:40, 0.728s/it]: train_loss_raw=0.3626, running_loss=0.3430, LR=0.000100
[2025-08-27 16:50:27,525][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085368] [Batch 02208/03080] [00:26:46/00:10:34, 0.728s/it]: train_loss_raw=0.3983, running_loss=0.3435, LR=0.000100
[2025-08-27 16:50:33,588][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085376] [Batch 02216/03080] [00:26:52/00:10:28, 0.728s/it]: train_loss_raw=0.3184, running_loss=0.3449, LR=0.000100
[2025-08-27 16:50:39,528][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085384] [Batch 02224/03080] [00:26:58/00:10:23, 0.728s/it]: train_loss_raw=0.4220, running_loss=0.3455, LR=0.000100
[2025-08-27 16:50:45,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085392] [Batch 02232/03080] [00:27:04/00:10:17, 0.728s/it]: train_loss_raw=0.2970, running_loss=0.3464, LR=0.000100
[2025-08-27 16:50:51,085][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085400] [Batch 02240/03080] [00:27:10/00:10:11, 0.728s/it]: train_loss_raw=0.3524, running_loss=0.3451, LR=0.000100
[2025-08-27 16:50:56,865][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085408] [Batch 02248/03080] [00:27:16/00:10:05, 0.728s/it]: train_loss_raw=0.3591, running_loss=0.3429, LR=0.000100
[2025-08-27 16:51:02,902][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085416] [Batch 02256/03080] [00:27:22/00:09:59, 0.728s/it]: train_loss_raw=0.2477, running_loss=0.3409, LR=0.000100
[2025-08-27 16:51:08,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085424] [Batch 02264/03080] [00:27:28/00:09:54, 0.728s/it]: train_loss_raw=0.3488, running_loss=0.3419, LR=0.000100
[2025-08-27 16:51:14,555][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085432] [Batch 02272/03080] [00:27:33/00:09:48, 0.728s/it]: train_loss_raw=0.4524, running_loss=0.3433, LR=0.000100
[2025-08-27 16:51:20,197][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085440] [Batch 02280/03080] [00:27:39/00:09:42, 0.728s/it]: train_loss_raw=0.3568, running_loss=0.3452, LR=0.000100
[2025-08-27 16:51:26,038][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085448] [Batch 02288/03080] [00:27:45/00:09:36, 0.728s/it]: train_loss_raw=0.4311, running_loss=0.3432, LR=0.000100
[2025-08-27 16:51:31,574][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085456] [Batch 02296/03080] [00:27:50/00:09:30, 0.728s/it]: train_loss_raw=0.3986, running_loss=0.3465, LR=0.000100
[2025-08-27 16:51:37,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085464] [Batch 02304/03080] [00:27:56/00:09:24, 0.728s/it]: train_loss_raw=0.2849, running_loss=0.3446, LR=0.000100
[2025-08-27 16:51:43,132][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085472] [Batch 02312/03080] [00:28:02/00:09:18, 0.728s/it]: train_loss_raw=0.3698, running_loss=0.3463, LR=0.000100
[2025-08-27 16:51:49,020][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085480] [Batch 02320/03080] [00:28:08/00:09:13, 0.728s/it]: train_loss_raw=0.3947, running_loss=0.3446, LR=0.000100
[2025-08-27 16:51:54,879][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085488] [Batch 02328/03080] [00:28:14/00:09:07, 0.728s/it]: train_loss_raw=0.3860, running_loss=0.3426, LR=0.000100
[2025-08-27 16:52:00,483][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085496] [Batch 02336/03080] [00:28:19/00:09:01, 0.728s/it]: train_loss_raw=0.2999, running_loss=0.3408, LR=0.000100
[2025-08-27 16:52:06,437][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085504] [Batch 02344/03080] [00:28:25/00:08:55, 0.728s/it]: train_loss_raw=0.3216, running_loss=0.3404, LR=0.000100
[2025-08-27 16:52:12,350][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085512] [Batch 02352/03080] [00:28:31/00:08:49, 0.728s/it]: train_loss_raw=0.3173, running_loss=0.3416, LR=0.000100
[2025-08-27 16:52:18,236][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085520] [Batch 02360/03080] [00:28:37/00:08:44, 0.728s/it]: train_loss_raw=0.2912, running_loss=0.3423, LR=0.000100
[2025-08-27 16:52:24,168][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085528] [Batch 02368/03080] [00:28:43/00:08:38, 0.728s/it]: train_loss_raw=0.2946, running_loss=0.3426, LR=0.000100
[2025-08-27 16:52:29,853][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085536] [Batch 02376/03080] [00:28:49/00:08:32, 0.728s/it]: train_loss_raw=0.3024, running_loss=0.3438, LR=0.000100
[2025-08-27 16:52:35,665][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085544] [Batch 02384/03080] [00:28:55/00:08:26, 0.728s/it]: train_loss_raw=0.3282, running_loss=0.3433, LR=0.000100
[2025-08-27 16:52:41,346][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085552] [Batch 02392/03080] [00:29:00/00:08:20, 0.728s/it]: train_loss_raw=0.3656, running_loss=0.3429, LR=0.000100
[2025-08-27 16:52:47,351][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085560] [Batch 02400/03080] [00:29:06/00:08:14, 0.728s/it]: train_loss_raw=0.3220, running_loss=0.3451, LR=0.000100
[2025-08-27 16:52:52,981][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085568] [Batch 02408/03080] [00:29:12/00:08:09, 0.728s/it]: train_loss_raw=0.2920, running_loss=0.3442, LR=0.000100
[2025-08-27 16:52:58,658][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085576] [Batch 02416/03080] [00:29:18/00:08:03, 0.728s/it]: train_loss_raw=0.3792, running_loss=0.3446, LR=0.000100
[2025-08-27 16:53:04,388][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085584] [Batch 02424/03080] [00:29:23/00:07:57, 0.728s/it]: train_loss_raw=0.3093, running_loss=0.3438, LR=0.000100
[2025-08-27 16:53:10,108][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085592] [Batch 02432/03080] [00:29:29/00:07:51, 0.728s/it]: train_loss_raw=0.3576, running_loss=0.3431, LR=0.000100
[2025-08-27 16:53:15,857][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085600] [Batch 02440/03080] [00:29:35/00:07:45, 0.728s/it]: train_loss_raw=0.3842, running_loss=0.3436, LR=0.000100
[2025-08-27 16:53:21,694][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085608] [Batch 02448/03080] [00:29:41/00:07:39, 0.728s/it]: train_loss_raw=0.3429, running_loss=0.3425, LR=0.000100
[2025-08-27 16:53:27,391][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085616] [Batch 02456/03080] [00:29:46/00:07:33, 0.728s/it]: train_loss_raw=0.3118, running_loss=0.3430, LR=0.000100
[2025-08-27 16:53:33,184][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085624] [Batch 02464/03080] [00:29:52/00:07:28, 0.728s/it]: train_loss_raw=0.3205, running_loss=0.3418, LR=0.000100
[2025-08-27 16:53:39,022][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085632] [Batch 02472/03080] [00:29:58/00:07:22, 0.728s/it]: train_loss_raw=0.3674, running_loss=0.3426, LR=0.000100
[2025-08-27 16:53:44,727][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085640] [Batch 02480/03080] [00:30:04/00:07:16, 0.727s/it]: train_loss_raw=0.2943, running_loss=0.3436, LR=0.000100
[2025-08-27 16:53:50,378][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085648] [Batch 02488/03080] [00:30:09/00:07:10, 0.727s/it]: train_loss_raw=0.3141, running_loss=0.3419, LR=0.000100
[2025-08-27 16:53:55,796][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085656] [Batch 02496/03080] [00:30:15/00:07:04, 0.727s/it]: train_loss_raw=0.2543, running_loss=0.3417, LR=0.000100
[2025-08-27 16:54:01,679][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085664] [Batch 02504/03080] [00:30:21/00:06:58, 0.727s/it]: train_loss_raw=0.2705, running_loss=0.3390, LR=0.000100
[2025-08-27 16:54:07,568][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085672] [Batch 02512/03080] [00:30:26/00:06:53, 0.727s/it]: train_loss_raw=0.3380, running_loss=0.3398, LR=0.000100
[2025-08-27 16:54:13,285][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085680] [Batch 02520/03080] [00:30:32/00:06:47, 0.727s/it]: train_loss_raw=0.3391, running_loss=0.3385, LR=0.000100
[2025-08-27 16:54:19,140][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085688] [Batch 02528/03080] [00:30:38/00:06:41, 0.727s/it]: train_loss_raw=0.4108, running_loss=0.3420, LR=0.000100
[2025-08-27 16:54:24,839][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085696] [Batch 02536/03080] [00:30:44/00:06:35, 0.727s/it]: train_loss_raw=0.3986, running_loss=0.3441, LR=0.000100
[2025-08-27 16:54:30,411][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085704] [Batch 02544/03080] [00:30:49/00:06:29, 0.727s/it]: train_loss_raw=0.4093, running_loss=0.3452, LR=0.000100
[2025-08-27 16:54:36,159][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085712] [Batch 02552/03080] [00:30:55/00:06:23, 0.727s/it]: train_loss_raw=0.2733, running_loss=0.3442, LR=0.000100
[2025-08-27 16:54:42,375][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085720] [Batch 02560/03080] [00:31:01/00:06:18, 0.727s/it]: train_loss_raw=0.4592, running_loss=0.3468, LR=0.000100
[2025-08-27 16:54:48,078][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085728] [Batch 02568/03080] [00:31:07/00:06:12, 0.727s/it]: train_loss_raw=0.2535, running_loss=0.3442, LR=0.000100
[2025-08-27 16:54:53,473][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085736] [Batch 02576/03080] [00:31:12/00:06:06, 0.727s/it]: train_loss_raw=0.3391, running_loss=0.3447, LR=0.000100
[2025-08-27 16:54:58,900][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085744] [Batch 02584/03080] [00:31:18/00:06:00, 0.727s/it]: train_loss_raw=0.3345, running_loss=0.3438, LR=0.000100
[2025-08-27 16:55:04,673][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085752] [Batch 02592/03080] [00:31:24/00:05:54, 0.727s/it]: train_loss_raw=0.3460, running_loss=0.3432, LR=0.000100
[2025-08-27 16:55:10,468][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085760] [Batch 02600/03080] [00:31:29/00:05:48, 0.727s/it]: train_loss_raw=0.2632, running_loss=0.3414, LR=0.000100
[2025-08-27 16:55:15,904][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085768] [Batch 02608/03080] [00:31:35/00:05:43, 0.727s/it]: train_loss_raw=0.2883, running_loss=0.3403, LR=0.000100
[2025-08-27 16:55:21,336][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085776] [Batch 02616/03080] [00:31:40/00:05:37, 0.727s/it]: train_loss_raw=0.3525, running_loss=0.3420, LR=0.000100
[2025-08-27 16:55:27,077][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085784] [Batch 02624/03080] [00:31:46/00:05:31, 0.727s/it]: train_loss_raw=0.3741, running_loss=0.3445, LR=0.000100
[2025-08-27 16:55:32,739][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085792] [Batch 02632/03080] [00:31:52/00:05:25, 0.726s/it]: train_loss_raw=0.3576, running_loss=0.3446, LR=0.000100
[2025-08-27 16:55:38,427][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085800] [Batch 02640/03080] [00:31:57/00:05:19, 0.726s/it]: train_loss_raw=0.3423, running_loss=0.3458, LR=0.000100
[2025-08-27 16:55:44,128][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085808] [Batch 02648/03080] [00:32:03/00:05:13, 0.726s/it]: train_loss_raw=0.3241, running_loss=0.3447, LR=0.000100
[2025-08-27 16:55:49,957][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085816] [Batch 02656/03080] [00:32:09/00:05:07, 0.726s/it]: train_loss_raw=0.2888, running_loss=0.3425, LR=0.000100
[2025-08-27 16:55:55,730][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085824] [Batch 02664/03080] [00:32:15/00:05:02, 0.726s/it]: train_loss_raw=0.3957, running_loss=0.3436, LR=0.000100
[2025-08-27 16:56:01,571][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085832] [Batch 02672/03080] [00:32:20/00:04:56, 0.726s/it]: train_loss_raw=0.3223, running_loss=0.3442, LR=0.000100
[2025-08-27 16:56:07,291][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085840] [Batch 02680/03080] [00:32:26/00:04:50, 0.726s/it]: train_loss_raw=0.4201, running_loss=0.3428, LR=0.000100
[2025-08-27 16:56:13,071][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085848] [Batch 02688/03080] [00:32:32/00:04:44, 0.726s/it]: train_loss_raw=0.3096, running_loss=0.3416, LR=0.000100
[2025-08-27 16:56:18,771][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085856] [Batch 02696/03080] [00:32:38/00:04:38, 0.726s/it]: train_loss_raw=0.3384, running_loss=0.3428, LR=0.000100
[2025-08-27 16:56:24,368][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085864] [Batch 02704/03080] [00:32:43/00:04:33, 0.726s/it]: train_loss_raw=0.3329, running_loss=0.3442, LR=0.000100
[2025-08-27 16:56:30,246][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085872] [Batch 02712/03080] [00:32:49/00:04:27, 0.726s/it]: train_loss_raw=0.3845, running_loss=0.3442, LR=0.000100
[2025-08-27 16:56:35,871][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085880] [Batch 02720/03080] [00:32:55/00:04:21, 0.726s/it]: train_loss_raw=0.3655, running_loss=0.3433, LR=0.000100
[2025-08-27 16:56:41,406][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085888] [Batch 02728/03080] [00:33:00/00:04:15, 0.726s/it]: train_loss_raw=0.3838, running_loss=0.3465, LR=0.000100
[2025-08-27 16:56:47,175][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085896] [Batch 02736/03080] [00:33:06/00:04:09, 0.726s/it]: train_loss_raw=0.4231, running_loss=0.3459, LR=0.000100
[2025-08-27 16:56:52,933][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085904] [Batch 02744/03080] [00:33:12/00:04:03, 0.726s/it]: train_loss_raw=0.4190, running_loss=0.3473, LR=0.000100
[2025-08-27 16:56:58,999][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085912] [Batch 02752/03080] [00:33:18/00:03:58, 0.726s/it]: train_loss_raw=0.3013, running_loss=0.3472, LR=0.000100
[2025-08-27 16:57:04,893][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085920] [Batch 02760/03080] [00:33:24/00:03:52, 0.726s/it]: train_loss_raw=0.3532, running_loss=0.3473, LR=0.000100
[2025-08-27 16:57:10,601][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085928] [Batch 02768/03080] [00:33:29/00:03:46, 0.726s/it]: train_loss_raw=0.4069, running_loss=0.3459, LR=0.000100
[2025-08-27 16:57:16,492][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085936] [Batch 02776/03080] [00:33:35/00:03:40, 0.726s/it]: train_loss_raw=0.4060, running_loss=0.3464, LR=0.000100
[2025-08-27 16:57:22,235][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085944] [Batch 02784/03080] [00:33:41/00:03:34, 0.726s/it]: train_loss_raw=0.3754, running_loss=0.3452, LR=0.000100
[2025-08-27 16:57:28,176][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085952] [Batch 02792/03080] [00:33:47/00:03:29, 0.726s/it]: train_loss_raw=0.3689, running_loss=0.3451, LR=0.000100
[2025-08-27 16:57:34,071][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085960] [Batch 02800/03080] [00:33:53/00:03:23, 0.726s/it]: train_loss_raw=0.2815, running_loss=0.3442, LR=0.000100
[2025-08-27 16:57:39,756][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085968] [Batch 02808/03080] [00:33:59/00:03:17, 0.726s/it]: train_loss_raw=0.3246, running_loss=0.3436, LR=0.000100
[2025-08-27 16:57:45,662][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085976] [Batch 02816/03080] [00:34:05/00:03:11, 0.726s/it]: train_loss_raw=0.3321, running_loss=0.3430, LR=0.000100
[2025-08-27 16:57:51,480][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085984] [Batch 02824/03080] [00:34:10/00:03:05, 0.726s/it]: train_loss_raw=0.3094, running_loss=0.3422, LR=0.000100
[2025-08-27 16:57:57,171][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 085992] [Batch 02832/03080] [00:34:16/00:03:00, 0.726s/it]: train_loss_raw=0.3208, running_loss=0.3425, LR=0.000100
[2025-08-27 16:58:03,021][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086000] [Batch 02840/03080] [00:34:22/00:02:54, 0.726s/it]: train_loss_raw=0.3871, running_loss=0.3428, LR=0.000100
[2025-08-27 16:58:12,617][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086008] [Batch 02848/03080] [00:34:32/00:02:48, 0.728s/it]: train_loss_raw=0.3977, running_loss=0.3420, LR=0.000100
[2025-08-27 16:58:18,357][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086016] [Batch 02856/03080] [00:34:37/00:02:42, 0.728s/it]: train_loss_raw=0.3526, running_loss=0.3432, LR=0.000100
[2025-08-27 16:58:24,114][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086024] [Batch 02864/03080] [00:34:43/00:02:37, 0.727s/it]: train_loss_raw=0.3277, running_loss=0.3411, LR=0.000100
[2025-08-27 16:58:29,683][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086032] [Batch 02872/03080] [00:34:49/00:02:31, 0.727s/it]: train_loss_raw=0.3104, running_loss=0.3413, LR=0.000100
[2025-08-27 16:58:35,298][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086040] [Batch 02880/03080] [00:34:54/00:02:25, 0.727s/it]: train_loss_raw=0.3723, running_loss=0.3449, LR=0.000100
[2025-08-27 16:58:41,162][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086048] [Batch 02888/03080] [00:35:00/00:02:19, 0.727s/it]: train_loss_raw=0.3872, running_loss=0.3436, LR=0.000100
[2025-08-27 16:58:46,933][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086056] [Batch 02896/03080] [00:35:06/00:02:13, 0.727s/it]: train_loss_raw=0.3009, running_loss=0.3416, LR=0.000100
[2025-08-27 16:58:53,008][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086064] [Batch 02904/03080] [00:35:12/00:02:08, 0.727s/it]: train_loss_raw=0.2973, running_loss=0.3418, LR=0.000100
[2025-08-27 16:58:58,800][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086072] [Batch 02912/03080] [00:35:18/00:02:02, 0.727s/it]: train_loss_raw=0.3650, running_loss=0.3397, LR=0.000100
[2025-08-27 16:59:04,268][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086080] [Batch 02920/03080] [00:35:23/00:01:56, 0.727s/it]: train_loss_raw=0.3423, running_loss=0.3411, LR=0.000100
[2025-08-27 16:59:10,134][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086088] [Batch 02928/03080] [00:35:29/00:01:50, 0.727s/it]: train_loss_raw=0.3405, running_loss=0.3402, LR=0.000100
[2025-08-27 16:59:16,069][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086096] [Batch 02936/03080] [00:35:35/00:01:44, 0.727s/it]: train_loss_raw=0.3653, running_loss=0.3383, LR=0.000100
[2025-08-27 16:59:21,634][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086104] [Batch 02944/03080] [00:35:41/00:01:38, 0.727s/it]: train_loss_raw=0.3340, running_loss=0.3386, LR=0.000100
[2025-08-27 16:59:27,151][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086112] [Batch 02952/03080] [00:35:46/00:01:33, 0.727s/it]: train_loss_raw=0.3494, running_loss=0.3390, LR=0.000100
[2025-08-27 16:59:32,911][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086120] [Batch 02960/03080] [00:35:52/00:01:27, 0.727s/it]: train_loss_raw=0.3599, running_loss=0.3394, LR=0.000100
[2025-08-27 16:59:38,893][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086128] [Batch 02968/03080] [00:35:58/00:01:21, 0.727s/it]: train_loss_raw=0.3673, running_loss=0.3409, LR=0.000100
[2025-08-27 16:59:44,712][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086136] [Batch 02976/03080] [00:36:04/00:01:15, 0.727s/it]: train_loss_raw=0.4231, running_loss=0.3426, LR=0.000100
[2025-08-27 16:59:50,587][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086144] [Batch 02984/03080] [00:36:09/00:01:09, 0.727s/it]: train_loss_raw=0.3219, running_loss=0.3417, LR=0.000100
[2025-08-27 16:59:56,498][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086152] [Batch 02992/03080] [00:36:15/00:01:03, 0.727s/it]: train_loss_raw=0.3577, running_loss=0.3407, LR=0.000100
[2025-08-27 17:00:02,398][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086160] [Batch 03000/03080] [00:36:21/00:00:58, 0.727s/it]: train_loss_raw=0.3356, running_loss=0.3386, LR=0.000100
[2025-08-27 17:00:08,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086168] [Batch 03008/03080] [00:36:27/00:00:52, 0.727s/it]: train_loss_raw=0.2952, running_loss=0.3380, LR=0.000100
[2025-08-27 17:00:14,094][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086176] [Batch 03016/03080] [00:36:33/00:00:46, 0.727s/it]: train_loss_raw=0.3938, running_loss=0.3400, LR=0.000100
[2025-08-27 17:00:19,945][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086184] [Batch 03024/03080] [00:36:39/00:00:40, 0.727s/it]: train_loss_raw=0.3202, running_loss=0.3423, LR=0.000100
[2025-08-27 17:00:25,653][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086192] [Batch 03032/03080] [00:36:45/00:00:34, 0.727s/it]: train_loss_raw=0.3639, running_loss=0.3417, LR=0.000100
[2025-08-27 17:00:31,785][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086200] [Batch 03040/03080] [00:36:51/00:00:29, 0.727s/it]: train_loss_raw=0.2787, running_loss=0.3418, LR=0.000100
[2025-08-27 17:00:37,886][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086208] [Batch 03048/03080] [00:36:57/00:00:23, 0.727s/it]: train_loss_raw=0.3792, running_loss=0.3426, LR=0.000100
[2025-08-27 17:00:43,648][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086216] [Batch 03056/03080] [00:37:03/00:00:17, 0.727s/it]: train_loss_raw=0.3496, running_loss=0.3427, LR=0.000100
[2025-08-27 17:00:49,250][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086224] [Batch 03064/03080] [00:37:08/00:00:11, 0.727s/it]: train_loss_raw=0.3556, running_loss=0.3434, LR=0.000100
[2025-08-27 17:00:55,254][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086232] [Batch 03072/03080] [00:37:14/00:00:05, 0.727s/it]: train_loss_raw=0.3186, running_loss=0.3431, LR=0.000100
[2025-08-27 17:01:05,476][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 086240] [Batch 03080/03080] [00:37:24/00:00:00, 0.729s/it]: train_loss_raw=0.3305, running_loss=0.3437, LR=0.000100
[2025-08-27 17:01:05,996][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-27 17:01:17,415][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00007/00310] [00:00:11/00:07:11, 1.427s/it]
[2025-08-27 17:01:28,622][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00015/00310] [00:00:22/00:06:55, 1.414s/it]
[2025-08-27 17:01:40,430][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00023/00310] [00:00:34/00:06:50, 1.435s/it]
[2025-08-27 17:01:51,770][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00031/00310] [00:00:45/00:06:37, 1.430s/it]
[2025-08-27 17:02:03,704][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00039/00310] [00:00:57/00:06:29, 1.443s/it]
[2025-08-27 17:02:16,277][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00047/00310] [00:01:10/00:06:23, 1.464s/it]
[2025-08-27 17:02:28,067][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00055/00310] [00:01:22/00:06:12, 1.466s/it]
[2025-08-27 17:02:39,630][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00063/00310] [00:01:33/00:05:59, 1.463s/it]
[2025-08-27 17:02:51,731][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00071/00310] [00:01:45/00:05:49, 1.469s/it]
[2025-08-27 17:03:03,906][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00079/00310] [00:01:57/00:05:38, 1.474s/it]
[2025-08-27 17:03:15,574][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00087/00310] [00:02:09/00:05:26, 1.472s/it]
[2025-08-27 17:03:27,055][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00095/00310] [00:02:21/00:05:14, 1.469s/it]
[2025-08-27 17:03:38,761][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00103/00310] [00:02:32/00:05:02, 1.469s/it]
[2025-08-27 17:03:49,953][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00111/00310] [00:02:43/00:04:49, 1.464s/it]
[2025-08-27 17:04:01,722][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00119/00310] [00:02:55/00:04:38, 1.464s/it]
[2025-08-27 17:04:13,402][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00127/00310] [00:03:07/00:04:26, 1.464s/it]
[2025-08-27 17:04:25,788][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00135/00310] [00:03:19/00:04:15, 1.469s/it]
[2025-08-27 17:04:37,244][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00143/00310] [00:03:31/00:04:03, 1.467s/it]
[2025-08-27 17:04:48,859][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00151/00310] [00:03:42/00:03:51, 1.466s/it]
[2025-08-27 17:04:59,391][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00159/00310] [00:03:53/00:03:38, 1.459s/it]
[2025-08-27 17:05:11,667][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00167/00310] [00:04:05/00:03:27, 1.462s/it]
[2025-08-27 17:05:21,555][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00175/00310] [00:04:15/00:03:14, 1.452s/it]
[2025-08-27 17:05:32,184][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00183/00310] [00:04:26/00:03:02, 1.447s/it]
[2025-08-27 17:05:44,392][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00191/00310] [00:04:38/00:02:51, 1.450s/it]
[2025-08-27 17:05:55,967][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00199/00310] [00:04:49/00:02:39, 1.450s/it]
[2025-08-27 17:06:07,063][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00207/00310] [00:05:01/00:02:27, 1.447s/it]
[2025-08-27 17:06:18,030][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00215/00310] [00:05:12/00:02:15, 1.445s/it]
[2025-08-27 17:06:29,814][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00223/00310] [00:05:23/00:02:04, 1.446s/it]
[2025-08-27 17:06:42,163][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00231/00310] [00:05:36/00:01:53, 1.449s/it]
[2025-08-27 17:06:53,397][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00239/00310] [00:05:47/00:01:41, 1.448s/it]
[2025-08-27 17:07:03,939][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00247/00310] [00:05:57/00:01:29, 1.443s/it]
[2025-08-27 17:07:16,123][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00255/00310] [00:06:10/00:01:18, 1.446s/it]
[2025-08-27 17:07:27,360][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00263/00310] [00:06:21/00:01:06, 1.445s/it]
[2025-08-27 17:07:38,790][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00271/00310] [00:06:32/00:00:54, 1.444s/it]
[2025-08-27 17:07:49,601][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00279/00310] [00:06:43/00:00:43, 1.441s/it]
[2025-08-27 17:08:01,208][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00287/00310] [00:06:55/00:00:31, 1.442s/it]
[2025-08-27 17:08:11,739][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00295/00310] [00:07:05/00:00:20, 1.438s/it]
[2025-08-27 17:08:23,278][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 086241] [Batch 00303/00310] [00:07:17/00:00:08, 1.438s/it]
[2025-08-27 17:08:32,504][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.34374, valid_loss=1.41576
[2025-08-27 17:08:32,504][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-27 17:08:32,505][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.475
[2025-08-27 17:08:32,505][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.159
[2025-08-27 17:08:32,505][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.163
[2025-08-27 17:08:32,505][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.090
[2025-08-27 17:08:32,521][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 21:41:46, remaining time 01:32:59, 00:46:29 per epoch
[2025-08-27 17:08:38,371][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086248] [Batch 00008/03080] [00:00:05/00:35:46, 0.699s/it]: train_loss_raw=0.3137, running_loss=0.2841, LR=0.000100
[2025-08-27 17:08:44,179][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086256] [Batch 00016/03080] [00:00:11/00:36:22, 0.712s/it]: train_loss_raw=0.2751, running_loss=0.2865, LR=0.000100
[2025-08-27 17:08:49,993][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086264] [Batch 00024/03080] [00:00:17/00:36:31, 0.717s/it]: train_loss_raw=0.3619, running_loss=0.2901, LR=0.000100
[2025-08-27 17:08:55,820][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086272] [Batch 00032/03080] [00:00:23/00:36:34, 0.720s/it]: train_loss_raw=0.3364, running_loss=0.2916, LR=0.000100
[2025-08-27 17:09:01,688][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086280] [Batch 00040/03080] [00:00:28/00:36:36, 0.723s/it]: train_loss_raw=0.3223, running_loss=0.2924, LR=0.000100
[2025-08-27 17:09:07,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086288] [Batch 00048/03080] [00:00:35/00:36:52, 0.730s/it]: train_loss_raw=0.3316, running_loss=0.2958, LR=0.000100
[2025-08-27 17:09:13,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086296] [Batch 00056/03080] [00:00:41/00:37:04, 0.735s/it]: train_loss_raw=0.4200, running_loss=0.2988, LR=0.000100
[2025-08-27 17:09:19,957][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086304] [Batch 00064/03080] [00:00:47/00:37:03, 0.737s/it]: train_loss_raw=0.3353, running_loss=0.3014, LR=0.000100
[2025-08-27 17:09:25,457][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086312] [Batch 00072/03080] [00:00:52/00:36:40, 0.732s/it]: train_loss_raw=0.2742, running_loss=0.2998, LR=0.000100
[2025-08-27 17:09:31,326][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086320] [Batch 00080/03080] [00:00:58/00:36:35, 0.732s/it]: train_loss_raw=0.3564, running_loss=0.3025, LR=0.000100
[2025-08-27 17:09:36,859][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086328] [Batch 00088/03080] [00:01:04/00:36:18, 0.728s/it]: train_loss_raw=0.3346, running_loss=0.3043, LR=0.000100
[2025-08-27 17:09:42,354][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086336] [Batch 00096/03080] [00:01:09/00:36:02, 0.725s/it]: train_loss_raw=0.2318, running_loss=0.3055, LR=0.000100
[2025-08-27 17:09:48,015][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086344] [Batch 00104/03080] [00:01:15/00:35:52, 0.723s/it]: train_loss_raw=0.3127, running_loss=0.3080, LR=0.000100
[2025-08-27 17:09:53,486][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086352] [Batch 00112/03080] [00:01:20/00:35:38, 0.721s/it]: train_loss_raw=0.3049, running_loss=0.3117, LR=0.000100
[2025-08-27 17:09:59,383][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086360] [Batch 00120/03080] [00:01:26/00:35:36, 0.722s/it]: train_loss_raw=0.2939, running_loss=0.3131, LR=0.000100
[2025-08-27 17:10:04,936][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086368] [Batch 00128/03080] [00:01:32/00:35:25, 0.720s/it]: train_loss_raw=0.3982, running_loss=0.3142, LR=0.000100
[2025-08-27 17:10:10,759][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086376] [Batch 00136/03080] [00:01:37/00:35:20, 0.720s/it]: train_loss_raw=0.2724, running_loss=0.3157, LR=0.000100
[2025-08-27 17:10:16,525][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086384] [Batch 00144/03080] [00:01:43/00:35:15, 0.720s/it]: train_loss_raw=0.2520, running_loss=0.3160, LR=0.000100
[2025-08-27 17:10:22,448][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086392] [Batch 00152/03080] [00:01:49/00:35:12, 0.721s/it]: train_loss_raw=0.3365, running_loss=0.3171, LR=0.000100
[2025-08-27 17:10:28,469][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086400] [Batch 00160/03080] [00:01:55/00:35:11, 0.723s/it]: train_loss_raw=0.3459, running_loss=0.3175, LR=0.000100
[2025-08-27 17:10:34,464][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086408] [Batch 00168/03080] [00:02:01/00:35:09, 0.724s/it]: train_loss_raw=0.3252, running_loss=0.3172, LR=0.000100
[2025-08-27 17:10:40,200][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086416] [Batch 00176/03080] [00:02:07/00:35:02, 0.724s/it]: train_loss_raw=0.3291, running_loss=0.3192, LR=0.000100
[2025-08-27 17:10:46,066][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086424] [Batch 00184/03080] [00:02:13/00:34:57, 0.724s/it]: train_loss_raw=0.2515, running_loss=0.3202, LR=0.000100
[2025-08-27 17:10:52,107][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086432] [Batch 00192/03080] [00:02:19/00:34:55, 0.726s/it]: train_loss_raw=0.3416, running_loss=0.3209, LR=0.000100
[2025-08-27 17:10:58,185][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086440] [Batch 00200/03080] [00:02:25/00:34:53, 0.727s/it]: train_loss_raw=0.3355, running_loss=0.3193, LR=0.000100
[2025-08-27 17:11:04,063][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086448] [Batch 00208/03080] [00:02:31/00:34:48, 0.727s/it]: train_loss_raw=0.3531, running_loss=0.3207, LR=0.000100
[2025-08-27 17:11:09,716][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086456] [Batch 00216/03080] [00:02:36/00:34:40, 0.727s/it]: train_loss_raw=0.3152, running_loss=0.3197, LR=0.000100
[2025-08-27 17:11:15,735][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086464] [Batch 00224/03080] [00:02:42/00:34:37, 0.727s/it]: train_loss_raw=0.2976, running_loss=0.3186, LR=0.000100
[2025-08-27 17:11:21,831][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086472] [Batch 00232/03080] [00:02:49/00:34:35, 0.729s/it]: train_loss_raw=0.2566, running_loss=0.3201, LR=0.000100
[2025-08-27 17:11:27,799][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086480] [Batch 00240/03080] [00:02:55/00:34:31, 0.729s/it]: train_loss_raw=0.2573, running_loss=0.3216, LR=0.000100
[2025-08-27 17:11:33,717][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086488] [Batch 00248/03080] [00:03:00/00:34:26, 0.730s/it]: train_loss_raw=0.3070, running_loss=0.3216, LR=0.000100
[2025-08-27 17:11:39,182][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086496] [Batch 00256/03080] [00:03:06/00:34:16, 0.728s/it]: train_loss_raw=0.3416, running_loss=0.3212, LR=0.000100
[2025-08-27 17:11:44,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086504] [Batch 00264/03080] [00:03:11/00:34:06, 0.727s/it]: train_loss_raw=0.3017, running_loss=0.3211, LR=0.000100
[2025-08-27 17:11:50,317][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086512] [Batch 00272/03080] [00:03:17/00:33:59, 0.726s/it]: train_loss_raw=0.2820, running_loss=0.3201, LR=0.000100
[2025-08-27 17:11:56,221][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086520] [Batch 00280/03080] [00:03:23/00:33:54, 0.727s/it]: train_loss_raw=0.3586, running_loss=0.3192, LR=0.000100
[2025-08-27 17:12:02,227][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086528] [Batch 00288/03080] [00:03:29/00:33:50, 0.727s/it]: train_loss_raw=0.2616, running_loss=0.3182, LR=0.000100
[2025-08-27 17:12:07,873][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086536] [Batch 00296/03080] [00:03:35/00:33:43, 0.727s/it]: train_loss_raw=0.3753, running_loss=0.3183, LR=0.000100
[2025-08-27 17:12:13,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086544] [Batch 00304/03080] [00:03:41/00:33:39, 0.728s/it]: train_loss_raw=0.3292, running_loss=0.3184, LR=0.000100
[2025-08-27 17:12:20,190][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086552] [Batch 00312/03080] [00:03:47/00:33:37, 0.729s/it]: train_loss_raw=0.3190, running_loss=0.3201, LR=0.000100
[2025-08-27 17:12:26,031][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086560] [Batch 00320/03080] [00:03:53/00:33:31, 0.729s/it]: train_loss_raw=0.3509, running_loss=0.3212, LR=0.000100
[2025-08-27 17:12:31,919][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086568] [Batch 00328/03080] [00:03:59/00:33:26, 0.729s/it]: train_loss_raw=0.3077, running_loss=0.3221, LR=0.000100
[2025-08-27 17:12:37,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086576] [Batch 00336/03080] [00:04:04/00:33:19, 0.729s/it]: train_loss_raw=0.3099, running_loss=0.3221, LR=0.000100
[2025-08-27 17:12:43,182][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086584] [Batch 00344/03080] [00:04:10/00:33:11, 0.728s/it]: train_loss_raw=0.3265, running_loss=0.3211, LR=0.000100
[2025-08-27 17:12:48,586][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086592] [Batch 00352/03080] [00:04:15/00:33:02, 0.727s/it]: train_loss_raw=0.3424, running_loss=0.3196, LR=0.000100
[2025-08-27 17:12:54,389][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086600] [Batch 00360/03080] [00:04:21/00:32:56, 0.727s/it]: train_loss_raw=0.3130, running_loss=0.3173, LR=0.000100
[2025-08-27 17:13:00,170][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086608] [Batch 00368/03080] [00:04:27/00:32:50, 0.727s/it]: train_loss_raw=0.3803, running_loss=0.3153, LR=0.000100
[2025-08-27 17:13:05,932][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086616] [Batch 00376/03080] [00:04:33/00:32:44, 0.726s/it]: train_loss_raw=0.3850, running_loss=0.3152, LR=0.000100
[2025-08-27 17:13:11,703][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086624] [Batch 00384/03080] [00:04:38/00:32:38, 0.726s/it]: train_loss_raw=0.2882, running_loss=0.3159, LR=0.000100
[2025-08-27 17:13:17,412][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086632] [Batch 00392/03080] [00:04:44/00:32:31, 0.726s/it]: train_loss_raw=0.2990, running_loss=0.3150, LR=0.000100
[2025-08-27 17:13:23,311][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086640] [Batch 00400/03080] [00:04:50/00:32:26, 0.726s/it]: train_loss_raw=0.2800, running_loss=0.3146, LR=0.000100
[2025-08-27 17:13:28,901][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086648] [Batch 00408/03080] [00:04:56/00:32:19, 0.726s/it]: train_loss_raw=0.3615, running_loss=0.3162, LR=0.000100
[2025-08-27 17:13:34,891][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086656] [Batch 00416/03080] [00:05:02/00:32:14, 0.726s/it]: train_loss_raw=0.3058, running_loss=0.3143, LR=0.000100
[2025-08-27 17:13:40,933][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086664] [Batch 00424/03080] [00:05:08/00:32:10, 0.727s/it]: train_loss_raw=0.3232, running_loss=0.3147, LR=0.000100
[2025-08-27 17:13:46,895][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086672] [Batch 00432/03080] [00:05:14/00:32:05, 0.727s/it]: train_loss_raw=0.3478, running_loss=0.3167, LR=0.000100
[2025-08-27 17:13:52,626][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086680] [Batch 00440/03080] [00:05:19/00:31:59, 0.727s/it]: train_loss_raw=0.4319, running_loss=0.3193, LR=0.000100
[2025-08-27 17:13:58,427][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086688] [Batch 00448/03080] [00:05:25/00:31:53, 0.727s/it]: train_loss_raw=0.3949, running_loss=0.3195, LR=0.000100
[2025-08-27 17:14:04,275][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086696] [Batch 00456/03080] [00:05:31/00:31:47, 0.727s/it]: train_loss_raw=0.3100, running_loss=0.3206, LR=0.000100
[2025-08-27 17:14:10,046][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086704] [Batch 00464/03080] [00:05:37/00:31:41, 0.727s/it]: train_loss_raw=0.2949, running_loss=0.3208, LR=0.000100
[2025-08-27 17:14:15,616][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086712] [Batch 00472/03080] [00:05:42/00:31:34, 0.726s/it]: train_loss_raw=0.3320, running_loss=0.3203, LR=0.000100
[2025-08-27 17:14:21,049][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086720] [Batch 00480/03080] [00:05:48/00:31:26, 0.726s/it]: train_loss_raw=0.3260, running_loss=0.3197, LR=0.000100
[2025-08-27 17:14:26,756][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086728] [Batch 00488/03080] [00:05:53/00:31:20, 0.725s/it]: train_loss_raw=0.3627, running_loss=0.3204, LR=0.000100
[2025-08-27 17:14:32,553][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086736] [Batch 00496/03080] [00:05:59/00:31:14, 0.725s/it]: train_loss_raw=0.3158, running_loss=0.3209, LR=0.000100
[2025-08-27 17:14:38,281][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086744] [Batch 00504/03080] [00:06:05/00:31:08, 0.725s/it]: train_loss_raw=0.3595, running_loss=0.3203, LR=0.000100
[2025-08-27 17:14:44,021][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086752] [Batch 00512/03080] [00:06:11/00:31:02, 0.725s/it]: train_loss_raw=0.3523, running_loss=0.3205, LR=0.000100
[2025-08-27 17:14:49,697][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086760] [Batch 00520/03080] [00:06:16/00:30:55, 0.725s/it]: train_loss_raw=0.3221, running_loss=0.3197, LR=0.000100
[2025-08-27 17:14:55,402][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086768] [Batch 00528/03080] [00:06:22/00:30:49, 0.725s/it]: train_loss_raw=0.2757, running_loss=0.3190, LR=0.000100
[2025-08-27 17:15:01,160][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086776] [Batch 00536/03080] [00:06:28/00:30:43, 0.725s/it]: train_loss_raw=0.3715, running_loss=0.3210, LR=0.000100
[2025-08-27 17:15:06,914][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086784] [Batch 00544/03080] [00:06:34/00:30:37, 0.725s/it]: train_loss_raw=0.3306, running_loss=0.3209, LR=0.000100
[2025-08-27 17:15:12,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086792] [Batch 00552/03080] [00:06:39/00:30:31, 0.724s/it]: train_loss_raw=0.2892, running_loss=0.3204, LR=0.000100
[2025-08-27 17:15:18,400][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086800] [Batch 00560/03080] [00:06:45/00:30:25, 0.724s/it]: train_loss_raw=0.3455, running_loss=0.3228, LR=0.000100
[2025-08-27 17:15:24,134][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086808] [Batch 00568/03080] [00:06:51/00:30:19, 0.724s/it]: train_loss_raw=0.3481, running_loss=0.3243, LR=0.000100
[2025-08-27 17:15:29,864][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086816] [Batch 00576/03080] [00:06:57/00:30:13, 0.724s/it]: train_loss_raw=0.2503, running_loss=0.3227, LR=0.000100
[2025-08-27 17:15:35,621][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086824] [Batch 00584/03080] [00:07:02/00:30:07, 0.724s/it]: train_loss_raw=0.3208, running_loss=0.3216, LR=0.000100
[2025-08-27 17:15:41,768][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086832] [Batch 00592/03080] [00:07:08/00:30:02, 0.725s/it]: train_loss_raw=0.3041, running_loss=0.3219, LR=0.000100
[2025-08-27 17:15:47,619][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086840] [Batch 00600/03080] [00:07:14/00:29:57, 0.725s/it]: train_loss_raw=0.2550, running_loss=0.3206, LR=0.000100
[2025-08-27 17:15:53,190][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086848] [Batch 00608/03080] [00:07:20/00:29:50, 0.724s/it]: train_loss_raw=0.2215, running_loss=0.3200, LR=0.000100
[2025-08-27 17:15:59,099][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086856] [Batch 00616/03080] [00:07:26/00:29:45, 0.725s/it]: train_loss_raw=0.3851, running_loss=0.3210, LR=0.000100
[2025-08-27 17:16:04,796][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086864] [Batch 00624/03080] [00:07:32/00:29:39, 0.724s/it]: train_loss_raw=0.3198, running_loss=0.3228, LR=0.000100
[2025-08-27 17:16:10,324][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086872] [Batch 00632/03080] [00:07:37/00:29:32, 0.724s/it]: train_loss_raw=0.2596, running_loss=0.3226, LR=0.000100
[2025-08-27 17:16:15,763][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086880] [Batch 00640/03080] [00:07:42/00:29:25, 0.723s/it]: train_loss_raw=0.3234, running_loss=0.3222, LR=0.000100
[2025-08-27 17:16:21,308][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086888] [Batch 00648/03080] [00:07:48/00:29:18, 0.723s/it]: train_loss_raw=0.3444, running_loss=0.3234, LR=0.000100
[2025-08-27 17:16:27,224][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086896] [Batch 00656/03080] [00:07:54/00:29:13, 0.723s/it]: train_loss_raw=0.4022, running_loss=0.3250, LR=0.000100
[2025-08-27 17:16:32,608][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086904] [Batch 00664/03080] [00:07:59/00:29:05, 0.723s/it]: train_loss_raw=0.3203, running_loss=0.3245, LR=0.000100
[2025-08-27 17:16:38,043][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086912] [Batch 00672/03080] [00:08:05/00:28:58, 0.722s/it]: train_loss_raw=0.3093, running_loss=0.3249, LR=0.000100
[2025-08-27 17:16:43,603][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086920] [Batch 00680/03080] [00:08:10/00:28:52, 0.722s/it]: train_loss_raw=0.2845, running_loss=0.3225, LR=0.000100
[2025-08-27 17:16:49,657][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086928] [Batch 00688/03080] [00:08:16/00:28:47, 0.722s/it]: train_loss_raw=0.2961, running_loss=0.3233, LR=0.000100
[2025-08-27 17:16:55,123][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086936] [Batch 00696/03080] [00:08:22/00:28:40, 0.722s/it]: train_loss_raw=0.3714, running_loss=0.3226, LR=0.000100
[2025-08-27 17:17:00,525][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086944] [Batch 00704/03080] [00:08:27/00:28:33, 0.721s/it]: train_loss_raw=0.3015, running_loss=0.3222, LR=0.000100
[2025-08-27 17:17:06,613][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086952] [Batch 00712/03080] [00:08:33/00:28:28, 0.722s/it]: train_loss_raw=0.2474, running_loss=0.3218, LR=0.000100
[2025-08-27 17:17:12,408][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086960] [Batch 00720/03080] [00:08:39/00:28:23, 0.722s/it]: train_loss_raw=0.3521, running_loss=0.3218, LR=0.000100
[2025-08-27 17:17:18,428][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086968] [Batch 00728/03080] [00:08:45/00:28:18, 0.722s/it]: train_loss_raw=0.2760, running_loss=0.3206, LR=0.000100
[2025-08-27 17:17:24,488][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086976] [Batch 00736/03080] [00:08:51/00:28:13, 0.722s/it]: train_loss_raw=0.3093, running_loss=0.3212, LR=0.000100
[2025-08-27 17:17:30,793][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086984] [Batch 00744/03080] [00:08:58/00:28:09, 0.723s/it]: train_loss_raw=0.3049, running_loss=0.3224, LR=0.000100
[2025-08-27 17:17:36,572][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 086992] [Batch 00752/03080] [00:09:03/00:28:03, 0.723s/it]: train_loss_raw=0.2917, running_loss=0.3249, LR=0.000100
[2025-08-27 17:17:42,334][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087000] [Batch 00760/03080] [00:09:09/00:27:57, 0.723s/it]: train_loss_raw=0.3677, running_loss=0.3258, LR=0.000100
[2025-08-27 17:17:48,462][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087008] [Batch 00768/03080] [00:09:15/00:27:52, 0.724s/it]: train_loss_raw=0.3630, running_loss=0.3254, LR=0.000100
[2025-08-27 17:17:54,475][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087016] [Batch 00776/03080] [00:09:21/00:27:47, 0.724s/it]: train_loss_raw=0.3248, running_loss=0.3257, LR=0.000100
[2025-08-27 17:18:00,446][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087024] [Batch 00784/03080] [00:09:27/00:27:42, 0.724s/it]: train_loss_raw=0.3628, running_loss=0.3275, LR=0.000100
[2025-08-27 17:18:06,037][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087032] [Batch 00792/03080] [00:09:33/00:27:36, 0.724s/it]: train_loss_raw=0.3021, running_loss=0.3255, LR=0.000100
[2025-08-27 17:18:12,117][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087040] [Batch 00800/03080] [00:09:39/00:27:31, 0.724s/it]: train_loss_raw=0.3246, running_loss=0.3251, LR=0.000100
[2025-08-27 17:18:17,805][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087048] [Batch 00808/03080] [00:09:45/00:27:25, 0.724s/it]: train_loss_raw=0.3244, running_loss=0.3239, LR=0.000100
[2025-08-27 17:18:23,594][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087056] [Batch 00816/03080] [00:09:50/00:27:19, 0.724s/it]: train_loss_raw=0.3009, running_loss=0.3239, LR=0.000100
[2025-08-27 17:18:28,975][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087064] [Batch 00824/03080] [00:09:56/00:27:12, 0.724s/it]: train_loss_raw=0.3473, running_loss=0.3244, LR=0.000100
[2025-08-27 17:18:34,608][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087072] [Batch 00832/03080] [00:10:01/00:27:06, 0.723s/it]: train_loss_raw=0.2752, running_loss=0.3241, LR=0.000100
[2025-08-27 17:18:40,058][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087080] [Batch 00840/03080] [00:10:07/00:26:59, 0.723s/it]: train_loss_raw=0.4447, running_loss=0.3238, LR=0.000100
[2025-08-27 17:18:45,669][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087088] [Batch 00848/03080] [00:10:12/00:26:53, 0.723s/it]: train_loss_raw=0.2968, running_loss=0.3256, LR=0.000100
[2025-08-27 17:18:51,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087096] [Batch 00856/03080] [00:10:18/00:26:46, 0.723s/it]: train_loss_raw=0.3547, running_loss=0.3266, LR=0.000100
[2025-08-27 17:18:56,659][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087104] [Batch 00864/03080] [00:10:23/00:26:40, 0.722s/it]: train_loss_raw=0.2810, running_loss=0.3271, LR=0.000100
[2025-08-27 17:19:02,170][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087112] [Batch 00872/03080] [00:10:29/00:26:33, 0.722s/it]: train_loss_raw=0.3444, running_loss=0.3295, LR=0.000100
[2025-08-27 17:19:07,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087120] [Batch 00880/03080] [00:10:35/00:26:27, 0.722s/it]: train_loss_raw=0.3034, running_loss=0.3299, LR=0.000100
[2025-08-27 17:19:14,046][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087128] [Batch 00888/03080] [00:10:41/00:26:22, 0.722s/it]: train_loss_raw=0.3384, running_loss=0.3273, LR=0.000100
[2025-08-27 17:19:20,027][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087136] [Batch 00896/03080] [00:10:47/00:26:17, 0.722s/it]: train_loss_raw=0.2757, running_loss=0.3281, LR=0.000100
[2025-08-27 17:19:25,903][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087144] [Batch 00904/03080] [00:10:53/00:26:12, 0.722s/it]: train_loss_raw=0.4037, running_loss=0.3301, LR=0.000100
[2025-08-27 17:19:31,288][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087152] [Batch 00912/03080] [00:10:58/00:26:05, 0.722s/it]: train_loss_raw=0.3159, running_loss=0.3292, LR=0.000100
[2025-08-27 17:19:36,666][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087160] [Batch 00920/03080] [00:11:03/00:25:58, 0.722s/it]: train_loss_raw=0.2926, running_loss=0.3284, LR=0.000100
[2025-08-27 17:19:42,479][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087168] [Batch 00928/03080] [00:11:09/00:25:53, 0.722s/it]: train_loss_raw=0.2984, running_loss=0.3270, LR=0.000100
[2025-08-27 17:19:48,031][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087176] [Batch 00936/03080] [00:11:15/00:25:46, 0.721s/it]: train_loss_raw=0.3180, running_loss=0.3262, LR=0.000100
[2025-08-27 17:19:53,860][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087184] [Batch 00944/03080] [00:11:21/00:25:41, 0.721s/it]: train_loss_raw=0.3432, running_loss=0.3255, LR=0.000100
[2025-08-27 17:19:59,559][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087192] [Batch 00952/03080] [00:11:26/00:25:35, 0.721s/it]: train_loss_raw=0.3455, running_loss=0.3240, LR=0.000100
[2025-08-27 17:20:05,362][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087200] [Batch 00960/03080] [00:11:32/00:25:29, 0.721s/it]: train_loss_raw=0.3209, running_loss=0.3241, LR=0.000100
[2025-08-27 17:20:10,979][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087208] [Batch 00968/03080] [00:11:38/00:25:23, 0.721s/it]: train_loss_raw=0.3046, running_loss=0.3231, LR=0.000100
[2025-08-27 17:20:16,374][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087216] [Batch 00976/03080] [00:11:43/00:25:16, 0.721s/it]: train_loss_raw=0.2489, running_loss=0.3211, LR=0.000100
[2025-08-27 17:20:21,954][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087224] [Batch 00984/03080] [00:11:49/00:25:10, 0.721s/it]: train_loss_raw=0.3193, running_loss=0.3224, LR=0.000100
[2025-08-27 17:20:27,808][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087232] [Batch 00992/03080] [00:11:55/00:25:05, 0.721s/it]: train_loss_raw=0.3167, running_loss=0.3226, LR=0.000100
[2025-08-27 17:20:33,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087240] [Batch 01000/03080] [00:12:00/00:24:59, 0.721s/it]: train_loss_raw=0.3080, running_loss=0.3219, LR=0.000100
[2025-08-27 17:20:39,257][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087248] [Batch 01008/03080] [00:12:06/00:24:53, 0.721s/it]: train_loss_raw=0.3596, running_loss=0.3224, LR=0.000100
[2025-08-27 17:20:44,991][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087256] [Batch 01016/03080] [00:12:12/00:24:47, 0.721s/it]: train_loss_raw=0.2538, running_loss=0.3223, LR=0.000100
[2025-08-27 17:20:50,378][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087264] [Batch 01024/03080] [00:12:17/00:24:40, 0.720s/it]: train_loss_raw=0.4354, running_loss=0.3203, LR=0.000100
[2025-08-27 17:20:55,767][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087272] [Batch 01032/03080] [00:12:22/00:24:34, 0.720s/it]: train_loss_raw=0.3143, running_loss=0.3208, LR=0.000100
[2025-08-27 17:21:01,388][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087280] [Batch 01040/03080] [00:12:28/00:24:28, 0.720s/it]: train_loss_raw=0.2851, running_loss=0.3204, LR=0.000100
[2025-08-27 17:21:07,186][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087288] [Batch 01048/03080] [00:12:34/00:24:22, 0.720s/it]: train_loss_raw=0.3914, running_loss=0.3219, LR=0.000100
[2025-08-27 17:21:12,957][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087296] [Batch 01056/03080] [00:12:40/00:24:17, 0.720s/it]: train_loss_raw=0.3110, running_loss=0.3213, LR=0.000100
[2025-08-27 17:21:19,070][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087304] [Batch 01064/03080] [00:12:46/00:24:11, 0.720s/it]: train_loss_raw=0.3394, running_loss=0.3226, LR=0.000100
[2025-08-27 17:21:24,580][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087312] [Batch 01072/03080] [00:12:51/00:24:05, 0.720s/it]: train_loss_raw=0.3023, running_loss=0.3216, LR=0.000100
[2025-08-27 17:21:30,119][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087320] [Batch 01080/03080] [00:12:57/00:23:59, 0.720s/it]: train_loss_raw=0.3354, running_loss=0.3213, LR=0.000100
[2025-08-27 17:21:36,086][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087328] [Batch 01088/03080] [00:13:03/00:23:54, 0.720s/it]: train_loss_raw=0.2822, running_loss=0.3200, LR=0.000100
[2025-08-27 17:21:41,441][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087336] [Batch 01096/03080] [00:13:08/00:23:47, 0.720s/it]: train_loss_raw=0.3258, running_loss=0.3211, LR=0.000100
[2025-08-27 17:21:47,274][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087344] [Batch 01104/03080] [00:13:14/00:23:42, 0.720s/it]: train_loss_raw=0.2950, running_loss=0.3199, LR=0.000100
[2025-08-27 17:21:52,913][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087352] [Batch 01112/03080] [00:13:20/00:23:36, 0.720s/it]: train_loss_raw=0.3304, running_loss=0.3203, LR=0.000100
[2025-08-27 17:21:58,806][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087360] [Batch 01120/03080] [00:13:26/00:23:30, 0.720s/it]: train_loss_raw=0.3293, running_loss=0.3205, LR=0.000100
[2025-08-27 17:22:04,760][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087368] [Batch 01128/03080] [00:13:31/00:23:25, 0.720s/it]: train_loss_raw=0.2432, running_loss=0.3196, LR=0.000100
[2025-08-27 17:22:10,866][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087376] [Batch 01136/03080] [00:13:38/00:23:19, 0.720s/it]: train_loss_raw=0.3080, running_loss=0.3199, LR=0.000100
[2025-08-27 17:22:17,057][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087384] [Batch 01144/03080] [00:13:44/00:23:14, 0.721s/it]: train_loss_raw=0.3095, running_loss=0.3187, LR=0.000100
[2025-08-27 17:22:23,000][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087392] [Batch 01152/03080] [00:13:50/00:23:09, 0.721s/it]: train_loss_raw=0.3632, running_loss=0.3204, LR=0.000100
[2025-08-27 17:22:28,906][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087400] [Batch 01160/03080] [00:13:56/00:23:03, 0.721s/it]: train_loss_raw=0.2980, running_loss=0.3212, LR=0.000100
[2025-08-27 17:22:34,624][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087408] [Batch 01168/03080] [00:14:01/00:22:58, 0.721s/it]: train_loss_raw=0.3091, running_loss=0.3215, LR=0.000100
[2025-08-27 17:22:40,417][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087416] [Batch 01176/03080] [00:14:07/00:22:52, 0.721s/it]: train_loss_raw=0.2585, running_loss=0.3195, LR=0.000100
[2025-08-27 17:22:46,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087424] [Batch 01184/03080] [00:14:13/00:22:46, 0.721s/it]: train_loss_raw=0.3738, running_loss=0.3208, LR=0.000100
[2025-08-27 17:22:52,420][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087432] [Batch 01192/03080] [00:14:19/00:22:41, 0.721s/it]: train_loss_raw=0.3832, running_loss=0.3215, LR=0.000100
[2025-08-27 17:22:58,413][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087440] [Batch 01200/03080] [00:14:25/00:22:36, 0.721s/it]: train_loss_raw=0.3143, running_loss=0.3218, LR=0.000100
[2025-08-27 17:23:04,277][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087448] [Batch 01208/03080] [00:14:31/00:22:30, 0.721s/it]: train_loss_raw=0.2696, running_loss=0.3218, LR=0.000100
[2025-08-27 17:23:10,052][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087456] [Batch 01216/03080] [00:14:37/00:22:24, 0.721s/it]: train_loss_raw=0.3318, running_loss=0.3210, LR=0.000100
[2025-08-27 17:23:15,730][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087464] [Batch 01224/03080] [00:14:42/00:22:18, 0.721s/it]: train_loss_raw=0.3559, running_loss=0.3199, LR=0.000100
[2025-08-27 17:23:21,378][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087472] [Batch 01232/03080] [00:14:48/00:22:12, 0.721s/it]: train_loss_raw=0.3447, running_loss=0.3204, LR=0.000100
[2025-08-27 17:23:27,370][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087480] [Batch 01240/03080] [00:14:54/00:22:07, 0.721s/it]: train_loss_raw=0.3529, running_loss=0.3205, LR=0.000100
[2025-08-27 17:23:33,028][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087488] [Batch 01248/03080] [00:15:00/00:22:01, 0.721s/it]: train_loss_raw=0.3205, running_loss=0.3206, LR=0.000100
[2025-08-27 17:23:38,460][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087496] [Batch 01256/03080] [00:15:05/00:21:55, 0.721s/it]: train_loss_raw=0.2782, running_loss=0.3202, LR=0.000100
[2025-08-27 17:23:44,136][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087504] [Batch 01264/03080] [00:15:11/00:21:49, 0.721s/it]: train_loss_raw=0.3136, running_loss=0.3183, LR=0.000100
[2025-08-27 17:23:49,934][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087512] [Batch 01272/03080] [00:15:17/00:21:43, 0.721s/it]: train_loss_raw=0.3422, running_loss=0.3189, LR=0.000100
[2025-08-27 17:23:56,055][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087520] [Batch 01280/03080] [00:15:23/00:21:38, 0.721s/it]: train_loss_raw=0.3711, running_loss=0.3185, LR=0.000100
[2025-08-27 17:24:01,707][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087528] [Batch 01288/03080] [00:15:28/00:21:32, 0.721s/it]: train_loss_raw=0.3020, running_loss=0.3172, LR=0.000100
[2025-08-27 17:24:07,448][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087536] [Batch 01296/03080] [00:15:34/00:21:26, 0.721s/it]: train_loss_raw=0.4134, running_loss=0.3196, LR=0.000100
[2025-08-27 17:24:12,818][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087544] [Batch 01304/03080] [00:15:40/00:21:20, 0.721s/it]: train_loss_raw=0.3780, running_loss=0.3203, LR=0.000100
[2025-08-27 17:24:18,599][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087552] [Batch 01312/03080] [00:15:45/00:21:14, 0.721s/it]: train_loss_raw=0.3593, running_loss=0.3205, LR=0.000100
[2025-08-27 17:24:24,360][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087560] [Batch 01320/03080] [00:15:51/00:21:08, 0.721s/it]: train_loss_raw=0.2992, running_loss=0.3199, LR=0.000100
[2025-08-27 17:24:30,231][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087568] [Batch 01328/03080] [00:15:57/00:21:03, 0.721s/it]: train_loss_raw=0.2753, running_loss=0.3188, LR=0.000100
[2025-08-27 17:24:35,866][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087576] [Batch 01336/03080] [00:16:03/00:20:57, 0.721s/it]: train_loss_raw=0.2873, running_loss=0.3189, LR=0.000100
[2025-08-27 17:24:41,576][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087584] [Batch 01344/03080] [00:16:08/00:20:51, 0.721s/it]: train_loss_raw=0.3506, running_loss=0.3188, LR=0.000100
[2025-08-27 17:24:47,580][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087592] [Batch 01352/03080] [00:16:14/00:20:45, 0.721s/it]: train_loss_raw=0.3491, running_loss=0.3191, LR=0.000100
[2025-08-27 17:24:53,410][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087600] [Batch 01360/03080] [00:16:20/00:20:40, 0.721s/it]: train_loss_raw=0.3373, running_loss=0.3199, LR=0.000100
[2025-08-27 17:24:59,341][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087608] [Batch 01368/03080] [00:16:26/00:20:34, 0.721s/it]: train_loss_raw=0.3403, running_loss=0.3206, LR=0.000100
[2025-08-27 17:25:05,452][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087616] [Batch 01376/03080] [00:16:32/00:20:29, 0.721s/it]: train_loss_raw=0.3438, running_loss=0.3210, LR=0.000100
[2025-08-27 17:25:10,958][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087624] [Batch 01384/03080] [00:16:38/00:20:23, 0.721s/it]: train_loss_raw=0.3170, running_loss=0.3208, LR=0.000100
[2025-08-27 17:25:16,955][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087632] [Batch 01392/03080] [00:16:44/00:20:17, 0.721s/it]: train_loss_raw=0.3127, running_loss=0.3213, LR=0.000100
[2025-08-27 17:25:22,977][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087640] [Batch 01400/03080] [00:16:50/00:20:12, 0.722s/it]: train_loss_raw=0.3494, running_loss=0.3222, LR=0.000100
[2025-08-27 17:25:28,736][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087648] [Batch 01408/03080] [00:16:55/00:20:06, 0.722s/it]: train_loss_raw=0.2881, running_loss=0.3217, LR=0.000100
[2025-08-27 17:25:34,657][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087656] [Batch 01416/03080] [00:17:01/00:20:00, 0.722s/it]: train_loss_raw=0.4022, running_loss=0.3219, LR=0.000100
[2025-08-27 17:25:40,466][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087664] [Batch 01424/03080] [00:17:07/00:19:55, 0.722s/it]: train_loss_raw=0.3237, running_loss=0.3219, LR=0.000100
[2025-08-27 17:25:46,512][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087672] [Batch 01432/03080] [00:17:13/00:19:49, 0.722s/it]: train_loss_raw=0.3364, running_loss=0.3226, LR=0.000100
[2025-08-27 17:25:52,521][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087680] [Batch 01440/03080] [00:17:19/00:19:44, 0.722s/it]: train_loss_raw=0.3757, running_loss=0.3213, LR=0.000100
[2025-08-27 17:25:58,222][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087688] [Batch 01448/03080] [00:17:25/00:19:38, 0.722s/it]: train_loss_raw=0.3691, running_loss=0.3228, LR=0.000100
[2025-08-27 17:26:04,143][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087696] [Batch 01456/03080] [00:17:31/00:19:32, 0.722s/it]: train_loss_raw=0.3505, running_loss=0.3221, LR=0.000100
[2025-08-27 17:26:09,830][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087704] [Batch 01464/03080] [00:17:37/00:19:26, 0.722s/it]: train_loss_raw=0.3276, running_loss=0.3222, LR=0.000100
[2025-08-27 17:26:15,884][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087712] [Batch 01472/03080] [00:17:43/00:19:21, 0.722s/it]: train_loss_raw=0.3931, running_loss=0.3236, LR=0.000100
[2025-08-27 17:26:21,641][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087720] [Batch 01480/03080] [00:17:48/00:19:15, 0.722s/it]: train_loss_raw=0.4421, running_loss=0.3236, LR=0.000100
[2025-08-27 17:26:27,591][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087728] [Batch 01488/03080] [00:17:54/00:19:09, 0.722s/it]: train_loss_raw=0.3468, running_loss=0.3238, LR=0.000100
[2025-08-27 17:26:33,611][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087736] [Batch 01496/03080] [00:18:00/00:19:04, 0.722s/it]: train_loss_raw=0.3666, running_loss=0.3242, LR=0.000100
[2025-08-27 17:26:39,359][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087744] [Batch 01504/03080] [00:18:06/00:18:58, 0.722s/it]: train_loss_raw=0.3540, running_loss=0.3234, LR=0.000100
[2025-08-27 17:26:44,740][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087752] [Batch 01512/03080] [00:18:11/00:18:52, 0.722s/it]: train_loss_raw=0.3070, running_loss=0.3241, LR=0.000100
[2025-08-27 17:26:50,377][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087760] [Batch 01520/03080] [00:18:17/00:18:46, 0.722s/it]: train_loss_raw=0.3165, running_loss=0.3255, LR=0.000100
[2025-08-27 17:26:56,086][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087768] [Batch 01528/03080] [00:18:23/00:18:40, 0.722s/it]: train_loss_raw=0.3570, running_loss=0.3254, LR=0.000100
[2025-08-27 17:27:01,652][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087776] [Batch 01536/03080] [00:18:28/00:18:34, 0.722s/it]: train_loss_raw=0.3359, running_loss=0.3253, LR=0.000100
[2025-08-27 17:27:07,025][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087784] [Batch 01544/03080] [00:18:34/00:18:28, 0.722s/it]: train_loss_raw=0.3534, running_loss=0.3247, LR=0.000100
[2025-08-27 17:27:12,410][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087792] [Batch 01552/03080] [00:18:39/00:18:22, 0.721s/it]: train_loss_raw=0.3316, running_loss=0.3247, LR=0.000100
[2025-08-27 17:27:18,163][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087800] [Batch 01560/03080] [00:18:45/00:18:16, 0.721s/it]: train_loss_raw=0.2603, running_loss=0.3222, LR=0.000100
[2025-08-27 17:27:23,637][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087808] [Batch 01568/03080] [00:18:50/00:18:10, 0.721s/it]: train_loss_raw=0.2915, running_loss=0.3231, LR=0.000100
[2025-08-27 17:27:29,107][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087816] [Batch 01576/03080] [00:18:56/00:18:04, 0.721s/it]: train_loss_raw=0.2948, running_loss=0.3228, LR=0.000100
[2025-08-27 17:27:34,983][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087824] [Batch 01584/03080] [00:19:02/00:17:58, 0.721s/it]: train_loss_raw=0.3023, running_loss=0.3229, LR=0.000100
[2025-08-27 17:27:40,922][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087832] [Batch 01592/03080] [00:19:08/00:17:53, 0.721s/it]: train_loss_raw=0.2377, running_loss=0.3222, LR=0.000100
[2025-08-27 17:27:46,555][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087840] [Batch 01600/03080] [00:19:13/00:17:47, 0.721s/it]: train_loss_raw=0.2925, running_loss=0.3217, LR=0.000100
[2025-08-27 17:27:52,094][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087848] [Batch 01608/03080] [00:19:19/00:17:41, 0.721s/it]: train_loss_raw=0.3676, running_loss=0.3201, LR=0.000100
[2025-08-27 17:27:57,696][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087856] [Batch 01616/03080] [00:19:24/00:17:35, 0.721s/it]: train_loss_raw=0.3781, running_loss=0.3201, LR=0.000100
[2025-08-27 17:28:03,825][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087864] [Batch 01624/03080] [00:19:31/00:17:29, 0.721s/it]: train_loss_raw=0.3660, running_loss=0.3211, LR=0.000100
[2025-08-27 17:28:09,492][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087872] [Batch 01632/03080] [00:19:36/00:17:24, 0.721s/it]: train_loss_raw=0.3569, running_loss=0.3219, LR=0.000100
[2025-08-27 17:28:15,187][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087880] [Batch 01640/03080] [00:19:42/00:17:18, 0.721s/it]: train_loss_raw=0.3544, running_loss=0.3219, LR=0.000100
[2025-08-27 17:28:20,889][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087888] [Batch 01648/03080] [00:19:48/00:17:12, 0.721s/it]: train_loss_raw=0.2706, running_loss=0.3204, LR=0.000100
[2025-08-27 17:28:26,616][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087896] [Batch 01656/03080] [00:19:53/00:17:06, 0.721s/it]: train_loss_raw=0.4236, running_loss=0.3221, LR=0.000100
[2025-08-27 17:28:32,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087904] [Batch 01664/03080] [00:19:59/00:17:00, 0.721s/it]: train_loss_raw=0.3141, running_loss=0.3241, LR=0.000100
[2025-08-27 17:28:38,336][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087912] [Batch 01672/03080] [00:20:05/00:16:55, 0.721s/it]: train_loss_raw=0.2752, running_loss=0.3247, LR=0.000100
[2025-08-27 17:28:44,120][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087920] [Batch 01680/03080] [00:20:11/00:16:49, 0.721s/it]: train_loss_raw=0.2744, running_loss=0.3224, LR=0.000100
[2025-08-27 17:28:50,165][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087928] [Batch 01688/03080] [00:20:17/00:16:43, 0.721s/it]: train_loss_raw=0.3034, running_loss=0.3223, LR=0.000100
[2025-08-27 17:28:56,293][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087936] [Batch 01696/03080] [00:20:23/00:16:38, 0.721s/it]: train_loss_raw=0.2923, running_loss=0.3217, LR=0.000100
[2025-08-27 17:29:02,178][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087944] [Batch 01704/03080] [00:20:29/00:16:32, 0.721s/it]: train_loss_raw=0.3080, running_loss=0.3213, LR=0.000100
[2025-08-27 17:29:08,356][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087952] [Batch 01712/03080] [00:20:35/00:16:27, 0.722s/it]: train_loss_raw=0.2693, running_loss=0.3201, LR=0.000100
[2025-08-27 17:29:14,360][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087960] [Batch 01720/03080] [00:20:41/00:16:21, 0.722s/it]: train_loss_raw=0.3951, running_loss=0.3220, LR=0.000100
[2025-08-27 17:29:20,209][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087968] [Batch 01728/03080] [00:20:47/00:16:15, 0.722s/it]: train_loss_raw=0.3397, running_loss=0.3211, LR=0.000100
[2025-08-27 17:29:25,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087976] [Batch 01736/03080] [00:20:52/00:16:10, 0.722s/it]: train_loss_raw=0.3498, running_loss=0.3218, LR=0.000100
[2025-08-27 17:29:31,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087984] [Batch 01744/03080] [00:20:58/00:16:04, 0.722s/it]: train_loss_raw=0.3264, running_loss=0.3207, LR=0.000100
[2025-08-27 17:29:36,902][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 087992] [Batch 01752/03080] [00:21:04/00:15:58, 0.722s/it]: train_loss_raw=0.2941, running_loss=0.3202, LR=0.000100
[2025-08-27 17:29:42,646][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088000] [Batch 01760/03080] [00:21:09/00:15:52, 0.722s/it]: train_loss_raw=0.3842, running_loss=0.3192, LR=0.000100
[2025-08-27 17:29:52,198][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088008] [Batch 01768/03080] [00:21:19/00:15:49, 0.724s/it]: train_loss_raw=0.4024, running_loss=0.3201, LR=0.000100
[2025-08-27 17:29:58,050][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088016] [Batch 01776/03080] [00:21:25/00:15:43, 0.724s/it]: train_loss_raw=0.3815, running_loss=0.3211, LR=0.000100
[2025-08-27 17:30:04,029][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088024] [Batch 01784/03080] [00:21:31/00:15:38, 0.724s/it]: train_loss_raw=0.3498, running_loss=0.3216, LR=0.000100
[2025-08-27 17:30:09,489][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088032] [Batch 01792/03080] [00:21:36/00:15:32, 0.724s/it]: train_loss_raw=0.3033, running_loss=0.3208, LR=0.000100
[2025-08-27 17:30:15,414][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088040] [Batch 01800/03080] [00:21:42/00:15:26, 0.724s/it]: train_loss_raw=0.2974, running_loss=0.3203, LR=0.000100
[2025-08-27 17:30:21,324][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088048] [Batch 01808/03080] [00:21:48/00:15:20, 0.724s/it]: train_loss_raw=0.2702, running_loss=0.3198, LR=0.000100
[2025-08-27 17:30:27,282][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088056] [Batch 01816/03080] [00:21:54/00:15:14, 0.724s/it]: train_loss_raw=0.3106, running_loss=0.3210, LR=0.000100
[2025-08-27 17:30:32,991][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088064] [Batch 01824/03080] [00:22:00/00:15:09, 0.724s/it]: train_loss_raw=0.2972, running_loss=0.3208, LR=0.000100
[2025-08-27 17:30:38,634][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088072] [Batch 01832/03080] [00:22:05/00:15:03, 0.724s/it]: train_loss_raw=0.3178, running_loss=0.3212, LR=0.000100
[2025-08-27 17:30:44,600][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088080] [Batch 01840/03080] [00:22:11/00:14:57, 0.724s/it]: train_loss_raw=0.3539, running_loss=0.3206, LR=0.000100
[2025-08-27 17:30:50,619][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088088] [Batch 01848/03080] [00:22:17/00:14:51, 0.724s/it]: train_loss_raw=0.3449, running_loss=0.3200, LR=0.000100
[2025-08-27 17:30:56,533][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088096] [Batch 01856/03080] [00:22:23/00:14:46, 0.724s/it]: train_loss_raw=0.2657, running_loss=0.3195, LR=0.000100
[2025-08-27 17:31:02,251][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088104] [Batch 01864/03080] [00:22:29/00:14:40, 0.724s/it]: train_loss_raw=0.3161, running_loss=0.3190, LR=0.000100
[2025-08-27 17:31:08,302][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088112] [Batch 01872/03080] [00:22:35/00:14:34, 0.724s/it]: train_loss_raw=0.3080, running_loss=0.3184, LR=0.000100
[2025-08-27 17:31:13,898][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088120] [Batch 01880/03080] [00:22:41/00:14:28, 0.724s/it]: train_loss_raw=0.2854, running_loss=0.3186, LR=0.000100
[2025-08-27 17:31:19,527][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088128] [Batch 01888/03080] [00:22:46/00:14:22, 0.724s/it]: train_loss_raw=0.3466, running_loss=0.3188, LR=0.000100
[2025-08-27 17:31:25,229][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088136] [Batch 01896/03080] [00:22:52/00:14:17, 0.724s/it]: train_loss_raw=0.3812, running_loss=0.3193, LR=0.000100
[2025-08-27 17:31:30,641][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088144] [Batch 01904/03080] [00:22:57/00:14:11, 0.724s/it]: train_loss_raw=0.2476, running_loss=0.3183, LR=0.000100
[2025-08-27 17:31:36,534][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088152] [Batch 01912/03080] [00:23:03/00:14:05, 0.724s/it]: train_loss_raw=0.4363, running_loss=0.3198, LR=0.000100
[2025-08-27 17:31:42,148][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088160] [Batch 01920/03080] [00:23:09/00:13:59, 0.724s/it]: train_loss_raw=0.3616, running_loss=0.3204, LR=0.000100
[2025-08-27 17:31:47,970][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088168] [Batch 01928/03080] [00:23:15/00:13:53, 0.724s/it]: train_loss_raw=0.3960, running_loss=0.3205, LR=0.000100
[2025-08-27 17:31:53,768][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088176] [Batch 01936/03080] [00:23:20/00:13:47, 0.724s/it]: train_loss_raw=0.4150, running_loss=0.3215, LR=0.000100
[2025-08-27 17:31:59,319][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088184] [Batch 01944/03080] [00:23:26/00:13:41, 0.724s/it]: train_loss_raw=0.3747, running_loss=0.3226, LR=0.000100
[2025-08-27 17:32:05,143][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088192] [Batch 01952/03080] [00:23:32/00:13:36, 0.724s/it]: train_loss_raw=0.2810, running_loss=0.3220, LR=0.000100
[2025-08-27 17:32:11,046][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088200] [Batch 01960/03080] [00:23:38/00:13:30, 0.724s/it]: train_loss_raw=0.3136, running_loss=0.3214, LR=0.000100
[2025-08-27 17:32:16,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088208] [Batch 01968/03080] [00:23:43/00:13:24, 0.724s/it]: train_loss_raw=0.3332, running_loss=0.3216, LR=0.000100
[2025-08-27 17:32:22,441][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088216] [Batch 01976/03080] [00:23:49/00:13:18, 0.724s/it]: train_loss_raw=0.3186, running_loss=0.3222, LR=0.000100
[2025-08-27 17:32:28,344][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088224] [Batch 01984/03080] [00:23:55/00:13:13, 0.724s/it]: train_loss_raw=0.3483, running_loss=0.3227, LR=0.000100
[2025-08-27 17:32:34,147][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088232] [Batch 01992/03080] [00:24:01/00:13:07, 0.724s/it]: train_loss_raw=0.2436, running_loss=0.3235, LR=0.000100
[2025-08-27 17:32:39,916][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088240] [Batch 02000/03080] [00:24:07/00:13:01, 0.724s/it]: train_loss_raw=0.3398, running_loss=0.3242, LR=0.000100
[2025-08-27 17:32:45,738][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088248] [Batch 02008/03080] [00:24:12/00:12:55, 0.724s/it]: train_loss_raw=0.3618, running_loss=0.3262, LR=0.000100
[2025-08-27 17:32:51,896][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088256] [Batch 02016/03080] [00:24:19/00:12:50, 0.724s/it]: train_loss_raw=0.3767, running_loss=0.3245, LR=0.000100
[2025-08-27 17:32:57,512][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088264] [Batch 02024/03080] [00:24:24/00:12:44, 0.724s/it]: train_loss_raw=0.2759, running_loss=0.3238, LR=0.000100
[2025-08-27 17:33:03,320][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088272] [Batch 02032/03080] [00:24:30/00:12:38, 0.724s/it]: train_loss_raw=0.3329, running_loss=0.3232, LR=0.000100
[2025-08-27 17:33:09,100][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088280] [Batch 02040/03080] [00:24:36/00:12:32, 0.724s/it]: train_loss_raw=0.3065, running_loss=0.3249, LR=0.000100
[2025-08-27 17:33:14,678][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088288] [Batch 02048/03080] [00:24:41/00:12:26, 0.724s/it]: train_loss_raw=0.3695, running_loss=0.3237, LR=0.000100
[2025-08-27 17:33:20,122][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088296] [Batch 02056/03080] [00:24:47/00:12:20, 0.723s/it]: train_loss_raw=0.2939, running_loss=0.3241, LR=0.000100
[2025-08-27 17:33:26,185][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088304] [Batch 02064/03080] [00:24:53/00:12:15, 0.724s/it]: train_loss_raw=0.3973, running_loss=0.3251, LR=0.000100
[2025-08-27 17:33:31,904][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088312] [Batch 02072/03080] [00:24:59/00:12:09, 0.724s/it]: train_loss_raw=0.2924, running_loss=0.3243, LR=0.000100
[2025-08-27 17:33:37,624][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088320] [Batch 02080/03080] [00:25:04/00:12:03, 0.723s/it]: train_loss_raw=0.3637, running_loss=0.3278, LR=0.000100
[2025-08-27 17:33:43,167][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088328] [Batch 02088/03080] [00:25:10/00:11:57, 0.723s/it]: train_loss_raw=0.4174, running_loss=0.3263, LR=0.000100
[2025-08-27 17:33:49,083][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088336] [Batch 02096/03080] [00:25:16/00:11:51, 0.723s/it]: train_loss_raw=0.3181, running_loss=0.3272, LR=0.000100
[2025-08-27 17:33:54,797][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088344] [Batch 02104/03080] [00:25:22/00:11:46, 0.723s/it]: train_loss_raw=0.4108, running_loss=0.3264, LR=0.000100
[2025-08-27 17:34:00,659][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088352] [Batch 02112/03080] [00:25:27/00:11:40, 0.723s/it]: train_loss_raw=0.3440, running_loss=0.3285, LR=0.000100
[2025-08-27 17:34:06,466][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088360] [Batch 02120/03080] [00:25:33/00:11:34, 0.723s/it]: train_loss_raw=0.3660, running_loss=0.3288, LR=0.000100
[2025-08-27 17:34:12,126][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088368] [Batch 02128/03080] [00:25:39/00:11:28, 0.723s/it]: train_loss_raw=0.3027, running_loss=0.3264, LR=0.000100
[2025-08-27 17:34:17,739][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088376] [Batch 02136/03080] [00:25:44/00:11:22, 0.723s/it]: train_loss_raw=0.3194, running_loss=0.3263, LR=0.000100
[2025-08-27 17:34:23,866][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088384] [Batch 02144/03080] [00:25:51/00:11:17, 0.723s/it]: train_loss_raw=0.3094, running_loss=0.3256, LR=0.000100
[2025-08-27 17:34:29,320][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088392] [Batch 02152/03080] [00:25:56/00:11:11, 0.723s/it]: train_loss_raw=0.3608, running_loss=0.3248, LR=0.000100
[2025-08-27 17:34:35,271][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088400] [Batch 02160/03080] [00:26:02/00:11:05, 0.723s/it]: train_loss_raw=0.3506, running_loss=0.3257, LR=0.000100
[2025-08-27 17:34:41,033][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088408] [Batch 02168/03080] [00:26:08/00:10:59, 0.723s/it]: train_loss_raw=0.3352, running_loss=0.3261, LR=0.000100
[2025-08-27 17:34:46,803][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088416] [Batch 02176/03080] [00:26:14/00:10:53, 0.723s/it]: train_loss_raw=0.3634, running_loss=0.3262, LR=0.000100
[2025-08-27 17:34:52,637][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088424] [Batch 02184/03080] [00:26:19/00:10:48, 0.723s/it]: train_loss_raw=0.2999, running_loss=0.3270, LR=0.000100
[2025-08-27 17:34:58,569][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088432] [Batch 02192/03080] [00:26:25/00:10:42, 0.723s/it]: train_loss_raw=0.2504, running_loss=0.3256, LR=0.000100
[2025-08-27 17:35:04,069][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088440] [Batch 02200/03080] [00:26:31/00:10:36, 0.723s/it]: train_loss_raw=0.3130, running_loss=0.3248, LR=0.000100
[2025-08-27 17:35:09,482][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088448] [Batch 02208/03080] [00:26:36/00:10:30, 0.723s/it]: train_loss_raw=0.2712, running_loss=0.3234, LR=0.000100
[2025-08-27 17:35:15,188][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088456] [Batch 02216/03080] [00:26:42/00:10:24, 0.723s/it]: train_loss_raw=0.2960, running_loss=0.3216, LR=0.000100
[2025-08-27 17:35:20,904][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088464] [Batch 02224/03080] [00:26:48/00:10:18, 0.723s/it]: train_loss_raw=0.3904, running_loss=0.3227, LR=0.000100
[2025-08-27 17:35:26,825][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088472] [Batch 02232/03080] [00:26:54/00:10:13, 0.723s/it]: train_loss_raw=0.3407, running_loss=0.3232, LR=0.000100
[2025-08-27 17:35:32,697][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088480] [Batch 02240/03080] [00:26:59/00:10:07, 0.723s/it]: train_loss_raw=0.3648, running_loss=0.3233, LR=0.000100
[2025-08-27 17:35:38,757][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088488] [Batch 02248/03080] [00:27:05/00:10:01, 0.723s/it]: train_loss_raw=0.2707, running_loss=0.3230, LR=0.000100
[2025-08-27 17:35:44,750][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088496] [Batch 02256/03080] [00:27:11/00:09:56, 0.723s/it]: train_loss_raw=0.2793, running_loss=0.3229, LR=0.000100
[2025-08-27 17:35:50,694][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088504] [Batch 02264/03080] [00:27:17/00:09:50, 0.723s/it]: train_loss_raw=0.3679, running_loss=0.3219, LR=0.000100
[2025-08-27 17:35:56,653][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088512] [Batch 02272/03080] [00:27:23/00:09:44, 0.724s/it]: train_loss_raw=0.4101, running_loss=0.3217, LR=0.000100
[2025-08-27 17:36:02,294][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088520] [Batch 02280/03080] [00:27:29/00:09:38, 0.723s/it]: train_loss_raw=0.2826, running_loss=0.3212, LR=0.000100
[2025-08-27 17:36:07,731][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088528] [Batch 02288/03080] [00:27:34/00:09:32, 0.723s/it]: train_loss_raw=0.3962, running_loss=0.3210, LR=0.000100
[2025-08-27 17:36:13,204][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088536] [Batch 02296/03080] [00:27:40/00:09:26, 0.723s/it]: train_loss_raw=0.3302, running_loss=0.3194, LR=0.000100
[2025-08-27 17:36:18,868][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088544] [Batch 02304/03080] [00:27:46/00:09:21, 0.723s/it]: train_loss_raw=0.3287, running_loss=0.3207, LR=0.000100
[2025-08-27 17:36:24,560][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088552] [Batch 02312/03080] [00:27:51/00:09:15, 0.723s/it]: train_loss_raw=0.3371, running_loss=0.3199, LR=0.000100
[2025-08-27 17:36:30,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088560] [Batch 02320/03080] [00:27:57/00:09:09, 0.723s/it]: train_loss_raw=0.3206, running_loss=0.3184, LR=0.000100
[2025-08-27 17:36:35,839][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088568] [Batch 02328/03080] [00:28:03/00:09:03, 0.723s/it]: train_loss_raw=0.3316, running_loss=0.3182, LR=0.000100
[2025-08-27 17:36:41,310][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088576] [Batch 02336/03080] [00:28:08/00:08:57, 0.723s/it]: train_loss_raw=0.3364, running_loss=0.3197, LR=0.000100
[2025-08-27 17:36:46,818][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088584] [Batch 02344/03080] [00:28:14/00:08:51, 0.723s/it]: train_loss_raw=0.4037, running_loss=0.3221, LR=0.000100
[2025-08-27 17:36:52,274][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088592] [Batch 02352/03080] [00:28:19/00:08:46, 0.723s/it]: train_loss_raw=0.3796, running_loss=0.3231, LR=0.000100
[2025-08-27 17:36:58,207][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088600] [Batch 02360/03080] [00:28:25/00:08:40, 0.723s/it]: train_loss_raw=0.3322, running_loss=0.3220, LR=0.000100
[2025-08-27 17:37:04,302][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088608] [Batch 02368/03080] [00:28:31/00:08:34, 0.723s/it]: train_loss_raw=0.2687, running_loss=0.3215, LR=0.000100
[2025-08-27 17:37:09,942][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088616] [Batch 02376/03080] [00:28:37/00:08:28, 0.723s/it]: train_loss_raw=0.2522, running_loss=0.3223, LR=0.000100
[2025-08-27 17:37:15,551][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088624] [Batch 02384/03080] [00:28:42/00:08:22, 0.723s/it]: train_loss_raw=0.3557, running_loss=0.3223, LR=0.000100
[2025-08-27 17:37:21,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088632] [Batch 02392/03080] [00:28:48/00:08:17, 0.723s/it]: train_loss_raw=0.2992, running_loss=0.3213, LR=0.000100
[2025-08-27 17:37:27,431][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088640] [Batch 02400/03080] [00:28:54/00:08:11, 0.723s/it]: train_loss_raw=0.3710, running_loss=0.3204, LR=0.000100
[2025-08-27 17:37:33,368][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088648] [Batch 02408/03080] [00:29:00/00:08:05, 0.723s/it]: train_loss_raw=0.2545, running_loss=0.3205, LR=0.000100
[2025-08-27 17:37:39,072][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088656] [Batch 02416/03080] [00:29:06/00:07:59, 0.723s/it]: train_loss_raw=0.3637, running_loss=0.3199, LR=0.000100
[2025-08-27 17:37:44,924][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088664] [Batch 02424/03080] [00:29:12/00:07:54, 0.723s/it]: train_loss_raw=0.3112, running_loss=0.3212, LR=0.000100
[2025-08-27 17:37:50,918][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088672] [Batch 02432/03080] [00:29:18/00:07:48, 0.723s/it]: train_loss_raw=0.3500, running_loss=0.3217, LR=0.000100
[2025-08-27 17:37:56,657][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088680] [Batch 02440/03080] [00:29:23/00:07:42, 0.723s/it]: train_loss_raw=0.2749, running_loss=0.3216, LR=0.000100
[2025-08-27 17:38:02,352][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088688] [Batch 02448/03080] [00:29:29/00:07:36, 0.723s/it]: train_loss_raw=0.3666, running_loss=0.3226, LR=0.000100
[2025-08-27 17:38:08,262][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088696] [Batch 02456/03080] [00:29:35/00:07:31, 0.723s/it]: train_loss_raw=0.3537, running_loss=0.3231, LR=0.000100
[2025-08-27 17:38:14,253][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088704] [Batch 02464/03080] [00:29:41/00:07:25, 0.723s/it]: train_loss_raw=0.2905, running_loss=0.3231, LR=0.000100
[2025-08-27 17:38:20,170][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088712] [Batch 02472/03080] [00:29:47/00:07:19, 0.723s/it]: train_loss_raw=0.3020, running_loss=0.3222, LR=0.000100
[2025-08-27 17:38:26,159][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088720] [Batch 02480/03080] [00:29:53/00:07:13, 0.723s/it]: train_loss_raw=0.2955, running_loss=0.3217, LR=0.000100
[2025-08-27 17:38:31,999][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088728] [Batch 02488/03080] [00:29:59/00:07:08, 0.723s/it]: train_loss_raw=0.3511, running_loss=0.3208, LR=0.000100
[2025-08-27 17:38:37,736][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088736] [Batch 02496/03080] [00:30:04/00:07:02, 0.723s/it]: train_loss_raw=0.3388, running_loss=0.3197, LR=0.000100
[2025-08-27 17:38:43,513][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088744] [Batch 02504/03080] [00:30:10/00:06:56, 0.723s/it]: train_loss_raw=0.3955, running_loss=0.3215, LR=0.000100
[2025-08-27 17:38:49,276][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088752] [Batch 02512/03080] [00:30:16/00:06:50, 0.723s/it]: train_loss_raw=0.4145, running_loss=0.3214, LR=0.000100
[2025-08-27 17:38:55,462][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088760] [Batch 02520/03080] [00:30:22/00:06:45, 0.723s/it]: train_loss_raw=0.2815, running_loss=0.3203, LR=0.000100
[2025-08-27 17:39:01,528][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088768] [Batch 02528/03080] [00:30:28/00:06:39, 0.723s/it]: train_loss_raw=0.2812, running_loss=0.3209, LR=0.000100
[2025-08-27 17:39:07,284][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088776] [Batch 02536/03080] [00:30:34/00:06:33, 0.723s/it]: train_loss_raw=0.2607, running_loss=0.3210, LR=0.000100
[2025-08-27 17:39:12,891][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088784] [Batch 02544/03080] [00:30:40/00:06:27, 0.723s/it]: train_loss_raw=0.3552, running_loss=0.3206, LR=0.000100
[2025-08-27 17:39:18,607][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088792] [Batch 02552/03080] [00:30:45/00:06:21, 0.723s/it]: train_loss_raw=0.3697, running_loss=0.3198, LR=0.000100
[2025-08-27 17:39:23,992][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088800] [Batch 02560/03080] [00:30:51/00:06:16, 0.723s/it]: train_loss_raw=0.3192, running_loss=0.3206, LR=0.000100
[2025-08-27 17:39:29,996][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088808] [Batch 02568/03080] [00:30:57/00:06:10, 0.723s/it]: train_loss_raw=0.3904, running_loss=0.3195, LR=0.000100
[2025-08-27 17:39:35,663][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088816] [Batch 02576/03080] [00:31:02/00:06:04, 0.723s/it]: train_loss_raw=0.3746, running_loss=0.3216, LR=0.000100
[2025-08-27 17:39:41,441][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088824] [Batch 02584/03080] [00:31:08/00:05:58, 0.723s/it]: train_loss_raw=0.2548, running_loss=0.3218, LR=0.000100
[2025-08-27 17:39:47,601][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088832] [Batch 02592/03080] [00:31:14/00:05:52, 0.723s/it]: train_loss_raw=0.4144, running_loss=0.3241, LR=0.000100
[2025-08-27 17:39:53,354][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088840] [Batch 02600/03080] [00:31:20/00:05:47, 0.723s/it]: train_loss_raw=0.2923, running_loss=0.3238, LR=0.000100
[2025-08-27 17:39:59,330][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088848] [Batch 02608/03080] [00:31:26/00:05:41, 0.723s/it]: train_loss_raw=0.3363, running_loss=0.3246, LR=0.000100
[2025-08-27 17:40:05,532][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088856] [Batch 02616/03080] [00:31:32/00:05:35, 0.724s/it]: train_loss_raw=0.3752, running_loss=0.3249, LR=0.000100
[2025-08-27 17:40:11,857][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088864] [Batch 02624/03080] [00:31:39/00:05:30, 0.724s/it]: train_loss_raw=0.3179, running_loss=0.3238, LR=0.000100
[2025-08-27 17:40:17,976][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088872] [Batch 02632/03080] [00:31:45/00:05:24, 0.724s/it]: train_loss_raw=0.3545, running_loss=0.3249, LR=0.000100
[2025-08-27 17:40:24,105][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088880] [Batch 02640/03080] [00:31:51/00:05:18, 0.724s/it]: train_loss_raw=0.3170, running_loss=0.3261, LR=0.000100
[2025-08-27 17:40:29,903][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088888] [Batch 02648/03080] [00:31:57/00:05:12, 0.724s/it]: train_loss_raw=0.3791, running_loss=0.3276, LR=0.000100
[2025-08-27 17:40:35,811][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088896] [Batch 02656/03080] [00:32:03/00:05:06, 0.724s/it]: train_loss_raw=0.3287, running_loss=0.3276, LR=0.000100
[2025-08-27 17:40:41,712][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088904] [Batch 02664/03080] [00:32:08/00:05:01, 0.724s/it]: train_loss_raw=0.3416, running_loss=0.3268, LR=0.000100
[2025-08-27 17:40:47,502][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088912] [Batch 02672/03080] [00:32:14/00:04:55, 0.724s/it]: train_loss_raw=0.3408, running_loss=0.3253, LR=0.000100
[2025-08-27 17:40:53,466][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088920] [Batch 02680/03080] [00:32:20/00:04:49, 0.724s/it]: train_loss_raw=0.2689, running_loss=0.3242, LR=0.000100
[2025-08-27 17:40:59,342][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088928] [Batch 02688/03080] [00:32:26/00:04:43, 0.724s/it]: train_loss_raw=0.3539, running_loss=0.3256, LR=0.000100
[2025-08-27 17:41:05,365][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088936] [Batch 02696/03080] [00:32:32/00:04:38, 0.724s/it]: train_loss_raw=0.2283, running_loss=0.3260, LR=0.000100
[2025-08-27 17:41:11,330][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088944] [Batch 02704/03080] [00:32:38/00:04:32, 0.724s/it]: train_loss_raw=0.3263, running_loss=0.3251, LR=0.000100
[2025-08-27 17:41:17,340][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088952] [Batch 02712/03080] [00:32:44/00:04:26, 0.724s/it]: train_loss_raw=0.3274, running_loss=0.3230, LR=0.000100
[2025-08-27 17:41:23,095][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088960] [Batch 02720/03080] [00:32:50/00:04:20, 0.724s/it]: train_loss_raw=0.3387, running_loss=0.3239, LR=0.000100
[2025-08-27 17:41:28,770][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088968] [Batch 02728/03080] [00:32:55/00:04:14, 0.724s/it]: train_loss_raw=0.2866, running_loss=0.3246, LR=0.000100
[2025-08-27 17:41:34,579][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088976] [Batch 02736/03080] [00:33:01/00:04:09, 0.724s/it]: train_loss_raw=0.3381, running_loss=0.3270, LR=0.000100
[2025-08-27 17:41:40,276][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088984] [Batch 02744/03080] [00:33:07/00:04:03, 0.724s/it]: train_loss_raw=0.3277, running_loss=0.3278, LR=0.000100
[2025-08-27 17:41:45,890][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 088992] [Batch 02752/03080] [00:33:13/00:03:57, 0.724s/it]: train_loss_raw=0.3021, running_loss=0.3263, LR=0.000100
[2025-08-27 17:41:51,873][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089000] [Batch 02760/03080] [00:33:19/00:03:51, 0.724s/it]: train_loss_raw=0.2816, running_loss=0.3262, LR=0.000100
[2025-08-27 17:41:57,917][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089008] [Batch 02768/03080] [00:33:25/00:03:46, 0.724s/it]: train_loss_raw=0.3539, running_loss=0.3269, LR=0.000100
[2025-08-27 17:42:03,522][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089016] [Batch 02776/03080] [00:33:30/00:03:40, 0.724s/it]: train_loss_raw=0.3024, running_loss=0.3269, LR=0.000100
[2025-08-27 17:42:08,907][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089024] [Batch 02784/03080] [00:33:36/00:03:34, 0.724s/it]: train_loss_raw=0.3307, running_loss=0.3270, LR=0.000100
[2025-08-27 17:42:14,546][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089032] [Batch 02792/03080] [00:33:41/00:03:28, 0.724s/it]: train_loss_raw=0.3137, running_loss=0.3252, LR=0.000100
[2025-08-27 17:42:20,163][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089040] [Batch 02800/03080] [00:33:47/00:03:22, 0.724s/it]: train_loss_raw=0.3725, running_loss=0.3239, LR=0.000100
[2025-08-27 17:42:25,972][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089048] [Batch 02808/03080] [00:33:53/00:03:16, 0.724s/it]: train_loss_raw=0.2814, running_loss=0.3221, LR=0.000100
[2025-08-27 17:42:31,808][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089056] [Batch 02816/03080] [00:33:59/00:03:11, 0.724s/it]: train_loss_raw=0.3050, running_loss=0.3217, LR=0.000100
[2025-08-27 17:42:37,852][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089064] [Batch 02824/03080] [00:34:05/00:03:05, 0.724s/it]: train_loss_raw=0.2732, running_loss=0.3223, LR=0.000100
[2025-08-27 17:42:44,012][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089072] [Batch 02832/03080] [00:34:11/00:02:59, 0.724s/it]: train_loss_raw=0.2530, running_loss=0.3207, LR=0.000100
[2025-08-27 17:42:50,086][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089080] [Batch 02840/03080] [00:34:17/00:02:53, 0.724s/it]: train_loss_raw=0.3505, running_loss=0.3193, LR=0.000100
[2025-08-27 17:42:55,846][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089088] [Batch 02848/03080] [00:34:23/00:02:48, 0.724s/it]: train_loss_raw=0.3023, running_loss=0.3202, LR=0.000100
[2025-08-27 17:43:01,745][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089096] [Batch 02856/03080] [00:34:28/00:02:42, 0.724s/it]: train_loss_raw=0.3242, running_loss=0.3177, LR=0.000100
[2025-08-27 17:43:07,413][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089104] [Batch 02864/03080] [00:34:34/00:02:36, 0.724s/it]: train_loss_raw=0.4402, running_loss=0.3196, LR=0.000100
[2025-08-27 17:43:13,436][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089112] [Batch 02872/03080] [00:34:40/00:02:30, 0.724s/it]: train_loss_raw=0.2769, running_loss=0.3180, LR=0.000100
[2025-08-27 17:43:19,422][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089120] [Batch 02880/03080] [00:34:46/00:02:24, 0.725s/it]: train_loss_raw=0.3527, running_loss=0.3167, LR=0.000100
[2025-08-27 17:43:25,229][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089128] [Batch 02888/03080] [00:34:52/00:02:19, 0.725s/it]: train_loss_raw=0.4166, running_loss=0.3183, LR=0.000100
[2025-08-27 17:43:30,988][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089136] [Batch 02896/03080] [00:34:58/00:02:13, 0.725s/it]: train_loss_raw=0.3334, running_loss=0.3198, LR=0.000100
[2025-08-27 17:43:36,771][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089144] [Batch 02904/03080] [00:35:03/00:02:07, 0.725s/it]: train_loss_raw=0.2744, running_loss=0.3215, LR=0.000100
[2025-08-27 17:43:42,486][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089152] [Batch 02912/03080] [00:35:09/00:02:01, 0.724s/it]: train_loss_raw=0.3775, running_loss=0.3228, LR=0.000100
[2025-08-27 17:43:48,226][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089160] [Batch 02920/03080] [00:35:15/00:01:55, 0.724s/it]: train_loss_raw=0.2879, running_loss=0.3219, LR=0.000100
[2025-08-27 17:43:54,123][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089168] [Batch 02928/03080] [00:35:21/00:01:50, 0.725s/it]: train_loss_raw=0.3940, running_loss=0.3220, LR=0.000100
[2025-08-27 17:43:59,838][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089176] [Batch 02936/03080] [00:35:27/00:01:44, 0.724s/it]: train_loss_raw=0.2971, running_loss=0.3217, LR=0.000100
[2025-08-27 17:44:05,297][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089184] [Batch 02944/03080] [00:35:32/00:01:38, 0.724s/it]: train_loss_raw=0.3331, running_loss=0.3233, LR=0.000100
[2025-08-27 17:44:10,686][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089192] [Batch 02952/03080] [00:35:37/00:01:32, 0.724s/it]: train_loss_raw=0.3239, running_loss=0.3237, LR=0.000100
[2025-08-27 17:44:16,577][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089200] [Batch 02960/03080] [00:35:43/00:01:26, 0.724s/it]: train_loss_raw=0.2771, running_loss=0.3244, LR=0.000100
[2025-08-27 17:44:22,461][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089208] [Batch 02968/03080] [00:35:49/00:01:21, 0.724s/it]: train_loss_raw=0.2982, running_loss=0.3250, LR=0.000100
[2025-08-27 17:44:28,399][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089216] [Batch 02976/03080] [00:35:55/00:01:15, 0.724s/it]: train_loss_raw=0.2715, running_loss=0.3245, LR=0.000100
[2025-08-27 17:44:34,246][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089224] [Batch 02984/03080] [00:36:01/00:01:09, 0.724s/it]: train_loss_raw=0.3298, running_loss=0.3244, LR=0.000100
[2025-08-27 17:44:39,887][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089232] [Batch 02992/03080] [00:36:07/00:01:03, 0.724s/it]: train_loss_raw=0.3369, running_loss=0.3268, LR=0.000100
[2025-08-27 17:44:45,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089240] [Batch 03000/03080] [00:36:13/00:00:57, 0.724s/it]: train_loss_raw=0.2903, running_loss=0.3273, LR=0.000100
[2025-08-27 17:44:52,131][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089248] [Batch 03008/03080] [00:36:19/00:00:52, 0.725s/it]: train_loss_raw=0.2732, running_loss=0.3264, LR=0.000100
[2025-08-27 17:44:58,217][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089256] [Batch 03016/03080] [00:36:25/00:00:46, 0.725s/it]: train_loss_raw=0.2755, running_loss=0.3281, LR=0.000100
[2025-08-27 17:45:04,009][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089264] [Batch 03024/03080] [00:36:31/00:00:40, 0.725s/it]: train_loss_raw=0.3426, running_loss=0.3289, LR=0.000100
[2025-08-27 17:45:09,792][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089272] [Batch 03032/03080] [00:36:37/00:00:34, 0.725s/it]: train_loss_raw=0.3005, running_loss=0.3271, LR=0.000100
[2025-08-27 17:45:15,142][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089280] [Batch 03040/03080] [00:36:42/00:00:28, 0.724s/it]: train_loss_raw=0.3744, running_loss=0.3263, LR=0.000100
[2025-08-27 17:45:20,915][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089288] [Batch 03048/03080] [00:36:48/00:00:23, 0.724s/it]: train_loss_raw=0.3768, running_loss=0.3261, LR=0.000100
[2025-08-27 17:45:26,973][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089296] [Batch 03056/03080] [00:36:54/00:00:17, 0.725s/it]: train_loss_raw=0.3666, running_loss=0.3276, LR=0.000100
[2025-08-27 17:45:32,831][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089304] [Batch 03064/03080] [00:37:00/00:00:11, 0.725s/it]: train_loss_raw=0.3976, running_loss=0.3272, LR=0.000100
[2025-08-27 17:45:38,786][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089312] [Batch 03072/03080] [00:37:06/00:00:05, 0.725s/it]: train_loss_raw=0.3604, running_loss=0.3254, LR=0.000100
[2025-08-27 17:45:44,847][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 089320] [Batch 03080/03080] [00:37:12/00:00:00, 0.725s/it]: train_loss_raw=0.3331, running_loss=0.3253, LR=0.000100
[2025-08-27 17:45:45,380][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-27 17:45:57,092][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00007/00310] [00:00:11/00:07:22, 1.464s/it]
[2025-08-27 17:46:08,464][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00015/00310] [00:00:23/00:07:04, 1.443s/it]
[2025-08-27 17:46:19,818][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00023/00310] [00:00:34/00:06:50, 1.435s/it]
[2025-08-27 17:46:32,140][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00031/00310] [00:00:46/00:06:46, 1.461s/it]
[2025-08-27 17:46:44,572][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00039/00310] [00:00:59/00:06:39, 1.480s/it]
[2025-08-27 17:46:55,690][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00047/00310] [00:01:10/00:06:23, 1.465s/it]
[2025-08-27 17:47:08,177][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00055/00310] [00:01:22/00:06:15, 1.478s/it]
[2025-08-27 17:47:19,581][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00063/00310] [00:01:34/00:06:02, 1.472s/it]
[2025-08-27 17:47:32,331][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00071/00310] [00:01:46/00:05:53, 1.485s/it]
[2025-08-27 17:47:44,692][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00079/00310] [00:01:59/00:05:43, 1.491s/it]
[2025-08-27 17:47:56,214][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00087/00310] [00:02:10/00:05:30, 1.487s/it]
[2025-08-27 17:48:08,225][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00095/00310] [00:02:22/00:05:18, 1.488s/it]
[2025-08-27 17:48:19,041][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00103/00310] [00:02:33/00:05:04, 1.478s/it]
[2025-08-27 17:48:30,368][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00111/00310] [00:02:44/00:04:51, 1.473s/it]
[2025-08-27 17:48:42,112][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00119/00310] [00:02:56/00:04:39, 1.473s/it]
[2025-08-27 17:48:53,886][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00127/00310] [00:03:08/00:04:28, 1.473s/it]
[2025-08-27 17:49:05,989][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00135/00310] [00:03:20/00:04:16, 1.475s/it]
[2025-08-27 17:49:18,940][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00143/00310] [00:03:33/00:04:06, 1.483s/it]
[2025-08-27 17:49:29,553][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00151/00310] [00:03:44/00:03:53, 1.475s/it]
[2025-08-27 17:49:40,837][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00159/00310] [00:03:55/00:03:40, 1.472s/it]
[2025-08-27 17:49:52,578][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00167/00310] [00:04:07/00:03:28, 1.471s/it]
[2025-08-27 17:50:01,858][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00175/00310] [00:04:16/00:03:15, 1.457s/it]
[2025-08-27 17:50:12,372][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00183/00310] [00:04:26/00:03:02, 1.451s/it]
[2025-08-27 17:50:23,530][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00191/00310] [00:04:38/00:02:50, 1.449s/it]
[2025-08-27 17:50:35,474][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00199/00310] [00:04:50/00:02:39, 1.450s/it]
[2025-08-27 17:50:46,938][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00207/00310] [00:05:01/00:02:27, 1.450s/it]
[2025-08-27 17:50:57,571][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00215/00310] [00:05:12/00:02:15, 1.445s/it]
[2025-08-27 17:51:09,189][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00223/00310] [00:05:23/00:02:04, 1.446s/it]
[2025-08-27 17:51:21,149][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00231/00310] [00:05:35/00:01:52, 1.447s/it]
[2025-08-27 17:51:32,190][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00239/00310] [00:05:46/00:01:41, 1.445s/it]
[2025-08-27 17:51:43,071][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00247/00310] [00:05:57/00:01:29, 1.442s/it]
[2025-08-27 17:51:54,733][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00255/00310] [00:06:09/00:01:17, 1.443s/it]
[2025-08-27 17:52:06,328][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00263/00310] [00:06:20/00:01:06, 1.443s/it]
[2025-08-27 17:52:18,245][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00271/00310] [00:06:32/00:00:54, 1.444s/it]
[2025-08-27 17:52:29,873][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00279/00310] [00:06:44/00:00:43, 1.445s/it]
[2025-08-27 17:52:42,409][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00287/00310] [00:06:57/00:00:31, 1.448s/it]
[2025-08-27 17:52:53,036][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00295/00310] [00:07:07/00:00:20, 1.445s/it]
[2025-08-27 17:53:04,944][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 089321] [Batch 00303/00310] [00:07:19/00:00:08, 1.446s/it]
[2025-08-27 17:53:13,873][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.32534, valid_loss=1.43859
[2025-08-27 17:53:13,874][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-27 17:53:13,874][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.477
[2025-08-27 17:53:13,874][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.160
[2025-08-27 17:53:13,874][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.163
[2025-08-27 17:53:13,874][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.088
[2025-08-27 17:53:13,889][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 22:26:27, remaining time 00:46:25, 00:46:25 per epoch
[2025-08-27 17:53:19,542][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089328] [Batch 00008/03080] [00:00:05/00:34:25, 0.672s/it]: train_loss_raw=0.3901, running_loss=0.3163, LR=0.000100
[2025-08-27 17:53:25,558][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089336] [Batch 00016/03080] [00:00:11/00:36:22, 0.712s/it]: train_loss_raw=0.4119, running_loss=0.3193, LR=0.000100
[2025-08-27 17:53:31,541][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089344] [Batch 00024/03080] [00:00:17/00:36:52, 0.724s/it]: train_loss_raw=0.3604, running_loss=0.3184, LR=0.000100
[2025-08-27 17:53:37,488][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089352] [Batch 00032/03080] [00:00:23/00:37:01, 0.729s/it]: train_loss_raw=0.2399, running_loss=0.3196, LR=0.000100
[2025-08-27 17:53:43,296][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089360] [Batch 00040/03080] [00:00:29/00:36:54, 0.728s/it]: train_loss_raw=0.3761, running_loss=0.3235, LR=0.000100
[2025-08-27 17:53:49,131][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089368] [Batch 00048/03080] [00:00:34/00:36:48, 0.728s/it]: train_loss_raw=0.3251, running_loss=0.3249, LR=0.000100
[2025-08-27 17:53:55,152][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089376] [Batch 00056/03080] [00:00:40/00:36:53, 0.732s/it]: train_loss_raw=0.3165, running_loss=0.3242, LR=0.000100
[2025-08-27 17:54:01,076][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089384] [Batch 00064/03080] [00:00:46/00:36:50, 0.733s/it]: train_loss_raw=0.2684, running_loss=0.3229, LR=0.000100
[2025-08-27 17:54:07,185][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089392] [Batch 00072/03080] [00:00:53/00:36:55, 0.736s/it]: train_loss_raw=0.2454, running_loss=0.3223, LR=0.000100
[2025-08-27 17:54:13,178][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089400] [Batch 00080/03080] [00:00:59/00:36:53, 0.738s/it]: train_loss_raw=0.3174, running_loss=0.3222, LR=0.000100
[2025-08-27 17:54:19,158][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089408] [Batch 00088/03080] [00:01:04/00:36:49, 0.739s/it]: train_loss_raw=0.3407, running_loss=0.3199, LR=0.000100
[2025-08-27 17:54:25,183][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089416] [Batch 00096/03080] [00:01:11/00:36:47, 0.740s/it]: train_loss_raw=0.3148, running_loss=0.3203, LR=0.000100
[2025-08-27 17:54:30,949][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089424] [Batch 00104/03080] [00:01:16/00:36:37, 0.738s/it]: train_loss_raw=0.2909, running_loss=0.3192, LR=0.000100
[2025-08-27 17:54:36,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089432] [Batch 00112/03080] [00:01:22/00:36:22, 0.735s/it]: train_loss_raw=0.3096, running_loss=0.3190, LR=0.000100
[2025-08-27 17:54:42,251][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089440] [Batch 00120/03080] [00:01:28/00:36:12, 0.734s/it]: train_loss_raw=0.3558, running_loss=0.3217, LR=0.000100
[2025-08-27 17:54:48,048][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089448] [Batch 00128/03080] [00:01:33/00:36:05, 0.733s/it]: train_loss_raw=0.3816, running_loss=0.3206, LR=0.000100
[2025-08-27 17:54:54,101][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089456] [Batch 00136/03080] [00:01:39/00:36:03, 0.735s/it]: train_loss_raw=0.2294, running_loss=0.3196, LR=0.000100
[2025-08-27 17:54:59,619][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089464] [Batch 00144/03080] [00:01:45/00:35:50, 0.732s/it]: train_loss_raw=0.2755, running_loss=0.3188, LR=0.000100
[2025-08-27 17:55:05,710][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089472] [Batch 00152/03080] [00:01:51/00:35:48, 0.734s/it]: train_loss_raw=0.2841, running_loss=0.3188, LR=0.000100
[2025-08-27 17:55:11,409][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089480] [Batch 00160/03080] [00:01:57/00:35:39, 0.733s/it]: train_loss_raw=0.3124, running_loss=0.3184, LR=0.000100
[2025-08-27 17:55:17,018][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089488] [Batch 00168/03080] [00:02:02/00:35:29, 0.731s/it]: train_loss_raw=0.2569, running_loss=0.3200, LR=0.000100
[2025-08-27 17:55:22,902][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089496] [Batch 00176/03080] [00:02:08/00:35:24, 0.731s/it]: train_loss_raw=0.3613, running_loss=0.3204, LR=0.000100
[2025-08-27 17:55:28,844][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089504] [Batch 00184/03080] [00:02:14/00:35:19, 0.732s/it]: train_loss_raw=0.3349, running_loss=0.3203, LR=0.000100
[2025-08-27 17:55:34,360][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089512] [Batch 00192/03080] [00:02:20/00:35:08, 0.730s/it]: train_loss_raw=0.3445, running_loss=0.3197, LR=0.000100
[2025-08-27 17:55:40,191][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089520] [Batch 00200/03080] [00:02:26/00:35:02, 0.730s/it]: train_loss_raw=0.3860, running_loss=0.3209, LR=0.000100
[2025-08-27 17:55:45,561][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089528] [Batch 00208/03080] [00:02:31/00:34:50, 0.728s/it]: train_loss_raw=0.2683, running_loss=0.3209, LR=0.000100
[2025-08-27 17:55:51,182][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089536] [Batch 00216/03080] [00:02:37/00:34:41, 0.727s/it]: train_loss_raw=0.2415, running_loss=0.3206, LR=0.000100
[2025-08-27 17:55:57,125][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089544] [Batch 00224/03080] [00:02:42/00:34:37, 0.728s/it]: train_loss_raw=0.3438, running_loss=0.3213, LR=0.000100
[2025-08-27 17:56:03,122][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089552] [Batch 00232/03080] [00:02:48/00:34:34, 0.728s/it]: train_loss_raw=0.3572, running_loss=0.3215, LR=0.000100
[2025-08-27 17:56:08,920][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089560] [Batch 00240/03080] [00:02:54/00:34:27, 0.728s/it]: train_loss_raw=0.3614, running_loss=0.3215, LR=0.000100
[2025-08-27 17:56:14,794][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089568] [Batch 00248/03080] [00:03:00/00:34:22, 0.728s/it]: train_loss_raw=0.2830, running_loss=0.3210, LR=0.000100
[2025-08-27 17:56:20,692][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089576] [Batch 00256/03080] [00:03:06/00:34:17, 0.729s/it]: train_loss_raw=0.3697, running_loss=0.3220, LR=0.000100
[2025-08-27 17:56:26,331][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089584] [Batch 00264/03080] [00:03:12/00:34:09, 0.728s/it]: train_loss_raw=0.3687, running_loss=0.3229, LR=0.000100
[2025-08-27 17:56:31,879][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089592] [Batch 00272/03080] [00:03:17/00:34:01, 0.727s/it]: train_loss_raw=0.3410, running_loss=0.3221, LR=0.000100
[2025-08-27 17:56:37,901][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089600] [Batch 00280/03080] [00:03:23/00:33:57, 0.728s/it]: train_loss_raw=0.3405, running_loss=0.3231, LR=0.000100
[2025-08-27 17:56:43,597][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089608] [Batch 00288/03080] [00:03:29/00:33:50, 0.727s/it]: train_loss_raw=0.3264, running_loss=0.3234, LR=0.000100
[2025-08-27 17:56:49,397][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089616] [Batch 00296/03080] [00:03:35/00:33:44, 0.727s/it]: train_loss_raw=0.4056, running_loss=0.3230, LR=0.000100
[2025-08-27 17:56:55,153][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089624] [Batch 00304/03080] [00:03:40/00:33:37, 0.727s/it]: train_loss_raw=0.3363, running_loss=0.3225, LR=0.000100
[2025-08-27 17:57:01,145][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089632] [Batch 00312/03080] [00:03:46/00:33:33, 0.728s/it]: train_loss_raw=0.2697, running_loss=0.3246, LR=0.000100
[2025-08-27 17:57:06,627][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089640] [Batch 00320/03080] [00:03:52/00:33:25, 0.726s/it]: train_loss_raw=0.3018, running_loss=0.3239, LR=0.000100
[2025-08-27 17:57:12,322][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089648] [Batch 00328/03080] [00:03:58/00:33:18, 0.726s/it]: train_loss_raw=0.3079, running_loss=0.3226, LR=0.000100
[2025-08-27 17:57:18,320][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089656] [Batch 00336/03080] [00:04:04/00:33:13, 0.727s/it]: train_loss_raw=0.3970, running_loss=0.3233, LR=0.000100
[2025-08-27 17:57:24,321][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089664] [Batch 00344/03080] [00:04:10/00:33:09, 0.727s/it]: train_loss_raw=0.3684, running_loss=0.3239, LR=0.000100
[2025-08-27 17:57:30,291][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089672] [Batch 00352/03080] [00:04:16/00:33:04, 0.728s/it]: train_loss_raw=0.3783, running_loss=0.3217, LR=0.000100
[2025-08-27 17:57:36,508][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089680] [Batch 00360/03080] [00:04:22/00:33:02, 0.729s/it]: train_loss_raw=0.3201, running_loss=0.3217, LR=0.000100
[2025-08-27 17:57:42,543][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089688] [Batch 00368/03080] [00:04:28/00:32:57, 0.729s/it]: train_loss_raw=0.3089, running_loss=0.3207, LR=0.000100
[2025-08-27 17:57:48,541][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089696] [Batch 00376/03080] [00:04:34/00:32:53, 0.730s/it]: train_loss_raw=0.3318, running_loss=0.3214, LR=0.000100
[2025-08-27 17:57:54,576][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089704] [Batch 00384/03080] [00:04:40/00:32:48, 0.730s/it]: train_loss_raw=0.3301, running_loss=0.3223, LR=0.000100
[2025-08-27 17:58:00,123][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089712] [Batch 00392/03080] [00:04:45/00:32:40, 0.729s/it]: train_loss_raw=0.2590, running_loss=0.3201, LR=0.000100
[2025-08-27 17:58:06,181][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089720] [Batch 00400/03080] [00:04:52/00:32:36, 0.730s/it]: train_loss_raw=0.3054, running_loss=0.3205, LR=0.000100
[2025-08-27 17:58:12,210][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089728] [Batch 00408/03080] [00:04:58/00:32:31, 0.731s/it]: train_loss_raw=0.3017, running_loss=0.3207, LR=0.000100
[2025-08-27 17:58:17,953][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089736] [Batch 00416/03080] [00:05:03/00:32:25, 0.730s/it]: train_loss_raw=0.2608, running_loss=0.3222, LR=0.000100
[2025-08-27 17:58:23,510][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089744] [Batch 00424/03080] [00:05:09/00:32:17, 0.730s/it]: train_loss_raw=0.3143, running_loss=0.3208, LR=0.000100
[2025-08-27 17:58:29,242][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089752] [Batch 00432/03080] [00:05:15/00:32:11, 0.729s/it]: train_loss_raw=0.3065, running_loss=0.3237, LR=0.000100
[2025-08-27 17:58:34,707][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089760] [Batch 00440/03080] [00:05:20/00:32:03, 0.729s/it]: train_loss_raw=0.3654, running_loss=0.3238, LR=0.000100
[2025-08-27 17:58:40,576][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089768] [Batch 00448/03080] [00:05:26/00:31:57, 0.729s/it]: train_loss_raw=0.2911, running_loss=0.3231, LR=0.000100
[2025-08-27 17:58:46,271][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089776] [Batch 00456/03080] [00:05:32/00:31:51, 0.728s/it]: train_loss_raw=0.2478, running_loss=0.3232, LR=0.000100
[2025-08-27 17:58:51,844][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089784] [Batch 00464/03080] [00:05:37/00:31:43, 0.728s/it]: train_loss_raw=0.3049, running_loss=0.3244, LR=0.000100
[2025-08-27 17:58:57,451][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089792] [Batch 00472/03080] [00:05:43/00:31:36, 0.727s/it]: train_loss_raw=0.3086, running_loss=0.3229, LR=0.000100
[2025-08-27 17:59:03,222][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089800] [Batch 00480/03080] [00:05:49/00:31:30, 0.727s/it]: train_loss_raw=0.3178, running_loss=0.3238, LR=0.000100
[2025-08-27 17:59:08,562][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089808] [Batch 00488/03080] [00:05:54/00:31:22, 0.726s/it]: train_loss_raw=0.3328, running_loss=0.3251, LR=0.000100
[2025-08-27 17:59:14,594][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089816] [Batch 00496/03080] [00:06:00/00:31:17, 0.727s/it]: train_loss_raw=0.3220, running_loss=0.3271, LR=0.000100
[2025-08-27 17:59:20,591][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089824] [Batch 00504/03080] [00:06:06/00:31:12, 0.727s/it]: train_loss_raw=0.3729, running_loss=0.3270, LR=0.000100
[2025-08-27 17:59:26,325][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089832] [Batch 00512/03080] [00:06:12/00:31:06, 0.727s/it]: train_loss_raw=0.3290, running_loss=0.3263, LR=0.000100
[2025-08-27 17:59:32,143][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089840] [Batch 00520/03080] [00:06:17/00:31:00, 0.727s/it]: train_loss_raw=0.3286, running_loss=0.3290, LR=0.000100
[2025-08-27 17:59:38,177][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089848] [Batch 00528/03080] [00:06:24/00:30:56, 0.727s/it]: train_loss_raw=0.3255, running_loss=0.3280, LR=0.000100
[2025-08-27 17:59:43,569][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089856] [Batch 00536/03080] [00:06:29/00:30:48, 0.727s/it]: train_loss_raw=0.3384, running_loss=0.3272, LR=0.000100
[2025-08-27 17:59:49,320][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089864] [Batch 00544/03080] [00:06:35/00:30:42, 0.726s/it]: train_loss_raw=0.3026, running_loss=0.3251, LR=0.000100
[2025-08-27 17:59:55,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089872] [Batch 00552/03080] [00:06:40/00:30:36, 0.726s/it]: train_loss_raw=0.3647, running_loss=0.3261, LR=0.000100
[2025-08-27 18:00:00,715][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089880] [Batch 00560/03080] [00:06:46/00:30:29, 0.726s/it]: train_loss_raw=0.3284, running_loss=0.3256, LR=0.000100
[2025-08-27 18:00:06,636][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089888] [Batch 00568/03080] [00:06:52/00:30:24, 0.726s/it]: train_loss_raw=0.2392, running_loss=0.3253, LR=0.000100
[2025-08-27 18:00:12,320][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089896] [Batch 00576/03080] [00:06:58/00:30:17, 0.726s/it]: train_loss_raw=0.3389, running_loss=0.3241, LR=0.000100
[2025-08-27 18:00:18,227][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089904] [Batch 00584/03080] [00:07:04/00:30:12, 0.726s/it]: train_loss_raw=0.3046, running_loss=0.3239, LR=0.000100
[2025-08-27 18:00:24,224][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089912] [Batch 00592/03080] [00:07:10/00:30:07, 0.726s/it]: train_loss_raw=0.2940, running_loss=0.3218, LR=0.000100
[2025-08-27 18:00:30,395][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089920] [Batch 00600/03080] [00:07:16/00:30:03, 0.727s/it]: train_loss_raw=0.3689, running_loss=0.3216, LR=0.000100
[2025-08-27 18:00:36,265][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089928] [Batch 00608/03080] [00:07:22/00:29:57, 0.727s/it]: train_loss_raw=0.3534, running_loss=0.3227, LR=0.000100
[2025-08-27 18:00:42,163][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089936] [Batch 00616/03080] [00:07:27/00:29:51, 0.727s/it]: train_loss_raw=0.3821, running_loss=0.3241, LR=0.000100
[2025-08-27 18:00:47,845][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089944] [Batch 00624/03080] [00:07:33/00:29:45, 0.727s/it]: train_loss_raw=0.3451, running_loss=0.3242, LR=0.000100
[2025-08-27 18:00:53,840][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089952] [Batch 00632/03080] [00:07:39/00:29:40, 0.727s/it]: train_loss_raw=0.2685, running_loss=0.3257, LR=0.000100
[2025-08-27 18:00:59,620][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089960] [Batch 00640/03080] [00:07:45/00:29:34, 0.727s/it]: train_loss_raw=0.3159, running_loss=0.3246, LR=0.000100
[2025-08-27 18:01:05,262][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089968] [Batch 00648/03080] [00:07:51/00:29:28, 0.727s/it]: train_loss_raw=0.3000, running_loss=0.3254, LR=0.000100
[2025-08-27 18:01:11,226][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089976] [Batch 00656/03080] [00:07:57/00:29:22, 0.727s/it]: train_loss_raw=0.2493, running_loss=0.3247, LR=0.000100
[2025-08-27 18:01:17,282][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089984] [Batch 00664/03080] [00:08:03/00:29:17, 0.728s/it]: train_loss_raw=0.3116, running_loss=0.3236, LR=0.000100
[2025-08-27 18:01:23,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 089992] [Batch 00672/03080] [00:08:09/00:29:12, 0.728s/it]: train_loss_raw=0.4022, running_loss=0.3231, LR=0.000100
[2025-08-27 18:01:29,212][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090000] [Batch 00680/03080] [00:08:15/00:29:07, 0.728s/it]: train_loss_raw=0.3728, running_loss=0.3218, LR=0.000100
[2025-08-27 18:01:39,355][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090008] [Batch 00688/03080] [00:08:25/00:29:16, 0.734s/it]: train_loss_raw=0.3391, running_loss=0.3209, LR=0.000100
[2025-08-27 18:01:45,481][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090016] [Batch 00696/03080] [00:08:31/00:29:11, 0.735s/it]: train_loss_raw=0.2553, running_loss=0.3209, LR=0.000100
[2025-08-27 18:01:51,406][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090024] [Batch 00704/03080] [00:08:37/00:29:05, 0.735s/it]: train_loss_raw=0.3017, running_loss=0.3213, LR=0.000100
[2025-08-27 18:01:57,213][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090032] [Batch 00712/03080] [00:08:43/00:28:59, 0.735s/it]: train_loss_raw=0.3194, running_loss=0.3229, LR=0.000100
[2025-08-27 18:02:03,351][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090040] [Batch 00720/03080] [00:08:49/00:28:54, 0.735s/it]: train_loss_raw=0.3750, running_loss=0.3234, LR=0.000100
[2025-08-27 18:02:09,108][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090048] [Batch 00728/03080] [00:08:54/00:28:48, 0.735s/it]: train_loss_raw=0.3699, running_loss=0.3240, LR=0.000100
[2025-08-27 18:02:14,510][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090056] [Batch 00736/03080] [00:09:00/00:28:40, 0.734s/it]: train_loss_raw=0.3231, running_loss=0.3226, LR=0.000100
[2025-08-27 18:02:20,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090064] [Batch 00744/03080] [00:09:05/00:28:34, 0.734s/it]: train_loss_raw=0.3040, running_loss=0.3227, LR=0.000100
[2025-08-27 18:02:25,896][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090072] [Batch 00752/03080] [00:09:11/00:28:28, 0.734s/it]: train_loss_raw=0.3228, running_loss=0.3226, LR=0.000100
[2025-08-27 18:02:31,815][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090080] [Batch 00760/03080] [00:09:17/00:28:22, 0.734s/it]: train_loss_raw=0.4371, running_loss=0.3216, LR=0.000100
[2025-08-27 18:02:37,657][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090088] [Batch 00768/03080] [00:09:23/00:28:16, 0.734s/it]: train_loss_raw=0.3469, running_loss=0.3231, LR=0.000100
[2025-08-27 18:02:43,094][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090096] [Batch 00776/03080] [00:09:28/00:28:09, 0.733s/it]: train_loss_raw=0.4276, running_loss=0.3254, LR=0.000100
[2025-08-27 18:02:48,863][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090104] [Batch 00784/03080] [00:09:34/00:28:03, 0.733s/it]: train_loss_raw=0.2920, running_loss=0.3253, LR=0.000100
[2025-08-27 18:02:54,897][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090112] [Batch 00792/03080] [00:09:40/00:27:57, 0.733s/it]: train_loss_raw=0.3035, running_loss=0.3259, LR=0.000100
[2025-08-27 18:03:00,883][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090120] [Batch 00800/03080] [00:09:46/00:27:52, 0.733s/it]: train_loss_raw=0.3707, running_loss=0.3260, LR=0.000100
[2025-08-27 18:03:06,952][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090128] [Batch 00808/03080] [00:09:52/00:27:46, 0.734s/it]: train_loss_raw=0.3971, running_loss=0.3260, LR=0.000100
[2025-08-27 18:03:12,823][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090136] [Batch 00816/03080] [00:09:58/00:27:40, 0.734s/it]: train_loss_raw=0.2895, running_loss=0.3247, LR=0.000100
[2025-08-27 18:03:18,529][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090144] [Batch 00824/03080] [00:10:04/00:27:34, 0.733s/it]: train_loss_raw=0.2710, running_loss=0.3228, LR=0.000100
[2025-08-27 18:03:23,908][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090152] [Batch 00832/03080] [00:10:09/00:27:27, 0.733s/it]: train_loss_raw=0.4306, running_loss=0.3236, LR=0.000100
[2025-08-27 18:03:29,309][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090160] [Batch 00840/03080] [00:10:15/00:27:20, 0.732s/it]: train_loss_raw=0.3079, running_loss=0.3249, LR=0.000100
[2025-08-27 18:03:34,902][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090168] [Batch 00848/03080] [00:10:20/00:27:13, 0.732s/it]: train_loss_raw=0.3323, running_loss=0.3253, LR=0.000100
[2025-08-27 18:03:40,901][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090176] [Batch 00856/03080] [00:10:26/00:27:08, 0.732s/it]: train_loss_raw=0.2827, running_loss=0.3242, LR=0.000100
[2025-08-27 18:03:46,737][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090184] [Batch 00864/03080] [00:10:32/00:27:02, 0.732s/it]: train_loss_raw=0.3700, running_loss=0.3270, LR=0.000100
[2025-08-27 18:03:52,949][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090192] [Batch 00872/03080] [00:10:38/00:26:57, 0.733s/it]: train_loss_raw=0.3020, running_loss=0.3264, LR=0.000100
[2025-08-27 18:03:58,946][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090200] [Batch 00880/03080] [00:10:44/00:26:51, 0.733s/it]: train_loss_raw=0.3952, running_loss=0.3261, LR=0.000100
[2025-08-27 18:04:04,746][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090208] [Batch 00888/03080] [00:10:50/00:26:45, 0.733s/it]: train_loss_raw=0.2984, running_loss=0.3266, LR=0.000100
[2025-08-27 18:04:10,513][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090216] [Batch 00896/03080] [00:10:56/00:26:39, 0.733s/it]: train_loss_raw=0.2490, running_loss=0.3262, LR=0.000100
[2025-08-27 18:04:16,240][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090224] [Batch 00904/03080] [00:11:02/00:26:33, 0.732s/it]: train_loss_raw=0.3966, running_loss=0.3275, LR=0.000100
[2025-08-27 18:04:22,251][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090232] [Batch 00912/03080] [00:11:08/00:26:28, 0.733s/it]: train_loss_raw=0.4026, running_loss=0.3278, LR=0.000100
[2025-08-27 18:04:28,250][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090240] [Batch 00920/03080] [00:11:14/00:26:22, 0.733s/it]: train_loss_raw=0.3462, running_loss=0.3281, LR=0.000100
[2025-08-27 18:04:34,279][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090248] [Batch 00928/03080] [00:11:20/00:26:17, 0.733s/it]: train_loss_raw=0.2593, running_loss=0.3273, LR=0.000100
[2025-08-27 18:04:39,630][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090256] [Batch 00936/03080] [00:11:25/00:26:10, 0.732s/it]: train_loss_raw=0.3481, running_loss=0.3245, LR=0.000100
[2025-08-27 18:04:45,156][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090264] [Batch 00944/03080] [00:11:30/00:26:03, 0.732s/it]: train_loss_raw=0.2485, running_loss=0.3237, LR=0.000100
[2025-08-27 18:04:50,859][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090272] [Batch 00952/03080] [00:11:36/00:25:57, 0.732s/it]: train_loss_raw=0.2910, running_loss=0.3215, LR=0.000100
[2025-08-27 18:04:56,314][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090280] [Batch 00960/03080] [00:11:42/00:25:50, 0.731s/it]: train_loss_raw=0.3529, running_loss=0.3205, LR=0.000100
[2025-08-27 18:05:02,063][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090288] [Batch 00968/03080] [00:11:47/00:25:44, 0.731s/it]: train_loss_raw=0.2995, running_loss=0.3197, LR=0.000100
[2025-08-27 18:05:07,604][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090296] [Batch 00976/03080] [00:11:53/00:25:37, 0.731s/it]: train_loss_raw=0.3184, running_loss=0.3204, LR=0.000100
[2025-08-27 18:05:13,569][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090304] [Batch 00984/03080] [00:11:59/00:25:32, 0.731s/it]: train_loss_raw=0.3248, running_loss=0.3204, LR=0.000100
[2025-08-27 18:05:19,218][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090312] [Batch 00992/03080] [00:12:05/00:25:26, 0.731s/it]: train_loss_raw=0.3154, running_loss=0.3214, LR=0.000100
[2025-08-27 18:05:25,018][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090320] [Batch 01000/03080] [00:12:10/00:25:20, 0.731s/it]: train_loss_raw=0.2929, running_loss=0.3222, LR=0.000100
[2025-08-27 18:05:30,759][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090328] [Batch 01008/03080] [00:12:16/00:25:14, 0.731s/it]: train_loss_raw=0.2426, running_loss=0.3203, LR=0.000100
[2025-08-27 18:05:36,416][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090336] [Batch 01016/03080] [00:12:22/00:25:07, 0.731s/it]: train_loss_raw=0.4142, running_loss=0.3209, LR=0.000100
[2025-08-27 18:05:42,203][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090344] [Batch 01024/03080] [00:12:28/00:25:01, 0.731s/it]: train_loss_raw=0.3200, running_loss=0.3209, LR=0.000100
[2025-08-27 18:05:47,778][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090352] [Batch 01032/03080] [00:12:33/00:24:55, 0.730s/it]: train_loss_raw=0.3815, running_loss=0.3231, LR=0.000100
[2025-08-27 18:05:53,444][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090360] [Batch 01040/03080] [00:12:39/00:24:49, 0.730s/it]: train_loss_raw=0.4121, running_loss=0.3247, LR=0.000100
[2025-08-27 18:05:59,056][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090368] [Batch 01048/03080] [00:12:44/00:24:43, 0.730s/it]: train_loss_raw=0.2331, running_loss=0.3249, LR=0.000100
[2025-08-27 18:06:05,234][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090376] [Batch 01056/03080] [00:12:51/00:24:37, 0.730s/it]: train_loss_raw=0.3204, running_loss=0.3244, LR=0.000100
[2025-08-27 18:06:11,290][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090384] [Batch 01064/03080] [00:12:57/00:24:32, 0.730s/it]: train_loss_raw=0.3371, running_loss=0.3243, LR=0.000100
[2025-08-27 18:06:17,583][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090392] [Batch 01072/03080] [00:13:03/00:24:27, 0.731s/it]: train_loss_raw=0.2803, running_loss=0.3258, LR=0.000100
[2025-08-27 18:06:23,624][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090400] [Batch 01080/03080] [00:13:09/00:24:21, 0.731s/it]: train_loss_raw=0.3311, running_loss=0.3258, LR=0.000100
[2025-08-27 18:06:29,368][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090408] [Batch 01088/03080] [00:13:15/00:24:15, 0.731s/it]: train_loss_raw=0.3628, running_loss=0.3266, LR=0.000100
[2025-08-27 18:06:35,354][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090416] [Batch 01096/03080] [00:13:21/00:24:10, 0.731s/it]: train_loss_raw=0.3076, running_loss=0.3274, LR=0.000100
[2025-08-27 18:06:41,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090424] [Batch 01104/03080] [00:13:26/00:24:04, 0.731s/it]: train_loss_raw=0.3754, running_loss=0.3268, LR=0.000100
[2025-08-27 18:06:46,753][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090432] [Batch 01112/03080] [00:13:32/00:23:58, 0.731s/it]: train_loss_raw=0.2995, running_loss=0.3240, LR=0.000100
[2025-08-27 18:06:52,718][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090440] [Batch 01120/03080] [00:13:38/00:23:52, 0.731s/it]: train_loss_raw=0.2943, running_loss=0.3236, LR=0.000100
[2025-08-27 18:06:58,715][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090448] [Batch 01128/03080] [00:13:44/00:23:46, 0.731s/it]: train_loss_raw=0.2516, running_loss=0.3225, LR=0.000100
[2025-08-27 18:07:04,555][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090456] [Batch 01136/03080] [00:13:50/00:23:41, 0.731s/it]: train_loss_raw=0.3919, running_loss=0.3236, LR=0.000100
[2025-08-27 18:07:10,223][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090464] [Batch 01144/03080] [00:13:56/00:23:34, 0.731s/it]: train_loss_raw=0.3500, running_loss=0.3232, LR=0.000100
[2025-08-27 18:07:16,135][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090472] [Batch 01152/03080] [00:14:01/00:23:29, 0.731s/it]: train_loss_raw=0.2867, running_loss=0.3251, LR=0.000100
[2025-08-27 18:07:22,108][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090480] [Batch 01160/03080] [00:14:07/00:23:23, 0.731s/it]: train_loss_raw=0.2954, running_loss=0.3243, LR=0.000100
[2025-08-27 18:07:28,212][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090488] [Batch 01168/03080] [00:14:14/00:23:18, 0.731s/it]: train_loss_raw=0.3051, running_loss=0.3231, LR=0.000100
[2025-08-27 18:07:33,763][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090496] [Batch 01176/03080] [00:14:19/00:23:11, 0.731s/it]: train_loss_raw=0.2785, running_loss=0.3229, LR=0.000100
[2025-08-27 18:07:39,130][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090504] [Batch 01184/03080] [00:14:24/00:23:05, 0.731s/it]: train_loss_raw=0.3814, running_loss=0.3254, LR=0.000100
[2025-08-27 18:07:44,517][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090512] [Batch 01192/03080] [00:14:30/00:22:58, 0.730s/it]: train_loss_raw=0.3739, running_loss=0.3242, LR=0.000100
[2025-08-27 18:07:50,336][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090520] [Batch 01200/03080] [00:14:36/00:22:52, 0.730s/it]: train_loss_raw=0.3056, running_loss=0.3240, LR=0.000100
[2025-08-27 18:07:55,703][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090528] [Batch 01208/03080] [00:14:41/00:22:46, 0.730s/it]: train_loss_raw=0.3488, running_loss=0.3248, LR=0.000100
[2025-08-27 18:08:01,459][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090536] [Batch 01216/03080] [00:14:47/00:22:40, 0.730s/it]: train_loss_raw=0.3568, running_loss=0.3274, LR=0.000100
[2025-08-27 18:08:07,619][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090544] [Batch 01224/03080] [00:14:53/00:22:34, 0.730s/it]: train_loss_raw=0.2975, running_loss=0.3271, LR=0.000100
[2025-08-27 18:08:13,777][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090552] [Batch 01232/03080] [00:14:59/00:22:29, 0.730s/it]: train_loss_raw=0.2565, running_loss=0.3267, LR=0.000100
[2025-08-27 18:08:19,484][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090560] [Batch 01240/03080] [00:15:05/00:22:23, 0.730s/it]: train_loss_raw=0.3161, running_loss=0.3245, LR=0.000100
[2025-08-27 18:08:25,504][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090568] [Batch 01248/03080] [00:15:11/00:22:17, 0.730s/it]: train_loss_raw=0.2874, running_loss=0.3249, LR=0.000100
[2025-08-27 18:08:31,892][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090576] [Batch 01256/03080] [00:15:17/00:22:12, 0.731s/it]: train_loss_raw=0.3030, running_loss=0.3247, LR=0.000100
[2025-08-27 18:08:37,681][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090584] [Batch 01264/03080] [00:15:23/00:22:06, 0.731s/it]: train_loss_raw=0.3352, running_loss=0.3255, LR=0.000100
[2025-08-27 18:08:43,449][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090592] [Batch 01272/03080] [00:15:29/00:22:00, 0.731s/it]: train_loss_raw=0.3067, running_loss=0.3240, LR=0.000100
[2025-08-27 18:08:49,610][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090600] [Batch 01280/03080] [00:15:35/00:21:55, 0.731s/it]: train_loss_raw=0.3719, running_loss=0.3244, LR=0.000100
[2025-08-27 18:08:55,831][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090608] [Batch 01288/03080] [00:15:41/00:21:50, 0.731s/it]: train_loss_raw=0.2687, running_loss=0.3256, LR=0.000100
[2025-08-27 18:09:01,617][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090616] [Batch 01296/03080] [00:15:47/00:21:44, 0.731s/it]: train_loss_raw=0.2963, running_loss=0.3254, LR=0.000100
[2025-08-27 18:09:07,844][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090624] [Batch 01304/03080] [00:15:53/00:21:38, 0.731s/it]: train_loss_raw=0.2866, running_loss=0.3234, LR=0.000100
[2025-08-27 18:09:13,983][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090632] [Batch 01312/03080] [00:15:59/00:21:33, 0.732s/it]: train_loss_raw=0.3066, running_loss=0.3230, LR=0.000100
[2025-08-27 18:09:19,677][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090640] [Batch 01320/03080] [00:16:05/00:21:27, 0.731s/it]: train_loss_raw=0.3628, running_loss=0.3228, LR=0.000100
[2025-08-27 18:09:25,608][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090648] [Batch 01328/03080] [00:16:11/00:21:21, 0.732s/it]: train_loss_raw=0.3390, running_loss=0.3213, LR=0.000100
[2025-08-27 18:09:31,152][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090656] [Batch 01336/03080] [00:16:16/00:21:15, 0.731s/it]: train_loss_raw=0.3773, running_loss=0.3230, LR=0.000100
[2025-08-27 18:09:36,971][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090664] [Batch 01344/03080] [00:16:22/00:21:09, 0.731s/it]: train_loss_raw=0.2936, running_loss=0.3237, LR=0.000100
[2025-08-27 18:09:42,832][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090672] [Batch 01352/03080] [00:16:28/00:21:03, 0.731s/it]: train_loss_raw=0.3092, running_loss=0.3222, LR=0.000100
[2025-08-27 18:09:48,222][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090680] [Batch 01360/03080] [00:16:34/00:20:57, 0.731s/it]: train_loss_raw=0.3481, running_loss=0.3206, LR=0.000100
[2025-08-27 18:09:53,934][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090688] [Batch 01368/03080] [00:16:39/00:20:51, 0.731s/it]: train_loss_raw=0.3654, running_loss=0.3215, LR=0.000100
[2025-08-27 18:10:00,047][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090696] [Batch 01376/03080] [00:16:45/00:20:45, 0.731s/it]: train_loss_raw=0.2772, running_loss=0.3204, LR=0.000100
[2025-08-27 18:10:06,028][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090704] [Batch 01384/03080] [00:16:51/00:20:39, 0.731s/it]: train_loss_raw=0.2229, running_loss=0.3193, LR=0.000100
[2025-08-27 18:10:11,706][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090712] [Batch 01392/03080] [00:16:57/00:20:33, 0.731s/it]: train_loss_raw=0.3180, running_loss=0.3177, LR=0.000100
[2025-08-27 18:10:17,203][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090720] [Batch 01400/03080] [00:17:03/00:20:27, 0.731s/it]: train_loss_raw=0.3578, running_loss=0.3193, LR=0.000100
[2025-08-27 18:10:22,936][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090728] [Batch 01408/03080] [00:17:08/00:20:21, 0.731s/it]: train_loss_raw=0.4320, running_loss=0.3202, LR=0.000100
[2025-08-27 18:10:28,667][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090736] [Batch 01416/03080] [00:17:14/00:20:15, 0.731s/it]: train_loss_raw=0.3177, running_loss=0.3186, LR=0.000100
[2025-08-27 18:10:34,179][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090744] [Batch 01424/03080] [00:17:20/00:20:09, 0.730s/it]: train_loss_raw=0.3075, running_loss=0.3178, LR=0.000100
[2025-08-27 18:10:40,243][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090752] [Batch 01432/03080] [00:17:26/00:20:03, 0.731s/it]: train_loss_raw=0.2658, running_loss=0.3171, LR=0.000100
[2025-08-27 18:10:46,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090760] [Batch 01440/03080] [00:17:31/00:19:58, 0.731s/it]: train_loss_raw=0.2796, running_loss=0.3166, LR=0.000100
[2025-08-27 18:10:51,983][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090768] [Batch 01448/03080] [00:17:37/00:19:52, 0.731s/it]: train_loss_raw=0.3306, running_loss=0.3159, LR=0.000100
[2025-08-27 18:10:57,993][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090776] [Batch 01456/03080] [00:17:43/00:19:46, 0.731s/it]: train_loss_raw=0.3318, running_loss=0.3165, LR=0.000100
[2025-08-27 18:11:04,198][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090784] [Batch 01464/03080] [00:17:50/00:19:41, 0.731s/it]: train_loss_raw=0.2942, running_loss=0.3154, LR=0.000100
[2025-08-27 18:11:10,118][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090792] [Batch 01472/03080] [00:17:55/00:19:35, 0.731s/it]: train_loss_raw=0.3137, running_loss=0.3151, LR=0.000100
[2025-08-27 18:11:16,183][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090800] [Batch 01480/03080] [00:18:02/00:19:29, 0.731s/it]: train_loss_raw=0.2696, running_loss=0.3167, LR=0.000100
[2025-08-27 18:11:21,575][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090808] [Batch 01488/03080] [00:18:07/00:19:23, 0.731s/it]: train_loss_raw=0.3121, running_loss=0.3167, LR=0.000100
[2025-08-27 18:11:27,052][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090816] [Batch 01496/03080] [00:18:12/00:19:17, 0.731s/it]: train_loss_raw=0.2792, running_loss=0.3156, LR=0.000100
[2025-08-27 18:11:32,492][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090824] [Batch 01504/03080] [00:18:18/00:19:10, 0.730s/it]: train_loss_raw=0.3117, running_loss=0.3160, LR=0.000100
[2025-08-27 18:11:38,242][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090832] [Batch 01512/03080] [00:18:24/00:19:04, 0.730s/it]: train_loss_raw=0.2879, running_loss=0.3161, LR=0.000100
[2025-08-27 18:11:43,761][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090840] [Batch 01520/03080] [00:18:29/00:18:58, 0.730s/it]: train_loss_raw=0.3269, running_loss=0.3174, LR=0.000100
[2025-08-27 18:11:49,476][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090848] [Batch 01528/03080] [00:18:35/00:18:52, 0.730s/it]: train_loss_raw=0.3368, running_loss=0.3194, LR=0.000100
[2025-08-27 18:11:54,901][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090856] [Batch 01536/03080] [00:18:40/00:18:46, 0.730s/it]: train_loss_raw=0.3674, running_loss=0.3192, LR=0.000100
[2025-08-27 18:12:00,444][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090864] [Batch 01544/03080] [00:18:46/00:18:40, 0.729s/it]: train_loss_raw=0.4311, running_loss=0.3197, LR=0.000100
[2025-08-27 18:12:06,218][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090872] [Batch 01552/03080] [00:18:52/00:18:34, 0.729s/it]: train_loss_raw=0.3139, running_loss=0.3202, LR=0.000100
[2025-08-27 18:12:11,950][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090880] [Batch 01560/03080] [00:18:57/00:18:28, 0.729s/it]: train_loss_raw=0.3075, running_loss=0.3221, LR=0.000100
[2025-08-27 18:12:17,380][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090888] [Batch 01568/03080] [00:19:03/00:18:22, 0.729s/it]: train_loss_raw=0.3985, running_loss=0.3215, LR=0.000100
[2025-08-27 18:12:22,795][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090896] [Batch 01576/03080] [00:19:08/00:18:16, 0.729s/it]: train_loss_raw=0.3113, running_loss=0.3198, LR=0.000100
[2025-08-27 18:12:28,797][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090904] [Batch 01584/03080] [00:19:14/00:18:10, 0.729s/it]: train_loss_raw=0.3929, running_loss=0.3217, LR=0.000100
[2025-08-27 18:12:34,659][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090912] [Batch 01592/03080] [00:19:20/00:18:04, 0.729s/it]: train_loss_raw=0.2709, running_loss=0.3213, LR=0.000100
[2025-08-27 18:12:40,350][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090920] [Batch 01600/03080] [00:19:26/00:17:58, 0.729s/it]: train_loss_raw=0.2888, running_loss=0.3203, LR=0.000100
[2025-08-27 18:12:46,397][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090928] [Batch 01608/03080] [00:19:32/00:17:53, 0.729s/it]: train_loss_raw=0.3705, running_loss=0.3210, LR=0.000100
[2025-08-27 18:12:52,203][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090936] [Batch 01616/03080] [00:19:38/00:17:47, 0.729s/it]: train_loss_raw=0.3288, running_loss=0.3204, LR=0.000100
[2025-08-27 18:12:58,103][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090944] [Batch 01624/03080] [00:19:43/00:17:41, 0.729s/it]: train_loss_raw=0.2780, running_loss=0.3195, LR=0.000100
[2025-08-27 18:13:03,783][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090952] [Batch 01632/03080] [00:19:49/00:17:35, 0.729s/it]: train_loss_raw=0.2786, running_loss=0.3182, LR=0.000100
[2025-08-27 18:13:09,568][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090960] [Batch 01640/03080] [00:19:55/00:17:29, 0.729s/it]: train_loss_raw=0.2906, running_loss=0.3185, LR=0.000100
[2025-08-27 18:13:15,093][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090968] [Batch 01648/03080] [00:20:00/00:17:23, 0.729s/it]: train_loss_raw=0.2928, running_loss=0.3168, LR=0.000100
[2025-08-27 18:13:20,708][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090976] [Batch 01656/03080] [00:20:06/00:17:17, 0.729s/it]: train_loss_raw=0.3102, running_loss=0.3192, LR=0.000100
[2025-08-27 18:13:26,694][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090984] [Batch 01664/03080] [00:20:12/00:17:11, 0.729s/it]: train_loss_raw=0.3915, running_loss=0.3196, LR=0.000100
[2025-08-27 18:13:32,313][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 090992] [Batch 01672/03080] [00:20:18/00:17:05, 0.729s/it]: train_loss_raw=0.3422, running_loss=0.3185, LR=0.000100
[2025-08-27 18:13:38,181][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091000] [Batch 01680/03080] [00:20:24/00:17:00, 0.729s/it]: train_loss_raw=0.2909, running_loss=0.3184, LR=0.000100
[2025-08-27 18:13:43,695][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091008] [Batch 01688/03080] [00:20:29/00:16:53, 0.728s/it]: train_loss_raw=0.3531, running_loss=0.3194, LR=0.000100
[2025-08-27 18:13:49,178][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091016] [Batch 01696/03080] [00:20:35/00:16:47, 0.728s/it]: train_loss_raw=0.3046, running_loss=0.3183, LR=0.000100
[2025-08-27 18:13:54,554][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091024] [Batch 01704/03080] [00:20:40/00:16:41, 0.728s/it]: train_loss_raw=0.3667, running_loss=0.3173, LR=0.000100
[2025-08-27 18:14:00,244][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091032] [Batch 01712/03080] [00:20:46/00:16:35, 0.728s/it]: train_loss_raw=0.2987, running_loss=0.3164, LR=0.000100
[2025-08-27 18:14:05,914][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091040] [Batch 01720/03080] [00:20:51/00:16:29, 0.728s/it]: train_loss_raw=0.3189, running_loss=0.3188, LR=0.000100
[2025-08-27 18:14:11,696][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091048] [Batch 01728/03080] [00:20:57/00:16:23, 0.728s/it]: train_loss_raw=0.3244, running_loss=0.3176, LR=0.000100
[2025-08-27 18:14:17,436][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091056] [Batch 01736/03080] [00:21:03/00:16:18, 0.728s/it]: train_loss_raw=0.2199, running_loss=0.3182, LR=0.000100
[2025-08-27 18:14:22,966][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091064] [Batch 01744/03080] [00:21:08/00:16:11, 0.728s/it]: train_loss_raw=0.3329, running_loss=0.3188, LR=0.000100
[2025-08-27 18:14:28,674][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091072] [Batch 01752/03080] [00:21:14/00:16:06, 0.727s/it]: train_loss_raw=0.2906, running_loss=0.3177, LR=0.000100
[2025-08-27 18:14:34,559][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091080] [Batch 01760/03080] [00:21:20/00:16:00, 0.727s/it]: train_loss_raw=0.3319, running_loss=0.3178, LR=0.000100
[2025-08-27 18:14:39,950][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091088] [Batch 01768/03080] [00:21:25/00:15:54, 0.727s/it]: train_loss_raw=0.3206, running_loss=0.3162, LR=0.000100
[2025-08-27 18:14:45,691][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091096] [Batch 01776/03080] [00:21:31/00:15:48, 0.727s/it]: train_loss_raw=0.3838, running_loss=0.3158, LR=0.000100
[2025-08-27 18:14:51,526][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091104] [Batch 01784/03080] [00:21:37/00:15:42, 0.727s/it]: train_loss_raw=0.3552, running_loss=0.3161, LR=0.000100
[2025-08-27 18:14:57,545][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091112] [Batch 01792/03080] [00:21:43/00:15:36, 0.727s/it]: train_loss_raw=0.3507, running_loss=0.3175, LR=0.000100
[2025-08-27 18:15:03,426][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091120] [Batch 01800/03080] [00:21:49/00:15:31, 0.727s/it]: train_loss_raw=0.2641, running_loss=0.3178, LR=0.000100
[2025-08-27 18:15:09,061][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091128] [Batch 01808/03080] [00:21:54/00:15:25, 0.727s/it]: train_loss_raw=0.3721, running_loss=0.3177, LR=0.000100
[2025-08-27 18:15:14,545][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091136] [Batch 01816/03080] [00:22:00/00:15:19, 0.727s/it]: train_loss_raw=0.3006, running_loss=0.3194, LR=0.000100
[2025-08-27 18:15:20,332][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091144] [Batch 01824/03080] [00:22:06/00:15:13, 0.727s/it]: train_loss_raw=0.2974, running_loss=0.3183, LR=0.000100
[2025-08-27 18:15:26,483][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091152] [Batch 01832/03080] [00:22:12/00:15:07, 0.727s/it]: train_loss_raw=0.3506, running_loss=0.3196, LR=0.000100
[2025-08-27 18:15:32,563][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091160] [Batch 01840/03080] [00:22:18/00:15:01, 0.727s/it]: train_loss_raw=0.3190, running_loss=0.3184, LR=0.000100
[2025-08-27 18:15:38,534][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091168] [Batch 01848/03080] [00:22:24/00:14:56, 0.727s/it]: train_loss_raw=0.3652, running_loss=0.3182, LR=0.000100
[2025-08-27 18:15:44,592][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091176] [Batch 01856/03080] [00:22:30/00:14:50, 0.728s/it]: train_loss_raw=0.3865, running_loss=0.3189, LR=0.000100
[2025-08-27 18:15:50,484][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091184] [Batch 01864/03080] [00:22:36/00:14:44, 0.728s/it]: train_loss_raw=0.4019, running_loss=0.3179, LR=0.000100
[2025-08-27 18:15:56,511][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091192] [Batch 01872/03080] [00:22:42/00:14:39, 0.728s/it]: train_loss_raw=0.2962, running_loss=0.3192, LR=0.000100
[2025-08-27 18:16:02,509][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091200] [Batch 01880/03080] [00:22:48/00:14:33, 0.728s/it]: train_loss_raw=0.2306, running_loss=0.3192, LR=0.000100
[2025-08-27 18:16:08,508][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091208] [Batch 01888/03080] [00:22:54/00:14:27, 0.728s/it]: train_loss_raw=0.4009, running_loss=0.3198, LR=0.000100
[2025-08-27 18:16:14,196][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091216] [Batch 01896/03080] [00:23:00/00:14:21, 0.728s/it]: train_loss_raw=0.3284, running_loss=0.3223, LR=0.000100
[2025-08-27 18:16:20,005][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091224] [Batch 01904/03080] [00:23:05/00:14:15, 0.728s/it]: train_loss_raw=0.3770, running_loss=0.3213, LR=0.000100
[2025-08-27 18:16:25,823][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091232] [Batch 01912/03080] [00:23:11/00:14:10, 0.728s/it]: train_loss_raw=0.3426, running_loss=0.3214, LR=0.000100
[2025-08-27 18:16:31,697][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091240] [Batch 01920/03080] [00:23:17/00:14:04, 0.728s/it]: train_loss_raw=0.3219, running_loss=0.3227, LR=0.000100
[2025-08-27 18:16:37,407][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091248] [Batch 01928/03080] [00:23:23/00:13:58, 0.728s/it]: train_loss_raw=0.2997, running_loss=0.3213, LR=0.000100
[2025-08-27 18:16:43,171][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091256] [Batch 01936/03080] [00:23:29/00:13:52, 0.728s/it]: train_loss_raw=0.3035, running_loss=0.3220, LR=0.000100
[2025-08-27 18:16:48,561][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091264] [Batch 01944/03080] [00:23:34/00:13:46, 0.728s/it]: train_loss_raw=0.3608, running_loss=0.3214, LR=0.000100
[2025-08-27 18:16:54,225][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091272] [Batch 01952/03080] [00:23:40/00:13:40, 0.727s/it]: train_loss_raw=0.3579, running_loss=0.3230, LR=0.000100
[2025-08-27 18:16:59,592][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091280] [Batch 01960/03080] [00:23:45/00:13:34, 0.727s/it]: train_loss_raw=0.3238, running_loss=0.3236, LR=0.000100
[2025-08-27 18:17:05,279][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091288] [Batch 01968/03080] [00:23:51/00:13:28, 0.727s/it]: train_loss_raw=0.2430, running_loss=0.3225, LR=0.000100
[2025-08-27 18:17:11,362][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091296] [Batch 01976/03080] [00:23:57/00:13:22, 0.727s/it]: train_loss_raw=0.3542, running_loss=0.3220, LR=0.000100
[2025-08-27 18:17:17,368][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091304] [Batch 01984/03080] [00:24:03/00:13:17, 0.727s/it]: train_loss_raw=0.2448, running_loss=0.3202, LR=0.000100
[2025-08-27 18:17:23,205][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091312] [Batch 01992/03080] [00:24:09/00:13:11, 0.727s/it]: train_loss_raw=0.2615, running_loss=0.3197, LR=0.000100
[2025-08-27 18:17:28,871][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091320] [Batch 02000/03080] [00:24:14/00:13:05, 0.727s/it]: train_loss_raw=0.3563, running_loss=0.3225, LR=0.000100
[2025-08-27 18:17:34,865][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091328] [Batch 02008/03080] [00:24:20/00:12:59, 0.727s/it]: train_loss_raw=0.3771, running_loss=0.3235, LR=0.000100
[2025-08-27 18:17:40,531][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091336] [Batch 02016/03080] [00:24:26/00:12:53, 0.727s/it]: train_loss_raw=0.2709, running_loss=0.3235, LR=0.000100
[2025-08-27 18:17:46,163][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091344] [Batch 02024/03080] [00:24:31/00:12:47, 0.727s/it]: train_loss_raw=0.2639, running_loss=0.3229, LR=0.000100
[2025-08-27 18:17:52,066][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091352] [Batch 02032/03080] [00:24:37/00:12:42, 0.727s/it]: train_loss_raw=0.2207, running_loss=0.3222, LR=0.000100
[2025-08-27 18:17:57,915][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091360] [Batch 02040/03080] [00:24:43/00:12:36, 0.727s/it]: train_loss_raw=0.3707, running_loss=0.3240, LR=0.000100
[2025-08-27 18:18:03,646][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091368] [Batch 02048/03080] [00:24:49/00:12:30, 0.727s/it]: train_loss_raw=0.3144, running_loss=0.3233, LR=0.000100
[2025-08-27 18:18:09,625][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091376] [Batch 02056/03080] [00:24:55/00:12:24, 0.727s/it]: train_loss_raw=0.2886, running_loss=0.3230, LR=0.000100
[2025-08-27 18:18:15,196][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091384] [Batch 02064/03080] [00:25:01/00:12:18, 0.727s/it]: train_loss_raw=0.3512, running_loss=0.3239, LR=0.000100
[2025-08-27 18:18:21,092][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091392] [Batch 02072/03080] [00:25:06/00:12:13, 0.727s/it]: train_loss_raw=0.3576, running_loss=0.3239, LR=0.000100
[2025-08-27 18:18:27,030][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091400] [Batch 02080/03080] [00:25:12/00:12:07, 0.727s/it]: train_loss_raw=0.2899, running_loss=0.3234, LR=0.000100
[2025-08-27 18:18:32,884][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091408] [Batch 02088/03080] [00:25:18/00:12:01, 0.727s/it]: train_loss_raw=0.3448, running_loss=0.3238, LR=0.000100
[2025-08-27 18:18:38,267][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091416] [Batch 02096/03080] [00:25:24/00:11:55, 0.727s/it]: train_loss_raw=0.2629, running_loss=0.3228, LR=0.000100
[2025-08-27 18:18:44,040][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091424] [Batch 02104/03080] [00:25:29/00:11:49, 0.727s/it]: train_loss_raw=0.3434, running_loss=0.3229, LR=0.000100
[2025-08-27 18:18:49,995][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091432] [Batch 02112/03080] [00:25:35/00:11:43, 0.727s/it]: train_loss_raw=0.4086, running_loss=0.3227, LR=0.000100
[2025-08-27 18:18:55,738][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091440] [Batch 02120/03080] [00:25:41/00:11:38, 0.727s/it]: train_loss_raw=0.3083, running_loss=0.3230, LR=0.000100
[2025-08-27 18:19:01,502][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091448] [Batch 02128/03080] [00:25:47/00:11:32, 0.727s/it]: train_loss_raw=0.3984, running_loss=0.3243, LR=0.000100
[2025-08-27 18:19:07,401][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091456] [Batch 02136/03080] [00:25:53/00:11:26, 0.727s/it]: train_loss_raw=0.3802, running_loss=0.3255, LR=0.000100
[2025-08-27 18:19:12,819][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091464] [Batch 02144/03080] [00:25:58/00:11:20, 0.727s/it]: train_loss_raw=0.3108, running_loss=0.3252, LR=0.000100
[2025-08-27 18:19:18,488][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091472] [Batch 02152/03080] [00:26:04/00:11:14, 0.727s/it]: train_loss_raw=0.3303, running_loss=0.3253, LR=0.000100
[2025-08-27 18:19:24,484][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091480] [Batch 02160/03080] [00:26:10/00:11:08, 0.727s/it]: train_loss_raw=0.3017, running_loss=0.3233, LR=0.000100
[2025-08-27 18:19:30,117][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091488] [Batch 02168/03080] [00:26:15/00:11:02, 0.727s/it]: train_loss_raw=0.3194, running_loss=0.3242, LR=0.000100
[2025-08-27 18:19:35,900][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091496] [Batch 02176/03080] [00:26:21/00:10:57, 0.727s/it]: train_loss_raw=0.3099, running_loss=0.3240, LR=0.000100
[2025-08-27 18:19:41,775][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091504] [Batch 02184/03080] [00:26:27/00:10:51, 0.727s/it]: train_loss_raw=0.3890, running_loss=0.3259, LR=0.000100
[2025-08-27 18:19:47,468][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091512] [Batch 02192/03080] [00:26:33/00:10:45, 0.727s/it]: train_loss_raw=0.4125, running_loss=0.3260, LR=0.000100
[2025-08-27 18:19:53,141][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091520] [Batch 02200/03080] [00:26:38/00:10:39, 0.727s/it]: train_loss_raw=0.3767, running_loss=0.3250, LR=0.000100
[2025-08-27 18:19:58,711][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091528] [Batch 02208/03080] [00:26:44/00:10:33, 0.727s/it]: train_loss_raw=0.3139, running_loss=0.3242, LR=0.000100
[2025-08-27 18:20:04,140][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091536] [Batch 02216/03080] [00:26:49/00:10:27, 0.727s/it]: train_loss_raw=0.2862, running_loss=0.3244, LR=0.000100
[2025-08-27 18:20:10,218][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091544] [Batch 02224/03080] [00:26:56/00:10:22, 0.727s/it]: train_loss_raw=0.4078, running_loss=0.3264, LR=0.000100
[2025-08-27 18:20:15,963][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091552] [Batch 02232/03080] [00:27:01/00:10:16, 0.727s/it]: train_loss_raw=0.4026, running_loss=0.3264, LR=0.000100
[2025-08-27 18:20:21,693][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091560] [Batch 02240/03080] [00:27:07/00:10:10, 0.727s/it]: train_loss_raw=0.4890, running_loss=0.3261, LR=0.000100
[2025-08-27 18:20:27,413][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091568] [Batch 02248/03080] [00:27:13/00:10:04, 0.727s/it]: train_loss_raw=0.3376, running_loss=0.3250, LR=0.000100
[2025-08-27 18:20:33,240][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091576] [Batch 02256/03080] [00:27:19/00:09:58, 0.727s/it]: train_loss_raw=0.2523, running_loss=0.3246, LR=0.000100
[2025-08-27 18:20:39,172][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091584] [Batch 02264/03080] [00:27:25/00:09:52, 0.727s/it]: train_loss_raw=0.2693, running_loss=0.3238, LR=0.000100
[2025-08-27 18:20:44,908][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091592] [Batch 02272/03080] [00:27:30/00:09:47, 0.727s/it]: train_loss_raw=0.3191, running_loss=0.3247, LR=0.000100
[2025-08-27 18:20:50,719][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091600] [Batch 02280/03080] [00:27:36/00:09:41, 0.727s/it]: train_loss_raw=0.3068, running_loss=0.3256, LR=0.000100
[2025-08-27 18:20:56,730][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091608] [Batch 02288/03080] [00:27:42/00:09:35, 0.727s/it]: train_loss_raw=0.2956, running_loss=0.3242, LR=0.000100
[2025-08-27 18:21:02,872][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091616] [Batch 02296/03080] [00:27:48/00:09:29, 0.727s/it]: train_loss_raw=0.3219, running_loss=0.3252, LR=0.000100
[2025-08-27 18:21:08,664][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091624] [Batch 02304/03080] [00:27:54/00:09:23, 0.727s/it]: train_loss_raw=0.3175, running_loss=0.3244, LR=0.000100
[2025-08-27 18:21:14,441][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091632] [Batch 02312/03080] [00:28:00/00:09:18, 0.727s/it]: train_loss_raw=0.3344, running_loss=0.3249, LR=0.000100
[2025-08-27 18:21:20,489][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091640] [Batch 02320/03080] [00:28:06/00:09:12, 0.727s/it]: train_loss_raw=0.2840, running_loss=0.3270, LR=0.000100
[2025-08-27 18:21:26,328][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091648] [Batch 02328/03080] [00:28:12/00:09:06, 0.727s/it]: train_loss_raw=0.3271, running_loss=0.3266, LR=0.000100
[2025-08-27 18:21:32,297][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091656] [Batch 02336/03080] [00:28:18/00:09:00, 0.727s/it]: train_loss_raw=0.3766, running_loss=0.3261, LR=0.000100
[2025-08-27 18:21:38,076][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091664] [Batch 02344/03080] [00:28:23/00:08:55, 0.727s/it]: train_loss_raw=0.2933, running_loss=0.3247, LR=0.000100
[2025-08-27 18:21:43,683][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091672] [Batch 02352/03080] [00:28:29/00:08:49, 0.727s/it]: train_loss_raw=0.3890, running_loss=0.3260, LR=0.000100
[2025-08-27 18:21:49,482][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091680] [Batch 02360/03080] [00:28:35/00:08:43, 0.727s/it]: train_loss_raw=0.3360, running_loss=0.3259, LR=0.000100
[2025-08-27 18:21:55,023][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091688] [Batch 02368/03080] [00:28:40/00:08:37, 0.727s/it]: train_loss_raw=0.3287, running_loss=0.3257, LR=0.000100
[2025-08-27 18:22:01,148][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091696] [Batch 02376/03080] [00:28:46/00:08:31, 0.727s/it]: train_loss_raw=0.3058, running_loss=0.3251, LR=0.000100
[2025-08-27 18:22:06,975][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091704] [Batch 02384/03080] [00:28:52/00:08:25, 0.727s/it]: train_loss_raw=0.3979, running_loss=0.3245, LR=0.000100
[2025-08-27 18:22:12,572][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091712] [Batch 02392/03080] [00:28:58/00:08:20, 0.727s/it]: train_loss_raw=0.3171, running_loss=0.3244, LR=0.000100
[2025-08-27 18:22:18,601][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091720] [Batch 02400/03080] [00:29:04/00:08:14, 0.727s/it]: train_loss_raw=0.2858, running_loss=0.3255, LR=0.000100
[2025-08-27 18:22:24,462][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091728] [Batch 02408/03080] [00:29:10/00:08:08, 0.727s/it]: train_loss_raw=0.3366, running_loss=0.3258, LR=0.000100
[2025-08-27 18:22:30,162][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091736] [Batch 02416/03080] [00:29:15/00:08:02, 0.727s/it]: train_loss_raw=0.3231, running_loss=0.3229, LR=0.000100
[2025-08-27 18:22:35,965][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091744] [Batch 02424/03080] [00:29:21/00:07:56, 0.727s/it]: train_loss_raw=0.3189, running_loss=0.3231, LR=0.000100
[2025-08-27 18:22:41,775][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091752] [Batch 02432/03080] [00:29:27/00:07:50, 0.727s/it]: train_loss_raw=0.2923, running_loss=0.3218, LR=0.000100
[2025-08-27 18:22:47,405][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091760] [Batch 02440/03080] [00:29:33/00:07:45, 0.727s/it]: train_loss_raw=0.2459, running_loss=0.3213, LR=0.000100
[2025-08-27 18:22:52,955][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091768] [Batch 02448/03080] [00:29:38/00:07:39, 0.727s/it]: train_loss_raw=0.3455, running_loss=0.3217, LR=0.000100
[2025-08-27 18:22:58,723][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091776] [Batch 02456/03080] [00:29:44/00:07:33, 0.727s/it]: train_loss_raw=0.3034, running_loss=0.3196, LR=0.000100
[2025-08-27 18:23:04,445][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091784] [Batch 02464/03080] [00:29:50/00:07:27, 0.727s/it]: train_loss_raw=0.2702, running_loss=0.3201, LR=0.000100
[2025-08-27 18:23:09,943][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091792] [Batch 02472/03080] [00:29:55/00:07:21, 0.726s/it]: train_loss_raw=0.2890, running_loss=0.3195, LR=0.000100
[2025-08-27 18:23:15,464][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091800] [Batch 02480/03080] [00:30:01/00:07:15, 0.726s/it]: train_loss_raw=0.3945, running_loss=0.3211, LR=0.000100
[2025-08-27 18:23:20,998][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091808] [Batch 02488/03080] [00:30:06/00:07:09, 0.726s/it]: train_loss_raw=0.2950, running_loss=0.3223, LR=0.000100
[2025-08-27 18:23:26,598][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091816] [Batch 02496/03080] [00:30:12/00:07:04, 0.726s/it]: train_loss_raw=0.2473, running_loss=0.3210, LR=0.000100
[2025-08-27 18:23:32,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091824] [Batch 02504/03080] [00:30:18/00:06:58, 0.726s/it]: train_loss_raw=0.2961, running_loss=0.3210, LR=0.000100
[2025-08-27 18:23:38,656][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091832] [Batch 02512/03080] [00:30:24/00:06:52, 0.726s/it]: train_loss_raw=0.2883, running_loss=0.3211, LR=0.000100
[2025-08-27 18:23:44,265][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091840] [Batch 02520/03080] [00:30:30/00:06:46, 0.726s/it]: train_loss_raw=0.3799, running_loss=0.3222, LR=0.000100
[2025-08-27 18:23:50,272][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091848] [Batch 02528/03080] [00:30:36/00:06:40, 0.726s/it]: train_loss_raw=0.3409, running_loss=0.3222, LR=0.000100
[2025-08-27 18:23:56,099][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091856] [Batch 02536/03080] [00:30:41/00:06:35, 0.726s/it]: train_loss_raw=0.3271, running_loss=0.3233, LR=0.000100
[2025-08-27 18:24:01,696][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091864] [Batch 02544/03080] [00:30:47/00:06:29, 0.726s/it]: train_loss_raw=0.2682, running_loss=0.3241, LR=0.000100
[2025-08-27 18:24:07,513][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091872] [Batch 02552/03080] [00:30:53/00:06:23, 0.726s/it]: train_loss_raw=0.2569, running_loss=0.3228, LR=0.000100
[2025-08-27 18:24:13,543][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091880] [Batch 02560/03080] [00:30:59/00:06:17, 0.726s/it]: train_loss_raw=0.2997, running_loss=0.3212, LR=0.000100
[2025-08-27 18:24:19,602][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091888] [Batch 02568/03080] [00:31:05/00:06:11, 0.726s/it]: train_loss_raw=0.3009, running_loss=0.3205, LR=0.000100
[2025-08-27 18:24:25,111][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091896] [Batch 02576/03080] [00:31:10/00:06:06, 0.726s/it]: train_loss_raw=0.2761, running_loss=0.3210, LR=0.000100
[2025-08-27 18:24:30,791][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091904] [Batch 02584/03080] [00:31:16/00:06:00, 0.726s/it]: train_loss_raw=0.3465, running_loss=0.3223, LR=0.000100
[2025-08-27 18:24:36,447][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091912] [Batch 02592/03080] [00:31:22/00:05:54, 0.726s/it]: train_loss_raw=0.2769, running_loss=0.3205, LR=0.000100
[2025-08-27 18:24:42,166][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091920] [Batch 02600/03080] [00:31:28/00:05:48, 0.726s/it]: train_loss_raw=0.2325, running_loss=0.3205, LR=0.000100
[2025-08-27 18:24:48,040][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091928] [Batch 02608/03080] [00:31:33/00:05:42, 0.726s/it]: train_loss_raw=0.3740, running_loss=0.3202, LR=0.000100
[2025-08-27 18:24:53,832][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091936] [Batch 02616/03080] [00:31:39/00:05:36, 0.726s/it]: train_loss_raw=0.3355, running_loss=0.3195, LR=0.000100
[2025-08-27 18:24:59,760][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091944] [Batch 02624/03080] [00:31:45/00:05:31, 0.726s/it]: train_loss_raw=0.3335, running_loss=0.3188, LR=0.000100
[2025-08-27 18:25:05,455][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091952] [Batch 02632/03080] [00:31:51/00:05:25, 0.726s/it]: train_loss_raw=0.3113, running_loss=0.3193, LR=0.000100
[2025-08-27 18:25:10,865][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091960] [Batch 02640/03080] [00:31:56/00:05:19, 0.726s/it]: train_loss_raw=0.3098, running_loss=0.3175, LR=0.000100
[2025-08-27 18:25:16,861][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091968] [Batch 02648/03080] [00:32:02/00:05:13, 0.726s/it]: train_loss_raw=0.4114, running_loss=0.3185, LR=0.000100
[2025-08-27 18:25:22,918][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091976] [Batch 02656/03080] [00:32:08/00:05:07, 0.726s/it]: train_loss_raw=0.2551, running_loss=0.3189, LR=0.000100
[2025-08-27 18:25:28,806][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091984] [Batch 02664/03080] [00:32:14/00:05:02, 0.726s/it]: train_loss_raw=0.2905, running_loss=0.3203, LR=0.000100
[2025-08-27 18:25:34,756][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 091992] [Batch 02672/03080] [00:32:20/00:04:56, 0.726s/it]: train_loss_raw=0.2665, running_loss=0.3199, LR=0.000100
[2025-08-27 18:25:40,245][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092000] [Batch 02680/03080] [00:32:26/00:04:50, 0.726s/it]: train_loss_raw=0.3176, running_loss=0.3186, LR=0.000100
[2025-08-27 18:25:49,801][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092008] [Batch 02688/03080] [00:32:35/00:04:45, 0.728s/it]: train_loss_raw=0.4117, running_loss=0.3204, LR=0.000100
[2025-08-27 18:25:55,642][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092016] [Batch 02696/03080] [00:32:41/00:04:39, 0.728s/it]: train_loss_raw=0.3563, running_loss=0.3200, LR=0.000100
[2025-08-27 18:26:01,251][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092024] [Batch 02704/03080] [00:32:47/00:04:33, 0.727s/it]: train_loss_raw=0.3311, running_loss=0.3218, LR=0.000100
[2025-08-27 18:26:07,052][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092032] [Batch 02712/03080] [00:32:52/00:04:27, 0.727s/it]: train_loss_raw=0.3491, running_loss=0.3213, LR=0.000100
[2025-08-27 18:26:12,895][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092040] [Batch 02720/03080] [00:32:58/00:04:21, 0.727s/it]: train_loss_raw=0.2794, running_loss=0.3201, LR=0.000100
[2025-08-27 18:26:18,512][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092048] [Batch 02728/03080] [00:33:04/00:04:16, 0.727s/it]: train_loss_raw=0.2559, running_loss=0.3200, LR=0.000100
[2025-08-27 18:26:24,359][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092056] [Batch 02736/03080] [00:33:10/00:04:10, 0.727s/it]: train_loss_raw=0.2713, running_loss=0.3196, LR=0.000100
[2025-08-27 18:26:29,745][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092064] [Batch 02744/03080] [00:33:15/00:04:04, 0.727s/it]: train_loss_raw=0.3812, running_loss=0.3183, LR=0.000100
[2025-08-27 18:26:35,442][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092072] [Batch 02752/03080] [00:33:21/00:03:58, 0.727s/it]: train_loss_raw=0.3095, running_loss=0.3180, LR=0.000100
[2025-08-27 18:26:41,321][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092080] [Batch 02760/03080] [00:33:27/00:03:52, 0.727s/it]: train_loss_raw=0.3231, running_loss=0.3169, LR=0.000100
[2025-08-27 18:26:47,246][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092088] [Batch 02768/03080] [00:33:33/00:03:46, 0.727s/it]: train_loss_raw=0.3826, running_loss=0.3176, LR=0.000100
[2025-08-27 18:26:53,192][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092096] [Batch 02776/03080] [00:33:39/00:03:41, 0.727s/it]: train_loss_raw=0.3085, running_loss=0.3180, LR=0.000100
[2025-08-27 18:26:58,865][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092104] [Batch 02784/03080] [00:33:44/00:03:35, 0.727s/it]: train_loss_raw=0.2876, running_loss=0.3174, LR=0.000100
[2025-08-27 18:27:04,745][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092112] [Batch 02792/03080] [00:33:50/00:03:29, 0.727s/it]: train_loss_raw=0.3017, running_loss=0.3190, LR=0.000100
[2025-08-27 18:27:10,854][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092120] [Batch 02800/03080] [00:33:56/00:03:23, 0.727s/it]: train_loss_raw=0.2679, running_loss=0.3179, LR=0.000100
[2025-08-27 18:27:16,873][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092128] [Batch 02808/03080] [00:34:02/00:03:17, 0.727s/it]: train_loss_raw=0.2582, running_loss=0.3168, LR=0.000100
[2025-08-27 18:27:22,721][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092136] [Batch 02816/03080] [00:34:08/00:03:12, 0.727s/it]: train_loss_raw=0.3484, running_loss=0.3183, LR=0.000100
[2025-08-27 18:27:28,671][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092144] [Batch 02824/03080] [00:34:14/00:03:06, 0.728s/it]: train_loss_raw=0.3342, running_loss=0.3185, LR=0.000100
[2025-08-27 18:27:34,443][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092152] [Batch 02832/03080] [00:34:20/00:03:00, 0.727s/it]: train_loss_raw=0.3043, running_loss=0.3181, LR=0.000100
[2025-08-27 18:27:40,069][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092160] [Batch 02840/03080] [00:34:25/00:02:54, 0.727s/it]: train_loss_raw=0.2978, running_loss=0.3165, LR=0.000100
[2025-08-27 18:27:46,115][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092168] [Batch 02848/03080] [00:34:31/00:02:48, 0.728s/it]: train_loss_raw=0.3494, running_loss=0.3165, LR=0.000100
[2025-08-27 18:27:51,915][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092176] [Batch 02856/03080] [00:34:37/00:02:42, 0.728s/it]: train_loss_raw=0.2901, running_loss=0.3187, LR=0.000100
[2025-08-27 18:27:57,727][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092184] [Batch 02864/03080] [00:34:43/00:02:37, 0.728s/it]: train_loss_raw=0.3193, running_loss=0.3194, LR=0.000100
[2025-08-27 18:28:03,269][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092192] [Batch 02872/03080] [00:34:49/00:02:31, 0.727s/it]: train_loss_raw=0.3336, running_loss=0.3210, LR=0.000100
[2025-08-27 18:28:09,133][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092200] [Batch 02880/03080] [00:34:54/00:02:25, 0.727s/it]: train_loss_raw=0.3481, running_loss=0.3225, LR=0.000100
[2025-08-27 18:28:14,946][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092208] [Batch 02888/03080] [00:35:00/00:02:19, 0.727s/it]: train_loss_raw=0.3812, running_loss=0.3226, LR=0.000100
[2025-08-27 18:28:20,709][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092216] [Batch 02896/03080] [00:35:06/00:02:13, 0.727s/it]: train_loss_raw=0.3178, running_loss=0.3233, LR=0.000100
[2025-08-27 18:28:26,622][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092224] [Batch 02904/03080] [00:35:12/00:02:08, 0.727s/it]: train_loss_raw=0.2864, running_loss=0.3239, LR=0.000100
[2025-08-27 18:28:32,695][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092232] [Batch 02912/03080] [00:35:18/00:02:02, 0.728s/it]: train_loss_raw=0.2362, running_loss=0.3237, LR=0.000100
[2025-08-27 18:28:38,668][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092240] [Batch 02920/03080] [00:35:24/00:01:56, 0.728s/it]: train_loss_raw=0.3291, running_loss=0.3210, LR=0.000100
[2025-08-27 18:28:44,548][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092248] [Batch 02928/03080] [00:35:30/00:01:50, 0.728s/it]: train_loss_raw=0.3567, running_loss=0.3215, LR=0.000100
[2025-08-27 18:28:50,481][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092256] [Batch 02936/03080] [00:35:36/00:01:44, 0.728s/it]: train_loss_raw=0.3363, running_loss=0.3206, LR=0.000100
[2025-08-27 18:28:56,428][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092264] [Batch 02944/03080] [00:35:42/00:01:38, 0.728s/it]: train_loss_raw=0.2700, running_loss=0.3193, LR=0.000100
[2025-08-27 18:29:02,453][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092272] [Batch 02952/03080] [00:35:48/00:01:33, 0.728s/it]: train_loss_raw=0.2713, running_loss=0.3174, LR=0.000100
[2025-08-27 18:29:08,576][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092280] [Batch 02960/03080] [00:35:54/00:01:27, 0.728s/it]: train_loss_raw=0.2509, running_loss=0.3150, LR=0.000100
[2025-08-27 18:29:14,711][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092288] [Batch 02968/03080] [00:36:00/00:01:21, 0.728s/it]: train_loss_raw=0.2413, running_loss=0.3149, LR=0.000100
[2025-08-27 18:29:20,348][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092296] [Batch 02976/03080] [00:36:06/00:01:15, 0.728s/it]: train_loss_raw=0.3316, running_loss=0.3151, LR=0.000100
[2025-08-27 18:29:26,433][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092304] [Batch 02984/03080] [00:36:12/00:01:09, 0.728s/it]: train_loss_raw=0.3149, running_loss=0.3141, LR=0.000100
[2025-08-27 18:29:32,529][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092312] [Batch 02992/03080] [00:36:18/00:01:04, 0.728s/it]: train_loss_raw=0.3390, running_loss=0.3152, LR=0.000100
[2025-08-27 18:29:38,538][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092320] [Batch 03000/03080] [00:36:24/00:00:58, 0.728s/it]: train_loss_raw=0.3184, running_loss=0.3157, LR=0.000100
[2025-08-27 18:29:44,199][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092328] [Batch 03008/03080] [00:36:30/00:00:52, 0.728s/it]: train_loss_raw=0.2622, running_loss=0.3152, LR=0.000100
[2025-08-27 18:29:49,741][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092336] [Batch 03016/03080] [00:36:35/00:00:46, 0.728s/it]: train_loss_raw=0.3062, running_loss=0.3156, LR=0.000100
[2025-08-27 18:29:55,361][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092344] [Batch 03024/03080] [00:36:41/00:00:40, 0.728s/it]: train_loss_raw=0.3848, running_loss=0.3180, LR=0.000100
[2025-08-27 18:30:01,138][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092352] [Batch 03032/03080] [00:36:46/00:00:34, 0.728s/it]: train_loss_raw=0.2998, running_loss=0.3171, LR=0.000100
[2025-08-27 18:30:06,514][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092360] [Batch 03040/03080] [00:36:52/00:00:29, 0.728s/it]: train_loss_raw=0.2883, running_loss=0.3158, LR=0.000100
[2025-08-27 18:30:11,999][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092368] [Batch 03048/03080] [00:36:57/00:00:23, 0.728s/it]: train_loss_raw=0.2960, running_loss=0.3155, LR=0.000100
[2025-08-27 18:30:17,473][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092376] [Batch 03056/03080] [00:37:03/00:00:17, 0.728s/it]: train_loss_raw=0.3305, running_loss=0.3169, LR=0.000100
[2025-08-27 18:30:22,850][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092384] [Batch 03064/03080] [00:37:08/00:00:11, 0.727s/it]: train_loss_raw=0.3001, running_loss=0.3170, LR=0.000100
[2025-08-27 18:30:28,887][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092392] [Batch 03072/03080] [00:37:14/00:00:05, 0.727s/it]: train_loss_raw=0.3796, running_loss=0.3168, LR=0.000100
[2025-08-27 18:30:39,388][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 092400] [Batch 03080/03080] [00:37:25/00:00:00, 0.729s/it]: train_loss_raw=0.2675, running_loss=0.3181, LR=0.000100
[2025-08-27 18:30:39,903][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-27 18:30:50,658][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00007/00310] [00:00:10/00:06:45, 1.344s/it]
[2025-08-27 18:31:02,579][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00015/00310] [00:00:22/00:06:56, 1.417s/it]
[2025-08-27 18:31:14,376][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00023/00310] [00:00:34/00:06:50, 1.436s/it]
[2025-08-27 18:31:25,589][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00031/00310] [00:00:45/00:06:36, 1.428s/it]
[2025-08-27 18:31:36,748][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00039/00310] [00:00:56/00:06:23, 1.421s/it]
[2025-08-27 18:31:49,444][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00047/00310] [00:01:09/00:06:19, 1.449s/it]
[2025-08-27 18:32:01,359][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00055/00310] [00:01:21/00:06:09, 1.455s/it]
[2025-08-27 18:32:13,605][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00063/00310] [00:01:33/00:06:00, 1.464s/it]
[2025-08-27 18:32:25,203][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00071/00310] [00:01:45/00:05:48, 1.462s/it]
[2025-08-27 18:32:37,450][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00079/00310] [00:01:57/00:05:37, 1.469s/it]
[2025-08-27 18:32:49,519][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00087/00310] [00:02:09/00:05:26, 1.473s/it]
[2025-08-27 18:33:02,042][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00095/00310] [00:02:22/00:05:16, 1.481s/it]
[2025-08-27 18:33:13,736][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00103/00310] [00:02:33/00:05:04, 1.479s/it]
[2025-08-27 18:33:25,955][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00111/00310] [00:02:46/00:04:53, 1.483s/it]
[2025-08-27 18:33:37,780][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00119/00310] [00:02:57/00:04:41, 1.482s/it]
[2025-08-27 18:33:49,663][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00127/00310] [00:03:09/00:04:29, 1.483s/it]
[2025-08-27 18:34:01,936][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00135/00310] [00:03:22/00:04:18, 1.486s/it]
[2025-08-27 18:34:14,105][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00143/00310] [00:03:34/00:04:06, 1.488s/it]
[2025-08-27 18:34:24,039][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00151/00310] [00:03:44/00:03:52, 1.475s/it]
[2025-08-27 18:34:34,458][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00159/00310] [00:03:54/00:03:39, 1.466s/it]
[2025-08-27 18:34:46,718][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00167/00310] [00:04:06/00:03:28, 1.469s/it]
[2025-08-27 18:34:56,316][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00175/00310] [00:04:16/00:03:15, 1.457s/it]
[2025-08-27 18:35:06,042][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00183/00310] [00:04:26/00:03:02, 1.446s/it]
[2025-08-27 18:35:16,915][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00191/00310] [00:04:37/00:02:50, 1.443s/it]
[2025-08-27 18:35:28,273][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00199/00310] [00:04:48/00:02:38, 1.442s/it]
[2025-08-27 18:35:39,192][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00207/00310] [00:04:59/00:02:26, 1.439s/it]
[2025-08-27 18:35:50,483][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00215/00310] [00:05:10/00:02:15, 1.438s/it]
[2025-08-27 18:36:00,912][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00223/00310] [00:05:21/00:02:03, 1.433s/it]
[2025-08-27 18:36:12,550][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00231/00310] [00:05:32/00:01:51, 1.434s/it]
[2025-08-27 18:36:24,216][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00239/00310] [00:05:44/00:01:40, 1.435s/it]
[2025-08-27 18:36:34,713][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00247/00310] [00:05:54/00:01:28, 1.431s/it]
[2025-08-27 18:36:45,111][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00255/00310] [00:06:05/00:01:17, 1.427s/it]
[2025-08-27 18:36:56,443][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00263/00310] [00:06:16/00:01:05, 1.426s/it]
[2025-08-27 18:37:07,674][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00271/00310] [00:06:27/00:00:54, 1.426s/it]
[2025-08-27 18:37:19,575][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00279/00310] [00:06:39/00:00:42, 1.427s/it]
[2025-08-27 18:37:31,783][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00287/00310] [00:06:51/00:00:31, 1.430s/it]
[2025-08-27 18:37:42,140][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00295/00310] [00:07:02/00:00:19, 1.426s/it]
[2025-08-27 18:37:54,849][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 092401] [Batch 00303/00310] [00:07:14/00:00:08, 1.431s/it]
[2025-08-27 18:38:04,344][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.31813, valid_loss=1.46971
[2025-08-27 18:38:04,344][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-27 18:38:04,344][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.482
[2025-08-27 18:38:04,344][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.158
[2025-08-27 18:38:04,345][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.162
[2025-08-27 18:38:04,345][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.088
[2025-08-27 18:38:04,353][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 23:11:18, remaining time 00:00:00, 00:46:22 per epoch
[2025-08-27 18:38:05,078][__main__][INFO] - InstaNovo training finished.
